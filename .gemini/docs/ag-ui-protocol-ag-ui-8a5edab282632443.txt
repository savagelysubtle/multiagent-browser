Directory structure:
└── ag-ui-protocol-ag-ui/
    ├── README.md
    ├── CLAUDE.md
    ├── CONTRIBUTING.md
    ├── LICENSE
    ├── docs/
    │   ├── README.md
    │   ├── ag_ui.md
    │   ├── docs.json
    │   ├── integrations.mdx
    │   ├── introduction.mdx
    │   ├── LICENSE
    │   ├── package.json
    │   ├── .prettierignore
    │   ├── .prettierrc
    │   ├── concepts/
    │   │   ├── agents.mdx
    │   │   ├── architecture.mdx
    │   │   ├── events.mdx
    │   │   ├── messages.mdx
    │   │   ├── state.mdx
    │   │   └── tools.mdx
    │   ├── development/
    │   │   ├── contributing.mdx
    │   │   ├── roadmap.mdx
    │   │   └── updates.mdx
    │   ├── drafts/
    │   │   ├── activity-events.mdx
    │   │   ├── generative-ui.mdx
    │   │   ├── interrupts.mdx
    │   │   ├── meta-events.mdx
    │   │   ├── multimodal-messages.mdx
    │   │   ├── overview.mdx
    │   │   ├── reasoning.mdx
    │   │   └── serialization.mdx
    │   ├── icons/
    │   │   ├── custom-icons.tsx
    │   │   └── index.tsx
    │   ├── images/
    │   │   └── left-illustration.avif
    │   ├── quickstart/
    │   │   ├── applications.mdx
    │   │   ├── clients.mdx
    │   │   ├── introduction.mdx
    │   │   ├── middleware.mdx
    │   │   └── server.mdx
    │   ├── sdk/
    │   │   ├── js/
    │   │   │   ├── encoder.mdx
    │   │   │   ├── overview.mdx
    │   │   │   ├── proto.mdx
    │   │   │   ├── client/
    │   │   │   │   ├── abstract-agent.mdx
    │   │   │   │   ├── http-agent.mdx
    │   │   │   │   ├── overview.mdx
    │   │   │   │   └── subscriber.mdx
    │   │   │   └── core/
    │   │   │       ├── events.mdx
    │   │   │       ├── overview.mdx
    │   │   │       └── types.mdx
    │   │   └── python/
    │   │       ├── core/
    │   │       │   ├── events.mdx
    │   │       │   ├── overview.mdx
    │   │       │   └── types.mdx
    │   │       └── encoder/
    │   │           └── overview.mdx
    │   ├── snippets/
    │   │   └── snippet-intro.mdx
    │   └── tutorials/
    │       ├── cursor.mdx
    │       └── debugging.mdx
    ├── python-sdk/
    │   ├── README.md
    │   ├── LICENSE
    │   ├── pyproject.toml
    │   ├── ag_ui/
    │   │   ├── py.typed
    │   │   ├── core/
    │   │   │   ├── __init__.py
    │   │   │   ├── events.py
    │   │   │   └── types.py
    │   │   └── encoder/
    │   │       ├── __init__.py
    │   │       └── encoder.py
    │   └── tests/
    │       ├── __init__.py
    │       ├── test_encoder.py
    │       ├── test_events.py
    │       ├── test_text_roles.py
    │       └── test_types.py
    ├── typescript-sdk/
    │   ├── README.md
    │   ├── LICENSE
    │   ├── package.json
    │   ├── pnpm-workspace.yaml
    │   ├── tsconfig.json
    │   ├── turbo.json
    │   ├── .npmrc
    │   ├── .prettierrc
    │   ├── apps/
    │   │   ├── client-cli-example/
    │   │   │   ├── README.md
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   └── src/
    │   │   │       ├── agent.ts
    │   │   │       ├── index.ts
    │   │   │       └── tools/
    │   │   │           ├── browser.tool.ts
    │   │   │           └── weather.tool.ts
    │   │   └── dojo/
    │   │       ├── README.md
    │   │       ├── eslint.config.mjs
    │   │       ├── LICENSE
    │   │       ├── next.config.ts
    │   │       ├── package.json
    │   │       ├── postcss.config.mjs
    │   │       ├── tailwind.config.ts
    │   │       ├── tsconfig.json
    │   │       ├── e2e/
    │   │       │   ├── README.md
    │   │       │   ├── clean-reporter.js
    │   │       │   ├── package.json
    │   │       │   ├── playwright.config.ts
    │   │       │   ├── pnpm-workspace.yaml
    │   │       │   ├── setup-aws.sh
    │   │       │   ├── slack-layout-simple.ts
    │   │       │   ├── slack-layout.ts
    │   │       │   ├── test-isolation-helper.ts
    │   │       │   ├── test-isolation-setup.ts
    │   │       │   ├── VIDEO_SETUP.md
    │   │       │   ├── featurePages/
    │   │       │   │   ├── AgenticChatPage.ts
    │   │       │   │   ├── SharedStatePage.ts
    │   │       │   │   └── ToolBaseGenUIPage.ts
    │   │       │   ├── lib/
    │   │       │   │   └── upload-video.ts
    │   │       │   ├── pages/
    │   │       │   │   ├── adkMiddlewarePages/
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   └── PredictiveStateUpdatesPage.ts
    │   │       │   │   ├── crewAIPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   └── PredictiveStateUpdatesPage.ts
    │   │       │   │   ├── langGraphFastAPIPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   ├── PredictiveStateUpdatesPage.ts
    │   │       │   │   │   └── SubgraphsPage.ts
    │   │       │   │   ├── langGraphPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   ├── PredictiveStateUpdatesPage.ts
    │   │       │   │   │   └── SubgraphsPage.ts
    │   │       │   │   ├── llamaIndexPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   └── HumanInLoopPage.ts
    │   │       │   │   ├── pydanticAIPages/
    │   │       │   │   │   ├── AgenticUIGenPage.ts
    │   │       │   │   │   ├── HumanInLoopPage.ts
    │   │       │   │   │   └── PredictiveStateUpdatesPage.ts
    │   │       │   │   └── serverStarterAllFeaturesPages/
    │   │       │   │       ├── AgenticUIGenPage.ts
    │   │       │   │       ├── HumanInLoopPage.ts
    │   │       │   │       └── PredictiveStateUpdatesPage.ts
    │   │       │   ├── reporters/
    │   │       │   │   └── s3-video-reporter.ts
    │   │       │   ├── tests/
    │   │       │   │   ├── copilotkit-home.spec.ts
    │   │       │   │   ├── adkMiddlewareTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── agnoTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── crewAITests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── integration/
    │   │       │   │   │   └── ai-features.spec.ts
    │   │       │   │   ├── langgraphFastAPITests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   ├── subgraphsPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── langgraphPythonTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   ├── subgraphsPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── langgraphTypescriptTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   ├── subgraphsPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── llamaIndexTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   └── sharedStatePage.spec.ts
    │   │       │   │   ├── mastraAgentLocalTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── mastraTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── middlewareStarterTests/
    │   │       │   │   │   └── agenticChatPage.spec.ts
    │   │       │   │   ├── pydanticAITests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── serverStarterAllFeaturesTests/
    │   │       │   │   │   ├── agenticChatPage.spec.ts
    │   │       │   │   │   ├── agenticGenUI.spec.ts
    │   │       │   │   │   ├── humanInTheLoopPage.spec.ts
    │   │       │   │   │   ├── predictiveStateUpdatePage.spec.ts
    │   │       │   │   │   ├── sharedStatePage.spec.ts
    │   │       │   │   │   └── toolBasedGenUIPage.spec.ts
    │   │       │   │   ├── serverStarterTests/
    │   │       │   │   │   └── agenticChatPage.spec.ts
    │   │       │   │   ├── smoke-only/
    │   │       │   │   │   └── basic-loading.spec.ts
    │   │       │   │   └── vercelAISdkTests/
    │   │       │   │       └── agenticChatPage.spec.ts
    │   │       │   └── utils/
    │   │       │       └── aiWaitHelpers.ts
    │   │       ├── public/
    │   │       │   ├── logo_dark.webp
    │   │       │   └── logo_light.webp
    │   │       ├── scripts/
    │   │       │   ├── generate-content-json.ts
    │   │       │   ├── link-cpk.js
    │   │       │   ├── prep-dojo-everything.js
    │   │       │   └── run-dojo-everything.js
    │   │       └── src/
    │   │           ├── agents.ts
    │   │           ├── config.ts
    │   │           ├── env.ts
    │   │           ├── menu.ts
    │   │           ├── app/
    │   │           │   ├── globals.css
    │   │           │   ├── layout.tsx
    │   │           │   ├── page.tsx
    │   │           │   ├── [integrationId]/
    │   │           │   │   ├── not-found.tsx
    │   │           │   │   ├── page.tsx
    │   │           │   │   └── feature/
    │   │           │   │       ├── layout.tsx
    │   │           │   │       ├── agentic_chat/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── agentic_chat_reasoning/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── agentic_generative_ui/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── human_in_the_loop/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── predictive_state_updates/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── shared_state/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       ├── subgraphs/
    │   │           │   │       │   ├── README.mdx
    │   │           │   │       │   ├── page.tsx
    │   │           │   │       │   └── style.css
    │   │           │   │       └── tool_based_generative_ui/
    │   │           │   │           ├── README.mdx
    │   │           │   │           ├── page.tsx
    │   │           │   │           └── style.css
    │   │           │   └── api/
    │   │           │       └── copilotkit/
    │   │           │           └── [integrationId]/
    │   │           │               └── route.ts
    │   │           ├── components/
    │   │           │   ├── theme-provider.tsx
    │   │           │   ├── code-viewer/
    │   │           │   │   ├── code-editor.tsx
    │   │           │   │   └── code-viewer.tsx
    │   │           │   ├── demo-list/
    │   │           │   │   └── demo-list.tsx
    │   │           │   ├── file-tree/
    │   │           │   │   ├── file-tree-nav.tsx
    │   │           │   │   └── file-tree.tsx
    │   │           │   ├── layout/
    │   │           │   │   ├── main-layout.tsx
    │   │           │   │   └── viewer-layout.tsx
    │   │           │   ├── readme/
    │   │           │   │   └── readme.tsx
    │   │           │   ├── sidebar/
    │   │           │   │   └── sidebar.tsx
    │   │           │   └── ui/
    │   │           │       ├── badge.tsx
    │   │           │       ├── button.tsx
    │   │           │       ├── dropdown-menu.tsx
    │   │           │       ├── markdown-components.tsx
    │   │           │       ├── mdx-components.tsx
    │   │           │       ├── tabs.tsx
    │   │           │       └── theme-toggle.tsx
    │   │           ├── contexts/
    │   │           │   └── url-params-context.tsx
    │   │           ├── lib/
    │   │           │   └── utils.ts
    │   │           ├── mastra/
    │   │           │   └── index.ts
    │   │           ├── styles/
    │   │           │   └── typography.css
    │   │           ├── types/
    │   │           │   ├── feature.ts
    │   │           │   ├── integration.ts
    │   │           │   └── interface.ts
    │   │           └── utils/
    │   │               ├── domain-config.ts
    │   │               ├── mdx-utils.tsx
    │   │               ├── use-mobile-chat.ts
    │   │               └── use-mobile-view.ts
    │   ├── integrations/
    │   │   ├── adk-middleware/
    │   │   │   ├── README.md
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── python/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── ARCHITECTURE.md
    │   │   │   │   ├── CHANGELOG.md
    │   │   │   │   ├── CONFIGURATION.md
    │   │   │   │   ├── LOGGING.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── pytest.ini
    │   │   │   │   ├── TOOLS.md
    │   │   │   │   ├── USAGE.md
    │   │   │   │   ├── examples/
    │   │   │   │   │   ├── README.md
    │   │   │   │   │   ├── pyproject.toml
    │   │   │   │   │   ├── other/
    │   │   │   │   │   │   ├── complete_setup.py
    │   │   │   │   │   │   ├── configure_adk_agent.py
    │   │   │   │   │   │   └── simple_agent.py
    │   │   │   │   │   └── server/
    │   │   │   │   │       ├── __init__.py
    │   │   │   │   │       └── api/
    │   │   │   │   │           ├── __init__.py
    │   │   │   │   │           ├── agentic_chat.py
    │   │   │   │   │           ├── human_in_the_loop.py
    │   │   │   │   │           ├── predictive_state_updates.py
    │   │   │   │   │           ├── shared_state.py
    │   │   │   │   │           └── tool_based_generative_ui.py
    │   │   │   │   ├── src/
    │   │   │   │   │   └── ag_ui_adk/
    │   │   │   │   │       ├── __init__.py
    │   │   │   │   │       ├── adk_agent.py
    │   │   │   │   │       ├── client_proxy_tool.py
    │   │   │   │   │       ├── client_proxy_toolset.py
    │   │   │   │   │       ├── endpoint.py
    │   │   │   │   │       ├── event_translator.py
    │   │   │   │   │       ├── execution_state.py
    │   │   │   │   │       ├── session_manager.py
    │   │   │   │   │       └── utils/
    │   │   │   │   │           ├── __init__.py
    │   │   │   │   │           └── converters.py
    │   │   │   │   └── tests/
    │   │   │   │       ├── __init__.py
    │   │   │   │       ├── run_all_tests.sh
    │   │   │   │       ├── server_setup.py
    │   │   │   │       ├── test_adk_agent.py
    │   │   │   │       ├── test_adk_agent_memory_integration.py
    │   │   │   │       ├── test_app_name_extractor.py
    │   │   │   │       ├── test_basic.py
    │   │   │   │       ├── test_chunk_event.py
    │   │   │   │       ├── test_client_proxy_tool.py
    │   │   │   │       ├── test_client_proxy_toolset.py
    │   │   │   │       ├── test_concurrency.py
    │   │   │   │       ├── test_concurrent_limits.py
    │   │   │   │       ├── test_credential_service_defaults.py
    │   │   │   │       ├── test_endpoint.py
    │   │   │   │       ├── test_endpoint_error_handling.py
    │   │   │   │       ├── test_event_bookending.py
    │   │   │   │       ├── test_event_translator_comprehensive.py
    │   │   │   │       ├── test_execution_state.py
    │   │   │   │       ├── test_integration.py
    │   │   │   │       ├── test_session_cleanup.py
    │   │   │   │       ├── test_session_creation.py
    │   │   │   │       ├── test_session_deletion.py
    │   │   │   │       ├── test_session_memory.py
    │   │   │   │       ├── test_streaming.py
    │   │   │   │       ├── test_text_events.py
    │   │   │   │       ├── test_tool_error_handling.py
    │   │   │   │       ├── test_tool_result_flow.py
    │   │   │   │       ├── test_tool_tracking_hitl.py
    │   │   │   │       ├── test_user_id_extractor.py
    │   │   │   │       ├── test_utils_converters.py
    │   │   │   │       └── test_utils_init.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── agno/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── examples/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── requirements.txt
    │   │   │   │   └── server/
    │   │   │   │       ├── __init__.py
    │   │   │   │       └── api/
    │   │   │   │           ├── __init__.py
    │   │   │   │           ├── agentic_chat.py
    │   │   │   │           └── tool_based_generative_ui.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── crewai/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── python/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── ag_ui_crewai/
    │   │   │   │   │   ├── __init__.py
    │   │   │   │   │   ├── context.py
    │   │   │   │   │   ├── crews.py
    │   │   │   │   │   ├── dojo.py
    │   │   │   │   │   ├── endpoint.py
    │   │   │   │   │   ├── enterprise.py
    │   │   │   │   │   ├── events.py
    │   │   │   │   │   ├── sdk.py
    │   │   │   │   │   ├── utils.py
    │   │   │   │   │   └── examples/
    │   │   │   │   │       ├── __init__.py
    │   │   │   │   │       ├── agentic_chat.py
    │   │   │   │   │       ├── agentic_generative_ui.py
    │   │   │   │   │       ├── human_in_the_loop.py
    │   │   │   │   │       ├── predictive_state_updates.py
    │   │   │   │   │       ├── shared_state.py
    │   │   │   │   │       └── tool_based_generative_ui.py
    │   │   │   │   └── tests/
    │   │   │   │       └── __init__.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── langgraph/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── examples/
    │   │   │   │   ├── python/
    │   │   │   │   │   ├── README.md
    │   │   │   │   │   ├── langgraph.json
    │   │   │   │   │   ├── pyproject.toml
    │   │   │   │   │   ├── .env.example
    │   │   │   │   │   └── agents/
    │   │   │   │   │       ├── __init__.py
    │   │   │   │   │       ├── dojo.py
    │   │   │   │   │       ├── agentic_chat/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── agentic_chat_reasoning/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── agentic_generative_ui/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── human_in_the_loop/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── predictive_state_updates/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── shared_state/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       ├── subgraphs/
    │   │   │   │   │       │   ├── __init__.py
    │   │   │   │   │       │   └── agent.py
    │   │   │   │   │       └── tool_based_generative_ui/
    │   │   │   │   │           ├── __init__.py
    │   │   │   │   │           └── agent.py
    │   │   │   │   └── typescript/
    │   │   │   │       ├── README.md
    │   │   │   │       ├── langgraph.json
    │   │   │   │       ├── package.json
    │   │   │   │       ├── pnpm-lock.yaml
    │   │   │   │       ├── pnpm-workspace.yaml
    │   │   │   │       ├── tsconfig.json
    │   │   │   │       ├── .env.example
    │   │   │   │       └── src/
    │   │   │   │           └── agents/
    │   │   │   │               ├── agentic_chat/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── agentic_generative_ui/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── human_in_the_loop/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── predictive_state_updates/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── shared_state/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               ├── subgraphs/
    │   │   │   │               │   └── agent.ts
    │   │   │   │               └── tool_based_generative_ui/
    │   │   │   │                   └── agent.ts
    │   │   │   ├── python/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   ├── ag_ui_langgraph/
    │   │   │   │   │   ├── __init__.py
    │   │   │   │   │   ├── agent.py
    │   │   │   │   │   ├── endpoint.py
    │   │   │   │   │   ├── types.py
    │   │   │   │   │   └── utils.py
    │   │   │   │   └── tests/
    │   │   │   │       └── __init__.py
    │   │   │   └── src/
    │   │   │       ├── agent.ts
    │   │   │       ├── index.ts
    │   │   │       ├── types.ts
    │   │   │       └── utils.ts
    │   │   ├── llamaindex/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── server-py/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   └── server/
    │   │   │   │       ├── __init__.py
    │   │   │   │       └── routers/
    │   │   │   │           ├── agentic_chat.py
    │   │   │   │           ├── agentic_generative_ui.py
    │   │   │   │           ├── human_in_the_loop.py
    │   │   │   │           └── shared_state.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── mastra/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── example/
    │   │   │   │   ├── package.json
    │   │   │   │   ├── tsconfig.json
    │   │   │   │   └── src/
    │   │   │   │       └── mastra/
    │   │   │   │           ├── index.ts
    │   │   │   │           ├── agents/
    │   │   │   │           │   ├── agentic-chat.ts
    │   │   │   │           │   └── tool-based-generative-ui.ts
    │   │   │   │           └── tools/
    │   │   │   │               └── weather-tool.ts
    │   │   │   └── src/
    │   │   │       ├── copilotkit.ts
    │   │   │       ├── index.ts
    │   │   │       ├── mastra.ts
    │   │   │       └── utils.ts
    │   │   ├── middleware-starter/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── pydantic-ai/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── examples/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── pyproject.toml
    │   │   │   │   └── server/
    │   │   │   │       ├── __init__.py
    │   │   │   │       └── api/
    │   │   │   │           ├── __init__.py
    │   │   │   │           ├── agentic_chat.py
    │   │   │   │           ├── agentic_generative_ui.py
    │   │   │   │           ├── human_in_the_loop.py
    │   │   │   │           ├── predictive_state_updates.py
    │   │   │   │           ├── shared_state.py
    │   │   │   │           └── tool_based_generative_ui.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── server-starter/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── server/
    │   │   │   │   └── python/
    │   │   │   │       ├── README.md
    │   │   │   │       ├── pyproject.toml
    │   │   │   │       ├── example_server/
    │   │   │   │       │   └── __init__.py
    │   │   │   │       └── tests/
    │   │   │   │           └── __init__.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── server-starter-all-features/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   ├── server/
    │   │   │   │   └── python/
    │   │   │   │       ├── README.md
    │   │   │   │       ├── pyproject.toml
    │   │   │   │       ├── example_server/
    │   │   │   │       │   ├── __init__.py
    │   │   │   │       │   ├── agentic_chat.py
    │   │   │   │       │   ├── agentic_generative_ui.py
    │   │   │   │       │   ├── human_in_the_loop.py
    │   │   │   │       │   ├── predictive_state_updates.py
    │   │   │   │       │   ├── shared_state.py
    │   │   │   │       │   └── tool_based_generative_ui.py
    │   │   │   │       └── tests/
    │   │   │   │           └── __init__.py
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   └── vercel-ai-sdk/
    │   │       ├── README.md
    │   │       ├── jest.config.js
    │   │       ├── package.json
    │   │       ├── tsconfig.json
    │   │       ├── tsup.config.ts
    │   │       ├── .npmignore
    │   │       └── src/
    │   │           └── index.ts
    │   ├── packages/
    │   │   ├── cli/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       └── index.ts
    │   │   ├── client/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       ├── index.ts
    │   │   │       ├── utils.ts
    │   │   │       ├── agent/
    │   │   │       │   ├── agent.ts
    │   │   │       │   ├── http.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── subscriber.ts
    │   │   │       │   ├── types.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── agent-concurrent.test.ts
    │   │   │       │       ├── agent-multiple-runs.test.ts
    │   │   │       │       ├── agent-mutations.test.ts
    │   │   │       │       ├── agent-result.test.ts
    │   │   │       │       ├── agent-text-roles.test.ts
    │   │   │       │       ├── http.test.ts
    │   │   │       │       ├── legacy-bridged.test.ts
    │   │   │       │       └── subscriber.test.ts
    │   │   │       ├── apply/
    │   │   │       │   ├── default.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── default.concurrent.test.ts
    │   │   │       │       ├── default.state.test.ts
    │   │   │       │       ├── default.text-message.test.ts
    │   │   │       │       └── default.tool-calls.test.ts
    │   │   │       ├── chunks/
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── transform.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── transform-roles.test.ts
    │   │   │       │       └── transform.test.ts
    │   │   │       ├── legacy/
    │   │   │       │   ├── convert.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── types.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── convert.concurrent.test.ts
    │   │   │       │       ├── convert.predictive.test.ts
    │   │   │       │       ├── convert.state.test.ts
    │   │   │       │       └── convert.tool-calls.test.ts
    │   │   │       ├── run/
    │   │   │       │   ├── http-request.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       └── http-request.test.ts
    │   │   │       ├── transform/
    │   │   │       │   ├── http.ts
    │   │   │       │   ├── index.ts
    │   │   │       │   ├── proto.ts
    │   │   │       │   ├── sse.ts
    │   │   │       │   └── __tests__/
    │   │   │       │       ├── http.test.ts
    │   │   │       │       ├── proto.test.ts
    │   │   │       │       └── sse.test.ts
    │   │   │       └── verify/
    │   │   │           ├── index.ts
    │   │   │           ├── verify.ts
    │   │   │           └── __tests__/
    │   │   │               ├── verify.concurrent.test.ts
    │   │   │               ├── verify.events.test.ts
    │   │   │               ├── verify.lifecycle.test.ts
    │   │   │               ├── verify.multiple-runs.test.ts
    │   │   │               ├── verify.steps.test.ts
    │   │   │               ├── verify.text-messages.test.ts
    │   │   │               └── verify.tool-calls.test.ts
    │   │   ├── core/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       ├── events.ts
    │   │   │       ├── index.ts
    │   │   │       ├── types.ts
    │   │   │       └── __tests__/
    │   │   │           ├── events-role-defaults.test.ts
    │   │   │           └── index.test.ts
    │   │   ├── encoder/
    │   │   │   ├── README.md
    │   │   │   ├── jest.config.js
    │   │   │   ├── package.json
    │   │   │   ├── tsconfig.json
    │   │   │   ├── tsup.config.ts
    │   │   │   ├── .npmignore
    │   │   │   └── src/
    │   │   │       ├── encoder.ts
    │   │   │       ├── index.ts
    │   │   │       ├── media-type.ts
    │   │   │       └── __tests__/
    │   │   │           └── encoder.test.ts
    │   │   └── proto/
    │   │       ├── README.md
    │   │       ├── jest.config.js
    │   │       ├── package.json
    │   │       ├── tsconfig.json
    │   │       ├── tsup.config.ts
    │   │       ├── .npmignore
    │   │       ├── __tests__/
    │   │       │   ├── message-events.test.ts
    │   │       │   ├── proto.test.ts
    │   │       │   ├── run-events.test.ts
    │   │       │   ├── state-events.test.ts
    │   │       │   ├── test-utils.ts
    │   │       │   └── tool-call-events.test.ts
    │   │       └── src/
    │   │           ├── index.ts
    │   │           ├── proto.ts
    │   │           └── proto/
    │   │               ├── events.proto
    │   │               ├── patch.proto
    │   │               └── types.proto
    │   └── .cursor/
    │       └── rules/
    │           └── project-rules.mdc
    └── .github/
        ├── CODEOWNERS
        └── workflows/
            ├── check-generated-files.yml
            ├── dojo-e2e.yml
            └── test.yml

================================================
FILE: README.md
================================================

# <img src="https://github.com/user-attachments/assets/ebc0dd08-8732-4519-9b6c-452ce54d8058" alt="ag-ui Logo" width="22"/> AG-UI: The Agent-User Interaction Protocol

AG-UI is an open, lightweight, event-based protocol that standardizes how AI agents connect to user-facing applications.
Built for simplicity and flexibility, it enables seamless integration between AI agents, real time user context, and user interfaces.

---


<br>


[![Version](https://img.shields.io/npm/v/@ag-ui/core?label=Version&color=6963ff&logo=npm&logoColor=white)](https://www.npmjs.com/package/@ag-ui/core)
![MIT](https://img.shields.io/github/license/copilotkit/copilotkit?color=%236963ff&label=License)
![Discord](https://img.shields.io/discord/1379082175625953370?logo=discord&logoColor=%23FFFFFF&label=Discord&color=%236963ff)

<a href="https://discord.gg/Jd3FzfdJa8" target="_blank"> Join our Discord → </a> &nbsp;&nbsp;&nbsp; <a href="https://ag-ui.com/" target="_blank"> Read the Docs → </a> &nbsp;&nbsp;&nbsp; <a href="https://dojo.ag-ui.com/" target="_blank"> Go to the AG-UI Dojo → </a> &nbsp;&nbsp;&nbsp; <a href="https://x.com/CopilotKit" target="_blank"> Follow us → </a>

<img width="4096" height="1752" alt="Your application-AG-UI protocol" src="https://github.com/user-attachments/assets/dc58c64c-3257-490a-b827-e163475f4166" />

## 🚀 Getting Started
Create a new AG-UI application in seconds:
```bash
npx create-ag-ui-app my-agent-app
```

<h3> Useful Links:</h3>

- [The AG-UI Dojo](https://dojo.ag-ui.com/)
- [Build AG-UI-powered applications(Quickstart)](https://docs.ag-ui.com/quickstart/applications)
- [Build new AG-UI framework integrations (Quickstart)](https://go.copilotkit.ai/agui-contribute)
- [Book a call to discuss an AG-UI integration with a new framework](https://calendly.com/markus-copilotkit/ag-ui)
- [Join the Discord Community](https://discord.gg/Jd3FzfdJa8)

## What is AG-UI?

AG-UI is an open, lightweight, event-based protocol for agent-human interaction, designed for simplicity & flexibility:

- During agent executions, agent backends **emit events _compatible_ with one of AG-UI's ~16 standard event types**
- Agent backends can **accept one of a few simple AG-UI compatible inputs** as arguments

**AG-UI includes a flexible middleware layer** that ensures compatibility across diverse environments:

- Works with **any event transport** (SSE, WebSockets, webhooks, etc.)
- Allows for **loose event format matching**, enabling broad agent and app interoperability

It also ships with a **reference HTTP implementation** and **default connector** to help teams get started fast.


[Learn more about the specs →](https://go.copilotkit.ai/ag-ui-introduction)


## Why AG-UI?

AG-UI was developed based on real-world requirements and practical experience building in-app agent interactions.


## Where does AGUI fit in the agentic protocol stack?
AG-UI is complementary to the other 2 top agentic protocols
- MCP gives agents tools
- A2A allows agents to communicate with other agents
- AG-UI brings agents into user-facing applications

<div align="center">
  <img width="2048" height="1182" alt="The Agent Protocol Stack" src="https://github.com/user-attachments/assets/41138f71-50be-4812-98aa-20e0ad595716" />
</div>  
   
## 🚀 Features

- 💬 Real-time agentic chat with streaming
- 🔄 Bi-directional state synchronization
- 🧩 Generative UI and structured messages
- 🧠 Real-time context enrichment
- 🛠️ Frontend tool integration
- 🧑‍💻 Human-in-the-loop collaboration


## 🛠 Supported Frameworks

AG-UI was born from CopilotKit's initial partnership with LangGraph and CrewAI - and brings the incredibly popular agent-user-interactivity infrastructure to the wider agentic ecosystem.

| Framework                                                          | Status                   | AG-UI Resources                                                              | Integrations             | 
| ------------------------------------------------------------------ | ------------------------ | ---------------------------------------------------------------------------- | ------------------------ |
| No-framework                                                       | ✅ Supported             | ➡️ Docs coming soon                                                          |                          |
| [LangGraph](https://www.langchain.com/langgraph)                   | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/langgraph/) 🎮 [Demos](https://dojo.ag-ui.com/langgraph-fastapi/feature/shared_state)                           | Partnership              |
| [CrewAI](https://crewai.com/)                                      | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/crewai-flows) 🎮 [Demos](https://dojo.ag-ui.com/crewai/feature/shared_state)                          | Partnership              |
| [Mastra](https://mastra.ai/)                                       | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/mastra/) 🎮 [Demos](https://dojo.ag-ui.com/mastra)                               | 1st party                |
| [AG2](https://ag2.ai/)                                             | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/ag2/)                                  | 1st party                |
| [Agno](https://github.com/agno-agi/agno)                           | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/agno/) 🎮 [Demos](https://dojo.ag-ui.com/agno)                                  | 1st party                |
| [LlamaIndex](https://github.com/run-llama/llama_index)             | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/llamaindex/) 🎮 [Demos](https://dojo.ag-ui.com/llamaindex/feature/shared_state)                            | 1st party                |
| [Pydantic AI](https://github.com/pydantic/pydantic-ai)             | ✅ Supported             | ➡️ [Docs](https://docs.copilotkit.ai/pydantic-ai/) 🎮 [Demos](https://dojo.ag-ui.com/pydantic-ai/feature/shared_state)                           | 1st party                | 
| [Google ADK](https://google.github.io/adk-docs/get-started/)       | ✅ Supported            | ➡️ [Docs](https://docs.copilotkit.ai/adk) 🎮 [Demos](https://dojo.ag-ui.com/adk-middleware)                                                                            | Partnership                |
| [AWS Bedrock Agents](https://aws.amazon.com/bedrock/agents/)       | 🛠️ In Progress           | –                                                                            | 1st party                |
| [AWS Strands Agents](https://github.com/strands-agents/sdk-python) | 🛠️ In Progress           | –                                                                            | 1st Party                |   
| [Vercel AI SDK](https://github.com/vercel/ai)                      | 🛠️ In Progress           | –                                                                            | Community                |
| [OpenAI Agent SDK](https://openai.github.io/openai-agents-python/) | 🛠️ In Progress           | –                                                                            | Community                |
| [Cloudflare Agents](https://developers.cloudflare.com/agents/)     | 💡 Open to Contributions | –                                                                            | Community                |

[View all supported frameworks →](https://ag-ui.com/frameworks)


| Language SDK                                                       | Status                    | AG-UI Resources                                                              |
| ------------------------------------------------------------------ | ------------------------  | ---------------------------------------------------------------------------- |
| [Kotlin]()                                                         | ✅ Supported              | ➡️ [GitHub Source](https://github.com/Contextable/ag-ui-4k)                  |
| [.NET]()                                                           | 🛠️ In Progress            | ➡️ [PR](https://github.com/ag-ui-protocol/ag-ui/pull/38)                     |
| [Nim]()                                                            | 🛠️ In Progress            | ➡️ [PR](https://github.com/ag-ui-protocol/ag-ui/pull/29)                     |
| [Golang]()                                                         | 🛠️ In Progress            | ➡️ [Issue](https://github.com/ag-ui-protocol/ag-ui/issues/156)               |
| [Rust]()                                                           | 🛠️ In Progress            | ➡️ [Issue](https://github.com/ag-ui-protocol/ag-ui/issues/239)               |
| [Java]()                                                           | 🛠️ In Progress            | ➡️ [GitHub Source](https://github.com/work-m8/ag-ui-4j)                      |


[View all supported frameworks →](https://ag-ui.com/frameworks)


## Examples
### Hello World App

Video:

https://github.com/user-attachments/assets/18c03330-1ebc-4863-b2b8-cc6c3a4c7bae

https://agui-demo.vercel.app/



## The AG-UI Dojo (Building-Blocks Viewer)
The AG-UI Dojo demonstrates AG-UI's core building blocks through simple, focused examples—each just 50-200 lines of code. 

View the source code for the Dojo and all framework integrations [here](https://github.com/ag-ui-protocol/ag-ui/tree/main/typescript-sdk/apps/dojo).

https://github.com/user-attachments/assets/c298eea8-3f39-4a94-b968-7712429b0c49



## 🙋🏽‍♂️ Contributing to AG-UI

Check out the [Contributing guide](https://github.com/ag-ui-protocol/ag-ui/blob/main/CONTRIBUTING.md)

- **[Bi-Weekely AG-UI Working Group](https://lu.ma/CopilotKit?k=c)**  
  📅 Follow the CopilotKit Luma Events Calendar

## Roadmap

Check out the [AG-UI Roadmap](https://github.com/orgs/ag-ui-protocol/projects/1) to see what's being built and where you can jump in.


## 📄 License

AG-UI is open source software [licensed as MIT](https://opensource.org/licenses/MIT).  



================================================
FILE: CLAUDE.md
================================================
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Common Development Commands

### TypeScript SDK (Main Development)
```bash
# Navigate to typescript-sdk directory for all TypeScript work
cd typescript-sdk

# Install dependencies (using pnpm)
pnpm install

# Build all packages
pnpm build

# Run development mode
pnpm dev

# Run linting
pnpm lint

# Run type checking
pnpm check-types

# Run tests
pnpm test

# Format code
pnpm format

# Clean build artifacts
pnpm clean

# Full clean build
pnpm build:clean
```

### Python SDK
```bash
# Navigate to python-sdk directory
cd python-sdk

# Install dependencies (using poetry)
poetry install

# Run tests
python -m unittest discover tests

# Build distribution
poetry build
```

### Running Specific Integration Tests
```bash
# For TypeScript packages/integrations
cd typescript-sdk/packages/<package-name>
pnpm test

# For running a single test file
cd typescript-sdk/packages/<package-name>
pnpm test -- path/to/test.spec.ts
```

## High-Level Architecture

AG-UI is an event-based protocol that standardizes agent-user interactions. The codebase is organized as a monorepo with the following structure:

### Core Protocol Architecture
- **Event-Driven Communication**: All agent-UI communication happens through typed events (BaseEvent and its subtypes)
- **Transport Agnostic**: Protocol supports SSE, WebSockets, HTTP binary, and custom transports
- **Observable Pattern**: Uses RxJS Observables for streaming agent responses

### Key Abstractions
1. **AbstractAgent**: Base class that all agents must implement with a `run(input: RunAgentInput) -> Observable<BaseEvent>` method
2. **HttpAgent**: Standard HTTP client supporting SSE and binary protocols for connecting to agent endpoints
3. **Event Types**: Lifecycle events (RUN_STARTED/FINISHED), message events (TEXT_MESSAGE_*), tool events (TOOL_CALL_*), and state management events (STATE_SNAPSHOT/DELTA)

### Repository Structure
- `/typescript-sdk/`: Main TypeScript implementation
  - `/packages/`: Core protocol packages (@ag-ui/core, @ag-ui/client, @ag-ui/encoder, @ag-ui/proto)
  - `/integrations/`: Framework integrations (langgraph, mastra, crewai, etc.)
  - `/apps/`: Example applications including the AG-UI Dojo demo viewer
- `/python-sdk/`: Python implementation of the protocol
- `/docs/`: Documentation site content

### Integration Pattern
Each framework integration follows a similar pattern:
1. Implements the AbstractAgent interface
2. Translates framework-specific events to AG-UI protocol events
3. Provides both TypeScript client and Python server implementations
4. Includes examples demonstrating key AG-UI features (agentic chat, generative UI, human-in-the-loop, etc.)

### State Management
- Uses STATE_SNAPSHOT for complete state representations
- Uses STATE_DELTA with JSON Patch (RFC 6902) for efficient incremental updates
- MESSAGES_SNAPSHOT provides conversation history

### Multiple Sequential Runs
- AG-UI supports multiple sequential runs in a single event stream
- Each run must complete (RUN_FINISHED) before a new run can start (RUN_STARTED)
- Messages accumulate across runs (e.g., messages from run1 + messages from run2)
- State continues to evolve across runs unless explicitly reset with STATE_SNAPSHOT
- Run-specific tracking (active messages, tool calls, steps) resets between runs

### Development Workflow
- Turbo is used for monorepo build orchestration
- Each package has independent versioning
- Integration tests demonstrate protocol compliance
- The AG-UI Dojo app showcases all protocol features with live examples


================================================
FILE: CONTRIBUTING.md
================================================
# 👋 Contributing to AG-UI

Thanks for checking out AG-UI! Whether you’re here to fix a bug, ship a feature, improve the docs, or just figure out how things work—we’re glad you’re here.

Here’s how to get involved:

---

## 🤔 Have a Question or Ran Into Something?

Pick the right spot so we can help you faster:

- **🐛 Bugs / Feature Ideas** → [GitHub Issues](https://github.com/ag-ui-protocol/ag-ui/issues)  
- **❓ "How do I...?" / General Questions** → [GitHub Discussions](https://github.com/ag-ui-protocol/ag-ui/discussions)  
- **💬 Quick chats / casual stuff** → [Discord](https://discord.gg/Jd3FzfdJa8) → `#-💎-contributing`

---

## 🧑‍💻 Want to Contribute Code?

1. **Find Something to Work On**  
   Browse open issues on [GitHub](https://github.com/ag-ui-protocol/ag-ui/issues).  
   Got your own idea? Open an issue first so we can start the discussion.

2. **Ask to Be Assigned**  
   Comment on the issue and tag a code owner:  
   → [Code Owners](https://github.com/ag-ui-protocol/ag-ui/blob/main/.github/CODEOWNERS)

3. **Get on the Roadmap**  
   Once approved, you'll be assigned the issue, and it'll get added to our [roadmap](https://github.com/orgs/ag-ui-protocol/projects/1).

4. **Coordinate With Others**  
   - If you're collaborating or need feedback, start a thread in `#-💎-contributing` on Discord  
   - Or just DM the assignee directly

5. **Open a Pull Request**  
   - When you’re ready, submit your PR  
   - In the description, include: `Fixes #<issue-number>`  
     (This links your PR to the issue and closes it automatically)

6. **Review & Merge**  
   - A maintainer will review your code and leave comments if needed  
   - Once it’s approved, we’ll merge it and move the issue to “done.”

**NOTE:** All community integrations (ie, .NET, Golang SDK, etc.) will need to be maintained by the community

---

## 📝 Want to Contribute to the Docs?

Docs are part of the codebase and super valuable—thanks for helping improve them!

Here’s how to contribute:

1. **Open an Issue First**  
   - Open a [GitHub issue](https://github.com/ag-ui-protocol/ag-ui/issues) describing what you’d like to update or add.  
   - Then comment and ask to be assigned.

2. **Submit a PR**  
   - Once assigned, make your edits and open a pull request.
   - In the description, include: `Fixes #<issue-number>`  
     (This links your PR to the issue and closes it automatically)

   - A maintainer will review it and merge if it looks good.

That’s it! Simple and appreciated.

---

## 🙌 That’s It!

AG-UI is community-built, and every contribution helps shape where we go next.  
Big thanks for being part of it!



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2025

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: docs/README.md
================================================
# Agent User Interaction Protocol Documentation

The official documentation for the [Agent User Interaction Protocol](https://ag-ui.com).

### Publishing Changes

Changes will be deployed to production automatically after pushing to the default branch.



================================================
FILE: docs/ag_ui.md
================================================
# AG‑UI: The Agent–User Interaction Protocol

*A horizontal standard to bring AI agents into user‑facing frontend applications.*

AG‑UI is the boundary layer where agents and users meet. It standardizes how agent state, UI intents, and user interactions flow between your model/agent runtime and your app’s frontend—so you can ship reliable, debuggable, user‑friendly agentic features fast.

---

## Built with the ecosystem

**First‑party partnerships & integrations**

> **Logo strip goes here** (e.g., LangGraph • CrewAI • Autogen 2 • LlamaIndex • Mastra • Pydantic AI • Vercel AI SDK • Next.js)

Short blurb: *AG‑UI works across leading agent frameworks and frontend stacks, with shared vocabulary and primitives that keep your UX consistent as your agents evolve.*

---

## Building blocks (today & upcoming)

- **Streaming chat** — Token‑level and tool‑event streaming for responsive UIs.
- **Static generative UI** — Render model output into stable, typed components.
- **Declarative generative UI** — Let agents propose UI trees; app decides what to mount.
- **Frontend tools** — Safe, typed tool calls that bridge agent logic to app actions.
- **Interrupts & human‑in‑the‑loop** — Pause, approve, edit, or steer mid‑flow.
- **In‑chat + in‑app interactions** — Chat commands alongside regular app controls.
- **Attachments & multimodality** — Files, images, audio, and structured payloads.
- **Thinking steps** — Expose summaries/redactions of chain‑of‑thought artifacts to users, safely.
- **Sub‑agent calls** — Orchestrate nested agents and delegate specialized tasks.
- **Agent steering** — Guardrails, policies, and UX affordances to keep agents on track.

> **CTA to deeper docs** → *See the full capability map in the docs.*

---

## Design patterns

Explore reusable interaction patterns for agentic UX:

- **Link‑out:** [AI‑UI Design Patterns →](/patterns) *(placeholder URL)*

---

## Why AG‑UI

**Agentic apps break the classic request/response contract.** Agents run for longer, stream work as they go, and make nondeterministic choices that can affect your UI and state. AG‑UI defines a clean, observable boundary so frontends remain predictable while agents stay flexible.

### What’s hard about user‑facing agents

- Agents are **long‑running** and **stream** intermediate work—often across multi‑turn sessions.
- Agents are **nondeterministic** and can **control UI** in ways that must be supervised.
- Apps must mix **structured + unstructured IO** (text, voice, tool calls, state updates).
- Agents need **composition**: agents **call sub‑agents**, often non-deterministically.

With AG‑UI, these become deliberate, well‑typed interactions rather than ad‑hoc wiring.

---

## Deeper proof (docs, demos, code)

| Framework / Platform    | What works today                       | Docs      | Demo      |
| ----------------------- | -------------------------------------- | --------- | --------- |
| LangGraph               | Streams, tools, interrupts, sub‑agents | [Docs](#) | [Demo](#) |
| CrewAI                  | Tools, action routing, steering        | [Docs](#) | [Demo](#) |
| Autogen 2               | Multi‑agent orchestration, messaging   | [Docs](#) | [Demo](#) |
| LlamaIndex              | Query/agent routing, UI intents        | [Docs](#) | [Demo](#) |
| OpenAI Realtime         | Live stream, events, attachments       | [Docs](#) | [Demo](#) |
| Vercel AI SDK / Next.js | Edge streaming, SSR hydration          | [Docs](#) | [Demo](#) |

> **Note:** Replace placeholders with actual URLs to docs and demos.

---

## Quick links

- **Get started** → */docs/getting-started* (placeholder)
- **Concepts** → */docs/concepts/agent-ui-boundary* (placeholder)
- **Reference** → */docs/reference* (placeholder)
- **Patterns** → */patterns* (placeholder)

---

## Optional section: How AG‑UI fits

- **Protocol**: Events, intents, and payload schemas shared by agents & apps.
- **Runtime adapters**: Bindings for popular agent frameworks.
- **Frontend kit**: Lightweight client + components to handle streaming & interrupts.
- **Observability hooks**: Surface interaction timelines for debugging & learning.

*(Include a simple diagram later: Agent(s) ⇄ AG‑UI Boundary ⇄ App UI/State)*




================================================
FILE: docs/docs.json
================================================
{
  "$schema": "https://mintlify.com/docs.json",
  "theme": "willow",
  "name": "Agent User Interaction Protocol",
  "colors": {
    "primary": "#09090b",
    "light": "#FAFAFA",
    "dark": "#09090b"
  },
  "favicon": "/favicon.svg",
  "navigation": {
    "tabs": [
      {
        "tab": "Documentation",
        "groups": [
          {
            "group": "Get Started",
            "pages": [
              "introduction",
              {
                "group": "Quickstart",
                "pages": [
                  "quickstart/applications",
                  {
                    "group": "Build integrations",
                    "pages": [
                      "quickstart/introduction",
                      "quickstart/server",
                      "quickstart/middleware"
                    ]
                  },
                  "quickstart/clients"
                ]
              }
            ]
          },
          {
            "group": "Concepts",
            "pages": [
              "concepts/architecture",
              "concepts/events",
              "concepts/agents",
              "concepts/messages",
              "concepts/state",
              "concepts/tools"
            ]
          },
          {
            "group": "Draft Proposals",
            "pages": [
              "drafts/overview",
              "drafts/activity-events",
              "drafts/reasoning",
              "drafts/serialization",
              "drafts/multimodal-messages",
              "drafts/interrupts",
              "drafts/generative-ui",
              "drafts/meta-events"
            ]
          },
          {
            "group": "Tutorials",
            "pages": ["tutorials/cursor", "tutorials/debugging"]
          },
          {
            "group": "Development",
            "pages": ["development/updates", "development/roadmap", "development/contributing"]
          }
        ]
      },
      {
        "tab": "SDKs",
        "icon": "book-open",
        "groups": [
          {
            "group": "TypeScript",
            "pages": [
              {
                "group": "@ag-ui/core",
                "pages": ["sdk/js/core/overview", "sdk/js/core/types", "sdk/js/core/events"]
              },
              {
                "group": "@ag-ui/client",
                "pages": [
                  "sdk/js/client/overview",
                  "sdk/js/client/abstract-agent",
                  "sdk/js/client/http-agent",
                  "sdk/js/client/subscriber"
                ]
              },
              "sdk/js/encoder",
              "sdk/js/proto"
            ]
          },
          {
            "group": "Python",
            "pages": [
              {
                "group": "ag_ui.core",
                "pages": [
                  "sdk/python/core/overview",
                  "sdk/python/core/types",
                  "sdk/python/core/events"
                ]
              },
              {
                "group": "ag_ui.encoder",
                "pages": ["sdk/python/encoder/overview"]
              }
            ]
          }
        ]
      }
    ],
    "global": {
      "anchors": [
        {
          "anchor": "TypeScript SDK",
          "href": "https://docs.ag-ui.com/sdk/js/core/overview",
          "icon": "square-js"
        },
        {
          "anchor": "Python SDK",
          "href": "https://docs.ag-ui.com/sdk/python/core/overview",
          "icon": "python"
        }
      ]
    }
  },
  "logo": {
    "light": "/logo/light.svg",
    "dark": "/logo/dark.svg"
  },
  "navbar": {
    "links": [
      {
        "label": "Discord",
        "href": "https://discord.gg/Jd3FzfdJa8",
        "icon": "server"
      }
    ],
    "primary": {
      "type": "github",
      "href": "https://github.com/ag-ui-protocol/ag-ui"
    }
  },
  "seo": {
    "metatags": {
      "og:image": "https://raw.githubusercontent.com/ag-ui-protocol/docs/logo/light.png"
    },
    "indexing": "navigable"
  },
  "integrations": {
    "posthog": {
      "apiKey": "phc_XZdymVYjrph9Mi0xZYGNyCKexxgblXRR1jMENCtdz5Q",
      "apiHost": "https://eu.posthog.com"
    }
  },
  "footer": {
    "socials": {
      "github": "https://github.com/ag-ui-protocol/ag-ui"
    }
  },
  "redirects": [
    {
      "source": "/quickstart",
      "destination": "/quickstart/build"
    },
    {
      "source": "/quickstart/connect",
      "destination": "/quickstart/middleware"
    },
    {
      "source": "/quickstart/build",
      "destination": "/quickstart/server"
    }
  ]
}



================================================
FILE: docs/integrations.mdx
================================================
---
title: Integrations
description: "A list of AG-UI integrations"
---

This page showcases various Agent User Interaction Protocol (AG-UI) integrations
that demonstrate the protocol's capabilities and versatility.

## Frontend Integrations

- **[CopilotKit](https://copilotkit.ai)** - AI Copilots for your product.

## Agent Frameworks

- **[Mastra](https://mastra.ai)** - The TypeScript Agent Framework
- **[LangGraph](https://www.langchain.com/langgraph)** - Balance agent control
  with agency
- **[CrewAI](https://crewai.com)** - Streamline workflows across industries with
  powerful AI agents.
- **[AG2](https://ag2.ai)** - The Open-Source AgentOS
- **[Agno](https://agno.com)** - A full-stack framework for building Multi-Agent Systems

Visit our
[GitHub Discussions](https://github.com/orgs/ag-ui-protocol/discussions) to
engage with the AG-UI community.



================================================
FILE: docs/introduction.mdx
================================================
---
title: AG-UI Overview
description: 
---

# The Agent–User Interaction (AG-UI) Protocol


AG-UI is an <u><strong>open</strong></u>, <u><strong>lightweight</strong></u>, <u><strong>event-based</strong></u> protocol that standardizes how AI agents connect to user-facing applications.


Built for simplicity and flexibility, it standardizes how agent state, UI intents, and user interactions flow between your model/agent runtime and user-facing frontend applications—to allow application developers to ship reliable, debuggable, user‑friendly agentic features fast while focusing on application needs and avoding complex ad-hoc wiring.



<div style={{textAlign: 'center', margin: '2rem 0'}}>
  <img src="/images/ag-ui-overview-with-partners.png" alt="AG-UI Overview" style={{maxWidth: '100%', height: 'auto', borderRadius: '8px'}} />
</div>

---

## Building blocks (today & upcoming)

<div style={{display: 'grid', gridTemplateColumns: 'repeat(2, 1fr)', gap: '1rem', margin: '1.5rem 0'}}>
  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Streaming chat
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Live token and event streaming for responsive multi turn sessions, with cancel and resume.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Multimodality
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Typed attachments and real time media (files, images, audio, transcripts); supports voice, previews, annotations, provenance.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Generative UI, static
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Render model output as stable, typed components under app control.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Generative UI, declarative
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Small declarative language for constrained yet open-ended agent UIs; agents propose trees and constraints, the app validates and mounts.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Shared state
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        (Read-only & read-write). Typed store shared between agent and app, with streamed event-sourced diffs and conflict resolution for snappy collaboration.
      </div>
    </div>
  </div>

    <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Thinking steps
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Visualize intermediate reasoning from traces and tool events; no raw chain of thought.
      </div>
    </div>
  </div>


  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Frontend tool calls
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Typed handoffs from agent to frontend-executed actions, and back.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Backend tool rendering & side effects
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Visualize backend tool outputs in app and chat, emit side effects as first-class events.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Interrupts (human in the loop)
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Pause, approve, edit, retry, or escalate mid flow without losing state.
      </div>
    </div>
  </div>


  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Sub-agents and composition
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Nested delegation with scoped state, tracing, and cancellation.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Agent steering
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Dynamically redirect agent execution with real-time user input to guide behavior and outcomes.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Tool output streaming
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Stream tool results and logs so UIs can render long-running effects in real time.
      </div>
    </div>
  </div>

  <div style={{border: '1px solid #e5e7eb', borderRadius: '8px', overflow: 'hidden', transition: 'all 0.3s ease', cursor: 'pointer'}} onMouseEnter={(e) => { e.currentTarget.style.borderColor = '#3b82f6'; e.currentTarget.style.boxShadow = '0 4px 12px rgba(59, 130, 246, 0.15)'; e.currentTarget.querySelector('.content').style.maxHeight = '200px'; e.currentTarget.querySelector('.content').style.opacity = '1'; }} onMouseLeave={(e) => { e.currentTarget.style.borderColor = '#e5e7eb'; e.currentTarget.style.boxShadow = 'none'; e.currentTarget.querySelector('.content').style.maxHeight = '0px'; e.currentTarget.querySelector('.content').style.opacity = '0'; }}>
    <div style={{padding: '1rem 1.5rem', backgroundColor: '#f9fafb', fontWeight: '600', color: '#374151'}}>
      Custom events
    </div>
    <div className="content" style={{maxHeight: '0px', opacity: '0', overflow: 'hidden', transition: 'all 0.3s ease', padding: '0 1.5rem', backgroundColor: '#ffffff'}}>
      <div style={{padding: '1rem 0', color: '#6b7280', lineHeight: '1.6'}}>
        Open-ended data exchange for needs not covered by the protocol.
      </div>
    </div>
  </div>
</div>



---

## Why Agentic Apps need AG-UI

Agentic applications break the simple request/response model that dominated frontend-backend development in the pre-agentic era: a client makes a request, the server returns data, the client renders it, and the interaction ends.

#### The requirements of user‑facing agents

While agents are just software, they exhibit characteristics that make them challenging to serve behind traditional REST/GraphQL APIs:

- Agents are **long‑running** and **stream** intermediate work—often across multi‑turn sessions.
- Agents are **nondeterministic** and can **control application UI nondeterministically**.
- Agents simultanously mix **structured + unstructured IO** (e.g. text & voice, alongside tool calls and state updates).
- Agents need user-interactive **composition**: e.g. they may call sub‑agents, often recursively.
- And more...

AG-UI is an event-based protocol that enables dynamic communication between agentic frontends and backends. It builds on top of the foundational protocols of the web (HTTP, WebSockets) as an abstraction layer designed for the agentic age—bridging the gap between traditional client-server architectures and the dynamic, stateful nature of AI agents.

## The AI protocol landscape

AG-UI has emerged as the 3rd leg of the AI protocol landscape:
<div style={{textAlign: 'center', margin: '2rem 0'}}>
  <img src="/images/ai-protocol-stack.png" alt="AI Protocol Stack" style={{maxWidth: '40%', height: 'auto', borderRadius: '8px'}} />
</div>

- MCP: Connects agents to tool and to context.
- A2A: Connects agents to other agents.
- **AG-UI:** Connects agents to users (through user-facing applications)


These protocols are complimentary and have distinct technical goals; a single agent can and often does use all 3 simultanously.
Where these protocols intersect, there are opportunities for seamless handshakes facilitating interoperability—work on these integration points is actively ongoing.
AG-UI's mandate is to support the full set of building blocks required by modern agentic applications.




---

## AG-UI in action

<div style={{textAlign: 'center', margin: '3rem 0 1rem 0'}}>
  <video 
    width="100%" 
    height="auto" 
    autoPlay 
    muted 
    loop 
    controls 
    style={{maxWidth: '800px', borderRadius: '12px', boxShadow: '0 8px 32px rgba(0, 0, 0, 0.12)'}}
  >
    <source src="/videos/Dojo-overview.mp4" type="video/mp4" />
    Your browser does not support the video tag.
  </video>
</div>

<Callout type="info" icon="lightbulb">
You can see demo apps of the AG-UI features with the framework of your choice, with preview, code and walkthrough docs in the [AG-UI Dojo](dojo.ag-ui.com)
</Callout>

---

## Supported Frameworks

AG-UI was born from an initial partnership between CopilotKit, LangGraph and CrewAI - and is steadily gaining integrations across the wider AI developer ecosystem.

| Framework | Docs | Demos |
| :----------------------- | :--- | :---- |
| [LangGraph](https://www.langchain.com/langgraph) | [Documentation](https://docs.copilotkit.ai/langgraph/) | [Live Demo](https://dojo.ag-ui.com/langgraph-fastapi/feature/shared_state) |
| [CrewAI](https://crewai.com/) | [Documentation](https://docs.copilotkit.ai/crewai-flows) | [Live Demo](https://dojo.ag-ui.com/crewai/feature/shared_state) |
| [Mastra](https://mastra.ai/) | [Documentation](https://docs.copilotkit.ai/mastra/) | [Live Demo](https://dojo.ag-ui.com/mastra) |
| [AG2](https://ag2.ai/) | [Documentation](https://docs.copilotkit.ai/ag2/) | Coming Soon |
| [Agno](https://github.com/agno-agi/agno) | [Documentation](https://docs.copilotkit.ai/agno/) | [Live Demo](https://dojo.ag-ui.com/agno) |
| [LlamaIndex](https://github.com/run-llama/llama_index) | [Documentation](https://docs.copilotkit.ai/llamaindex/) | [Live Demo](https://dojo.ag-ui.com/llamaindex/feature/shared_state) |
| [Pydantic AI](https://github.com/pydantic/pydantic-ai) | [Documentation](https://docs.copilotkit.ai/pydantic-ai/) | [Live Demo](https://dojo.ag-ui.com/pydantic-ai/feature/shared_state) |
| [Google ADK](https://google.github.io/adk-docs/get-started/) | [Documentation](https://docs.copilotkit.ai/adk) | [Live Demo](https://dojo.ag-ui.com/adk-middleware) |
| [AWS Bedrock Agents](https://aws.amazon.com/bedrock/agents/) | In Progress | Coming Soon |
| [AWS Strands Agents](https://github.com/strands-agents/sdk-python) | In Progress | Coming Soon |
| [Vercel AI SDK](https://github.com/vercel/ai) | In Progress | Coming Soon |
| [OpenAI Agent SDK](https://openai.github.io/openai-agents-python/) | In Progress | Coming Soon |
| [Cloudflare Agents](https://developers.cloudflare.com/agents/) | Open to Contributions | Coming Soon |

---

## Quick Start

Choose the path that fits your needs:

<CardGroup cols={3}>
  <Card
    title="Build agentic applications"
    icon="rocket"
    href="/quickstart/applications"
    color="#3B82F6"
    iconType="solid"
  >
    Build agentic applications powered by AG-UI compatible agents.
  </Card>

  <Card
    title="Build new AG-UI integrations"
    icon="plug"
    href="/quickstart/introduction"
    color="#3B82F6"
    iconType="solid"
  >
    Build integrations for new agent frameworks, custom in-house solutions, or use AG-UI without any agent framework.
  </Card>

  <Card
    title="Build AG-UI compatible clients"
    icon="desktop"
    href="/quickstart/clients"
    color="#3B82F6"
    iconType="solid"
  >
    Build new clients for AG-UI-compatible agents (web, mobile, slack, messaging, etc.)
  </Card>

</CardGroup>

## Explore AG-UI

Dive deeper into AG-UI's core concepts and capabilities:

<CardGroup cols={2}>
  <Card
    title="Core architecture"
    icon="sitemap"
    iconType="light"
    color="#3B82F6"
    href="/concepts/architecture"
  >
    Understand how AG-UI connects agents, protocols, and front-ends
  </Card>

  <Card
    title="Events"
    icon="bolt"
    iconType="light"
    color="#3B82F6"
    href="/concepts/events"
  >
    Learn about AG-UI's event-driven protocol
  </Card>
</CardGroup>

## Resources

Explore guides, tools, and integrations to help you build, optimize, and extend
your AG-UI implementation. These resources cover everything from practical
development workflows to debugging techniques.

<CardGroup cols={2}>
  <Card
    title="Developing with Cursor"
    icon="rocket"
    iconType="light"
    color="#3B82F6"
    href="/tutorials/cursor"
  >
    Use Cursor to build AG-UI implementations faster
  </Card>
  <Card
    title="Troubleshooting AG-UI"
    icon="bug"
    iconType="light"
    color="#3B82F6"
    href="/tutorials/debugging"
  >
    Fix common issues when working with AG-UI servers and clients
  </Card>
</CardGroup>


## Contributing

Want to contribute? Check out our
[Contributing Guide](/development/contributing) to learn how you can help
improve AG-UI.

## Support and Feedback

Here's how to get help or provide feedback:

- For bug reports and feature requests related to the AG-UI specification, SDKs,
  or documentation (open source), please
  [create a GitHub issue](https://github.com/ag-ui-protocol)
- For discussions or Q&A about the AG-UI specification, use the
  [specification discussions](https://github.com/ag-ui-protocol/specification/discussions)
- For discussions or Q&A about other AG-UI open source components, use the
  [organization discussions](https://github.com/orgs/ag-ui-protocol/discussions)



================================================
FILE: docs/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: docs/package.json
================================================
{
  "name": "docs",
  "scripts": {
    "dev": "mintlify dev --port=4000",
    "build": "mintlify build"
  },
  "dependencies": {
    "mintlify": "^4.0.459",
    "react-icons": "^5.3.0",
    "@icons-pack/react-simple-icons": "^11.2.0", 
    "lucide-react": "^0.446.0"
  }
}



================================================
FILE: docs/.prettierignore
================================================




================================================
FILE: docs/.prettierrc
================================================
{
  "printWidth": 100,
  "singleQuote": false,
  "semi": true,
  "tabWidth": 2,
  "overrides": [
    {
      "files": "*.mdx",
      "options": {
        "printWidth": 80,
        "proseWrap": "always",
        "semi": false,
        "singleQuote": false
      }
    }
  ]
}



================================================
FILE: docs/concepts/agents.mdx
================================================
---
title: "Agents"
description: "Learn about agents in the Agent User Interaction Protocol"
---

# Agents

Agents are the core components in the AG-UI protocol that process requests and
generate responses. They establish a standardized way for front-end applications
to communicate with AI services through a consistent interface, regardless of
the underlying implementation.

## What is an Agent?

In AG-UI, an agent is a class that:

1. Manages conversation state and message history
2. Processes incoming messages and context
3. Generates responses through an event-driven streaming interface
4. Follows a standardized protocol for communication

Agents can be implemented to connect with any AI service, including:

- Large language models (LLMs) like GPT-4 or Claude
- Custom AI systems
- Retrieval augmented generation (RAG) systems
- Multi-agent systems

## Agent Architecture

All agents in AG-UI extend the `AbstractAgent` class, which provides the
foundation for:

- State management
- Message history tracking
- Event stream processing
- Tool usage

```typescript
import { AbstractAgent } from "@ag-ui/client"

class MyAgent extends AbstractAgent {
  protected run(input: RunAgentInput): RunAgent {
    // Implementation details
  }
}
```

### Core Components

AG-UI agents have several key components:

1. **Configuration**: Agent ID, thread ID, and initial state
2. **Messages**: Conversation history with user and assistant messages
3. **State**: Structured data that persists across interactions
4. **Events**: Standardized messages for communication with clients
5. **Tools**: Functions that agents can use to interact with external systems

## Agent Types

AG-UI provides different agent implementations to suit various needs:

### AbstractAgent

The base class that all agents extend. It handles core event processing, state
management, and message history.

### HttpAgent

A concrete implementation that connects to remote AI services via HTTP:

```typescript
import { HttpAgent } from "@ag-ui/client"

const agent = new HttpAgent({
  url: "https://your-agent-endpoint.com/agent",
  headers: {
    Authorization: "Bearer your-api-key",
  },
})
```

### Custom Agents

You can create custom agents to integrate with any AI service by extending
`AbstractAgent`:

```typescript
class CustomAgent extends AbstractAgent {
  // Custom properties and methods

  protected run(input: RunAgentInput): RunAgent {
    // Implement the agent's logic
  }
}
```

## Implementing Agents

### Basic Implementation

To create a custom agent, extend the `AbstractAgent` class and implement the
required `run` method:

```typescript
import {
  AbstractAgent,
  RunAgent,
  RunAgentInput,
  EventType,
  BaseEvent,
} from "@ag-ui/client"
import { Observable } from "rxjs"

class SimpleAgent extends AbstractAgent {
  protected run(input: RunAgentInput): RunAgent {
    const { threadId, runId } = input

    return () =>
      new Observable<BaseEvent>((observer) => {
        // Emit RUN_STARTED event
        observer.next({
          type: EventType.RUN_STARTED,
          threadId,
          runId,
        })

        // Send a message
        const messageId = Date.now().toString()

        // Message start
        observer.next({
          type: EventType.TEXT_MESSAGE_START,
          messageId,
          role: "assistant",
        })

        // Message content
        observer.next({
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId,
          delta: "Hello, world!",
        })

        // Message end
        observer.next({
          type: EventType.TEXT_MESSAGE_END,
          messageId,
        })

        // Emit RUN_FINISHED event
        observer.next({
          type: EventType.RUN_FINISHED,
          threadId,
          runId,
        })

        // Complete the observable
        observer.complete()
      })
  }
}
```

## Agent Capabilities

Agents in the AG-UI protocol provide a rich set of capabilities that enable
sophisticated AI interactions:

### Interactive Communication

Agents establish bi-directional communication channels with front-end
applications through event streams. This enables:

- Real-time streaming responses character-by-character
- Immediate feedback loops between user and AI
- Progress indicators for long-running operations
- Structured data exchange in both directions

### Tool Usage

Agents can use tools to perform actions and access external resources.
Importantly, tools are defined and passed in from the front-end application to
the agent, allowing for a flexible and extensible system:

```typescript
// Tool definition
const confirmAction = {
  name: "confirmAction",
  description: "Ask the user to confirm a specific action before proceeding",
  parameters: {
    type: "object",
    properties: {
      action: {
        type: "string",
        description: "The action that needs user confirmation",
      },
      importance: {
        type: "string",
        enum: ["low", "medium", "high", "critical"],
        description: "The importance level of the action",
      },
      details: {
        type: "string",
        description: "Additional details about the action",
      },
    },
    required: ["action"],
  },
}

// Running an agent with tools from the frontend
agent.runAgent({
  tools: [confirmAction], // Frontend-defined tools passed to the agent
  // other parameters
})
```

Tools are invoked through a sequence of events:

1. `TOOL_CALL_START`: Indicates the beginning of a tool call
2. `TOOL_CALL_ARGS`: Streams the arguments for the tool call
3. `TOOL_CALL_END`: Marks the completion of the tool call

Front-end applications can then execute the tool and provide results back to the
agent. This bidirectional flow enables sophisticated human-in-the-loop workflows
where:

- The agent can request specific actions be performed
- Humans can execute those actions with appropriate judgment
- Results are fed back to the agent for continued reasoning
- The agent maintains awareness of all decisions made in the process

This mechanism is particularly powerful for implementing interfaces where AI and
humans collaborate. For example, [CopilotKit](https://docs.copilotkit.ai/)
leverages this exact pattern with their
[`useCopilotAction`](https://docs.copilotkit.ai/guides/frontend-actions) hook,
which provides a simplified way to define and handle tools in React
applications.

By keeping the AI informed about human decisions through the tool mechanism,
applications can maintain context and create more natural collaborative
experiences between users and AI assistants.

### State Management

Agents maintain a structured state that persists across interactions. This state
can be:

- Updated incrementally through `STATE_DELTA` events
- Completely refreshed with `STATE_SNAPSHOT` events
- Accessed by both the agent and front-end
- Used to store user preferences, conversation context, or application state

```typescript
// Accessing agent state
console.log(agent.state.preferences)

// State is automatically updated during agent runs
agent.runAgent().subscribe((event) => {
  if (event.type === EventType.STATE_DELTA) {
    // State has been updated
    console.log("New state:", agent.state)
  }
})
```

### Multi-Agent Collaboration

AG-UI supports agent-to-agent handoff and collaboration:

- Agents can delegate tasks to other specialized agents
- Multiple agents can work together in a coordinated workflow
- State and context can be transferred between agents
- The front-end maintains a consistent experience across agent transitions

For example, a general assistant agent might hand off to a specialized coding
agent when programming help is needed, passing along the conversation context
and specific requirements.

### Human-in-the-Loop Workflows

Agents support human intervention and assistance:

- Agents can request human input on specific decisions
- Front-ends can pause agent execution and resume it after human feedback
- Human experts can review and modify agent outputs before they're finalized
- Hybrid workflows combine AI efficiency with human judgment

This enables applications where the agent acts as a collaborative partner rather
than an autonomous system.

### Conversational Memory

Agents maintain a complete history of conversation messages:

- Past interactions inform future responses
- Message history is synchronized between client and server
- Messages can include rich content (text, structured data, references)
- The context window can be managed to focus on relevant information

```typescript
// Accessing message history
console.log(agent.messages)

// Adding a new user message
agent.messages.push({
  id: "msg_123",
  role: "user",
  content: "Can you explain that in more detail?",
})
```

### Metadata and Instrumentation

Agents can emit metadata about their internal processes:

- Reasoning steps through custom events
- Performance metrics and timing information
- Source citations and reference tracking
- Confidence scores for different response options

This allows front-ends to provide transparency into the agent's decision-making
process and help users understand how conclusions were reached.

## Using Agents

Once you've implemented or instantiated an agent, you can use it like this:

```typescript
// Create an agent instance
const agent = new HttpAgent({
  url: "https://your-agent-endpoint.com/agent",
})

// Add initial messages if needed
agent.messages = [
  {
    id: "1",
    role: "user",
    content: "Hello, how can you help me today?",
  },
]

// Run the agent
agent
  .runAgent({
    runId: "run_123",
    tools: [], // Optional tools
    context: [], // Optional context
  })
  .subscribe({
    next: (event) => {
      // Handle different event types
      switch (event.type) {
        case EventType.TEXT_MESSAGE_CONTENT:
          console.log("Content:", event.delta)
          break
        // Handle other events
      }
    },
    error: (error) => console.error("Error:", error),
    complete: () => console.log("Run complete"),
  })
```

## Agent Configuration

Agents accept configuration through the constructor:

```typescript
interface AgentConfig {
  agentId?: string // Unique identifier for the agent
  description?: string // Human-readable description
  threadId?: string // Conversation thread identifier
  initialMessages?: Message[] // Initial messages
  initialState?: State // Initial state object
}

// Using the configuration
const agent = new HttpAgent({
  agentId: "my-agent-123",
  description: "A helpful assistant",
  threadId: "thread-456",
  initialMessages: [
    { id: "1", role: "system", content: "You are a helpful assistant." },
  ],
  initialState: { preferredLanguage: "English" },
})
```

## Agent State Management

AG-UI agents maintain state across interactions:

```typescript
// Access current state
console.log(agent.state)

// Access messages
console.log(agent.messages)

// Clone an agent with its state
const clonedAgent = agent.clone()
```

## Conclusion

Agents are the foundation of the AG-UI protocol, providing a standardized way to
connect front-end applications with AI services. By implementing the
`AbstractAgent` class, you can create custom integrations with any AI service
while maintaining a consistent interface for your applications.

The event-driven architecture enables real-time, streaming interactions that are
essential for modern AI applications, and the standardized protocol ensures
compatibility across different implementations.



================================================
FILE: docs/concepts/architecture.mdx
================================================
---
title: "Core architecture"
description: "Understand how AG-UI connects front-end applications to AI agents"
---

Agent User Interaction Protocol (AG-UI) is built on a flexible, event-driven
architecture that enables seamless, efficient communication between front-end
applications and AI agents. This document covers the core architectural
components and concepts.

## Design Principles

AG-UI is designed to be lightweight and minimally opinionated, making it easy to
integrate with a wide range of agent implementations. The protocol's flexibility
comes from its simple requirements:

1. **Event-Driven Communication**: Agents need to emit any of the 16
   standardized event types during execution, creating a stream of updates that
   clients can process.

2. **Bidirectional Interaction**: Agents accept input from users, enabling
   collaborative workflows where humans and AI work together seamlessly.

The protocol includes a built-in middleware layer that maximizes compatibility
in two key ways:

- **Flexible Event Structure**: Events don't need to match AG-UI's format
  exactly—they just need to be AG-UI-compatible. This allows existing agent
  frameworks to adapt their native event formats with minimal effort.

- **Transport Agnostic**: AG-UI doesn't mandate how events are delivered,
  supporting various transport mechanisms including Server-Sent Events (SSE),
  webhooks, WebSockets, and more. This flexibility lets developers choose the
  transport that best fits their architecture.

This pragmatic approach makes AG-UI easy to adopt without requiring major
changes to existing agent implementations or frontend applications.

## Architectural Overview

AG-UI follows a client-server architecture that standardizes communication
between agents and applications:

```mermaid
flowchart LR
    subgraph "Frontend"
        App["Application"]
        Client["AG-UI Client"]
    end

    subgraph "Backend"
        A1["AI Agent A"]
        P["Secure Proxy"]
        A2["AI Agent B"]
        A3["AI Agent C"]
    end

    App <--> Client
    Client <-->|"AG-UI Protocol"| A1
    Client <-->|"AG-UI Protocol"| P
    P <-->|"AG-UI Protocol"| A2
    P <-->|"AG-UI Protocol"| A3

    class P mintStyle;
    classDef mintStyle fill:#E0F7E9,stroke:#66BB6A,stroke-width:2px,color:#000000;

    style App rx:5, ry:5;
    style Client rx:5, ry:5;
    style A1 rx:5, ry:5;
    style P rx:5, ry:5;
    style A2 rx:5, ry:5;
    style A3 rx:5, ry:5;
```

- **Application**: User-facing apps (i.e. chat or any AI-enabled application).
- **AG-UI Client**: Generic communication clients like `HttpAgent` or
  specialized clients for connecting to existing protocols.
- **Agents**: Backend AI agents that process requests and generate streaming
  responses.
- **Secure Proxy**: Backend services that provide additional capabilities and
  act as a secure proxy.

## Core components

### Protocol layer

AG-UI's protocol layer provides a flexible foundation for agent communication.

- **Universal compatibility**: Connect to any protocol by implementing
  `run(input: RunAgentInput) -> Observable<BaseEvent>`

The protocol's primary abstraction enables applications to run agents and
receive a stream of events:

{/* prettier-ignore */}
```typescript
// Core agent execution interface
type RunAgent = () => Observable<BaseEvent>

class MyAgent extends AbstractAgent {
  run(input: RunAgentInput): RunAgent {
    const { threadId, runId } = input
    return () =>
      from([
        { type: EventType.RUN_STARTED, threadId, runId },
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: [
            { id: "msg_1", role: "assistant", content: "Hello, world!" }
          ],
        },
        { type: EventType.RUN_FINISHED, threadId, runId },
      ])
  }
}
```

### Standard HTTP client

AG-UI offers a standard HTTP client `HttpAgent` that can be used to connect to
any endpoint that accepts POST requests with a body of type `RunAgentInput` and
sends a stream of `BaseEvent` objects.

`HttpAgent` supports the following transports:

- **HTTP SSE (Server-Sent Events)**

  - Text-based streaming for wide compatibility
  - Easy to read and debug

- **HTTP binary protocol**
  - Highly performant and space-efficient custom transport
  - Robust binary serialization for production environments

### Message types

AG-UI defines several event categories for different aspects of agent
communication:

- **Lifecycle events**

  - `RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`
  - `STEP_STARTED`, `STEP_FINISHED`

- **Text message events**

  - `TEXT_MESSAGE_START`, `TEXT_MESSAGE_CONTENT`, `TEXT_MESSAGE_END`

- **Tool call events**

  - `TOOL_CALL_START`, `TOOL_CALL_ARGS`, `TOOL_CALL_END`

- **State management events**

  - `STATE_SNAPSHOT`, `STATE_DELTA`, `MESSAGES_SNAPSHOT`

- **Special events**
  - `RAW`, `CUSTOM`

## Running Agents

To run an agent, you create a client instance and execute it:

```typescript
// Create an HTTP agent client
const agent = new HttpAgent({
  url: "https://your-agent-endpoint.com/agent",
  agentId: "unique-agent-id",
  threadId: "conversation-thread"
});

// Start the agent and handle events
agent.runAgent({
  tools: [...],
  context: [...]
}).subscribe({
  next: (event) => {
    // Handle different event types
    switch(event.type) {
      case EventType.TEXT_MESSAGE_CONTENT:
        // Update UI with new content
        break;
      // Handle other event types
    }
  },
  error: (error) => console.error("Agent error:", error),
  complete: () => console.log("Agent run complete")
});
```

## State Management

AG-UI provides efficient state management through specialized events:

- `STATE_SNAPSHOT`: Complete state representation at a point in time
- `STATE_DELTA`: Incremental state changes using JSON Patch format (RFC 6902)
- `MESSAGES_SNAPSHOT`: Complete conversation history

These events enable efficient client-side state management with minimal data
transfer.

## Tools and Handoff

AG-UI supports agent-to-agent handoff and tool usage through standardized
events:

- Tool definitions are passed in the `runAgent` parameters
- Tool calls are streamed as sequences of `TOOL_CALL_START` → `TOOL_CALL_ARGS` →
  `TOOL_CALL_END` events
- Agents can hand off to other agents, maintaining context continuity

## Events

All communication in AG-UI is based on typed events. Every event inherits from
`BaseEvent`:

```typescript
interface BaseEvent {
  type: EventType
  timestamp?: number
  rawEvent?: any
}
```

Events are strictly typed and validated, ensuring reliable communication between
components.



================================================
FILE: docs/concepts/events.mdx
================================================
---
title: "Events"
description: "Understanding events in the Agent User Interaction Protocol"
---

# Events

The Agent User Interaction Protocol uses a streaming event-based architecture.
Events are the fundamental units of communication between agents and frontends,
enabling real-time, structured interaction.

## Event Types Overview

Events in the protocol are categorized by their purpose:

| Category                | Description                             |
| ----------------------- | --------------------------------------- |
| Lifecycle Events        | Monitor the progression of agent runs   |
| Text Message Events     | Handle streaming textual content        |
| Tool Call Events        | Manage tool executions by agents        |
| State Management Events | Synchronize state between agents and UI |
| Special Events          | Support custom functionality            |
| Draft Events            | Proposed events under development       |

## Base Event Properties

All events share a common set of base properties:

| Property    | Description                                                      |
| ----------- | ---------------------------------------------------------------- |
| `type`      | The specific event type identifier                               |
| `timestamp` | Optional timestamp indicating when the event was created         |
| `rawEvent`  | Optional field containing the original event data if transformed |

## Lifecycle Events

These events represent the lifecycle of an agent run. A typical agent run
follows a predictable pattern: it begins with a `RunStarted` event, may contain
multiple optional `StepStarted`/`StepFinished` pairs, and concludes with either
a `RunFinished` event (success) or a `RunError` event (failure).

Lifecycle events provide crucial structure to agent runs, enabling frontends to
track progress, manage UI states appropriately, and handle errors gracefully.
They create a consistent framework for understanding when operations begin and
end, making it possible to implement features like loading indicators, progress
tracking, and error recovery mechanisms.

```mermaid
sequenceDiagram
    participant Agent
    participant Client

    Note over Agent,Client: Run begins
    Agent->>Client: RunStarted

    opt Sending steps is optional
        Note over Agent,Client: Step execution
        Agent->>Client: StepStarted
        Agent->>Client: StepFinished
    end

    Note over Agent,Client: Run completes
    alt
        Agent->>Client: RunFinished
    else
        Agent->>Client: RunError
    end
```

The `RunStarted` and either `RunFinished` or `RunError` events are mandatory,
forming the boundaries of an agent run. Step events are optional and may occur
multiple times within a run, allowing for structured, observable progress
tracking.

### RunStarted

Signals the start of an agent run.

The `RunStarted` event is the first event emitted when an agent begins
processing a request. It establishes a new execution context identified by a
unique `runId`. This event serves as a marker for frontends to initialize UI
elements such as progress indicators or loading states. It also provides crucial
identifiers that can be used to associate subsequent events with this specific
run.

| Property   | Description                   |
| ---------- | ----------------------------- |
| `threadId` | ID of the conversation thread |
| `runId`    | ID of the agent run           |

### RunFinished

Signals the successful completion of an agent run.

The `RunFinished` event indicates that an agent has successfully completed all
its work for the current run. Upon receiving this event, frontends should
finalize any UI states that were waiting on the agent's completion. This event
marks a clean termination point and indicates that no further processing will
occur in this run unless explicitly requested. The optional `result` field can
contain any output data produced by the agent run.

| Property   | Description                   |
| ---------- | ----------------------------- |
| `threadId` | ID of the conversation thread |
| `runId`    | ID of the agent run           |
| `result`   | Optional result data from run |

### RunError

Signals an error during an agent run.

The `RunError` event indicates that the agent encountered an error it could not
recover from, causing the run to terminate prematurely. This event provides
information about what went wrong, allowing frontends to display appropriate
error messages and potentially offer recovery options. After a `RunError` event,
no further processing will occur in this run.

| Property  | Description         |
| --------- | ------------------- |
| `message` | Error message       |
| `code`    | Optional error code |

### StepStarted

Signals the start of a step within an agent run.

The `StepStarted` event indicates that the agent is beginning a specific subtask
or phase of its processing. Steps provide granular visibility into the agent's
progress, enabling more precise tracking and feedback in the UI. Steps are
optional but highly recommended for complex operations that benefit from being
broken down into observable stages. The `stepName` could be the name of a node
or function that is currently executing.

| Property   | Description      |
| ---------- | ---------------- |
| `stepName` | Name of the step |

### StepFinished

Signals the completion of a step within an agent run.

The `StepFinished` event indicates that the agent has completed a specific
subtask or phase. When paired with a corresponding `StepStarted` event, it
creates a bounded context for a discrete unit of work. Frontends can use these
events to update progress indicators, show completion animations, or reveal
results specific to that step. The `stepName` must match the corresponding
`StepStarted` event to properly pair the beginning and end of the step.

| Property   | Description      |
| ---------- | ---------------- |
| `stepName` | Name of the step |

## Text Message Events

These events represent the lifecycle of text messages in a conversation. Text
message events follow a streaming pattern, where content is delivered
incrementally. A message begins with a `TextMessageStart` event, followed by one
or more `TextMessageContent` events that deliver chunks of text as they become
available, and concludes with a `TextMessageEnd` event.

This streaming approach enables real-time display of message content as it's
generated, creating a more responsive user experience compared to waiting for
the entire message to be complete before showing anything.

```mermaid
sequenceDiagram
    participant Agent
    participant Client

    Note over Agent,Client: Message begins
    Agent->>Client: TextMessageStart

    loop Content streaming
        Agent->>Client: TextMessageContent
    end

    Note over Agent,Client: Message completes
    Agent->>Client: TextMessageEnd
```

The `TextMessageContent` events each contain a `delta` field with a chunk of
text. Frontends should concatenate these deltas in the order received to
construct the complete message. The `messageId` property links all related
events, allowing the frontend to associate content chunks with the correct
message.

### TextMessageStart

Signals the start of a text message.

The `TextMessageStart` event initializes a new text message in the conversation.
It establishes a unique `messageId` that will be referenced by subsequent
content chunks and the end event. This event allows frontends to prepare the UI
for an incoming message, such as creating a new message bubble with a loading
indicator. The `role` property identifies whether the message is coming from the
assistant or potentially another participant in the conversation.

| Property    | Description                                                                       |
| ----------- | --------------------------------------------------------------------------------- |
| `messageId` | Unique identifier for the message                                                 |
| `role`      | Role of the message sender ("developer", "system", "assistant", "user", "tool") |

### TextMessageContent

Represents a chunk of content in a streaming text message.

The `TextMessageContent` event delivers incremental parts of the message text as
they become available. Each event contains a small chunk of text in the `delta`
property that should be appended to previously received chunks. The streaming
nature of these events enables real-time display of content, creating a more
responsive and engaging user experience. Implementations should handle these
events efficiently to ensure smooth text rendering without visible delays or
flickering.

| Property    | Description                            |
| ----------- | -------------------------------------- |
| `messageId` | Matches the ID from `TextMessageStart` |
| `delta`     | Text content chunk (non-empty)         |

### TextMessageEnd

Signals the end of a text message.

The `TextMessageEnd` event marks the completion of a streaming text message.
After receiving this event, the frontend knows that the message is complete and
no further content will be added. This allows the UI to finalize rendering,
remove any loading indicators, and potentially trigger actions that should occur
after message completion, such as enabling reply controls or performing
automatic scrolling to ensure the full message is visible.

| Property    | Description                            |
| ----------- | -------------------------------------- |
| `messageId` | Matches the ID from `TextMessageStart` |

### TextMessageChunk

A self-contained text message event that combines start, content, and end.

The `TextMessageChunk` event provides a convenient way to send complete text messages 
in a single event instead of the three-event sequence (start, content, end). This is 
particularly useful for simple messages or when the entire content is available at once. 
The event includes both the message metadata and content, making it more efficient for 
non-streaming scenarios.

| Property    | Description                                                                           |
| ----------- | ------------------------------------------------------------------------------------- |
| `messageId` | Optional unique identifier for the message                                            |
| `role`      | Optional role of the sender ("developer", "system", "assistant", "user", "tool")    |
| `delta`     | Optional text content of the message                                                  |

## Tool Call Events

These events represent the lifecycle of tool calls made by agents. Tool calls
follow a streaming pattern similar to text messages. When an agent needs to use
a tool, it emits a `ToolCallStart` event, followed by one or more `ToolCallArgs`
events that stream the arguments being passed to the tool, and concludes with a
`ToolCallEnd` event.

This streaming approach allows frontends to show tool executions in real-time,
making the agent's actions transparent and providing immediate feedback about
what tools are being invoked and with what parameters.

```mermaid
sequenceDiagram
    participant Agent
    participant Client

    Note over Agent,Client: Tool call begins
    Agent->>Client: ToolCallStart

    loop Arguments streaming
        Agent->>Client: ToolCallArgs
    end

    Note over Agent,Client: Tool call completes
    Agent->>Client: ToolCallEnd

    Note over Agent,Client: Tool execution result
    Agent->>Client: ToolCallResult
```

The `ToolCallArgs` events each contain a `delta` field with a chunk of the
arguments. Frontends should concatenate these deltas in the order received to
construct the complete arguments object. The `toolCallId` property links all
related events, allowing the frontend to associate argument chunks with the
correct tool call.

### ToolCallStart

Signals the start of a tool call.

The `ToolCallStart` event indicates that the agent is invoking a tool to perform
a specific function. This event provides the name of the tool being called and
establishes a unique `toolCallId` that will be referenced by subsequent events
in this tool call. Frontends can use this event to display tool usage to users,
such as showing a notification that a specific operation is in progress. The
optional `parentMessageId` allows linking the tool call to a specific message in
the conversation, providing context for why the tool is being used.

| Property          | Description                         |
| ----------------- | ----------------------------------- |
| `toolCallId`      | Unique identifier for the tool call |
| `toolCallName`    | Name of the tool being called       |
| `parentMessageId` | Optional ID of the parent message   |

### ToolCallArgs

Represents a chunk of argument data for a tool call.

The `ToolCallArgs` event delivers incremental parts of the tool's arguments as
they become available. Each event contains a segment of the argument data in the
`delta` property. These deltas are often JSON fragments that, when combined,
form the complete arguments object for the tool. Streaming the arguments is
particularly valuable for complex tool calls where constructing the full
arguments may take time. Frontends can progressively reveal these arguments to
users, providing insight into exactly what parameters are being passed to tools.

| Property     | Description                         |
| ------------ | ----------------------------------- |
| `toolCallId` | Matches the ID from `ToolCallStart` |
| `delta`      | Argument data chunk                 |

### ToolCallEnd

Signals the end of a tool call.

The `ToolCallEnd` event marks the completion of a tool call. After receiving
this event, the frontend knows that all arguments have been transmitted and the
tool execution is underway or completed. This allows the UI to finalize the tool
call display and prepare for potential results. In systems where tool execution
results are returned separately, this event indicates that the agent has
finished specifying the tool and its arguments, and is now waiting for or has
received the results.

| Property     | Description                         |
| ------------ | ----------------------------------- |
| `toolCallId` | Matches the ID from `ToolCallStart` |

### ToolCallResult

Provides the result of a tool call execution.

The `ToolCallResult` event delivers the output or result from a tool that was
previously invoked by the agent. This event is sent after the tool has been
executed by the system and contains the actual output generated by the tool.
Unlike the streaming pattern of tool call specification (start, args, end), the
result is delivered as a complete unit since tool execution typically produces a
complete output. Frontends can use this event to display tool results to users,
append them to the conversation history, or trigger follow-up actions based on
the tool's output.

| Property     | Description                                                 |
| ------------ | ----------------------------------------------------------- |
| `messageId`  | ID of the conversation message this result belongs to       |
| `toolCallId` | Matches the ID from the corresponding `ToolCallStart` event |
| `content`    | The actual result/output content from the tool execution    |
| `role`       | Optional role identifier, typically "tool" for tool results |

## State Management Events

These events are used to manage and synchronize the agent's state with the
frontend. State management in the protocol follows an efficient snapshot-delta
pattern where complete state snapshots are sent initially or infrequently, while
incremental updates (deltas) are used for ongoing changes.

This approach optimizes for both completeness and efficiency: snapshots ensure
the frontend has the full state context, while deltas minimize data transfer for
frequent updates. Together, they enable frontends to maintain an accurate
representation of agent state without unnecessary data transmission.

```mermaid
sequenceDiagram
    participant Agent
    participant Client

    Note over Agent,Client: Initial state transfer
    Agent->>Client: StateSnapshot

    Note over Agent,Client: Incremental updates
    loop State changes over time
        Agent->>Client: StateDelta
        Agent->>Client: StateDelta
    end

    Note over Agent,Client: Occasional full refresh
    Agent->>Client: StateSnapshot

    loop More incremental updates
        Agent->>Client: StateDelta
    end

    Note over Agent,Client: Message history update
    Agent->>Client: MessagesSnapshot
```

The combination of snapshots and deltas allows frontends to efficiently track
changes to agent state while ensuring consistency. Snapshots serve as
synchronization points that reset the state to a known baseline, while deltas
provide lightweight updates between snapshots.

### StateSnapshot

Provides a complete snapshot of an agent's state.

The `StateSnapshot` event delivers a comprehensive representation of the agent's
current state. This event is typically sent at the beginning of an interaction
or when synchronization is needed. It contains all state variables relevant to
the frontend, allowing it to completely rebuild its internal representation.
Frontends should replace their existing state model with the contents of this
snapshot rather than trying to merge it with previous state.

| Property   | Description             |
| ---------- | ----------------------- |
| `snapshot` | Complete state snapshot |

### StateDelta

Provides a partial update to an agent's state using JSON Patch.

The `StateDelta` event contains incremental updates to the agent's state in the
form of JSON Patch operations (as defined in RFC 6902). Each delta represents
specific changes to apply to the current state model. This approach is
bandwidth-efficient, sending only what has changed rather than the entire state.
Frontends should apply these patches in sequence to maintain an accurate state
representation. If a frontend detects inconsistencies after applying patches, it
may request a fresh `StateSnapshot`.

| Property | Description                               |
| -------- | ----------------------------------------- |
| `delta`  | Array of JSON Patch operations (RFC 6902) |

### MessagesSnapshot

Provides a snapshot of all messages in a conversation.

The `MessagesSnapshot` event delivers a complete history of messages in the
current conversation. Unlike the general state snapshot, this focuses
specifically on the conversation transcript. This event is useful for
initializing the chat history, synchronizing after connection interruptions, or
providing a comprehensive view when a user joins an ongoing conversation.
Frontends should use this to establish or refresh the conversational context
displayed to users.

| Property   | Description              |
| ---------- | ------------------------ |
| `messages` | Array of message objects |

## Special Events

Special events provide flexibility in the protocol by allowing for
system-specific functionality and integration with external systems. These
events don't follow the standard lifecycle or streaming patterns of other event
types but instead serve specialized purposes.

### Raw

Used to pass through events from external systems.

The `Raw` event acts as a container for events originating from external systems
or sources that don't natively follow the Agent UI Protocol. This event type
enables interoperability with other event-based systems by wrapping their events
in a standardized format. The enclosed event data is preserved in its original
form inside the `event` property, while the optional `source` property
identifies the system it came from. Frontends can use this information to handle
external events appropriately, either by processing them directly or by
delegating them to system-specific handlers.

| Property | Description                |
| -------- | -------------------------- |
| `event`  | Original event data        |
| `source` | Optional source identifier |

### Custom

Used for application-specific custom events.

The `Custom` event provides an extension mechanism for implementing features not
covered by the standard event types. Unlike `Raw` events which act as
passthrough containers, `Custom` events are explicitly part of the protocol but
with application-defined semantics. The `name` property identifies the specific
custom event type, while the `value` property contains the associated data. This
mechanism allows for protocol extensions without requiring formal specification
changes. Teams should document their custom events to ensure consistent
implementation across frontends and agents.

| Property | Description                     |
| -------- | ------------------------------- |
| `name`   | Name of the custom event        |
| `value`  | Value associated with the event |

## Draft Events

These events are currently in draft status and may change before finalization. They represent proposed extensions to the protocol that are under active development and discussion.

### Activity Events

<span style={{backgroundColor: '#3b82f6', color: 'white', padding: '2px 6px', borderRadius: '4px', fontSize: '0.75em', fontWeight: 'bold'}}>DRAFT</span> [View Proposal](/drafts/activity-events)

Activity events represent ongoing agent progress between chat messages, allowing frameworks to surface fine-grained activity updates chronologically.

#### ActivitySnapshotEvent

Provides the complete activity state at a point in time.

| Property       | Description                                          |
| -------------- | ---------------------------------------------------- |
| `messageId`    | Unique identifier for the ActivityMessage           |
| `activityType` | Activity type (e.g., "PLAN", "SEARCH", "SCRAPE")    |
| `content`      | Complete activity state at this point               |

#### ActivityDeltaEvent

Provides incremental updates to the activity state using JSON Patch operations.

| Property       | Description                                          |
| -------------- | ---------------------------------------------------- |
| `messageId`    | Unique identifier for the ActivityMessage           |
| `activityType` | Activity type (e.g., "PLAN", "SEARCH", "SCRAPE")    |
| `patch`        | JSON Patch operations (RFC 6902) to apply           |

### Reasoning Events

<span style={{backgroundColor: '#3b82f6', color: 'white', padding: '2px 6px', borderRadius: '4px', fontSize: '0.75em', fontWeight: 'bold'}}>DRAFT</span> [View Proposal](/drafts/reasoning)

Reasoning events support LLM reasoning visibility and continuity, enabling chain-of-thought reasoning while maintaining privacy.

#### ReasoningStart

Marks the start of reasoning.

| Property           | Description                             |
| ------------------ | --------------------------------------- |
| `messageId`        | Unique identifier of this reasoning     |
| `encryptedContent` | Optional encrypted content              |

#### ReasoningMessageStart

Signals the start of a reasoning message.

| Property    | Description                         |
| ----------- | ----------------------------------- |
| `messageId` | Unique identifier of the message    |
| `role`      | Role of the reasoning message       |

#### ReasoningMessageContent

Represents a chunk of content in a streaming reasoning message.

| Property    | Description                          |
| ----------- | ------------------------------------ |
| `messageId` | Matches ID from ReasoningMessageStart |
| `delta`     | Reasoning content chunk (non-empty)   |

#### ReasoningMessageEnd

Signals the end of a reasoning message.

| Property    | Description                          |
| ----------- | ------------------------------------ |
| `messageId` | Matches ID from ReasoningMessageStart |

#### ReasoningMessageChunk

A convenience event to auto start/close reasoning messages.

| Property    | Description                               |
| ----------- | ----------------------------------------- |
| `messageId` | Optional message ID                       |
| `delta`     | Optional reasoning content chunk          |

#### ReasoningEnd

Marks the end of reasoning.

| Property    | Description                         |
| ----------- | ----------------------------------- |
| `messageId` | Unique identifier of this reasoning |

### Meta Events

<span style={{backgroundColor: '#3b82f6', color: 'white', padding: '2px 6px', borderRadius: '4px', fontSize: '0.75em', fontWeight: 'bold'}}>DRAFT</span> [View Proposal](/drafts/meta-events)

Meta events provide annotations and signals independent of agent runs, such as user feedback or external system events.

#### MetaEvent

A side-band annotation event that can occur anywhere in the stream.

| Property   | Description                                               |
| ---------- | --------------------------------------------------------- |
| `metaType` | Application-defined type (e.g., "thumbs_up", "tag")      |
| `payload`  | Application-defined payload                               |

### Modified Lifecycle Events

<span style={{backgroundColor: '#3b82f6', color: 'white', padding: '2px 6px', borderRadius: '4px', fontSize: '0.75em', fontWeight: 'bold'}}>DRAFT</span> [View Proposal](/drafts/interrupts)

Extensions to existing lifecycle events to support interrupts and branching.

#### RunFinished (Extended)

The `RunFinished` event gains new fields to support interrupt-aware workflows.

| Property    | Description                                          |
| ----------- | ---------------------------------------------------- |
| `outcome`   | Optional: "success" or "interrupt"                  |
| `interrupt` | Optional: Contains interrupt details when paused    |

<span style={{backgroundColor: '#3b82f6', color: 'white', padding: '2px 6px', borderRadius: '4px', fontSize: '0.75em', fontWeight: 'bold'}}>DRAFT</span> [View Proposal](/drafts/serialization)

#### RunStarted (Extended)

The `RunStarted` event gains new fields to support branching and input tracking.

| Property     | Description                                        |
| ------------ | -------------------------------------------------- |
| `parentRunId`| Optional: Parent run ID for branching/time travel |
| `input`      | Optional: The exact agent input for this run      |

## Event Flow Patterns

Events in the protocol typically follow specific patterns:

1. **Start-Content-End Pattern**: Used for streaming content (text messages,
   tool calls)

   - `Start` event initiates the stream
   - `Content` events deliver data chunks
   - `End` event signals completion

2. **Snapshot-Delta Pattern**: Used for state synchronization

   - `Snapshot` provides complete state
   - `Delta` events provide incremental updates

3. **Lifecycle Pattern**: Used for monitoring agent runs
   - `Started` events signal beginnings
   - `Finished`/`Error` events signal endings

## Implementation Considerations

When implementing event handlers:

- Events should be processed in the order they are received
- Events with the same ID (e.g., `messageId`, `toolCallId`) belong to the same
  logical stream
- Implementations should be resilient to out-of-order delivery
- Custom events should follow the established patterns for consistency



================================================
FILE: docs/concepts/messages.mdx
================================================
---
title: "Messages"
description: "Understanding message structure and communication in AG-UI"
---

# Messages

Messages form the backbone of communication in the AG-UI protocol. They
represent the conversation history between users and AI agents, and provide a
standardized way to exchange information regardless of the underlying AI service
being used.

## Message Structure

AG-UI messages follow a vendor-neutral format, ensuring compatibility across
different AI providers while maintaining a consistent structure. This allows
applications to switch between AI services (like OpenAI, Anthropic, or custom
models) without changing the client-side implementation.

The basic message structure includes:

```typescript
interface BaseMessage {
  id: string // Unique identifier for the message
  role: string // The role of the sender (user, assistant, system, tool)
  content?: string // Optional text content of the message
  name?: string // Optional name of the sender
}
```

## Message Types

AG-UI supports several message types to accommodate different participants in a
conversation:

### User Messages

Messages from the end user to the agent:

```typescript
interface UserMessage {
  id: string
  role: "user"
  content: string // Text input from the user
  name?: string // Optional user identifier
}
```

### Assistant Messages

Messages from the AI assistant to the user:

```typescript
interface AssistantMessage {
  id: string
  role: "assistant"
  content?: string // Text response from the assistant (optional if using tool calls)
  name?: string // Optional assistant identifier
  toolCalls?: ToolCall[] // Optional tool calls made by the assistant
}
```

### System Messages

Instructions or context provided to the agent:

```typescript
interface SystemMessage {
  id: string
  role: "system"
  content: string // Instructions or context for the agent
  name?: string // Optional identifier
}
```

### Tool Messages

Results from tool executions:

```typescript
interface ToolMessage {
  id: string
  role: "tool"
  content: string // Result from the tool execution
  toolCallId: string // ID of the tool call this message responds to
}
```

### Developer Messages

Internal messages used for development or debugging:

```typescript
interface DeveloperMessage {
  id: string
  role: "developer"
  content: string
  name?: string
}
```

## Vendor Neutrality

AG-UI messages are designed to be vendor-neutral, meaning they can be easily
mapped to and from proprietary formats used by various AI providers:

```typescript
// Example: Converting AG-UI messages to OpenAI format
const openaiMessages = agUiMessages
  .filter((msg) => ["user", "system", "assistant"].includes(msg.role))
  .map((msg) => ({
    role: msg.role as "user" | "system" | "assistant",
    content: msg.content || "",
    // Map tool calls if present
    ...(msg.role === "assistant" && msg.toolCalls
      ? {
          tool_calls: msg.toolCalls.map((tc) => ({
            id: tc.id,
            type: tc.type,
            function: {
              name: tc.function.name,
              arguments: tc.function.arguments,
            },
          })),
        }
      : {}),
  }))
```

This abstraction allows AG-UI to serve as a common interface regardless of the
underlying AI service.

## Message Synchronization

Messages can be synchronized between client and server through two primary
mechanisms:

### Complete Snapshots

The `MESSAGES_SNAPSHOT` event provides a complete view of all messages in a
conversation:

```typescript
interface MessagesSnapshotEvent {
  type: EventType.MESSAGES_SNAPSHOT
  messages: Message[] // Complete array of all messages
}
```

This is typically used:

- When initializing a conversation
- After connection interruptions
- When major state changes occur
- To ensure client-server synchronization

### Streaming Messages

For real-time interactions, new messages can be streamed as they're generated:

1. **Start a message**: Indicate a new message is being created

   ```typescript
   interface TextMessageStartEvent {
     type: EventType.TEXT_MESSAGE_START
     messageId: string
     role: string
   }
   ```

2. **Stream content**: Send content chunks as they become available

   ```typescript
   interface TextMessageContentEvent {
     type: EventType.TEXT_MESSAGE_CONTENT
     messageId: string
     delta: string // Text chunk to append
   }
   ```

3. **End a message**: Signal the message is complete
   ```typescript
   interface TextMessageEndEvent {
     type: EventType.TEXT_MESSAGE_END
     messageId: string
   }
   ```

This streaming approach provides a responsive user experience with immediate
feedback.

## Tool Integration in Messages

AG-UI messages elegantly integrate tool usage, allowing agents to perform
actions and process their results:

### Tool Calls

Tool calls are embedded within assistant messages:

```typescript
interface ToolCall {
  id: string // Unique ID for this tool call
  type: "function" // Type of tool call
  function: {
    name: string // Name of the function to call
    arguments: string // JSON-encoded string of arguments
  }
}
```

Example assistant message with tool calls:

```typescript
{
  id: "msg_123",
  role: "assistant",
  content: "I'll help you with that calculation.",
  toolCalls: [
    {
      id: "call_456",
      type: "function",
      function: {
        name: "calculate",
        arguments: '{"expression": "24 * 7"}'
      }
    }
  ]
}
```

### Tool Results

Results from tool executions are represented as tool messages:

```typescript
{
  id: "result_789",
  role: "tool",
  content: "168",
  toolCallId: "call_456" // References the original tool call
}
```

This creates a clear chain of tool usage:

1. Assistant requests a tool call
2. Tool executes and returns a result
3. Assistant can reference and respond to the result

## Streaming Tool Calls

Similar to text messages, tool calls can be streamed to provide real-time
visibility into the agent's actions:

1. **Start a tool call**:

   ```typescript
   interface ToolCallStartEvent {
     type: EventType.TOOL_CALL_START
     toolCallId: string
     toolCallName: string
     parentMessageId?: string // Optional link to parent message
   }
   ```

2. **Stream arguments**:

   ```typescript
   interface ToolCallArgsEvent {
     type: EventType.TOOL_CALL_ARGS
     toolCallId: string
     delta: string // JSON fragment to append to arguments
   }
   ```

3. **End a tool call**:
   ```typescript
   interface ToolCallEndEvent {
     type: EventType.TOOL_CALL_END
     toolCallId: string
   }
   ```

This allows frontends to show tools being invoked progressively as the agent
constructs its reasoning.

## Practical Example

Here's a complete example of a conversation with tool usage:

```typescript
// Conversation history
;[
  // User query
  {
    id: "msg_1",
    role: "user",
    content: "What's the weather in New York?",
  },

  // Assistant response with tool call
  {
    id: "msg_2",
    role: "assistant",
    content: "Let me check the weather for you.",
    toolCalls: [
      {
        id: "call_1",
        type: "function",
        function: {
          name: "get_weather",
          arguments: '{"location": "New York", "unit": "celsius"}',
        },
      },
    ],
  },

  // Tool result
  {
    id: "result_1",
    role: "tool",
    content:
      '{"temperature": 22, "condition": "Partly Cloudy", "humidity": 65}',
    toolCallId: "call_1",
  },

  // Assistant's final response using tool results
  {
    id: "msg_3",
    role: "assistant",
    content:
      "The weather in New York is partly cloudy with a temperature of 22°C and 65% humidity.",
  },
]
```

## Conclusion

The message structure in AG-UI enables sophisticated conversational AI
experiences while maintaining vendor neutrality. By standardizing how messages
are represented, synchronized, and streamed, AG-UI provides a consistent way to
implement interactive human-agent communication regardless of the underlying AI
service.

This system supports everything from simple text exchanges to complex tool-based
workflows, all while optimizing for both real-time responsiveness and efficient
data transfer.



================================================
FILE: docs/concepts/state.mdx
================================================
---
title: "State Management"
description:
  "Understanding state synchronization between agents and frontends in AG-UI"
---

# State Management

State management is a core feature of the AG-UI protocol that enables real-time
synchronization between agents and frontend applications. By providing efficient
mechanisms for sharing and updating state, AG-UI creates a foundation for
collaborative experiences where both AI agents and human users can work together
seamlessly.

## Shared State Architecture

In AG-UI, state is a structured data object that:

1. Persists across interactions with an agent
2. Can be accessed by both the agent and the frontend
3. Updates in real-time as the interaction progresses
4. Provides context for decision-making on both sides

This shared state architecture creates a bidirectional communication channel
where:

- Agents can access the application's current state to make informed decisions
- Frontends can observe and react to changes in the agent's internal state
- Both sides can modify the state, creating a collaborative workflow

## State Synchronization Methods

AG-UI provides two complementary methods for state synchronization:

### State Snapshots

The `STATE_SNAPSHOT` event delivers a complete representation of an agent's
current state:

```typescript
interface StateSnapshotEvent {
  type: EventType.STATE_SNAPSHOT
  snapshot: any // Complete state object
}
```

Snapshots are typically used:

- At the beginning of an interaction to establish the initial state
- After connection interruptions to ensure synchronization
- When major state changes occur that require a complete refresh
- To establish a new baseline for future delta updates

When a frontend receives a `STATE_SNAPSHOT` event, it should replace its
existing state model entirely with the contents of the snapshot.

### State Deltas

The `STATE_DELTA` event delivers incremental updates to the state using JSON
Patch format (RFC 6902):

```typescript
interface StateDeltaEvent {
  type: EventType.STATE_DELTA
  delta: JsonPatchOperation[] // Array of JSON Patch operations
}
```

Deltas are bandwidth-efficient, sending only what has changed rather than the
entire state. This approach is particularly valuable for:

- Frequent small updates during streaming interactions
- Large state objects where most properties remain unchanged
- High-frequency updates that would be inefficient to send as full snapshots

## JSON Patch Format

AG-UI uses the JSON Patch format (RFC 6902) for state deltas, which defines a
standardized way to express changes to a JSON document:

```typescript
interface JsonPatchOperation {
  op: "add" | "remove" | "replace" | "move" | "copy" | "test"
  path: string // JSON Pointer (RFC 6901) to the target location
  value?: any // The value to apply (for add, replace)
  from?: string // Source path (for move, copy)
}
```

Common operations include:

1. **add**: Adds a value to an object or array

   ```json
   { "op": "add", "path": "/user/preferences", "value": { "theme": "dark" } }
   ```

2. **replace**: Replaces a value

   ```json
   { "op": "replace", "path": "/conversation_state", "value": "paused" }
   ```

3. **remove**: Removes a value

   ```json
   { "op": "remove", "path": "/temporary_data" }
   ```

4. **move**: Moves a value from one location to another
   ```json
   { "op": "move", "path": "/completed_items", "from": "/pending_items/0" }
   ```

Frontends should apply these patches in sequence to maintain an accurate state
representation. If inconsistencies are detected after applying patches, the
frontend can request a fresh `STATE_SNAPSHOT`.

## State Processing in AG-UI

In the AG-UI implementation, state deltas are applied using the
`fast-json-patch` library:

```typescript
case EventType.STATE_DELTA: {
  const { delta } = event as StateDeltaEvent;

  try {
    // Apply the JSON Patch operations to the current state without mutating the original
    const result = applyPatch(state, delta, true, false);
    state = result.newDocument;
    return emitUpdate({ state });
  } catch (error: unknown) {
    console.warn(
      `Failed to apply state patch:\n` +
      `Current state: ${JSON.stringify(state, null, 2)}\n` +
      `Patch operations: ${JSON.stringify(delta, null, 2)}\n` +
      `Error: ${errorMessage}`
    );
    return emitNoUpdate();
  }
}
```

This implementation ensures that:

- Patches are applied atomically (all or none)
- The original state is not mutated during the application process
- Errors are caught and handled gracefully

## Human-in-the-Loop Collaboration

The shared state system is fundamental to human-in-the-loop workflows in AG-UI.
It enables:

1. **Real-time visibility**: Users can observe the agent's thought process and
   current status
2. **Contextual awareness**: The agent can access user actions, preferences, and
   application state
3. **Collaborative decision-making**: Both human and AI can contribute to the
   evolving state
4. **Feedback loops**: Humans can correct or guide the agent by modifying state
   properties

For example, an agent might update its state with a proposed action:

```json
{
  "proposal": {
    "action": "send_email",
    "recipient": "client@example.com",
    "content": "Draft email content..."
  }
}
```

The frontend can display this proposal to the user, who can then approve,
reject, or modify it before execution.

## CopilotKit Implementation

[CopilotKit](https://docs.copilotkit.ai), a popular framework for building AI
assistants, leverages AG-UI's state management system through its "shared state"
feature. This implementation enables bidirectional state synchronization between
agents (particularly LangGraph agents) and frontend applications.

CopilotKit's shared state system is implemented through:

```jsx
// In the frontend React application
const { state: agentState, setState: setAgentState } = useCoAgent({
  name: "agent",
  initialState: { someProperty: "initialValue" },
})
```

This hook creates a real-time connection to the agent's state, allowing:

1. Reading the agent's current state in the frontend
2. Updating the agent's state from the frontend
3. Rendering UI components based on the agent's state

On the backend, LangGraph agents can emit state updates using:

```python
# In the LangGraph agent
async def tool_node(self, state: ResearchState, config: RunnableConfig):
    # Update state with new information
    tool_state = {
        "title": new_state.get("title", ""),
        "outline": new_state.get("outline", {}),
        "sections": new_state.get("sections", []),
        # Other state properties...
    }

    # Emit updated state to frontend
    await copilotkit_emit_state(config, tool_state)

    return tool_state
```

These state updates are transmitted using AG-UI's state snapshot and delta
mechanisms, creating a seamless shared context between agent and frontend.

## Best Practices

When implementing state management in AG-UI:

1. **Use snapshots judiciously**: Full snapshots should be sent only when
   necessary to establish a baseline.
2. **Prefer deltas for incremental changes**: Small state updates should use
   deltas to minimize data transfer.
3. **Structure state thoughtfully**: Design state objects to support partial
   updates and minimize patch complexity.
4. **Handle state conflicts**: Implement strategies for resolving conflicting
   updates from agent and frontend.
5. **Include error recovery**: Provide mechanisms to resynchronize state if
   inconsistencies are detected.
6. **Consider security implications**: Avoid storing sensitive information in
   shared state.

## Conclusion

AG-UI's state management system provides a powerful foundation for building
collaborative applications where humans and AI agents work together. By
efficiently synchronizing state between frontend and backend through snapshots
and JSON Patch deltas, AG-UI enables sophisticated human-in-the-loop workflows
that combine the strengths of both human intuition and AI capabilities.

The implementation in frameworks like CopilotKit demonstrates how this shared
state approach can create collaborative experiences that are more effective than
either fully autonomous systems or traditional user interfaces.



================================================
FILE: docs/concepts/tools.mdx
================================================
---
title: "Tools"
description:
  "Understanding tools and how they enable human-in-the-loop AI workflows"
---

# Tools

Tools are a fundamental concept in the AG-UI protocol that enable AI agents to
interact with external systems and incorporate human judgment into their
workflows. By defining tools in the frontend and passing them to agents,
developers can create sophisticated human-in-the-loop experiences that combine
AI capabilities with human expertise.

## What Are Tools?

In AG-UI, tools are functions that agents can call to:

1. Request specific information
2. Perform actions in external systems
3. Ask for human input or confirmation
4. Access specialized capabilities

Tools bridge the gap between AI reasoning and real-world actions, allowing
agents to accomplish tasks that would be impossible through conversation alone.

## Tool Structure

Tools follow a consistent structure that defines their name, purpose, and
expected parameters:

```typescript
interface Tool {
  name: string // Unique identifier for the tool
  description: string // Human-readable explanation of what the tool does
  parameters: {
    // JSON Schema defining the tool's parameters
    type: "object"
    properties: {
      // Tool-specific parameters
    }
    required: string[] // Array of required parameter names
  }
}
```

The `parameters` field uses [JSON Schema](https://json-schema.org/) to define
the structure of arguments that the tool accepts. This schema is used by both
the agent (to generate valid tool calls) and the frontend (to validate and parse
tool arguments).

## Frontend-Defined Tools

A key aspect of AG-UI's tool system is that tools are defined in the frontend
and passed to the agent during execution:

```typescript
// Define tools in the frontend
const userConfirmationTool = {
  name: "confirmAction",
  description: "Ask the user to confirm a specific action before proceeding",
  parameters: {
    type: "object",
    properties: {
      action: {
        type: "string",
        description: "The action that needs user confirmation",
      },
      importance: {
        type: "string",
        enum: ["low", "medium", "high", "critical"],
        description: "The importance level of the action",
      },
    },
    required: ["action"],
  },
}

// Pass tools to the agent during execution
agent.runAgent({
  tools: [userConfirmationTool],
  // Other parameters...
})
```

This approach has several advantages:

1. **Frontend control**: The frontend determines what capabilities are available
   to the agent
2. **Dynamic capabilities**: Tools can be added or removed based on user
   permissions, context, or application state
3. **Separation of concerns**: Agents focus on reasoning while frontends handle
   tool implementation
4. **Security**: Sensitive operations are controlled by the application, not the
   agent

## Tool Call Lifecycle

When an agent needs to use a tool, it follows a standardized sequence of events:

1. **ToolCallStart**: Indicates the beginning of a tool call with a unique ID
   and tool name

   ```typescript
   {
     type: EventType.TOOL_CALL_START,
     toolCallId: "tool-123",
     toolCallName: "confirmAction",
     parentMessageId: "msg-456" // Optional reference to a message
   }
   ```

2. **ToolCallArgs**: Streams the tool arguments as they're generated

   ```typescript
   {
     type: EventType.TOOL_CALL_ARGS,
     toolCallId: "tool-123",
     delta: '{"act' // Partial JSON being streamed
   }
   ```

   ```typescript
   {
     type: EventType.TOOL_CALL_ARGS,
     toolCallId: "tool-123",
     delta: 'ion":"Depl' // More JSON being streamed
   }
   ```

   ```typescript
   {
     type: EventType.TOOL_CALL_ARGS,
     toolCallId: "tool-123",
     delta: 'oy the application to production"}' // Final JSON fragment
   }
   ```

3. **ToolCallEnd**: Marks the completion of the tool call
   ```typescript
   {
     type: EventType.TOOL_CALL_END,
     toolCallId: "tool-123"
   }
   ```

The frontend accumulates these deltas to construct the complete tool call
arguments. Once the tool call is complete, the frontend can execute the tool and
provide results back to the agent.

## Tool Results

After a tool has been executed, the result is sent back to the agent as a "tool
message":

```typescript
{
  id: "result-789",
  role: "tool",
  content: "true", // Tool result as a string
  toolCallId: "tool-123" // References the original tool call
}
```

This message becomes part of the conversation history, allowing the agent to
reference and incorporate the tool's result in subsequent responses.

## Human-in-the-Loop Workflows

The AG-UI tool system is especially powerful for implementing human-in-the-loop
workflows. By defining tools that request human input or confirmation,
developers can create AI experiences that seamlessly blend autonomous operation
with human judgment.

For example:

1. Agent needs to make an important decision
2. Agent calls the `confirmAction` tool with details about the decision
3. Frontend displays a confirmation dialog to the user
4. User provides their input
5. Frontend sends the user's decision back to the agent
6. Agent continues processing with awareness of the user's choice

This pattern enables use cases like:

- **Approval workflows**: AI suggests actions that require human approval
- **Data verification**: Humans verify or correct AI-generated data
- **Collaborative decision-making**: AI and humans jointly solve complex
  problems
- **Supervised learning**: Human feedback improves future AI decisions

## CopilotKit Integration

[CopilotKit](https://docs.copilotkit.ai/) provides a simplified way to work with
AG-UI tools in React applications through its
[`useCopilotAction`](https://docs.copilotkit.ai/guides/frontend-actions) hook:

```tsx
import { useCopilotAction } from "@copilotkit/react-core"

// Define a tool for user confirmation
useCopilotAction({
  name: "confirmAction",
  description: "Ask the user to confirm an action",
  parameters: {
    type: "object",
    properties: {
      action: {
        type: "string",
        description: "The action to confirm",
      },
    },
    required: ["action"],
  },
  handler: async ({ action }) => {
    // Show a confirmation dialog
    const confirmed = await showConfirmDialog(action)
    return confirmed ? "approved" : "rejected"
  },
})
```

This approach makes it easy to define tools that integrate with your React
components and handle the tool execution logic in a clean, declarative way.

## Tool Examples

Here are some common types of tools used in AG-UI applications:

### User Confirmation

```typescript
{
  name: "confirmAction",
  description: "Ask the user to confirm an action",
  parameters: {
    type: "object",
    properties: {
      action: {
        type: "string",
        description: "The action to confirm"
      },
      importance: {
        type: "string",
        enum: ["low", "medium", "high", "critical"],
        description: "The importance level"
      }
    },
    required: ["action"]
  }
}
```

### Data Retrieval

```typescript
{
  name: "fetchUserData",
  description: "Retrieve data about a specific user",
  parameters: {
    type: "object",
    properties: {
      userId: {
        type: "string",
        description: "ID of the user"
      },
      fields: {
        type: "array",
        items: {
          type: "string"
        },
        description: "Fields to retrieve"
      }
    },
    required: ["userId"]
  }
}
```

### User Interface Control

```typescript
{
  name: "navigateTo",
  description: "Navigate to a different page or view",
  parameters: {
    type: "object",
    properties: {
      destination: {
        type: "string",
        description: "Destination page or view"
      },
      params: {
        type: "object",
        description: "Optional parameters for the navigation"
      }
    },
    required: ["destination"]
  }
}
```

### Content Generation

```typescript
{
  name: "generateImage",
  description: "Generate an image based on a description",
  parameters: {
    type: "object",
    properties: {
      prompt: {
        type: "string",
        description: "Description of the image to generate"
      },
      style: {
        type: "string",
        description: "Visual style for the image"
      },
      dimensions: {
        type: "object",
        properties: {
          width: { type: "number" },
          height: { type: "number" }
        },
        description: "Dimensions of the image"
      }
    },
    required: ["prompt"]
  }
}
```

## Best Practices

When designing tools for AG-UI:

1. **Clear naming**: Use descriptive, action-oriented names
2. **Detailed descriptions**: Include thorough descriptions to help the agent
   understand when and how to use the tool
3. **Structured parameters**: Define precise parameter schemas with descriptive
   field names and constraints
4. **Required fields**: Only mark parameters as required if they're truly
   necessary
5. **Error handling**: Implement robust error handling in tool execution code
6. **User experience**: Design tool UIs that provide appropriate context for
   human decision-making

## Conclusion

Tools in AG-UI bridge the gap between AI reasoning and real-world actions,
enabling sophisticated workflows that combine the strengths of AI and human
intelligence. By defining tools in the frontend and passing them to agents,
developers can create interactive experiences where AI and humans collaborate
efficiently.

The tool system is particularly powerful for implementing human-in-the-loop
workflows, where AI can suggest actions but defer critical decisions to humans.
This balances automation with human judgment, creating AI experiences that are
both powerful and trustworthy.



================================================
FILE: docs/development/contributing.mdx
================================================
---
title: Contributing
description: How to participate in Agent User Interaction Protocol development
---

# Naming conventions

Add your package under `typescript-sdk/integrations/` with docs and tests.

If your integration is work in progress, you can still add it to main branch.
You can prefix it with `wip-`, i.e.
(`typescript-sdk/integrations/wip-your-integration`) or if you're a third party
contributor use the `community` prefix, i.e.
(`typescript-sdk/integrations/community-your-integration`).

For questions and discussions, please use
[GitHub Discussions](https://github.com/orgs/ag-ui-protocol/discussions).



================================================
FILE: docs/development/roadmap.mdx
================================================
---
title: Roadmap
description: Our plans for evolving Agent User Interaction Protocol
---

You can follow the progress of the AG-UI Protocol on our
[public roadmap](https://github.com/orgs/ag-ui-protocol/projects/1).

## Get Involved

If you’d like to contribute ideas, feature requests, or bug reports to 
the roadmap, please see the [Contributing Guide](https://github.com/ag-ui-protocol/ag-ui/blob/main/CONTRIBUTING.md)
for details on how to get involved.



================================================
FILE: docs/development/updates.mdx
================================================
---
title: "What's New"
description: "The latest updates and improvements to AG-UI"
---

<Update label="2025-04-09" description="AG-UI repositories are now public">
  - Initial release of the Agent User Interaction Protocol
</Update>



================================================
FILE: docs/drafts/activity-events.mdx
================================================
---
title: Activity Events
description:
  Proposal for representing ongoing agent progress between chat messages
---

# Activity Events Proposal

## Summary

### Problem Statement

Users want to render "activity" updates inline with chat, not just at run start
or end. Currently, there's no standardized way to represent ongoing agent
progress between chat messages.

### Motivation

AG-UI is extended with **ActivityEvents** and **ActivityMessages** to represent
ongoing agent progress in between chat messages. This allows frameworks to
surface fine-grained activity updates chronologically, giving users immediate
visibility into what an agent is doing without waiting for the next message or
run boundary.

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Background

Users want real-time visibility into agent activities as they happen. Consider
this example UI:

```
+------------------------------------------------------------+
| I will search the internet for relevant information        | <- TextMessage
+------------------------------------------------------------+
+------------------------------------------------------------+
| ✓ checking reddit                                          | <- ActivityMessage
| searching X.com...                                         |
+------------------------------------------------------------+
```

### Use Cases

- **Workflows**: Step-by-step progress through workflow execution
- **Planning**: Intermediate planning or tool use visibility
- **Custom frameworks**: Signals representing ongoing work in any agent system

## Challenges

- **Flexibility**: Must handle arbitrary activity data from different frameworks
- **Serializability**: Events must be replayable and rehydrated for session
  recovery
- **Extensibility**: Developers should define custom renderers per activity
  type, with a generic fallback
- **Chronology**: Activities must interleave naturally with chat and run events

## Detailed Specification

### Overview

This proposal introduces new concepts to the AG-UI protocol:

1. **ActivitySnapshotEvent** and **ActivityDeltaEvent**: Two new event types following the established state management pattern
2. **ActivityMessage**: A new message type alongside TextMessage, ToolMessage,
   etc.

Frameworks may emit ActivityEvents, and frontends can render them inline with
chat.

### New Events: ActivitySnapshotEvent and ActivityDeltaEvent

Following the established pattern in AG-UI (similar to `StateSnapshotEvent` and `StateDeltaEvent`), activities are represented using two complementary events:

#### ActivitySnapshotEvent

Provides the complete activity state at a point in time.

```typescript
type ActivitySnapshotEvent = BaseEvent & {
  type: EventType.ACTIVITY_SNAPSHOT
  /**
   * Unique identifier for the ActivityMessage this event belongs to.
   */
  messageId: string
  /**
   * Activity type, e.g. "PLAN", "SEARCH", "SCRAPE"
   */
  activityType: string
  /**
   * Complete activity state at this point in time.
   */
  content: Record<string, any>
}
```

#### ActivityDeltaEvent

Provides incremental updates to the activity state.

```typescript
type ActivityDeltaEvent = BaseEvent & {
  type: EventType.ACTIVITY_DELTA
  /**
   * Unique identifier for the ActivityMessage this event belongs to.
   */
  messageId: string
  /**
   * Activity type, e.g. "PLAN", "SEARCH", "SCRAPE"
   */
  activityType: string
  /**
   * JSON Patch operations to apply to the current activity state.
   * Follows RFC 6902 semantics.
   */
  patch: JSONPatchOperation[]
}
```

#### Example Events

Initial activity snapshot:

```json
{
  "id": "evt_001",
  "ts": 1714064100000,
  "type": "ACTIVITY_SNAPSHOT",
  "messageId": "msg_789",
  "activityType": "PLAN",
  "content": {
    "tasks": ["check reddit", "search X.com"]
  }
}
```

Incremental update via patch:

```json
{
  "id": "evt_002",
  "ts": 1714064120000,
  "type": "ACTIVITY_DELTA",
  "messageId": "msg_789",
  "activityType": "PLAN",
  "patch": [
    {
      "op": "replace",
      "path": "/tasks/0",
      "value": "✓ check reddit"
    }
  ]
}
```

### New Message: ActivityMessage

```typescript
type ActivityMessage = {
  id: string
  role: "activity"
  activityType: string
  /**
   * Finalized activity content as of compaction.
   */
  content: Record<string, any>
}
```

### Rendering Strategy

- **Generic renderer**: Displays raw snapshot/patch as JSON or formatted text
- **Custom renderer**: Developers can register a renderer per `activityType`:
  - `"PLAN"` → Interactive checklist component
  - `"SEARCH"` → Live status with progress indicators
  - `"WORKFLOW"` → Step-by-step workflow visualization

## Implementation Considerations

### Client SDK Changes

TypeScript SDK additions:

- New `ActivitySnapshotEvent` and `ActivityDeltaEvent` types in `@ag-ui/core`
- New `ActivityMessage` type in message unions
- Activity renderer registry in `@ag-ui/client`
- JSON Patch utilities for activity updates

Python SDK additions:

- New `ActivitySnapshotEvent` and `ActivityDeltaEvent` classes in `ag_ui.core.events`
- New `ActivityMessage` class in message types
- Activity serialization/deserialization support
- JSON Patch utilities for activity updates

### Integration Impact

- **Planning Frameworks**: Can emit ActivitySnapshotEvent/ActivityDeltaEvent during planning or tool
  execution phases
- **Workflow Systems**: Can surface step-by-step workflow progress as
  ActivitySnapshotEvent/ActivityDeltaEvent
- **Other frameworks**: May emit ActivitySnapshotEvent/ActivityDeltaEvent freely; AG-UI will serialize
  them like other events

## Examples and Use Cases

### Example 1: Web Search Activity

```typescript
// Agent emits initial search activity snapshot
agent.emitActivitySnapshot({
  messageId: "msg_123",
  activityType: "SEARCH",
  content: {
    sources: [
      { name: "Reddit", status: "pending" },
      { name: "X.com", status: "pending" },
      { name: "Google", status: "pending" },
    ],
  },
})

// Update as search progresses
agent.emitActivityDelta({
  messageId: "msg_123",
  activityType: "SEARCH",
  patch: [
    {
      op: "replace",
      path: "/sources/0/status",
      value: "complete",
    }
  ],
})
```

### Use Case: Multi-Step Workflow Visibility

A data analysis agent performing multiple steps:

1. Loading dataset → ActivitySnapshotEvent/ActivityDeltaEvent shows progress bar
2. Cleaning data → ActivitySnapshotEvent/ActivityDeltaEvent shows rows processed
3. Running analysis → ActivitySnapshotEvent/ActivityDeltaEvent shows current computation
4. Generating report → ActivitySnapshotEvent/ActivityDeltaEvent shows sections completed

Each step appears inline with chat, giving users real-time feedback.

## Testing Strategy

- Unit tests for ActivitySnapshotEvent/ActivityDeltaEvent serialization/deserialization
- Integration tests with mock frameworks emitting ActivitySnapshotEvent/ActivityDeltaEvent
- E2E tests in AG-UI Dojo demonstrating activity rendering
- Performance benchmarks for high-frequency activity updates
- JSON Patch application correctness tests

## References

- [JSON Patch RFC 6902](https://tools.ietf.org/html/rfc6902)
- [AG-UI Events Documentation](/concepts/events)
- [AG-UI Messages Documentation](/concepts/messages)



================================================
FILE: docs/drafts/generative-ui.mdx
================================================
---
title: Generative User Interfaces
description: AI-generated interfaces without custom tool renderers
---

# Generative User Interfaces

## Summary

### Problem Statement

Currently, creating custom user interfaces for agent interactions requires
programmers to define specific tool renderers. This limits the flexibility and
adaptability of agent-driven applications.

### Motivation

This draft describes an AG-UI extension that addresses **generative user
interfaces**—interfaces produced directly by artificial intelligence without
requiring a programmer to define custom tool renderers. The key idea is to
leverage our ability to send client-side tools to the agent, thereby enabling
this capability across all agent frameworks supported by AG-UI.

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Challenges and Limitations

### Tool Description Length

OpenAI enforces a limit of 1024 characters for tool descriptions. Gemini and
Anthropic impose no such limit.

### Arguments JSON Schema Constraints

Classes, nesting, `$ref`, and `oneOf` are not reliably supported across LLM
providers.

### Context Window Considerations

Injecting a large UI description language into an agent may reduce its
performance. Agents dedicated solely to UI generation perform better than agents
combining UI generation with other tasks.

## Detailed Specification

### Two-Step Generation Process

```mermaid
flowchart TD
    A[Agent needs UI] --> B["Step 1: <b>What?</b> <br/> Agent calls generateUserInterface <br/>(description, data, output)"]
    B --> C["Step 2: <b>How?</b> <br/> Secondary generator builds actual UI <br/>(JSON Schema, React, etc.)"]
    C --> D[Rendered UI shown to user]
    D --> E[Validated user input returned to Agent]
```

### Step 1: What to Generate?

Inject a lightweight tool into the agent:

**Tool Definition:**

- **Name:** `generateUserInterface`
- **Arguments:**
  - **description**: A high-level description of the UI (e.g., _"A form for
    entering the user's address"_)
  - **data**: Arbitrary pre-populated data for the generated UI
  - **output**: A description or schema of the data the agent expects the user
    to submit back (fields, required/optional, types, constraints)

**Example Tool Call:**

```json
{
  "tool": "generateUserInterface",
  "arguments": {
    "description": "A form that collects a user's shipping address.",
    "data": {
      "firstName": "Ada",
      "lastName": "Lovelace",
      "city": "London"
    },
    "output": {
      "type": "object",
      "required": [
        "firstName",
        "lastName",
        "street",
        "city",
        "postalCode",
        "country"
      ],
      "properties": {
        "firstName": { "type": "string", "title": "First Name" },
        "lastName": { "type": "string", "title": "Last Name" },
        "street": { "type": "string", "title": "Street Address" },
        "city": { "type": "string", "title": "City" },
        "postalCode": { "type": "string", "title": "Postal Code" },
        "country": {
          "type": "string",
          "title": "Country",
          "enum": ["GB", "US", "DE", "AT"]
        }
      }
    }
  }
}
```

### Step 2: How to Generate?

Delegate UI generation to a secondary LLM or agent:

- The CopilotKit user stays in control: Can make their own generators, add
  custom libraries, include additional prompts etc.
- On tool invocation, the secondary model consumes `description`, `data`, and
  `output` to generate the user interface
- This model is focused solely on UI generation, ensuring maximum fidelity and
  consistency
- The generation method can be swapped as needed (e.g., JSON, HTML, or other
  renderable formats)
- The UI format description is not subject to structural or length constraints,
  allowing arbitrarily complex specifications

## Implementation Examples

### Example Output: UISchemaGenerator

```json
{
  "jsonSchema": {
    "title": "Shipping Address",
    "type": "object",
    "required": [
      "firstName",
      "lastName",
      "street",
      "city",
      "postalCode",
      "country"
    ],
    "properties": {
      "firstName": { "type": "string", "title": "First name" },
      "lastName": { "type": "string", "title": "Last name" },
      "street": { "type": "string", "title": "Street address" },
      "city": { "type": "string", "title": "City" },
      "postalCode": { "type": "string", "title": "Postal code" },
      "country": {
        "type": "string",
        "title": "Country",
        "enum": ["GB", "US", "DE", "AT"]
      }
    }
  },
  "uiSchema": {
    "type": "VerticalLayout",
    "elements": [
      {
        "type": "Group",
        "label": "Personal Information",
        "elements": [
          { "type": "Control", "scope": "#/properties/firstName" },
          { "type": "Control", "scope": "#/properties/lastName" }
        ]
      },
      {
        "type": "Group",
        "label": "Address",
        "elements": [
          { "type": "Control", "scope": "#/properties/street" },
          { "type": "Control", "scope": "#/properties/city" },
          { "type": "Control", "scope": "#/properties/postalCode" },
          { "type": "Control", "scope": "#/properties/country" }
        ]
      }
    ]
  },
  "initialData": {
    "firstName": "Ada",
    "lastName": "Lovelace",
    "city": "London",
    "country": "GB"
  }
}
```

### Example Output: ReactFormHookGenerator

```tsx
import React from "react"
import { useForm } from "react-hook-form"
import { z } from "zod"
import { zodResolver } from "@hookform/resolvers/zod"

// ----- Schema (contract) -----
const AddressSchema = z.object({
  firstName: z.string().min(1, "Required"),
  lastName: z.string().min(1, "Required"),
  street: z.string().min(1, "Required"),
  city: z.string().min(1, "Required"),
  postalCode: z.string().regex(/^[A-Za-z0-9\\-\\s]{3,10}$/, "3–10 chars"),
  country: z.enum(["GB", "US", "DE", "AT", "FR", "IT", "ES"]),
})
export type Address = z.infer<typeof AddressSchema>

type Props = {
  initialData?: Partial<Address>
  meta?: { title?: string; submitLabel?: string }
  respond: (data: Address) => void // <-- called on successful submit
}

const COUNTRIES: Address["country"][] = [
  "GB",
  "US",
  "DE",
  "AT",
  "FR",
  "IT",
  "ES",
]

export default function AddressForm({ initialData, meta, respond }: Props) {
  const {
    register,
    handleSubmit,
    formState: { errors },
  } = useForm<Address>({
    resolver: zodResolver(AddressSchema),
    defaultValues: {
      firstName: "",
      lastName: "",
      street: "",
      city: "",
      postalCode: "",
      country: "GB",
      ...initialData,
    },
  })

  const onSubmit = (data: Address) => {
    // Guaranteed to match AddressSchema
    respond(data)
  }

  return (
    <form onSubmit={handleSubmit(onSubmit)}>
      {meta?.title && <h2>{meta.title}</h2>}

      {/* Section: Personal Information */}
      <fieldset>
        <legend>Personal Information</legend>

        <div>
          <label>First name</label>
          <input {...register("firstName")} placeholder="Ada" autoFocus />
          {errors.firstName && <small>{errors.firstName.message}</small>}
        </div>

        <div>
          <label>Last name</label>
          <input {...register("lastName")} placeholder="Lovelace" />
          {errors.lastName && <small>{errors.lastName.message}</small>}
        </div>
      </fieldset>

      {/* Section: Address */}
      <fieldset>
        <legend>Address</legend>

        <div>
          <label>Street address</label>
          <input {...register("street")} />
          {errors.street && <small>{errors.street.message}</small>}
        </div>

        <div>
          <label>City</label>
          <input {...register("city")} />
          {errors.city && <small>{errors.city.message}</small>}
        </div>

        <div>
          <label>Postal code</label>
          <input {...register("postalCode")} />
          {errors.postalCode && <small>{errors.postalCode.message}</small>}
        </div>

        <div>
          <label>Country</label>
          <select {...register("country")}>
            {COUNTRIES.map((c) => (
              <option key={c} value={c}>
                {c}
              </option>
            ))}
          </select>
          {errors.country && <small>{errors.country.message}</small>}
        </div>
      </fieldset>

      <div>
        <button type="submit">{meta?.submitLabel ?? "Submit"}</button>
      </div>
    </form>
  )
}
```

## Implementation Considerations

### Client SDK Changes

TypeScript SDK additions:

- New `generateUserInterface` tool type
- UI generator registry for pluggable generators
- Validation layer for generated UI schemas
- Response handler for user-submitted data

Python SDK additions:

- Support for UI generation tool invocation
- Schema validation utilities
- Serialization for UI definitions

### Integration Impact

- All AG-UI integrations can leverage this capability without modification
- Frameworks emit standard tool calls; client handles UI generation
- Backward compatible with existing tool-based UI approaches

## Use Cases

### Dynamic Forms

Agents can generate forms on-the-fly based on conversation context without
pre-defined schemas.

### Data Visualization

Generate charts, graphs, or tables appropriate to the data being discussed.

### Interactive Workflows

Create multi-step wizards or guided processes tailored to user needs.

### Adaptive Interfaces

Generate different UI layouts based on user preferences or device capabilities.

## Testing Strategy

- Unit tests for tool injection and invocation
- Integration tests with multiple UI generators
- E2E tests demonstrating various UI types
- Performance benchmarks comparing single vs. two-step generation
- Cross-provider compatibility testing

## References

- [AG-UI Tools Documentation](/concepts/tools)
- [JSON Schema](https://json-schema.org/)
- [React Hook Form](https://react-hook-form.com/)
- [JSON Forms](https://jsonforms.io/)



================================================
FILE: docs/drafts/interrupts.mdx
================================================
---
title: Interrupt-Aware Run Lifecycle
description: Native support for human-in-the-loop pauses and interrupts
---

# Interrupt-Aware Run Lifecycle Proposal

## Summary

### Problem Statement

Agents often need to pause execution to request human approval, gather
additional input, or confirm potentially risky actions. Currently, there's no
standardized way to handle these interruptions across different agent
frameworks.

### Motivation

Support **human-in-the-loop pauses** (and related mechanisms) natively in AG-UI
and CopilotKit. This enables compatibility with various framework interrupts,
workflow suspend/resume, and other framework-specific pause mechanisms.

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Overview

This proposal introduces a standardized interrupt/resume pattern:

```mermaid
sequenceDiagram
  participant Agent
  participant Client as Client App

  Agent-->>Client: RUN_FINISHED { outcome: "interrupt", interrupt:{ id, reason, payload }}
  Client-->>Agent: RunAgentInput.resume { threadId, interruptId, payload }
  Agent-->>Client: RUN_FINISHED { outcome: "success", result }
```

## Detailed Specification

### Updates to RUN_FINISHED Event

```typescript
type RunFinishedOutcome = "success" | "interrupt"

type RunFinished = {
  type: "RUN_FINISHED"

  // ... existing fields

  outcome?: RunFinishedOutcome // optional for back-compat (see rules below)

  // Present when outcome === "success" (or when outcome omitted and interrupt is absent)
  result?: any

  // Present when outcome === "interrupt" (or when outcome omitted and interrupt is present)
  interrupt?: {
    id?: string // id can be set when needed
    reason?: string // e.g. "human_approval" | "upload_required" | "policy_hold"
    payload?: any // arbitrary JSON for UI (forms, proposals, diffs, etc.)
  }
}
```

When a run finishes with `outcome == "interrupt"`, the agent indicates that on
the next run, a value needs to be provided to continue.

### Updates to RunAgentInput

```typescript
type RunAgentInput = {
  // ... existing fields

  // NEW: resume channel for continuing a suspension
  resume?: {
    interruptId?: string // echo back if one was provided
    payload?: any // arbitrary JSON: approvals, edits, files-as-refs, etc.
  }
}
```

### Contract Rules

- Resume requests **must** use the same `threadId`
- When given in the `interrupt`, the `interruptId` must be provided via
  `RunAgentInput`
- Agents should handle missing or invalid resume payloads gracefully

## Implementation Examples

### Minimal Interrupt/Resume

**Agent sends interrupt:**

```json
{
  "type": "RUN_FINISHED",
  "threadId": "t1",
  "runId": "r1",
  "outcome": "interrupt",
  "interrupt": {
    "id": "int-abc123",
    "reason": "human_approval",
    "payload": {
      "proposal": {
        "tool": "sendEmail",
        "args": { "to": "a@b.com", "subject": "Hi", "body": "…" }
      }
    }
  }
}
```

**User responds:**

```json
{
  "threadId": "t1",
  "runId": "r2",
  "resume": {
    "interruptId": "int-abc123",
    "payload": { "approved": true }
  }
}
```

### Complex Approval Flow

**Agent requests approval with context:**

```json
{
  "type": "RUN_FINISHED",
  "threadId": "thread-456",
  "runId": "run-789",
  "outcome": "interrupt",
  "interrupt": {
    "id": "approval-001",
    "reason": "database_modification",
    "payload": {
      "action": "DELETE",
      "table": "users",
      "affectedRows": 42,
      "query": "DELETE FROM users WHERE last_login < '2023-01-01'",
      "rollbackPlan": "Restore from backup snapshot-2025-01-23",
      "riskLevel": "high"
    }
  }
}
```

**User approves with modifications:**

```json
{
  "threadId": "thread-456",
  "runId": "run-790",
  "resume": {
    "interruptId": "approval-001",
    "payload": {
      "approved": true,
      "modifications": {
        "batchSize": 10,
        "dryRun": true
      }
    }
  }
}
```

## Use Cases

### Human Approval

Agents pause before executing sensitive operations (sending emails, making
purchases, deleting data).

### Information Gathering

Agent requests additional context or files from the user mid-execution.

### Policy Enforcement

Automatic pauses triggered by organizational policies or compliance
requirements.

### Multi-Step Wizards

Complex workflows where each step requires user confirmation or input.

### Error Recovery

Agent pauses when encountering an error, allowing user to provide guidance.

## Implementation Considerations

### Client SDK Changes

TypeScript SDK:

- Extended `RunFinishedEvent` type with outcome and interrupt fields
- Updated `RunAgentInput` with resume field
- Helper methods for interrupt handling

Python SDK:

- Extended `RunFinishedEvent` class
- Updated `RunAgentInput` with resume support
- Interrupt state management utilities

### Framework Integration

**Planning Frameworks:**

- Map framework interrupts to AG-UI interrupt events
- Handle resume payloads in execution continuation

**Workflow Systems:**

- Convert workflow suspensions to AG-UI interrupts
- Resume workflow execution with provided payload

**Custom Frameworks:**

- Provide interrupt/resume adapter interface
- Documentation for integration patterns

### UI Considerations

- Standard components for common interrupt reasons
- Customizable interrupt UI based on payload
- Clear indication of pending interrupts
- History of interrupt/resume actions

## Testing Strategy

- Unit tests for interrupt/resume serialization
- Integration tests with multiple frameworks
- E2E tests demonstrating various interrupt scenarios
- State consistency tests across interrupt boundaries
- Performance tests for rapid interrupt/resume cycles

## References

- [AG-UI Events Documentation](/concepts/events)
- [AG-UI State Management](/concepts/state)



================================================
FILE: docs/drafts/meta-events.mdx
================================================
---
title: Meta Events
description: Annotations and signals independent of agent runs
---

# Meta Events Proposal

## Summary

### Problem Statement

Currently, AG-UI events are tightly coupled to agent runs. There's no
standardized way to attach user feedback, annotations, or external signals to
the event stream that are independent of the agent's execution lifecycle.

### Motivation

AG-UI is extended with **MetaEvents**, a new class of events that can occur at
any point in the event stream, independent of agent runs. MetaEvents provide a
way to attach annotations, signals, or feedback to a serialized stream. They may
originate from users, clients, or external systems rather than from agents.
Examples include reactions such as thumbs up/down on a message.

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Detailed Specification

### Overview

This proposal introduces:

- A new **MetaEvent** type for side-band annotations
- Events that can appear anywhere in the stream
- Support for user feedback, tags, and external annotations
- Extensible payload structure for application-specific data

## New Type: MetaEvent

```typescript
type MetaEvent = BaseEvent & {
  type: EventType.META
  /**
   * Application-defined type of the meta event.
   * Examples: "thumbs_up", "thumbs_down", "tag", "note"
   */
  metaType: string

  /**
   * Application-defined payload.
   * May reference other entities (e.g., messageId) or contain freeform data.
   */
  payload: Record<string, unknown>
}
```

### Key Characteristics

- **Run-independent**: MetaEvents are not tied to any specific run lifecycle
- **Position-flexible**: Can appear before, between, or after runs
- **Origin-diverse**: May come from users, clients, or external systems
- **Extensible**: Applications define their own metaType values and payload
  schemas

## Implementation Examples

### User Feedback

**Thumbs Up:**

```json
{
  "id": "evt_123",
  "ts": 1714063982000,
  "type": "META",
  "metaType": "thumbs_up",
  "payload": {
    "messageId": "msg_456",
    "userId": "user_789"
  }
}
```

**Thumbs Down with Reason:**

```json
{
  "id": "evt_124",
  "ts": 1714063985000,
  "type": "META",
  "metaType": "thumbs_down",
  "payload": {
    "messageId": "msg_456",
    "userId": "user_789",
    "reason": "inaccurate",
    "comment": "The calculation seems incorrect"
  }
}
```

### Annotations

**User Note:**

```json
{
  "id": "evt_789",
  "ts": 1714064001000,
  "type": "META",
  "metaType": "note",
  "payload": {
    "text": "Important question to revisit",
    "relatedRunId": "run_001",
    "author": "user_123"
  }
}
```

**Tag Assignment:**

```json
{
  "id": "evt_890",
  "ts": 1714064100000,
  "type": "META",
  "metaType": "tag",
  "payload": {
    "tags": ["important", "follow-up"],
    "threadId": "thread_001"
  }
}
```

### External System Events

**Analytics Event:**

```json
{
  "id": "evt_901",
  "ts": 1714064200000,
  "type": "META",
  "metaType": "analytics",
  "payload": {
    "event": "conversation_shared",
    "properties": {
      "shareMethod": "link",
      "recipientCount": 3
    }
  }
}
```

**Moderation Flag:**

```json
{
  "id": "evt_902",
  "ts": 1714064300000,
  "type": "META",
  "metaType": "moderation",
  "payload": {
    "action": "flag",
    "messageId": "msg_999",
    "category": "inappropriate_content",
    "confidence": 0.95
  }
}
```

## Common Meta Event Types

While applications can define their own types, these are commonly used:

| MetaType      | Description       | Typical Payload                    |
| ------------- | ----------------- | ---------------------------------- |
| `thumbs_up`   | Positive feedback | `{ messageId, userId }`            |
| `thumbs_down` | Negative feedback | `{ messageId, userId, reason? }`   |
| `note`        | User annotation   | `{ text, relatedId?, author }`     |
| `tag`         | Categorization    | `{ tags[], targetId }`             |
| `bookmark`    | Save for later    | `{ messageId, userId }`            |
| `copy`        | Content copied    | `{ messageId, content }`           |
| `share`       | Content shared    | `{ messageId, method }`            |
| `rating`      | Numeric rating    | `{ messageId, rating, maxRating }` |

## Use Cases

### User Feedback Collection

Capture user reactions to agent responses for quality improvement.

### Conversation Annotation

Allow users to add notes, tags, or bookmarks to important parts of
conversations.

### Analytics and Tracking

Record user interactions and behaviors without affecting agent execution.

### Content Moderation

Flag or mark content for review by external moderation systems.

### Collaborative Features

Enable multiple users to annotate or comment on shared conversations.

### Audit Trail

Create a complete record of all interactions, not just agent responses.

## Implementation Considerations

### Client SDK Changes

TypeScript SDK:

- New `MetaEvent` type in `@ag-ui/core`
- Helper functions for common meta event types
- MetaEvent filtering and querying utilities

Python SDK:

- `MetaEvent` class implementation
- Meta event builders for common types
- Event stream filtering capabilities

## Testing Strategy

- Unit tests for MetaEvent creation and validation
- Integration tests with mixed event streams
- Performance tests with high-volume meta events
- Security tests for payload validation

## References

- [AG-UI Events Documentation](/concepts/events)
- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
- [CQRS Pattern](https://martinfowler.com/bliki/CQRS.html)



================================================
FILE: docs/drafts/multimodal-messages.mdx
================================================
---
title: Multi-modal Messages
description:
  Support for multimodal input messages including text, images, audio, and files
---

# Multi-modal Messages Proposal

## Summary

### Problem Statement

Current AG-UI protocol only supports text-based user messages. As LLMs
increasingly support multimodal inputs (images, audio, files), the protocol
needs to evolve to handle these richer input types.

### Motivation

Evolve AG-UI to support **multimodal input messages** without breaking existing
apps. Inputs may include text, images, audio, and files.

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Detailed Specification

### Overview

Extend the `UserMessage` `content` property to be either a string or an array of
`InputContent`:

```typescript
interface TextInputContent {
  type: "text"
  text: string
}

interface BinaryInputContent {
  type: "binary"
  mimeType: string
  id?: string
  url?: string
  data?: string
  filename?: string
}

type InputContent = TextInputContent | BinaryInputContent

type UserMessage = {
  id: string
  role: "user"
  content: string | InputContent[]
  name?: string
}
```

### InputContent Types

#### TextInputContent

Represents text content within a multimodal message.

```typescript
interface TextInputContent {
  type: "text"
  text: string
}
```

| Property | Type     | Description                     |
| -------- | -------- | ------------------------------- |
| `type`   | `"text"` | Identifies this as text content |
| `text`   | `string` | The text content                |

#### BinaryInputContent

Represents binary content such as images, audio, or files.

```typescript
interface BinaryInputContent {
  type: "binary"
  mimeType: string
  id?: string
  url?: string
  data?: string
  filename?: string
}
```

| Property   | Type       | Description                                                |
| ---------- | ---------- | ---------------------------------------------------------- |
| `type`     | `"binary"` | Identifies this as binary content                          |
| `mimeType` | `string`   | MIME type of the content (e.g., "image/jpeg", "audio/wav") |
| `id`       | `string?`  | Optional identifier for content reference                  |
| `url`      | `string?`  | Optional URL to fetch the content                          |
| `data`     | `string?`  | Optional base64-encoded content                            |
| `filename` | `string?`  | Optional filename for the content                          |

### Content Delivery Methods

Binary content can be provided through multiple methods:

1. **Inline Data**: Base64-encoded in the `data` field
2. **URL Reference**: External URL in the `url` field
3. **ID Reference**: Reference to pre-uploaded content via `id` field

At least one of `data`, `url`, or `id` must be provided for binary content.

## Implementation Examples

### Simple Text Message (Backward Compatible)

```json
{
  "id": "msg-001",
  "role": "user",
  "content": "What's in this image?"
}
```

### Image with Text

```json
{
  "id": "msg-002",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": "What's in this image?"
    },
    {
      "type": "binary",
      "mimeType": "image/jpeg",
      "data": "base64-encoded-image-data..."
    }
  ]
}
```

### Multiple Images with Question

```json
{
  "id": "msg-003",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": "What are the differences between these images?"
    },
    {
      "type": "binary",
      "mimeType": "image/png",
      "url": "https://example.com/image1.png"
    },
    {
      "type": "binary",
      "mimeType": "image/png",
      "url": "https://example.com/image2.png"
    }
  ]
}
```

### Audio Transcription Request

```json
{
  "id": "msg-004",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": "Please transcribe this audio recording"
    },
    {
      "type": "binary",
      "mimeType": "audio/wav",
      "filename": "meeting-recording.wav",
      "id": "audio-upload-123"
    }
  ]
}
```

### Document Analysis

```json
{
  "id": "msg-005",
  "role": "user",
  "content": [
    {
      "type": "text",
      "text": "Summarize the key points from this PDF"
    },
    {
      "type": "binary",
      "mimeType": "application/pdf",
      "filename": "quarterly-report.pdf",
      "url": "https://example.com/reports/q4-2024.pdf"
    }
  ]
}
```

## Implementation Considerations

### Client SDK Changes

TypeScript SDK:

- Extended `UserMessage` type in `@ag-ui/core`
- Content validation utilities
- Helper methods for constructing multimodal messages
- Binary content encoding/decoding utilities

Python SDK:

- Extended `UserMessage` class
- Content type validation
- Multimodal message builders
- Binary content handling utilities

### Framework Integration

Frameworks need to:

- Parse multimodal user messages
- Forward content to LLM providers that support multimodal inputs
- Handle fallbacks for models that don't support certain content types
- Manage content upload/storage for binary data

## Use Cases

### Visual Question Answering

Users can upload images and ask questions about them.

### Document Processing

Upload PDFs, Word documents, or spreadsheets for analysis.

### Audio Transcription and Analysis

Process voice recordings, podcasts, or meeting audio.

### Multi-document Comparison

Compare multiple images, documents, or mixed media.

### Screenshot Analysis

Share screenshots for UI/UX feedback or debugging assistance.

## Testing Strategy

- Unit tests for content type validation
- Integration tests with multimodal LLMs
- Backward compatibility tests with string content
- Performance tests for large binary payloads
- Security tests for content validation and sanitization

## References

- [OpenAI Vision API](https://platform.openai.com/docs/guides/vision)
- [Anthropic Vision](https://docs.anthropic.com/en/docs/vision)
- [MIME Types](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types)
- [Data URLs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs)



================================================
FILE: docs/drafts/overview.mdx
================================================
---
title: Overview
description: Draft changes being considered for the AG-UI protocol
---

# Overview

This section contains draft changes being considered for the AG-UI protocol. These proposals are under internal review and may be modified or withdrawn before implementation.

## Current Drafts

<CardGroup cols={2}>
  <Card
    title="Activity Events"
    href="/drafts/activity-events"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    Represent ongoing agent progress between chat messages with fine-grained activity updates
  </Card>
  <Card
    title="Reasoning"
    href="/drafts/reasoning"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    Support for LLM reasoning visibility and continuity with encrypted content
  </Card>
  <Card
    title="Serialization"
    href="/drafts/serialization"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    Stream serialization for chat history restoration and event compaction
  </Card>
  <Card
    title="Multi-modal Messages"
    href="/drafts/multimodal-messages"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    Support for multimodal input messages including images, audio, and files
  </Card>
  <Card
    title="Interrupt-Aware Run Lifecycle"
    href="/drafts/interrupts"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    Native support for agent pauses requiring human approval or input
  </Card>
  <Card
    title="Generative User Interfaces"
    href="/drafts/generative-ui"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    AI-generated interfaces without requiring custom tool renderers
  </Card>
  <Card
    title="Meta Events"
    href="/drafts/meta-events"
    icon="file-lines"
    color="#3B82F6"
    iconType="light"
  >
    Annotations and signals independent of agent runs
  </Card>
</CardGroup>

## Status Definitions

- **Draft** - Initial proposal under consideration
- **Under Review** - Active development and testing
- **Accepted** - Approved for implementation
- **Implemented** - Merged into the main protocol specification
- **Withdrawn** - Proposal has been withdrawn or superseded


================================================
FILE: docs/drafts/reasoning.mdx
================================================
---
title: Reasoning
description: Support for LLM reasoning visibility and continuity
---

# Reasoning Proposal

## Summary

### Problem Statement

LLMs increasingly use chain-of-thought reasoning to improve response quality,
but there's no standardized way to surface reasoning signals while maintaining
privacy and state continuity across turns.

### Motivation

AG-UI should support **LLM reasoning** without breaking existing apps.

- **Reasoning visibility & continuity**: We must surface reasoning signals
  (e.g., **reasoning summaries**) and support **encrypted reasoning items** for
  state carry-over across turns—especially under `store:false`/ZDR—_without
  exposing raw chain-of-thought_.
- **Backwards compatibility**: Existing AG-UI clients must keep working
  unchanged. New capabilities should be non-breaking.

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Detailed Specification

### Overview

This proposal introduces:

- New events for reasoning lifecycle management
- A new `ReasoningMessage` type for message history
- Support for encrypted reasoning content

## New Reasoning Events

These events represent the lifecycle of reasoning messages in a conversation.

### ReasoningStartEvent

Marks the start of reasoning.

```typescript
type ReasoningStartEvent = BaseEvent & {
  type: EventType.REASONING_START
  messageId: string
  encryptedContent?: string
}
```

| Property           | Type      | Description                         |
| ------------------ | --------- | ----------------------------------- |
| `messageId`        | `string`  | Unique identifier of this reasoning |
| `encryptedContent` | `string?` | Optionally the encrypted content    |

### ReasoningMessageStartEvent

Signals the start of a reasoning message.

```typescript
type ReasoningMessageStartEvent = BaseEvent & {
  type: EventType.REASONING_MESSAGE_START
  messageId: string
  role: "assistant"
}
```

| Property    | Type          | Description                      |
| ----------- | ------------- | -------------------------------- |
| `messageId` | `string`      | Unique identifier of the message |
| `role`      | `"assistant"` | Role of the reasoning message    |

### ReasoningMessageContentEvent

Represents a chunk of content in a streaming reasoning message.

```typescript
type ReasoningMessageContentEvent = BaseEvent & {
  type: EventType.REASONING_MESSAGE_CONTENT
  messageId: string
  delta: string // Non-empty string
}
```

| Property    | Type     | Description                                    |
| ----------- | -------- | ---------------------------------------------- |
| `messageId` | `string` | Matches the ID from ReasoningMessageStartEvent |
| `delta`     | `string` | Reasoning content chunk (non-empty)            |

### ReasoningMessageEndEvent

Signals the end of a reasoning message.

```typescript
type ReasoningMessageEndEvent = BaseEvent & {
  type: EventType.REASONING_MESSAGE_END
  messageId: string
}
```

| Property    | Type     | Description                                    |
| ----------- | -------- | ---------------------------------------------- |
| `messageId` | `string` | Matches the ID from ReasoningMessageStartEvent |

### ReasoningMessageChunkEvent

A convenience event to auto start/close reasoning messages.

```typescript
type ReasoningMessageChunkEvent = BaseEvent & {
  type: EventType.REASONING_MESSAGE_CHUNK
  messageId?: string
  delta?: string
}
```

| Property    | Type      | Description                                |
| ----------- | --------- | ------------------------------------------ |
| `messageId` | `string?` | Message ID (first event must be non-empty) |
| `delta`     | `string?` | Reasoning content chunk                    |

### ReasoningEndEvent

Marks the end of reasoning.

```typescript
type ReasoningEndEvent = BaseEvent & {
  type: EventType.REASONING_END
  messageId: string
}
```

| Property    | Type     | Description                         |
| ----------- | -------- | ----------------------------------- |
| `messageId` | `string` | Unique identifier of this reasoning |

## New ReasoningMessage Type

```typescript
type ReasoningMessage = {
  id: string
  role: "reasoning"
  content: string[]
  encryptedContent?: string
}
```

## Removed Events

These events have never been publicly documented and will be removed:

- `THINKING_TEXT_MESSAGE_START`
- `THINKING_TEXT_MESSAGE_CONTENT`
- `THINKING_TEXT_MESSAGE_END`

## Implementation Considerations

### Client SDK Changes

TypeScript SDK:

- New event types in `@ag-ui/core`
- ReasoningMessage type in message unions
- Reasoning event handlers in subscriber
- Support for encrypted content handling

Python SDK:

- New event classes in `ag_ui.core.events`
- ReasoningMessage class
- Encryption/decryption utilities

### Privacy and Security

- **Encrypted reasoning**: Support for encrypted reasoning content that clients
  cannot decrypt
- **State continuity**: Encrypted reasoning items can be passed across turns
  without exposing content
- **ZDR compliance**: Works with `store:false` and zero data retention policies

### Backward Compatibility

- Clients not handling reasoning events continue to work
- Reasoning messages are optional in message history
- No changes required to existing integrations

## Use Cases

### Chain-of-Thought Visibility

Show users that the model is "thinking" without exposing internal reasoning.

### Reasoning Summaries

Provide high-level summaries of reasoning process for transparency.

### State Continuity

Maintain reasoning context across conversation turns without storing raw
content.

### Compliance and Privacy

Meet data retention requirements while preserving reasoning capabilities.

## Examples

### Basic Reasoning Flow

```typescript
// Agent emits reasoning start
{
  "type": "REASONING_START",
  "messageId": "reasoning-001",
  "encryptedContent": "encrypted-blob-xyz"
}

// Stream reasoning content (visible to client)
{
  "type": "REASONING_MESSAGE_START",
  "messageId": "msg-123",
  "role": "assistant"
}

{
  "type": "REASONING_MESSAGE_CONTENT",
  "messageId": "msg-123",
  "delta": "Let me think through this step by step..."
}

{
  "type": "REASONING_MESSAGE_END",
  "messageId": "msg-123"
}

// End reasoning
{
  "type": "REASONING_END",
  "messageId": "reasoning-001"
}
```

### Convenience Event Usage

```typescript
// Using chunk event for simpler implementation
{
  "type": "REASONING_MESSAGE_CHUNK",
  "messageId": "msg-456",
  "delta": "Analyzing the requirements..."
}

// Auto-closes on next non-reasoning event or empty chunk
{
  "type": "REASONING_MESSAGE_CHUNK",
  "messageId": "msg-456",
  "delta": ""
}
```

## Testing Strategy

- Unit tests for new event types
- Integration tests with reasoning-capable models
- Backward compatibility tests with existing clients
- Encryption/decryption roundtrip tests
- Performance tests for reasoning event streaming

## References

- [AG-UI Events Documentation](/concepts/events)
- [AG-UI Messages Documentation](/concepts/messages)



================================================
FILE: docs/drafts/serialization.mdx
================================================
---
title: Serialization
description:
  Stream serialization for chat history restoration and event compaction
---

# Serialization Proposal

## Summary

### Problem Statement

Currently, there's no standardized way to serialize and restore AG-UI event
streams, making it difficult to reload chat history, attach to running agents,
or implement branching/time travel features.

### Motivation

AG-UI adds **stream serialization** to reload chat history and attach to active
agents, enabling restoration and interaction with live state. A standardized
`compactEvents(events: BaseEvent[]): BaseEvent[]` reduces already-streamed
events and normalizes inputs. Additionally, `RunStartedEvent` gains
`parentRunId` for branching/time travel and an `input` field carrying the exact
`AgentInput` sent to the agent (which may omit messages already present in
history).

## Status

- **Status**: Draft
- **Author(s)**: Markus Ecker (mail@mme.xyz)

## Detailed Specification

### Overview

This proposal introduces three key capabilities:

1. **Stream serialization** - Serialize/deserialize event streams for
   persistence and restoration
2. **Event compaction** - Reduce event volume while preserving semantic meaning
3. **Run lineage tracking** - Enable branching and time travel with parent run
   references

### Git-like Branching Model

The `parentRunId` field enables a git-like branching structure where the entire
conversation history can be stored as a continuous serialized stream, with each
run forming nodes in a directed acyclic graph:

```mermaid
gitGraph
    commit id: "run1"
    commit id: "run2"
    branch alternative-path
    checkout alternative-path
    commit id: "run3 (parent run2)"
    commit id: "run4"
    checkout main
    commit id: "run5 (parent run2)"
    commit id: "run6"
    checkout alternative-path
```

**Key Benefits of This Append-Only Architecture:**

- **Immutable History**: Events are never modified or deleted, only appended
- **Serializable Stream**: The entire DAG can be stored as a single continuous
  stream of events
- **Multiple Branches**: Different conversation paths coexist in the same
  serialized log
- **Time Travel**: Navigate to any point in any branch without data loss
- **Efficient Storage**: Compaction reduces redundancy while preserving the full
  graph structure

## Proposed Changes

### Stream Serialization

Support serializing/deserializing the event stream so chat history can be
reloaded and sessions can attach to running agents/live state.

### Event Compaction

Introduce `compactEvents(events: BaseEvent[]): BaseEvent[]` to:

- Reduce the number of already-streamed events
- **Normalize** `RunStartedEvent.input` so it contains only the messages that
  were not already sent/recorded earlier in the thread

```typescript
// Event compaction API
declare function compactEvents(events: BaseEvent[]): BaseEvent[]
```

### Run Lineage and Input Capture

Extend `RunStartedEvent` with:

- `parentRunId?: string` to enable branching/time travel - similar to git
  commits, this creates an append-only log where each run points to its parent,
  forming a directed acyclic graph of conversation branches
- `input?: AgentInput` containing the agent input exactly as sent
  - `input.messages` **may omit** messages already present in history
  - `compactEvents` **normalizes** this field to a minimal form

## Updated Types

```typescript
type RunStartedEvent = BaseEvent & {
  type: EventType.RUN_STARTED
  threadId: string
  runId: string
  /**
   * Optional lineage pointer for branching/time travel.
   * If present, refers to a prior run within the same thread.
   * Creates a git-like append-only log where runs form a DAG (directed acyclic graph),
   * enabling conversation branching without mutating existing history.
   */
  parentRunId?: string
  /**
   * The exact AgentInput payload that was sent to the agent for this run.
   * May omit messages already present in history; compactEvents() will normalize.
   */
  input?: AgentInput
}
```

## Event Compaction Rules

The `compactEvents` function applies these transformations:

### Message Events

- Consecutive `TEXT_MESSAGE_CONTENT` events with same `messageId` → single event
  with concatenated content
- Complete message sequences (START + CONTENT + END) → single snapshot event
- Tool call sequences → compacted tool invocation records

### State Events

- Multiple `STATE_DELTA` events → single `STATE_SNAPSHOT` with final state
- Redundant state updates → removed if superseded by later snapshots

### Run Input Normalization

- Messages in `RunStartedEvent.input` that exist in prior events → removed
- Only new/incremental messages retained in normalized form

## Implementation Examples

### Basic Serialization

```typescript
// Serialize event stream
const events: BaseEvent[] = [...]; // Full event history
const serialized = JSON.stringify(events);

// Store to database, file, etc.
await storage.save(threadId, serialized);

// Later: deserialize and restore
const restored = JSON.parse(await storage.load(threadId));
const compacted = compactEvents(restored);
```

### Event Compaction Example

**Before compaction:**

```typescript
;[
  { type: "TEXT_MESSAGE_START", messageId: "msg1", role: "user" },
  { type: "TEXT_MESSAGE_CONTENT", messageId: "msg1", delta: "Hello " },
  { type: "TEXT_MESSAGE_CONTENT", messageId: "msg1", delta: "world" },
  { type: "TEXT_MESSAGE_END", messageId: "msg1" },
  { type: "STATE_DELTA", patch: { op: "add", path: "/foo", value: 1 } },
  { type: "STATE_DELTA", patch: { op: "replace", path: "/foo", value: 2 } },
]
```

**After compaction:**

```typescript
;[
  {
    type: "MESSAGES_SNAPSHOT",
    messages: [{ id: "msg1", role: "user", content: "Hello world" }],
  },
  {
    type: "STATE_SNAPSHOT",
    state: { foo: 2 },
  },
]
```

### Branching with Parent Run ID

The `parentRunId` field creates a git-like branching model where the event
stream becomes an immutable, append-only log. Each run can branch from any
previous run, creating alternative conversation paths without modifying the
original history.

```typescript
// Original run (like a git commit)
{
  type: "RUN_STARTED",
  threadId: "thread1",
  runId: "run1",
  input: { messages: ["Tell me about Paris"] }
}

// Branch from run1 (like creating a git branch from a specific commit)
{
  type: "RUN_STARTED",
  threadId: "thread1",
  runId: "run2",
  parentRunId: "run1",  // Points to parent, creating a new branch
  input: { messages: ["Actually, tell me about London instead"] }
}
```

This append-only structure ensures that:

- No existing events are ever modified or deleted
- Multiple branches can coexist in the same event stream
- You can always trace back the full lineage of any conversation branch
- Time travel and undo operations are possible without data loss

### Normalized Input Example

```typescript
// First run includes full message
{
  type: "RUN_STARTED",
  runId: "run1",
  input: {
    messages: [
      { id: "msg1", role: "user", content: "Hello" }
    ]
  }
}

// Second run omits already-present message
{
  type: "RUN_STARTED",
  runId: "run2",
  input: {
    messages: [
      { id: "msg2", role: "user", content: "How are you?" }
    ]
    // msg1 omitted as it's already in history
  }
}
```

## Use Cases

### Session Restoration

Reload a previous chat session with full history and state.

### Live Agent Attachment

Connect to an already-running agent and receive ongoing events.

### Branching Conversations

Create alternative conversation branches from any point in history.

### Time Travel Debugging

Navigate to any point in conversation history for debugging.

### Efficient Storage

Compact events before long-term storage to reduce size.

## Implementation Considerations

### Client SDK Changes

TypeScript SDK:

- `compactEvents` function implementation
- Serialization/deserialization utilities
- Branch management helpers
- Storage adapter interfaces

Python SDK:

- Event compaction algorithm
- Serialization utilities
- Parent run tracking
- Storage abstractions

### Storage Considerations

- Support for various storage backends (memory, database, file)
- Incremental storage for append-only events
- Compression support for serialized streams
- Indexing strategies for quick access

## Testing Strategy

- Unit tests for compaction algorithm
- Round-trip serialization tests
- Branch/merge scenario tests
- Performance benchmarks for large event streams
- Storage adapter integration tests

## References

- [Event Sourcing](https://martinfowler.com/eaaDev/EventSourcing.html)
- [AG-UI Events Documentation](/concepts/events)
- [AG-UI State Management](/concepts/state)
- [JSON Patch RFC 6902](https://tools.ietf.org/html/rfc6902)



================================================
FILE: docs/icons/custom-icons.tsx
================================================
import { FaReact } from "react-icons/fa";
import { HiOutlineServerStack } from "react-icons/hi2";
import { LuBrush, LuZap, LuGlobe } from "react-icons/lu";
import { SiLangchain } from "react-icons/si";
import { TbBrandTypescript } from "react-icons/tb";
import { FaPython } from "react-icons/fa";
import { SiCrewai } from "@icons-pack/react-simple-icons";
import { LuLayoutTemplate } from "react-icons/lu";
import { IconBaseProps } from "react-icons";
import { RocketIcon } from "lucide-react";

export const DirectToLLMIcon = (props: IconBaseProps) => (
  <svg
    width="24"
    height="24"
    viewBox="0 0 24 24"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    {...props}
  >
    <path
      d="M12 2L13.09 8.26L20 9L15 14L16.18 21L12 17.77L7.82 21L9 14L2 9L8.91 8.26L12 2Z"
      fill="currentColor"
    />
    <path
      d="M12 16L10.5 22L12 20.5L13.5 22L12 16Z"
      fill="currentColor"
      opacity="0.6"
    />
  </svg>
);

export const ADKIcon = ({ className = "", ...props }: IconBaseProps) => (
  <svg
    version="1.1"
    xmlns="http://www.w3.org/2000/svg"
    viewBox="0 0 512 512"
    width="512"
    height="512"
    className={className}
    {...props}>
    <g transform="scale(0.9)" transformOrigin="center">
      <rect width="512" height="512" rx="128" ry="128" fill="#000000" />
    </g>
    <g transform="scale(0.85)" transformOrigin="center">
      <path d="M0 0 C1.31304611 -0.0071553 2.62609222 -0.01431061 3.97892761 -0.02168274 C5.41728187 -0.02452244 6.85563638 -0.02723424 8.29399109 -0.02983093 C9.82245027 -0.03610391 11.35090795 -0.04275144 12.87936401 -0.04974365 C17.88434302 -0.07069886 22.88932201 -0.08114259 27.89433289 -0.09111023 C29.62590742 -0.0951619 31.35748179 -0.09927894 33.08905602 -0.10346031 C41.23265771 -0.12249846 49.37625046 -0.13672865 57.5198701 -0.14507228 C66.87604093 -0.1548198 76.23197362 -0.18107987 85.58806068 -0.22157317 C92.8470237 -0.25189579 100.10591912 -0.2665566 107.36494416 -0.26985329 C111.68704116 -0.27218669 116.00888341 -0.28092007 120.33091164 -0.30631447 C156.48887641 -0.50776358 186.91460747 5.52279404 213.96855164 31.39717102 C235.95430616 54.21378255 243.8744487 81.85805342 243.56230164 113.01435852 C242.82592359 140.93045009 229.0853173 166.40142904 209.24198914 185.52217102 C191.67223194 201.09852568 168.35185318 212.20479416 144.56210327 212.29434204 C143.24905716 212.30149734 141.93601105 212.30865265 140.58317566 212.31602478 C139.14482141 212.31886448 137.7064669 212.32157628 136.26811218 212.32417297 C134.739653 212.33044595 133.21119532 212.33709348 131.68273926 212.34408569 C126.67776025 212.3650409 121.67278127 212.37548463 116.66777039 212.38545227 C114.93619586 212.38950394 113.20462148 212.39362098 111.47304726 212.39780235 C103.32944556 212.4168405 95.18585281 212.43107069 87.04223317 212.43941432 C77.68606234 212.44916184 68.33012965 212.47542191 58.97404259 212.51591522 C51.71507957 212.54623783 44.45618416 212.56089864 37.19715911 212.56419533 C32.87506212 212.56652873 28.55321986 212.57526211 24.23119164 212.60065651 C-11.92677313 212.80210562 -42.3525042 206.771548 -69.40644836 180.89717102 C-91.39220289 158.08055949 -99.31234543 130.43628862 -99.00019836 99.27998352 C-98.26382032 71.36389195 -84.52321403 45.892913 -64.67988586 26.77217102 C-47.11012867 11.19581636 -23.78974991 0.08954788 0 0 Z M-46.71894836 56.14717102 C-47.38668274 56.79299133 -48.05441711 57.43881165 -48.74238586 58.10420227 C-61.67195913 71.53106682 -66.89202154 90.95525774 -66.71894836 109.14717102 C-65.29530616 129.51620557 -57.05214152 145.96044845 -42.71894836 160.14717102 C-42.07312805 160.8149054 -41.42730774 161.48263977 -40.76191711 162.17060852 C-24.98727636 177.36100332 -3.35172872 180.30022142 17.56498718 180.29243469 C19.52295479 180.29747261 19.52295479 180.29747261 21.52047729 180.3026123 C25.07862687 180.31139119 28.63675235 180.31378787 32.19491172 180.31442809 C34.42546379 180.31514223 36.65600987 180.31728344 38.88656044 180.31992531 C46.68985503 180.32915951 54.49313262 180.33326274 62.2964325 180.33247375 C69.53487138 180.33187394 76.77323552 180.34241182 84.01165551 180.35821742 C90.25489513 180.37135716 96.49811051 180.37665495 102.74136382 180.37601835 C106.45736026 180.37576518 110.17329021 180.37851461 113.88927269 180.3891964 C118.04294698 180.40081177 122.19645719 180.39609147 126.35014343 180.39009094 C127.55737061 180.39571045 128.76459778 180.40132996 130.00840759 180.40711975 C152.39194774 180.32551845 172.41914732 174.77307242 188.63261414 158.82295227 C189.50659851 157.93994446 190.38058289 157.05693665 191.28105164 156.14717102 C192.2826532 155.17844055 192.2826532 155.17844055 193.30448914 154.19013977 C206.23406241 140.76327522 211.45412481 121.3390843 211.28105164 103.14717102 C209.85740944 82.77813647 201.61424479 66.33389359 187.28105164 52.14717102 C186.63523132 51.47943665 185.98941101 50.81170227 185.32402039 50.12373352 C169.54937963 34.93333872 147.91383199 31.99412062 126.99711609 32.00190735 C125.69180435 31.99854874 124.38649261 31.99519012 123.04162598 31.99172974 C119.4834764 31.98295085 115.92535092 31.98055418 112.36719155 31.97991395 C110.13663948 31.97919981 107.9060934 31.9770586 105.67554283 31.97441673 C97.87224824 31.96518253 90.06897065 31.9610793 82.26567078 31.96186829 C75.02723189 31.9624681 67.78886776 31.95193022 60.55044776 31.93612462 C54.30720814 31.92298488 48.06399276 31.91768709 41.82073945 31.9183237 C38.10474301 31.91857686 34.38881306 31.91582744 30.67283058 31.90514565 C26.51915629 31.89353027 22.36564608 31.89825057 18.21195984 31.9042511 C17.00473267 31.89863159 15.79750549 31.89301208 14.55369568 31.88722229 C-9.74912493 31.97582051 -29.57176548 38.82295232 -46.71894836 56.14717102 Z " fill="#4285F3" transform="translate(183.7189483642578,64.85282897949219)"/>
      <path d="M0 0 C1.0116774 -0.0071553 2.0233548 -0.01431061 3.06568909 -0.02168274 C4.18036057 -0.02437164 5.29503204 -0.02706055 6.44348145 -0.02983093 C7.61454941 -0.03640213 8.78561737 -0.04297333 9.99217224 -0.04974365 C13.88804468 -0.06953217 17.78390359 -0.08116344 21.67980957 -0.09111023 C23.02597575 -0.09515966 24.37214173 -0.09927664 25.7183075 -0.10346031 C32.05722186 -0.12253533 38.39612456 -0.13674947 44.73506212 -0.14507228 C52.0141461 -0.15478951 59.29292149 -0.18095284 66.57189703 -0.22157317 C72.21718494 -0.25197492 77.86238582 -0.2665645 83.50775385 -0.26985329 C86.86869574 -0.27218089 90.22905077 -0.28287636 93.58995056 -0.30631447 C127.52447927 -0.52804368 155.90682785 7.49509286 180.89855957 31.39717102 C202.8843141 54.21378255 210.80445664 81.85805342 210.49230957 113.01435852 C209.75593153 140.93045009 196.01532523 166.40142904 176.17199707 185.52217102 C157.21503455 202.3283436 133.22869857 212.44791206 107.77355957 212.20967102 C106.85123535 212.2051593 105.92891113 212.20064758 104.9786377 212.19599915 C102.72270909 212.1843104 100.4669199 212.16792557 98.21105957 212.14717102 C98.80660645 211.8661554 99.40215332 211.58513977 100.01574707 211.29560852 C104.55080571 208.92317571 108.31448565 205.9588493 110.21105957 201.14717102 C110.91963049 196.1542178 110.76258648 192.23052744 108.46105957 187.70967102 C105.35448295 184.17162543 102.39148647 182.20254758 98.21105957 180.14717102 C98.84495605 180.07723938 99.47885254 180.00730774 100.13195801 179.93525696 C117.08170288 178.25720486 117.08170288 178.25720486 133.21105957 173.14717102 C134.26035645 172.67666321 135.30965332 172.2061554 136.39074707 171.72138977 C155.03767156 162.52955288 167.5962346 146.47746783 174.27746582 127.04560852 C180.02943998 106.42742096 176.68231485 85.87299508 166.32043457 67.38545227 C155.2959017 50.46075274 138.75429348 39.2147683 119.18762207 34.65498352 C111.44830405 33.33462743 103.84588907 33.00120148 96.0032959 33.00532532 C94.91921951 33.00185089 93.83514313 32.99837646 92.71821594 32.99479675 C90.37912819 32.98748064 88.04003368 32.98211334 85.70093727 32.97850609 C81.99776791 32.9713016 78.29472806 32.95560844 74.59159851 32.93716431 C64.06803408 32.88485903 53.54455821 32.83667226 43.02087402 32.82124329 C36.57184779 32.81117073 30.12315547 32.78187562 23.67426109 32.73992348 C21.22029836 32.72761024 18.76628853 32.7224928 16.31229591 32.72472191 C12.88471273 32.72707104 9.45809275 32.70494028 6.03063965 32.67720032 C5.01906799 32.68380173 4.00749634 32.69040314 2.965271 32.69720459 C-2.80021041 32.62054081 -6.24711946 32.06102164 -10.78894043 28.14717102 C-15.09121633 23.37978421 -16.15176546 19.70969807 -16.07019043 13.42842102 C-15.48074654 8.64737616 -12.64073246 5.89755924 -9.16394043 2.83467102 C-5.79446793 0.44057214 -4.08456692 0.01979461 0 0 Z " fill="#34A753" transform="translate(216.7889404296875,64.85282897949219)"/>
      <path d="M0 0 C0.969944 -0.0099852 1.939888 -0.0199704 2.93922424 -0.03025818 C4.98230751 -0.04538665 7.02546429 -0.05248561 9.06860352 -0.05200195 C12.17914707 -0.05856787 15.28650395 -0.11311746 18.39648438 -0.16992188 C20.38931209 -0.17872467 22.38215484 -0.1846784 24.375 -0.1875 C25.2960704 -0.20905655 26.21714081 -0.2306131 27.16612244 -0.25282288 C33.11450504 -0.19027226 36.5357215 1.08734462 41.17347717 4.8250885 C45.27116401 9.1778744 45.29139256 13.69858971 45.20703125 19.44921875 C44.50380333 24.18994493 42.28995027 27.3409311 38.75390625 30.50390625 C28.00422925 35.87874475 14.7724105 32.50390625 2.75390625 32.50390625 C2.75390625 60.22390625 2.75390625 87.94390625 2.75390625 116.50390625 C13.31390625 116.50390625 23.87390625 116.50390625 34.75390625 116.50390625 C42.51252694 121.67632004 42.51252694 121.67632004 44.75390625 126.50390625 C45.76706246 132.70512099 45.75733985 137.90839454 42.00390625 143.12890625 C39.37436439 146.27638817 36.77704938 148.24253595 32.63180542 148.77806091 C31.87142975 148.78870071 31.11105408 148.79934052 30.32763672 148.81030273 C29.02510452 148.83428383 29.02510452 148.83428383 27.69625854 148.85874939 C26.76395416 148.86411209 25.83164978 148.86947479 24.87109375 148.875 C23.41692551 148.88854271 23.41692551 148.88854271 21.93338013 148.90235901 C19.88074833 148.91686062 17.82807032 148.92574802 15.77539062 148.92944336 C12.66064566 148.94128558 9.54791756 148.99042637 6.43359375 149.04101562 C4.43360335 149.05048689 2.43360086 149.05771856 0.43359375 149.0625 C-0.94664474 149.09179848 -0.94664474 149.09179848 -2.35476685 149.12168884 C-9.92572472 149.06982826 -16.49482381 146.93193879 -22.16726685 141.74827576 C-28.65531841 134.81932604 -29.69318322 127.92658301 -29.66601562 118.77026367 C-29.67448517 117.71241165 -29.68295471 116.65455963 -29.69168091 115.56465149 C-29.7150144 112.07943585 -29.7160738 108.59466273 -29.71484375 105.109375 C-29.72194814 102.67710698 -29.72964755 100.24484064 -29.73791504 97.81257629 C-29.75135198 92.71769552 -29.75293235 87.62296969 -29.74707031 82.52807617 C-29.74117899 76.01481781 -29.77174719 69.50230607 -29.81218719 62.98919201 C-29.83810035 57.96613087 -29.8409382 52.94324854 -29.83729553 47.92012978 C-29.83898377 45.51966795 -29.84859751 43.11919761 -29.86643982 40.7188015 C-29.88869701 37.3539445 -29.87889134 33.99058647 -29.86132812 30.62573242 C-29.87459137 29.64410126 -29.88785461 28.66247009 -29.90151978 27.65109253 C-29.80889397 19.9725961 -27.76071089 13.34695187 -22.49068451 7.58446026 C-15.75554207 1.27156305 -8.92472752 0.03227723 0 0 Z " fill="#FBBC04" transform="translate(114.24609375,298.49609375)"/>
      <path d="M0 0 C1.00804687 -0.02835937 2.01609375 -0.05671875 3.0546875 -0.0859375 C9.43320633 0.87165184 14.10205612 5.93302187 18.8125 10.0625 C20.05383751 11.13900176 21.29603371 12.21451409 22.5390625 13.2890625 C23.14782227 13.81532227 23.75658203 14.34158203 24.38378906 14.88378906 C27.65387491 17.68436174 31.00567465 20.38382978 34.34765625 23.09765625 C38.02975925 26.11687714 41.65562893 29.20001945 45.28271484 32.28491211 C48.75762479 35.23471308 52.26962023 38.13171652 55.8125 41 C59.4625647 43.99176857 63.10593378 46.98892096 66.6875 50.0625 C67.49316406 50.74699219 68.29882812 51.43148437 69.12890625 52.13671875 C72.25531681 55.64245897 72.99009286 59.16083572 73.5 63.75 C72.23112403 76.01580108 61.6567399 82.50975572 52.75 89.8125 C51.84507812 90.54339844 50.94015625 91.27429688 50.0078125 92.02734375 C46.84483953 94.60315236 43.73182328 97.23205222 40.625 99.875 C35.7854038 103.98801755 30.89546343 108.03129034 25.96484375 112.03515625 C23.85439681 113.77402519 21.76654861 115.52850079 19.69140625 117.30859375 C18.81742187 118.05689453 18.81742187 118.05689453 17.92578125 118.8203125 C16.79381663 119.79202146 15.66474961 120.76711942 14.5390625 121.74609375 C8.54117063 126.89141745 4.89439365 127.84040182 -2.9609375 127.6875 C-8.26240101 127.11897844 -10.71472495 124.59634216 -14.25 120.875 C-16.66962394 115.66350228 -16.82157547 111.01718605 -15.875 105.375 C-13.14263444 99.03635439 -7.2128306 94.95475519 -1.93359375 90.79296875 C1.31680523 88.22336854 4.47447973 85.56496979 7.625 82.875 C12.58417214 78.65340994 17.60608304 74.51974134 22.6875 70.4453125 C25.31218374 68.21601381 27.72108729 65.83901053 30.125 63.375 C22.79394251 57.04995624 15.43855789 50.77249376 7.921875 44.66796875 C3.62741415 41.14723059 -0.60036933 37.54886866 -4.83203125 33.953125 C-6.38015925 32.64148896 -7.93057745 31.33124859 -9.52490234 30.07617188 C-13.59763742 26.84364661 -15.51766108 24.78016584 -16.28125 19.640625 C-16.48744609 13.00798425 -15.87605463 9.04292903 -11.578125 3.8984375 C-7.91857027 0.62498258 -4.86609762 0.06190964 0 0 Z " fill="#EA4335" transform="translate(353.875,308.625)"/>
      <path d="M0 0 C4.8143755 4.57365673 6.75156236 7.6837462 7 14.375 C7.05442907 19.60019083 5.74920258 22.29348937 2.5 26.375 C0.41477163 28.44352984 -1.79612751 30.32113007 -4.0625 32.1875 C-4.68310303 32.70884521 -5.30370605 33.23019043 -5.94311523 33.76733398 C-10.4931635 37.5786204 -15.09008477 41.33381521 -19.6953125 45.078125 C-22.96474094 47.75559564 -26.20638031 50.46400467 -29.4375 53.1875 C-29.98156494 53.64390869 -30.52562988 54.10031738 -31.08618164 54.57055664 C-34.02478096 57.0547381 -36.82445279 59.60919337 -39.5 62.375 C-32.16894251 68.70004376 -24.81355789 74.97750624 -17.296875 81.08203125 C-13.00241415 84.60276941 -8.77463067 88.20113134 -4.54296875 91.796875 C-2.99484075 93.10851104 -1.44442255 94.41875141 0.14990234 95.67382812 C4.25387546 98.93114699 6.21122997 100.96410599 6.8359375 106.1796875 C6.96940663 116.67036144 6.96940663 116.67036144 2.5 121.375 C-1.14862143 124.84119036 -4.2835837 125.75704768 -9.1875 126.125 C-16.77761867 125.81729249 -20.9482353 122.2355227 -26.5 117.375 C-27.7114746 116.33764761 -28.92375896 115.30124039 -30.13671875 114.265625 C-32.72788532 112.04071271 -35.3021929 109.79798436 -37.8671875 107.54296875 C-41.75272303 104.13629156 -45.74276272 100.86973525 -49.7578125 97.6171875 C-53.42820794 94.61603796 -57.03852636 91.54658493 -60.64697266 88.47143555 C-64.21555198 85.43755671 -67.84162128 82.48821954 -71.5 79.5625 C-80.20927177 72.45289039 -80.20927177 72.45289039 -82.3125 67.4375 C-82.374375 66.756875 -82.43625 66.07625 -82.5 65.375 C-82.6546875 63.76625 -82.6546875 63.76625 -82.8125 62.125 C-82.06556266 53.16175197 -77.08290815 48.60490099 -70.48828125 42.875 C-66.808321 39.79634044 -63.11536392 36.73740932 -59.3828125 33.72265625 C-56.21983953 31.14684764 -53.10682328 28.51794778 -50 25.875 C-45.1604038 21.76198245 -40.27046343 17.71870966 -35.33984375 13.71484375 C-33.22939681 11.97597481 -31.14154861 10.22149921 -29.06640625 8.44140625 C-28.48375 7.94253906 -27.90109375 7.44367188 -27.30078125 6.9296875 C-26.16881663 5.95797854 -25.03974961 4.98288058 -23.9140625 4.00390625 C-16.77309541 -2.12201066 -8.93231938 -4.14714828 0 0 Z " fill="#EA4335" transform="translate(263.5,310.625)"/>
      <path d="M0 0 C4.58944252 2.59067597 8.07973488 5.95843049 9.58984375 11.1171875 C10.43895989 16.98821911 10.4991943 22.35248537 7.52734375 27.6171875 C4.02449419 32.28765359 0.50237103 34.69595422 -5.24609375 35.52734375 C-11.27485226 35.82346665 -15.88471772 35.3237664 -20.78515625 31.6484375 C-25.50423874 27.20160977 -26.66198643 23.50460631 -26.97265625 17.1796875 C-26.75311095 11.33246435 -25.4377323 7.39134984 -21.41015625 3.1171875 C-15.27205905 -1.89350409 -7.4975257 -2.74625739 0 0 Z " fill="#4285F4" transform="translate(327.41015625,153.8828125)"/>
      <path d="M0 0 C4.58944252 2.59067597 8.07973488 5.95843049 9.58984375 11.1171875 C10.43895989 16.98821911 10.4991943 22.35248537 7.52734375 27.6171875 C4.02449419 32.28765359 0.50237103 34.69595422 -5.24609375 35.52734375 C-11.27485226 35.82346665 -15.88471772 35.3237664 -20.78515625 31.6484375 C-25.50423874 27.20160977 -26.66198643 23.50460631 -26.97265625 17.1796875 C-26.75311095 11.33246435 -25.4377323 7.39134984 -21.41015625 3.1171875 C-15.27205905 -1.89350409 -7.4975257 -2.74625739 0 0 Z " fill="#4285F4" transform="translate(203.41015625,153.8828125)"/>
    </g>
  </svg>
);

export const AG2Icon = ({ className = "", ...props }: IconBaseProps) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    fill="none"
    viewBox="0 0 90 50"
    className={className}
    {...props}
  >
    <path
      fill="currentColor"
      d="M69.285 0h-3.232v3.232h3.232V0Zm-3.232 16.095h-3.21v6.442h3.21v-6.442Zm0-12.863h-3.21v3.21h3.21v-3.21Zm-3.21 9.652h-3.21v3.21h3.21v-3.21Zm0-6.442h-3.21v3.232h3.21V6.442Zm-3.211 3.232H53.19v3.21h6.442v-3.21ZM53.19 6.442H37.095v3.232H53.19V6.442Zm6.442 19.305v-6.42h-3.231v-3.232H33.885v3.232h-3.232v6.42h28.98Zm-9.652-6.42h3.21v3.21h-3.21v-3.21Zm-12.885 0h3.21v3.21h-3.21v-3.21Zm0-9.653h-6.442v3.21h6.442v-3.21Zm-6.442 3.21h-3.21v3.21h3.21v-3.21Zm0-6.442h-3.21v3.232h3.21V6.442Zm-3.211 9.653h-3.21v6.442h3.21v-6.442Zm0-12.863h-3.21v3.21h3.21v-3.21ZM24.232 0H21v3.232h3.232V0Z"
    />
    <path
      fill="currentColor"
      d="M65.867 37.748V34.33H55.615v-3.418h10.252v3.418h3.418v3.417h-3.418Zm-6.834 3.417v-3.417h6.834v3.417h-6.834ZM55.615 48v-6.835h3.418v3.418h10.252V48h-13.67Zm-13.89-13.67v-3.417h10.252v3.418H41.725Zm-3.417 10.253V34.33h3.417v10.252h-3.417Zm10.252 0v-3.418h-3.417v-3.417h6.834v6.835H48.56ZM41.725 48v-3.417h6.835V48h-6.835ZM21 48V34.33h3.417v-3.417h6.835v3.418h3.418V48h-3.418v-6.835h-6.835V48H21Zm3.417-10.252h6.835v-3.28h-6.835v3.28Z"
    />
  </svg>
);

export const MastraIcon = ({ className = "", ...props }: IconBaseProps) => (
  <svg
    viewBox="0 0 34 34"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    className={className}
    {...props}
  >
    <circle
      cx="16.6532"
      cy="16.9999"
      r="14.0966"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
    <ellipse
      cx="16.6533"
      cy="17"
      rx="14.0966"
      ry="9.45478"
      transform="rotate(45 16.6533 17)"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
    <path
      d="M10.8984 17.0508H22.483"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
    <path
      d="M13.748 19.9932L19.6339 14.1074"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
  </svg>
);

export const AgnoIcon = ({ className = "", ...props }: IconBaseProps) => (
  <svg
    viewBox="0 0 195 75"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    className={className}
    {...props}
  >
    <path
      d="M44.9802 0.200195H16.5703V10.1702H38.0442L56.3442 58.8102H68.1658L44.9802 0.200195Z"
      fill="currentColor"
    />
    <path d="M29.59 48.8403H0.5V58.8103H29.59V48.8403Z" fill="currentColor" />
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M106.781 57.3271L106.748 57.2946C106.538 62.7046 104.862 66.8535 101.651 69.6754C99.5756 71.5114 96.5827 72.8283 93.2745 73.5576C89.9605 74.288 86.2923 74.4374 82.8361 73.9058C75.9469 72.8462 69.7197 69.0281 69.1124 61.5207L69.0687 60.9803H78.6597L78.725 61.4043C79.2382 64.7375 82.2366 66.4244 85.7803 66.7766C87.5364 66.9511 89.3766 66.7868 91.0038 66.3457C92.6378 65.9028 94.0152 65.1926 94.8845 64.3096L94.8981 64.2958L94.9127 64.2831C95.4723 63.7965 95.9123 63.0704 96.2494 62.1504C96.5856 61.2328 96.8086 60.152 96.9526 58.9907C97.2411 56.6652 97.2058 54.0891 97.1761 51.9777L97.176 51.9732L97.1725 51.7158C94.7704 55.4822 91.6364 57.5831 88.3259 58.402C84.6598 59.3088 80.8264 58.6317 77.5991 56.9885C73.8994 55.2095 71.4248 51.9689 69.8863 48.249C68.3481 44.5298 67.7308 40.2996 67.7608 36.4697C67.7213 29.0048 71.2243 20.2031 78.2871 16.8883C81.4568 15.376 85.3623 14.7771 88.9867 15.6312C92.1761 16.3827 95.1358 18.258 97.1608 21.5917V16.3104H106.781V57.3271ZM94.6816 46.608C92.9795 49.2165 90.4738 50.8999 87.1583 50.8504L87.1487 50.8504C83.8825 50.8645 81.4259 49.1844 79.7641 46.5957C78.0929 43.9925 77.2408 40.4841 77.2408 36.9466C77.2408 33.4091 78.0929 29.9014 79.764 27.2995C81.4258 24.7121 83.8822 23.0339 87.1483 23.0504L87.1567 23.0504L87.1652 23.0502C90.5349 22.9535 93.0495 24.6029 94.7414 27.1812C96.4443 29.7765 97.3024 33.306 97.2896 36.8736C97.2767 40.4407 96.3932 43.9852 94.6816 46.608Z"
      fill="currentColor"
    />
    <path
      d="M122.38 21.817V16.29H113.24V58.84H122.83V32.77C122.83 31.4259 123.051 30.1528 123.481 28.9482C123.912 27.743 124.51 26.7201 125.264 25.8723L125.272 25.8624C126.034 24.9601 126.941 24.2776 128.028 23.8091L128.036 23.8056L128.044 23.8018C129.13 23.2869 130.356 23.02 131.75 23.02C134.224 23.02 135.948 23.6948 137.019 24.9541L137.027 24.9623C138.12 26.1911 138.761 28.2555 138.86 31.2684V58.84H148.45V29C148.45 24.4884 147.192 21.012 144.594 18.678C142.019 16.364 138.517 15.23 134.16 15.23C131.517 15.23 129.089 15.8709 126.898 17.1784C125.084 18.2196 123.584 20.0156 122.38 21.817Z"
      fill="currentColor"
    />
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M189.43 21.9877C186.048 17.7695 180.97 15.0322 174.236 15.2401C167.503 15.0322 162.425 17.7695 159.043 21.9877C155.669 26.1945 153.999 31.8497 154 37.4791C154.001 43.1085 155.672 48.7631 159.045 52.9686C162.428 57.1855 167.505 59.9209 174.236 59.7106C180.967 59.9209 186.044 57.1855 189.427 52.9686C192.801 48.7631 194.472 43.1085 194.473 37.4791C194.473 31.8497 192.803 26.1945 189.43 21.9877ZM182.196 47.4833C180.409 50.1702 177.762 51.9245 174.238 51.9103H174.234C170.71 51.9245 168.064 50.1702 166.277 47.4833C164.481 44.7816 163.564 41.1431 163.561 37.4762C163.559 33.8093 164.471 30.1718 166.266 27.4716C168.051 24.7867 170.699 23.0337 174.234 23.0503L174.239 23.0503C177.773 23.0337 180.422 24.7867 182.207 27.4716C184.002 30.1718 184.914 33.8093 184.911 37.4762C184.909 41.1431 183.992 44.7816 182.196 47.4833Z"
      fill="currentColor"
    />
  </svg>
);

export const AgnoIconBlack = (props: IconBaseProps, className?: string) => (
  <svg
    width="195"
    height="75"
    viewBox="0 0 195 75"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    {...props}
  >
    <path
      d="M44.9802 0.200195H16.5703V10.1702H38.0442L56.3442 58.8102H68.1658L44.9802 0.200195Z"
      fill="#18181B"
    />
    <path d="M29.59 48.8403H0.5V58.8103H29.59V48.8403Z" fill="#18181B" />
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M106.781 57.3271L106.748 57.2946C106.538 62.7046 104.862 66.8535 101.651 69.6754C99.5756 71.5114 96.5827 72.8283 93.2745 73.5576C89.9605 74.288 86.2923 74.4374 82.8361 73.9058C75.9469 72.8462 69.7197 69.0281 69.1124 61.5207L69.0687 60.9803H78.6597L78.725 61.4043C79.2382 64.7375 82.2366 66.4244 85.7803 66.7766C87.5364 66.9511 89.3766 66.7868 91.0038 66.3457C92.6378 65.9028 94.0152 65.1926 94.8845 64.3096L94.8981 64.2958L94.9127 64.2831C95.4723 63.7965 95.9123 63.0704 96.2494 62.1504C96.5856 61.2328 96.8086 60.152 96.9526 58.9907C97.2411 56.6652 97.2058 54.0891 97.1761 51.9777L97.176 51.9732L97.1725 51.7158C94.7704 55.4822 91.6364 57.5831 88.3259 58.402C84.6598 59.3088 80.8264 58.6317 77.5991 56.9885C73.8994 55.2095 71.4248 51.9689 69.8863 48.249C68.3481 44.5298 67.7308 40.2996 67.7608 36.4697C67.7213 29.0048 71.2243 20.2031 78.2871 16.8883C81.4568 15.376 85.3623 14.7771 88.9867 15.6312C92.1761 16.3827 95.1358 18.258 97.1608 21.5917V16.3104H106.781V57.3271ZM94.6816 46.608C92.9795 49.2165 90.4738 50.8999 87.1583 50.8504L87.1487 50.8504C83.8825 50.8645 81.4259 49.1844 79.7641 46.5957C78.0929 43.9925 77.2408 40.4841 77.2408 36.9466C77.2408 33.4091 78.0929 29.9014 79.764 27.2995C81.4258 24.7121 83.8822 23.0339 87.1483 23.0504L87.1567 23.0504L87.1652 23.0502C90.5349 22.9535 93.0495 24.6029 94.7414 27.1812C96.4443 29.7765 97.3024 33.306 97.2896 36.8736C97.2767 40.4407 96.3932 43.9852 94.6816 46.608Z"
      fill="#18181B"
    />
    <path
      d="M122.38 21.817V16.29H113.24V58.84H122.83V32.77C122.83 31.4259 123.051 30.1528 123.481 28.9482C123.912 27.743 124.51 26.7201 125.264 25.8723L125.272 25.8624C126.034 24.9601 126.941 24.2776 128.028 23.8091L128.036 23.8056L128.044 23.8018C129.13 23.2869 130.356 23.02 131.75 23.02C134.224 23.02 135.948 23.6948 137.019 24.9541L137.027 24.9623C138.12 26.1911 138.761 28.2555 138.86 31.2684V58.84H148.45V29C148.45 24.4884 147.192 21.012 144.594 18.678C142.019 16.364 138.517 15.23 134.16 15.23C131.517 15.23 129.089 15.8709 126.898 17.1784C125.084 18.2196 123.584 20.0156 122.38 21.817Z"
      fill="#18181B"
    />
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M189.43 21.9877C186.048 17.7695 180.97 15.0322 174.236 15.2401C167.503 15.0322 162.425 17.7695 159.043 21.9877C155.669 26.1945 153.999 31.8497 154 37.4791C154.001 43.1085 155.672 48.7631 159.045 52.9686C162.428 57.1855 167.505 59.9209 174.236 59.7106C180.967 59.9209 186.044 57.1855 189.427 52.9686C192.801 48.7631 194.472 43.1085 194.473 37.4791C194.473 31.8497 192.803 26.1945 189.43 21.9877ZM182.196 47.4833C180.409 50.1702 177.762 51.9245 174.238 51.9103H174.234C170.71 51.9245 168.064 50.1702 166.277 47.4833C164.481 44.7816 163.564 41.1431 163.561 37.4762C163.559 33.8093 164.471 30.1718 166.266 27.4716C168.051 24.7867 170.699 23.0337 174.234 23.0503L174.239 23.0503C177.773 23.0337 180.422 24.7867 182.207 27.4716C184.002 30.1718 184.914 33.8093 184.911 37.4762C184.909 41.1431 183.992 44.7816 182.196 47.4833Z"
      fill="#18181B"
    />
  </svg>
);

export const LlamaIndexIcon = ({ className = "", ...props }: IconBaseProps) => (
  <svg
    viewBox="0 0 81 80"
    version="1.1"
    xmlns="http://www.w3.org/2000/svg"
    className={className}
    {...props}
  >
    <title>llamaindex</title>
    <defs>
      <linearGradient
        x1="23.4558085%"
        y1="8.41682113%"
        x2="91.6436502%"
        y2="80.3192605%"
        id="linearGradient-1"
      >
        <stop stopColor="#F6DCD9" offset="6.19804%"></stop>
        <stop stopColor="#FFA5EA" offset="32.5677%"></stop>
        <stop stopColor="#45DFF8" offset="58.9257%"></stop>
        <stop stopColor="#BC8DEB" offset="100%"></stop>
      </linearGradient>
    </defs>
    <g id="Page-1" stroke="none" strokeWidth="1" fill="none" fillRule="evenodd">
      <g id="llamaindex" transform="translate(0, 0)" fillRule="nonzero">
        <path
          d="M0,16 C0,7.16344 7.16925,0 16.013,0 L64.0518,0 C72.8955,0 80.0648,7.16344 80.0648,16 L80.0648,64 C80.0648,72.8366 72.8955,80 64.0518,80 L16.013,80 C7.16924,80 0,72.8366 0,64 L0,16 Z"
          id="Path"
          fill="#000000"
        ></path>
        <path
          d="M50.3091,52.6201 C45.1552,54.8952 39.5718,53.963 37.4243,53.2126 C37.4243,53.726 37.4009,55.3218 37.3072,57.597 C37.2135,59.8721 36.4873,61.3099 36.1359,61.7444 C36.1749,63.1664 36.2062,66.271 36.0188,67.3138 C35.8313,68.3566 35.1598,69.2493 34.8474,69.5652 L31.6848,69.5652 C31.9659,68.1433 33.0513,67.2348 33.5589,66.9583 C33.84,64.0195 33.2856,61.4679 32.9733,60.5594 C32.6609,61.6654 31.8956,64.2328 31.3334,65.6548 C30.7711,67.0768 29.9278,68.3803 29.5763,68.8543 L27.2337,68.8543 C27.1165,67.4323 27.8974,66.9583 28.405,66.9583 C28.6393,66.5238 29.2015,65.1571 29.5763,63.1664 C29.9512,61.1756 29.4202,57.439 29.1078,55.8195 L29.1078,50.7241 C25.3595,48.7096 23.9539,46.6952 23.0168,44.4437 C22.2672,42.6425 22.4702,39.9013 22.6654,38.7558 C22.4311,38.3213 21.7481,37.217 21.4941,35.6749 C21.1427,33.5419 21.3379,32.0014 21.4941,31.1719 C21.2598,30.9349 20.7913,29.7263 20.7913,26.7875 C20.7913,23.8488 21.6502,22.3241 22.0797,21.9291 L22.0797,20.6256 C20.4398,20.5071 18.7999,19.7961 17.8629,18.8482 C16.9258,17.9002 17.6286,16.4782 18.2143,16.0042 C18.7999,15.5302 19.3856,15.8857 20.2056,15.6487 C21.0255,15.4117 21.7283,15.1747 22.0797,14.4637 C22.3608,13.895 21.8064,11.5408 21.494,10.4348 C22.8997,10.6244 23.7977,11.8568 24.071,12.4493L24.071,10.4348 C25.828,11.2643 28.9907,13.2788 30.0449,17.6632 C30.8882,21.1707 31.4895,28.5255 31.6847,31.7645 C36.1749,31.804 41.8755,31.1211 47.0294,32.2384 C51.7148,33.2542 53.8232,35.3194 56.283,35.3194 C58.7428,35.3194 60.1484,33.8974 61.9055,35.0824 C63.6625,36.2674 64.5996,39.5853 64.3653,42.0738 C64.1779,44.0645 62.6473,44.7202 61.9055,44.7992 C60.9684,47.9276 61.9055,50.9216 62.4911,52.0276 L62.4911,56.5305 C62.7645,56.9255 63.3111,58.1421 63.3111,59.8484 C63.3111,61.5548 62.7645,62.6924 62.4911,63.0479 C62.9597,65.7022 62.2959,68.4198 61.9055,69.4468 L58.7428,69.4468 C59.1177,68.4988 59.758,68.2618 60.0313,68.2618 C60.5936,65.3231 60.1875,62.6134 59.9142,61.6259 C58.1337,60.5831 56.9858,58.7425 56.6344,57.9525 C56.6735,58.624 56.5641,60.4883 55.8145,62.5739 C55.0648,64.6595 53.9403,65.8918 53.4718,66.2473 L53.4718,68.7358 L50.3091,68.7358 C50.3091,67.219 51.1681,66.9188 51.5976,66.9583 C52.1443,65.9708 53.4718,64.4699 53.4718,61.5074 C53.4718,59.0077 51.7148,57.834 50.4263,55.5825 C49.8141,54.5128 50.1139,53.1731 50.3091,52.6201 Z"
          id="Path"
          fill="url(#linearGradient-1)"
        ></path>
      </g>
    </g>
  </svg>
);

export const PydanticAIIcon = (props: IconBaseProps) => (
  <svg
    width="139px"
    height="120px"
    viewBox="0 0 139 120"
    version="1.1"
    xmlns="http://www.w3.org/2000/svg"
    {...props}
  >
    <g id="Page-1" stroke="none" strokeWidth="1" fill="none" fillRule="evenodd">
      <g
        id="pydantic-logo"
        transform="translate(0, 0.1733)"
        fill="currentColor"
        fillRule="nonzero"
      >
        <path
          d="M137.124,90.38975 L73.371,2.06775 C71.364,-0.68925 66.738,-0.68925 64.751,2.06775 L0.998,90.38975 C0.349072482,91.2935362 0,92.3781241 0,93.49075 C0.00318943775,95.7819584 1.469778,97.814973 3.643,98.54075 L67.397,119.39175 L67.407,119.39175 C68.4772724,119.740719 69.6307276,119.740719 70.701,119.39175 L70.711,119.39175 L134.464,98.54175 C136.077884,98.0193374 137.341287,96.7514677 137.858,95.13575 C138.390392,93.5257019 138.111354,91.7575889 137.109,90.38975 L137.124,90.38975 Z M69.064,14.23875 L94.617,49.64175 L70.721,41.82875 C70.536,41.76875 70.341,41.77875 70.157,41.73475 C69.976359,41.6901364 69.7924394,41.6600405 69.607,41.64475 C69.423,41.61975 69.248,41.54975 69.064,41.54975 C68.879,41.54975 68.709,41.61975 68.524,41.64475 C68.34,41.66475 68.155,41.69475 67.976,41.73475 C67.786,41.76975 67.591,41.76975 67.422,41.82875 L43.67,49.59675 L43.52,49.64675 L69.074,14.23675 L69.064,14.23675 L69.064,14.23875 Z M32.96,64.26475 L60.779,55.16075 L63.749,54.19375 L63.749,107.03175 L13.869,90.71375 L32.959,64.26475 L32.96,64.26475 Z M74.384,107.02175 L74.384,54.19375 L105.172,64.26475 L124.263,90.69875 L74.379,107.02175 L74.384,107.02175 Z"
          id="Shape"
        ></path>
      </g>
    </g>
  </svg>
);

export const customIcons = {
  adk: ADKIcon,
  react: FaReact,
  server: HiOutlineServerStack,
  zap: LuZap,
  brush: LuBrush,
  globe: LuGlobe,
  langchain: SiLangchain,
  typescript: TbBrandTypescript,
  python: FaPython,
  crewai: SiCrewai,
  component: LuLayoutTemplate,
  ag2: AG2Icon,
  mastra: MastraIcon,
  agno: AgnoIcon,
  agnoBlack: AgnoIconBlack,
  llamaindex: LlamaIndexIcon,
  pydantic: PydanticAIIcon,
  llm: RocketIcon,
  "direct-to-llm": RocketIcon,
};



================================================
FILE: docs/icons/index.tsx
================================================
import { icons as lucideIcons } from "lucide-react";
import { createElement } from "react";
import { customIcons } from "./custom-icons";

export function icon(icon: any) {
  if (!icon) {
    return;
  }

  let iconElement: React.ReactNode = null;

  if (icon.startsWith("lucide/")) {
    const iconName = icon.split("lucide/")[1];
    if (iconName in lucideIcons)
      iconElement = createElement(
        lucideIcons[iconName as keyof typeof lucideIcons]
      );
  }

  if (icon.startsWith("custom/")) {
    const iconName = icon.split("custom/")[1];
    if (iconName in customIcons)
      iconElement = createElement(
        customIcons[iconName as keyof typeof customIcons]
      );
  }

  return (
    <div key={icon} className="text-primary">
      {iconElement}
    </div>
  );
}



================================================
FILE: docs/images/left-illustration.avif
================================================
[Binary file]


================================================
FILE: docs/quickstart/applications.mdx
================================================
---
title: "Build applications"
description:
  "Build agentic applications utilizing compatible event AG-UI event streams"
---

# Introduction

AG-UI provides a concise, event-driven protocol that lets any agent stream rich,
structured output to any client. It can be used to connect any agentic system to
any client.

A client is defined as any system that can receieve, display, and respond to 
AG-UI events. For more information on existing clients and integrations, see
the [integrations](/integrations) page.

# Automatic Setup
AG-UI provides a CLI tool to automatically create or scaffold a new application with any client and server.

```sh
npx create-ag-ui-app@latest
```

<img
  className="w-full rounded-3xl mx-auto"
  src="https://copilotkit-public-assets.s3.us-east-1.amazonaws.com/docs/ag-ui/quickstart.gif"
/>

Once the setup is done, start the server with

```sh
npm run dev
```

For the copilotkit example you can head to http://localhost:3000/copilotkit to see the app in action.



================================================
FILE: docs/quickstart/clients.mdx
================================================
---
title: "Build clients"
description:
  "Showcase: build a conversational CLI agent from scratch using AG-UI and Mastra"
---

# Introduction

A client implementation allows you to **build conversational applications that
leverage AG-UI's event-driven protocol**. This approach creates a direct
interface between your users and AI agents, demonstrating direct access to the
AG-UI protocol.

## When to use a client implementation

Building your own client is useful if you want to explore/hack on the AG-UI
protocol. For production use, use a full-featured client like
[CopilotKit](https://copilotkit.ai).

## What you'll build

In this guide, we'll create a CLI client that:

1. Uses the `MastraAgent` from `@ag-ui/mastra`
2. Connects to OpenAI's GPT-4o model
3. Implements a weather tool for real-world functionality
4. Provides an interactive chat interface in the terminal

Let's get started!

## Prerequisites

Before we begin, make sure you have:

- [Node.js](https://nodejs.org/) **v18 or later**
- An **OpenAI API key**
- [pnpm](https://pnpm.io/) package manager

### 1. Provide your OpenAI API key

First, let's set up your API key:

```bash
# Set your OpenAI API key
export OPENAI_API_KEY=your-api-key-here
```

### 2. Install pnpm

If you don't have pnpm installed:

```bash
# Install pnpm
npm install -g pnpm
```

## Step 1 – Initialize your project

Create a new directory for your AG-UI client:

```bash
mkdir my-ag-ui-client
cd my-ag-ui-client
```

Initialize a new Node.js project:

```bash
pnpm init
```

### Set up TypeScript and basic configuration

Install TypeScript and essential development dependencies:

```bash
pnpm add -D typescript @types/node tsx
```

Create a `tsconfig.json` file:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "commonjs",
    "lib": ["ES2022"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
```

Update your `package.json` scripts:

```json
{
  // ...

  "scripts": {
    "start": "tsx src/index.ts",
    "dev": "tsx --watch src/index.ts",
    "build": "tsc",
    "clean": "rm -rf dist"
  }

  // ...
}
```

## Step 2 – Install AG-UI and dependencies

Install the core AG-UI packages and dependencies:

```bash
# Core AG-UI packages
pnpm add @ag-ui/client @ag-ui/core @ag-ui/mastra

# Mastra ecosystem packages
pnpm add @mastra/core @mastra/memory @mastra/libsql

# AI SDK and utilities
pnpm add @ai-sdk/openai zod@^3.25
```

## Step 3 – Create your agent

Let's create a basic conversational agent. Create `src/agent.ts`:

```typescript
import { openai } from "@ai-sdk/openai"
import { Agent } from "@mastra/core/agent"
import { MastraAgent } from "@ag-ui/mastra"
import { Memory } from "@mastra/memory"
import { LibSQLStore } from "@mastra/libsql"

export const agent = new MastraAgent({
  agent: new Agent({
    name: "AG-UI Assistant",
    instructions: `
      You are a helpful AI assistant. Be friendly, conversational, and helpful. 
      Answer questions to the best of your ability and engage in natural conversation.
    `,
    model: openai("gpt-4o"),
    memory: new Memory({
      storage: new LibSQLStore({
        url: "file:./assistant.db",
      }),
    }),
  }),
  threadId: "main-conversation",
})
```

### What's happening in the agent?

1. **MastraAgent** – We wrap a Mastra Agent with the AG-UI protocol adapter
2. **Model Configuration** – We use OpenAI's GPT-4o for high-quality responses
3. **Memory Setup** – We configure persistent memory using LibSQL for
   conversation context
4. **Instructions** – We give the agent basic guidelines for helpful
   conversation

## Step 4 – Create the CLI interface

Now let's create the interactive chat interface. Create `src/index.ts`:

```typescript
import * as readline from "readline"
import { agent } from "./agent"
import { randomUUID } from "node:crypto"

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
})

async function chatLoop() {
  console.log("🤖 AG-UI Assistant started!")
  console.log("Type your messages and press Enter. Press Ctrl+D to quit.\n")

  return new Promise<void>((resolve) => {
    const promptUser = () => {
      rl.question("> ", async (input) => {
        if (input.trim() === "") {
          promptUser()
          return
        }
        console.log("")

        // Pause input while processing
        rl.pause()

        // Add user message to conversation
        agent.messages.push({
          id: randomUUID(),
          role: "user",
          content: input.trim(),
        })

        try {
          // Run the agent with event handlers
          await agent.runAgent(
            {}, // No additional configuration needed
            {
              onTextMessageStartEvent() {
                process.stdout.write("🤖 Assistant: ")
              },
              onTextMessageContentEvent({ event }) {
                process.stdout.write(event.delta)
              },
              onTextMessageEndEvent() {
                console.log("\n")
              },
            }
          )
        } catch (error) {
          console.error("❌ Error:", error)
        }

        // Resume input
        rl.resume()
        promptUser()
      })
    }

    // Handle Ctrl+D to quit
    rl.on("close", () => {
      console.log("\n👋 Thanks for using AG-UI Assistant!")
      resolve()
    })

    promptUser()
  })
}

async function main() {
  await chatLoop()
}

main().catch(console.error)
```

### What's happening in the CLI interface?

1. **Readline Interface** – We create an interactive prompt for user input
2. **Message Management** – We add each user input to the agent's conversation
   history
3. **Event Handling** – We listen to AG-UI events to provide real-time feedback
4. **Streaming Display** – We show the agent's response as it's being generated

## Step 5 – Test your assistant

Let's run your new AG-UI client:

```bash
pnpm dev
```

You should see:

```
🤖 AG-UI Assistant started!
Type your messages and press Enter. Press Ctrl+D to quit.

>
```

Try asking questions like:

- "Hello! How are you?"
- "What can you help me with?"
- "Tell me a joke"
- "Explain quantum computing in simple terms"

You'll see the agent respond with streaming text in real-time!

## Step 6 – Understanding the AG-UI event flow

Let's break down what happens when you send a message:

1. **User Input** – You type a question and press Enter
2. **Message Added** – Your input is added to the conversation history
3. **Agent Processing** – The agent analyzes your request and formulates a
   response
4. **Response Generation** – The agent streams its response back
5. **Streaming Output** – You see the response appear word by word

### Event types you're handling:

- `onTextMessageStartEvent` – Agent starts responding
- `onTextMessageContentEvent` – Each chunk of the response
- `onTextMessageEndEvent` – Response is complete

## Step 7 – Add tool functionality

Now that you have a working chat interface, let's add some real-world
capabilities by creating tools. We'll start with a weather tool.

### Create your first tool

Let's create a weather tool that your agent can use. Create the directory
structure:

```bash
mkdir -p src/tools
```

Create `src/tools/weather.tool.ts`:

```typescript
import { createTool } from "@mastra/core/tools"
import { z } from "zod"

interface GeocodingResponse {
  results: {
    latitude: number
    longitude: number
    name: string
  }[]
}

interface WeatherResponse {
  current: {
    time: string
    temperature_2m: number
    apparent_temperature: number
    relative_humidity_2m: number
    wind_speed_10m: number
    wind_gusts_10m: number
    weather_code: number
  }
}

export const weatherTool = createTool({
  id: "get-weather",
  description: "Get current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("City name"),
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string(),
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location)
  },
})

const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(
    location
  )}&count=1`
  const geocodingResponse = await fetch(geocodingUrl)
  const geocodingData = (await geocodingResponse.json()) as GeocodingResponse

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`)
  }

  const { latitude, longitude, name } = geocodingData.results[0]

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`

  const response = await fetch(weatherUrl)
  const data = (await response.json()) as WeatherResponse

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name,
  }
}

function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    56: "Light freezing drizzle",
    57: "Dense freezing drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    66: "Light freezing rain",
    67: "Heavy freezing rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    77: "Snow grains",
    80: "Slight rain showers",
    81: "Moderate rain showers",
    82: "Violent rain showers",
    85: "Slight snow showers",
    86: "Heavy snow showers",
    95: "Thunderstorm",
    96: "Thunderstorm with slight hail",
    99: "Thunderstorm with heavy hail",
  }
  return conditions[code] || "Unknown"
}
```

### What's happening in the weather tool?

1. **Tool Definition** – We use `createTool` from Mastra to define the tool's
   interface
2. **Input Schema** – We specify that the tool accepts a location string
3. **Output Schema** – We define the structure of the weather data returned
4. **API Integration** – We fetch data from Open-Meteo's free weather API
5. **Data Processing** – We convert weather codes to human-readable conditions

### Update your agent

Now let's update our agent to use the weather tool. Update `src/agent.ts`:

```typescript
import { weatherTool } from "./tools/weather.tool" // <--- Import the tool

export const agent = new MastraAgent({
  agent: new Agent({
    // ...

    tools: { weatherTool }, // <--- Add the tool to the agent

    // ...
  }),
  threadId: "main-conversation",
})
```

### Update your CLI to handle tools

Update your CLI interface in `src/index.ts` to handle tool events:

```typescript
// Add these new event handlers to your agent.runAgent call:
await agent.runAgent(
  {}, // No additional configuration needed
  {
    // ... existing event handlers ...

    onToolCallStartEvent({ event }) {
      console.log("🔧 Tool call:", event.toolCallName)
    },
    onToolCallArgsEvent({ event }) {
      process.stdout.write(event.delta)
    },
    onToolCallEndEvent() {
      console.log("")
    },
    onToolCallResultEvent({ event }) {
      if (event.content) {
        console.log("🔍 Tool call result:", event.content)
      }
    },
  }
)
```

### Test your weather tool

Now restart your application and try asking about weather:

```bash
pnpm dev
```

Try questions like:

- "What's the weather like in London?"
- "How's the weather in Tokyo today?"
- "Is it raining in Seattle?"

You'll see the agent use the weather tool to fetch real data and provide
detailed responses!

## Step 8 – Add more functionality

### Create a browser tool

Let's add a web browsing capability. First install the `open` package:

```bash
pnpm add open
```

Create `src/tools/browser.tool.ts`:

```typescript
import { createTool } from "@mastra/core/tools"
import { z } from "zod"
import { open } from "open"

export const browserTool = createTool({
  id: "open-browser",
  description: "Open a URL in the default web browser",
  inputSchema: z.object({
    url: z.string().url().describe("The URL to open"),
  }),
  outputSchema: z.object({
    success: z.boolean(),
    message: z.string(),
  }),
  execute: async ({ context }) => {
    try {
      await open(context.url)
      return {
        success: true,
        message: `Opened ${context.url} in your default browser`,
      }
    } catch (error) {
      return {
        success: false,
        message: `Failed to open browser: ${error}`,
      }
    }
  },
})
```

### Update your agent with both tools

Update `src/agent.ts` to include both tools:

```typescript
import { openai } from "@ai-sdk/openai"
import { Agent } from "@mastra/core/agent"
import { MastraAgent } from "@ag-ui/mastra"
import { Memory } from "@mastra/memory"
import { LibSQLStore } from "@mastra/libsql"
import { weatherTool } from "./tools/weather.tool"
import { browserTool } from "./tools/browser.tool"

export const agent = new MastraAgent({
  agent: new Agent({
    name: "AG-UI Assistant",
    instructions: `
      You are a helpful assistant with weather and web browsing capabilities.

      For weather queries:
      - Always ask for a location if none is provided
      - Use the weatherTool to fetch current weather data

      For web browsing:
      - Always use full URLs (e.g., "https://www.google.com")
      - Use the browserTool to open web pages

      Be friendly and helpful in all interactions!
    `,
    model: openai("gpt-4o"),
    tools: { weatherTool, browserTool }, // Add both tools
    memory: new Memory({
      storage: new LibSQLStore({
        url: "file:./assistant.db",
      }),
    }),
  }),
  threadId: "main-conversation",
})
```

Now you can ask your assistant to open websites: "Open Google for me" or "Show
me the weather website".

## Step 9 – Deploy your client

### Building your client

Create a production build:

```bash
pnpm build
```

### Create a startup script

Add to your `package.json`:

```json
{
  "bin": {
    "weather-assistant": "./dist/index.js"
  }
}
```

Add a shebang to your built `dist/index.js`:

```javascript
#!/usr/bin/env node
// ... rest of your compiled code
```

Make it executable:

```bash
chmod +x dist/index.js
```

### Link globally

Install your CLI globally:

```bash
pnpm link --global
```

Now you can run `weather-assistant` from anywhere!

## Extending your client

Your AG-UI client is now a solid foundation. Here are some ideas for
enhancement:

### Add more tools

- **Calculator tool** – For mathematical operations
- **File system tool** – For reading/writing files
- **API tools** – For connecting to other services
- **Database tools** – For querying data

### Improve the interface

- **Rich formatting** – Use libraries like `chalk` for colored output
- **Progress indicators** – Show loading states for long operations
- **Configuration files** – Allow users to customize settings
- **Command-line arguments** – Support different modes and options

### Add persistence

- **Conversation history** – Save and restore chat sessions
- **User preferences** – Remember user settings
- **Tool results caching** – Cache expensive API calls

## Share your client

Built something useful? Consider sharing it with the community:

1. **Open source it** – Publish your code on GitHub
2. **Publish to npm** – Make it installable via `npm install`
3. **Create documentation** – Help others understand and extend your work
4. **Join discussions** – Share your experience in the
   [AG-UI GitHub Discussions](https://github.com/orgs/ag-ui-protocol/discussions)

## Conclusion

You've built a complete AG-UI client from scratch! Your weather assistant
demonstrates the core concepts:

- **Event-driven architecture** with real-time streaming
- **Tool integration** for real-world functionality
- **Conversation memory** for context retention
- **Interactive CLI interface** for user engagement

From here, you can extend your client to support any use case – from simple CLI
tools to complex conversational applications. The AG-UI protocol provides the
foundation, and your creativity provides the possibilities.

Happy building! 🚀



================================================
FILE: docs/quickstart/introduction.mdx
================================================
---
title: "Introduction"
description: "Learn how to get started building an AG-UI integration"
---

<video
  src="https://copilotkit-public-assets.s3.us-east-1.amazonaws.com/docs/ag-ui/ag-ui-animation-simple.mp4"
  autoPlay
  playsInline
  muted
  className="w-full h-[390px] rounded-lg object-cover mx-auto block"
/>

# What is an Integration?

An AG-UI integration makes your agent speak the AG-UI protocol. This means your agent can work with any AG-UI compatible client application - like chat interfaces, copilots, or custom AI tools.

Think of it like adding a universal translator to your agent. Instead of building custom APIs for each client, you implement AG-UI once and instantly work with any compatible application.

Agents integrating with AG-UI can:
- **Stream responses** - Real-time text that appears as it's generated
- **Call client-side tools** - Your agent can use functions and services defined by clients
- **Share state** - Your agent's state is bidirectional shared state
- **Execute universally** - Integrate with any AG-UI compatible client application
- **And much more!** - Check out the full specification [here](/concepts/events).

### When should I make any integration?
If the integration you're looking for is not listed on our [integrations page](/integrations), you'll need to make an integration. We've got a few guides on this below!

However, if you're looking to utilize an existing integration (like LangGraph, CrewAI, Mastra, etc.), you can skip this step and go straight to [building an application](/quickstart/applications).

# Types of Integrations
So you've decided you need an integration! Great, there are **two main ways** to implement an AG-UI integration:

<CardGroup cols={2}>
  <Card
    icon="server"
    title="Server Implementation"
    href="/quickstart/server"
  >
    Emit AG-UI events **directly from your agent** or server.
  </Card>
  <Card
    icon="code"
    title="Middleware Implementation"
    href="/quickstart/middleware"
  >
    **Translate existing protocols** and applications to AG-UI events.
  </Card>
</CardGroup>

### When to use a server implementation
Server implementations allow you to directly emit AG-UI events from your agent or server. If you are not using an
agent framework or haven't created a protocol for your agent framework yet, this is the best way to get started.

Server implementations are also great for:
- Building a **new agent frameworks** from scratch
- **Maximum control** over how and what events are emitted
- Exposing your agent as a **standalone API**

### When to use a middleware implementation
Middleware is the flexible option. It allows you to translate existing protocols and applications to AG-UI events
creating a bridge between your existing system and AG-UI.

Middleware is great for:
- Taking your **existing protocol or API** and **translating it universally**
- Working within the confines of **an existing system or framework**
- **When you don't have direct control** over the agent framework or system



================================================
FILE: docs/quickstart/middleware.mdx
================================================
---
title: "Middleware"
description:
  "Connect to existing protocols, in process agents or custom solutions via
  AG-UI"
---

# Introduction

A middleware implementation allows you to **translate existing protocols and
applications to AG-UI events**. This approach creates a bridge between your
existing system and AG-UI, making it perfect for adding agent capabilities to
current applications.

## When to use a middleware implementation

Middleware is the flexible option. It allows you to translate existing protocols
and applications to AG-UI events creating a bridge between your existing system
and AG-UI.

Middleware is great for:

- Taking your **existing protocol or API** and **translating it universally**
- Working within the confines of **an existing system or framework**
- **When you don't have direct control** over the agent framework or system

## What you'll build

In this guide, we'll create a middleware agent that:

1. Extends the `AbstractAgent` class
2. Connects to OpenAI's GPT-4o model
3. Translates OpenAI responses to AG-UI events
4. Runs in-process with your application

This approach gives you maximum flexibility to integrate with existing codebases
while maintaining the full power of the AG-UI protocol.

Let's get started!

## Prerequisites

Before we begin, make sure you have:

- [Node.js](https://nodejs.org/) **v16 or later**
- An **OpenAI API key**

### 1. Provide your OpenAI API key

First, let's set up your API key:

```bash
# Set your OpenAI API key
export OPENAI_API_KEY=your-api-key-here
```

### 2. Install build utilities

Install the following tools:

```bash
brew install protobuf
```

```bash
npm i turbo
```

```bash
curl -fsSL https://get.pnpm.io/install.sh | sh -
```

## Step 1 – Scaffold your integration

Start by cloning the repo and navigating to the TypeScript SDK:

```bash
git clone git@github.com:ag-ui-protocol/ag-ui.git
cd ag-ui/typescript-sdk
```

Copy the middleware-starter template to create your OpenAI integration:

```bash
cp -r integrations/middleware-starter integrations/openai
```

### Update metadata

Open `integrations/openai/package.json` and update the fields to match your new
folder:

```json
{
  "name": "@ag-ui/openai",
  "author": "Your Name <your-email@example.com>",
  "version": "0.0.1",

  ... rest of package.json
}
```

Next, update the class name inside `integrations/openai/src/index.ts`:

```ts
// change the name to OpenAIAgent
export class OpenAIAgent extends AbstractAgent {}
```

Finally, introduce your integration to the dojo by adding it to
`apps/dojo/src/menu.ts`:

```ts
// ...
export const menuIntegrations: MenuIntegrationConfig[] = [
  // ...

  {
    id: "openai",
    name: "OpenAI",
    features: ["agentic_chat"],
  },
]
```

And `apps/dojo/src/agents.ts`:

```ts
// ...
import { OpenAIAgent } from "@ag-ui/openai"

export const agentsIntegrations: AgentIntegrationConfig[] = [
  // ...

  {
    id: "openai",
    agents: async () => {
      return {
        agentic_chat: new OpenAIAgent(),
      }
    },
  },
]
```

## Step 2 – Add package to dojo dependencies

Open `apps/dojo/package.json` and add the package `@ag-ui/openai`:

```json
{
  "name": "demo-viewer",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@ag-ui/agno": "workspace:*",
    "@ag-ui/langgraph": "workspace:*",
    "@ag-ui/mastra": "workspace:*",
    "@ag-ui/middleware-starter": "workspace:*",
    "@ag-ui/server-starter": "workspace:*",
    "@ag-ui/server-starter-all-features": "workspace:*",
    "@ag-ui/vercel-ai-sdk": "workspace:*",
    "@ag-ui/openai": "workspace:*", <- Add this line

  ... rest of package.json
}
```

## Step 3 – Start the dojo

Now let's see your work in action:

```bash
# Install dependencies
pnpm install

# Compile the project and run the dojo
turbo run dev
```

Head over to [http://localhost:3000](http://localhost:3000) and choose
**OpenAI** from the drop-down. You'll see the stub agent replies with **Hello
world!** for now.

Here's what's happening with that stub agent:

```ts
// integrations/openai/src/index.ts
import {
  AbstractAgent,
  BaseEvent,
  EventType,
  RunAgentInput,
} from "@ag-ui/client"
import { Observable } from "rxjs"

export class OpenAIAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = Date.now().toString()
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
      } as any)

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
      } as any)

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      observer.complete()
    })
  }
}
```

## Step 4 – Bridge OpenAI with AG-UI

Let's transform our stub into a real agent that streams completions from OpenAI.

### Install the OpenAI SDK

First, we need the OpenAI SDK:

```bash
cd integrations/openai
pnpm install openai
```

### AG-UI recap

An AG-UI agent extends `AbstractAgent` and emits a sequence of events to signal:

- lifecycle events (`RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`)
- content events (`TEXT_MESSAGE_*`, `TOOL_CALL_*`, and more)

### Implement the streaming agent

Now we'll transform our stub agent into a real OpenAI integration. The key
difference is that instead of sending a hardcoded "Hello world!" message, we'll
connect to OpenAI's API and stream the response back through AG-UI events.

The implementation follows the same event flow as our stub, but we'll add the
OpenAI client initialization in the constructor and replace our mock response
with actual API calls. We'll also handle tool calls if they're present in the
response, making our agent fully capable of using functions when needed.

```typescript
// integrations/openai/src/index.ts
import {
  AbstractAgent,
  RunAgentInput,
  EventType,
  BaseEvent,
} from "@ag-ui/client"
import { Observable } from "rxjs"

import { OpenAI } from "openai"

export class OpenAIAgent extends AbstractAgent {
  private openai: OpenAI

  constructor(openai?: OpenAI) {
    super()
    // Initialize OpenAI client - uses OPENAI_API_KEY from environment if not provided
    this.openai = openai ?? new OpenAI()
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return new Observable<BaseEvent>((observer) => {
      // Same as before - emit RUN_STARTED to begin
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any)

      // NEW: Instead of hardcoded response, call OpenAI's API
      this.openai.chat.completions
        .create({
          model: "gpt-4o",
          stream: true, // Enable streaming for real-time responses
          // Convert AG-UI tools format to OpenAI's expected format
          tools: input.tools.map((tool) => ({
            type: "function",
            function: {
              name: tool.name,
              description: tool.description,
              parameters: tool.parameters,
            },
          })),
          // Transform AG-UI messages to OpenAI's message format
          messages: input.messages.map((message) => ({
            role: message.role as any,
            content: message.content ?? "",
            // Include tool calls if this is an assistant message with tools
            ...(message.role === "assistant" && message.toolCalls
              ? {
                  tool_calls: message.toolCalls,
                }
              : {}),
            // Include tool call ID if this is a tool result message
            ...(message.role === "tool"
              ? { tool_call_id: message.toolCallId }
              : {}),
          })),
        })
        .then(async (response) => {
          const messageId = Date.now().toString()

          // NEW: Stream each chunk from OpenAI's response
          for await (const chunk of response) {
            // Handle text content chunks
            if (chunk.choices[0].delta.content) {
              observer.next({
                type: EventType.TEXT_MESSAGE_CHUNK, // Chunk events open and close messages automatically
                messageId,
                delta: chunk.choices[0].delta.content,
              } as any)
            }
            // Handle tool call chunks (when the model wants to use a function)
            else if (chunk.choices[0].delta.tool_calls) {
              let toolCall = chunk.choices[0].delta.tool_calls[0]

              observer.next({
                type: EventType.TOOL_CALL_CHUNK,
                toolCallId: toolCall.id,
                toolCallName: toolCall.function?.name,
                parentMessageId: messageId,
                delta: toolCall.function?.arguments,
              } as any)
            }
          }

          // Same as before - emit RUN_FINISHED when complete
          observer.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
          } as any)

          observer.complete()
        })
        // NEW: Handle errors from the API
        .catch((error) => {
          observer.next({
            type: EventType.RUN_ERROR,
            message: error.message,
          } as any)

          observer.error(error)
        })
    })
  }
}
```

### What happens under the hood?

Let's break down what your agent is doing:

1. **Setup** – We create an OpenAI client and emit `RUN_STARTED`
2. **Request** – We send the user's messages to `chat.completions` with
   `stream: true`
3. **Streaming** – We forward each chunk as either `TEXT_MESSAGE_CHUNK` or
   `TOOL_CALL_CHUNK`
4. **Finish** – We emit `RUN_FINISHED` (or `RUN_ERROR` if something goes wrong)
   and complete the observable

## Step 4 – Chat with your agent

Reload the dojo page and start typing. You'll see GPT-4o streaming its answer in
real-time, word by word.

## Bridging AG-UI to any protocol

The pattern you just implemented—translate inputs, forward streaming chunks,
emit AG-UI events—works for virtually any backend:

- REST or GraphQL APIs
- WebSockets
- IoT protocols such as MQTT

## Connect your agent to a frontend

Tools like [CopilotKit](https://docs.copilotkit.ai) already understand AG-UI and
provide plug-and-play React components. Point them at your agent endpoint and
you get a full-featured chat UI out of the box.

## Share your integration

Did you build a custom adapter that others could reuse? We welcome community
contributions!

1. Fork the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui)
2. Add your package under `typescript-sdk/integrations/`. See
   [Contributing](../development/contributing) for more details and naming
   conventions.
3. Open a pull request describing your use-case and design decisions

If you have questions, need feedback, or want to validate an idea first, start a
thread in the GitHub Discussions board:
[AG-UI GitHub Discussions board](https://github.com/orgs/ag-ui-protocol/discussions).

Your integration might ship in the next release and help the entire AG-UI
ecosystem grow.

## Conclusion

You now have a fully-functional AG-UI adapter for OpenAI and a local playground
to test it. From here you can:

- Add tool calls to enhance your agent
- Publish your integration to npm
- Bridge AG-UI to any other model or service

Happy building!



================================================
FILE: docs/quickstart/server.mdx
================================================
---
title: "Server"
description: "Implement AG-UI compatible servers"
---

# Introduction

A server implementation allows you to **emit AG-UI events directly from your
agent or server**. This approach is ideal when you're building a new agent from
scratch or want a dedicated service for your agent capabilities.

## When to use a server implementation

Server implementations allow you to directly emit AG-UI events from your agent
or server. If you are not using an agent framework or haven't created a protocol
for your agent framework yet, this is the best way to get started.

Server implementations are also great for:

- Building a **new agent frameworks** from scratch
- **Maximum control** over how and what events are emitted
- Exposing your agent as a **standalone API**

## What you'll build

In this guide, we'll create a standalone HTTP server that:

1. Accepts AG-UI protocol requests
2. Connects to OpenAI's GPT-4o model
3. Streams responses back as AG-UI events
4. Handles tool calls and state management

Let's get started!

## Prerequisites

Before we begin, make sure you have:

- [Python](https://www.python.org/downloads/) **3.12 or later**
- [Poetry](https://python-poetry.org/docs/#installation) for dependency
  management
- An **OpenAI API key**

### 1. Provide your OpenAI API key

First, let's set up your API key:

```bash
# Set your OpenAI API key
export OPENAI_API_KEY=your-api-key-here
```

### 2. Install build utilities

Install the following tools:

```bash
brew install protobuf
```

```bash
npm i turbo
```

```bash
curl -fsSL https://get.pnpm.io/install.sh | sh -
```

## Step 1 – Scaffold your server

Start by cloning the repo and navigating to the TypeScript SDK:

```bash
git clone git@github.com:ag-ui-protocol/ag-ui.git
cd ag-ui/typescript-sdk
```

Copy the server-starter template to create your OpenAI server:

```bash
cp -r integrations/server-starter integrations/openai-server
```

### Update metadata

Open `integrations/openai-server/package.json` and update the fields to match
your new folder:

```json
{
  "name": "@ag-ui/openai-server",
  "author": "Your Name <your-email@example.com>",
  "version": "0.0.1",

  ... rest of package.json
}
```

Next, update the class name inside `integrations/openai-server/src/index.ts`:

```ts
// Change the name to OpenAIServerAgent to add a minimal middleware for your integration.
// You can use this later on to add configuration etc.
export class OpenAIServerAgent extends HttpAgent {}
```

Finally, introduce your integration to the dojo by adding it to
`apps/dojo/src/menu.ts`:

```ts
// ...
export const menuIntegrations: MenuIntegrationConfig[] = [
  // ...

  {
    id: "openai-server",
    name: "OpenAI Server",
    features: ["agentic_chat"],
  },
]
```

And `apps/dojo/src/agents.ts`:

```ts
// ...
import { OpenAIServerAgent } from "@ag-ui/openai-server"

export const agentsIntegrations: AgentIntegrationConfig[] = [
  // ...

  {
    id: "openai-server",
    agents: async () => {
      return {
        agentic_chat: new OpenAIServerAgent(),
      }
    },
  },
]
```

## Step 2 – Add package to dojo dependencies

Open `apps/dojo/package.json` and add the package `@ag-ui/openai-server`:

```json
{
  "name": "demo-viewer",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@ag-ui/agno": "workspace:*",
    "@ag-ui/langgraph": "workspace:*",
    "@ag-ui/mastra": "workspace:*",
    "@ag-ui/middleware-starter": "workspace:*",
    "@ag-ui/server-starter": "workspace:*",
    "@ag-ui/server-starter-all-features": "workspace:*",
    "@ag-ui/vercel-ai-sdk": "workspace:*",
    "@ag-ui/openai-server": "workspace:*", <- Add this line

  ... rest of package.json
}
```

## Step 3 – Start the dojo and server

Now let's see your work in action. First, start your Python server:

```bash
cd integrations/openai-server/server/python
poetry install && poetry run dev
```

In another terminal, start the dojo:

```bash
cd typescript-sdk

# Install dependencies
pnpm install

# Compile the project and run the dojo
turbo run dev
```

Head over to [http://localhost:3000](http://localhost:3000) and choose
**OpenAI** from the drop-down. You'll see the stub server replies with **Hello
world!** for now.

Here's what's happening with that stub server:

```python
# integrations/openai-server/server/python/example_server/__init__.py
@app.post("/")
async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic chat endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():

        # Send run started event
        yield encoder.encode(
          RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id=input_data.thread_id,
            run_id=input_data.run_id
          ),
        )

        message_id = str(uuid.uuid4())

        yield encoder.encode(
            TextMessageStartEvent(
                type=EventType.TEXT_MESSAGE_START,
                message_id=message_id,
                role="assistant"
            )
        )

        yield encoder.encode(
            TextMessageContentEvent(
                type=EventType.TEXT_MESSAGE_CONTENT,
                message_id=message_id,
                delta="Hello world!"
            )
        )

        yield encoder.encode(
            TextMessageEndEvent(
                type=EventType.TEXT_MESSAGE_END,
                message_id=message_id
            )
        )

        # Send run finished event
        yield encoder.encode(
          RunFinishedEvent(
            type=EventType.RUN_FINISHED,
            thread_id=input_data.thread_id,
            run_id=input_data.run_id
          ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )
```

## Step 4 – Bridge OpenAI with AG-UI

Let's transform our stub into a real server that streams completions from
OpenAI.

### Install the OpenAI SDK

First, we need the OpenAI SDK:

```bash
cd integrations/openai-server/server/python
poetry add openai
```

### AG-UI recap

An AG-UI server implements the endpoint and emits a sequence of events to
signal:

- lifecycle events (`RUN_STARTED`, `RUN_FINISHED`, `RUN_ERROR`)
- content events (`TEXT_MESSAGE_*`, `TOOL_CALL_*`, and more)

### Implement the streaming server

Now we'll transform our stub server into a real OpenAI integration. The key
difference is that instead of sending a hardcoded "Hello world!" message, we'll
connect to OpenAI's API and stream the response back through AG-UI events.

The implementation follows the same event flow as our stub, but we'll add the
OpenAI client initialization and replace our mock response with actual API
calls. We'll also handle tool calls if they're present in the response, making
our server fully capable of using functions when needed.

```python
import os
import uuid
import uvicorn
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
)
from ag_ui.encoder import EventEncoder
from openai import OpenAI

app = FastAPI(title="AG-UI OpenAI Server")

# Initialize OpenAI client - uses OPENAI_API_KEY from environment
client = OpenAI()

@app.post("/")
async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
    """OpenAI agentic chat endpoint"""
    accept_header = request.headers.get("accept")
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        try:
            yield encoder.encode(
                RunStartedEvent(
                    type=EventType.RUN_STARTED,
                    thread_id=input_data.thread_id,
                    run_id=input_data.run_id
                )
            )

            # Call OpenAI's API with streaming enabled
            stream = client.chat.completions.create(
                model="gpt-4o",
                stream=True,
                # Convert AG-UI tools format to OpenAI's expected format
                tools=[
                    {
                        "type": "function",
                        "function": {
                            "name": tool.name,
                            "description": tool.description,
                            "parameters": tool.parameters,
                        }
                    }
                    for tool in input_data.tools
                ] if input_data.tools else None,
                # Transform AG-UI messages to OpenAI's message format
                messages=[
                    {
                        "role": message.role,
                        "content": message.content or "",
                        # Include tool calls if this is an assistant message with tools
                        **({"tool_calls": message.tool_calls} if message.role == "assistant" and hasattr(message, 'tool_calls') and message.tool_calls else {}),
                        # Include tool call ID if this is a tool result message
                        **({"tool_call_id": message.tool_call_id} if message.role == "tool" and hasattr(message, 'tool_call_id') else {}),
                    }
                    for message in input_data.messages
                ],
            )

            message_id = str(uuid.uuid4())

            # Stream each chunk from OpenAI's response
            for chunk in stream:
                # Handle text content chunks
                if chunk.choices[0].delta.content:
                    yield encoder.encode({
                        "type": EventType.TEXT_MESSAGE_CHUNK,
                        "message_id": message_id,
                        "delta": chunk.choices[0].delta.content,
                    })
                # Handle tool call chunks
                elif chunk.choices[0].delta.tool_calls:
                    tool_call = chunk.choices[0].delta.tool_calls[0]

                    yield encoder.encode({
                        "type": EventType.TOOL_CALL_CHUNK,
                        "tool_call_id": tool_call.id,
                        "tool_call_name": tool_call.function.name if tool_call.function else None,
                        "parent_message_id": message_id,
                        "delta": tool_call.function.arguments if tool_call.function else None,
                    })

            yield encoder.encode(
                RunFinishedEvent(
                    type=EventType.RUN_FINISHED,
                    thread_id=input_data.thread_id,
                    run_id=input_data.run_id
                )
            )

        except Exception as error:
            yield encoder.encode(
                RunErrorEvent(
                    type=EventType.RUN_ERROR,
                    message=str(error)
                )
            )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "example_server:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )

if __name__ == "__main__":
    main()
```

### What happens under the hood?

Let's break down what your server is doing:

1. **Setup** – We create an OpenAI client and emit `RUN_STARTED`
2. **Request** – We send the user's messages to `chat.completions` with
   `stream=True`
3. **Streaming** – We forward each chunk as either `TEXT_MESSAGE_CHUNK` or
   `TOOL_CALL_CHUNK`
4. **Finish** – We emit `RUN_FINISHED` (or `RUN_ERROR` if something goes wrong)

## Step 5 – Chat with your server

Reload the dojo page and start typing. You'll see GPT-4o streaming its answer in
real-time, word by word.

Tools like [CopilotKit](https://docs.copilotkit.ai) already understand AG-UI and
provide plug-and-play React components. Point them at your server endpoint and
you get a full-featured chat UI out of the box.

## Share your integration

Did you build a custom server that others could reuse? We welcome community
contributions!

1. Fork the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui)
2. Add your package under `typescript-sdk/integrations/`. See
   [Contributing](../development/contributing) for more details and naming
   conventions.
3. Open a pull request describing your use-case and design decisions

If you have questions, need feedback, or want to validate an idea first, start a
thread in the GitHub Discussions board:
[AG-UI GitHub Discussions board](https://github.com/orgs/ag-ui-protocol/discussions).

Your integration might ship in the next release and help the entire AG-UI
ecosystem grow.

## Conclusion

You now have a fully-functional AG-UI server for OpenAI and a local playground
to test it. From here you can:

- Add tool calls to enhance your server
- Deploy your server to production
- Bring AG-UI to any other model or service

Happy building!



================================================
FILE: docs/sdk/js/encoder.mdx
================================================
---
title: "@ag-ui/encoder"
description: ""
---



================================================
FILE: docs/sdk/js/overview.mdx
================================================
[Empty file]


================================================
FILE: docs/sdk/js/proto.mdx
================================================
---
title: "@ag-ui/proto"
description: ""
---



================================================
FILE: docs/sdk/js/client/abstract-agent.mdx
================================================
---
title: "AbstractAgent"
description: "Base agent implementation with core event handling"
---

# AbstractAgent

The `AbstractAgent` class provides the foundation for all agent implementations
in the Agent User Interaction Protocol. It handles the core event stream
processing, state management, and message history.

```typescript
import { AbstractAgent } from "@ag-ui/client"
```

## Configuration

By default, all agents are configured by providing an optional `AgentConfig`
object to the constructor.

```typescript
interface AgentConfig {
  agentId?: string // The identifier of the agent
  description?: string // A description of the agent, used by the LLM
  threadId?: string // The conversation thread identifier
  initialMessages?: Message[] // An array of initial messages
  initialState?: State // The initial state of the agent
}
```

### Adding Configuration Options in your Subclass

To add additional configuration options, it is recommended to extend the
`AgentConfig` interface and call the super constructor with the extended config
from your subclass like this:

```typescript
interface MyAgentConfig extends AgentConfig {
  myConfigOption: string
}

class MyAgent extends AbstractAgent {
  private myConfigOption: string

  constructor(config: MyAgentConfig) {
    super(config)
    this.myConfigOption = config.myConfigOption
  }
}
```

## Core Methods

### runAgent()

The primary method for executing an agent and processing the result.

```typescript
runAgent(parameters?: RunAgentParameters, subscriber?: AgentSubscriber): Promise<RunAgentResult>
```

#### Parameters

```typescript
interface RunAgentParameters {
  runId?: string // Unique ID for this execution run
  tools?: Tool[] // Available tools for the agent
  context?: Context[] // Contextual information
  forwardedProps?: Record<string, any> // Additional properties to forward
}
```

The optional `subscriber` parameter allows you to provide an
[AgentSubscriber](/sdk/js/client/subscriber) for handling events during this
specific run.

#### Return Value

```typescript
interface RunAgentResult {
  result: any // The final result returned by the agent
  newMessages: Message[] // New messages added during this run
}
```

### subscribe()

Adds an [AgentSubscriber](/sdk/js/client/subscriber) to handle events across
multiple agent runs.

```typescript
subscribe(subscriber: AgentSubscriber): { unsubscribe: () => void }
```

Returns an object with an `unsubscribe()` method to remove the subscriber when
no longer needed.

### abortRun()

Cancels the current agent execution.

```typescript
abortRun(): void
```

### clone()

Creates a deep copy of the agent instance.

```typescript
clone(): AbstractAgent
```

## Properties

- `agentId`: Unique identifier for the agent instance
- `description`: Human-readable description
- `threadId`: Conversation thread identifier
- `messages`: Array of conversation messages
- `state`: Current agent state object

## Protected Methods

These methods are meant to be implemented or extended by subclasses:

### run()

Executes the agent and returns an observable event stream.

```typescript
protected abstract run(input: RunAgentInput): RunAgent
```

### apply()

Processes events from the run and updates the agent state.

```typescript
protected apply(input: RunAgentInput): ApplyEvents
```

### prepareRunAgentInput()

Prepares the input parameters for the agent execution.

```typescript
protected prepareRunAgentInput(parameters?: RunAgentParameters): RunAgentInput
```

### onError() and onFinalize()

Lifecycle hooks for error handling and cleanup operations.

```typescript
protected onError(error: Error): void
protected onFinalize(): void
```



================================================
FILE: docs/sdk/js/client/http-agent.mdx
================================================
---
title: "HttpAgent"
description: "HTTP-based agent for connecting to remote AI agents"
---

# HttpAgent

The `HttpAgent` extends `AbstractAgent` to provide HTTP-based connectivity to
remote AI agents. It handles the request/response cycle and transforms the HTTP
event stream into standard Agent User Interaction Protocol events.

```typescript
import { HttpAgent } from "@ag-ui/client"
```

## Configuration

When creating an HTTP agent, you need to provide an `HttpAgentConfig` object:

```typescript
interface HttpAgentConfig extends AgentConfig {
  url: string // Endpoint URL for the agent service
  headers?: Record<string, string> // Optional HTTP headers
}
```

## Creating an HttpAgent

```typescript
const agent = new HttpAgent({
  url: "https://api.example.com/v1/agent",
  headers: {
    Authorization: "Bearer your-api-key",
  },
})
```

## Methods

### runAgent()

Executes the agent by making an HTTP request to the configured endpoint.

```typescript
runAgent(parameters?: RunAgentParameters, subscriber?: AgentSubscriber): Promise<RunAgentResult>
```

#### Parameters

The `parameters` argument follows the standard `RunAgentParameters` interface.
The optional `subscriber` parameter allows you to provide an
[AgentSubscriber](/sdk/js/client/subscriber) for handling events during this
specific run.

#### Return Value

```typescript
interface RunAgentResult {
  result: any // The final result returned by the agent
  newMessages: Message[] // New messages added during this run
}
```

### subscribe()

Adds an [AgentSubscriber](/sdk/js/client/subscriber) to handle events across
multiple agent runs.

```typescript
subscribe(subscriber: AgentSubscriber): { unsubscribe: () => void }
```

Returns an object with an `unsubscribe()` method to remove the subscriber when
no longer needed.

### abortRun()

Cancels the current HTTP request using the AbortController.

```typescript
abortRun(): void
```

## Protected Methods

### requestInit()

Configures the HTTP request. Override this method to customize how requests are
made.

```typescript
protected requestInit(input: RunAgentInput): RequestInit
```

Default implementation:

```typescript
{
  method: "POST",
  headers: {
    ...this.headers,
    "Content-Type": "application/json",
    Accept: "text/event-stream",
  },
  body: JSON.stringify(input),
  signal: this.abortController.signal,
}
```

### run()

Implements the abstract `run()` method from `AbstractAgent` using HTTP requests.

```typescript
protected run(input: RunAgentInput): RunAgent
```

## Properties

- `url`: The endpoint URL for the agent service
- `headers`: HTTP headers to include with requests
- `abortController`: AbortController instance for request cancellation



================================================
FILE: docs/sdk/js/client/overview.mdx
================================================
---
title: "Overview"
description: "Client package overview"
---

# @ag-ui/client

The Agent User Interaction Protocol Client SDK provides agent connectivity
options for AI systems. This package builds on the core types and events to
deliver flexible connection methods to agent implementations.

```bash
npm install @ag-ui/client
```

## AbstractAgent

`AbstractAgent` is the base agent class for implementing custom agent
connectivity. Extending this class and implementing `run()` lets you bridge your
own service or agent implementation to AG-UI.

- [Configuration](/sdk/js/client/abstract-agent#configuration) - Setup with
  agent ID, messages, and state
- [Core Methods](/sdk/js/client/abstract-agent#core-methods) - Run, abort, and
  clone functionality
- [Protected Methods](/sdk/js/client/abstract-agent#protected-methods) -
  Extensible hooks for custom implementations
- [Properties](/sdk/js/client/abstract-agent#properties) - State and message
  tracking

<Card
  title="AbstractAgent Reference"
  icon="cube"
  href="/sdk/js/client/abstract-agent"
  color="#3B82F6"
  iconType="solid"
>
  Base class for creating custom agent connections
</Card>

## HttpAgent

Concrete implementation for HTTP-based agent connectivity:

- [Configuration](/sdk/js/client/http-agent#configuration) - URL and header
  setup
- [Methods](/sdk/js/client/http-agent#methods) - HTTP-specific execution and
  cancellation
- [Protected Methods](/sdk/js/client/http-agent#protected-methods) -
  Customizable HTTP request handling
- [Properties](/sdk/js/client/http-agent#properties) - Connection management

<Card
  title="HttpAgent Reference"
  icon="cube"
  href="/sdk/js/client/http-agent"
  color="#3B82F6"
  iconType="solid"
>
  Ready-to-use HTTP implementation for agent connectivity, using a highly
  efficient event encoding format
</Card>

## AgentSubscriber

Event-driven subscriber system for handling agent lifecycle events and state
mutations during agent execution:

- [Event Handlers](/sdk/js/client/subscriber#event-handlers) - Lifecycle,
  message, tool call, and state events
- [State Management](/sdk/js/client/subscriber#state-management) - Mutation
  control and propagation handling
- [Usage Examples](/sdk/js/client/subscriber#usage-examples) - Logging,
  persistence, and error handling patterns
- [Integration](/sdk/js/client/subscriber#integration-with-agents) - Registering
  and using subscribers with agents

<Card
  title="AgentSubscriber Reference"
  icon="bolt"
  href="/sdk/js/client/subscriber"
  color="#3B82F6"
  iconType="solid"
>
  Comprehensive event system for reactive agent interaction and middleware-style
  functionality
</Card>



================================================
FILE: docs/sdk/js/client/subscriber.mdx
================================================
---
title: "AgentSubscriber"
description:
  "Event-driven subscriber system for agent lifecycle and event handling"
---

# AgentSubscriber

The `AgentSubscriber` interface provides a comprehensive event-driven system for
handling agent lifecycle events, message updates, and state mutations during
agent execution. It allows you to hook into various stages of the agent's
operation and modify its behavior.

```typescript
import { AgentSubscriber } from "@ag-ui/client"
```

## Overview

`AgentSubscriber` defines a collection of optional event handlers and lifecycle
hooks that can respond to different stages of agent execution. All methods in
the interface are optional, allowing you to implement only the events you need
to handle.

All subscriber methods can be either synchronous or asynchronous - if they
return a Promise, the agent will await their completion before proceeding.

## Adding Subscribers to Agents

Subscribers can be added to agents in two ways:

### Permanent Subscription

Use the `subscribe()` method to add a subscriber that will persist across
multiple agent runs:

```typescript
const agent = new HttpAgent({ url: "https://api.example.com/agent" })

const subscriber: AgentSubscriber = {
  onTextMessageContentEvent: ({ textMessageBuffer }) => {
    console.log("Streaming text:", textMessageBuffer)
  },
}

// Add permanent subscriber
const subscription = agent.subscribe(subscriber)

// Later, remove the subscriber if needed
subscription.unsubscribe()
```

### Temporary Subscription

Pass a subscriber directly to `runAgent()` for one-time use:

```typescript
const temporarySubscriber: AgentSubscriber = {
  onRunFinishedEvent: ({ result }) => {
    console.log("Run completed with result:", result)
  },
}

// Use subscriber for this run only
await agent.runAgent({ tools: [myTool] }, temporarySubscriber)
```

## Core Interfaces

### AgentSubscriber

The main interface that defines all available event handlers and lifecycle
hooks. All methods in the interface are optional, allowing you to implement only
the events you need to handle.

### AgentStateMutation

Event handlers can return an `AgentStateMutation` object to modify the agent's
state and control event processing:

```typescript
interface AgentStateMutation {
  messages?: Message[] // Update the message history
  state?: State // Update the agent state
  stopPropagation?: boolean // Prevent further subscribers from processing this event
}
```

When a subscriber returns a mutation:

- **messages**: Replaces the current message history
- **state**: Replaces the current agent state
- **stopPropagation**: If `true`, prevents subsequent subscribers from handling
  the event (useful for overriding default behavior)

### AgentSubscriberParams

Common parameters passed to most subscriber methods:

```typescript
interface AgentSubscriberParams {
  messages: Message[] // Current message history
  state: State // Current agent state
  agent: AbstractAgent // The agent instance
  input: RunAgentInput // The original input parameters
}
```

## Event Handlers

### Lifecycle Events

#### onRunInitialized()

Called when the agent run is first initialized, before any processing begins.

```typescript
onRunInitialized?(params: AgentSubscriberParams): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>
```

#### onRunFailed()

Called when the agent run encounters an error.

```typescript
onRunFailed?(params: { error: Error } & AgentSubscriberParams): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>
```

#### onRunFinalized()

Called when the agent run completes, regardless of success or failure.

```typescript
onRunFinalized?(params: AgentSubscriberParams): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>
```

### Event Handlers

#### onEvent()

General event handler that receives all events during agent execution.

```typescript
onEvent?(params: { event: BaseEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onRunStartedEvent()

Triggered when an agent run begins execution.

```typescript
onRunStartedEvent?(params: { event: RunStartedEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onRunFinishedEvent()

Called when an agent run completes successfully.

```typescript
onRunFinishedEvent?(params: { event: RunFinishedEvent; result?: any } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onRunErrorEvent()

Triggered when an agent run encounters an error.

```typescript
onRunErrorEvent?(params: { event: RunErrorEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onStepStartedEvent()

Called when a step within an agent run begins.

```typescript
onStepStartedEvent?(params: { event: StepStartedEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onStepFinishedEvent()

Triggered when a step within an agent run completes.

```typescript
onStepFinishedEvent?(params: { event: StepFinishedEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

### Message Events

#### onTextMessageStartEvent()

Triggered when a text message starts being generated.

```typescript
onTextMessageStartEvent?(params: { event: TextMessageStartEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onTextMessageContentEvent()

Called for each chunk of text content as it's generated.

```typescript
onTextMessageContentEvent?(params: { event: TextMessageContentEvent; textMessageBuffer: string } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onTextMessageEndEvent()

Called when a text message generation is complete.

```typescript
onTextMessageEndEvent?(params: { event: TextMessageEndEvent; textMessageBuffer: string } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

### Tool Call Events

#### onToolCallStartEvent()

Triggered when a tool call begins.

```typescript
onToolCallStartEvent?(params: { event: ToolCallStartEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onToolCallArgsEvent()

Called as tool call arguments are being parsed, providing both raw and parsed
argument data.

```typescript
onToolCallArgsEvent?(params: { event: ToolCallArgsEvent; toolCallBuffer: string; toolCallName: string; partialToolCallArgs: Record<string, any> } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onToolCallEndEvent()

Called when a tool call is complete with final arguments.

```typescript
onToolCallEndEvent?(params: { event: ToolCallEndEvent; toolCallName: string; toolCallArgs: Record<string, any> } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onToolCallResultEvent()

Triggered when a tool call result is received.

```typescript
onToolCallResultEvent?(params: { event: ToolCallResultEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

### State Events

#### onStateSnapshotEvent()

Called when a complete state snapshot is provided.

```typescript
onStateSnapshotEvent?(params: { event: StateSnapshotEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onStateDeltaEvent()

Triggered when partial state changes are applied.

```typescript
onStateDeltaEvent?(params: { event: StateDeltaEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onMessagesSnapshotEvent()

Called when a complete message history snapshot is provided.

```typescript
onMessagesSnapshotEvent?(params: { event: MessagesSnapshotEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onRawEvent()

Handler for raw, unprocessed events.

```typescript
onRawEvent?(params: { event: RawEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

#### onCustomEvent()

Handler for custom application-specific events.

```typescript
onCustomEvent?(params: { event: CustomEvent } & AgentSubscriberParams): MaybePromise<AgentStateMutation | void>
```

### State Change Handlers

#### onMessagesChanged()

Called when the agent's message history is updated.

```typescript
onMessagesChanged?(params: Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput }): MaybePromise<void>
```

#### onStateChanged()

Triggered when the agent's state is modified.

```typescript
onStateChanged?(params: Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput }): MaybePromise<void>
```

#### onNewMessage()

Called when a new message is added to the conversation.

```typescript
onNewMessage?(params: { message: Message } & Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput }): MaybePromise<void>
```

#### onNewToolCall()

Triggered when a new tool call is added to a message.

```typescript
onNewToolCall?(params: { toolCall: ToolCall } & Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput }): MaybePromise<void>
```

## Async Support

All subscriber methods support both synchronous and asynchronous execution:

```typescript
const subscriber: AgentSubscriber = {
  // Synchronous handler
  onTextMessageContentEvent: ({ textMessageBuffer }) => {
    updateUI(textMessageBuffer)
  },

  // Asynchronous handler
  onStateChanged: async ({ state }) => {
    await saveStateToDatabase(state)
  },

  // Async handler with mutation
  onRunInitialized: async ({ messages, state }) => {
    const enrichedState = await loadUserPreferences()
    return {
      state: { ...state, ...enrichedState },
    }
  },
}
```

## Multiple Subscribers

Agents can have multiple subscribers, which are processed in the order they were
added:

```typescript
// First subscriber modifies state
const stateEnricher: AgentSubscriber = {
  onRunInitialized: ({ state }) => ({
    state: { ...state, timestamp: new Date().toISOString() },
  }),
}

// Second subscriber sees the modified state
const logger: AgentSubscriber = {
  onRunInitialized: ({ state }) => {
    console.log("State after enrichment:", state)
  },
}

agent.subscribe(stateEnricher)
agent.subscribe(logger)
```

## Integration with Agents

Basic usage pattern:

```typescript
const agent = new HttpAgent({ url: "https://api.example.com/agent" })

// Add persistent subscriber
agent.subscribe({
  onTextMessageContentEvent: ({ textMessageBuffer }) => {
    updateStreamingUI(textMessageBuffer)
  },
  onRunFinishedEvent: ({ result }) => {
    displayFinalResult(result)
  },
})

// Run agent (subscriber will be called automatically)
const result = await agent.runAgent({
  tools: [myTool],
})
```



================================================
FILE: docs/sdk/js/core/events.mdx
================================================
---
title: "Events"
description:
  "Documentation for the events used in the Agent User Interaction Protocol SDK"
---

# Events

The Agent User Interaction Protocol SDK uses a streaming event-based
architecture. Events are the fundamental units of communication between agents
and the frontend. This section documents the event types and their properties.

## EventType Enum

The `EventType` enum defines all possible event types in the system:

```typescript
enum EventType {
  TEXT_MESSAGE_START = "TEXT_MESSAGE_START",
  TEXT_MESSAGE_CONTENT = "TEXT_MESSAGE_CONTENT",
  TEXT_MESSAGE_END = "TEXT_MESSAGE_END",
  TOOL_CALL_START = "TOOL_CALL_START",
  TOOL_CALL_ARGS = "TOOL_CALL_ARGS",
  TOOL_CALL_END = "TOOL_CALL_END",
  TOOL_CALL_RESULT = "TOOL_CALL_RESULT",
  STATE_SNAPSHOT = "STATE_SNAPSHOT",
  STATE_DELTA = "STATE_DELTA",
  MESSAGES_SNAPSHOT = "MESSAGES_SNAPSHOT",
  RAW = "RAW",
  CUSTOM = "CUSTOM",
  RUN_STARTED = "RUN_STARTED",
  RUN_FINISHED = "RUN_FINISHED",
  RUN_ERROR = "RUN_ERROR",
  STEP_STARTED = "STEP_STARTED",
  STEP_FINISHED = "STEP_FINISHED",
}
```

## BaseEvent

All events inherit from the `BaseEvent` type, which provides common properties
shared across all event types.

```typescript
type BaseEvent = {
  type: EventType // Discriminator field
  timestamp?: number
  rawEvent?: any
}
```

| Property    | Type                | Description                                           |
| ----------- | ------------------- | ----------------------------------------------------- |
| `type`      | `EventType`         | The type of event (discriminator field for the union) |
| `timestamp` | `number` (optional) | Timestamp when the event was created                  |
| `rawEvent`  | `any` (optional)    | Original event data if this event was transformed     |

## Lifecycle Events

These events represent the lifecycle of an agent run.

### RunStartedEvent

Signals the start of an agent run.

```typescript
type RunStartedEvent = BaseEvent & {
  type: EventType.RUN_STARTED
  threadId: string
  runId: string
}
```

| Property   | Type     | Description                   |
| ---------- | -------- | ----------------------------- |
| `threadId` | `string` | ID of the conversation thread |
| `runId`    | `string` | ID of the agent run           |

### RunFinishedEvent

Signals the successful completion of an agent run.

```typescript
type RunFinishedEvent = BaseEvent & {
  type: EventType.RUN_FINISHED
  threadId: string
  runId: string
  result?: any
}
```

| Property   | Type             | Description                    |
| ---------- | ---------------- | ------------------------------ |
| `threadId` | `string`         | ID of the conversation thread  |
| `runId`    | `string`         | ID of the agent run            |
| `result`   | `any` (optional) | Result data from the agent run |

### RunErrorEvent

Signals an error during an agent run.

```typescript
type RunErrorEvent = BaseEvent & {
  type: EventType.RUN_ERROR
  message: string
  code?: string
}
```

| Property  | Type                | Description   |
| --------- | ------------------- | ------------- |
| `message` | `string`            | Error message |
| `code`    | `string` (optional) | Error code    |

### StepStartedEvent

Signals the start of a step within an agent run.

```typescript
type StepStartedEvent = BaseEvent & {
  type: EventType.STEP_STARTED
  stepName: string
}
```

| Property   | Type     | Description      |
| ---------- | -------- | ---------------- |
| `stepName` | `string` | Name of the step |

### StepFinishedEvent

Signals the completion of a step within an agent run.

```typescript
type StepFinishedEvent = BaseEvent & {
  type: EventType.STEP_FINISHED
  stepName: string
}
```

| Property   | Type     | Description      |
| ---------- | -------- | ---------------- |
| `stepName` | `string` | Name of the step |

## Text Message Events

These events represent the lifecycle of text messages in a conversation.

### TextMessageStartEvent

Signals the start of a text message.

```typescript
type TextMessageStartEvent = BaseEvent & {
  type: EventType.TEXT_MESSAGE_START
  messageId: string
  role: "assistant"
}
```

| Property    | Type          | Description                       |
| ----------- | ------------- | --------------------------------- |
| `messageId` | `string`      | Unique identifier for the message |
| `role`      | `"assistant"` | Role is always "assistant"        |

### TextMessageContentEvent

Represents a chunk of content in a streaming text message.

```typescript
type TextMessageContentEvent = BaseEvent & {
  type: EventType.TEXT_MESSAGE_CONTENT
  messageId: string
  delta: string // Non-empty string
}
```

| Property    | Type     | Description                               |
| ----------- | -------- | ----------------------------------------- |
| `messageId` | `string` | Matches the ID from TextMessageStartEvent |
| `delta`     | `string` | Text content chunk (non-empty)            |

### TextMessageEndEvent

Signals the end of a text message.

```typescript
type TextMessageEndEvent = BaseEvent & {
  type: EventType.TEXT_MESSAGE_END
  messageId: string
}
```

| Property    | Type     | Description                               |
| ----------- | -------- | ----------------------------------------- |
| `messageId` | `string` | Matches the ID from TextMessageStartEvent |

## Tool Call Events

These events represent the lifecycle of tool calls made by agents.

### ToolCallStartEvent

Signals the start of a tool call.

```typescript
type ToolCallStartEvent = BaseEvent & {
  type: EventType.TOOL_CALL_START
  toolCallId: string
  toolCallName: string
  parentMessageId?: string
}
```

| Property          | Type                | Description                         |
| ----------------- | ------------------- | ----------------------------------- |
| `toolCallId`      | `string`            | Unique identifier for the tool call |
| `toolCallName`    | `string`            | Name of the tool being called       |
| `parentMessageId` | `string` (optional) | ID of the parent message            |

### ToolCallArgsEvent

Represents a chunk of argument data for a tool call.

```typescript
type ToolCallArgsEvent = BaseEvent & {
  type: EventType.TOOL_CALL_ARGS
  toolCallId: string
  delta: string
}
```

| Property     | Type     | Description                            |
| ------------ | -------- | -------------------------------------- |
| `toolCallId` | `string` | Matches the ID from ToolCallStartEvent |
| `delta`      | `string` | Argument data chunk                    |

### ToolCallEndEvent

Signals the end of a tool call.

```typescript
type ToolCallEndEvent = BaseEvent & {
  type: EventType.TOOL_CALL_END
  toolCallId: string
}
```

| Property     | Type     | Description                            |
| ------------ | -------- | -------------------------------------- |
| `toolCallId` | `string` | Matches the ID from ToolCallStartEvent |

### ToolCallResultEvent

Provides the result of a tool call execution.

```typescript
type ToolCallResultEvent = BaseEvent & {
  type: EventType.TOOL_CALL_RESULT
  messageId: string
  toolCallId: string
  content: string
  role?: "tool"
}
```

| Property     | Type                | Description                                                 |
| ------------ | ------------------- | ----------------------------------------------------------- |
| `messageId`  | `string`            | ID of the conversation message this result belongs to       |
| `toolCallId` | `string`            | Matches the ID from the corresponding ToolCallStartEvent    |
| `content`    | `string`            | The actual result/output content from the tool execution    |
| `role`       | `"tool"` (optional) | Optional role identifier, typically "tool" for tool results |

## State Management Events

These events are used to manage agent state.

### StateSnapshotEvent

Provides a complete snapshot of an agent's state.

```typescript
type StateSnapshotEvent = BaseEvent & {
  type: EventType.STATE_SNAPSHOT
  snapshot: any // StateSchema
}
```

| Property   | Type  | Description             |
| ---------- | ----- | ----------------------- |
| `snapshot` | `any` | Complete state snapshot |

### StateDeltaEvent

Provides a partial update to an agent's state using JSON Patch.

```typescript
type StateDeltaEvent = BaseEvent & {
  type: EventType.STATE_DELTA
  delta: any[] // JSON Patch operations (RFC 6902)
}
```

| Property | Type    | Description                    |
| -------- | ------- | ------------------------------ |
| `delta`  | `any[]` | Array of JSON Patch operations |

### MessagesSnapshotEvent

Provides a snapshot of all messages in a conversation.

```typescript
type MessagesSnapshotEvent = BaseEvent & {
  type: EventType.MESSAGES_SNAPSHOT
  messages: Message[]
}
```

| Property   | Type        | Description              |
| ---------- | ----------- | ------------------------ |
| `messages` | `Message[]` | Array of message objects |

## Special Events

### RawEvent

Used to pass through events from external systems.

```typescript
type RawEvent = BaseEvent & {
  type: EventType.RAW
  event: any
  source?: string
}
```

| Property | Type                | Description         |
| -------- | ------------------- | ------------------- |
| `event`  | `any`               | Original event data |
| `source` | `string` (optional) | Source of the event |

### CustomEvent

Used for application-specific custom events.

```typescript
type CustomEvent = BaseEvent & {
  type: EventType.CUSTOM
  name: string
  value: any
}
```

| Property | Type     | Description                     |
| -------- | -------- | ------------------------------- |
| `name`   | `string` | Name of the custom event        |
| `value`  | `any`    | Value associated with the event |

## Event Schemas

The SDK uses Zod schemas to validate events:

```typescript
const EventSchemas = z.discriminatedUnion("type", [
  TextMessageStartEventSchema,
  TextMessageContentEventSchema,
  TextMessageEndEventSchema,
  ToolCallStartEventSchema,
  ToolCallArgsEventSchema,
  ToolCallEndEventSchema,
  ToolCallResultEventSchema,
  StateSnapshotEventSchema,
  StateDeltaEventSchema,
  MessagesSnapshotEventSchema,
  RawEventSchema,
  CustomEventSchema,
  RunStartedEventSchema,
  RunFinishedEventSchema,
  RunErrorEventSchema,
  StepStartedEventSchema,
  StepFinishedEventSchema,
])
```

This allows for runtime validation of events and provides TypeScript type
inference.



================================================
FILE: docs/sdk/js/core/overview.mdx
================================================
---
title: "Overview"
description: "Core concepts in the Agent User Interaction Protocol SDK"
---

# @ag-ui/core

The Agent User Interaction Protocol SDK uses a streaming event-based
architecture with strongly typed data structures. This package provides the
foundation for connecting to agent systems.

```bash
npm install @ag-ui/core
```

## Types

Core data structures that represent the building blocks of the system:

- [RunAgentInput](/sdk/js/core/types#runagentinput) - Input parameters for
  running agents
- [Message](/sdk/js/core/types#message-types) - User assistant communication and
  tool usage
- [Context](/sdk/js/core/types#context) - Contextual information provided to
  agents
- [Tool](/sdk/js/core/types#tool) - Defines functions that agents can call
- [State](/sdk/js/core/types#state) - Agent state management

<Card
  title="Types Reference"
  icon="cube"
  href="/sdk/js/core/types"
  color="#3B82F6"
  iconType="solid"
>
  Complete documentation of all types in the @ag-ui/core package
</Card>

## Events

Events that power communication between agents and frontends:

- [Lifecycle Events](/sdk/js/core/events#lifecycle-events) - Run and step
  tracking
- [Text Message Events](/sdk/js/core/events#text-message-events) - Assistant
  message streaming
- [Tool Call Events](/sdk/js/core/events#tool-call-events) - Function call
  lifecycle
- [State Management Events](/sdk/js/core/events#state-management-events) - Agent
  state updates
- [Special Events](/sdk/js/core/events#special-events) - Raw and custom events

<Card
  title="Events Reference"
  icon="cube"
  href="/sdk/js/core/events"
  color="#3B82F6"
  iconType="solid"
>
  Complete documentation of all events in the @ag-ui/core package
</Card>



================================================
FILE: docs/sdk/js/core/types.mdx
================================================
---
title: "Types"
description:
  "Documentation for the core types used in the Agent User Interaction Protocol
  SDK"
---

# Core Types

The Agent User Interaction Protocol SDK is built on a set of core types that
represent the fundamental structures used throughout the system. This page
documents these types and their properties.

## RunAgentInput

Input parameters for running an agent. In the HTTP API, this is the body of the
`POST` request.

```typescript
type RunAgentInput = {
  threadId: string
  runId: string
  state: any
  messages: Message[]
  tools: Tool[]
  context: Context[]
  forwardedProps: any
}
```

| Property         | Type        | Description                                    |
| ---------------- | ----------- | ---------------------------------------------- |
| `threadId`       | `string`    | ID of the conversation thread                  |
| `runId`          | `string`    | ID of the current run                          |
| `state`          | `any`       | Current state of the agent                     |
| `messages`       | `Message[]` | Array of messages in the conversation          |
| `tools`          | `Tool[]`    | Array of tools available to the agent          |
| `context`        | `Context[]` | Array of context objects provided to the agent |
| `forwardedProps` | `any`       | Additional properties forwarded to the agent   |

## Message Types

The SDK includes several message types that represent different kinds of
messages in the system.

### Role

Represents the possible roles a message sender can have.

```typescript
type Role = "developer" | "system" | "assistant" | "user" | "tool"
```

### DeveloperMessage

Represents a message from a developer.

```typescript
type DeveloperMessage = {
  id: string
  role: "developer"
  content: string
  name?: string
}
```

| Property  | Type          | Description                                      |
| --------- | ------------- | ------------------------------------------------ |
| `id`      | `string`      | Unique identifier for the message                |
| `role`    | `"developer"` | Role of the message sender, fixed as "developer" |
| `content` | `string`      | Text content of the message (required)           |
| `name`    | `string`      | Optional name of the sender                      |

### SystemMessage

Represents a system message.

```typescript
type SystemMessage = {
  id: string
  role: "system"
  content: string
  name?: string
}
```

| Property  | Type       | Description                                   |
| --------- | ---------- | --------------------------------------------- |
| `id`      | `string`   | Unique identifier for the message             |
| `role`    | `"system"` | Role of the message sender, fixed as "system" |
| `content` | `string`   | Text content of the message (required)        |
| `name`    | `string`   | Optional name of the sender                   |

### AssistantMessage

Represents a message from an assistant.

```typescript
type AssistantMessage = {
  id: string
  role: "assistant"
  content?: string
  name?: string
  toolCalls?: ToolCall[]
}
```

| Property    | Type                    | Description                                      |
| ----------- | ----------------------- | ------------------------------------------------ |
| `id`        | `string`                | Unique identifier for the message                |
| `role`      | `"assistant"`           | Role of the message sender, fixed as "assistant" |
| `content`   | `string` (optional)     | Text content of the message                      |
| `name`      | `string` (optional)     | Name of the sender                               |
| `toolCalls` | `ToolCall[]` (optional) | Tool calls made in this message                  |

### UserMessage

Represents a message from a user.

```typescript
type UserMessage = {
  id: string
  role: "user"
  content: string
  name?: string
}
```

| Property  | Type     | Description                                 |
| --------- | -------- | ------------------------------------------- |
| `id`      | `string` | Unique identifier for the message           |
| `role`    | `"user"` | Role of the message sender, fixed as "user" |
| `content` | `string` | Text content of the message (required)      |
| `name`    | `string` | Optional name of the sender                 |

### ToolMessage

Represents a message from a tool.

```typescript
type ToolMessage = {
  id: string
  content: string
  role: "tool"
  toolCallId: string
  error?: string
}
```

| Property     | Type     | Description                                  |
| ------------ | -------- | -------------------------------------------- |
| `id`         | `string` | Unique identifier for the message            |
| `content`    | `string` | Text content of the message                  |
| `role`       | `"tool"` | Role of the message sender, fixed as "tool"  |
| `toolCallId` | `string` | ID of the tool call this message responds to |
| `error`      | `string` | Error message if the tool call failed        |

### Message

A union type representing any type of message in the system.

```typescript
type Message =
  | DeveloperMessage
  | SystemMessage
  | AssistantMessage
  | UserMessage
  | ToolMessage
```

### ToolCall

Represents a tool call made by an agent.

```typescript
type ToolCall = {
  id: string
  type: "function"
  function: FunctionCall
}
```

| Property   | Type           | Description                              |
| ---------- | -------------- | ---------------------------------------- |
| `id`       | `string`       | Unique identifier for the tool call      |
| `type`     | `"function"`   | Type of the tool call, always "function" |
| `function` | `FunctionCall` | Details about the function being called  |

#### FunctionCall

Represents function name and arguments in a tool call.

```typescript
type FunctionCall = {
  name: string
  arguments: string
}
```

| Property    | Type     | Description                                      |
| ----------- | -------- | ------------------------------------------------ |
| `name`      | `string` | Name of the function to call                     |
| `arguments` | `string` | JSON-encoded string of arguments to the function |

## Context

Represents a piece of contextual information provided to an agent.

```typescript
type Context = {
  description: string
  value: string
}
```

| Property      | Type     | Description                                 |
| ------------- | -------- | ------------------------------------------- |
| `description` | `string` | Description of what this context represents |
| `value`       | `string` | The actual context value                    |

## Tool

Defines a tool that can be called by an agent.

```typescript
type Tool = {
  name: string
  description: string
  parameters: any // JSON Schema
}
```

| Property      | Type     | Description                                      |
| ------------- | -------- | ------------------------------------------------ |
| `name`        | `string` | Name of the tool                                 |
| `description` | `string` | Description of what the tool does                |
| `parameters`  | `any`    | JSON Schema defining the parameters for the tool |

## State

Represents the state of an agent during execution.

```typescript
type State = any
```

The state type is flexible and can hold any data structure needed by the agent
implementation.



================================================
FILE: docs/sdk/python/core/events.mdx
================================================
---
title: "Events"
description:
  "Documentation for the events used in the Agent User Interaction Protocol
  Python SDK"
---

# Events

The Agent User Interaction Protocol Python SDK uses a streaming event-based
architecture. Events are the fundamental units of communication between agents
and the frontend. This section documents the event types and their properties.

## EventType Enum

`from ag_ui.core import EventType`

The `EventType` enum defines all possible event types in the system:

```python
class EventType(str, Enum):
    TEXT_MESSAGE_START = "TEXT_MESSAGE_START"
    TEXT_MESSAGE_CONTENT = "TEXT_MESSAGE_CONTENT"
    TEXT_MESSAGE_END = "TEXT_MESSAGE_END"
    TOOL_CALL_START = "TOOL_CALL_START"
    TOOL_CALL_ARGS = "TOOL_CALL_ARGS"
    TOOL_CALL_END = "TOOL_CALL_END"
    TOOL_CALL_RESULT = "TOOL_CALL_RESULT"
    STATE_SNAPSHOT = "STATE_SNAPSHOT"
    STATE_DELTA = "STATE_DELTA"
    MESSAGES_SNAPSHOT = "MESSAGES_SNAPSHOT"
    RAW = "RAW"
    CUSTOM = "CUSTOM"
    RUN_STARTED = "RUN_STARTED"
    RUN_FINISHED = "RUN_FINISHED"
    RUN_ERROR = "RUN_ERROR"
    STEP_STARTED = "STEP_STARTED"
    STEP_FINISHED = "STEP_FINISHED"
```

## BaseEvent

`from ag_ui.core import BaseEvent`

All events inherit from the `BaseEvent` class, which provides common properties
shared across all event types.

```python
class BaseEvent(ConfiguredBaseModel):
    type: EventType
    timestamp: Optional[int] = None
    raw_event: Optional[Any] = None
```

| Property    | Type            | Description                                           |
| ----------- | --------------- | ----------------------------------------------------- |
| `type`      | `EventType`     | The type of event (discriminator field for the union) |
| `timestamp` | `Optional[int]` | Timestamp when the event was created                  |
| `raw_event` | `Optional[Any]` | Original event data if this event was transformed     |

## Lifecycle Events

These events represent the lifecycle of an agent run.

### RunStartedEvent

`from ag_ui.core import RunStartedEvent`

Signals the start of an agent run.

```python
class RunStartedEvent(BaseEvent):
    type: Literal[EventType.RUN_STARTED]
    thread_id: str
    run_id: str
```

| Property    | Type  | Description                   |
| ----------- | ----- | ----------------------------- |
| `thread_id` | `str` | ID of the conversation thread |
| `run_id`    | `str` | ID of the agent run           |

### RunFinishedEvent

`from ag_ui.core import RunFinishedEvent`

Signals the successful completion of an agent run.

```python
class RunFinishedEvent(BaseEvent):
    type: Literal[EventType.RUN_FINISHED]
    thread_id: str
    run_id: str
    result: Optional[Any] = None
```

| Property    | Type            | Description                    |
| ----------- | --------------- | ------------------------------ |
| `thread_id` | `str`           | ID of the conversation thread  |
| `run_id`    | `str`           | ID of the agent run            |
| `result`    | `Optional[Any]` | Result data from the agent run |

### RunErrorEvent

`from ag_ui.core import RunErrorEvent`

Signals an error during an agent run.

```python
class RunErrorEvent(BaseEvent):
    type: Literal[EventType.RUN_ERROR]
    message: str
    code: Optional[str] = None
```

| Property  | Type            | Description   |
| --------- | --------------- | ------------- |
| `message` | `str`           | Error message |
| `code`    | `Optional[str]` | Error code    |

### StepStartedEvent

`from ag_ui.core import StepStartedEvent`

Signals the start of a step within an agent run.

```python
class StepStartedEvent(BaseEvent):
    type: Literal[EventType.STEP_STARTED]
    step_name: str
```

| Property    | Type  | Description      |
| ----------- | ----- | ---------------- |
| `step_name` | `str` | Name of the step |

### StepFinishedEvent

`from ag_ui.core import StepFinishedEvent`

Signals the completion of a step within an agent run.

```python
class StepFinishedEvent(BaseEvent):
    type: Literal[EventType.STEP_FINISHED]
    step_name: str
```

| Property    | Type  | Description      |
| ----------- | ----- | ---------------- |
| `step_name` | `str` | Name of the step |

## Text Message Events

These events represent the lifecycle of text messages in a conversation.

### TextMessageStartEvent

`from ag_ui.core import TextMessageStartEvent`

Signals the start of a text message.

```python
class TextMessageStartEvent(BaseEvent):
    type: Literal[EventType.TEXT_MESSAGE_START]
    message_id: str
    role: Literal["assistant"]
```

| Property     | Type                   | Description                       |
| ------------ | ---------------------- | --------------------------------- |
| `message_id` | `str`                  | Unique identifier for the message |
| `role`       | `Literal["assistant"]` | Role is always "assistant"        |

### TextMessageContentEvent

`from ag_ui.core import TextMessageContentEvent`

Represents a chunk of content in a streaming text message.

```python
class TextMessageContentEvent(BaseEvent):
    type: Literal[EventType.TEXT_MESSAGE_CONTENT]
    message_id: str
    delta: str  # Non-empty string

    def model_post_init(self, __context):
        if len(self.delta) == 0:
            raise ValueError("Delta must not be an empty string")
```

| Property     | Type  | Description                               |
| ------------ | ----- | ----------------------------------------- |
| `message_id` | `str` | Matches the ID from TextMessageStartEvent |
| `delta`      | `str` | Text content chunk (non-empty)            |

### TextMessageEndEvent

`from ag_ui.core import TextMessageEndEvent`

Signals the end of a text message.

```python
class TextMessageEndEvent(BaseEvent):
    type: Literal[EventType.TEXT_MESSAGE_END]
    message_id: str
```

| Property     | Type  | Description                               |
| ------------ | ----- | ----------------------------------------- |
| `message_id` | `str` | Matches the ID from TextMessageStartEvent |

## Tool Call Events

These events represent the lifecycle of tool calls made by agents.

### ToolCallStartEvent

`from ag_ui.core import ToolCallStartEvent`

Signals the start of a tool call.

```python
class ToolCallStartEvent(BaseEvent):
    type: Literal[EventType.TOOL_CALL_START]
    tool_call_id: str
    tool_call_name: str
    parent_message_id: Optional[str] = None
```

| Property            | Type            | Description                         |
| ------------------- | --------------- | ----------------------------------- |
| `tool_call_id`      | `str`           | Unique identifier for the tool call |
| `tool_call_name`    | `str`           | Name of the tool being called       |
| `parent_message_id` | `Optional[str]` | ID of the parent message            |

### ToolCallArgsEvent

`from ag_ui.core import ToolCallArgsEvent`

Represents a chunk of argument data for a tool call.

```python
class ToolCallArgsEvent(BaseEvent):
    type: Literal[EventType.TOOL_CALL_ARGS]
    tool_call_id: str
    delta: str
```

| Property       | Type  | Description                            |
| -------------- | ----- | -------------------------------------- |
| `tool_call_id` | `str` | Matches the ID from ToolCallStartEvent |
| `delta`        | `str` | Argument data chunk                    |

### ToolCallEndEvent

`from ag_ui.core import ToolCallEndEvent`

Signals the end of a tool call.

```python
class ToolCallEndEvent(BaseEvent):
    type: Literal[EventType.TOOL_CALL_END]
    tool_call_id: str
```

| Property       | Type  | Description                            |
| -------------- | ----- | -------------------------------------- |
| `tool_call_id` | `str` | Matches the ID from ToolCallStartEvent |

### ToolCallResultEvent

`from ag_ui.core import ToolCallResultEvent`

Provides the result of a tool call execution.

```python
class ToolCallResultEvent(BaseEvent):
    message_id: str
    type: Literal[EventType.TOOL_CALL_RESULT]
    tool_call_id: str
    content: str
    role: Optional[Literal["tool"]] = None
```

| Property       | Type                        | Description                                                 |
| -------------- | --------------------------- | ----------------------------------------------------------- |
| `message_id`   | `str`                       | ID of the conversation message this result belongs to       |
| `tool_call_id` | `str`                       | Matches the ID from the corresponding ToolCallStartEvent    |
| `content`      | `str`                       | The actual result/output content from the tool execution    |
| `role`         | `Optional[Literal["tool"]]` | Optional role identifier, typically "tool" for tool results |

## State Management Events

These events are used to manage agent state.

### StateSnapshotEvent

`from ag_ui.core import StateSnapshotEvent`

Provides a complete snapshot of an agent's state.

```python
class StateSnapshotEvent(BaseEvent):
    type: Literal[EventType.STATE_SNAPSHOT]
    snapshot: State
```

| Property   | Type    | Description             |
| ---------- | ------- | ----------------------- |
| `snapshot` | `State` | Complete state snapshot |

### StateDeltaEvent

`from ag_ui.core import StateDeltaEvent`

Provides a partial update to an agent's state using JSON Patch.

```python
class StateDeltaEvent(BaseEvent):
    type: Literal[EventType.STATE_DELTA]
    delta: List[Any]  # JSON Patch (RFC 6902)
```

| Property | Type        | Description                    |
| -------- | ----------- | ------------------------------ |
| `delta`  | `List[Any]` | Array of JSON Patch operations |

### MessagesSnapshotEvent

`from ag_ui.core import MessagesSnapshotEvent`

Provides a snapshot of all messages in a conversation.

```python
class MessagesSnapshotEvent(BaseEvent):
    type: Literal[EventType.MESSAGES_SNAPSHOT]
    messages: List[Message]
```

| Property   | Type            | Description              |
| ---------- | --------------- | ------------------------ |
| `messages` | `List[Message]` | Array of message objects |

## Special Events

### RawEvent

`from ag_ui.core import RawEvent`

Used to pass through events from external systems.

```python
class RawEvent(BaseEvent):
    type: Literal[EventType.RAW]
    event: Any
    source: Optional[str] = None
```

| Property | Type            | Description         |
| -------- | --------------- | ------------------- |
| `event`  | `Any`           | Original event data |
| `source` | `Optional[str]` | Source of the event |

### CustomEvent

`from ag_ui.core import CustomEvent`

Used for application-specific custom events.

```python
class CustomEvent(BaseEvent):
    type: Literal[EventType.CUSTOM]
    name: str
    value: Any
```

| Property | Type  | Description                     |
| -------- | ----- | ------------------------------- |
| `name`   | `str` | Name of the custom event        |
| `value`  | `Any` | Value associated with the event |

## Event Discrimination

`from ag_ui.core import Event`

The SDK uses Pydantic's discriminated unions for event validation:

```python
Event = Annotated[
    Union[
        TextMessageStartEvent,
        TextMessageContentEvent,
        TextMessageEndEvent,
        ToolCallStartEvent,
        ToolCallArgsEvent,
        ToolCallEndEvent,
        ToolCallResultEvent,
        StateSnapshotEvent,
        StateDeltaEvent,
        MessagesSnapshotEvent,
        RawEvent,
        CustomEvent,
        RunStartedEvent,
        RunFinishedEvent,
        RunErrorEvent,
        StepStartedEvent,
        StepFinishedEvent,
    ],
    Field(discriminator="type")
]
```

This allows for runtime validation of events and type checking at development
time.



================================================
FILE: docs/sdk/python/core/overview.mdx
================================================
---
title: "Overview"
description: "Core concepts in the Agent User Interaction Protocol SDK"
---

```bash
pip install ag-ui-protocol
```

# ag_ui.core

The Agent User Interaction Protocol SDK uses a streaming event-based
architecture with strongly typed data structures. This package provides the
foundation for connecting to agent systems.

```python
from ag_ui.core import ...
```

## Types

Core data structures that represent the building blocks of the system:

- [RunAgentInput](/sdk/python/core/types#runagentinput) - Input parameters for
  running agents
- [Message](/sdk/python/core/types#message-types) - User assistant communication
  and tool usage
- [Context](/sdk/python/core/types#context) - Contextual information provided to
  agents
- [Tool](/sdk/python/core/types#tool) - Defines functions that agents can call
- [State](/sdk/python/core/types#state) - Agent state management

<Card
  title="Types Reference"
  icon="cube"
  href="/sdk/python/core/types"
  color="#3B82F6"
  iconType="solid"
>
  Complete documentation of all types in the ag_ui.core package
</Card>

## Events

Events that power communication between agents and frontends:

- [Lifecycle Events](/sdk/python/core/events#lifecycle-events) - Run and step
  tracking
- [Text Message Events](/sdk/python/core/events#text-message-events) - Assistant
  message streaming
- [Tool Call Events](/sdk/python/core/events#tool-call-events) - Function call
  lifecycle
- [State Management Events](/sdk/python/core/events#state-management-events) -
  Agent state updates
- [Special Events](/sdk/python/core/events#special-events) - Raw and custom
  events

<Card
  title="Events Reference"
  icon="cube"
  href="/sdk/python/core/events"
  color="#3B82F6"
  iconType="solid"
>
  Complete documentation of all events in the ag_ui.core package
</Card>



================================================
FILE: docs/sdk/python/core/types.mdx
================================================
---
title: "Types"
description:
  "Documentation for the core types used in the Agent User Interaction Protocol
  Python SDK"
---

# Core Types

The Agent User Interaction Protocol Python SDK is built on a set of core types
that represent the fundamental structures used throughout the system. This page
documents these types and their properties.

## RunAgentInput

`from ag_ui.core import RunAgentInput`

Input parameters for running an agent. In the HTTP API, this is the body of the
`POST` request.

```python
class RunAgentInput(ConfiguredBaseModel):
    thread_id: str
    run_id: str
    state: Any
    messages: List[Message]
    tools: List[Tool]
    context: List[Context]
    forwarded_props: Any
```

| Property          | Type            | Description                                   |
| ----------------- | --------------- | --------------------------------------------- |
| `thread_id`       | `str`           | ID of the conversation thread                 |
| `run_id`          | `str`           | ID of the current run                         |
| `state`           | `Any`           | Current state of the agent                    |
| `messages`        | `List[Message]` | List of messages in the conversation          |
| `tools`           | `List[Tool]`    | List of tools available to the agent          |
| `context`         | `List[Context]` | List of context objects provided to the agent |
| `forwarded_props` | `Any`           | Additional properties forwarded to the agent  |

## Message Types

The SDK includes several message types that represent different kinds of
messages in the system.

### Role

`from ag_ui.core import Role`

Represents the possible roles a message sender can have.

```python
Role = Literal["developer", "system", "assistant", "user", "tool"]
```

### DeveloperMessage

`from ag_ui.core import DeveloperMessage`

Represents a message from a developer.

```python
class DeveloperMessage(BaseMessage):
    role: Literal["developer"]
    content: str
```

| Property  | Type                   | Description                                      |
| --------- | ---------------------- | ------------------------------------------------ |
| `id`      | `str`                  | Unique identifier for the message                |
| `role`    | `Literal["developer"]` | Role of the message sender, fixed as "developer" |
| `content` | `str`                  | Text content of the message (required)           |
| `name`    | `Optional[str]`        | Optional name of the sender                      |

### SystemMessage

`from ag_ui.core import SystemMessage`

Represents a system message.

```python
class SystemMessage(BaseMessage):
    role: Literal["system"]
    content: str
```

| Property  | Type                | Description                                   |
| --------- | ------------------- | --------------------------------------------- |
| `id`      | `str`               | Unique identifier for the message             |
| `role`    | `Literal["system"]` | Role of the message sender, fixed as "system" |
| `content` | `str`               | Text content of the message (required)        |
| `name`    | `Optional[str]`     | Optional name of the sender                   |

### AssistantMessage

`from ag_ui.core import AssistantMessage`

Represents a message from an assistant.

```python
class AssistantMessage(BaseMessage):
    role: Literal["assistant"]
    content: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None
```

| Property     | Type                       | Description                                      |
| ------------ | -------------------------- | ------------------------------------------------ |
| `id`         | `str`                      | Unique identifier for the message                |
| `role`       | `Literal["assistant"]`     | Role of the message sender, fixed as "assistant" |
| `content`    | `Optional[str]`            | Text content of the message                      |
| `name`       | `Optional[str]`            | Name of the sender                               |
| `tool_calls` | `Optional[List[ToolCall]]` | Tool calls made in this message                  |

### UserMessage

`from ag_ui.core import UserMessage`

Represents a message from a user.

```python
class UserMessage(BaseMessage):
    role: Literal["user"]
    content: str
```

| Property  | Type              | Description                                 |
| --------- | ----------------- | ------------------------------------------- |
| `id`      | `str`             | Unique identifier for the message           |
| `role`    | `Literal["user"]` | Role of the message sender, fixed as "user" |
| `content` | `str`             | Text content of the message (required)      |
| `name`    | `Optional[str]`   | Optional name of the sender                 |

### ToolMessage

`from ag_ui.core import ToolMessage`

Represents a message from a tool.

```python
class ToolMessage(ConfiguredBaseModel):
    id: str
    role: Literal["tool"]
    content: str
    tool_call_id: str
    error: Optional[str] = None
```

| Property       | Type              | Description                                  |
| -------------- | ----------------- | -------------------------------------------- |
| `id`           | `str`             | Unique identifier for the message            |
| `content`      | `str`             | Text content of the message                  |
| `role`         | `Literal["tool"]` | Role of the message sender, fixed as "tool"  |
| `tool_call_id` | `str`             | ID of the tool call this message responds to |
| `error`        | `Optional[str]`   | Error message if the tool call failed        |

### Message

`from ag_ui.core import Message`

A union type representing any type of message in the system.

```python
Message = Annotated[
    Union[DeveloperMessage, SystemMessage, AssistantMessage, UserMessage, ToolMessage],
    Field(discriminator="role")
]
```

### ToolCall

`from ag_ui.core import ToolCall`

Represents a tool call made by an agent.

```python
class ToolCall(ConfiguredBaseModel):
    id: str
    type: Literal["function"]
    function: FunctionCall
```

| Property   | Type                  | Description                              |
| ---------- | --------------------- | ---------------------------------------- |
| `id`       | `str`                 | Unique identifier for the tool call      |
| `type`     | `Literal["function"]` | Type of the tool call, always "function" |
| `function` | `FunctionCall`        | Details about the function being called  |

#### FunctionCall

`from ag_ui.core import FunctionCall`

Represents function name and arguments in a tool call.

```python
class FunctionCall(ConfiguredBaseModel):
    name: str
    arguments: str
```

| Property    | Type  | Description                                      |
| ----------- | ----- | ------------------------------------------------ |
| `name`      | `str` | Name of the function to call                     |
| `arguments` | `str` | JSON-encoded string of arguments to the function |

## Context

`from ag_ui.core import Context`

Represents a piece of contextual information provided to an agent.

```python
class Context(ConfiguredBaseModel):
    description: str
    value: str
```

| Property      | Type  | Description                                 |
| ------------- | ----- | ------------------------------------------- |
| `description` | `str` | Description of what this context represents |
| `value`       | `str` | The actual context value                    |

## Tool

`from ag_ui.core import Tool`

Defines a tool that can be called by an agent.

```python
class Tool(ConfiguredBaseModel):
    name: str
    description: str
    parameters: Any  # JSON Schema
```

| Property      | Type  | Description                                      |
| ------------- | ----- | ------------------------------------------------ |
| `name`        | `str` | Name of the tool                                 |
| `description` | `str` | Description of what the tool does                |
| `parameters`  | `Any` | JSON Schema defining the parameters for the tool |

## State

`from ag_ui.core import State`

Represents the state of an agent during execution.

```python
State = Any
```

The state type is flexible and can hold any data structure needed by the agent
implementation.



================================================
FILE: docs/sdk/python/encoder/overview.mdx
================================================
---
title: "Overview"
description: "Documentation for encoding Agent User Interaction Protocol events"
---

```bash
pip install ag-ui-protocol
```

# Event Encoder

The Agent User Interaction Protocol uses a streaming approach to send events
from agents to clients. The `EventEncoder` class provides the functionality to
encode events into a format that can be sent over HTTP.

## EventEncoder

`from ag_ui.encoder import EventEncoder`

The `EventEncoder` class is responsible for encoding `BaseEvent` objects into
string representations that can be transmitted to clients.

```python
from ag_ui.core import BaseEvent
from ag_ui.encoder import EventEncoder

# Initialize the encoder
encoder = EventEncoder()

# Encode an event
encoded_event = encoder.encode(event)
```

### Usage

The `EventEncoder` is typically used in HTTP handlers to convert event objects
into a stream of data. The current implementation encodes events as Server-Sent
Events (SSE), which can be consumed by clients using the EventSource API.

### Methods

#### `__init__(accept: str = None)`

Creates a new encoder instance.

| Parameter | Type             | Description                         |
| --------- | ---------------- | ----------------------------------- |
| `accept`  | `str` (optional) | Content type accepted by the client |

#### `encode(event: BaseEvent) -> str`

Encodes an event into a string representation.

| Parameter | Type        | Description         |
| --------- | ----------- | ------------------- |
| `event`   | `BaseEvent` | The event to encode |

**Returns**: A string representation of the event in SSE format.

### Example

```python
from ag_ui.core import TextMessageContentEvent, EventType
from ag_ui.encoder import EventEncoder

# Create an event
event = TextMessageContentEvent(
    type=EventType.TEXT_MESSAGE_CONTENT,
    message_id="msg_123",
    delta="Hello, world!"
)

# Initialize the encoder
encoder = EventEncoder()

# Encode the event
encoded_event = encoder.encode(event)
print(encoded_event)
# Output: data: {"type":"TEXT_MESSAGE_CONTENT","messageId":"msg_123","delta":"Hello, world!"}\n\n
```

### Implementation Details

Internally, the encoder converts events to JSON and formats them as Server-Sent
Events with the following structure:

```
data: {json-serialized event}\n\n
```

This format allows clients to receive a continuous stream of events and process
them as they arrive.



================================================
FILE: docs/snippets/snippet-intro.mdx
================================================
One of the core principles of software development is DRY (Don't Repeat
Yourself). This is a principle that apply to documentation as well. If you find
yourself repeating the same content in multiple places, you should consider
creating a custom snippet to keep your content in sync.



================================================
FILE: docs/tutorials/cursor.mdx
================================================
---
title: "Developing with Cursor"
description: "Use Cursor to build AG-UI implementations faster"
---

This guide will help you set up Cursor to help you build custom Agent User
Interaction Protocol (AG-UI) servers and clients faster. The same principles
apply to other IDE's like Windsurf, VSCode, etc.

## Adding the documentation to Cursor

1. Open up the Cursor settings
2. Go to Features > Docs and click "+ Add new Doc"
3. Paste in the following URL: https://docs.ag-ui.com/llms-full.txt
4. Click "Add"

## Using the documentation

Now you can use the documentation to help you build your AG-UI project. Load the
docs into the current prompt by typing the `@` symbol, selecting "Docs" and then
selecting "Agent User Interaction Protocol" from the list. Happy coding!

## Best practices

When building AG-UI servers with Cursor:

- Break down complex problems into smaller steps
- Have a look at what the agent was doing by checking which files it edited
  (above the chat input)
- Let the agent write unit tests to verify your implementation
- Follow AG-UI protocol specifications carefully



================================================
FILE: docs/tutorials/debugging.mdx
================================================
---
title: Debugging
description:
  A comprehensive guide to debugging Agent User Interaction Protocol (AG-UI)
  integrations
---

# Debugging AG-UI Integrations

Debugging agent-based applications can be challenging, especially when working
with real-time, event-driven protocols like AG-UI. This guide introduces you to
the AG-UI Dojo, a powerful tool for learning, testing, and debugging your AG-UI
implementations.

## The AG-UI Dojo

The AG-UI Dojo is the best way to bring AG-UI to a new surface, and is also an
excellent resource for learning about the protocol's basic capabilities. It
provides a structured environment where you can test and validate each component
of the AG-UI protocol.

### What is the Dojo?

The Dojo consists of a series of "hello world"-sized demonstrations for the
different building blocks available via AG-UI. Each demonstration:

1. Shows a specific AG-UI capability in action
2. Presents both the user-visible interaction and the underlying code side by
   side
3. Allows you to test and verify your implementation

### Using the Dojo as an Implementation Checklist

When working on bringing AG-UI to a new surface or platform, you can use the
Dojo as a comprehensive "todo list":

1. Work through each demonstration one by one
2. Implement and test each AG-UI building block in your environment
3. When all demonstrations work correctly in your implementation, you can be
   confident that full-featured copilots and agent-native applications can be
   built on your new surface

This methodical approach ensures you've covered all the necessary functionality
required for a complete AG-UI implementation.

### Using the Dojo as a Learning Resource

For developers new to AG-UI, the Dojo serves as an interactive learning
resource:

- Each item demonstrates a specific AG-UI capability
- You can see both what the interaction looks like from a user perspective
- The underlying code is shown alongside, helping you understand how it works
- The incremental complexity helps build understanding from basics to advanced
  features

### Common Debugging Patterns

When using the Dojo for debugging your AG-UI implementation, keep these patterns
in mind:

1. **Event Sequence Issues**: Verify that events are being emitted in the
   correct order and with proper nesting (e.g., `TEXT_MESSAGE_START` before
   `TEXT_MESSAGE_CONTENT`)

2. **Data Format Problems**: Ensure your event payloads match the expected
   structure for each event type

3. **Transport Layer Debugging**: Check that your chosen transport mechanism
   (SSE, WebSockets, etc.) is correctly delivering events

4. **State Synchronization**: Confirm that state updates are correctly applied
   using snapshots and deltas

5. **Tool Execution**: Verify that tool calls and responses are properly
   formatted and processed

## Getting Started with the Dojo

To start using the AG-UI Dojo:

1. Clone the repository from
   [github.com/ag-ui-protocol/ag-ui](https://github.com/ag-ui-protocol/ag-ui)
2. Follow the setup instructions in the README
3. Start working through the demonstrations in order
4. Use the provided test cases to validate your implementation

The Dojo's structured approach makes it an invaluable resource for both learning
AG-UI and ensuring your implementation meets all requirements.



================================================
FILE: python-sdk/README.md
================================================
# ag-ui-protocol

Python SDK for the **Agent-User Interaction (AG-UI) Protocol**.

`ag-ui-protocol` provides Python developers with strongly-typed data structures and event encoding for building AG-UI compatible agent servers. Built on Pydantic for robust validation and automatic camelCase serialization for seamless frontend integration.

## Installation

```bash
pip install ag-ui-protocol
poetry add ag-ui-protocol
pipenv install ag-ui-protocol
```

## Features

- 🐍 **Python-native** – Idiomatic Python APIs with full type hints and validation
- 📋 **Pydantic models** – Runtime validation and automatic JSON serialization
- 🔄 **Streaming events** – 16 core event types for real-time agent communication
- ⚡ **High performance** – Efficient event encoding for Server-Sent Events

## Quick example

```python
from ag_ui.core import TextMessageContentEvent, EventType
from ag_ui.encoder import EventEncoder

# Create a streaming text event
event = TextMessageContentEvent(
    type=EventType.TEXT_MESSAGE_CONTENT,
    message_id="msg_123",
    delta="Hello from Python!"
)

# Encode for HTTP streaming
encoder = EventEncoder()
sse_data = encoder.encode(event)
# Output: data: {"type":"TEXT_MESSAGE_CONTENT","messageId":"msg_123","delta":"Hello from Python!"}\n\n
```

## Packages

- **`ag_ui.core`** – Types, events, and data models for AG-UI protocol
- **`ag_ui.encoder`** – Event encoding utilities for HTTP streaming

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/python`](https://docs.ag-ui.com/sdk/python/core/overview)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: python-sdk/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: python-sdk/pyproject.toml
================================================
[tool.poetry]
name = "ag-ui-protocol"
version = "0.1.9"
description = ""
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"
license = "MIT"
packages = [{include = "ag_ui", from = "."}]
[tool.poetry.dependencies]
python = "^3.9"
pydantic = "^2.11.2"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"



================================================
FILE: python-sdk/ag_ui/py.typed
================================================
[Empty file]


================================================
FILE: python-sdk/ag_ui/core/__init__.py
================================================
"""
This module contains the core types and events for the Agent User Interaction Protocol.
"""

from ag_ui.core.events import (
    EventType,
    BaseEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    TextMessageChunkEvent,
    ThinkingTextMessageStartEvent,
    ThinkingTextMessageContentEvent,
    ThinkingTextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    ToolCallChunkEvent,
    ToolCallResultEvent,
    ThinkingStartEvent,
    ThinkingEndEvent,
    StateSnapshotEvent,
    StateDeltaEvent,
    MessagesSnapshotEvent,
    RawEvent,
    CustomEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    StepStartedEvent,
    StepFinishedEvent,
    Event
)

from ag_ui.core.types import (
    FunctionCall,
    ToolCall,
    BaseMessage,
    DeveloperMessage,
    SystemMessage,
    AssistantMessage,
    UserMessage,
    ToolMessage,
    Message,
    Role,
    Context,
    Tool,
    RunAgentInput,
    State
)

__all__ = [
    # Events
    "EventType",
    "BaseEvent",
    "TextMessageStartEvent",
    "TextMessageContentEvent",
    "TextMessageEndEvent",
    "TextMessageChunkEvent",
    "ThinkingTextMessageStartEvent",
    "ThinkingTextMessageContentEvent",
    "ThinkingTextMessageEndEvent",
    "ToolCallStartEvent",
    "ToolCallArgsEvent",
    "ToolCallEndEvent",
    "ToolCallChunkEvent",
    "ToolCallResultEvent",
    "ThinkingStartEvent",
    "ThinkingEndEvent",
    "StateSnapshotEvent",
    "StateDeltaEvent",
    "MessagesSnapshotEvent",
    "RawEvent",
    "CustomEvent",
    "RunStartedEvent",
    "RunFinishedEvent",
    "RunErrorEvent",
    "StepStartedEvent",
    "StepFinishedEvent",
    "Event",
    # Types
    "FunctionCall",
    "ToolCall",
    "BaseMessage",
    "DeveloperMessage",
    "SystemMessage",
    "AssistantMessage",
    "UserMessage",
    "ToolMessage",
    "Message",
    "Role",
    "Context",
    "Tool",
    "RunAgentInput",
    "State"
]



================================================
FILE: python-sdk/ag_ui/core/events.py
================================================
"""
This module contains the event types for the Agent User Interaction Protocol Python SDK.
"""

from enum import Enum
from typing import Annotated, Any, List, Literal, Optional, Union

from pydantic import Field

from .types import ConfiguredBaseModel, Message, State, Role

# Text messages can have any role except "tool"
TextMessageRole = Literal["developer", "system", "assistant", "user"]


class EventType(str, Enum):
    """
    The type of event.
    """
    TEXT_MESSAGE_START = "TEXT_MESSAGE_START"
    TEXT_MESSAGE_CONTENT = "TEXT_MESSAGE_CONTENT"
    TEXT_MESSAGE_END = "TEXT_MESSAGE_END"
    TEXT_MESSAGE_CHUNK = "TEXT_MESSAGE_CHUNK"
    THINKING_TEXT_MESSAGE_START = "THINKING_TEXT_MESSAGE_START"
    THINKING_TEXT_MESSAGE_CONTENT = "THINKING_TEXT_MESSAGE_CONTENT"
    THINKING_TEXT_MESSAGE_END = "THINKING_TEXT_MESSAGE_END"
    TOOL_CALL_START = "TOOL_CALL_START"
    TOOL_CALL_ARGS = "TOOL_CALL_ARGS"
    TOOL_CALL_END = "TOOL_CALL_END"
    TOOL_CALL_CHUNK = "TOOL_CALL_CHUNK"
    TOOL_CALL_RESULT = "TOOL_CALL_RESULT"
    THINKING_START = "THINKING_START"
    THINKING_END = "THINKING_END"
    STATE_SNAPSHOT = "STATE_SNAPSHOT"
    STATE_DELTA = "STATE_DELTA"
    MESSAGES_SNAPSHOT = "MESSAGES_SNAPSHOT"
    RAW = "RAW"
    CUSTOM = "CUSTOM"
    RUN_STARTED = "RUN_STARTED"
    RUN_FINISHED = "RUN_FINISHED"
    RUN_ERROR = "RUN_ERROR"
    STEP_STARTED = "STEP_STARTED"
    STEP_FINISHED = "STEP_FINISHED"


class BaseEvent(ConfiguredBaseModel):
    """
    Base event for all events in the Agent User Interaction Protocol.
    """
    type: EventType
    timestamp: Optional[int] = None
    raw_event: Optional[Any] = None


class TextMessageStartEvent(BaseEvent):
    """
    Event indicating the start of a text message.
    """
    type: Literal[EventType.TEXT_MESSAGE_START] = EventType.TEXT_MESSAGE_START  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: str
    role: TextMessageRole = "assistant"


class TextMessageContentEvent(BaseEvent):
    """
    Event containing a piece of text message content.
    """
    type: Literal[EventType.TEXT_MESSAGE_CONTENT] = EventType.TEXT_MESSAGE_CONTENT  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: str
    delta: str = Field(min_length=1)


class TextMessageEndEvent(BaseEvent):
    """
    Event indicating the end of a text message.
    """
    type: Literal[EventType.TEXT_MESSAGE_END] = EventType.TEXT_MESSAGE_END  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: str

class TextMessageChunkEvent(BaseEvent):
    """
    Event containing a chunk of text message content.
    """
    type: Literal[EventType.TEXT_MESSAGE_CHUNK] = EventType.TEXT_MESSAGE_CHUNK  # pyright: ignore[reportIncompatibleVariableOverride]
    message_id: Optional[str] = None
    role: Optional[TextMessageRole] = None
    delta: Optional[str] = None

class ThinkingTextMessageStartEvent(BaseEvent):
    """
    Event indicating the start of a thinking text message.
    """
    type: Literal[EventType.THINKING_TEXT_MESSAGE_START] = EventType.THINKING_TEXT_MESSAGE_START  # pyright: ignore[reportIncompatibleVariableOverride]

class ThinkingTextMessageContentEvent(BaseEvent):
    """
    Event indicating a piece of a thinking text message.
    """
    type: Literal[EventType.THINKING_TEXT_MESSAGE_CONTENT] = EventType.THINKING_TEXT_MESSAGE_CONTENT  # pyright: ignore[reportIncompatibleVariableOverride]
    delta: str = Field(min_length=1)

class ThinkingTextMessageEndEvent(BaseEvent):
    """
    Event indicating the end of a thinking text message.
    """
    type: Literal[EventType.THINKING_TEXT_MESSAGE_END] = EventType.THINKING_TEXT_MESSAGE_END  # pyright: ignore[reportIncompatibleVariableOverride]

class ToolCallStartEvent(BaseEvent):
    """
    Event indicating the start of a tool call.
    """
    type: Literal[EventType.TOOL_CALL_START] = EventType.TOOL_CALL_START  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str
    tool_call_name: str
    parent_message_id: Optional[str] = None


class ToolCallArgsEvent(BaseEvent):
    """
    Event containing tool call arguments.
    """
    type: Literal[EventType.TOOL_CALL_ARGS] = EventType.TOOL_CALL_ARGS  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str
    delta: str


class ToolCallEndEvent(BaseEvent):
    """
    Event indicating the end of a tool call.
    """
    type: Literal[EventType.TOOL_CALL_END] = EventType.TOOL_CALL_END  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str

class ToolCallChunkEvent(BaseEvent):
    """
    Event containing a chunk of tool call content.
    """
    type: Literal[EventType.TOOL_CALL_CHUNK] = EventType.TOOL_CALL_CHUNK  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: Optional[str] = None
    tool_call_name: Optional[str] = None
    parent_message_id: Optional[str] = None
    delta: Optional[str] = None

class ToolCallResultEvent(BaseEvent):
    """
    Event containing the result of a tool call.
    """
    message_id: str
    type: Literal[EventType.TOOL_CALL_RESULT] = EventType.TOOL_CALL_RESULT  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_call_id: str
    content: str
    role: Optional[Literal["tool"]] = None

class ThinkingStartEvent(BaseEvent):
    """
    Event indicating the start of a thinking step event.
    """
    type: Literal[EventType.THINKING_START] = EventType.THINKING_START  # pyright: ignore[reportIncompatibleVariableOverride]
    title: Optional[str] = None

class ThinkingEndEvent(BaseEvent):
    """
    Event indicating the end of a thinking step event.
    """
    type: Literal[EventType.THINKING_END] = EventType.THINKING_END  # pyright: ignore[reportIncompatibleVariableOverride]

class StateSnapshotEvent(BaseEvent):
    """
    Event containing a snapshot of the state.
    """
    type: Literal[EventType.STATE_SNAPSHOT] = EventType.STATE_SNAPSHOT  # pyright: ignore[reportIncompatibleVariableOverride]
    snapshot: State


class StateDeltaEvent(BaseEvent):
    """
    Event containing a delta of the state.
    """
    type: Literal[EventType.STATE_DELTA] = EventType.STATE_DELTA  # pyright: ignore[reportIncompatibleVariableOverride]
    delta: List[Any]  # JSON Patch (RFC 6902)


class MessagesSnapshotEvent(BaseEvent):
    """
    Event containing a snapshot of the messages.
    """
    type: Literal[EventType.MESSAGES_SNAPSHOT] = EventType.MESSAGES_SNAPSHOT  # pyright: ignore[reportIncompatibleVariableOverride]
    messages: List[Message]


class RawEvent(BaseEvent):
    """
    Event containing a raw event.
    """
    type: Literal[EventType.RAW] = EventType.RAW  # pyright: ignore[reportIncompatibleVariableOverride]
    event: Any
    source: Optional[str] = None


class CustomEvent(BaseEvent):
    """
    Event containing a custom event.
    """
    type: Literal[EventType.CUSTOM] = EventType.CUSTOM  # pyright: ignore[reportIncompatibleVariableOverride]
    name: str
    value: Any


class RunStartedEvent(BaseEvent):
    """
    Event indicating that a run has started.
    """
    type: Literal[EventType.RUN_STARTED] = EventType.RUN_STARTED  # pyright: ignore[reportIncompatibleVariableOverride]
    thread_id: str
    run_id: str


class RunFinishedEvent(BaseEvent):
    """
    Event indicating that a run has finished.
    """
    type: Literal[EventType.RUN_FINISHED] = EventType.RUN_FINISHED  # pyright: ignore[reportIncompatibleVariableOverride]
    thread_id: str
    run_id: str
    result: Optional[Any] = None


class RunErrorEvent(BaseEvent):
    """
    Event indicating that a run has encountered an error.
    """
    type: Literal[EventType.RUN_ERROR] = EventType.RUN_ERROR  # pyright: ignore[reportIncompatibleVariableOverride]
    message: str
    code: Optional[str] = None


class StepStartedEvent(BaseEvent):
    """
    Event indicating that a step has started.
    """
    type: Literal[EventType.STEP_STARTED] = EventType.STEP_STARTED  # pyright: ignore[reportIncompatibleVariableOverride]
    step_name: str


class StepFinishedEvent(BaseEvent):
    """
    Event indicating that a step has finished.
    """
    type: Literal[EventType.STEP_FINISHED] = EventType.STEP_FINISHED  # pyright: ignore[reportIncompatibleVariableOverride]
    step_name: str


Event = Annotated[
    Union[
        TextMessageStartEvent,
        TextMessageContentEvent,
        TextMessageEndEvent,
        TextMessageChunkEvent,
        ToolCallStartEvent,
        ToolCallArgsEvent,
        ToolCallEndEvent,
        ToolCallChunkEvent,
        ToolCallResultEvent,
        StateSnapshotEvent,
        StateDeltaEvent,
        MessagesSnapshotEvent,
        RawEvent,
        CustomEvent,
        RunStartedEvent,
        RunFinishedEvent,
        RunErrorEvent,
        StepStartedEvent,
        StepFinishedEvent,
    ],
    Field(discriminator="type")
]



================================================
FILE: python-sdk/ag_ui/core/types.py
================================================
"""
This module contains the types for the Agent User Interaction Protocol Python SDK.
"""

from typing import Annotated, Any, List, Literal, Optional, Union

from pydantic import BaseModel, ConfigDict, Field
from pydantic.alias_generators import to_camel


class ConfiguredBaseModel(BaseModel):
    """
    A configurable base model.
    """
    model_config = ConfigDict(
        extra="forbid",
        alias_generator=to_camel,
        populate_by_name=True,
    )


class FunctionCall(ConfiguredBaseModel):
    """
    Name and arguments of a function call.
    """
    name: str
    arguments: str


class ToolCall(ConfiguredBaseModel):
    """
    A tool call, modelled after OpenAI tool calls.
    """
    id: str
    type: Literal["function"] = "function"  # pyright: ignore[reportIncompatibleVariableOverride]
    function: FunctionCall


class BaseMessage(ConfiguredBaseModel):
    """
    A base message, modelled after OpenAI messages.
    """
    id: str
    role: str
    content: Optional[str] = None
    name: Optional[str] = None


class DeveloperMessage(BaseMessage):
    """
    A developer message.
    """
    role: Literal["developer"] = "developer"  # pyright: ignore[reportIncompatibleVariableOverride]
    content: str


class SystemMessage(BaseMessage):
    """
    A system message.
    """
    role: Literal["system"] = "system"  # pyright: ignore[reportIncompatibleVariableOverride]
    content: str


class AssistantMessage(BaseMessage):
    """
    An assistant message.
    """
    role: Literal["assistant"] = "assistant"  # pyright: ignore[reportIncompatibleVariableOverride]
    tool_calls: Optional[List[ToolCall]] = None


class UserMessage(BaseMessage):
    """
    A user message.
    """
    role: Literal["user"] = "user" # pyright: ignore[reportIncompatibleVariableOverride]
    content: str


class ToolMessage(ConfiguredBaseModel):
    """
    A tool result message.
    """
    id: str
    role: Literal["tool"] = "tool"
    content: str
    tool_call_id: str
    error: Optional[str] = None


Message = Annotated[
    Union[DeveloperMessage, SystemMessage, AssistantMessage, UserMessage, ToolMessage],
    Field(discriminator="role")
]

Role = Literal["developer", "system", "assistant", "user", "tool"]


class Context(ConfiguredBaseModel):
    """
    Additional context for the agent.
    """
    description: str
    value: str


class Tool(ConfiguredBaseModel):
    """
    A tool definition.
    """
    name: str
    description: str
    parameters: Any  # JSON Schema for the tool parameters


class RunAgentInput(ConfiguredBaseModel):
    """
    Input for running an agent.
    """
    thread_id: str
    run_id: str
    state: Any
    messages: List[Message]
    tools: List[Tool]
    context: List[Context]
    forwarded_props: Any


# State can be any type
State = Any



================================================
FILE: python-sdk/ag_ui/encoder/__init__.py
================================================
"""
This module contains the EventEncoder class.
"""

from ag_ui.encoder.encoder import EventEncoder, AGUI_MEDIA_TYPE

__all__ = ["EventEncoder", "AGUI_MEDIA_TYPE"]



================================================
FILE: python-sdk/ag_ui/encoder/encoder.py
================================================
"""
This module contains the EventEncoder class
"""

from ag_ui.core.events import BaseEvent

AGUI_MEDIA_TYPE = "application/vnd.ag-ui.event+proto"

class EventEncoder:
    """
    Encodes Agent User Interaction events.
    """
    def __init__(self, accept: str = None):
        pass

    def get_content_type(self) -> str:
        """
        Returns the content type of the encoder.
        """
        return "text/event-stream"

    def encode(self, event: BaseEvent) -> str:
        """
        Encodes an event.
        """
        return self._encode_sse(event)

    def _encode_sse(self, event: BaseEvent) -> str:
        """
        Encodes an event into an SSE string.
        """
        return f"data: {event.model_dump_json(by_alias=True, exclude_none=True)}\n\n"



================================================
FILE: python-sdk/tests/__init__.py
================================================
[Empty file]


================================================
FILE: python-sdk/tests/test_encoder.py
================================================
import unittest
import json
from datetime import datetime

from ag_ui.encoder.encoder import EventEncoder, AGUI_MEDIA_TYPE
from ag_ui.core.events import BaseEvent, EventType, TextMessageContentEvent, ToolCallStartEvent


class TestEventEncoder(unittest.TestCase):
    """Test suite for EventEncoder class"""

    def test_encoder_initialization(self):
        """Test initializing an EventEncoder"""
        encoder = EventEncoder()
        self.assertIsInstance(encoder, EventEncoder)

        # Test with accept parameter
        encoder_with_accept = EventEncoder(accept=AGUI_MEDIA_TYPE)
        self.assertIsInstance(encoder_with_accept, EventEncoder)

    def test_encode_method(self):
        """Test the encode method which calls encode_sse"""
        # Create a test event
        timestamp = int(datetime.now().timestamp() * 1000)
        event = BaseEvent(type=EventType.RAW, timestamp=timestamp)
        
        # Create encoder and encode event
        encoder = EventEncoder()
        encoded = encoder.encode(event)
        
        # The encode method calls encode_sse, so the result should be in SSE format
        expected = f"data: {event.model_dump_json(by_alias=True, exclude_none=True)}\n\n"
        self.assertEqual(encoded, expected)
        
        # Verify that camelCase is used in the encoded output
        self.assertIn('"type":', encoded)
        self.assertIn('"timestamp":', encoded)
        # Raw event should be excluded if it's None
        self.assertNotIn('"rawEvent":', encoded)
        self.assertNotIn('"raw_event":', encoded)

    def test_encode_sse_method(self):
        """Test the encode_sse method"""
        # Create a test event with specific data
        event = TextMessageContentEvent(
            message_id="msg_123",
            delta="Hello, world!",
            timestamp=1648214400000
        )
        
        # Create encoder and encode event to SSE
        encoder = EventEncoder()
        encoded_sse = encoder._encode_sse(event)
        
        # Verify the format is correct for SSE (data: [json]\n\n)
        self.assertTrue(encoded_sse.startswith("data: "))
        self.assertTrue(encoded_sse.endswith("\n\n"))
        
        # Extract and verify the JSON content
        json_content = encoded_sse[6:-2]  # Remove "data: " prefix and "\n\n" suffix
        decoded = json.loads(json_content)
        
        # Check that all fields were properly encoded
        self.assertEqual(decoded["type"], "TEXT_MESSAGE_CONTENT")
        self.assertEqual(decoded["messageId"], "msg_123")  # Check snake_case converted to camelCase
        self.assertEqual(decoded["delta"], "Hello, world!")
        self.assertEqual(decoded["timestamp"], 1648214400000)
        
        # Verify that snake_case has been converted to camelCase
        self.assertIn("messageId", decoded)  # camelCase key exists
        self.assertNotIn("message_id", decoded)  # snake_case key doesn't exist

    def test_encode_with_different_event_types(self):
        """Test encoding different types of events"""
        # Create encoder
        encoder = EventEncoder()
        
        # Test with a basic BaseEvent
        base_event = BaseEvent(type=EventType.RAW, timestamp=1648214400000)
        encoded_base = encoder.encode(base_event)
        self.assertIn('"type":"RAW"', encoded_base)
        
        # Test with a more complex event
        content_event = TextMessageContentEvent(
            message_id="msg_456",
            delta="Testing different events",
            timestamp=1648214400000
        )
        encoded_content = encoder.encode(content_event)
        
        # Verify correct encoding and camelCase conversion
        self.assertIn('"type":"TEXT_MESSAGE_CONTENT"', encoded_content)
        self.assertIn('"messageId":"msg_456"', encoded_content)  # Check snake_case converted to camelCase
        self.assertIn('"delta":"Testing different events"', encoded_content)
        
        # Extract JSON and verify camelCase conversion
        json_content = encoded_content.split("data: ")[1].rstrip("\n\n")
        decoded = json.loads(json_content)
        
        # Verify messageId is camelCase (not message_id)
        self.assertIn("messageId", decoded)
        self.assertNotIn("message_id", decoded)
        
    def test_null_value_exclusion(self):
        """Test that fields with None values are excluded from the JSON output"""
        # Create an event with some fields set to None
        event = BaseEvent(
            type=EventType.RAW,
            timestamp=1648214400000,
            raw_event=None  # Explicitly set to None
        )
        
        # Create encoder and encode event
        encoder = EventEncoder()
        encoded = encoder.encode(event)
        
        # Extract JSON
        json_content = encoded.split("data: ")[1].rstrip("\n\n")
        decoded = json.loads(json_content)
        
        # Verify fields that are present
        self.assertIn("type", decoded)
        self.assertIn("timestamp", decoded)
        
        # Verify null fields are excluded
        self.assertNotIn("rawEvent", decoded)
        
        # Test with another event that has optional fields
        # Create event with some optional fields set to None
        event_with_optional = ToolCallStartEvent(
            tool_call_id="call_123",
            tool_call_name="test_tool",
            parent_message_id=None,  # Optional field explicitly set to None
            timestamp=1648214400000
        )
        
        encoded_optional = encoder.encode(event_with_optional)
        json_content_optional = encoded_optional.split("data: ")[1].rstrip("\n\n")
        decoded_optional = json.loads(json_content_optional)
        
        # Required fields should be present
        self.assertIn("toolCallId", decoded_optional)
        self.assertIn("toolCallName", decoded_optional)
        
        # Optional field with None value should be excluded
        self.assertNotIn("parentMessageId", decoded_optional)
        
    def test_round_trip_serialization(self):
        """Test that events can be serialized to JSON with camelCase and deserialized back correctly"""
        # Create a complex event with multiple fields
        original_event = ToolCallStartEvent(
            tool_call_id="call_abc123",
            tool_call_name="search_tool",
            parent_message_id="msg_parent_456",
            timestamp=1648214400000
        )
        
        # Serialize to JSON with camelCase fields
        json_str = original_event.model_dump_json(by_alias=True)
        
        # Verify JSON uses camelCase
        json_data = json.loads(json_str)
        self.assertIn("toolCallId", json_data)
        self.assertIn("toolCallName", json_data)
        self.assertIn("parentMessageId", json_data)
        self.assertNotIn("tool_call_id", json_data)
        self.assertNotIn("tool_call_name", json_data)
        self.assertNotIn("parent_message_id", json_data)
        
        # Deserialize back to an event
        deserialized_event = ToolCallStartEvent.model_validate_json(json_str)
        
        # Verify the deserialized event is equivalent to the original
        self.assertEqual(deserialized_event.type, original_event.type)
        self.assertEqual(deserialized_event.tool_call_id, original_event.tool_call_id)
        self.assertEqual(deserialized_event.tool_call_name, original_event.tool_call_name)
        self.assertEqual(deserialized_event.parent_message_id, original_event.parent_message_id)
        self.assertEqual(deserialized_event.timestamp, original_event.timestamp)
        
        # Verify complete equality using model_dump
        self.assertEqual(
            original_event.model_dump(), 
            deserialized_event.model_dump()
        )



================================================
FILE: python-sdk/tests/test_events.py
================================================
import unittest
import json
from datetime import datetime
from pydantic import ValidationError, TypeAdapter

from ag_ui.core.types import Message, UserMessage, AssistantMessage, FunctionCall, ToolCall
from ag_ui.core.events import (
    EventType,
    BaseEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    StateSnapshotEvent,
    StateDeltaEvent,
    MessagesSnapshotEvent,
    RawEvent,
    CustomEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    StepStartedEvent,
    StepFinishedEvent,
    Event
)


class TestEvents(unittest.TestCase):
    """Test suite for event classes"""

    def test_event_types_enum(self):
        """Test the EventType enum values"""
        self.assertEqual(EventType.TEXT_MESSAGE_START.value, "TEXT_MESSAGE_START")
        self.assertEqual(EventType.TOOL_CALL_ARGS.value, "TOOL_CALL_ARGS")
        self.assertEqual(EventType.STATE_SNAPSHOT.value, "STATE_SNAPSHOT")
        self.assertEqual(EventType.RUN_ERROR.value, "RUN_ERROR")
        self.assertEqual(EventType.STEP_FINISHED.value, "STEP_FINISHED")

    def test_base_event_creation(self):
        """Test creating a BaseEvent instance"""
        timestamp = int(datetime.now().timestamp() * 1000)
        event = BaseEvent(type=EventType.RAW, timestamp=timestamp)
        self.assertEqual(event.type, EventType.RAW)
        self.assertEqual(event.timestamp, timestamp)
        self.assertIsNone(event.raw_event)

    def test_text_message_start(self):
        """Test creating and serializing a TextMessageStartEvent event"""
        event = TextMessageStartEvent(
            message_id="msg_123",
            timestamp=1648214400000
        )
        self.assertEqual(event.message_id, "msg_123")
        self.assertEqual(event.role, "assistant")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TEXT_MESSAGE_START")
        self.assertEqual(serialized["messageId"], "msg_123")
        self.assertEqual(serialized["timestamp"], 1648214400000)

    def test_text_message_content(self):
        """Test creating and serializing a TextMessageContentEvent event"""
        event = TextMessageContentEvent(
            message_id="msg_123",
            delta="Hello, world!",
            timestamp=1648214400000
        )
        self.assertEqual(event.message_id, "msg_123")
        self.assertEqual(event.delta, "Hello, world!")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TEXT_MESSAGE_CONTENT")
        self.assertEqual(serialized["messageId"], "msg_123")
        self.assertEqual(serialized["delta"], "Hello, world!")

    def test_text_message_end(self):
        """Test creating and serializing a TextMessageEndEvent event"""
        event = TextMessageEndEvent(
            message_id="msg_123",
            timestamp=1648214400000
        )
        self.assertEqual(event.message_id, "msg_123")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TEXT_MESSAGE_END")
        self.assertEqual(serialized["messageId"], "msg_123")

    def test_tool_call_start(self):
        """Test creating and serializing a ToolCallStartEvent event"""
        event = ToolCallStartEvent(
            tool_call_id="call_123",
            tool_call_name="get_weather",
            parent_message_id="msg_456",
            timestamp=1648214400000
        )
        self.assertEqual(event.tool_call_id, "call_123")
        self.assertEqual(event.tool_call_name, "get_weather")
        self.assertEqual(event.parent_message_id, "msg_456")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TOOL_CALL_START")
        self.assertEqual(serialized["toolCallId"], "call_123")
        self.assertEqual(serialized["toolCallName"], "get_weather")
        self.assertEqual(serialized["parentMessageId"], "msg_456")

    def test_tool_call_args(self):
        """Test creating and serializing a ToolCallArgsEvent event"""
        event = ToolCallArgsEvent(
            tool_call_id="call_123",
            delta='{"location": "New York"}',
            timestamp=1648214400000
        )
        self.assertEqual(event.tool_call_id, "call_123")
        self.assertEqual(event.delta, '{"location": "New York"}')
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TOOL_CALL_ARGS")
        self.assertEqual(serialized["toolCallId"], "call_123")
        self.assertEqual(serialized["delta"], '{"location": "New York"}')

    def test_tool_call_end(self):
        """Test creating and serializing a ToolCallEndEvent event"""
        event = ToolCallEndEvent(
            tool_call_id="call_123",
            timestamp=1648214400000
        )
        self.assertEqual(event.tool_call_id, "call_123")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "TOOL_CALL_END")
        self.assertEqual(serialized["toolCallId"], "call_123")

    def test_state_snapshot(self):
        """Test creating and serializing a StateSnapshotEvent event"""
        state = {"conversation_state": "active", "user_info": {"name": "John"}}
        event = StateSnapshotEvent(
            snapshot=state,
            timestamp=1648214400000
        )
        self.assertEqual(event.snapshot, state)
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STATE_SNAPSHOT")
        self.assertEqual(serialized["snapshot"]["conversation_state"], "active")
        self.assertEqual(serialized["snapshot"]["user_info"]["name"], "John")

    def test_state_delta(self):
        """Test creating and serializing a StateDeltaEvent event"""
        # JSON Patch format
        delta = [
            {"op": "replace", "path": "/conversation_state", "value": "paused"},
            {"op": "add", "path": "/user_info/age", "value": 30}
        ]
        event = StateDeltaEvent(
            delta=delta,
            timestamp=1648214400000
        )
        self.assertEqual(event.delta, delta)
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STATE_DELTA")
        self.assertEqual(len(serialized["delta"]), 2)
        self.assertEqual(serialized["delta"][0]["op"], "replace")
        self.assertEqual(serialized["delta"][1]["path"], "/user_info/age")

    def test_messages_snapshot(self):
        """Test creating and serializing a MessagesSnapshotEvent event"""
        messages = [
            UserMessage(id="user_1", content="Hello"),
            AssistantMessage(id="asst_1", content="Hi there", tool_calls=[
                ToolCall(
                    id="call_1",
                    function=FunctionCall(
                        name="get_weather",
                        arguments='{"location": "New York"}'
                    )
                )
            ])
        ]
        event = MessagesSnapshotEvent(
            messages=messages,
            timestamp=1648214400000
        )
        self.assertEqual(len(event.messages), 2)
        self.assertEqual(event.messages[0].id, "user_1")
        self.assertEqual(event.messages[1].tool_calls[0].function.name, "get_weather")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "MESSAGES_SNAPSHOT")
        self.assertEqual(len(serialized["messages"]), 2)
        self.assertEqual(serialized["messages"][0]["role"], "user")
        self.assertEqual(serialized["messages"][1]["toolCalls"][0]["function"]["name"], "get_weather")

    def test_raw_event(self):
        """Test creating and serializing a RawEvent"""
        raw_data = {"origin": "server", "data": {"key": "value"}}
        event = RawEvent(
            event=raw_data,
            source="api",
            timestamp=1648214400000
        )
        self.assertEqual(event.event, raw_data)
        self.assertEqual(event.source, "api")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RAW")
        self.assertEqual(serialized["event"]["origin"], "server")
        self.assertEqual(serialized["source"], "api")

    def test_custom_event(self):
        """Test creating and serializing a CustomEvent"""
        event = CustomEvent(
            name="user_action",
            value={"action": "click", "element": "button"},
            timestamp=1648214400000
        )
        self.assertEqual(event.name, "user_action")
        self.assertEqual(event.value["action"], "click")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "CUSTOM")
        self.assertEqual(serialized["name"], "user_action")
        self.assertEqual(serialized["value"]["element"], "button")

    def test_run_started(self):
        """Test creating and serializing a RunStartedEvent event"""
        event = RunStartedEvent(
            thread_id="thread_123",
            run_id="run_456",
            timestamp=1648214400000
        )
        self.assertEqual(event.thread_id, "thread_123")
        self.assertEqual(event.run_id, "run_456")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RUN_STARTED")
        self.assertEqual(serialized["threadId"], "thread_123")
        self.assertEqual(serialized["runId"], "run_456")

    def test_run_finished(self):
        """Test creating and serializing a RunFinishedEvent event"""
        event = RunFinishedEvent(
            thread_id="thread_123",
            run_id="run_456",
            timestamp=1648214400000
        )
        self.assertEqual(event.thread_id, "thread_123")
        self.assertEqual(event.run_id, "run_456")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RUN_FINISHED")
        self.assertEqual(serialized["threadId"], "thread_123")
        self.assertEqual(serialized["runId"], "run_456")

    def test_run_error(self):
        """Test creating and serializing a RunErrorEvent event"""
        event = RunErrorEvent(
            message="An error occurred during execution",
            code="ERROR_001",
            timestamp=1648214400000
        )
        self.assertEqual(event.message, "An error occurred during execution")
        self.assertEqual(event.code, "ERROR_001")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RUN_ERROR")
        self.assertEqual(serialized["message"], "An error occurred during execution")
        self.assertEqual(serialized["code"], "ERROR_001")

    def test_step_started(self):
        """Test creating and serializing a StepStartedEvent event"""
        event = StepStartedEvent(
            step_name="process_data",
            timestamp=1648214400000
        )
        self.assertEqual(event.step_name, "process_data")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STEP_STARTED")
        self.assertEqual(serialized["stepName"], "process_data")

    def test_step_finished(self):
        """Test creating and serializing a StepFinishedEvent event"""
        event = StepFinishedEvent(
            step_name="process_data",
            timestamp=1648214400000
        )
        self.assertEqual(event.step_name, "process_data")
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "STEP_FINISHED")
        self.assertEqual(serialized["stepName"], "process_data")

    def test_event_union_deserialization(self):
        """Test the Event union type correctly deserializes different event types"""
        event_adapter = TypeAdapter(Event)
        
        # Test different event types
        event_data = [
            {
                "type": "TEXT_MESSAGE_START",
                "messageId": "msg_start",
                "role": "assistant",
                "timestamp": 1648214400000
            },
            {
                "type": "TEXT_MESSAGE_CONTENT",
                "messageId": "msg_content",
                "delta": "Hello!",
                "timestamp": 1648214400000
            },
            {
                "type": "TOOL_CALL_START",
                "toolCallId": "call_start",
                "toolCallName": "get_info",
                "timestamp": 1648214400000
            },
            {
                "type": "STATE_SNAPSHOT",
                "snapshot": {"status": "active"},
                "timestamp": 1648214400000
            },
            {
                "type": "RUN_ERROR",
                "message": "Error occurred",
                "code": "ERR_001",
                "timestamp": 1648214400000
            }
        ]
        
        expected_types = [
            TextMessageStartEvent,
            TextMessageContentEvent,
            ToolCallStartEvent,
            StateSnapshotEvent,
            RunErrorEvent
        ]
        
        for data, expected_type in zip(event_data, expected_types):
            event = event_adapter.validate_python(data)
            self.assertIsInstance(event, expected_type)
            self.assertEqual(event.type.value, data["type"])
            self.assertEqual(event.timestamp, data["timestamp"])

    def test_validation_constraints(self):
        """Test validation constraints for different event types"""
        # TextMessageContentEvent delta cannot be empty
        with self.assertRaises(ValueError):
            TextMessageContentEvent(
                message_id="msg_123",
                delta=""  # Empty delta, should fail
            )

    def test_serialization_round_trip(self):
        """Test serialization and deserialization for different event types"""
        # Create events of different types
        events = [
            TextMessageStartEvent(
                message_id="msg_123",
            ),
            TextMessageContentEvent(
                message_id="msg_123",
                delta="Hello, world!"
            ),
            ToolCallStartEvent(
                tool_call_id="call_123",
                tool_call_name="get_weather"
            ),
            StateSnapshotEvent(
                snapshot={"status": "active"}
            ),
            MessagesSnapshotEvent(
                messages=[
                    UserMessage(id="user_1", content="Hello")
                ]
            ),
            RunStartedEvent(
                thread_id="thread_123",
                run_id="run_456"
            )
        ]
        
        event_adapter = TypeAdapter(Event)
        
        # Test round trip for each event
        for original_event in events:
            # Serialize to JSON
            json_str = original_event.model_dump_json(by_alias=True)
            
            # Deserialize back to object
            deserialized_event = event_adapter.validate_json(json_str)
            
            # Verify the types match
            self.assertIsInstance(deserialized_event, type(original_event))
            self.assertEqual(deserialized_event.type, original_event.type)
            
            # Verify event-specific fields
            if isinstance(original_event, TextMessageStartEvent):
                self.assertEqual(deserialized_event.message_id, original_event.message_id)
                self.assertEqual(deserialized_event.role, original_event.role)
            elif isinstance(original_event, TextMessageContentEvent):
                self.assertEqual(deserialized_event.message_id, original_event.message_id)
                self.assertEqual(deserialized_event.delta, original_event.delta)
            elif isinstance(original_event, ToolCallStartEvent):
                self.assertEqual(deserialized_event.tool_call_id, original_event.tool_call_id)
                self.assertEqual(deserialized_event.tool_call_name, original_event.tool_call_name)
            elif isinstance(original_event, StateSnapshotEvent):
                self.assertEqual(deserialized_event.snapshot, original_event.snapshot)
            elif isinstance(original_event, MessagesSnapshotEvent):
                self.assertEqual(len(deserialized_event.messages), len(original_event.messages))
                self.assertEqual(deserialized_event.messages[0].id, original_event.messages[0].id)
            elif isinstance(original_event, RunStartedEvent):
                self.assertEqual(deserialized_event.thread_id, original_event.thread_id)
                self.assertEqual(deserialized_event.run_id, original_event.run_id)

    def test_raw_event_with_null_source(self):
        """Test RawEvent with null source"""
        event = RawEvent(
            event={"data": "test"},
            source=None  # Explicit None
        )
        self.assertIsNone(event.source)
        
        # Test serialization
        serialized = event.model_dump(by_alias=True)
        self.assertEqual(serialized["type"], "RAW")
        self.assertEqual(serialized["event"]["data"], "test")
        self.assertIsNone(serialized["source"])
        
        # Test round-trip
        event_adapter = TypeAdapter(Event)
        json_str = event.model_dump_json(by_alias=True)
        deserialized = event_adapter.validate_json(json_str)
        self.assertIsNone(deserialized.source)

    def test_complex_nested_event_structures(self):
        """Test complex nested structures within events"""
        # Complex state with nested objects and arrays
        complex_state = {
            "session": {
                "user": {
                    "id": "user_123",
                    "preferences": {
                        "theme": "dark",
                        "notifications": True,
                        "filters": ["news", "social", "tech"]
                    }
                },
                "stats": {
                    "messages": 42,
                    "interactions": {
                        "clicks": 18,
                        "searches": 7
                    }
                }
            },
            "active_tools": ["search", "calculator", "weather"],
            "settings": {
                "language": "en",
                "timezone": "UTC-5"
            }
        }
        
        event = StateSnapshotEvent(
            snapshot=complex_state,
            timestamp=1648214400000
        )
        
        # Verify complex state structure
        self.assertEqual(event.snapshot["session"]["user"]["id"], "user_123")
        self.assertEqual(event.snapshot["session"]["user"]["preferences"]["theme"], "dark")
        self.assertEqual(event.snapshot["session"]["stats"]["interactions"]["searches"], 7)
        self.assertEqual(event.snapshot["active_tools"][1], "calculator")
        
        # Test serialization and deserialization
        event_adapter = TypeAdapter(Event)
        json_str = event.model_dump_json(by_alias=True)
        deserialized = event_adapter.validate_json(json_str)
        
        # Verify structure is preserved
        self.assertEqual(
            deserialized.snapshot["session"]["user"]["preferences"]["filters"],
            ["news", "social", "tech"]
        )
        self.assertEqual(deserialized.snapshot["settings"]["timezone"], "UTC-5")

    def test_event_with_unicode_and_special_chars(self):
        """Test events with Unicode and special characters"""
        # Text with Unicode and special characters
        text = "Hello 你好 こんにちは 안녕하세요 👋 🌍 \n\t\"'\\/<>{}[]"
        
        event = TextMessageContentEvent(
            message_id="msg_unicode",
            delta=text,
            timestamp=1648214400000
        )
        
        # Verify text is stored correctly
        self.assertEqual(event.delta, text)
        
        # Test serialization and deserialization
        event_adapter = TypeAdapter(Event)
        json_str = event.model_dump_json(by_alias=True)
        deserialized = event_adapter.validate_json(json_str)
        
        # Verify Unicode and special characters are preserved
        self.assertEqual(deserialized.delta, text)


if __name__ == "__main__":
    unittest.main()



================================================
FILE: python-sdk/tests/test_text_roles.py
================================================
"""Tests for text message events with different roles."""

import unittest
from pydantic import ValidationError
from ag_ui.core import (
    EventType,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    TextMessageChunkEvent,
    Role,
)

# Test all available roles for text messages (excluding "tool")
TEXT_MESSAGE_ROLES = ["developer", "system", "assistant", "user"]


class TestTextMessageRoles(unittest.TestCase):
    """Test text message events with different roles."""

    def test_text_message_start_with_all_roles(self) -> None:
        """Test TextMessageStartEvent with different roles."""
        for role in TEXT_MESSAGE_ROLES:
            with self.subTest(role=role):
                event = TextMessageStartEvent(
                    message_id="test-msg",
                    role=role,
                )
                
                self.assertEqual(event.type, EventType.TEXT_MESSAGE_START)
                self.assertEqual(event.message_id, "test-msg")
                self.assertEqual(event.role, role)

    def test_text_message_chunk_with_all_roles(self) -> None:
        """Test TextMessageChunkEvent with different roles."""
        for role in TEXT_MESSAGE_ROLES:
            with self.subTest(role=role):
                event = TextMessageChunkEvent(
                    message_id="test-msg",
                    role=role,
                    delta=f"Hello from {role}",
                )
                
                self.assertEqual(event.type, EventType.TEXT_MESSAGE_CHUNK)
                self.assertEqual(event.message_id, "test-msg")
                self.assertEqual(event.role, role)
                self.assertEqual(event.delta, f"Hello from {role}")

    def test_text_message_chunk_without_role(self) -> None:
        """Test TextMessageChunkEvent without role (should be optional)."""
        event = TextMessageChunkEvent(
            message_id="test-msg",
            delta="Hello without role",
        )
        
        self.assertEqual(event.type, EventType.TEXT_MESSAGE_CHUNK)
        self.assertEqual(event.message_id, "test-msg")
        self.assertIsNone(event.role)
        self.assertEqual(event.delta, "Hello without role")

    def test_multiple_messages_different_roles(self) -> None:
        """Test creating multiple messages with different roles."""
        events = []
        
        for role in TEXT_MESSAGE_ROLES:
            start_event = TextMessageStartEvent(
                message_id=f"msg-{role}",
                role=role,
            )
            content_event = TextMessageContentEvent(
                message_id=f"msg-{role}",
                delta=f"Message from {role}",
            )
            end_event = TextMessageEndEvent(
                message_id=f"msg-{role}",
            )
            
            events.extend([start_event, content_event, end_event])
        
        # Verify we have 3 events per role
        self.assertEqual(len(events), len(TEXT_MESSAGE_ROLES) * 3)
        
        # Verify each start event has the correct role
        for i, role in enumerate(TEXT_MESSAGE_ROLES):
            start_event = events[i * 3]
            self.assertIsInstance(start_event, TextMessageStartEvent)
            self.assertEqual(start_event.role, role)
            self.assertEqual(start_event.message_id, f"msg-{role}")

    def test_text_message_serialization(self) -> None:
        """Test that text message events serialize correctly with roles."""
        for role in TEXT_MESSAGE_ROLES:
            with self.subTest(role=role):
                event = TextMessageStartEvent(
                    message_id="test-msg",
                    role=role,
                )
                
                # Convert to dict and back
                event_dict = event.model_dump()
                self.assertEqual(event_dict["role"], role)
                self.assertEqual(event_dict["type"], EventType.TEXT_MESSAGE_START)
                self.assertEqual(event_dict["message_id"], "test-msg")
                
                # Recreate from dict
                new_event = TextMessageStartEvent(**event_dict)
                self.assertEqual(new_event.role, role)
                self.assertEqual(new_event, event)

    def test_invalid_role_rejected(self) -> None:
        """Test that invalid roles are rejected."""
        # Test with completely invalid role
        with self.assertRaises(ValidationError):
            TextMessageStartEvent(
                message_id="test-msg",
                role="invalid_role",  # type: ignore
            )
        
        # Test that 'tool' role is not allowed for text messages
        with self.assertRaises(ValidationError):
            TextMessageStartEvent(
                message_id="test-msg",
                role="tool",  # type: ignore
            )
        
        # Test that 'tool' role is not allowed for chunks either
        with self.assertRaises(ValidationError):
            TextMessageChunkEvent(
                message_id="test-msg",
                role="tool",  # type: ignore
                delta="Tool message",
            )

    def test_text_message_start_default_role(self) -> None:
        """Test that TextMessageStartEvent defaults to 'assistant' role."""
        event = TextMessageStartEvent(
            message_id="test-msg",
        )
        
        self.assertEqual(event.type, EventType.TEXT_MESSAGE_START)
        self.assertEqual(event.message_id, "test-msg")
        self.assertEqual(event.role, "assistant")  # Should default to assistant


if __name__ == "__main__":
    unittest.main()


================================================
FILE: python-sdk/tests/test_types.py
================================================
import unittest
from pydantic import ValidationError
from pydantic import TypeAdapter

from ag_ui.core.types import (
    FunctionCall,
    ToolCall,
    DeveloperMessage,
    SystemMessage,
    AssistantMessage,
    UserMessage,
    ToolMessage,
    Message,
    RunAgentInput
)


class TestBaseTypes(unittest.TestCase):
    """Test suite for base type classes"""

    def test_function_call_creation(self):
        """Test creating a FunctionCall instance"""
        func_call = FunctionCall(name="test_function", arguments="{}")
        self.assertEqual(func_call.name, "test_function")
        self.assertEqual(func_call.arguments, "{}")

    def test_message_serialization(self):
        """Test serialization of a basic message"""
        user_msg = UserMessage(
            id="msg_123",
            content="Hello, world!"
        )
        serialized = user_msg.model_dump(by_alias=True)
        self.assertEqual(serialized["id"], "msg_123")
        self.assertEqual(serialized["role"], "user")
        self.assertEqual(serialized["content"], "Hello, world!")

    def test_tool_call_serialization(self):
        """Test camel case serialization for ConfiguredBaseModel subclasses"""
        tool_call = ToolCall(
            id="call_123",
            function=FunctionCall(name="test_function", arguments="{}")
        )
        serialized = tool_call.model_dump(by_alias=True)
        # Should convert function to camelCase
        self.assertIn("function", serialized)

    def test_tool_message_camel_case(self):
        """Test camel case serialization for ToolMessage"""
        tool_msg = ToolMessage(
            id="tool_123",
            content="Tool result",
            tool_call_id="call_456"
        )
        serialized = tool_msg.model_dump(by_alias=True)
        self.assertIn("toolCallId", serialized)
        self.assertEqual(serialized["toolCallId"], "call_456")

    def test_parse_camel_case_json_tool_message(self):
        """Test parsing JSON with camelCase field names"""
        # JSON data with camelCase field names
        json_data = {
            "id": "tool_789",
            "role": "tool",
            "content": "Result from tool",
            "toolCallId": "call_123"  # camelCase field name
        }

        # Parse the JSON data into a ToolMessage instance
        tool_msg = ToolMessage.model_validate(json_data)

        # Verify fields are correctly set
        self.assertEqual(tool_msg.id, "tool_789")
        self.assertEqual(tool_msg.role, "tool")
        self.assertEqual(tool_msg.content, "Result from tool")
        self.assertEqual(tool_msg.tool_call_id, "call_123")

    def test_parse_camel_case_json_function_call(self):
        """Test parsing function call with camelCase fields"""
        # Create a tool call with nested function call in camelCase
        json_data = {
            "id": "call_abc",
            "type": "function",
            "function": {
                "name": "get_weather",
                "arguments": '{"location":"New York"}'
            }
        }

        # Parse JSON into a ToolCall instance
        tool_call = ToolCall.model_validate(json_data)

        # Verify fields are correctly set
        self.assertEqual(tool_call.id, "call_abc")
        self.assertEqual(tool_call.type, "function")
        self.assertEqual(tool_call.function.name, "get_weather")
        self.assertEqual(tool_call.function.arguments, '{"location":"New York"}')

    def test_developer_message(self):
        """Test creating and serializing a developer message"""
        msg = DeveloperMessage(
            id="dev_123",
            content="Developer note"
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "developer")
        self.assertEqual(serialized["content"], "Developer note")

    def test_system_message(self):
        """Test creating and serializing a system message"""
        msg = SystemMessage(
            id="sys_123",
            content="System instruction"
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "system")
        self.assertEqual(serialized["content"], "System instruction")

    def test_assistant_message(self):
        """Test creating and serializing an assistant message with tool calls"""
        tool_call = ToolCall(
            id="call_456",
            function=FunctionCall(name="get_data", arguments='{"param": "value"}')
        )
        msg = AssistantMessage(
            id="asst_123",
            content="Assistant response",
            tool_calls=[tool_call]
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "assistant")
        self.assertEqual(serialized["content"], "Assistant response")
        self.assertEqual(len(serialized["toolCalls"]), 1)
        self.assertEqual(serialized["toolCalls"][0]["id"], "call_456")

    def test_user_message(self):
        """Test creating and serializing a user message"""
        msg = UserMessage(
            id="user_123",
            content="User query"
        )
        serialized = msg.model_dump(by_alias=True)
        self.assertEqual(serialized["role"], "user")
        self.assertEqual(serialized["content"], "User query")

    def test_message_union_deserialization(self):
        """Test that the Message union correctly deserializes to the appropriate type"""
        # Create type adapter for the union
        message_adapter = TypeAdapter(Message)

        # Test each message type
        message_data = [
            {"id": "dev_123", "role": "developer", "content": "Developer note"},
            {"id": "sys_456", "role": "system", "content": "System instruction"},
            {"id": "asst_789", "role": "assistant", "content": "Assistant response"},
            {"id": "user_101", "role": "user", "content": "User query"},
            {
                "id": "tool_202", 
                "role": "tool", 
                "content": "Tool result", 
                "toolCallId": "call_303"
            }
        ]

        expected_types = [
            DeveloperMessage,
            SystemMessage,
            AssistantMessage,
            UserMessage,
            ToolMessage
        ]

        for data, expected_type in zip(message_data, expected_types):
            msg = message_adapter.validate_python(data)
            self.assertIsInstance(msg, expected_type)
            self.assertEqual(msg.id, data["id"])
            self.assertEqual(msg.role, data["role"])
            self.assertEqual(msg.content, data["content"])

    def test_message_union_with_tool_calls(self):
        """Test the Message union with an assistant message containing tool calls"""
        # Create type adapter for the union
        message_adapter = TypeAdapter(Message)

        data = {
            "id": "asst_123",
            "role": "assistant",
            "content": "I'll help with that",
            "toolCalls": [
                {
                    "id": "call_456",
                    "type": "function",
                    "function": {
                        "name": "search_data",
                        "arguments": '{"query": "python"}'
                    }
                }
            ]
        }

        msg = message_adapter.validate_python(data)
        self.assertIsInstance(msg, AssistantMessage)
        self.assertEqual(len(msg.tool_calls), 1)
        self.assertEqual(msg.tool_calls[0].function.name, "search_data")

    def test_run_agent_input_deserialization(self):
        """Test deserializing RunAgentInput JSON with diverse message types"""
        # Create JSON data for RunAgentInput with diverse messages
        run_agent_input_data = {
            "threadId": "thread_12345",
            "runId": "run_67890",
            "state": {"conversation_state": "active", "custom_data": {"key": "value"}},
            "messages": [
                # System message
                {
                    "id": "sys_001",
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                # User message
                {
                    "id": "user_001",
                    "role": "user",
                    "content": "Can you help me analyze this data?"
                },
                # Developer message
                {
                    "id": "dev_001",
                    "role": "developer",
                    "content": "The assistant should provide a detailed analysis."
                },
                # Assistant message with tool calls
                {
                    "id": "asst_001",
                    "role": "assistant",
                    "content": "I'll analyze the data for you.",
                    "toolCalls": [
                        {
                            "id": "call_001",
                            "type": "function",
                            "function": {
                                "name": "analyze_data",
                                "arguments": '{"dataset": "sales_2023", "metrics": ["mean", "median"]}' # pylint: disable=line-too-long
                            }
                        }
                    ]
                },
                # Tool message responding to tool call
                {
                    "id": "tool_001",
                    "role": "tool",
                    "content": '{"mean": 42.5, "median": 38.0}',
                    "toolCallId": "call_001"
                },
                # Another user message
                {
                    "id": "user_002",
                    "role": "user",
                    "content": "Can you explain these results?"
                }
            ],
            "tools": [
                {
                    "name": "analyze_data",
                    "description": "Analyze a dataset and return statistics",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "dataset": {"type": "string"},
                            "metrics": {"type": "array", "items": {"type": "string"}}
                        },
                        "required": ["dataset"]
                    }
                },
                {
                    "name": "fetch_data",
                    "description": "Fetch data from a database",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "source": {"type": "string"},
                            "query": {"type": "string"}
                        },
                        "required": ["source", "query"]
                    }
                }
            ],
            "context": [
                {
                    "description": "User preferences",
                    "value": '{"theme": "dark", "language": "English"}'
                },
                {
                    "description": "Environment",
                    "value": "production"
                }
            ],
            "forwardedProps": {
                "api_version": "v1",
                "custom_settings": {"max_tokens": 500}
            }
        }

        # Deserialize using TypeAdapter
        run_agent_input = RunAgentInput.model_validate(run_agent_input_data)

        # Verify basic fields
        self.assertEqual(run_agent_input.thread_id, "thread_12345")
        self.assertEqual(run_agent_input.run_id, "run_67890")
        self.assertEqual(run_agent_input.state["conversation_state"], "active")

        # Verify messages count and types
        self.assertEqual(len(run_agent_input.messages), 6)
        self.assertIsInstance(run_agent_input.messages[0], SystemMessage)
        self.assertIsInstance(run_agent_input.messages[1], UserMessage)
        self.assertIsInstance(run_agent_input.messages[2], DeveloperMessage)
        self.assertIsInstance(run_agent_input.messages[3], AssistantMessage)
        self.assertIsInstance(run_agent_input.messages[4], ToolMessage)
        self.assertIsInstance(run_agent_input.messages[5], UserMessage)

        # Verify specific message content
        self.assertEqual(run_agent_input.messages[0].content, "You are a helpful assistant.")
        self.assertEqual(run_agent_input.messages[1].content, "Can you help me analyze this data?")

        # Verify assistant message with tool call
        assistant_msg = run_agent_input.messages[3]
        self.assertEqual(len(assistant_msg.tool_calls), 1)
        self.assertEqual(assistant_msg.tool_calls[0].function.name, "analyze_data")

        # Verify tool message
        tool_msg = run_agent_input.messages[4]
        self.assertEqual(tool_msg.tool_call_id, "call_001")
        self.assertEqual(tool_msg.content, '{"mean": 42.5, "median": 38.0}')

        # Verify tools
        self.assertEqual(len(run_agent_input.tools), 2)
        self.assertEqual(run_agent_input.tools[0].name, "analyze_data")
        self.assertEqual(run_agent_input.tools[1].name, "fetch_data")

        # Verify context
        self.assertEqual(len(run_agent_input.context), 2)
        self.assertEqual(run_agent_input.context[0].description, "User preferences")
        self.assertEqual(run_agent_input.context[1].value, "production")

        # Verify forwarded props
        self.assertEqual(run_agent_input.forwarded_props["api_version"], "v1")
        self.assertEqual(run_agent_input.forwarded_props["custom_settings"]["max_tokens"], 500)

    def test_validation_errors(self):
        """Test validation errors for various message types"""
        message_adapter = TypeAdapter(Message)

        # Test invalid role value
        invalid_role_data = {
            "id": "msg_123",
            "role": "invalid_role",  # Invalid role
            "content": "Hello"
        }
        with self.assertRaises(ValidationError):
            message_adapter.validate_python(invalid_role_data)

        # Test missing required fields
        missing_id_data = {
            # Missing "id" field
            "role": "user",
            "content": "Hello"
        }
        with self.assertRaises(ValidationError):
            UserMessage.model_validate(missing_id_data)

        # Test extra fields
        extra_field_data = {
            "id": "msg_456",
            "role": "user",
            "content": "Hello",
            "extra_field": "This shouldn't be here"  # Extra field
        }
        with self.assertRaises(ValidationError):
            UserMessage.model_validate(extra_field_data)

        # Test invalid tool_call_id in ToolMessage
        invalid_tool_data = {
            "id": "tool_789",
            "role": "tool",
            "content": "Result",
            # Missing required tool_call_id
        }
        with self.assertRaises(ValidationError):
            ToolMessage.model_validate(invalid_tool_data)

    def test_empty_collections(self):
        """Test RunAgentInput with empty collections"""
        # Create RunAgentInput with empty lists
        empty_collections_data = {
            "threadId": "thread_empty",
            "runId": "run_empty",
            "state": {},
            "messages": [],  # Empty messages
            "tools": [],     # Empty tools
            "context": [],   # Empty context
            "forwardedProps": {}
        }

        # Deserialize and verify
        run_input = RunAgentInput.model_validate(empty_collections_data)
        self.assertEqual(run_input.thread_id, "thread_empty")
        self.assertEqual(run_input.run_id, "run_empty")
        self.assertEqual(len(run_input.messages), 0)
        self.assertEqual(len(run_input.tools), 0)
        self.assertEqual(len(run_input.context), 0)
        self.assertEqual(run_input.forwarded_props, {})

    def test_multiple_tool_calls(self):
        """Test assistant message with multiple tool calls"""
        # Create assistant message with multiple tool calls
        assistant_data = {
            "id": "asst_multi",
            "role": "assistant",
            "content": "I'll perform multiple operations",
            "toolCalls": [
                {
                    "id": "call_1",
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "arguments": '{"location": "New York"}'
                    }
                },
                {
                    "id": "call_2",
                    "type": "function",
                    "function": {
                        "name": "search_database",
                        "arguments": '{"query": "recent sales"}'
                    }
                },
                {
                    "id": "call_3",
                    "type": "function",
                    "function": {
                        "name": "calculate",
                        "arguments": '{"operation": "sum", "values": [1, 2, 3, 4, 5]}'
                    }
                }
            ]
        }

        # Deserialize and verify
        assistant_msg = AssistantMessage.model_validate(assistant_data)
        self.assertEqual(assistant_msg.id, "asst_multi")
        self.assertEqual(len(assistant_msg.tool_calls), 3)

        # Check each tool call
        self.assertEqual(assistant_msg.tool_calls[0].id, "call_1")
        self.assertEqual(assistant_msg.tool_calls[0].function.name, "get_weather")

        self.assertEqual(assistant_msg.tool_calls[1].id, "call_2")
        self.assertEqual(assistant_msg.tool_calls[1].function.name, "search_database")

        self.assertEqual(assistant_msg.tool_calls[2].id, "call_3")
        self.assertEqual(assistant_msg.tool_calls[2].function.name, "calculate")

    def test_serialization_round_trip(self):
        """Test serializing to JSON and deserializing back to verify data integrity"""
        # Create original instance
        original_data = {
            "threadId": "thread_round_trip",
            "runId": "run_round_trip",
            "state": {"status": "active"},
            "messages": [
                {
                    "id": "sys_rt",
                    "role": "system",
                    "content": "You are a helpful assistant."
                },
                {
                    "id": "user_rt",
                    "role": "user",
                    "content": "Help me with my task."
                },
                {
                    "id": "asst_rt",
                    "role": "assistant",
                    "content": "I'll help you.",
                    "toolCalls": [
                        {
                            "id": "call_rt",
                            "type": "function",
                            "function": {
                                "name": "get_task_info",
                                "arguments": "{}"
                            }
                        }
                    ]
                }
            ],
            "tools": [
                {
                    "name": "get_task_info",
                    "description": "Get task information",
                    "parameters": {
                        "type": "object",
                        "properties": {}
                    }
                }
            ],
            "context": [
                {
                    "description": "Session",
                    "value": "123456"
                }
            ],
            "forwardedProps": {
                "timestamp": 1648214400
            }
        }

        # Deserialize
        original_obj = RunAgentInput.model_validate(original_data)

        # Serialize back to JSON
        serialized_json = original_obj.model_dump_json(by_alias=True)

        # Deserialize again
        deserialized_obj = RunAgentInput.model_validate_json(serialized_json)

        # Verify round trip preserved data
        self.assertEqual(deserialized_obj.thread_id, original_obj.thread_id)
        self.assertEqual(deserialized_obj.run_id, original_obj.run_id)
        self.assertEqual(len(deserialized_obj.messages), len(original_obj.messages))

        # Verify message types are preserved
        self.assertIsInstance(deserialized_obj.messages[0], SystemMessage)
        self.assertIsInstance(deserialized_obj.messages[1], UserMessage)
        self.assertIsInstance(deserialized_obj.messages[2], AssistantMessage)

        # Verify tool calls are preserved
        self.assertEqual(len(deserialized_obj.messages[2].tool_calls), 1)
        self.assertEqual(
            deserialized_obj.messages[2].tool_calls[0].function.name,
            original_obj.messages[2].tool_calls[0].function.name
        )

    def test_content_edge_cases(self):
        """Test edge cases for message content"""

        # Test empty content
        empty_content_data = {
            "id": "msg_empty",
            "role": "user",
            "content": ""  # Empty string
        }
        empty_msg = UserMessage.model_validate(empty_content_data)
        self.assertEqual(empty_msg.content, "")

        # Test null content (for assistant messages)
        null_content_data = {
            "id": "asst_null",
            "role": "assistant",
            "content": None,  # Null content
            "toolCalls": [
                {
                    "id": "call_null",
                    "type": "function",
                    "function": {
                        "name": "get_data",
                        "arguments": "{}"
                    }
                }
            ]
        }
        null_msg = AssistantMessage.model_validate(null_content_data)
        self.assertIsNone(null_msg.content)

        # Test large content (not testing for performance, just functionality)
        large_content = "A" * 10000  # 10K characters
        large_content_data = {
            "id": "msg_large",
            "role": "user",
            "content": large_content
        }
        large_msg = UserMessage.model_validate(large_content_data)
        self.assertEqual(len(large_msg.content), 10000)

        # Test content with special characters
        special_chars = "Special chars: 你好 こんにちは 안녕하세요 👋 🌍 \n\t\"'\\/<>{}[]"
        special_chars_data = {
            "id": "msg_special",
            "role": "user",
            "content": special_chars
        }
        special_msg = UserMessage.model_validate(special_chars_data)
        self.assertEqual(special_msg.content, special_chars)

    def test_name_field_handling(self):
        """Test optional name field in different message types"""
        # Test user message with name
        user_with_name_data = {
            "id": "user_named",
            "role": "user",
            "content": "Hello",
            "name": "John"
        }
        user_msg = UserMessage.model_validate(user_with_name_data)
        self.assertEqual(user_msg.name, "John")

        # Test assistant message with name
        assistant_with_name_data = {
            "id": "asst_named",
            "role": "assistant",
            "content": "Hello",
            "name": "AI Assistant"
        }
        assistant_msg = AssistantMessage.model_validate(assistant_with_name_data)
        self.assertEqual(assistant_msg.name, "AI Assistant")

        # Verify serialization preserves name
        serialized = assistant_msg.model_dump(by_alias=True)
        self.assertEqual(serialized["name"], "AI Assistant")

        # Verify Union type handling with name
        message_adapter = TypeAdapter(Message)
        parsed_msg = message_adapter.validate_python(assistant_with_name_data)
        self.assertEqual(parsed_msg.name, "AI Assistant")

    def test_state_variations(self):
        """Test state with different structures and complex nested objects"""
        # Simple scalar state
        scalar_state_data = {
            "threadId": "thread_scalar",
            "runId": "run_scalar",
            "state": "ACTIVE",  # Scalar state
            "messages": [],
            "tools": [],
            "context": [],
            "forwardedProps": {}
        }
        scalar_input = RunAgentInput.model_validate(scalar_state_data)
        self.assertEqual(scalar_input.state, "ACTIVE")

        # Complex nested state
        complex_state = {
            "session": {
                "id": "sess_123",
                "user": {
                    "id": "user_456",
                    "preferences": {
                        "theme": "dark",
                        "notifications": True,
                        "filters": ["important", "urgent"]
                    }
                },
                "metrics": {
                    "requests": 42,
                    "tokens": {
                        "input": 1024,
                        "output": 2048
                    }
                }
            },
            "timestamp": 1648214400,
            "version": "1.0.0"
        }

        complex_state_data = {
            "threadId": "thread_complex",
            "runId": "run_complex",
            "state": complex_state,
            "messages": [],
            "tools": [],
            "context": [],
            "forwardedProps": {}
        }
        complex_input = RunAgentInput.model_validate(complex_state_data)

        # Verify nested state structure is preserved
        self.assertEqual(complex_input.state["session"]["id"], "sess_123")
        self.assertEqual(complex_input.state["session"]["user"]["id"], "user_456")
        self.assertEqual(complex_input.state["session"]["user"]["preferences"]["theme"], "dark")
        self.assertEqual(complex_input.state["session"]["metrics"]["tokens"]["output"], 2048)
        self.assertEqual(complex_input.state["version"], "1.0.0")

        # Verify serialization round-trip works with complex state
        serialized = complex_input.model_dump(by_alias=True)
        deserialized = RunAgentInput.model_validate(serialized)
        self.assertEqual(
            deserialized.state["session"]["user"]["preferences"]["filters"],
            ["important", "urgent"]
        )


if __name__ == "__main__":
    unittest.main()



================================================
FILE: typescript-sdk/README.md
================================================
# Agent User Interaction Protocol TypeScript SDK

The TypeScript SDK for the [Agent User Interaction Protocol](https://ag-ui.com).

For more information visit the [official documentation](https://docs.ag-ui.com/).



================================================
FILE: typescript-sdk/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: typescript-sdk/package.json
================================================
{
  "name": "ag-ui",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "private": true,
  "scripts": {
    "build": "turbo run build",
    "clean": "rm -rf dist .turbo node_modules && pnpm -r clean",
    "build:clean": "rm -rf dist .turbo node_modules && pnpm -r clean && pnpm install && turbo run build",
    "dev": "turbo run dev",
    "start": "turbo run start",
    "lint": "turbo run lint",
    "format": "prettier --write \"**/*.{ts,tsx,md,mdx}\"",
    "check-types": "turbo run check-types",
    "test": "turbo run test",
    "bump": "pnpm --filter './packages/*' exec -- pnpm version",
    "bump:alpha": "pnpm --filter './packages/*' exec -- pnpm version --preid alpha",
    "publish": "pnpm -r clean && pnpm install && turbo run build && pnpm publish -r --filter='./packages/*'",
    "publish:integrations": "pnpm -r clean && pnpm install && turbo run build && pnpm publish -r --filter='./integrations/*'",
    "publish:alpha": "pnpm -r clean && pnpm install && turbo run build && pnpm publish -r --no-git-checks --filter='./packages/*' --tag alpha"
  },
  "devDependencies": {
    "prettier": "^3.5.3",
    "turbo": "^2.4.4",
    "typescript": "5.8.2"
  },
  "packageManager": "pnpm@10.13.1",
  "engines": {
    "node": ">=18"
  },
  "version": "0.0.1"
}



================================================
FILE: typescript-sdk/pnpm-workspace.yaml
================================================
packages:
  - "apps/*"
  - "packages/*"
  - "integrations/*"



================================================
FILE: typescript-sdk/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2019",
    "module": "ESNext",
    "moduleResolution": "node",
    "declaration": true,
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  }
}



================================================
FILE: typescript-sdk/turbo.json
================================================
{
  "$schema": "https://turbo.build/schema.json",
  "ui": "tui",
  "envMode": "loose",
  "concurrency": "20",
  "tasks": {
    "generate": {
      "outputs": ["src/generated/**"]
    },
    "build": {
      "dependsOn": ["^build", "generate"],
      "inputs": ["$TURBO_DEFAULT$", ".env*"],
      "outputs": ["dist/**", ".next/**", "!.next/cache/**"]
    },
    "demo-viewer#build": {
      "dependsOn": ["^build", "generate"],
      "inputs": ["$TURBO_DEFAULT$", ".env*"],
      "outputs": ["dist/**", ".next/**", "!.next/cache/**"]
    },
    "lint": {
      "dependsOn": ["^lint"]
    },
    "check-types": {
      "dependsOn": ["^check-types"]
    },
    "dev": {
      "dependsOn": ["^build", "generate"],
      "cache": false,
      "persistent": true
    },
    "demo-viewer#dev": {
      "dependsOn": ["^build", "generate"],
      "cache": false,
      "persistent": true
    },
    "test": {
      "dependsOn": ["^build"],
      "outputs": []
    },
    "link:global": {
      "cache": false
    },
    "unlink:global": {
      "cache": false
    },
    "start": {
      "dependsOn": ["^build"],
      "cache": false,
      "persistent": true
    }
  }
}



================================================
FILE: typescript-sdk/.npmrc
================================================
[Empty file]


================================================
FILE: typescript-sdk/.prettierrc
================================================
{
  "printWidth": 100,
  "singleQuote": false,
  "semi": true,
  "tabWidth": 2,
  "overrides": [
    {
      "files": "*.mdx",
      "options": {
        "printWidth": 80,
        "proseWrap": "always",
        "semi": false,
        "singleQuote": false
      }
    }
  ]
}



================================================
FILE: typescript-sdk/apps/client-cli-example/README.md
================================================
# AG-UI CLI



================================================
FILE: typescript-sdk/apps/client-cli-example/package.json
================================================
{
  "name": "client-cli-example",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "start": "tsx src/index.ts",
    "dev": "tsx --watch src/index.ts",
    "build": "tsc",
    "clean": "rm -rf dist"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*",
    "@ag-ui/core": "workspace:*",
    "@ag-ui/mastra": "workspace:*",
    "@ai-sdk/openai": "1.3.22",
    "@mastra/client-js": "0.10.18",
    "@mastra/core": "0.12.1",
    "@mastra/libsql": "0.12.0",
    "@mastra/loggers": "0.10.5",
    "@mastra/memory": "0.12.0",
    "open": "^10.1.2",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/node": "^20",
    "tsx": "^4.7.0",
    "typescript": "^5"
  }
}



================================================
FILE: typescript-sdk/apps/client-cli-example/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020", "dom"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "moduleResolution": "node"
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/apps/client-cli-example/src/agent.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { MastraAgent } from "@ag-ui/mastra";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { weatherTool } from "./tools/weather.tool";
import { browserTool } from "./tools/browser.tool";

export const agent = new MastraAgent({
  // @ts-ignore
  agent: new Agent({
    name: "AG-UI Agent",
    instructions: `
        You are a helpful assistant that runs a CLI application.
  
        When helping users get weather details for specific locations, respond:
        - Always ask for a location if none is provided.
        - If the location name isn’t in English, please translate it
        - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
        - Include relevant details like humidity, wind conditions, and precipitation
        - Keep responses concise but informative
  
        Use the weatherTool to fetch current weather data.

        When helping users browse the web, always use a full URL, for example: "https://www.google.com"
        Use the browserTool to browse the web.

  `,
    model: openai("gpt-4o-mini"),
    tools: { weatherTool, browserTool },
    memory: new Memory({
      storage: new LibSQLStore({
        url: "file:./mastra.db",
      }),
    }),
  }),
  threadId: "1",
});



================================================
FILE: typescript-sdk/apps/client-cli-example/src/index.ts
================================================
import * as readline from "readline";
import { agent } from "./agent";
import { randomUUID } from "node:crypto";

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

async function chatLoop() {
  console.log("🤖 AG-UI chat started! Type your messages and press Enter. Press Ctrl+D to quit.\n");

  return new Promise<void>((resolve) => {
    const promptUser = () => {
      rl.question("> ", async (input) => {
        if (input.trim() === "") {
          promptUser();
          return;
        }
        console.log("");

        rl.pause();

        agent.messages.push({
          id: randomUUID(),
          role: "user",
          content: input.trim(),
        });

        try {
          await agent.runAgent(
            {},
            {
              onTextMessageStartEvent() {
                process.stdout.write("🤖 AG-UI assistant: ");
              },
              onTextMessageContentEvent({ event }) {
                process.stdout.write(event.delta);
              },
              onTextMessageEndEvent() {
                console.log("\n");
              },
              onToolCallStartEvent({ event }) {
                console.log("🔧 Tool call:", event.toolCallName);
              },
              onToolCallArgsEvent({ event }) {
                process.stdout.write(event.delta);
              },
              onToolCallEndEvent() {
                console.log("");
              },
              onToolCallResultEvent({ event }) {
                if (event.content) {
                  console.log("🔍 Tool call result:", event.content);
                }
              },
            },
          );
        } catch (error) {
          console.error("❌ Error running agent:", error);
        }

        rl.resume();
        promptUser();
      });
    };

    rl.on("close", () => {
      console.log("\n👋 Goodbye!");
      resolve();
    });

    promptUser();
  });
}

async function main() {
  await chatLoop();
}

main().catch(console.error);



================================================
FILE: typescript-sdk/apps/client-cli-example/src/tools/browser.tool.ts
================================================
import { createTool } from "@mastra/core/tools";
import { z } from "zod";
import open from "open";

export const browserTool = createTool({
  id: "browser",
  description: "Browse the web",
  inputSchema: z.object({
    url: z.string().describe("URL to browse"),
  }),
  outputSchema: z.string(),
  execute: async ({ context }) => {
    open(context.url);
    return `Browsed ${context.url}`;
  },
});



================================================
FILE: typescript-sdk/apps/client-cli-example/src/tools/weather.tool.ts
================================================
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

interface GeocodingResponse {
  results: {
    latitude: number;
    longitude: number;
    name: string;
  }[];
}
interface WeatherResponse {
  current: {
    time: string;
    temperature_2m: number;
    apparent_temperature: number;
    relative_humidity_2m: number;
    wind_speed_10m: number;
    wind_gusts_10m: number;
    weather_code: number;
  };
}

export const weatherTool = createTool({
  id: "get-weather",
  description: "Get current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("City name"),
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string(),
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location);
  },
});

const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;
  const geocodingResponse = await fetch(geocodingUrl);
  const geocodingData = (await geocodingResponse.json()) as GeocodingResponse;

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`);
  }

  const { latitude, longitude, name } = geocodingData.results[0];

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;

  const response = await fetch(weatherUrl);
  const data = (await response.json()) as WeatherResponse;

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name,
  };
};

function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    56: "Light freezing drizzle",
    57: "Dense freezing drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    66: "Light freezing rain",
    67: "Heavy freezing rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    77: "Snow grains",
    80: "Slight rain showers",
    81: "Moderate rain showers",
    82: "Violent rain showers",
    85: "Slight snow showers",
    86: "Heavy snow showers",
    95: "Thunderstorm",
    96: "Thunderstorm with slight hail",
    99: "Thunderstorm with heavy hail",
  };
  return conditions[code] || "Unknown";
}



================================================
FILE: typescript-sdk/apps/dojo/README.md
================================================
# AG-UI Protocol Dojo

A modern, interactive viewer for exploring CopilotKit agent demos with a clean, responsive UI and dark/light theme support.

## Overview

The Demo Viewer provides a centralized interface for browsing, viewing, and exploring the source code of various CopilotKit agent demos. It features:

- Clean, modern UI with dark/light theme support
- Interactive demo previews
- Source code exploration with syntax highlighting
- Organized demo listing with tags and descriptions
- LLM provider selection

## Development Setup

To run the Demo Viewer locally for development, follow these steps:

### Install dependencies

```bash
brew install protobuf
```

```bash
npm i turbo
```

```bash
curl -fsSL https://get.pnpm.io/install.sh | sh -
```

### Run the Demo Viewer

In a new terminal, navigate to the project root and start the Demo Viewer:

```bash
pnpm install
pnpm run dev
```

The Demo Viewer should now be running at [http://localhost:3000](http://localhost:3000).

### Adding a new integration

On a fresh clone of this repo, you'll find that we've created a mock agent that represents all of the events needed to create an ACP compliant agent. To extend this to support
your own integration, you'll need to:

1. Edit `src/examples/your-custom-http-agent.ts` to implement your own agent.
2. Alternatively, edit `src/examples/your-custom-agent.ts` to implement a non http based integration.
3. Read `src/app/api/sse/agentic_chat/route.ts` to understand what events need to be emitted on the agent side.

## Project Structure

- `src/examples` - Example agents
- `src/app` - Next.js app router files
- `src/components` - Reusable UI components
- `src/demos` - Demo configuration and utilities
- `src/hooks` - Custom React hooks
- `src/types` - TypeScript type definitions
- `public` - Static assets

## Technologies

- Next.js
- React
- TypeScript
- Tailwind CSS
- CopilotKit



================================================
FILE: typescript-sdk/apps/dojo/eslint.config.mjs
================================================
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  // ...compat.extends("next/core-web-vitals", "next/typescript"),
  ...compat.config({
    extends: ["next"],
    rules: {
      "@typescript-eslint/no-unused-vars": "off",
    },
  }),
];

export default eslintConfig;



================================================
FILE: typescript-sdk/apps/dojo/LICENSE
================================================
Copyright (c) 2025 Tawkit Inc.
Copyright (c) 2025 Markus Ecker

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



================================================
FILE: typescript-sdk/apps/dojo/next.config.ts
================================================
import type { NextConfig } from "next";
import createMDX from "@next/mdx";

const withMDX = createMDX({
  extension: /\.mdx?$/,
  options: {
    // If you use remark-gfm, you'll need to use next.config.mjs
    // as the package is ESM only
    // https://github.com/remarkjs/remark-gfm#install
    remarkPlugins: [],
    rehypePlugins: [],
    // If you use `MDXProvider`, uncomment the following line.
    providerImportSource: "@mdx-js/react",
  },
});

const nextConfig: NextConfig = {
  /* config options here */
  // Configure pageExtensions to include md and mdx
  pageExtensions: ["ts", "tsx", "js", "jsx", "md", "mdx"],
  webpack: (config, { isServer }) => {
    // Ignore the demo files during build
    config.module.rules.push({
      test: /agent\/demo\/crew_enterprise\/ui\/.*\.(ts|tsx|js|jsx)$/,
      loader: "ignore-loader",
    });

    return config;
  },
  serverExternalPackages: ["@mastra/libsql"],
};

// Merge MDX config with Next.js config
export default withMDX(nextConfig);



================================================
FILE: typescript-sdk/apps/dojo/package.json
================================================
{
  "name": "demo-viewer",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "npm run generate-content-json && next dev",
    "build": "next build",
    "start": "npm run generate-content-json && next start",
    "lint": "next lint",
    "mastra:dev": "mastra dev",
    "generate-content-json": "npx tsx scripts/generate-content-json.ts"
  },
  "dependencies": {
    "@ag-ui/adk": "workspace:*",
    "@ag-ui/agno": "workspace:*",
    "@ag-ui/crewai": "workspace:*",
    "@ag-ui/langgraph": "workspace:*",
    "@ag-ui/llamaindex": "workspace:*",
    "@ag-ui/mastra": "workspace:*",
    "@ag-ui/middleware-starter": "workspace:*",
    "@ag-ui/pydantic-ai": "workspace:*",
    "@ag-ui/server-starter": "workspace:*",
    "@ag-ui/server-starter-all-features": "workspace:*",
    "@ag-ui/vercel-ai-sdk": "workspace:*",
    "@ai-sdk/openai": "^1.3.22",
    "@copilotkit/react-core": "1.10.5",
    "@copilotkit/react-ui": "1.10.5",
    "@copilotkit/runtime": "1.10.5",
    "@copilotkit/runtime-client-gql": "1.10.5",
    "@copilotkit/shared": "1.10.5",
    "@mastra/client-js": "^0.10.18",
    "@mastra/core": "^0.13.0",
    "@mastra/dynamodb": "^0.13.3",
    "@mastra/libsql": "^0.13.0",
    "@mastra/loggers": "^0.10.5",
    "@mastra/memory": "^0.12.0",
    "@mdx-js/loader": "^3.1.0",
    "@mdx-js/mdx": "^3.1.0",
    "@mdx-js/react": "^3.1.0",
    "@monaco-editor/react": "^4.7.0",
    "@next/mdx": "^15.2.3",
    "@phosphor-icons/react": "^2.1.10",
    "@radix-ui/react-dropdown-menu": "^2.1.6",
    "@radix-ui/react-slot": "^1.1.2",
    "@radix-ui/react-tabs": "^1.1.3",
    "@tiptap/extension-color": "^2.11.5",
    "@tiptap/extension-placeholder": "^2.11.5",
    "@tiptap/pm": "^2.11.5",
    "@tiptap/react": "^2.11.5",
    "@tiptap/starter-kit": "^2.11.5",
    "@types/react-syntax-highlighter": "^15.5.13",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "diff": "^7.0.0",
    "fast-json-patch": "^3.1.1",
    "lucide-react": "^0.477.0",
    "markdown-it": "^14.1.0",
    "markdown-it-ins": "^4.0.0",
    "next": "15.2.1",
    "next-themes": "^0.4.6",
    "openai": "^4.98.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-markdown": "^10.1.0",
    "react-syntax-highlighter": "^15.6.1",
    "rxjs": "7.8.1",
    "tailwind-merge": "^3.0.2",
    "tailwindcss-animate": "^1.0.7",
    "uuid": "^11.1.0",
    "zod": "^3.22.4"
  },
  "peerDependencies": {
    "@ag-ui/client": "workspace:*",
    "@ag-ui/core": "workspace:*",
    "@ag-ui/encoder": "workspace:*",
    "@ag-ui/proto": "workspace:*"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@shadcn/ui": "^0.0.4",
    "@tailwindcss/postcss": "^4",
    "@tailwindcss/typography": "^0.5.16",
    "@types/diff": "^7.0.1",
    "@types/markdown-it": "^14.1.2",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "concurrently": "^9.2.0",
    "eslint": "^9",
    "eslint-config-next": "15.2.1",
    "tailwindcss": "^4",
    "tsx": "^4.7.0",
    "typescript": "^5",
    "wait-port": "^1.1.0"
  }
}


================================================
FILE: typescript-sdk/apps/dojo/postcss.config.mjs
================================================
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;



================================================
FILE: typescript-sdk/apps/dojo/tailwind.config.ts
================================================
import type { Config } from "tailwindcss";

const config = {
  darkMode: "class",
  content: [
    "./pages/**/*.{ts,tsx}",
    "./components/**/*.{ts,tsx}",
    "./app/**/*.{ts,tsx}",
    "./src/**/*.{ts,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        // Shadcn/ui colors
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      fontFamily: {
        sans: ['Plus Jakarta Sans', 'ui-sans-serif', 'system-ui', 'sans-serif'],
        mono: ['Spline Sans Mono', 'ui-monospace', 'SFMono-Regular', 'monospace'],
      },
      boxShadow: {
        'elevation-sm': 'var(--shadow-sm)',
        'elevation-md': 'var(--shadow-md)',
        'elevation-lg': 'var(--shadow-lg)',
        'elevation-xl': 'var(--shadow-xl)',
      },
      keyframes: {
        "accordion-down": {
          from: { height: "0" },
          to: { height: "var(--radix-accordion-content-height)" },
        },
        "accordion-up": {
          from: { height: "var(--radix-accordion-content-height)" },
          to: { height: "0" },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
    },
  },
  plugins: [require("tailwindcss-animate"), require("@tailwindcss/typography")],
} satisfies Config;

export default config;


================================================
FILE: typescript-sdk/apps/dojo/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*", "../../packages/client/src/*"],
      "@ag-ui/client": ["../../packages/client/src"],
      "@ag-ui/client/*": ["../../packages/client/src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules", "e2e"]
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/README.md
================================================
# CopilotKit Demo Smoke Tests

This repository houses Playwright-based smoke tests that run on a 6-hour schedule to make sure CopilotKit demo apps remain live and functional.

## 🔧 Local development

```bash
# Install deps
npm install

# Install browsers once
npx playwright install --with-deps

# Run the full suite
npm test
```

Playwright HTML reports are saved to `./playwright-report`.

## ➕ Adding a new smoke test

1. Duplicate an existing file in `tests/` or create `tests/<demo>.spec.ts`.
2. Use Playwright's `test` API—keep the test short (<30 s).
3. Commit and push—GitHub Actions will pick it up on the next scheduled run.

## 🚦 CI / CD

- `.github/workflows/scheduled-tests.yml` executes the suite every 6 hours and on manual trigger.
- Failing runs surface in the Actions tab; the HTML report is uploaded as an artifact.
- (Optional) Slack notifications can be wired by adding a step after the tests.
- Slack alert on failure is baked into the workflow. Just add `SLACK_WEBHOOK_URL` (Incoming Webhook) in repo secrets.



================================================
FILE: typescript-sdk/apps/dojo/e2e/clean-reporter.js
================================================
function getTimestamp() {
  return (process.env.CI || process.env.VERBOSE)
    ? new Date().toLocaleTimeString('en-US', { hour12: false })
    : '';
}

function logStamp(...args) {
  console.log(getTimestamp(), ...args);
}

class CleanReporter {
  onBegin(config, suite) {
    console.log(`\n🎭 Running ${suite.allTests().length} tests...\n`);
  }

  onTestEnd(test, result) {
    const suiteName = test.parent?.title || "Unknown";
    const testName = test.title;

    // Clean up suite name
    const cleanSuite = suiteName
      .replace(/Tests?$/i, "")
      .replace(/Page$/i, "")
      .replace(/([a-z])([A-Z])/g, "$1 $2")
      .trim();

    if (result.status === "passed") {
      logStamp(`✅ ${cleanSuite}: ${testName}`);
    } else if (result.status === "failed") {
      logStamp(`❌ ${cleanSuite}: ${testName}`);

      // Extract the most relevant error info
      const error = result.error || result.errors?.[0];
      if (error) {
        let errorMsg = error.message || "Unknown error";

        // Clean up common error patterns to make them more readable
        if (errorMsg.includes("None of the expected patterns matched")) {
          const patterns = errorMsg.match(/patterns matched[^:]*: ([^`]+)/);
          errorMsg = `AI response timeout - Expected: ${
            patterns?.[1] || "AI response"
          }`;
        } else if (
          errorMsg.includes("Timed out") &&
          errorMsg.includes("toBeVisible")
        ) {
          const element = errorMsg.match(/locator\('([^']+)'\)/);
          errorMsg = `Element not found: ${element?.[1] || "UI element"}`;
        } else if (errorMsg.includes("toBeGreaterThan")) {
          errorMsg = "Expected content not generated (count was 0)";
        }

        // Show just the key error info
        console.log(`   💥 ${errorMsg.split("\n")[0]}`);

        // If it's an AI/API issue, make it clear
        if (
          errorMsg.includes("AI") ||
          errorMsg.includes("patterns") ||
          errorMsg.includes("timeout")
        ) {
          console.log(`   🔑 Likely cause: AI service down or API key issue`);
        }
      }
      console.log(""); // Extra spacing after failures
    } else if (result.status === "skipped") {
      console.log(`⏭ ${cleanSuite}: ${testName} (skipped)`);
    }
  }

  onEnd(result) {
    console.log("\n" + "=".repeat(60));
    logStamp(`📊 TEST SUMMARY`);
    console.log("=".repeat(60));

    if (!process.env.CI) {
      console.log(
        `• Run 'pnpm exec playwright show-report' for detailed HTML report`
      );
    }

    console.log("=".repeat(60) + "\n");
  }
}

module.exports = CleanReporter;



================================================
FILE: typescript-sdk/apps/dojo/e2e/package.json
================================================
{
  "name": "copilotkit-e2e",
  "version": "0.1.0",
  "private": true,
  "description": "Scheduled Playwright smoke tests for CopilotKit demo apps",
  "scripts": {
    "postinstall": "playwright install --with-deps",
    "test": "playwright test",
    "test:ui": "playwright test --ui",
    "report": "playwright show-report"
  },
  "devDependencies": {
    "@playwright/test": "^1.43.1",
    "@slack/types": "^2.14.0",
    "@types/node": "^22.15.28",
    "playwright-slack-report": "^1.1.93"
  },
  "dependencies": {
    "@aws-sdk/client-s3": "^3.600.0",
    "json2md": "^2.0.1"
  }
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/playwright.config.ts
================================================
import { defineConfig, ReporterDescription } from "@playwright/test";
import { generateSimpleLayout } from "./slack-layout-simple";



function getReporters(): ReporterDescription[] {
  const videoReporter: ReporterDescription = [
    "./reporters/s3-video-reporter.ts",
    {
      outputFile: "test-results/video-urls.json",
      uploadVideos: true,
    },
  ];
  const s3Reporter: ReporterDescription = [
      "./node_modules/playwright-slack-report/dist/src/SlackReporter.js",
      {
        slackWebHookUrl: process.env.SLACK_WEBHOOK_URL,
        sendResults: "always", // always send results
        maxNumberOfFailuresToShow: 10,
        layout: generateSimpleLayout, // Use our simple layout
      },
    ];
  const githubReporter: ReporterDescription = ["github"];
  const htmlReporter: ReporterDescription = ["html", { open: "never" }];
  const cleanReporter: ReporterDescription = ["./clean-reporter.js"];

  const addVideoAndSlack = process.env.SLACK_WEBHOOK_URL && process.env.AWS_S3_BUCKET_NAME;

  return [
    process.env.CI ? githubReporter : undefined,
    addVideoAndSlack ? videoReporter : undefined,
    addVideoAndSlack ? s3Reporter : undefined,
    htmlReporter,
    cleanReporter,
  ].filter(Boolean) as ReporterDescription[];
}

function getBaseUrl(): string {
  if (process.env.BASE_URL) {
    return new URL(process.env.BASE_URL).toString();
  }
  console.error("BASE_URL is not set");
  process.exit(1);
}

export default defineConfig({
  timeout: process.env.CI ? 300_000 : 120_000, // 5min in CI, 2min locally for AI tests
  testDir: "./tests",
  retries: process.env.CI ? 3 : 0, // More retries for flaky AI tests in CI, 0 for local
  // Make this sequential for now to avoid race conditions
  workers: process.env.CI ? 1 : undefined,
  fullyParallel: process.env.CI ? false : true,
  use: {
    headless: true,
    viewport: { width: 1280, height: 720 },
    // Video recording for failed tests
    video: {
      mode: "retain-on-failure", // Only keep videos for failed tests
      size: { width: 1280, height: 720 },
    },
    // Increased timeouts for AI interactions
    navigationTimeout: 90_000, // 1.5 minutes for slow AI app loads
    actionTimeout: 60_000, // 1 minute for AI-driven actions (clicking, filling)
    // Test isolation - ensure clean state between tests
    testIdAttribute: "data-testid",
    baseURL: getBaseUrl(),
  },
  expect: {
    timeout: 120_000, // 2 minutes for AI-generated content to appear
  },
  // Test isolation between each test
  projects: [
    {
      name: "chromium",
      use: {
        ...require("@playwright/test").devices["Desktop Chrome"],
        // Force new context for each test to ensure isolation
        contextOptions: {
          // Clear all data between tests
          storageState: undefined,
        },
      },
    },
  ],
  reporter: getReporters(),
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/pnpm-workspace.yaml
================================================
packages:
  - '.'


================================================
FILE: typescript-sdk/apps/dojo/e2e/setup-aws.sh
================================================
#!/bin/bash

# AWS S3 Video Upload Setup Script
# This script creates the necessary AWS infrastructure for Playwright video uploads

set -e  # Exit on any error

# Configuration
BUCKET_NAME="copilotkit-e2e-smoke-test-recordings-$(openssl rand -hex 4)"
IAM_USER_NAME="copilotkit-e2e-smoke-test-uploader"
POLICY_NAME="CopilotKitE2ESmokeTestVideoUploadPolicy"
AWS_REGION="us-east-1"

echo "🚀 Setting up AWS infrastructure for Playwright video uploads..."
echo "Bucket name: $BUCKET_NAME"
echo "IAM user: $IAM_USER_NAME"
echo "Region: $AWS_REGION"
echo ""

# Check if AWS CLI is installed and configured
if ! command -v aws &> /dev/null; then
    echo "❌ AWS CLI is not installed. Please install it first."
    exit 1
fi

# Check if AWS credentials are configured
if ! aws sts get-caller-identity &> /dev/null; then
    echo "❌ AWS credentials not configured. Run 'aws configure' first."
    exit 1
fi

echo "✅ AWS CLI is configured"

# Step 1: Create S3 Bucket
echo "📦 Creating S3 bucket: $BUCKET_NAME"
aws s3api create-bucket \
    --bucket "$BUCKET_NAME" \
    --region "$AWS_REGION" \
    --create-bucket-configuration LocationConstraint="$AWS_REGION" 2>/dev/null || {
    # Handle us-east-1 special case (no LocationConstraint needed)
    if [ "$AWS_REGION" = "us-east-1" ]; then
        aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$AWS_REGION"
    else
        echo "❌ Failed to create bucket"
        exit 1
    fi
}

# Step 2: Configure bucket for public read access
echo "🔓 Configuring bucket for public read access..."

# Disable block public access
aws s3api put-public-access-block \
    --bucket "$BUCKET_NAME" \
    --public-access-block-configuration \
    "BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false"

# Apply bucket policy for public read access
aws s3api put-bucket-policy --bucket "$BUCKET_NAME" --policy "{
    \"Version\": \"2012-10-17\",
    \"Statement\": [
        {
            \"Sid\": \"PublicReadGetObject\",
            \"Effect\": \"Allow\",
            \"Principal\": \"*\",
            \"Action\": \"s3:GetObject\",
            \"Resource\": \"arn:aws:s3:::$BUCKET_NAME/*\"
        }
    ]
}"

# Step 3: Set up lifecycle policy for automatic cleanup (30 days)
echo "🗂️ Setting up lifecycle policy for automatic cleanup..."
aws s3api put-bucket-lifecycle-configuration \
    --bucket "$BUCKET_NAME" \
    --lifecycle-configuration '{
        "Rules": [
            {
                "ID": "DeleteOldVideos",
                "Status": "Enabled",
                "Filter": {
                    "Prefix": "github-runs/"
                },
                "Expiration": {
                    "Days": 30
                }
            }
        ]
    }'

# Step 4: Create IAM policy for S3 upload permissions
echo "👤 Creating IAM policy..."
POLICY_ARN=$(aws iam create-policy \
    --policy-name "$POLICY_NAME" \
    --policy-document '{
        "Version": "2012-10-17",
        "Statement": [
            {
                "Sid": "S3VideoUploadPermissions",
                "Effect": "Allow",
                "Action": [
                    "s3:PutObject",
                    "s3:PutObjectAcl",
                    "s3:GetObject"
                ],
                "Resource": "arn:aws:s3:::'"$BUCKET_NAME"'/*"
            },
            {
                "Sid": "S3ListBucketPermission",
                "Effect": "Allow",
                "Action": "s3:ListBucket",
                "Resource": "arn:aws:s3:::'"$BUCKET_NAME"'"
            }
        ]
    }' \
    --query 'Policy.Arn' \
    --output text)

echo "✅ Created policy: $POLICY_ARN"

# Step 5: Create IAM user
echo "👤 Creating IAM user: $IAM_USER_NAME"
aws iam create-user --user-name "$IAM_USER_NAME" || {
    echo "⚠️  User might already exist, continuing..."
}

# Step 6: Attach policy to user
echo "🔗 Attaching policy to user..."
aws iam attach-user-policy \
    --user-name "$IAM_USER_NAME" \
    --policy-arn "$POLICY_ARN"

# Step 7: Create access keys
echo "🔑 Creating access keys..."
ACCESS_KEY_OUTPUT=$(aws iam create-access-key --user-name "$IAM_USER_NAME")
ACCESS_KEY_ID=$(echo "$ACCESS_KEY_OUTPUT" | jq -r '.AccessKey.AccessKeyId')
SECRET_ACCESS_KEY=$(echo "$ACCESS_KEY_OUTPUT" | jq -r '.AccessKey.SecretAccessKey')

# No temporary files to clean up

# Step 8: Test the setup
echo "🧪 Testing S3 upload..."
echo "test file" > /tmp/test-upload.txt
aws s3 cp /tmp/test-upload.txt "s3://$BUCKET_NAME/test-upload.txt" \
    --region "$AWS_REGION"

# Test public access
TEST_URL="https://$BUCKET_NAME.s3.$AWS_REGION.amazonaws.com/test-upload.txt"
echo "🌐 Testing public access..."
if curl -s -f "$TEST_URL" > /dev/null; then
    echo "✅ Public access working!"
else
    echo "⚠️  Public access test failed, but bucket is created"
fi

# Clean up test file
aws s3 rm "s3://$BUCKET_NAME/test-upload.txt"
rm -f /tmp/test-upload.txt

echo ""
echo "🎉 AWS Setup Complete!"
echo "===================="
echo ""
echo "📋 Add these to your GitHub repository secrets:"
echo "AWS_ACCESS_KEY_ID: $ACCESS_KEY_ID"
echo "AWS_SECRET_ACCESS_KEY: $SECRET_ACCESS_KEY"
echo ""
echo "📦 S3 Bucket Details:"
echo "Bucket Name: $BUCKET_NAME"
echo "Region: $AWS_REGION"
echo "Public URL Pattern: https://$BUCKET_NAME.s3.$AWS_REGION.amazonaws.com/{path}"
echo ""
echo "🔄 Next Steps:"
echo "1. Add the above secrets to your GitHub repository"
echo "2. Update your Playwright configuration with the bucket name"
echo "3. Run your tests to start uploading videos!"
echo ""
echo "💡 Videos will be automatically deleted after 30 days"
echo "💡 Upload path format: github-runs/{RUN_ID}/{PROJECT}/{filename}.webm" 


================================================
FILE: typescript-sdk/apps/dojo/e2e/slack-layout-simple.ts
================================================
import { Block, KnownBlock } from "@slack/types";
import { SummaryResults } from "playwright-slack-report/dist/src";
import { readFileSync, existsSync } from "fs";

interface VideoInfo {
  url: string;
  testName: string;
}

function getVideos(): VideoInfo[] {
  const videoFilePath = "test-results/video-urls.json";
  if (!existsSync(videoFilePath)) {
    return [];
  }

  try {
    const videoData = JSON.parse(readFileSync(videoFilePath, "utf8"));
    return videoData.videos || [];
  } catch (error) {
    console.error("Failed to read videos:", error);
    return [];
  }
}

export function generateSimpleLayout(
  summaryResults: SummaryResults
): Array<KnownBlock | Block> {
  const { passed, failed, skipped, tests } = summaryResults;

  // Summary
  const summary = {
    type: "section",
    text: {
      type: "mrkdwn",
      text:
        failed === 0
          ? `✅ All ${passed} tests passed!`
          : `✅ ${passed} passed • ❌ ${failed} failed • ⏭ ${skipped} skipped`,
    },
  };

  if (failed === 0) {
    return [summary];
  }

  // Get videos
  const videos = getVideos();
  const videoMap = new Map(videos.map((v) => [v.testName, v.url]));

  // List failed tests
  const failedTests = tests.filter(
    (test) => test.status === "failed" || test.status === "timedOut"
  );

  const failureLines = failedTests.map((test) => {
    const videoUrl = videoMap.get(test.name);
    const videoLink = videoUrl ? ` • <${videoUrl}|📹 Video>` : "";
    return `• *${test.name}*${videoLink}`;
  });

  const failures = {
    type: "section",
    text: {
      type: "mrkdwn",
      text: `*Failed Tests:*\n${failureLines.join("\n")}`,
    },
  };

  return [summary, failures];
}

export default generateSimpleLayout;



================================================
FILE: typescript-sdk/apps/dojo/e2e/slack-layout.ts
================================================
import { Block, KnownBlock } from "@slack/types";
import { SummaryResults } from "playwright-slack-report/dist/src";
import { readFileSync, existsSync } from "fs";

interface VideoInfo {
  url: string;
  testName: string;
  suiteName?: string;
  category?: string;
}

function getVideosByCategory(): Map<string, VideoInfo[]> {
  const categoryMap = new Map<string, VideoInfo[]>();

  // Read from the JSON file that S3 reporter creates
  const videoFilePath = "test-results/video-urls.json";
  if (!existsSync(videoFilePath)) {
    console.log("📹 No video URLs file found yet");
    return categoryMap;
  }

  try {
    const videoData = JSON.parse(readFileSync(videoFilePath, "utf8"));
    const videos: VideoInfo[] = videoData.videos || [];

    for (const video of videos) {
      const category = video.category || "❓ Other Issues";
      if (!categoryMap.has(category)) {
        categoryMap.set(category, []);
      }
      categoryMap.get(category)!.push(video);
    }

    console.log(`📹 Loaded ${videos.length} videos from file for Slack`);
  } catch (error) {
    console.error("📹 Failed to read video URLs file:", error);
  }

  return categoryMap;
}

function getTestDisplayName(test: any): string {
  // Create a cleaner test name
  const suiteName =
    test.suiteName ||
    test.file?.replace(/\.spec\.ts$/, "").replace(/Tests?/g, "");
  const testName = test.name;

  // Remove redundant words and clean up
  const cleanSuite = suiteName
    ?.replace(/Tests?$/i, "")
    ?.replace(/Page$/i, "")
    ?.replace(/Spec$/i, "")
    ?.replace(/([a-z])([A-Z])/g, "$1 $2") // camelCase to spaces
    ?.trim();

  return `${cleanSuite}: ${testName}`;
}

function categorizeAndCleanError(test: any): {
  category: string;
  cleanError: string;
  action: string;
} {
  const error =
    test.error?.message || test.errors?.[0]?.message || "Unknown error";

  // Debug logging to see what error data we're getting
  console.log(`🐛 DEBUG: Categorizing test "${test.name}"`);
  console.log(
    `🐛 DEBUG: Error object:`,
    JSON.stringify(
      {
        hasError: !!test.error,
        hasErrors: !!test.errors,
        errorMessage: test.error?.message,
        errorsLength: test.errors?.length,
        firstErrorMessage: test.errors?.[0]?.message,
      },
      null,
      2
    )
  );

  // AI Response Timeouts
  if (error.includes("None of the expected patterns matched")) {
    const patterns = error.match(/patterns matched[^:]*: ([^`]+)/);
    return {
      category: "🤖 AI Response Issues",
      cleanError: `No AI response - Expected: ${
        patterns?.[1] || "AI response"
      }`,
      action: "Check API keys and AI service status",
    };
  }

  // Test timeout (usually AI-related in our suite)
  if (
    error.includes("Test timeout") ||
    test.name?.toLowerCase().includes("human")
  ) {
    return {
      category: "🤖 AI Response Issues",
      cleanError: "Test timeout waiting for AI response",
      action: "Check AI service availability and response times",
    };
  }

  // UI Element Missing
  if (error.includes("Timed out") && error.includes("toBeVisible")) {
    const element = error.match(/locator\('([^']+)'\)/);
    return {
      category: "🎨 UI Issues",
      cleanError: `Element not found: ${element?.[1] || "UI element"}`,
      action: "Check if demo app is loading correctly",
    };
  }

  // Content Generation Failures
  if (error.includes("toBeGreaterThan") && error.includes("0")) {
    return {
      category: "🎯 Content Generation",
      cleanError: "Expected AI content not generated (count was 0)",
      action: "AI generative features not working",
    };
  }

  // Strict Mode Violations (multiple elements found)
  if (error.includes("strict mode violation")) {
    return {
      category: "🎯 Test Reliability",
      cleanError: "Multiple matching elements found",
      action: "Test selectors need to be more specific",
    };
  }

  // CSS/Style Issues
  if (error.includes("toHaveCSS")) {
    return {
      category: "🎨 Styling Issues",
      cleanError: "Expected CSS styles not applied",
      action: "Check if dynamic styling is working",
    };
  }

  // Default fallback
  return {
    category: "❓ Other Issues",
    cleanError: error.split("\n")[0]?.trim() || error,
    action: "Check logs for details",
  };
}

export function generateCustomLayout(
  summaryResults: SummaryResults
): Array<KnownBlock | Block> {
  const { passed, failed, skipped, tests } = summaryResults;

  const summary = {
    type: "section",
    text: {
      type: "mrkdwn",
      text:
        failed === 0
          ? `✅ All ${passed} tests passed!`
          : `✅ ${passed} passed • ❌ ${failed} failed • ⏭ ${skipped} skipped`,
    },
  };

  // Only show failures if there are any
  const failures: Array<KnownBlock | Block> = [];
  if (failed > 0) {
    const failedTests = tests.filter(
      (test) => test.status === "failed" || test.status === "timedOut"
    );

    // Categorize failures
    const categorizedFailures = new Map<
      string,
      Array<{ test: any; cleanError: string; action: string }>
    >();

    failedTests.forEach((test) => {
      const { category, cleanError, action } = categorizeAndCleanError(test);
      if (!categorizedFailures.has(category)) {
        categorizedFailures.set(category, []);
      }
      categorizedFailures.get(category)!.push({ test, cleanError, action });
    });

    // Get video URLs by category
    const videosByCategory = getVideosByCategory();

    // Display failures by category
    for (const [category, categoryFailures] of categorizedFailures) {
      const failureLines = categoryFailures.map(
        ({ test, cleanError, action }) => {
          const testName = getTestDisplayName(test);

          // Look for videos for this test - search across ALL categories since
          // S3 reporter uses different categorization than Slack layout
          let testVideo: VideoInfo | undefined;
          for (const [_, videos] of videosByCategory) {
            testVideo = videos.find(
              (v) =>
                v.testName === test.name ||
                v.testName.includes(test.name) ||
                test.name.includes(v.testName)
            );
            if (testVideo) break;
          }

          const videoLink = testVideo
            ? `\n  📹 [Watch Video](${testVideo.url})`
            : "";

          return `• **${testName}**\n  → ${cleanError}${videoLink}`;
        }
      );

      const uniqueActions = [...new Set(categoryFailures.map((f) => f.action))];
      const actionText =
        uniqueActions.length === 1
          ? `\n🔧 *Action:* ${uniqueActions[0]}`
          : `\n🔧 *Actions:* ${uniqueActions.join(", ")}`;

      failures.push({
        type: "section",
        text: {
          type: "mrkdwn",
          text: `*${category}* (${categoryFailures.length} failure${
            categoryFailures.length > 1 ? "s" : ""
          })\n${failureLines.join("\n\n")}${actionText}`,
        },
      });
    }

    // Add overall action summary if there are AI issues
    const hasAIIssues =
      categorizedFailures.has("🤖 AI Response Issues") ||
      categorizedFailures.has("🎯 Content Generation");

    if (hasAIIssues) {
      failures.push({
        type: "context",
        elements: [
          {
            type: "mrkdwn",
            text: "💡 *Most failures are AI-related.* Check API keys, service status, and rate limits.",
          },
        ],
      });
    }
  }

  return [summary, ...failures];
}

export default generateCustomLayout;



================================================
FILE: typescript-sdk/apps/dojo/e2e/test-isolation-helper.ts
================================================
import { test as base, Page } from "@playwright/test";

// Extend base test with isolation setup
export const test = base.extend<{}, {}>({
  page: async ({ page }, use) => {
    // Before each test - ensure clean state
    await page.context().clearCookies();
    await page.context().clearPermissions();

    // Add delay to ensure AI services are ready
    await page.waitForTimeout(1000);

    await use(page);

    // After each test - cleanup
    await page.context().clearCookies();
  },
});

// Add AI-specific wait helpers for better reliability
export async function waitForAIResponse(page: Page, timeout: number = 90000) {
  // Wait for AI response indicators
  await page.waitForFunction(
    () => {
      // Look for common AI loading indicators
      const loadingIndicators = document.querySelectorAll(
        '[data-testid*="loading"], .loading, .spinner'
      );
      return loadingIndicators.length === 0;
    },
    { timeout }
  );

  // Additional wait for content to stabilize
  await page.waitForTimeout(2000);
}

export async function retryOnAIFailure<T>(
  operation: () => Promise<T>,
  maxRetries: number = 3,
  delayMs: number = 5000
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await operation();
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);

      // Check if this is an AI service error we should retry
      const shouldRetry =
        errorMsg.includes("timeout") ||
        errorMsg.includes("rate limit") ||
        errorMsg.includes("503") ||
        errorMsg.includes("502") ||
        errorMsg.includes("AI response") ||
        errorMsg.includes("network");

      if (shouldRetry && i < maxRetries - 1) {
        console.log(
          `🔄 Retrying operation (attempt ${
            i + 2
          }/${maxRetries}) after AI service error: ${errorMsg}`
        );
        await new Promise((resolve) => setTimeout(resolve, delayMs));
        continue;
      }

      throw error;
    }
  }

  throw new Error("Max retries exceeded");
}

export { expect } from "@playwright/test";



================================================
FILE: typescript-sdk/apps/dojo/e2e/test-isolation-setup.ts
================================================
import { chromium, FullConfig } from "@playwright/test";

async function globalSetup(config: FullConfig) {
  console.log("🧹 Setting up test isolation...");

  // Launch browser to clear any persistent state
  const browser = await chromium.launch();
  const context = await browser.newContext();

  // Clear all storage
  await context.clearCookies();
  await context.clearPermissions();

  // Clear any cached data
  const page = await context.newPage();
  await page.evaluate(() => {
    // Clear all storage types
    localStorage.clear();
    sessionStorage.clear();

    // Clear IndexedDB
    if (window.indexedDB) {
      indexedDB.deleteDatabase("test-db");
    }

    // Clear WebSQL (if supported)
    if (window.openDatabase) {
      try {
        const db = window.openDatabase("", "", "", "");
        db.transaction((tx) => {
          tx.executeSql("DELETE FROM test_table");
        });
      } catch (e) {
        // Ignore WebSQL errors
      }
    }
  });

  await browser.close();

  console.log("✅ Test isolation setup complete");
}

export default globalSetup;



================================================
FILE: typescript-sdk/apps/dojo/e2e/VIDEO_SETUP.md
================================================
# 📹 S3 Video Upload System

This system automatically uploads videos of failed Playwright tests to S3 and embeds clickable links in Slack notifications.

## ✅ **Setup Complete Checklist**

- [x] AWS infrastructure created (`setup-aws.sh`)
- [x] Dependencies installed (`@aws-sdk/client-s3`, `json2md`)
- [x] S3 video uploader created (`lib/upload-video.ts`)
- [x] Custom reporter created (`reporters/s3-video-reporter.ts`)
- [x] Playwright config updated (video recording enabled)
- [x] Slack layout updated (video links embedded)
- [x] GitHub Actions updated (AWS credentials)

## 🔧 **Required GitHub Secrets**

Add these secrets to your repository:

```
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_S3_BUCKET_NAME=copilotkit-e2e-smoke-test-recordings-abc123
AWS_S3_REGION=us-east-1
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
```

## 🎯 **How It Works**

### **1. Video Recording**

- Videos recorded only for **failed tests** (`retain-on-failure`)
- 1280x720 resolution, WebM format
- Stored temporarily in `test-results/`

### **2. S3 Upload Process**

```
Failed Test → Video Recorded → S3 Upload → Slack Notification
```

### **3. S3 File Organization**

```
copilotkit-e2e-smoke-test-recordings-{random}/
└── github-runs/
    └── {GITHUB_RUN_ID}/
        └── cpk-demos-smoke-tests/
            └── {SUITE_NAME}/
                └── {TEST_NAME}/
                    └── video.webm
```

### **4. Slack Integration**

Videos appear as clickable links in categorized failure notifications:

```
🤖 AI Response Issues (2 failures)
• Human in the Loop Feature: Chat interaction steps
  → No AI response - Expected: /Travel Guide/i
  📹 [Watch Video](https://bucket.s3.amazonaws.com/path/video.webm)

🔧 Action: Check API keys and AI service status
```

## 🛠 **Local Development**

### **Test Video Upload Locally**

```bash
# Set environment variables
export AWS_S3_BUCKET_NAME="your-bucket-name"
export AWS_S3_REGION="us-east-1"
export AWS_ACCESS_KEY_ID="your-key"
export AWS_SECRET_ACCESS_KEY="your-secret"

# Run tests with video upload enabled
CI=true pnpm exec playwright test --reporter=./reporters/s3-video-reporter.ts
```

### **Disable Video Upload Locally**

Videos are automatically disabled in local runs. To force enable:

```bash
# Edit playwright.config.ts
uploadVideos: true  // In local reporter config
```

## 📊 **Monitoring & Debugging**

### **Check Upload Status**

- Videos upload logs appear in GitHub Actions output
- Failed uploads are logged but don't fail the workflow
- Video URLs written to `test-results/video-urls.json`

### **Common Issues**

**❌ No videos in Slack**

- Check AWS credentials in GitHub secrets
- Verify S3 bucket permissions
- Look for upload errors in Actions logs

**❌ Videos not accessible**

- Verify S3 bucket has public read access
- Check bucket policy and CORS settings

**❌ Upload timeouts**

- Large video files may timeout
- Check network connectivity to S3
- Consider video compression settings

## 🧹 **Maintenance**

### **Automatic Cleanup**

- Videos automatically deleted after **30 days**
- Lifecycle policy configured in S3 bucket
- No manual cleanup required

### **Cost Management**

- Only failed tests generate videos (~5-10 MB each)
- 30-day retention keeps costs low
- Monitor S3 usage in AWS console

## 🚀 **Next Steps**

1. **Run `setup-aws.sh`** to create infrastructure ✅
2. **Add GitHub secrets** from script output ⏳
3. **Test the system** by running a failing test ⏳
4. **Check Slack notifications** for video links ⏳

## 🔗 **File Structure**

```
cpk-demos-smoke-tests/
├── lib/
│   └── upload-video.ts          # S3 upload functionality
├── reporters/
│   └── s3-video-reporter.ts     # Playwright reporter
├── .github/workflows/
│   └── scheduled-tests.yml      # AWS credentials setup
├── playwright.config.ts         # Video recording config
├── slack-layout.ts             # Video links in notifications
├── setup-aws.sh               # AWS infrastructure script
└── VIDEO_SETUP.md              # This file
```

## 📹 **Video URL Format**

```
https://{bucket}.s3.{region}.amazonaws.com/github-runs/{run-id}/{project}/{suite}/{test}/video-{timestamp}.webm
```

Example:

```
https://copilotkit-e2e-recordings.s3.us-east-1.amazonaws.com/github-runs/1234567890/cpk-demos-smoke-tests/Human-in-the-Loop-Feature/Chat-interaction-steps/video-20240115-143022.webm
```

**🎉 Your failed test videos are now automatically uploaded to S3 and linked in Slack!**



================================================
FILE: typescript-sdk/apps/dojo/e2e/featurePages/AgenticChatPage.ts
================================================
import { Page, Locator, expect } from "@playwright/test";

export class AgenticChatPage {
  readonly page: Page;
  readonly openChatButton: Locator;
  readonly agentGreeting: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly chatBackground: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.openChatButton = page.getByRole("button", {
      name: /chat/i,
    });
    this.agentGreeting = page
      .getByText("Hi, I'm an agent. Want to chat?");
    this.chatInput = page
      .getByRole("textbox", { name: "Type a message..." })
      .or(page.getByRole("textbox"))
      .or(page.locator('input[type="text"]'))
      .or(page.locator('textarea'));
    this.sendButton = page
      .locator('[data-test-id="copilot-chat-ready"]')
      .or(page.getByRole("button", { name: /send/i }))
      .or(page.locator('button[type="submit"]'));
    this.chatBackground = page
      .locator('div[style*="background"]')
      .or(page.locator('.flex.justify-center.items-center.h-full.w-full'))
      .or(page.locator('body'));
    this.agentMessage = page
      .locator(".copilotKitAssistantMessage");
    this.userMessage = page
      .locator(".copilotKitUserMessage");
  }

  async openChat() {
    try {
      await this.openChatButton.click({ timeout: 3000 });
    } catch (error) {
      // Chat might already be open
    }
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    try {
      await this.sendButton.click();
    } catch (error) {
      await this.chatInput.press("Enter");
    }
  }

  async getBackground(
    property: "backgroundColor" | "backgroundImage" = "backgroundColor"
  ): Promise<string> {
    // Wait a bit for background to apply
    await this.page.waitForTimeout(500);

    // Try multiple selectors for the background element
    const selectors = [
      'div[style*="background"]',
      'div[style*="background-color"]',
      '.flex.justify-center.items-center.h-full.w-full',
      'div.flex.justify-center.items-center.h-full.w-full',
      '[class*="bg-"]',
      'div[class*="background"]'
    ];

    for (const selector of selectors) {
      try {
        const element = this.page.locator(selector).first();
        if (await element.isVisible({ timeout: 1000 })) {
          const value = await element.evaluate(
            (el, prop) => {
              // Check inline style first
              if (el.style.background) return el.style.background;
              if (el.style.backgroundColor) return el.style.backgroundColor;
              // Then computed style
              return getComputedStyle(el)[prop as any];
            },
            property
          );
          if (value && value !== "rgba(0, 0, 0, 0)" && value !== "transparent") {
            console.log(`[${selector}] ${property}: ${value}`);
            return value;
          }
        }
      } catch (e) {
        continue;
      }
    }

    // Fallback to original element
    const value = await this.chatBackground.first().evaluate(
      (el, prop) => getComputedStyle(el)[prop as any],
      property
    );
    console.log(`[Fallback] ${property}: ${value}`);
    return value;
  }

  async getGradientButtonByName(name: string | RegExp) {
    return this.page.getByRole("button", { name });
  }

  async assertUserMessageVisible(text: string | RegExp) {
    await expect(this.userMessage.getByText(text)).toBeVisible();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    const agentMessage = this.page.locator(".copilotKitAssistantMessage", {
      hasText: expectedText,
    });
    await expect(agentMessage.last()).toBeVisible({ timeout: 10000 });
  }

  async assertAgentReplyContains(expectedText: string) {
    const agentMessage = this.page.locator(".copilotKitAssistantMessage").last();
    await expect(agentMessage).toContainText(expectedText, { timeout: 10000 });
  }

  async assertWeatherResponseStructure() {
    const agentMessage = this.page.locator(".copilotKitAssistantMessage").last();

    // Check for main weather response structure
    await expect(agentMessage).toContainText("The current weather in Islamabad is as follows:", { timeout: 10000 });

    // Check for temperature information
    await expect(agentMessage).toContainText("Temperature:", { timeout: 5000 });
    // Check for humidity
    await expect(agentMessage).toContainText("Humidity:", { timeout: 5000 });

    // Check for wind speed
    await expect(agentMessage).toContainText("Wind Speed:", { timeout: 5000 });
    // Check for conditions
    await expect(agentMessage).toContainText("Conditions:", { timeout: 5000 });
  }
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/featurePages/SharedStatePage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class SharedStatePage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly promptResponseLoader: Locator;
  readonly ingredientCards: Locator;
  readonly instructionsContainer: Locator;
  readonly addIngredient: Locator;

  constructor(page: Page) {
    this.page = page;
    // Remove iframe references and use actual greeting text
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your recipe?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.promptResponseLoader = page.getByRole('button', { name: 'Please Wait...', disabled: true });
    this.instructionsContainer = page.locator('.instructions-container');
    this.addIngredient = page.getByRole('button', { name: '+ Add Ingredient' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.ingredientCards = page.locator('.ingredient-card');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async loader() {
    const timeout = (ms) => new Promise((_, reject) => {
      setTimeout(() => reject(new Error("Timeout waiting for promptResponseLoader to become visible")), ms);
    });

    await Promise.race([
      this.promptResponseLoader.isVisible(),
      timeout(5000) // 5 seconds timeout
    ]);
  }

  async awaitIngredientCard(name: string) {
    const selector = `.ingredient-card:has(input.ingredient-name-input[value="${name}"])`;
    const cardLocator = this.page.locator(selector);
    await expect(cardLocator).toBeVisible();
  }

  async addNewIngredient(placeholderText: string) {
      this.addIngredient.click();
      this.page.locator(`input[placeholder="${placeholderText}"]`);
  }

  async getInstructionItems(containerLocator: Locator ) {
    const count = await containerLocator.locator('.instruction-item').count();
    if (count <= 0) {
      throw new Error('No instruction items found in the container.');
    }
    console.log(`✅ Found ${count} instruction items.`);
    return count;
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/featurePages/ToolBaseGenUIPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class ToolBaseGenUIPage {
  readonly page: Page;
  readonly haikuAgentIntro: Locator;
  readonly messageBox: Locator;
  readonly sendButton: Locator;
  readonly applyButton: Locator;
  readonly appliedButton: Locator;
  readonly haikuBlock: Locator;
  readonly japaneseLines: Locator;

  constructor(page: Page) {
    this.page = page;
    this.haikuAgentIntro = page.getByText("I'm a haiku generator 👋. How can I help you?");
    this.messageBox = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.haikuBlock = page.locator('[data-testid="haiku-card"]');
    this.applyButton = page.getByRole('button', { name: 'Apply' });
    this.japaneseLines = page.locator('[data-testid="haiku-line"]');
  }

  async generateHaiku(message: string) {
    await this.messageBox.click();
    await this.messageBox.fill(message);
    await this.sendButton.click();
  }

  async checkGeneratedHaiku() {
    await this.page.locator('[data-testid="haiku-card"]').last().isVisible();
    const mostRecentCard = this.page.locator('[data-testid="haiku-card"]').last();
    await mostRecentCard.locator('[data-testid="haiku-line"]').first().waitFor({ state: 'visible', timeout: 10000 });
  }

  async extractChatHaikuContent(page: Page): Promise<string> {
    await page.waitForTimeout(3000);
    await page.locator('[data-testid="haiku-card"]').first().waitFor({ state: 'visible' });
    const allHaikuCards = page.locator('[data-testid="haiku-card"]');
    const cardCount = await allHaikuCards.count();
    let chatHaikuContainer;
    let chatHaikuLines;

    for (let cardIndex = cardCount - 1; cardIndex >= 0; cardIndex--) {
      chatHaikuContainer = allHaikuCards.nth(cardIndex);
      chatHaikuLines = chatHaikuContainer.locator('[data-testid="haiku-line"]');
      const linesCount = await chatHaikuLines.count();

      if (linesCount > 0) {
        try {
          await chatHaikuLines.first().waitFor({ state: 'visible', timeout: 5000 });
          break;
        } catch (error) {
          continue;
        }
      }
    }

    if (!chatHaikuLines) {
      throw new Error('No haiku cards with visible lines found');
    }

    const count = await chatHaikuLines.count();
    const lines: string[] = [];

    for (let i = 0; i < count; i++) {
      const haikuLine = chatHaikuLines.nth(i);
      const japaneseText = await haikuLine.locator('p').first().innerText();
      lines.push(japaneseText);
    }

    const chatHaikuContent = lines.join('').replace(/\s/g, '');
    return chatHaikuContent;
  }

  async extractMainDisplayHaikuContent(page: Page): Promise<string> {
    const mainDisplayLines = page.locator('[data-testid="main-haiku-line"]');
    const mainCount = await mainDisplayLines.count();
    const lines: string[] = [];

    if (mainCount > 0) {
      for (let i = 0; i < mainCount; i++) {
        const haikuLine = mainDisplayLines.nth(i);
        const japaneseText = await haikuLine.locator('p').first().innerText();
        lines.push(japaneseText);
      }
    }

    const mainHaikuContent = lines.join('').replace(/\s/g, '');
    return mainHaikuContent;
  }

  async checkHaikuDisplay(page: Page): Promise<void> {
    const chatHaikuContent = await this.extractChatHaikuContent(page);

    await page.waitForTimeout(5000);

    const mainHaikuContent = await this.extractMainDisplayHaikuContent(page);

    if (mainHaikuContent === '') {
      expect(chatHaikuContent.length).toBeGreaterThan(0);
      return;
    }

    if (chatHaikuContent === mainHaikuContent) {
      expect(mainHaikuContent).toBe(chatHaikuContent);
    } else {
      await page.waitForTimeout(3000);

      const updatedMainContent = await this.extractMainDisplayHaikuContent(page);

      expect(updatedMainContent).toBe(chatHaikuContent);
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/lib/upload-video.ts
================================================
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";
import { readFileSync, existsSync } from "fs";
import { basename } from "path";

export interface VideoToUpload {
  videoPath: string;
  s3ObjectPath: string;
  testName: string;
  suiteName?: string;
}

export interface S3Config {
  bucketName: string;
  region: string;
  accessKeyId?: string;
  secretAccessKey?: string;
}

export class S3VideoUploader {
  private s3Client: S3Client;
  private config: S3Config;

  constructor(config: S3Config) {
    this.config = config;

    // Initialize S3 client with credentials from environment or passed config
    this.s3Client = new S3Client({
      region: config.region,
      credentials:
        config.accessKeyId && config.secretAccessKey
          ? {
              accessKeyId: config.accessKeyId,
              secretAccessKey: config.secretAccessKey,
            }
          : undefined, // Use default credential chain if not provided
    });
  }

  /**
   * Generate S3 object path for a video file
   */
  generateS3Path(
    videoPath: string,
    testName: string,
    suiteName?: string
  ): string {
    const filename = basename(videoPath);
    const runId = process.env.GITHUB_RUN_ID || `local-${Date.now()}`;
    const projectName =
      process.env.GITHUB_REPOSITORY?.split("/")[1] || "cpk-demos-smoke-tests";

    // Clean test names for file paths
    const cleanSuite =
      suiteName?.replace(/[^a-zA-Z0-9-_]/g, "-") || "unknown-suite";
    const cleanTest = testName.replace(/[^a-zA-Z0-9-_]/g, "-");

    return `github-runs/${runId}/${projectName}/${cleanSuite}/${cleanTest}/${filename}`;
  }

  /**
   * Generate public S3 URL for a given object path
   */
  generatePublicUrl(s3ObjectPath: string): string {
    return `https://${this.config.bucketName}.s3.${this.config.region}.amazonaws.com/${s3ObjectPath}`;
  }

  /**
   * Upload a single video file to S3
   */
  async uploadVideo(video: VideoToUpload): Promise<string> {
    try {
      // Check if file exists
      if (!existsSync(video.videoPath)) {
        throw new Error(`Video file not found: ${video.videoPath}`);
      }

      console.log(
        `📹 Uploading video: ${basename(video.videoPath)} for test: ${
          video.testName
        }`
      );

      // Read file content
      const fileContent = readFileSync(video.videoPath);

      // Upload to S3
      const command = new PutObjectCommand({
        Bucket: this.config.bucketName,
        Key: video.s3ObjectPath,
        Body: fileContent,
        ContentType: "video/webm",
        CacheControl: "public, max-age=86400", // Cache for 1 day
        Metadata: {
          "test-name": video.testName,
          "suite-name": video.suiteName || "unknown",
          "upload-time": new Date().toISOString(),
        },
      });

      await this.s3Client.send(command);

      const publicUrl = this.generatePublicUrl(video.s3ObjectPath);
      console.log(`✅ Video uploaded successfully: ${publicUrl}`);

      return publicUrl;
    } catch (error) {
      console.error(`❌ Failed to upload video ${video.videoPath}:`, error);
      throw error;
    }
  }

  /**
   * Upload multiple videos concurrently
   */
  async uploadVideos(
    videos: VideoToUpload[]
  ): Promise<{ url: string; testName: string; suiteName?: string }[]> {
    if (videos.length === 0) {
      console.log("📹 No videos to upload");
      return [];
    }

    console.log(`📹 Uploading ${videos.length} video(s) to S3...`);

    const uploadPromises = videos.map(async (video) => {
      try {
        const url = await this.uploadVideo(video);
        return {
          url,
          testName: video.testName,
          suiteName: video.suiteName,
        };
      } catch (error) {
        console.error(
          `Failed to upload video for test ${video.testName}:`,
          error
        );
        return null;
      }
    });

    const results = await Promise.allSettled(uploadPromises);

    // Filter out failed uploads
    const successfulUploads = results
      .filter(
        (
          result
        ): result is PromiseFulfilledResult<{
          url: string;
          testName: string;
          suiteName?: string;
        } | null> => result.status === "fulfilled" && result.value !== null
      )
      .map((result) => result.value!);

    const failedUploads = results.filter(
      (result) => result.status === "rejected"
    ).length;

    console.log(`✅ Successfully uploaded ${successfulUploads.length} videos`);
    if (failedUploads > 0) {
      console.warn(`⚠️  ${failedUploads} videos failed to upload`);
    }

    return successfulUploads;
  }
}

/**
 * Factory function to create uploader with environment variables
 */
export function createS3Uploader(): S3VideoUploader | null {
  const bucketName = process.env.AWS_S3_BUCKET_NAME;
  const region = process.env.AWS_S3_REGION || "us-east-1";

  if (!bucketName) {
    console.warn("⚠️  AWS_S3_BUCKET_NAME not set, video upload disabled");
    return null;
  }

  return new S3VideoUploader({
    bucketName,
    region,
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
  });
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/adkMiddlewarePages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }
    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/adkMiddlewarePages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('div.bg-white.rounded.shadow-lg >> text=Confirm Changes');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('div.copilotKitMarkdown').first();
    this.rejectedChangesResponse = page.locator('div.copilotKitMarkdown').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Confirm");
    const acceptedLabel = this.userApprovalModal.last().locator('text=✓ Accepted');
  }

  async getUserRejection() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Reject");
    const rejectedLabel = await this.getStatusLabelOfButton(this.page, "✕ Rejected");
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];

    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }

    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('div.bg-white.rounded.shadow-lg');
      await expect(modal).toBeVisible();
    }
  }
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/crewAIPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/crewAIPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }
    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/crewAIPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('div.bg-white.rounded.shadow-lg >> text=Confirm Changes');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('div.copilotKitMarkdown').first();
    this.rejectedChangesResponse = page.locator('div.copilotKitMarkdown').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Confirm");
    const acceptedLabel = this.userApprovalModal.last().locator('text=✓ Accepted');
  }

  async getUserRejection() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Reject");
    const rejectedLabel = await this.getStatusLabelOfButton(this.page, "✕ Rejected");
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];

    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }

    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('div.bg-white.rounded.shadow-lg');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText('This agent demonstrates human-in-the-loop');
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: '✨Perform Steps' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.planTaskButton.click();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();
    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('[data-testid="confirm-changes-modal"]').last();
    this.approveButton = page.getByText('✓ Accepted');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.rejectedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {   
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="confirm-button"]').click();
    const acceptedLabel = this.page.locator('[data-testid="status-display"]').last();
    await acceptedLabel.isVisible();
  }

  async getUserRejection() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="reject-button"]').click();
    const rejectedLabel = this.page.locator('[data-testid="status-display"]').last();
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];
    
    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }
    
    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('[data-testid="confirm-changes-modal"]');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphFastAPIPages/SubgraphsPage.ts
================================================
export { SubgraphsPage } from '../langGraphPages/SubgraphsPage'


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });

    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText('This agent demonstrates human-in-the-loop');
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: '✨Perform Steps' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.planTaskButton.click();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }

    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('[data-testid="confirm-changes-modal"]').last();
    this.approveButton = page.getByText('✓ Accepted');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.rejectedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {   
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="confirm-button"]').click();
    const acceptedLabel = this.page.locator('[data-testid="status-display"]').last();
    await acceptedLabel.isVisible();
  }

  async getUserRejection() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="reject-button"]').click();
    const rejectedLabel = this.page.locator('[data-testid="status-display"]').last();
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];
    
    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }
    
    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('[data-testid="confirm-changes-modal"]');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/langGraphPages/SubgraphsPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class SubgraphsPage {
  readonly page: Page;
  readonly travelPlannerButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  
  // Flight-related elements
  readonly flightOptions: Locator;
  readonly klmFlightOption: Locator;
  readonly unitedFlightOption: Locator;
  readonly flightSelectionInterface: Locator;
  
  // Hotel-related elements
  readonly hotelOptions: Locator;
  readonly hotelZephyrOption: Locator;
  readonly ritzCarltonOption: Locator;
  readonly hotelZoeOption: Locator;
  readonly hotelSelectionInterface: Locator;
  
  // Itinerary and state elements
  readonly itineraryDisplay: Locator;
  readonly selectedFlight: Locator;
  readonly selectedHotel: Locator;
  readonly experienceRecommendations: Locator;
  
  // Subgraph activity indicators
  readonly activeAgent: Locator;
  readonly supervisorIndicator: Locator;
  readonly flightsAgentIndicator: Locator;
  readonly hotelsAgentIndicator: Locator;
  readonly experiencesAgentIndicator: Locator;

  constructor(page: Page) {
    this.page = page;
    this.travelPlannerButton = page.getByRole('button', { name: /travel.*planner|subgraphs/i });
    this.agentGreeting = page.getByText(/travel.*planning|supervisor.*coordinate/i);
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    
    // Flight selection elements
    this.flightOptions = page.locator('[data-testid*="flight"], .flight-option');
    this.klmFlightOption = page.getByText(/KLM.*\$650.*11h 30m/);
    this.unitedFlightOption = page.getByText(/United.*\$720.*12h 15m/);
    this.flightSelectionInterface = page.locator('[data-testid*="flight-select"], .flight-selection');
    
    // Hotel selection elements
    this.hotelOptions = page.locator('[data-testid*="hotel"], .hotel-option');
    this.hotelZephyrOption = page.getByText(/Hotel Zephyr.*Fisherman\'s Wharf.*\$280/);
    this.ritzCarltonOption = page.getByText(/Ritz-Carlton.*Nob Hill.*\$550/);
    this.hotelZoeOption = page.getByText(/Hotel Zoe.*Union Square.*\$320/);
    this.hotelSelectionInterface = page.locator('[data-testid*="hotel-select"], .hotel-selection');
    
    // Itinerary elements
    this.itineraryDisplay = page.locator('[data-testid*="itinerary"], .itinerary');
    this.selectedFlight = page.locator('[data-testid*="selected-flight"], .selected-flight');
    this.selectedHotel = page.locator('[data-testid*="selected-hotel"], .selected-hotel');
    this.experienceRecommendations = page.locator('[data-testid*="experience"], .experience');
    
    // Agent activity indicators
    this.activeAgent = page.locator('[data-testid*="active-agent"], .active-agent');
    this.supervisorIndicator = page.locator('[data-testid*="supervisor"], .supervisor-active');
    this.flightsAgentIndicator = page.locator('[data-testid*="flights-agent"], .flights-agent-active');
    this.hotelsAgentIndicator = page.locator('[data-testid*="hotels-agent"], .hotels-agent-active');
    this.experiencesAgentIndicator = page.locator('[data-testid*="experiences-agent"], .experiences-agent-active');
  }

  async openChat() {
    await this.travelPlannerButton.click();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectFlight(airline: 'KLM' | 'United') {
    const flightOption = airline === 'KLM' ? this.klmFlightOption : this.unitedFlightOption;
    
    // Wait for flight options to be presented
    await expect(this.flightOptions.first()).toBeVisible({ timeout: 15000 });
    
    // Click on the desired flight option
    await flightOption.click();
  }

  async selectHotel(hotel: 'Zephyr' | 'Ritz-Carlton' | 'Zoe') {
    let hotelOption: Locator;
    
    switch (hotel) {
      case 'Zephyr':
        hotelOption = this.hotelZephyrOption;
        break;
      case 'Ritz-Carlton':
        hotelOption = this.ritzCarltonOption;
        break;
      case 'Zoe':
        hotelOption = this.hotelZoeOption;
        break;
    }
    
    // Wait for hotel options to be presented
    await expect(this.hotelOptions.first()).toBeVisible({ timeout: 15000 });
    
    // Click on the desired hotel option
    await hotelOption.click();
  }

  async waitForFlightsAgent() {
    // Wait for flights agent to become active (or look for flight-related content)
    // Use .first() to handle multiple matches in strict mode
    await expect(
      this.page.getByText(/flight.*options|Amsterdam.*San Francisco|KLM|United/i).first()
    ).toBeVisible({ timeout: 20000 });
  }

  async waitForHotelsAgent() {
    // Wait for hotels agent to become active (or look for hotel-related content)
    // Use .first() to handle multiple matches in strict mode
    await expect(
      this.page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i).first()
    ).toBeVisible({ timeout: 20000 });
  }

  async waitForExperiencesAgent() {
    // Wait for experiences agent to become active (or look for experience-related content)
    // Use .first() to handle multiple matches in strict mode
    await expect(
      this.page.getByText(/experience|activities|restaurant|Pier 39|Golden Gate|Swan Oyster|Tartine/i).first()
    ).toBeVisible({ timeout: 20000 });
  }

  async verifyStaticFlightData() {
    // Verify the hardcoded flight options are present
    await expect(this.page.getByText(/KLM.*\$650.*11h 30m/).first()).toBeVisible();
    await expect(this.page.getByText(/United.*\$720.*12h 15m/).first()).toBeVisible();
  }

  async verifyStaticHotelData() {
    // Verify the hardcoded hotel options are present
    await expect(this.page.getByText(/Hotel Zephyr.*\$280/).first()).toBeVisible();
    await expect(this.page.getByText(/Ritz-Carlton.*\$550/).first()).toBeVisible();
    await expect(this.page.getByText(/Hotel Zoe.*\$320/).first()).toBeVisible();
  }

  async verifyStaticExperienceData() {
    // Wait for experiences to load - this can take time as it's the final step in the agent flow
    // First ensure we're not stuck in "No experiences planned yet" state
    await expect(this.page.getByText('No experiences planned yet')).not.toBeVisible({ timeout: 20000 }).catch(() => {
      console.log('Still waiting for experiences to load...');
    });
    
    // Wait for actual experience content to appear
    await expect(this.page.locator('.activity-name').first()).toBeVisible({ timeout: 15000 });
    
    // Verify we have meaningful experience content (either static or AI-generated)
    const experienceContent = this.page.locator('.activity-name').first().or(
      this.page.getByText(/Pier 39|Golden Gate Bridge|Swan Oyster Depot|Tartine Bakery/i).first()
    );
    await expect(experienceContent).toBeVisible();
  }

  async verifyItineraryContainsFlight(airline: 'KLM' | 'United') {
    // Check that the selected flight appears in the itinerary or conversation
    await expect(this.page.getByText(new RegExp(airline, 'i'))).toBeVisible();
  }

  async verifyItineraryContainsHotel(hotel: 'Zephyr' | 'Ritz-Carlton' | 'Zoe') {
    // Check that the selected hotel appears in the itinerary or conversation
    const hotelName = hotel === 'Ritz-Carlton' ? 'Ritz-Carlton' : `Hotel ${hotel}`;
    await expect(this.page.getByText(new RegExp(hotelName, 'i'))).toBeVisible();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }

  async waitForSupervisorCoordination() {
    // Wait for supervisor to appear in the conversation
    await expect(
      this.page.getByText(/supervisor|coordinate|specialist|routing/i).first()
    ).toBeVisible({ timeout: 15000 });
  }

  async waitForAgentCompletion() {
    // Wait for the travel planning process to complete
    await expect(
      this.page.getByText(/complete|finished|planning.*done|itinerary.*ready/i).first()
    ).toBeVisible({ timeout: 30000 });
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/llamaIndexPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });

    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/llamaIndexPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }

    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({ 
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/pydanticAIPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/pydanticAIPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }
    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();

    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }
    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/pydanticAIPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('div.bg-white.rounded.shadow-lg >> text=Confirm Changes');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('div.copilotKitMarkdown').first();
    this.rejectedChangesResponse = page.locator('div.copilotKitMarkdown').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Confirm");
    const acceptedLabel = this.userApprovalModal.last().locator('text=✓ Accepted');
  }

  async getUserRejection() {
    await this.userApprovalModal.last().isVisible();
    await this.getButton(this.page, "Reject");
    const rejectedLabel = await this.getStatusLabelOfButton(this.page, "✕ Rejected");
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];

    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }

    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('div.bg-white.rounded.shadow-lg');
      await expect(modal).toBeVisible();
    }
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/serverStarterAllFeaturesPages/AgenticUIGenPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class AgenticGenUIPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly planTaskButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly agentGreeting: Locator;
  readonly agentPlannerContainer: Locator;
  readonly sendButton: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Agentic Generative UI' });

    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
    this.agentGreeting = page.getByText('This agent demonstrates');
    this.agentPlannerContainer = page.getByTestId('task-progress');
  }

  async plan() {
    const stepItems = this.agentPlannerContainer.getByTestId('task-step-text');
    const count = await stepItems.count();
    expect(count).toBeGreaterThan(0);
    for (let i = 0; i < count; i++) {
      const stepText = await stepItems.nth(i).textContent();
      console.log(`Step ${i + 1}: ${stepText?.trim()}`);
      await expect(stepItems.nth(i)).toBeVisible();
    }
  }

  async openChat() {
    await this.planTaskButton.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.fill(message);
    await this.page.waitForTimeout(5000)
  }

  getPlannerButton(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async getUserText(textOrRegex) {
    return await this.page.getByText(textOrRegex).isVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.userMessage.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/serverStarterAllFeaturesPages/HumanInLoopPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class HumanInLoopPage {
  readonly page: Page;
  readonly planTaskButton: Locator;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly plan: Locator;
  readonly performStepsButton: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;

  constructor(page: Page) {
    this.page = page;
    this.planTaskButton = page.getByRole('button', { name: 'Human in the loop Plan a task' });
    this.agentGreeting = page.getByText("Hi, I'm an agent specialized in helping you with your tasks. How can I help you?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.plan = page.getByTestId('select-steps');
    this.performStepsButton = page.getByRole('button', { name: 'Confirm' });
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {

    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async selectItemsInPlanner() {
    await expect(this.plan).toBeVisible({ timeout: 10000 });
    await this.plan.click();
  }

  async getPlannerOnClick(name: string | RegExp) {
    return this.page.getByRole('button', { name });
  }

  async uncheckItem(identifier: number | string): Promise<string> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');

    let item;
    if (typeof identifier === 'number') {
      item = items.nth(identifier);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: identifier })
      }).first();
    }

    const stepTextElement = item.getByTestId('step-text');
    const text = await stepTextElement.innerText();
    await item.click();
    return text;
  }

  async isStepItemUnchecked(target: number | string): Promise<boolean> {
    const plannerContainer = this.page.getByTestId('select-steps');
    const items = plannerContainer.getByTestId('step-item');
    let item;
    if (typeof target === 'number') {
      item = items.nth(target);
    } else {
      item = items.filter({
        has: this.page.getByTestId('step-text').filter({ hasText: target })
      }).first();
    }

    const checkbox = item.locator('input[type="checkbox"]');
    return !(await checkbox.isChecked());
  }

  async performSteps() {
    await this.performStepsButton.click();
  }

  async assertAgentReplyVisible(expectedText: RegExp) {
    await expect(this.agentMessage.last().getByText(expectedText)).toBeVisible();
  }

  async assertUserMessageVisible(message: string) {
    await expect(this.page.getByText(message)).toBeVisible();
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/pages/serverStarterAllFeaturesPages/PredictiveStateUpdatesPage.ts
================================================
import { Page, Locator, expect } from '@playwright/test';

export class PredictiveStateUpdatesPage {
  readonly page: Page;
  readonly chatInput: Locator;
  readonly sendButton: Locator;
  readonly agentGreeting: Locator;
  readonly agentResponsePrompt: Locator;
  readonly userApprovalModal: Locator;
  readonly approveButton: Locator;
  readonly acceptedButton: Locator;
  readonly confirmedChangesResponse: Locator;
  readonly rejectedChangesResponse: Locator;
  readonly agentMessage: Locator;
  readonly userMessage: Locator;
  readonly highlights: Locator;

  constructor(page: Page) {
    this.page = page;
    this.agentGreeting = page.getByText("Hi 👋 How can I help with your document?");
    this.chatInput = page.getByRole('textbox', { name: 'Type a message...' });
    this.sendButton = page.locator('[data-test-id="copilot-chat-ready"]');
    this.agentResponsePrompt = page.locator('div.tiptap.ProseMirror');
    this.userApprovalModal = page.locator('[data-testid="confirm-changes-modal"]').last();
    this.approveButton = page.getByText('✓ Accepted');
    this.acceptedButton = page.getByText('✓ Accepted');
    this.confirmedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.rejectedChangesResponse = page.locator('.copilotKitAssistantMessage').last();
    this.highlights = page.locator('.tiptap em');
    this.agentMessage = page.locator('.copilotKitAssistantMessage');
    this.userMessage = page.locator('.copilotKitUserMessage');
  }

  async openChat() {   
    await this.agentGreeting.isVisible();
  }

  async sendMessage(message: string) {
    await this.chatInput.click();
    await this.chatInput.fill(message);
    await this.sendButton.click();
  }

  async getPredictiveResponse() {
    await expect(this.agentResponsePrompt).toBeVisible({ timeout: 10000 });
    await this.agentResponsePrompt.click();
  }

  async getButton(page, buttonName) {
    return page.getByRole('button', { name: buttonName }).click();
  }

  async getStatusLabelOfButton(page, statusText) {
    return page.getByText(statusText, { exact: true });
  }

  async getUserApproval() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="confirm-button"]').click();
    const acceptedLabel = this.page.locator('[data-testid="status-display"]').last();
    await acceptedLabel.isVisible();
  }

  async getUserRejection() {
    await this.userApprovalModal.isVisible();
    await this.page.locator('[data-testid="reject-button"]').click();
    const rejectedLabel = this.page.locator('[data-testid="status-display"]').last();
    await rejectedLabel.isVisible();
  }

  async verifyAgentResponse(dragonName) {
    const paragraphWithName = await this.page.locator(`div.tiptap >> text=${dragonName}`).first();

    const fullText = await paragraphWithName.textContent();
    if (!fullText) {
      return null;
    }

    const match = fullText.match(new RegExp(dragonName, 'i'));
    return match ? match[0] : null;
  }

  async verifyHighlightedText(){
    const highlightSelectors = [
      '.tiptap em',
      '.tiptap s',
      'div.tiptap em',
      'div.tiptap s'
    ];
    
    let count = 0;
    for (const selector of highlightSelectors) {
      count = await this.page.locator(selector).count();
      if (count > 0) {
        break;
      }
    }
    
    if (count > 0) {
      expect(count).toBeGreaterThan(0);
    } else {
      const modal = this.page.locator('[data-testid="confirm-changes-modal"]');
      await expect(modal).toBeVisible();
    }
  }

  async getResponseContent() {
    const contentSelectors = [
      'div.tiptap.ProseMirror',
      'div.copilotKitMarkdown',
      '.copilotKitAssistantMessage',
      'div.tiptap'
    ];
    
    for (const selector of contentSelectors) {
      const elements = this.page.locator(selector);
      const count = await elements.count();
      
      if (count > 0) {
        try {
          const lastElement = elements.nth(count - 1);
          const content = await lastElement.textContent();
          if (content && content.trim().length > 0) {
            return content.trim();
          }
        } catch (error) {
          continue;
        }
      }
    }
    
    const fallbackElements = this.page.locator('div.tiptap, div.copilotKitMarkdown');
    const fallbackCount = await fallbackElements.count();
    if (fallbackCount > 0) {
      const fallbackContent = await fallbackElements.nth(fallbackCount - 1).textContent();
      return fallbackContent ? fallbackContent.trim() : null;
    }
    
    return null;
  }
}


================================================
FILE: typescript-sdk/apps/dojo/e2e/reporters/s3-video-reporter.ts
================================================
import {
  FullConfig,
  FullResult,
  Reporter,
  Suite,
  TestCase,
  TestResult,
  TestStep,
} from "@playwright/test/reporter";
import { createS3Uploader, VideoToUpload } from "../lib/upload-video";
import { writeFileSync, existsSync } from "fs";
import { dirname } from "path";
import { mkdirSync } from "fs";

interface S3VideoReporterOptions {
  outputFile?: string;
  uploadVideos?: boolean;
}

interface VideoInfo {
  url: string;
  testName: string;
  suiteName?: string;
  videoPath?: string; // Store the file path for upload
  timestamp?: number; // For deduplication - keep most recent
}

// Global variable to store video URLs for other reporters to access
export const uploadedVideos: VideoInfo[] = [];

export default class S3VideoReporter implements Reporter {
  private options: S3VideoReporterOptions;
  private videos: VideoInfo[] = []; // Only final attempt videos

  constructor(options: S3VideoReporterOptions = {}) {
    this.options = {
      outputFile: options.outputFile || "test-results/video-urls.json",
      uploadVideos: options.uploadVideos !== false, // Default to true
      ...options,
    };
    console.log(
      `📹 DEBUG: S3VideoReporter constructor called with options:`,
      options
    );
  }

  onBegin(config: FullConfig, suite: Suite) {
    console.log(`📹 S3 Video Reporter initialized`);
    console.log(`   Upload enabled: ${this.options.uploadVideos}`);
    console.log(`   Output file: ${this.options.outputFile}`);
  }

  onTestEnd(test: TestCase, result: TestResult) {
    // Only process failed tests
    if (result.status !== "failed" && result.status !== "timedOut") {
      return;
    }

    console.log(`📹 Processing test attempt for: ${test.title}`);

    // Look for video attachments
    const videoAttachments = result.attachments.filter(
      (attachment) => attachment.name === "video" && attachment.path
    );

    if (videoAttachments.length === 0) {
      console.log(`📹 No video attachments found for final attempt`);
      return;
    }

    console.log(
      `📹 Found ${videoAttachments.length} video(s) for failed test: ${test.title}`
    );

    // Store video info for later upload
    videoAttachments.forEach((attachment) => {
      console.log(
        `📹 DEBUG: Processing attachment path=${attachment.path}, exists=${
          attachment.path ? existsSync(attachment.path) : false
        }`
      );
      if (attachment.path && existsSync(attachment.path)) {
        const videoInfo = {
          url: "", // Will be set after upload
          testName: test.title,
          suiteName: test.parent?.title,
          videoPath: attachment.path, // Store actual file path
          timestamp: Date.now(), // For deduplication
        };
        this.videos.push(videoInfo);
        console.log(`📹 DEBUG: Added video info:`, videoInfo);
        console.log(`📹 DEBUG: Total videos now: ${this.videos.length}`);
      } else {
        console.log(
          `📹 DEBUG: Skipping attachment - path invalid or file doesn't exist`
        );
      }
    });
  }

  async onEnd(result: FullResult) {
    console.log(`📹 DEBUG: onEnd called`);
    console.log(`📹 DEBUG: uploadVideos=${this.options.uploadVideos}`);
    console.log(`📹 DEBUG: videos.length=${this.videos.length}`);
    console.log(
      `📹 DEBUG: videos=`,
      this.videos.map((v) => ({
        testName: v.testName,
        hasPath: !!v.videoPath,
        pathExists: v.videoPath ? existsSync(v.videoPath) : false,
      }))
    );

    if (!this.options.uploadVideos) {
      console.log("📹 Upload disabled in options");
      return;
    }

    if (this.videos.length === 0) {
      console.log("📹 No videos collected");
      return;
    }

    const uploader = createS3Uploader();
    if (!uploader) {
      console.warn("⚠️  S3 uploader not configured, skipping video upload");
      return;
    }

    try {
      // Deduplicate videos - keep only the most recent one for each test
      const videoMap = new Map<string, VideoInfo>();
      this.videos.forEach((video) => {
        const existing = videoMap.get(video.testName);
        if (!existing || (video.timestamp || 0) > (existing.timestamp || 0)) {
          videoMap.set(video.testName, video);
        }
      });

      const deduplicatedVideos = Array.from(videoMap.values());
      console.log(
        `📹 Deduplicated ${this.videos.length} videos down to ${deduplicatedVideos.length} (keeping most recent per test)`
      );

      // Use the deduplicated videos for upload
      const videosToUpload: VideoToUpload[] = deduplicatedVideos
        .filter((video) => video.videoPath && existsSync(video.videoPath))
        .map((video) => {
          const s3ObjectPath = uploader.generateS3Path(
            video.videoPath!,
            video.testName,
            video.suiteName
          );

          return {
            videoPath: video.videoPath!,
            s3ObjectPath,
            testName: video.testName,
            suiteName: video.suiteName,
          };
        });

      if (videosToUpload.length === 0) {
        console.log("📹 No video files found to upload");
        return;
      }

      console.log(
        `📹 Preparing to upload ${videosToUpload.length} video(s)...`
      );

      // Upload videos to S3
      const uploadResults = await uploader.uploadVideos(videosToUpload);

      // Update our video info with URLs
      this.videos = uploadResults;

      // Store globally for other reporters
      uploadedVideos.splice(0);
      uploadedVideos.push(...this.videos);

      // Write video URLs to file for other processes
      await this.writeVideoUrls();

      console.log(
        `✅ Successfully uploaded ${this.videos.length} videos to S3`
      );
    } catch (error) {
      console.error("❌ Failed to upload videos:", error);
    }
  }

  private async writeVideoUrls() {
    if (!this.options.outputFile) return;

    const outputDir = dirname(this.options.outputFile);
    if (!existsSync(outputDir)) {
      mkdirSync(outputDir, { recursive: true });
    }

    const videoData = {
      uploadTime: new Date().toISOString(),
      runId: process.env.GITHUB_RUN_ID || `local-${Date.now()}`,
      repository: process.env.GITHUB_REPOSITORY || "unknown",
      videos: this.videos,
    };

    writeFileSync(this.options.outputFile, JSON.stringify(videoData, null, 2));
    console.log(`📄 Video URLs written to: ${this.options.outputFile}`);
  }

  // Helper methods removed - we now collect videos directly in onTestEnd
}

/**
 * Get uploaded video URLs for use in other reporters
 */
export function getUploadedVideos(): VideoInfo[] {
  return [...uploadedVideos];
}

/**
 * Get all uploaded videos
 */
export function getAllVideos(): VideoInfo[] {
  return [...uploadedVideos];
}



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/copilotkit-home.spec.ts
================================================
import { test, expect } from "@playwright/test";

// Smoke test: ensure CopilotKit homepage loads and renders key content.

test('[Core] CopilotKit homepage renders', async ({ page }) => {
  await page.goto("https://copilotkit.ai/", { waitUntil: "domcontentloaded" });

  await expect(page).toHaveTitle(/CopilotKit/i);

  // Validate hero heading content.
  await expect(
    page.getByRole("heading", {
      name: /Build User-Facing Agentic Applications/i,
      exact: false,
    })
  ).toBeVisible();
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/adkMiddlewareTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";


test.describe("Agentic Chat Feature", () => {
  test("[ADK Middleware] Agentic Chat sends and receives a message", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      await page.goto(
        "/adk-middleware/feature/agentic_chat"
      );

      const chat = new AgenticChatPage(page);

      await chat.openChat();
      await chat.agentGreeting.isVisible;
      await chat.sendMessage("Hello, I am duaa.");

      await waitForAIResponse(page);
      await chat.assertUserMessageVisible("Hello, I am duaa.");
      await chat.assertAgentReplyVisible(/Hello/i);
    });
  });

  test("[ADK Middleware] Agentic Chat changes background on message and reset", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      await page.goto(
        "/adk-middleware/feature/agentic_chat"
      );

      const chat = new AgenticChatPage(page);

      await chat.openChat();
      await chat.agentGreeting.waitFor({ state: "visible" });

      // Store initial background color
      const backgroundContainer = page.locator('[data-testid="background-container"]')
      const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
      console.log("Initial background color:", initialBackground);

      // 1. Send message to change background to blue
      await chat.sendMessage("Hi change the background color to blue");
      await chat.assertUserMessageVisible(
        "Hi change the background color to blue"
      );
      await waitForAIResponse(page);

      await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
      const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
      // Check if background is blue (string color name or contains blue)
      expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

      // 2. Change to pink
      await chat.sendMessage("Hi change the background color to pink");
      await chat.assertUserMessageVisible(
        "Hi change the background color to pink"
      );
      await waitForAIResponse(page);

      await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
      const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
      // Check if background is pink (string color name or contains pink)
      expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
    });
  });

  test("[ADK Middleware] Agentic Chat retains memory of user messages during a conversation", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      await page.goto(
        "/adk-middleware/feature/agentic_chat"
      );

      const chat = new AgenticChatPage(page);
      await chat.openChat();
      await chat.agentGreeting.click();

      await chat.sendMessage("Hey there");
      await chat.assertUserMessageVisible("Hey there");
      await waitForAIResponse(page);
      await chat.assertAgentReplyVisible(/how can I assist you/i);

      const favFruit = "Mango";
      await chat.sendMessage(`My favorite fruit is ${favFruit}`);
      await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
      await waitForAIResponse(page);
      await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

      await chat.sendMessage("and I love listening to Kaavish");
      await chat.assertUserMessageVisible("and I love listening to Kaavish");
      await waitForAIResponse(page);
      await chat.assertAgentReplyVisible(/Kaavish/i);

      await chat.sendMessage("Can you remind me what my favorite fruit is?");
      await chat.assertUserMessageVisible(
        "Can you remind me what my favorite fruit is?"
      );
      await waitForAIResponse(page);
      await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/adkMiddlewareTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/adkMiddlewarePages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[ADK Middleware] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/adk-middleware/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[ADK Middleware] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/adk-middleware/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';

          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/adkMiddlewareTests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/adkMiddlewarePages/PredictiveStateUpdatesPage";

test.describe("Predictive State Updates Feature", () => {
  test.skip("[ADK Middleware] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/adk-middleware/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.nth(1).isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test.skip("[ADK Middleware] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/adk-middleware/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called called Atlantis in document"
      );
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/adkMiddlewareTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[ADK Middleware] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/adk-middleware/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[ADK Middleware] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/adk-middleware/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/adkMiddlewareTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL = "/adk-middleware/feature/tool_based_generative_ui";

test.describe("Tool Based Generative UI Feature", () => {
  test('[ADK Middleware] Haiku generation and display verification', async ({
    page,
  }) => {
    await page.goto(pageURL);

    const genAIAgent = new ToolBaseGenUIPage(page);

    await expect(genAIAgent.haikuAgentIntro).toBeVisible();
    await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
    await genAIAgent.checkGeneratedHaiku();
    await genAIAgent.checkHaikuDisplay(page);
  });

  test('[ADK Middleware] Haiku generation and UI consistency for two different prompts', async ({
    page,
  }) => {
    await page.goto(pageURL);

    const genAIAgent = new ToolBaseGenUIPage(page);

    await expect(genAIAgent.haikuAgentIntro).toBeVisible();

    const prompt1 = 'Generate Haiku for "I will always win"';
    await genAIAgent.generateHaiku(prompt1);
    await genAIAgent.checkGeneratedHaiku();
    await genAIAgent.checkHaikuDisplay(page);

    const prompt2 = 'Generate Haiku for "The moon shines bright"';
    await genAIAgent.generateHaiku(prompt2);
    await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
    await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/agnoTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

const appleAsk = "What is the current stock price of AAPL? Please respond in the format of 'The current stock price of Apple Inc. (AAPL) is {{price}}'"

test("[Agno] Agentic Chat sends and receives a greeting message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi");
    await chat.assertAgentReplyVisible(/Hello|Hi|hey/i);
  });
});

test("[Agno] Agentic Chat provides stock price information", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Ask for AAPL stock price
    await chat.sendMessage(appleAsk);
    await chat.assertUserMessageVisible(appleAsk);
    await waitForAIResponse(page);

    // Check if the response contains the expected stock price information
    await chat.assertAgentReplyContains("The current stock price of Apple Inc. (AAPL) is");
  });
});

test("[Agno] Agentic Chat retains memory of previous questions", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // First question
    await chat.sendMessage("Hi");
    await chat.sendMessage(appleAsk);
    await chat.assertUserMessageVisible(appleAsk);
    await waitForAIResponse(page);
    await chat.assertAgentReplyContains("The current stock price of Apple Inc. (AAPL) is");

    // Ask about the first question to test memory
    await chat.sendMessage("What was my first question");
    await chat.assertUserMessageVisible("What was my first question");
    await waitForAIResponse(page);

    // Check if the agent remembers the first question about AAPL stock price
    await chat.assertAgentReplyVisible(/Hi/i);
  });
});

test("[Agno] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/agno/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/agnoTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/agno/feature/tool_based_generative_ui";

test('[Agno] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[Agno] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[CrewAI] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/crewai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[CrewAI] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/crewai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[CrewAI] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/crewai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/crewAIPages/AgenticUIGenPage";

test.fixme("[CrewAI] Agentic Gen UI", () => {
  // Flaky
  test("[CrewAI] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/crewai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  // Flaky
  test.fixme("[CrewAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/crewai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/crewAIPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[CrewAI] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/crewai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[CrewAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/crewai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/crewAIPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[CrewAI] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/crewai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.nth(1).isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[CrewAI] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/crewai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called called Atlantis in document"
      );
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[CrewAI] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/crewai/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[CrewAI] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/crewai/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/crewAITests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/crewai/feature/tool_based_generative_ui";

test('[CrewAI] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[CrewAI] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/integration/ai-features.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { waitForAIPatterns } from "../../utils/aiWaitHelpers";

test.describe("Demo Viewer AI Features", () => {
  test("[Crew] Restaurant Finder Agent - Complex workflow", async ({
    page,
  }) => {
    try {
      await page.goto(
        "https://demo.copilotkit.ai/crew_enterprise_restaurant_finder",
        {
          waitUntil: "networkidle",
          timeout: 30_000,
        }
      );

      // Navigate through nested iframes
      const demoFrame = page.frameLocator('iframe[title="Demo Preview"]');
      const agentFrame = demoFrame.frameLocator(
        'iframe[title="Restaurant Finder Agent"]'
      );

      // Wait for agent interface to load
      await expect(agentFrame.locator("body")).toBeVisible({ timeout: 30_000 });

      // Look for input field
      const chatInput = agentFrame.locator("input, textarea").first();
      if ((await chatInput.count()) > 0) {
        await chatInput.fill("Find me a restaurant in San Francisco");
        await chatInput.press("Enter");

        // Wait for restaurant results or AI response
        await expect(
          agentFrame.locator("*", {
            hasText: /restaurant|san francisco|recommendation/i,
          })
        ).toBeVisible({ timeout: 90_000 });
        console.log("✅ Restaurant finder agent working");
      }
    } catch (error) {
      console.log("⚠️ Restaurant finder demo not available or not working");
      // Don't fail the test - this is expected if the demo is down
    }
  });
});

// Test configuration for CI vs local
test.describe.configure({
  timeout: process.env.CI ? 300_000 : 120_000, // 5min in CI, 2min locally
  retries: process.env.CI ? 1 : 0,
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LangGraph FastAPI] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-fastapi/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LangGraph FastAPI] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-fastapi/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[LangGraph FastAPI] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-fastapi/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/langGraphFastAPIPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[LangGraph FastAPI] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph-fastapi/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });

    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[LangGraph FastAPI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph-fastapi/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/langGraphFastAPIPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LangGraph FastAPI] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();
      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[LangGraph FastAPI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();
      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/langGraphFastAPIPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[LangGraph FastAPI] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[LangGraph FastAPI] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph-fastapi/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LangGraph FastAPI] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/langgraph-fastapi/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LangGraph FastAPI] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/langgraph-fastapi/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients, also list them in your message");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/subgraphsPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { SubgraphsPage } from "../../pages/langGraphPages/SubgraphsPage";

test.describe("Subgraphs Travel Agent Feature", () => {
  test("[LangGraph] should complete full travel planning flow with feature validation", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph-fastapi/feature/subgraphs");

      await subgraphsPage.openChat();

      // Initiate travel planning
      await subgraphsPage.sendMessage("Help me plan a trip to San Francisco");
      await waitForAIResponse(page);

      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test interrupt pause behavior - flow shouldn't auto-proceed
      await page.waitForTimeout(3000);
      // await expect(page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i)).not.toBeVisible();

      // Select KLM flight through interrupt
      await subgraphsPage.selectFlight('KLM');

      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('KLM').catch(async () => {
        await expect(page.getByText(/KLM/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // Select Hotel Zoe through interrupt
      await subgraphsPage.selectHotel('Zoe');

      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Zoe').catch(async () => {
        await expect(page.getByText(/Hotel Zoe|Zoe/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticExperienceData();
    });
  });

  test("[LangGraph] should handle different selections and demonstrate supervisor routing patterns", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph-fastapi/feature/subgraphs");

      await subgraphsPage.openChat();

      await subgraphsPage.sendMessage("I want to visit San Francisco from Amsterdam");
      await waitForAIResponse(page);

      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticFlightData();

      await page.waitForTimeout(3000);
      // FEATURE TEST: Test different selection - United instead of KLM
      await subgraphsPage.selectFlight('United');

      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('United').catch(async () => {
        await expect(page.getByText(/United/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });

      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // FEATURE TEST: Test different hotel selection - Ritz-Carlton
      await subgraphsPage.selectHotel('Ritz-Carlton');

      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton').catch(async () => {
        await expect(page.getByText(/Ritz-Carlton/i)).toBeVisible({ timeout: 2000 });
      });

      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      // FEATURE TEST: Verify subgraph streaming detection - experiences agent is active
      await expect(subgraphsPage.experiencesAgentIndicator).toHaveClass(/active/).catch(() => {
        console.log("Experiences agent not active, checking content instead");
      });

      // FEATURE TEST: Verify complete state persistence across all agents
      await expect(subgraphsPage.selectedFlight).toContainText('United'); // Flight selection persisted
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton'); // Hotel selection persisted
      await subgraphsPage.verifyStaticExperienceData(); // Experiences provided based on selections
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphFastAPITests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/langgraph-fastapi/feature/tool_based_generative_ui";

test('[LangGraph FastAPI] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[LangGraph FastAPI] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LangGraph] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LangGraph] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[LangGraph] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/langGraphPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[LangGraph] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    
    await genUIAgent.plan();
    
    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';
        
        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[LangGraph] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();
    
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();
    
    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';
        
        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/langGraphPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LangGraph] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);
      await page.goto(
        "/langgraph/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/langGraphPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[LangGraph] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[LangGraph] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LangGraph] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/langgraph/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LangGraph] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/langgraph/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/subgraphsPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { SubgraphsPage } from "../../pages/langGraphPages/SubgraphsPage";

test.describe("Subgraphs Travel Agent Feature", () => {
  test("[LangGraph] should complete full travel planning flow with feature validation", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph/feature/subgraphs");

      await subgraphsPage.openChat();

      // Initiate travel planning
      await subgraphsPage.sendMessage("Help me plan a trip to San Francisco");
      await waitForAIResponse(page);
      
      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test interrupt pause behavior - flow shouldn't auto-proceed
      await page.waitForTimeout(3000);
      // await expect(page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i)).not.toBeVisible();

      // Select KLM flight through interrupt
      await subgraphsPage.selectFlight('KLM');
      
      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('KLM').catch(async () => {
        await expect(page.getByText(/KLM/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches  
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // Select Hotel Zoe through interrupt
      await subgraphsPage.selectHotel('Zoe');
      
      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Zoe').catch(async () => {
        await expect(page.getByText(/Hotel Zoe|Zoe/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticExperienceData();
    });
  });

  test("[LangGraph] should handle different selections and demonstrate supervisor routing patterns", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph/feature/subgraphs");

      await subgraphsPage.openChat();

      await subgraphsPage.sendMessage("I want to visit San Francisco from Amsterdam");
      await waitForAIResponse(page);
      
      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test different selection - United instead of KLM
      await subgraphsPage.selectFlight('United');
      
      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('United').catch(async () => {
        await expect(page.getByText(/United/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches  
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });
      
      // FEATURE TEST: Test different hotel selection - Ritz-Carlton
      await subgraphsPage.selectHotel('Ritz-Carlton');
      
      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton').catch(async () => {
        await expect(page.getByText(/Ritz-Carlton/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      // FEATURE TEST: Verify subgraph streaming detection - experiences agent is active
      await expect(subgraphsPage.experiencesAgentIndicator).toHaveClass(/active/).catch(() => {
        console.log("Experiences agent not active, checking content instead");
      });

      // FEATURE TEST: Verify complete state persistence across all agents
      await expect(subgraphsPage.selectedFlight).toContainText('United'); // Flight selection persisted
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton'); // Hotel selection persisted
      await subgraphsPage.verifyStaticExperienceData(); // Experiences provided based on selections
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphPythonTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/langgraph/feature/tool_based_generative_ui";

test('[LangGraph] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[LangGraph] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LangGraph] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-typescript/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LangGraph] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-typescript/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[LangGraph] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/langgraph-typescript/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/langGraphPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[LangGraph] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph-typescript/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    
    await genUIAgent.plan();
    
    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';
        
        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[LangGraph] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/langgraph-typescript/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();
    
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();
    
    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';
        
        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/langGraphPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LangGraph] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/langgraph-typescript/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);
      await page.goto(
        "/langgraph-typescript/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/langGraphPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[LangGraph] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph-typescript/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  test("[LangGraph] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/langgraph-typescript/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LangGraph] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/langgraph-typescript/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LangGraph] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/langgraph-typescript/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/subgraphsPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { SubgraphsPage } from "../../pages/langGraphPages/SubgraphsPage";

test.describe("Subgraphs Travel Agent Feature", () => {
  test("[LangGraph] should complete full travel planning flow with feature validation", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph-typescript/feature/subgraphs");

      await subgraphsPage.openChat();

      // Initiate travel planning
      await subgraphsPage.sendMessage("Help me plan a trip to San Francisco");
      await waitForAIResponse(page);
      
      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test interrupt pause behavior - flow shouldn't auto-proceed
      await page.waitForTimeout(3000);
      // await expect(page.getByText(/hotel.*options|accommodation|Zephyr|Ritz-Carlton|Hotel Zoe/i)).not.toBeVisible();

      // Select KLM flight through interrupt
      await subgraphsPage.selectFlight('KLM');
      
      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('KLM').catch(async () => {
        await expect(page.getByText(/KLM/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches  
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticHotelData();

      // FEATURE TEST: Test interrupt pause behavior again
      await page.waitForTimeout(3000);

      // Select Hotel Zoe through interrupt
      await subgraphsPage.selectHotel('Zoe');
      
      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Zoe').catch(async () => {
        await expect(page.getByText(/Hotel Zoe|Zoe/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticExperienceData();
    });
  });

  test("[LangGraph] should handle different selections and demonstrate supervisor routing patterns", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const subgraphsPage = new SubgraphsPage(page);

      await page.goto("/langgraph-typescript/feature/subgraphs");

      await subgraphsPage.openChat();

      await subgraphsPage.sendMessage("I want to visit San Francisco from Amsterdam");
      await waitForAIResponse(page);
      
      // FEATURE TEST: Wait for supervisor coordination
      await subgraphsPage.waitForSupervisorCoordination();
      await expect(subgraphsPage.supervisorIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Supervisor indicator not found, verifying through content");
      });

      // FEATURE TEST: Flights Agent - verify agent indicator becomes active
      await subgraphsPage.waitForFlightsAgent();
      await expect(subgraphsPage.flightsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Flights agent indicator not found, checking content instead");
      });
      
      await subgraphsPage.verifyStaticFlightData();

      // FEATURE TEST: Test different selection - United instead of KLM
      await subgraphsPage.selectFlight('United');
      
      // FEATURE TEST: Verify immediate state update after selection
      await expect(subgraphsPage.selectedFlight).toContainText('United').catch(async () => {
        await expect(page.getByText(/United/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Hotels Agent - verify agent indicator switches  
      await subgraphsPage.waitForHotelsAgent();
      await expect(subgraphsPage.hotelsAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Hotels agent indicator not found, checking content instead");
      });
      
      // FEATURE TEST: Test different hotel selection - Ritz-Carlton
      await subgraphsPage.selectHotel('Ritz-Carlton');
      
      // FEATURE TEST: Verify hotel selection immediately updates state
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton').catch(async () => {
        await expect(page.getByText(/Ritz-Carlton/i)).toBeVisible({ timeout: 2000 });
      });
      
      await waitForAIResponse(page);

      // FEATURE TEST: Experiences Agent - verify agent indicator becomes active
      await subgraphsPage.waitForExperiencesAgent();
      await expect(subgraphsPage.experiencesAgentIndicator).toBeVisible({ timeout: 10000 }).catch(() => {
        console.log("Experiences agent indicator not found, checking content instead");
      });

      // FEATURE TEST: Verify subgraph streaming detection - experiences agent is active
      await expect(subgraphsPage.experiencesAgentIndicator).toHaveClass(/active/).catch(() => {
        console.log("Experiences agent not active, checking content instead");
      });

      // FEATURE TEST: Verify complete state persistence across all agents
      await expect(subgraphsPage.selectedFlight).toContainText('United'); // Flight selection persisted
      await expect(subgraphsPage.selectedHotel).toContainText('Ritz-Carlton'); // Hotel selection persisted
      await subgraphsPage.verifyStaticExperienceData(); // Experiences provided based on selections
    });
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/langgraphTypescriptTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/langgraph-typescript/feature/tool_based_generative_ui";

test('[LangGraph] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[LangGraph] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[LlamaIndex] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/llama-index/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[LlamaIndex] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/llama-index/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[LlamaIndex] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/llama-index/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/llamaIndexPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  // Fails. Issue with integration or something.
  test("[LlamaIndex] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/llama-index/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Give me a plan to make brownies using your tools");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });

    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  // Fails. Issue with integration or something.
  test("[LlamaIndex] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/llama-index/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars using your tools");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });

    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/llamaIndexPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[LlamaIndex] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/llama-index/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[LlamaIndex] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/llama-index/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Plan a mission to Mars with multiple steps and the first step being 'Start The Planning'"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();
      
      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
        
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/llamaIndexTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[LlamaIndex] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/llama-index/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[LlamaIndex] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/llama-index/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraAgentLocalTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[MastraAgentLocal] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra-agent-local/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[MastraAgentLocal] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra-agent-local/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[MastraAgentLocal] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra-agent-local/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraAgentLocalTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[MastraAgentLocal] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/mastra-agent-local/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[MastraAgentLocal] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/mastra-agent-local/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraAgentLocalTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/mastra-agent-local/feature/tool_based_generative_ui";

test('[Mastra Agent Local] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[Mastra Agent Local] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Mastra] Agentic Chat sends and receives a greeting message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi");
    await chat.assertAgentReplyVisible(/Hello|Hi|hey/i);
  });
});

test("[Mastra] Agentic Chat provides weather information", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Ask for Islamabad weather
    await chat.sendMessage("What is the weather in Islamabad");
    await chat.assertUserMessageVisible("What is the weather in Islamabad");
    await waitForAIResponse(page);

    // Check if the response contains the expected weather information structure
    await chat.assertWeatherResponseStructure();
  });
});

test("[Mastra] Agentic Chat retains memory of previous questions", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // First question about weather
    await chat.sendMessage("What is the weather in Islamabad");
    await chat.assertUserMessageVisible("What is the weather in Islamabad");
    await waitForAIResponse(page);
    await chat.assertWeatherResponseStructure();

    // Ask about the first question to test memory
    await chat.sendMessage("What was my first question");
    await chat.assertUserMessageVisible("What was my first question");
    await waitForAIResponse(page);

    // Check if the agent remembers the first question about weather
    await chat.assertAgentReplyVisible(/weather|Islamabad/i);
  });
});

test("[Mastra] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/mastra/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/mastraTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/mastra/feature/tool_based_generative_ui";

// Fails. Not a test issue, issue with the integration or cpk.
test.fixme('[Mastra] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

// Fails. Not a test issue, issue with the integration or cpk.
test.fixme('[Mastra] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/middlewareStarterTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Middleware Starter] Testing Agentic Chat", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/middleware-starter/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });
    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Hello world!/i);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[PydanticAI] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/pydantic-ai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[PydanticAI] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/pydantic-ai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[PydanticAI] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/pydantic-ai/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/pydanticAIPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  // Flaky. Sometimes the steps render but never process.
  test("[PydanticAI] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/pydantic-ai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("give me a plan to make brownies");
    await genUIAgent.sendButton.click();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });

  test("[PydanticAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/pydantic-ai/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await genUIAgent.assertAgentReplyVisible(/Hello/);

    await genUIAgent.sendMessage("Go to Mars");
    await genUIAgent.sendButton.click();

    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    await genUIAgent.plan();

    await page.waitForFunction(
      () => {
        const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
        const lastMessage = messages[messages.length - 1];
        const content = lastMessage?.textContent?.trim() || '';

        return messages.length >= 3 && content.length > 0;
      },
      { timeout: 30000 }
    );
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/pydanticAIPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test("[PydanticAI] should interact with the chat and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/pydantic-ai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();

      await humanInLoop.sendMessage(
        "Give me a plan to make brownies, there should be only one step with eggs and one step with oven, this is a strict requirement so adhere"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const itemText = "eggs";
      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(itemText);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';
          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${itemText}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });

  test("[PydanticAI] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/pydantic-ai/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await humanInLoop.sendMessage(
        "Plan a mission to Mars with the first step being Start The Planning"
      );
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });

      const uncheckedItem = "Start The Planning";

      await page.waitForTimeout(5000);
      await humanInLoop.uncheckItem(uncheckedItem);
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';

          return messages.length >= 3 && content.length > 0;
        },
        { timeout: 30000 }
      );

      await humanInLoop.sendMessage(
        `Does the planner include ${uncheckedItem}? ⚠️ Reply with only words 'Yes' or 'No' (no explanation, no punctuation).`
      );
      await waitForAIResponse(page);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/predictiveStateUpdatePage.spec.ts
================================================
import {
  test,
  expect,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/pydanticAIPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  // Fails on a production build.
  test.fixme("[PydanticAI] should interact with agent and approve asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/pydantic-ai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called Atlantis in document"
      );
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.nth(1).isVisible();
      const dragonNameNew = await predictiveStateUpdates.verifyAgentResponse(
        "Lola"
      );
      expect(dragonNameNew).not.toBe(dragonName);
    });
  });

  // SKipped while the above test is failing, the entire feature is temporarily disabled
  test.skip("[PydanticAI] should interact with agent and reject asked changes", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      // Update URL to new domain
      await page.goto(
        "/pydantic-ai/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();

      await predictiveStateUpdates.sendMessage(
        "Give me a story for a dragon called called Atlantis in document"
      );
      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();
      const dragonName = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonName).not.toBeNull();

      // Send update to change the dragon name
      await predictiveStateUpdates.sendMessage("Change dragon name to Lola");
      await page.waitForTimeout(2000);
      await predictiveStateUpdates.verifyHighlightedText();
      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();
      const dragonNameAfterRejection = await predictiveStateUpdates.verifyAgentResponse(
        "Atlantis"
      );
      expect(dragonNameAfterRejection).toBe(dragonName);
      expect(dragonNameAfterRejection).not.toBe("Lola");
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[PydanticAI] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/pydantic-ai/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Pasta');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  test("[PydanticAI] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/pydantic-ai/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify chat response includes both existing and new ingredients
    await expect(sharedStateAgent.agentMessage.getByText(/Potatoes/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/12/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/Carrots/)).toBeVisible();
    await expect(sharedStateAgent.agentMessage.getByText(/All-Purpose Flour/)).toBeVisible();
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/pydanticAITests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/pydantic-ai/feature/tool_based_generative_ui";

test('[PydanticAI] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[PydanticAI] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku(); // Wait for second haiku to be generated
  await genAIAgent.checkHaikuDisplay(page); // Now compare the second haiku
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Server Starter all features] Agentic Chat displays countdown from 10 to 1 with tick mark", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/server-starter-all-features/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });
    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);

    const countdownMessage = page
      .locator('.copilotKitAssistantMessage')
      .filter({ hasText: 'counting down:' });

    await expect(countdownMessage).toBeVisible({ timeout: 30000 });

    // Wait for countdown to complete by checking for the tick mark
    await expect(countdownMessage.locator('.copilotKitMarkdownElement'))
      .toContainText('✓', { timeout: 15000 });

    const countdownText = await countdownMessage
      .locator('.copilotKitMarkdownElement')
      .textContent();

    expect(countdownText).toContain("counting down:");
    expect(countdownText).toMatch(/counting down:\s*10\s+9\s+8\s+7\s+6\s+5\s+4\s+3\s+2\s+1\s+✓/);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/agenticGenUI.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { AgenticGenUIPage } from "../../pages/serverStarterAllFeaturesPages/AgenticUIGenPage";

test.describe("Agent Generative UI Feature", () => {
  test("[Server Starter all features] should interact with the chat to get a planner on prompt", async ({
    page,
  }) => {
    const genUIAgent = new AgenticGenUIPage(page);

    await page.goto(
      "/server-starter-all-features/feature/agentic_generative_ui"
    );

    await genUIAgent.openChat();
    await genUIAgent.sendMessage("Hi");
    await genUIAgent.sendButton.click();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 15000 });
    
    await genUIAgent.plan();
    await expect(genUIAgent.agentPlannerContainer).toBeVisible({ timeout: 8000 });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/humanInTheLoopPage.spec.ts
================================================
import { test, expect, waitForAIResponse, retryOnAIFailure } from "../../test-isolation-helper";
import { HumanInLoopPage } from "../../pages/serverStarterAllFeaturesPages/HumanInLoopPage";

test.describe("Human in the Loop Feature", () => {
  test(" [Server Starter all features] should interact with the chat using predefined prompts and perform steps", async ({
    page,
  }) => {
    await retryOnAIFailure(async () => {
      const humanInLoop = new HumanInLoopPage(page);

      await page.goto(
        "/server-starter-all-features/feature/human_in_the_loop"
      );

      await humanInLoop.openChat();

      await humanInLoop.sendMessage("Hi");
      await humanInLoop.agentGreeting.isVisible();
      await waitForAIResponse(page);
      await expect(humanInLoop.plan).toBeVisible({ timeout: 10000 });
      await humanInLoop.performSteps();

      await page.waitForFunction(
        () => {
          const messages = Array.from(document.querySelectorAll('.copilotKitAssistantMessage'));
          const lastMessage = messages[messages.length - 1];
          const content = lastMessage?.textContent?.trim() || '';

          return messages.length >= 2 && content.length > 0;
        },
        { timeout: 30000 }
      );
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/predictiveStateUpdatePage.spec.ts
================================================
import { test, expect, retryOnAIFailure, } from "../../test-isolation-helper";
import { PredictiveStateUpdatesPage } from "../../pages/serverStarterAllFeaturesPages/PredictiveStateUpdatesPage";

test.describe("Predictive Status Updates Feature", () => {
  test("[Server Starter all features] should interact with agent and approve asked changes", async ({ page, }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/server-starter-all-features/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage("Hi");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();

      const originalContent = await predictiveStateUpdates.getResponseContent();
      expect(originalContent).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change the dog name");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();

      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();

      const updatedContent = await predictiveStateUpdates.getResponseContent();

      expect(updatedContent).not.toBe(originalContent);
    });
  });

  test("[Server Starter all features] should interact with agent and reject asked changes", async ({ page, }) => {
    await retryOnAIFailure(async () => {
      const predictiveStateUpdates = new PredictiveStateUpdatesPage(page);

      await page.goto(
        "/server-starter-all-features/feature/predictive_state_updates"
      );

      await predictiveStateUpdates.openChat();
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.sendMessage("Hi");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.getPredictiveResponse();
      await predictiveStateUpdates.getUserApproval();
      await predictiveStateUpdates.confirmedChangesResponse.isVisible();

      const originalContent = await predictiveStateUpdates.getResponseContent();
      expect(originalContent).not.toBeNull();

      await page.waitForTimeout(3000);

      await predictiveStateUpdates.sendMessage("Change the dog name");
      await page.waitForTimeout(2000);
      await page.waitForTimeout(2000);

      await predictiveStateUpdates.verifyHighlightedText();

      await predictiveStateUpdates.getUserRejection();
      await predictiveStateUpdates.rejectedChangesResponse.isVisible();

      const currentContent = await predictiveStateUpdates.getResponseContent();

      expect(currentContent).toBe(originalContent);
    });
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/sharedStatePage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { SharedStatePage } from "../../featurePages/SharedStatePage";

test.describe("Shared State Feature", () => {
  test("[Server Starter all features] should interact with the chat to get a recipe on prompt", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    // Update URL to new domain
    await page.goto(
      "/server-starter-all-features/feature/shared_state"
    );

    await sharedStateAgent.openChat();
    await sharedStateAgent.sendMessage('Please give me a pasta recipe of your choosing, but one of the ingredients should be "Pasta"');
    await sharedStateAgent.loader();
    await sharedStateAgent.awaitIngredientCard('Salt');
    await sharedStateAgent.getInstructionItems(
      sharedStateAgent.instructionsContainer
    );
  });

  // Fails. Issue with the test, most likely
  test("[Server Starter all features] should share state between UI and chat", async ({
    page,
  }) => {
    const sharedStateAgent = new SharedStatePage(page);

    await page.goto(
      "/server-starter-all-features/feature/shared_state"
    );

    await sharedStateAgent.openChat();

    // Add new ingredient via UI
    await sharedStateAgent.addIngredient.click();

    // Fill in the new ingredient details
    const newIngredientCard = page.locator('.ingredient-card').last();
    await newIngredientCard.locator('.ingredient-name-input').fill('Potatoes');
    await newIngredientCard.locator('.ingredient-amount-input').fill('12');

    // Wait for UI to update
    await page.waitForTimeout(1000);

    // Ask chat for all ingredients
    await sharedStateAgent.sendMessage("Give me all the ingredients");
    await sharedStateAgent.loader();

    // Verify hardcoded ingredients
    await sharedStateAgent.awaitIngredientCard('chicken breast');
    await sharedStateAgent.awaitIngredientCard('chili powder');
    await sharedStateAgent.awaitIngredientCard('Salt');
    await sharedStateAgent.awaitIngredientCard('Lettuce leaves');

    expect(await sharedStateAgent.getInstructionItems(sharedStateAgent.instructionsContainer)).toBe(3);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterAllFeaturesTests/toolBasedGenUIPage.spec.ts
================================================
import { test, expect } from "@playwright/test";
import { ToolBaseGenUIPage } from "../../featurePages/ToolBaseGenUIPage";

const pageURL =
  "/server-starter-all-features/feature/tool_based_generative_ui";

test('[Server Starter all features] Haiku generation and display verification', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();
  await genAIAgent.generateHaiku('Generate Haiku for "I will always win"');
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});

test('[Server Starter all features] Haiku generation and UI consistency for two different prompts', async ({
  page,
}) => {
  await page.goto(pageURL);

  const genAIAgent = new ToolBaseGenUIPage(page);

  await expect(genAIAgent.haikuAgentIntro).toBeVisible();

  const prompt1 = 'Generate Haiku for "I will always win"';
  await genAIAgent.generateHaiku(prompt1);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);

  const prompt2 = 'Generate Haiku for "The moon shines bright"';
  await genAIAgent.generateHaiku(prompt2);
  await genAIAgent.checkGeneratedHaiku();
  await genAIAgent.checkHaikuDisplay(page);
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/serverStarterTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[Server Starter] Testing Agentic Chat", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/server-starter/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });
    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Hello world!/i);
  });
});


================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/smoke-only/basic-loading.spec.ts
================================================
import { test, expect } from "@playwright/test";

test.describe("Demo Apps Loading Smoke Tests", () => {
  test("[Smoke] AG2 Agentic Chat app loads successfully", async ({ page }) => {
    await page.goto(
      "https://ag2-feature-viewer.vercel.app/feature/agentic_chat"
    );

    // Just verify the page loads and key elements are present
    await expect(
      page.getByRole("button", { name: "Agentic Chat Chat with your" })
    ).toBeVisible();
    await expect(page.getByText("Hi, I'm an agent. Want to")).toBeVisible();

    // Click to open chat
    await page
      .getByRole("button", { name: "Agentic Chat Chat with your" })
      .click();

    // Verify chat interface appears (not AI response)
    await expect(
      page.getByRole("textbox", { name: "Type a message..." })
    ).toBeVisible();
    await expect(
      page.locator('[data-test-id="copilot-chat-ready"]')
    ).toBeVisible();
  });

  test("[Smoke] Human in the Loop app loads successfully", async ({ page }) => {
    await page.goto(
      "https://ag2-feature-viewer.vercel.app/feature/human_in_the_loop"
    );

    await expect(
      page.getByRole("button", { name: "Human in the loop Plan a task" })
    ).toBeVisible();

    // Click to open chat
    await page
      .getByRole("button", { name: "Human in the loop Plan a task" })
      .click();

    // Verify chat interface appears
    await expect(
      page.getByRole("textbox", { name: "Type a message..." })
    ).toBeVisible();
    await expect(
      page.locator('[data-test-id="copilot-chat-ready"]')
    ).toBeVisible();
  });

  test("[Smoke] CoBankKit loads successfully", async ({ page }) => {
    await page.goto("https://co-bank-kit.vercel.app/");

    // Verify the app loads - just check that the page responds
    await expect(page.locator("body")).toBeVisible();

    // Wait for page to fully load and check for any interactive elements
    await page.waitForLoadState("networkidle");

    // Check for any visible content (more generic)
    const hasAnyContent = await page.locator("*").count();
    expect(hasAnyContent).toBeGreaterThan(1); // At least html and body
  });

  test("[Smoke] AG2 feature viewer homepage loads", async ({ page }) => {
    await page.goto("https://ag2-feature-viewer.vercel.app/");

    // Verify the homepage loads
    await expect(page.locator("body")).toBeVisible();

    // Check that we can navigate to features
    const hasFeatureLinks = await page.locator("a, button").count();
    expect(hasFeatureLinks).toBeGreaterThan(0);
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/tests/vercelAISdkTests/agenticChatPage.spec.ts
================================================
import {
  test,
  expect,
  waitForAIResponse,
  retryOnAIFailure,
} from "../../test-isolation-helper";
import { AgenticChatPage } from "../../featurePages/AgenticChatPage";

test("[verceAISdkPages] Agentic Chat sends and receives a message", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/vercel-ai-sdk/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.isVisible;
    await chat.sendMessage("Hi, I am duaa");

    await waitForAIResponse(page);
    await chat.assertUserMessageVisible("Hi, I am duaa");
    await chat.assertAgentReplyVisible(/Hello/i);
  });
});

test("[Vercel AI SDK] Agentic Chat changes background on message and reset", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/vercel-ai-sdk/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);

    await chat.openChat();
    await chat.agentGreeting.waitFor({ state: "visible" });

    // Store initial background color
    const backgroundContainer = page.locator('[data-testid="background-container"]')
    const initialBackground = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    console.log("Initial background color:", initialBackground);

    // 1. Send message to change background to blue
    await chat.sendMessage("Hi change the background color to blue");
    await chat.assertUserMessageVisible(
      "Hi change the background color to blue"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', initialBackground, { timeout: 7000 });
    const backgroundBlue = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is blue (string color name or contains blue)
    expect(backgroundBlue.toLowerCase()).toMatch(/blue|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);

    // 2. Change to pink
    await chat.sendMessage("Hi change the background color to pink");
    await chat.assertUserMessageVisible(
      "Hi change the background color to pink"
    );
    await waitForAIResponse(page);

    await expect(backgroundContainer).not.toHaveCSS('background-color', backgroundBlue, { timeout: 7000 });
    const backgroundPink = await backgroundContainer.evaluate(el => getComputedStyle(el).backgroundColor);
    // Check if background is pink (string color name or contains pink)
    expect(backgroundPink.toLowerCase()).toMatch(/pink|rgb\(.*,.*,.*\)|#[0-9a-f]{6}/);
  });
});

test("[Vercel AI SDK] Agentic Chat retains memory of user messages during a conversation", async ({
  page,
}) => {
  await retryOnAIFailure(async () => {
    await page.goto(
      "/vercel-ai-sdk/feature/agentic_chat"
    );

    const chat = new AgenticChatPage(page);
    await chat.openChat();
    await chat.agentGreeting.click();

    await chat.sendMessage("Hey there");
    await chat.assertUserMessageVisible("Hey there");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/how can I assist you/i);

    const favFruit = "Mango";
    await chat.sendMessage(`My favorite fruit is ${favFruit}`);
    await chat.assertUserMessageVisible(`My favorite fruit is ${favFruit}`);
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));

    await chat.sendMessage("and I love listening to Kaavish");
    await chat.assertUserMessageVisible("and I love listening to Kaavish");
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Kaavish/i);

    await chat.sendMessage("tell me an interesting fact about Moon");
    await chat.assertUserMessageVisible(
      "tell me an interesting fact about Moon"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(/Moon/i);

    await chat.sendMessage("Can you remind me what my favorite fruit is?");
    await chat.assertUserMessageVisible(
      "Can you remind me what my favorite fruit is?"
    );
    await waitForAIResponse(page);
    await chat.assertAgentReplyVisible(new RegExp(favFruit, "i"));
  });
});



================================================
FILE: typescript-sdk/apps/dojo/e2e/utils/aiWaitHelpers.ts
================================================
import { expect, Locator, Page } from "@playwright/test";

/**
 * Wait for AI assistant messages with extended timeout and retry logic
 */
export async function waitForAIResponse(
  locator: Locator,
  pattern: RegExp,
  timeoutMs: number = 120_000 // 2 minutes default
) {
  await expect(locator.getByText(pattern)).toBeVisible({ timeout: timeoutMs });
}

/**
 * Wait for AI-generated content to appear with polling
 */
export async function waitForAIContent(
  locator: Locator,
  timeoutMs: number = 120_000 // 2 minutes default
) {
  await expect(locator).toBeVisible({ timeout: timeoutMs });
}

/**
 * Wait for AI form interactions with extended timeout
 */
export async function waitForAIFormReady(
  locator: Locator,
  timeoutMs: number = 60_000 // 1 minute default
) {
  await expect(locator).toBeVisible({ timeout: timeoutMs });
  await expect(locator).toBeEnabled({ timeout: timeoutMs });
  await expect(locator).toBeEditable({ timeout: timeoutMs });
}

/**
 * Wait for AI dialog/modal to appear
 */
export async function waitForAIDialog(
  locator: Locator,
  timeoutMs: number = 90_000 // 1.5 minutes default
) {
  await expect(locator).toBeVisible({ timeout: timeoutMs });
}

/**
 * Wait for pattern matching with custom timeout for AI responses
 */
export async function waitForAIPatterns(
  page: Page,
  patterns: RegExp[],
  timeoutMs: number = 120_000 // 2 minutes default
): Promise<void> {
  const endTime = Date.now() + timeoutMs;

  while (Date.now() < endTime) {
    for (const pattern of patterns) {
      try {
        const element = page.locator("body").getByText(pattern);
        if ((await element.count()) > 0) {
          await expect(element.first()).toBeVisible({ timeout: 5000 });
          return; // Found a match
        }
      } catch {
        // Continue searching
      }
    }

    await page.waitForTimeout(2000); // Wait 2s before next check
  }

  throw new Error(
    `None of the expected patterns matched within ${timeoutMs}ms: ${patterns
      .map((p) => p.toString())
      .join(", ")}`
  );
}



================================================
FILE: typescript-sdk/apps/dojo/public/logo_dark.webp
================================================
[Binary file]


================================================
FILE: typescript-sdk/apps/dojo/public/logo_light.webp
================================================
[Binary file]


================================================
FILE: typescript-sdk/apps/dojo/scripts/generate-content-json.ts
================================================
import fs from "fs";
import path from "path";

// Function to parse agents.ts file and extract agent keys without executing
function parseAgentsFile(): Array<{id: string, agentKeys: string[]}> {
  const agentsFilePath = path.join(__dirname, '../src/agents.ts');
  const agentsContent = fs.readFileSync(agentsFilePath, 'utf8');

  const agentConfigs: Array<{id: string, agentKeys: string[]}> = [];

  // Split the content to process each agent configuration individually
  const agentBlocks = agentsContent.split(/(?=\s*{\s*id:\s*["'])/);

  for (const block of agentBlocks) {
    // Extract the ID
    const idMatch = block.match(/id:\s*["']([^"']+)["']/);
    if (!idMatch) continue;

    const id = idMatch[1];

    // Find the return object by looking for the pattern and then manually parsing balanced braces
    const returnMatch = block.match(/agents:\s*async\s*\(\)\s*=>\s*{\s*return\s*{/);
    if (!returnMatch) continue;

    const startIndex = returnMatch.index! + returnMatch[0].length;
    const returnObjectContent = extractBalancedBraces(block, startIndex);


    // Extract keys from the return object - only capture keys that are followed by a colon and then 'new'
    // This ensures we only get the top-level keys like "agentic_chat: new ..." not nested keys like "url: ..."
    const keyRegex = /^\s*(\w+):\s*new\s+\w+/gm;
    const keys: string[] = [];
    let keyMatch;
    while ((keyMatch = keyRegex.exec(returnObjectContent)) !== null) {
      keys.push(keyMatch[1]);
    }

    agentConfigs.push({ id, agentKeys: keys });
  }

  return agentConfigs;
}

// Helper function to extract content between balanced braces
function extractBalancedBraces(text: string, startIndex: number): string {
  let braceCount = 0;
  let i = startIndex;

  while (i < text.length) {
    if (text[i] === '{') {
      braceCount++;
    } else if (text[i] === '}') {
      if (braceCount === 0) {
        // Found the closing brace for the return object
        return text.substring(startIndex, i);
      }
      braceCount--;
    }
    i++;
  }

  return '';
}

const agentConfigs = parseAgentsFile();

const featureFiles = ["page.tsx", "style.css", "README.mdx"]

async function getFile(_filePath: string | undefined, _fileName?: string) {
  if (!_filePath) {
    console.warn(`File path is undefined, skipping.`);
    return {}
  }

  const fileName = _fileName ?? _filePath.split('/').pop() ?? ''
  const filePath = _fileName ? path.join(_filePath, fileName) : _filePath;

  // Check if it's a remote URL
  const isRemoteUrl = _filePath.startsWith('http://') || _filePath.startsWith('https://');

  let content: string;

  try {
    if (isRemoteUrl) {
      // Convert GitHub URLs to raw URLs for direct file access
      let fetchUrl = _filePath;
      if (_filePath.includes('github.com') && _filePath.includes('/blob/')) {
        fetchUrl = _filePath.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/');
      }

      // Fetch remote file content
      console.log(`Fetching remote file: ${fetchUrl}`);
      const response = await fetch(fetchUrl);
      if (!response.ok) {
        console.warn(`Failed to fetch remote file: ${fetchUrl}, status: ${response.status}`);
        return {}
      }
      content = await response.text();
    } else {
      // Handle local file
      if (!fs.existsSync(filePath)) {
        console.warn(`File not found: ${filePath}, skipping.`);
        return {}
      }
      content = fs.readFileSync(filePath, "utf8");
    }

    const extension = fileName.split(".").pop();
    let language = extension;
    if (extension === "py") language = "python";
    else if (extension === "css") language = "css";
    else if (extension === "md" || extension === "mdx") language = "markdown";
    else if (extension === "tsx") language = "typescript";
    else if (extension === "js") language = "javascript";
    else if (extension === "json") language = "json";
    else if (extension === "yaml" || extension === "yml") language = "yaml";
    else if (extension === "toml") language = "toml";

    return {
      name: fileName,
      content,
      language,
      type: 'file'
    }
  } catch (error) {
    console.error(`Error reading file ${filePath}:`, error);
    return {}
  }
}

async function getFeatureFrontendFiles(featureId: string) {
  const featurePath = path.join(__dirname, `../src/app/[integrationId]/feature/${featureId as string}`);
  const retrievedFiles = []

  for (const fileName of featureFiles) {
    retrievedFiles.push(await getFile(featurePath, fileName))
  }

  return retrievedFiles;
}

const integrationsFolderPath = '../../../integrations'
const agentFilesMapper: Record<string, (agentKeys: string[]) => Record<string, string[]>> = {
  'middleware-starter': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/middleware-starter/src/index.ts`)]
  }),
  'pydantic-ai': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/pydantic-ai/examples/server/api/${agentId}.py`)]
    }), {})
  },
  'server-starter': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/server-starter/server/python/example_server/__init__.py`)]
  }),
  'server-starter-all-features': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/server-starter-all-features/server/python/example_server/${agentId}.py`)]
    }), {})
  },
  'mastra': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/mastra/example/src/mastra/agents/weather-agent.ts`)]
  }),
  'mastra-agent-lock': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/mastra/example/src/mastra/agents/weather-agent.ts`)]
  }),
  'vercel-ai-sdk': () => ({
    agentic_chat: [path.join(__dirname, integrationsFolderPath, `/vercel-ai-sdk/src/index.ts`)]
  }),
  'langgraph': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/python/agents/${agentId}/agent.py`),
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/typescript/src/agents/${agentId}/agent.ts`)
      ]
    }), {})
  },
  'langgraph-typescript': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/python/agents/${agentId}/agent.py`),
        path.join(__dirname, integrationsFolderPath, `/langgraph/examples/typescript/src/agents/${agentId}/agent.ts`)
      ]
    }), {})
  },
  'langgraph-fastapi': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/langgraph/examples/python/agents/${agentId}/agent.py`)]
    }), {})
  },
  'agno': () => ({}),
  'llama-index': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/llamaindex/server-py/server/routers/${agentId}.py`)]
    }), {})
  },
  'crewai': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/crewai/python/ag_ui_crewai/examples/${agentId}.py`)]
    }), {})
  },
  'adk-middleware': (agentKeys: string[]) => {
    return agentKeys.reduce((acc, agentId) => ({
      ...acc,
      [agentId]: [path.join(__dirname, integrationsFolderPath, `/adk-middleware/python/examples/server/api/${agentId}.py`)]
    }), {})
  }
}

async function runGenerateContent() {
  const result = {}
  for (const agentConfig of agentConfigs) {
    // Use the parsed agent keys instead of executing the agents function
    const agentsPerFeatures = agentConfig.agentKeys

    const agentFilePaths = agentFilesMapper[agentConfig.id](agentConfig.agentKeys)

    // Per feature, assign all the frontend files like page.tsx as well as all agent files
    for (const featureId of agentsPerFeatures) {
      const agentFilePathsForFeature = agentFilePaths[featureId] ?? []
      // @ts-expect-error -- redundant error about indexing of a new object.
      result[`${agentConfig.id}::${featureId}`] = [
        // Get all frontend files for the feature
        ...(await getFeatureFrontendFiles(featureId)),
        // Get the agent (python/TS) file
        ...(await Promise.all(agentFilePathsForFeature.map(async f => await getFile(f))))
      ]
    }
  }

  return result
}

(async () => {
  const result = await runGenerateContent();
  fs.writeFileSync(
      path.join(__dirname, "../src/files.json"),
      JSON.stringify(result, null, 2)
  );

  console.log("Successfully generated src/files.json");
})();


================================================
FILE: typescript-sdk/apps/dojo/scripts/link-cpk.js
================================================
#!/usr/bin/env node
const fs = require('fs');
const { execSync } = require('child_process');
const path = require('path');

const cpkPath = process.argv[2];
if (!cpkPath) {
  console.error('Usage: node link-cpk.js <cpk-path>');
  process.exit(1);
}

if (!fs.existsSync(cpkPath)) {
  console.error(`copilot kit repo path ${cpkPath} does not exist`);
  process.exit(1);
}


const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf-8', cwd: __dirname }).trim();
const dojoDir = path.join(gitRoot, 'typescript-sdk/apps/dojo');
const cpkPackageDir = path.join(cpkPath, 'CopilotKit', 'packages');
const relative = `./${path.relative(dojoDir, cpkPackageDir)}`;

function linkCopilotKit() {
  const pkgPath = path.join(dojoDir, 'package.json');
  const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
  const packages = Object.keys(pkg.dependencies).filter(pkg => pkg.startsWith('@copilotkit/'));

  success = true;
  packages.forEach(packageName => {
    const packageFolderName = packageName.replace('@copilotkit/', '');

    if (!fs.existsSync(path.join(cpkPackageDir, packageFolderName))) {
      console.error(`Package ${packageName} does not exist in ${cpkPackageDir}!!`);
      success = false;
    }

    pkg.dependencies[packageName] = path.join(relative, packageFolderName);
  });



  if (!success) {
    console.error('One or more packages do not exist in the copilot kit repo!');
    process.exit(1);
  }

  fs.writeFileSync(pkgPath, JSON.stringify(pkg, null, 2));

}

linkCopilotKit();


================================================
FILE: typescript-sdk/apps/dojo/scripts/prep-dojo-everything.js
================================================
#!/usr/bin/env node

const { execSync } = require('child_process');
const path = require('path');
const concurrently = require('concurrently');

// Parse command line arguments
const args = process.argv.slice(2);
const showHelp = args.includes('--help') || args.includes('-h');
const dryRun = args.includes('--dry-run');

// selection controls
function parseList(flag) {
  const idx = args.indexOf(flag);
  if (idx !== -1 && args[idx + 1]) {
    return args[idx + 1]
      .split(',')
      .map((s) => s.trim())
      .filter(Boolean);
  }
  return null;
}

const onlyList = parseList('--only') || parseList('--include');
const excludeList = parseList('--exclude') || [];

if (showHelp) {
  console.log(`
Usage: node prep-dojo-everything.js [options]

Options:
  --dry-run       Show what would be installed without actually running
  --only list     Comma-separated services to include (defaults to all)
  --exclude list  Comma-separated services to exclude
  --help, -h      Show this help message

Examples:
  node prep-dojo-everything.js
  node prep-dojo-everything.js --dry-run
  node prep-dojo-everything.js --only dojo,agno
  node prep-dojo-everything.js --exclude crew-ai,mastra
`);
  process.exit(0);
}

const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf-8' }).trim();
const integrationsRoot = path.join(gitRoot, 'typescript-sdk', 'integrations');



// Define all prep targets keyed by a stable id
const ALL_TARGETS = {
  'server-starter': {
    command: 'poetry install',
    name: 'Server Starter',
    cwd: path.join(integrationsRoot, 'server-starter/server/python'),
  },
  'server-starter-all': {
    command: 'poetry install',
    name: 'Server AF',
    cwd: path.join(integrationsRoot, 'server-starter-all-features/server/python'),
  },
  'agno': {
    command: 'uv sync',
    name: 'Agno',
    cwd: path.join(integrationsRoot, 'agno/examples'),
  },
  'crew-ai': {
    command: 'poetry install',
    name: 'CrewAI',
    cwd: path.join(integrationsRoot, 'crewai/python'),
  },
  'langgraph-fastapi': {
    command: 'poetry install',
    name: 'LG FastAPI',
    cwd: path.join(integrationsRoot, 'langgraph/examples/python'),
    env: {
      POETRY_VIRTUALENVS_IN_PROJECT: "false",
    },
  },
  'langgraph-platform-typescript': {
    command: 'pnpm install',
    name: 'LG Platform TS',
    cwd: path.join(integrationsRoot, 'langgraph/examples/typescript/'),
  },
  'llama-index': {
    command: 'uv sync',
    name: 'Llama Index',
    cwd: path.join(integrationsRoot, 'llamaindex/server-py'),
  },
  'mastra': {
    command: 'npm install',
    name: 'Mastra',
    cwd: path.join(integrationsRoot, 'mastra/example'),
  },
  'pydantic-ai': {
    command: 'uv sync',
    name: 'Pydantic AI',
    cwd: path.join(integrationsRoot, 'pydantic-ai/examples'),
  },
  'adk-middleware': {
    command: 'uv sync',
    name: 'ADK Middleware',
    cwd: path.join(integrationsRoot, 'adk-middleware/python/examples'),
  },
  'dojo': {
    command: 'pnpm install --no-frozen-lockfile && pnpm build --filter=demo-viewer...',
    name: 'Dojo',
    cwd: path.join(gitRoot, 'typescript-sdk'),
  },
};

function printDryRunServices(procs) {
  console.log('Dry run - would install dependencies for the following services:');
  procs.forEach(proc => {
    console.log(`  - ${proc.name} (${proc.cwd})`);
    console.log(`    Command: ${proc.command}`);
    console.log('');
  });
  process.exit(0);
}

async function main() {
  // determine selection
  let selectedKeys = Object.keys(ALL_TARGETS);
  if (onlyList && onlyList.length) {
    selectedKeys = onlyList;
  }
  if (excludeList && excludeList.length) {
    selectedKeys = selectedKeys.filter((k) => !excludeList.includes(k));
  }

  // Build procs list, warning on unknown keys
  const procs = [];
  for (const key of selectedKeys) {
    const target = ALL_TARGETS[key];
    if (!target) {
      console.warn(`Skipping unknown service: ${key}`);
      continue;
    }
    procs.push(target);
  }

  if (dryRun) {
    printDryRunServices(procs);
  }

  const {result} = concurrently(procs);

  result.then(() => process.exit(0)).catch((err) => {
    console.error(err);
    process.exit(1);
  });
}

main();



================================================
FILE: typescript-sdk/apps/dojo/scripts/run-dojo-everything.js
================================================
#!/usr/bin/env node

const { execSync } = require('child_process');
const path = require('path');
const concurrently = require('concurrently');

// Parse command line arguments
const args = process.argv.slice(2);
const showHelp = args.includes('--help') || args.includes('-h');
const dryRun = args.includes('--dry-run');

function parseList(flag) {
  const idx = args.indexOf(flag);
  if (idx !== -1 && args[idx + 1]) {
    return args[idx + 1]
      .split(',')
      .map((s) => s.trim())
      .filter(Boolean);
  }
  return null;
}

const onlyList = parseList('--only') || parseList('--include');
const excludeList = parseList('--exclude') || [];

if (showHelp) {
  console.log(`
Usage: node run-dojo-everything.js [options]

Options:
  --dry-run       Show what would be started without actually running
  --only list     Comma-separated services to include (defaults to all)
  --exclude list  Comma-separated services to exclude
  --help, -h      Show this help message

Examples:
  node run-dojo-everything.js
  node run-dojo-everything.js --dry-run
  node run-dojo-everything.js --only dojo,server-starter
  node run-dojo-everything.js --exclude crew-ai,mastra
`);
  process.exit(0);
}

const gitRoot = execSync('git rev-parse --show-toplevel', { encoding: 'utf-8' }).trim();
const integrationsRoot = path.join(gitRoot, 'typescript-sdk', 'integrations');

// Define all runnable services keyed by a stable id
const ALL_SERVICES = {
  'server-starter': {
    command: 'poetry run dev',
    name: 'Server Starter',
    cwd: path.join(integrationsRoot, 'server-starter/server/python'),
    env: { PORT: 8000 },
  },
  'server-starter-all': {
    command: 'poetry run dev',
    name: 'Server AF',
    cwd: path.join(integrationsRoot, 'server-starter-all-features/server/python'),
    env: { PORT: 8001 },
  },
  'agno': {
    command: 'uv run dev',
    name: 'Agno',
    cwd: path.join(integrationsRoot, 'agno/examples'),
    env: { PORT: 8002 },
  },
  'crew-ai': {
    command: 'poetry run dev',
    name: 'CrewAI',
    cwd: path.join(integrationsRoot, 'crewai/python'),
    env: { PORT: 8003 },
  },
  'langgraph-fastapi': {
    command: 'poetry run dev',
    name: 'LG FastAPI',
    cwd: path.join(integrationsRoot, 'langgraph/examples/python'),
    env: {
      PORT: 8004,
      POETRY_VIRTUALENVS_IN_PROJECT: 'false',
    },
  },
  'langgraph-platform-python': {
    command: 'pnpx @langchain/langgraph-cli@latest dev --no-browser --host 127.0.0.1 --port 8005',
    name: 'LG Platform Py',
    cwd: path.join(integrationsRoot, 'langgraph/examples/python'),
    env: { PORT: 8005 },
  },
  'langgraph-platform-typescript': {
    command: 'pnpx @langchain/langgraph-cli@latest dev --no-browser --host 127.0.0.1 --port 8006',
    name: 'LG Platform TS',
    cwd: path.join(integrationsRoot, 'langgraph/examples/typescript/'),
    env: { PORT: 8006 },
  },
  'llama-index': {
    command: 'uv run dev',
    name: 'Llama Index',
    cwd: path.join(integrationsRoot, 'llamaindex/server-py'),
    env: { PORT: 8007 },
  },
  'mastra': {
    command: 'npm run dev',
    name: 'Mastra',
    cwd: path.join(integrationsRoot, 'mastra/example'),
    env: { PORT: 8008 },
  },
  'pydantic-ai': {
    command: 'uv run dev',
    name: 'Pydantic AI',
    cwd: path.join(integrationsRoot, 'pydantic-ai/examples'),
    env: { PORT: 8009 },
  },
  'adk-middleware': {
    command: 'uv run dev',
    name: 'ADK Middleware',
    cwd: path.join(integrationsRoot, 'adk-middleware/python/examples'),
    env: { PORT: 8010 },
  },
  'dojo': {
    command: 'pnpm run start',
    name: 'Dojo',
    cwd: path.join(gitRoot, 'typescript-sdk/apps/dojo'),
    env: {
      PORT: 9999,
      SERVER_STARTER_URL: 'http://localhost:8000',
      SERVER_STARTER_ALL_FEATURES_URL: 'http://localhost:8001',
      AGNO_URL: 'http://localhost:8002',
      CREW_AI_URL: 'http://localhost:8003',
      LANGGRAPH_FAST_API_URL: 'http://localhost:8004',
      LANGGRAPH_PYTHON_URL: 'http://localhost:8005',
      LANGGRAPH_TYPESCRIPT_URL: 'http://localhost:8006',
      LLAMA_INDEX_URL: 'http://localhost:8007',
      MASTRA_URL: 'http://localhost:8008',
      PYDANTIC_AI_URL: 'http://localhost:8009',
      ADK_MIDDLEWARE_URL: 'http://localhost:8010',
      NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE: 'cpkdojo.local___CopilotKit Feature Viewer',
    },
  },
};

function printDryRunServices(procs) {
  console.log('Dry run - would start the following services:');
  procs.forEach(proc => {
    console.log(`  - ${proc.name} (${proc.cwd})`);
    console.log(`    Command: ${proc.command}`);
    console.log(`    Environment variables:`);
    if (proc.env) {
      Object.entries(proc.env).forEach(([key, value]) => {
        console.log(`      ${key}: ${value}`);
      });
    } else {
      console.log('      No environment variables specified.');
    }
    console.log('');
  });
  process.exit(0);
}

async function main() {
  // determine selection
  let selectedKeys = Object.keys(ALL_SERVICES);
  if (onlyList && onlyList.length) {
    selectedKeys = onlyList;
  }
  if (excludeList && excludeList.length) {
    selectedKeys = selectedKeys.filter((k) => !excludeList.includes(k));
  }

  // Build processes, warn for unknown keys
  const procs = [];
  for (const key of selectedKeys) {
    const svc = ALL_SERVICES[key];
    if (!svc) {
      console.warn(`Skipping unknown service: ${key}`);
      continue;
    }
    procs.push(svc);
  }

  if (dryRun) {
    printDryRunServices(procs);
  }

  console.log('Starting services: ', procs.map((p) => p.name).join(', '));

  const { result } = concurrently(procs, { killOthersOn: ['failure', 'success'] });

  result
    .then(() => process.exit(0))
    .catch((err) => {
      console.error(err);
      process.exit(1);
    });
}

main();



================================================
FILE: typescript-sdk/apps/dojo/src/agents.ts
================================================
import "server-only";

import { AgentIntegrationConfig } from "./types/integration";
import { MiddlewareStarterAgent } from "@ag-ui/middleware-starter";
import { ServerStarterAgent } from "@ag-ui/server-starter";
import { ServerStarterAllFeaturesAgent } from "@ag-ui/server-starter-all-features";
import { MastraClient } from "@mastra/client-js";
import { MastraAgent } from "@ag-ui/mastra";
import { VercelAISDKAgent } from "@ag-ui/vercel-ai-sdk";
import { openai } from "@ai-sdk/openai";
import { LangGraphAgent, LangGraphHttpAgent } from "@ag-ui/langgraph";
import { AgnoAgent } from "@ag-ui/agno";
import { LlamaIndexAgent } from "@ag-ui/llamaindex";
import { CrewAIAgent } from "@ag-ui/crewai";
import getEnvVars from "./env";
import { mastra } from "./mastra";
import { PydanticAIAgent } from "@ag-ui/pydantic-ai";
import { ADKAgent } from "@ag-ui/adk";

const envVars = getEnvVars();
export const agentsIntegrations: AgentIntegrationConfig[] = [
  {
    id: "middleware-starter",
    agents: async () => {
      return {
        agentic_chat: new MiddlewareStarterAgent(),
      };
    },
  },
  {
    id: "pydantic-ai",
    agents: async () => {
      return {
        agentic_chat: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/agentic_chat/`,
        }),
        agentic_generative_ui: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/agentic_generative_ui/`,
        }),
        human_in_the_loop: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/human_in_the_loop/`,
        }),
        // Disabled until we can figure out why production builds break
        // predictive_state_updates: new PydanticAIAgent({
        //   url: `${envVars.pydanticAIUrl}/predictive_state_updates/`,
        // }),
        shared_state: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/shared_state/`,
        }),
        tool_based_generative_ui: new PydanticAIAgent({
          url: `${envVars.pydanticAIUrl}/tool_based_generative_ui/`,
        }),
      };
    },
  },
  {
    id: "server-starter",
    agents: async () => {
      return {
        agentic_chat: new ServerStarterAgent({ url: envVars.serverStarterUrl }),
      };
    },
  },
  {
    id: "adk-middleware",
    agents: async () => {
      return {
        agentic_chat: new ADKAgent({ url: `${envVars.adkMiddlewareUrl}/chat` }),
        tool_based_generative_ui: new ADKAgent({ url: `${envVars.adkMiddlewareUrl}/adk-tool-based-generative-ui` }),
        human_in_the_loop: new ADKAgent({ url: `${envVars.adkMiddlewareUrl}/adk-human-in-loop-agent` }),
        shared_state: new ADKAgent({ url: `${envVars.adkMiddlewareUrl}/adk-shared-state-agent` }),
        // predictive_state_updates: new ADKAgent({ url: `${envVars.adkMiddlewareUrl}/adk-predictive-state-agent` }),
      };
    },
  },
  {
    id: "server-starter-all-features",
    agents: async () => {
      return {
        agentic_chat: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/agentic_chat`,
        }),
        human_in_the_loop: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/human_in_the_loop`,
        }),
        agentic_generative_ui: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/agentic_generative_ui`,
        }),
        tool_based_generative_ui: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/tool_based_generative_ui`,
        }),
        shared_state: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/shared_state`,
        }),
        predictive_state_updates: new ServerStarterAllFeaturesAgent({
          url: `${envVars.serverStarterAllFeaturesUrl}/predictive_state_updates`,
        }),
      };
    },
  },
  {
    id: "mastra",
    agents: async () => {
      const mastraClient = new MastraClient({
        baseUrl: envVars.mastraUrl,
      });

      return MastraAgent.getRemoteAgents({
        mastraClient,
      });
    },
  },
  {
    id: "mastra-agent-local",
    agents: async () => {
      return MastraAgent.getLocalAgents({ mastra });
    },
  },
  {
    id: "vercel-ai-sdk",
    agents: async () => {
      return {
        agentic_chat: new VercelAISDKAgent({ model: openai("gpt-4o") }),
      };
    },
  },
  {
    id: "langgraph",
    agents: async () => {
      return {
        agentic_chat: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "agentic_chat",
        }),
        agentic_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "agentic_generative_ui",
        }),
        human_in_the_loop: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "human_in_the_loop",
        }),
        predictive_state_updates: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "predictive_state_updates",
        }),
        shared_state: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "shared_state",
        }),
        tool_based_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "tool_based_generative_ui",
        }),
        agentic_chat_reasoning: new LangGraphHttpAgent({
          url: `${envVars.langgraphPythonUrl}/agent/agentic_chat_reasoning`,
        }),
        subgraphs: new LangGraphAgent({
          deploymentUrl: envVars.langgraphPythonUrl,
          graphId: "subgraphs",
        }),
      };
    },
  },
  {
    id: "langgraph-fastapi",
    agents: async () => {
      return {
        agentic_chat: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/agentic_chat`,
        }),
        agentic_generative_ui: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/agentic_generative_ui`,
        }),
        human_in_the_loop: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/human_in_the_loop`,
        }),
        predictive_state_updates: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/predictive_state_updates`,
        }),
        shared_state: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/shared_state`,
        }),
        tool_based_generative_ui: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/tool_based_generative_ui`,
        }),
        agentic_chat_reasoning: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/agentic_chat_reasoning`,
        }),
        subgraphs: new LangGraphHttpAgent({
          url: `${envVars.langgraphFastApiUrl}/agent/subgraphs`,
        }),
      };
    },
  },
  {
    id: "langgraph-typescript",
    agents: async () => {
      return {
        agentic_chat: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "agentic_chat",
        }),
        agentic_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "agentic_generative_ui",
        }),
        human_in_the_loop: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "human_in_the_loop",
        }),
        predictive_state_updates: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "predictive_state_updates",
        }),
        shared_state: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "shared_state",
        }),
        tool_based_generative_ui: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "tool_based_generative_ui",
        }),
        subgraphs: new LangGraphAgent({
          deploymentUrl: envVars.langgraphTypescriptUrl,
          graphId: "subgraphs",
        })
      };
    },
  },
  {
    id: "agno",
    agents: async () => {
      return {
        agentic_chat: new AgnoAgent({
          url: `${envVars.agnoUrl}/agentic_chat/agui`,
        }),
        tool_based_generative_ui: new AgnoAgent({
          url: `${envVars.agnoUrl}/tool_based_generative_ui/agui`,
        }),
      };
    },
  },
  {
    id: "llama-index",
    agents: async () => {
      return {
        agentic_chat: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/agentic_chat/run`,
        }),
        human_in_the_loop: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/human_in_the_loop/run`,
        }),
        agentic_generative_ui: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/agentic_generative_ui/run`,
        }),
        shared_state: new LlamaIndexAgent({
          url: `${envVars.llamaIndexUrl}/shared_state/run`,
        }),
      };
    },
  },
  {
    id: "crewai",
    agents: async () => {
      return {
        agentic_chat: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/agentic_chat`,
        }),
        human_in_the_loop: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/human_in_the_loop`,
        }),
        tool_based_generative_ui: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/tool_based_generative_ui`,
        }),
        agentic_generative_ui: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/agentic_generative_ui`,
        }),
        shared_state: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/shared_state`,
        }),
        predictive_state_updates: new CrewAIAgent({
          url: `${envVars.crewAiUrl}/predictive_state_updates`,
        }),
      };
    },
  },
];



================================================
FILE: typescript-sdk/apps/dojo/src/config.ts
================================================
import { FeatureConfig } from "@/types/feature";

// A helper method to creating a config
function createFeatureConfig({
  id,
  name,
  description,
  tags,
}: Pick<FeatureConfig, "id" | "name" | "description" | "tags">): FeatureConfig {
  return {
    id,
    name,
    description,
    path: `/feature/${id}`,
    tags,
  };
}

export const featureConfig: FeatureConfig[] = [
  createFeatureConfig({
    id: "agentic_chat",
    name: "Agentic Chat",
    description: "Chat with your Copilot and call frontend tools",
    tags: ["Chat", "Tools", "Streaming"],
  }),
  createFeatureConfig({
    id: "human_in_the_loop",
    name: "Human in the loop",
    description: "Plan a task together and direct the Copilot to take the right steps",
    tags: ["HITL", "Interactivity"],
  }),
  createFeatureConfig({
    id: "agentic_generative_ui",
    name: "Agentic Generative UI",
    description: "Assign a long running task to your Copilot and see how it performs!",
    tags: ["Generative ui (agent)", "Long running task"],
  }),
  createFeatureConfig({
    id: "tool_based_generative_ui",
    name: "Tool Based Generative UI",
    description: "Haiku generator that uses tool based generative UI.",
    tags: ["Generative ui (action)", "Tools"],
  }),
  createFeatureConfig({
    id: "shared_state",
    name: "Shared State between agent and UI",
    description: "A recipe Copilot which reads and updates collaboratively",
    tags: ["Agent State", "Collaborating"],
  }),
  createFeatureConfig({
    id: "predictive_state_updates",
    name: "Predictive State Updates",
    description: "Use collaboration to edit a document in real time with your Copilot",
    tags: ["State", "Streaming", "Tools"],
  }),
  createFeatureConfig({
    id: "agentic_chat_reasoning",
    name: "Agentic Chat Reasoning",
    description: "Chat with a reasoning Copilot and call frontend tools",
    tags: ["Chat", "Tools", "Streaming", "Reasoning"],
  }),
  createFeatureConfig({
    id: "subgraphs",
    name: "Subgraphs",
    description: "Have your tasks performed by multiple agents, working together",
    tags: ["Chat", "Multi-agent architecture", "Streaming", "Subgraphs"],
  }),
];

export default featureConfig;



================================================
FILE: typescript-sdk/apps/dojo/src/env.ts
================================================
type envVars = {
  serverStarterUrl: string;
  serverStarterAllFeaturesUrl: string;
  mastraUrl: string;
  langgraphPythonUrl: string;
  langgraphFastApiUrl: string;
  langgraphTypescriptUrl: string;
  agnoUrl: string;
  llamaIndexUrl: string;
  crewAiUrl: string;
  pydanticAIUrl: string;
  adkMiddlewareUrl: string;
  customDomainTitle: Record<string, string>;
}

export default function getEnvVars(): envVars {
  const customDomainTitle: Record<string, string> = {};
  if (process.env.NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE) {
    const [domain, title] = process.env.NEXT_PUBLIC_CUSTOM_DOMAIN_TITLE.split('___');
    if (domain && title) {
      customDomainTitle[domain] = title;
    }
  }

  return {
    serverStarterUrl: process.env.SERVER_STARTER_URL || 'http://localhost:8000',
    serverStarterAllFeaturesUrl: process.env.SERVER_STARTER_ALL_FEATURES_URL || 'http://localhost:8000',
    mastraUrl: process.env.MASTRA_URL || 'http://localhost:4111',
    langgraphPythonUrl: process.env.LANGGRAPH_PYTHON_URL || 'http://localhost:2024',
    langgraphFastApiUrl: process.env.LANGGRAPH_FAST_API_URL || 'http://localhost:8000',
    langgraphTypescriptUrl: process.env.LANGGRAPH_TYPESCRIPT_URL || 'http://localhost:2024',
    agnoUrl: process.env.AGNO_URL || 'http://localhost:9001',
    llamaIndexUrl: process.env.LLAMA_INDEX_URL || 'http://localhost:9000',
    crewAiUrl: process.env.CREW_AI_URL || 'http://localhost:9002',
    pydanticAIUrl: process.env.PYDANTIC_AI_URL || 'http://localhost:9000',
    adkMiddlewareUrl: process.env.ADK_MIDDLEWARE_URL || 'http://localhost:8000',
    customDomainTitle: customDomainTitle,
  }
}


================================================
FILE: typescript-sdk/apps/dojo/src/menu.ts
================================================
import { MenuIntegrationConfig } from "./types/integration";

export const menuIntegrations: MenuIntegrationConfig[] = [
  {
    id: "middleware-starter",
    name: "Middleware Starter",
    features: ["agentic_chat"],
  },
  {
    id: "server-starter",
    name: "Server Starter",
    features: ["agentic_chat"],
  },
  {
    id: "adk-middleware",
    name: "ADK Middleware",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "shared_state",
      "tool_based_generative_ui",
      // "predictive_state_updates"
    ],
  },
  {
    id: "server-starter-all-features",
    name: "Server Starter (All Features)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_chat_reasoning",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
    ],
  },
  {
    id: "agno",
    name: "Agno",
    features: ["agentic_chat", "tool_based_generative_ui"],
  },
  {
    id: "crewai",
    name: "CrewAI",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
    ],
  },
  {
    id: "langgraph",
    name: "LangGraph (Python)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
      "subgraphs",
    ],
  },
  {
    id: "langgraph-fastapi",
    name: "LangGraph (FastAPI)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_chat_reasoning",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
      "subgraphs",
    ],
  },
  {
    id: "langgraph-typescript",
    name: "LangGraph (Typescript)",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
      "subgraphs",
    ],
  },
  {
    id: "llama-index",
    name: "LlamaIndex",
    features: ["agentic_chat", "human_in_the_loop", "agentic_generative_ui", "shared_state"],

  },
  {
    id: "mastra",
    name: "Mastra",
    features: ["agentic_chat", "tool_based_generative_ui"],
  },
  {
    id: "mastra-agent-local",
    name: "Mastra Agent (Local)",
    features: ["agentic_chat", "shared_state", "tool_based_generative_ui"],
  },
  {
    id: "pydantic-ai",
    name: "Pydantic AI",
    features: [
      "agentic_chat",
      "human_in_the_loop",
      "agentic_generative_ui",
      // Disabled until we can figure out why production builds break
      // "predictive_state_updates",
      "shared_state",
      "tool_based_generative_ui",
    ],
  },
  {
    id: "vercel-ai-sdk",
    name: "Vercel AI SDK",
    features: ["agentic_chat"],
  },
];




================================================
FILE: typescript-sdk/apps/dojo/src/app/globals.css
================================================
@import "tailwindcss";
@import "../styles/typography.css";

@plugin "tailwindcss-animate";

@custom-variant dark (&:is(.dark *));

@theme {
  /* Base Shadcn Colors */
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --color-card: var(--card);
  --color-card-foreground: var(--card-foreground);
  --color-popover: var(--popover);
  --color-popover-foreground: var(--popover-foreground);
  --color-primary: var(--primary);
  --color-primary-foreground: var(--primary-foreground);
  --color-secondary: var(--secondary);
  --color-secondary-foreground: var(--secondary-foreground);
  --color-muted: var(--muted);
  --color-muted-foreground: var(--muted-foreground);
  --color-accent: var(--accent);
  --color-accent-foreground: var(--accent-foreground);
  --color-destructive: var(--destructive);
  --color-destructive-foreground: var(--destructive-foreground);
  --color-border: var(--border);
  --color-input: var(--input);
  --color-ring: var(--ring);
  
  /* Provider Colors */
  --color-provider-openai: var(--openai);
  --color-provider-anthropic: var(--anthropic);
  --color-provider-cohere: var(--cohere);
  
  /* CopilotCloud Palette Colors */
  --color-palette-grey-0: #FFFFFF;
  --color-palette-grey-25: #FAFCFA;
  --color-palette-grey-100: #F7F7F9;
  --color-palette-grey-200: #F0F0F4;
  --color-palette-grey-300: #E9E9EF;
  --color-palette-grey-400: #E2E2EA;
  --color-palette-grey-500: #DBDBE5;
  --color-palette-grey-600: #AFAFB7;
  --color-palette-grey-700: #838389;
  --color-palette-grey-800: #575758;
  --color-palette-grey-900: #2B2B2B;
  --color-palette-grey-1000: #010507;
  
  --color-palette-mint-40030: rgba(133,224,206,0.3);
  --color-palette-mint-400: #85E0CE;
  --color-palette-mint-800: #1B936F;
  
  --color-palette-lilac-40010: rgba(190,194,255,0.1);
  --color-palette-lilac-40020: rgba(190,194,255,0.2);
  --color-palette-lilac-40030: rgba(190,194,255,0.3);
  --color-palette-lilac-400: #BEC2FF;
  
  --color-palette-yellow-40030: rgba(255,243,136,0.3);
  --color-palette-yellow-400: #FFF388;
  
  --color-palette-orange-40020: rgba(255,172,77,0.2);
  --color-palette-orange-400: #FFAC4D;
  
  --color-palette-surface-main: #DEDEE9;
  --color-palette-surface-solidEquivalentDefault70: #F8F8FB;
  --color-palette-surface-default70: rgba(255,255,255,0.7);
  --color-palette-surface-default50: rgba(255,255,255,0.5);
  --color-palette-surface-default30: rgba(255,255,255,0.3);
  --color-palette-surface-container: #FFFFFF;
  --color-palette-surface-containerHovered: #FAFCFA;
  --color-palette-surface-containerFocusedPressed: rgba(190,194,255,0.1);
  --color-palette-surface-containerActive: #BEC2FF1A;
  --color-palette-surface-containerActiveHovered: rgba(190,194,255,0.2);
  --color-palette-surface-containerActiveFocused: rgba(190,194,255,0.3);
  --color-palette-surface-containerMint: #B5E0CE;
  --color-palette-surface-containerMint30: rgba(181,224,206,0.3);
  --color-palette-surface-containerLilac: #BEC2FF;
  --color-palette-surface-containerInvert: #010507;
  --color-palette-surface-background: #DBDBE5;
  --color-palette-surface-progressBarEmpty: #0105071A;
  --color-palette-surface-progressBarFull: #189370;
  --color-palette-surface-surfaceActionFilledHoveredAndFocused: #2B2B2B;
  --color-palette-surface-surfaceActionFilledPressed: #57575B;
  --color-palette-surface-containerPressed: #BEC2FF4D;
  --color-palette-surface-containerEnabledSolidEquivalent: #F8F9FF;
  --color-palette-surface-containerPressedHoverSolidEquivalent: #F1F2FF;
  --color-palette-surface-containerActivePressedSolidEquivalent: #E5E7FD;
  --color-palette-surface-containerHoveredAndFocused: #F0F0F4;
  --color-palette-surface-actionGhostHoveredAndFocused: #0105070D;
  
  --color-palette-text-primary: #010507;
  --color-palette-text-secondary: #57575B;
  --color-palette-text-disabled: #838389;
  --color-palette-text-invert: #FFFFFF;
  --color-palette-text-details: #189370;
  --color-palette-text-title: #3C464A;
  --color-palette-text-progressBar: #525252;
  --color-palette-text-link: #0D2E41;
  
  --color-palette-icon-default: #010507;
  --color-palette-icon-disabled: #838389;
  --color-palette-icon-invert: #FFFFFF;
  
  --color-palette-border-default: #FFFFFF;
  --color-palette-border-container: #DBDBE5;
  --color-palette-border-actionEnabled: #BEC2FF;
  --color-palette-border-divider: #DBDBE5;
  
  --color-palette-gradient-primary: linear-gradient(90deg, #85E0CE 0%, #FFF388 100%);
  
  /* CopilotCloud Spacing */
  --spacing-spacing-1: 4px;
  --spacing-spacing-2: 8px;
  --spacing-spacing-3: 12px;
  --spacing-spacing-4: 16px;
  --spacing-spacing-5: 20px;
  --spacing-spacing-6: 24px;
  --spacing-spacing-7: 28px;
  --spacing-spacing-8: 32px;
  --spacing-spacing-9: 36px;
  --spacing-spacing-10: 40px;
  --spacing-spacing-11: 44px;
  --spacing-spacing-12: 48px;
  --spacing-spacing-13: 52px;
  --spacing-spacing-14: 56px;
  --spacing-spacing-15: 60px;
  --spacing-spacing-16: 64px;
  --spacing-spacing-17: 68px;
  --spacing-spacing-18: 72px;
  
  /* CopilotCloud Border Radius */
  --radius-xs: 4px;
  --radius-sm: 8px;
  --radius-md: 12px;
  --radius-lg: 16px;
  --radius-xl: 24px;
  --radius-2xl: 48px;
  --radius-3xl: 200px;
  
  /* Font Families */
  --font-family-sans: 'Plus Jakarta Sans', ui-sans-serif, system-ui, sans-serif;
  --font-family-mono: 'Spline Sans Mono', ui-monospace, SFMono-Regular, monospace;
  
  /* Elevation/Shadows */
  --shadow-sm: 0px 1px 3px 0px rgba(1, 5, 7, 0.08);
  --shadow-md: 0px 6px 6px -2px rgba(1, 5, 7, 0.08);
  --shadow-lg: 0px 16px 24px -8px rgba(1, 5, 7, 0.12);
  --shadow-xl: 0px 24px 32px -12px rgba(1, 5, 7, 0.16);
}

:root {
  --background: oklch(1 0 0);
  --foreground: oklch(0.145 0 0);
  --card: oklch(1 0 0);
  --card-foreground: oklch(0.145 0 0);
  --popover: oklch(1 0 0);
  --popover-foreground: oklch(0.145 0 0);
  --primary: oklch(0.205 0 0);
  --primary-foreground: oklch(0.985 0 0);
  --secondary: oklch(0.97 0 0);
  --secondary-foreground: oklch(0.205 0 0);
  --muted: oklch(0.97 0 0);
  --muted-foreground: oklch(0.556 0 0);
  --accent: oklch(0.97 0 0);
  --accent-foreground: oklch(0.205 0 0);
  --destructive: oklch(0.577 0.245 27.325);
  --destructive-foreground: oklch(0.577 0.245 27.325);
  --border: oklch(0.922 0 0);
  --input: oklch(0.922 0 0);
  --ring: oklch(0.708 0 0);
  --chart-1: oklch(0.646 0.222 41.116);
  --chart-2: oklch(0.6 0.118 184.704);
  --chart-3: oklch(0.398 0.07 227.392);
  --chart-4: oklch(0.828 0.189 84.429);
  --chart-5: oklch(0.769 0.188 70.08);
  --radius: 0.5rem;
  --sidebar: oklch(0.985 0 0);
  --sidebar-foreground: oklch(0.145 0 0);
  --sidebar-primary: oklch(0.205 0 0);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.97 0 0);
  --sidebar-accent-foreground: oklch(0.205 0 0);
  --sidebar-border: oklch(0.922 0 0);
  --sidebar-ring: oklch(0.708 0 0);
  
  /* Provider Colors */
  --openai: hsl(160 70% 50%); /* Bright green */
  --anthropic: hsl(240 80% 60%); /* Bright blue */
  --cohere: hsl(0 80% 60%); /* Bright red */
  
}

.dark {
  --background: hsl(222.2 84% 4.9%);
  --foreground: hsl(210 40% 98%);
  
  --card: hsl(222.2 84% 4.9%);
  --card-foreground: hsl(210 40% 98%);
  
  --popover: hsl(222.2 84% 4.9%);
  --popover-foreground: hsl(210 40% 98%);
  
  --primary: hsl(210 40% 98%);
  --primary-foreground: hsl(222.2 47.4% 11.2%);
  
  --secondary: hsl(217.2 32.6% 17.5%);
  --secondary-foreground: hsl(210 40% 98%);
  
  --muted: hsl(217.2 32.6% 17.5%);
  --muted-foreground: hsl(215 20.2% 65.1%);
  
  --accent: hsl(217.2 32.6% 17.5%);
  --accent-foreground: hsl(210 40% 98%);
  
  --destructive: hsl(0 62.8% 50.6%);
  --destructive-foreground: hsl(210 40% 98%);
  
  --border: hsl(217.2 32.6% 17.5%);
  --input: hsl(217.2 32.6% 17.5%);
  --ring: hsl(212.7 26.8% 83.9%);
  
  --sidebar: hsl(222.2 84% 4.9%);
  --sidebar-foreground: hsl(210 40% 98%);
  --sidebar-primary: hsl(210 40% 98%);
  --sidebar-primary-foreground: hsl(222.2 47.4% 11.2%);
  --sidebar-accent: hsl(217.2 32.6% 17.5%);
  --sidebar-accent-foreground: hsl(210 40% 98%);
  --sidebar-border: hsl(217.2 32.6% 17.5%);
  --sidebar-ring: hsl(212.7 26.8% 83.9%);
  
  --chart-1: hsl(240 80% 60%);
  --chart-2: hsl(160 70% 50%);
  --chart-3: hsl(0 80% 60%);
  --chart-4: hsl(280 70% 60%);
  --chart-5: hsl(30 80% 60%);
}

@layer base {
  * {
    @apply border-border outline-ring/50;
  }
  body {
    @apply bg-background text-foreground font-sans;
  }
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/layout.tsx
================================================
import { Suspense } from "react";
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";
import "@copilotkit/react-ui/styles.css";
import { ThemeProvider } from "@/components/theme-provider";
import { MainLayout } from "@/components/layout/main-layout";
import { URLParamsProvider } from "@/contexts/url-params-context";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Demo Viewer by CopilotKit",
  description: "Demo Viewer by CopilotKit",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en" suppressHydrationWarning>
      <body className={`${geistSans.variable} ${geistMono.variable} antialiased`}>
        <ThemeProvider
          attribute="class"
          defaultTheme="light"
          enableSystem={false}
          themes={['light']}
          disableTransitionOnChange
        >
          <Suspense>
            <URLParamsProvider>
              <MainLayout>{children}</MainLayout>
            </URLParamsProvider>
          </Suspense>
        </ThemeProvider>
      </body>
    </html>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/page.tsx
================================================
"use client";

import React from "react";

export default function Home() {
  return (
    <div className="flex-1 h-screen w-full flex flex-col items-center justify-center p-8">
      <h1 className="text-base font-normal text-muted-foreground mb-4">
        Select an integration to get started
      </h1>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/not-found.tsx
================================================
import React from "react";
import Link from "next/link";

export default function NotFound() {
  return (
    <div className="flex-1 h-screen w-full flex flex-col items-center justify-center p-8">
      <h1 className="text-4xl font-bold text-center mb-4">Integration Not Found</h1>
      <p className="text-muted-foreground mb-6 text-center">
        The integration you&apos;re looking for doesn&apos;t exist.
      </p>
      <Link
        href="/"
        className="px-4 py-2 bg-primary text-primary-foreground rounded-md hover:bg-primary/90 transition-colors"
      >
        Back to Home
      </Link>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/page.tsx
================================================
import React from "react";
import { menuIntegrations } from "@/menu";
import { notFound } from "next/navigation";
import Readme from "@/components/readme/readme";
import path from "path";
import fs from "fs";

export async function generateStaticParams() {
  return menuIntegrations.map((integration) => ({
    integrationId: integration.id,
  }));
}

interface IntegrationPageProps {
  params: Promise<{
    integrationId: string;
  }>;
}

export default function IntegrationPage({ params }: IntegrationPageProps) {
  const { integrationId } = React.use(params);

  // Find the integration by ID
  const integration = menuIntegrations.find((integration) => integration.id === integrationId);

  const readmePath = path.join(
    process.cwd(),
    "..",
    "..",
    "integrations",
    integrationId,
    "README.md",
  );

  let md: string | undefined = undefined;

  if (fs.existsSync(readmePath)) {
    md = fs.readFileSync(readmePath, "utf8");
  }

  // If integration not found, show 404
  if (!integration) {
    notFound();
  }

  if (!md) {
    return (
      <div className="flex-1 h-screen w-full flex flex-col items-center justify-start pt-16 px-8">
        <div className="w-full max-w-4xl">
          <h1 className="text-4xl font-bold text-center">{integration.name}</h1>
          <p className="text-muted-foreground mt-4 text-center">Integration ID: {integration.id}</p>
        </div>
      </div>
    );
  } else {
    return <Readme content={md} />;
  }
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/layout.tsx
================================================
'use client';

import React, { useMemo } from "react";
import { usePathname } from "next/navigation";
import filesJSON from '../../../files.json'
import Readme from "@/components/readme/readme";
import CodeViewer from "@/components/code-viewer/code-viewer";
import { useURLParams } from "@/contexts/url-params-context";

type FileItem = {
  name: string;
  content: string;
  language: string;
  type: string;
};

type FilesJsonType = Record<string, FileItem[]>;

interface Props {
  params: Promise<{
    integrationId: string;
  }>;
  children: React.ReactNode
}

export default function FeatureLayout({ children, params }: Props) {
  const { integrationId } = React.use(params);
  const pathname = usePathname();
  const { view } = useURLParams();

  // Extract featureId from pathname: /[integrationId]/feature/[featureId]
  const pathParts = pathname.split('/');
  const featureId = pathParts[pathParts.length - 1]; // Last segment is the featureId

  const files = (filesJSON as FilesJsonType)[`${integrationId}::${featureId}`] || [];

  const readme = files.find((file) => file?.name?.includes(".mdx")) || null;
  const codeFiles = files.filter(
    (file) => file && Object.keys(file).length > 0 && !file.name?.includes(".mdx"),
  );


  const content = useMemo(() => {
    switch (view) {
      case "code":
        return (
          <CodeViewer codeFiles={codeFiles} />
        )
      case "readme":
        return (
          <Readme content={readme?.content ?? ''} />
        )
      default:
        return (
          <div className="h-full">{children}</div>
        )
    }
  }, [children, codeFiles, readme, view])

  return (
    <div className="bg-white rounded-lg w-full h-full overflow-hidden">
      <div className="flex flex-col h-full overflow-auto">
        {content}
      </div>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat/README.mdx
================================================
# 🤖 Agentic Chat with Frontend Tools

## What This Demo Shows

This demo showcases CopilotKit's **agentic chat** capabilities with **frontend
tool integration**:

1. **Natural Conversation**: Chat with your Copilot in a familiar chat interface
2. **Frontend Tool Execution**: The Copilot can directly interacts with your UI
   by calling frontend functions
3. **Seamless Integration**: Tools defined in the frontend and automatically
   discovered and made available to the agent

## How to Interact

Try asking your Copilot to:

- "Can you change the background color to something more vibrant?"
- "Make the background a blue to purple gradient"
- "Set the background to a sunset-themed gradient"
- "Change it back to a simple light color"

You can also chat about other topics - the agent will respond conversationally
while having the ability to use your UI tools when appropriate.

## ✨ Frontend Tool Integration in Action

**What's happening technically:**

- The React component defines a frontend function using `useCopilotAction`
- CopilotKit automatically exposes this function to the agent
- When you make a request, the agent determines whether to use the tool
- The agent calls the function with the appropriate parameters
- The UI immediately updates in response

**What you'll see in this demo:**

- The Copilot understands requests to change the background
- It generates CSS values for colors and gradients
- When it calls the tool, the background changes instantly
- The agent provides a conversational response about the changes it made

This technique of exposing frontend functions to your Copilot can be extended to
any UI manipulation you want to enable, from theme changes to data filtering,
navigation, or complex UI state management!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat/page.tsx
================================================
"use client";
import React, { useState } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgent, useCopilotAction, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";

interface AgenticChatProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const AgenticChat: React.FC<AgenticChatProps> = ({ params }) => {
  const { integrationId } = React.use(params);

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="agentic_chat"
    >
      <Chat />
    </CopilotKit>
  );
};

const Chat = () => {
  const [background, setBackground] = useState<string>("--copilot-kit-background-color");

  useCopilotAction({
    name: "change_background",
    description:
      "Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.",
    parameters: [
      {
        name: "background",
        type: "string",
        description: "The background. Prefer gradients.",
      },
    ],
    handler: ({ background }) => {
      setBackground(background);
      return {
        status: "success",
        message: `Background changed to ${background}`,
      };
    },
  });

  return (
    <div className="flex justify-center items-center h-full w-full" data-testid="background-container" style={{ background }}>
      <div className="h-full w-full md:w-8/10 md:h-8/10 rounded-lg">
        <CopilotChat
          className="h-full rounded-2xl"
          labels={{ initial: "Hi, I'm an agent. Want to chat?" }}
        />
      </div>
    </div>
  );
};

export default AgenticChat;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}
  
.copilotKitChat {
  background-color: #fff !important;
}
  


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat_reasoning/README.mdx
================================================
# 🤖 Agentic Chat with Reasoning

## What This Demo Shows

This demo showcases CopilotKit's **agentic chat** capabilities with **frontend
tool integration**:

1. **Natural Conversation**: Chat with your Copilot in a familiar chat interface
2. **Frontend Tool Execution**: The Copilot can directly interacts with your UI
   by calling frontend functions
3. **Seamless Integration**: Tools defined in the frontend and automatically
   discovered and made available to the agent

## How to Interact

Try asking your Copilot to:

- "Can you change the background color to something more vibrant?"
- "Make the background a blue to purple gradient"
- "Set the background to a sunset-themed gradient"
- "Change it back to a simple light color"

You can also chat about other topics - the agent will respond conversationally
while having the ability to use your UI tools when appropriate.

## ✨ Frontend Tool Integration in Action

**What's happening technically:**

- The React component defines a frontend function using `useCopilotAction`
- CopilotKit automatically exposes this function to the agent
- When you make a request, the agent determines whether to use the tool
- The agent calls the function with the appropriate parameters
- The UI immediately updates in response

**What you'll see in this demo:**

- The Copilot understands requests to change the background
- It generates CSS values for colors and gradients
- When it calls the tool, the background changes instantly
- The agent provides a conversational response about the changes it made

This technique of exposing frontend functions to your Copilot can be extended to
any UI manipulation you want to enable, from theme changes to data filtering,
navigation, or complex UI state management!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat_reasoning/page.tsx
================================================
"use client";
import React, { useState } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgent, useCopilotAction, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import { ChevronDown } from "lucide-react";
import { Button } from "@/components/ui/button";
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from "@/components/ui/dropdown-menu";

interface AgenticChatProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const AgenticChat: React.FC<AgenticChatProps> = ({ params }) => {
  const { integrationId } = React.use(params);

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="agentic_chat_reasoning"
    >
      <Chat />
    </CopilotKit>
  );
};

interface AgentState {
  model: string;
}

const Chat = () => {
  const [background, setBackground] = useState<string>("--copilot-kit-background-color");
  const { state: agentState, setState: setAgentState } = useCoAgent<AgentState>({
    name: "agentic_chat_reasoning",
    initialState: {
      model: "OpenAI",
    },
  });

  // Initialize model if not set
  const selectedModel = agentState?.model || "OpenAI";

  const handleModelChange = (model: string) => {
    setAgentState({ model });
  };

  useCopilotAction({
    name: "change_background",
    description:
      "Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.",
    parameters: [
      {
        name: "background",
        type: "string",
        description: "The background. Prefer gradients.",
      },
    ],
    handler: ({ background }) => {
      setBackground(background);
    },
  });

  return (
    <div className="flex flex-col h-full w-full" style={{ background }}>
      {/* Reasoning Model Dropdown */}
      <div className="h-[65px] border-b border-gray-200 dark:border-gray-700">
        <div className="h-full flex items-center justify-center">
          <div className="flex items-center gap-2">
            <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
              Reasoning Model:
            </span>
            <DropdownMenu>
              <DropdownMenuTrigger asChild>
                <Button variant="outline" className="w-[140px] justify-between">
                  {selectedModel}
                  <ChevronDown className="h-4 w-4 opacity-50" />
                </Button>
              </DropdownMenuTrigger>
              <DropdownMenuContent className="w-[140px]">
                <DropdownMenuLabel>Select Model</DropdownMenuLabel>
                <DropdownMenuSeparator />
                <DropdownMenuItem onClick={() => handleModelChange("OpenAI")}>
                  OpenAI
                </DropdownMenuItem>
                <DropdownMenuItem onClick={() => handleModelChange("Anthropic")}>
                  Anthropic
                </DropdownMenuItem>
                <DropdownMenuItem onClick={() => handleModelChange("Gemini")}>
                  Gemini
                </DropdownMenuItem>
              </DropdownMenuContent>
            </DropdownMenu>
          </div>
        </div>
      </div>

      {/* Chat Container */}
      <div className="flex-1 flex justify-center items-center p-4">
        <div className="w-8/10 h-full rounded-lg">
          <CopilotChat
            className="h-full rounded-2xl"
            labels={{ initial: "Hi, I'm an agent. Want to chat?" }}
          />
        </div>
      </div>
    </div>
  );
};

export default AgenticChat;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_chat_reasoning/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}
  
.copilotKitChat {
  background-color: #fff !important;
}
  


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_generative_ui/README.mdx
================================================
# 🚀 Agentic Generative UI Task Executor

## What This Demo Shows

This demo showcases CopilotKit's **agentic generative UI** capabilities:

1. **Real-time Status Updates**: The Copilot provides live feedback as it works
   through complex tasks
2. **Long-running Task Execution**: See how agents can handle extended processes
   with continuous feedback
3. **Dynamic UI Generation**: The interface updates in real-time to reflect the
   agent's progress

## How to Interact

Simply ask your Copilot to perform any moderately complex task:

- "Make me a sandwich"
- "Plan a vacation to Japan"
- "Create a weekly workout routine"

The Copilot will break down the task into steps and begin "executing" them,
providing real-time status updates as it progresses.

## ✨ Agentic Generative UI in Action

**What's happening technically:**

- The agent analyzes your request and creates a detailed execution plan
- Each step is processed sequentially with realistic timing
- Status updates are streamed to the frontend using CopilotKit's streaming
  capabilities
- The UI dynamically renders these updates without page refreshes
- The entire flow is managed by the agent, requiring no manual intervention

**What you'll see in this demo:**

- The Copilot breaks your task into logical steps
- A status indicator shows the current progress
- Each step is highlighted as it's being executed
- Detailed status messages explain what's happening at each moment
- Upon completion, you receive a summary of the task execution

This pattern of providing real-time progress for long-running tasks is perfect
for scenarios where users benefit from transparency into complex processes -
from data analysis to content creation, system configurations, or multi-stage
workflows!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_generative_ui/page.tsx
================================================
"use client";
import React from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgentStateRender } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import { useTheme } from "next-themes";

interface AgenticGenerativeUIProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const AgenticGenerativeUI: React.FC<AgenticGenerativeUIProps> = ({ params }) => {
  const { integrationId } = React.use(params);
  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="agentic_generative_ui"
    >
      <Chat />
    </CopilotKit>
  );
};

interface AgentState {
  steps: {
    description: string;
    status: "pending" | "completed";
  }[];
}

const Chat = () => {
  const { theme } = useTheme();
  useCoAgentStateRender<AgentState>({
    name: "agentic_generative_ui",
    render: ({ state }) => {
      if (!state.steps || state.steps.length === 0) {
        return null;
      }

      const completedCount = state.steps.filter(step => step.status === "completed").length;
      const progressPercentage = (completedCount / state.steps.length) * 100;

      return (
        <div className="flex">
          <div 
          data-testid="task-progress"
          className={`relative rounded-xl w-[700px] p-6 shadow-lg backdrop-blur-sm ${
            theme === "dark" 
              ? "bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 text-white border border-slate-700/50 shadow-2xl"
              : "bg-gradient-to-br from-white via-gray-50 to-white text-gray-800 border border-gray-200/80"
          }`}>
            {/* Header */}
            <div className="mb-5">
              <div className="flex items-center justify-between mb-3">
                <h3 className="text-xl font-bold bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
                  Task Progress
                </h3>
                <div className={`text-sm ${theme === "dark" ? "text-slate-400" : "text-gray-500"}`}>
                  {completedCount}/{state.steps.length} Complete
                </div>
              </div>
              
              {/* Progress Bar */}
              <div className={`relative h-2 rounded-full overflow-hidden ${theme === "dark" ? "bg-slate-700" : "bg-gray-200"}`}>
                <div 
                  className="absolute top-0 left-0 h-full bg-gradient-to-r from-blue-500 to-purple-500 rounded-full transition-all duration-1000 ease-out"
                  style={{ width: `${progressPercentage}%` }}
                />
                <div className={`absolute top-0 left-0 h-full w-full bg-gradient-to-r from-transparent to-transparent animate-pulse ${
                  theme === "dark" ? "via-white/20" : "via-white/40"
                }`} />
              </div>
            </div>

            {/* Steps */}
            <div className="space-y-2">
              {state.steps.map((step, index) => {
                const isCompleted = step.status === "completed";
                const isCurrentPending = step.status === "pending" && 
                  index === state.steps.findIndex((s) => s.status === "pending");
                const isFuturePending = step.status === "pending" && !isCurrentPending;

                return (
                  <div 
                    key={index} 
                    className={`relative flex items-center p-2.5 rounded-lg transition-all duration-500 ${
                      isCompleted 
                        ? theme === "dark" 
                          ? "bg-gradient-to-r from-green-900/30 to-emerald-900/20 border border-green-500/30"
                          : "bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200/60"
                        : isCurrentPending
                        ? theme === "dark"
                          ? "bg-gradient-to-r from-blue-900/40 to-purple-900/30 border border-blue-500/50 shadow-lg shadow-blue-500/20"
                          : "bg-gradient-to-r from-blue-50 to-purple-50 border border-blue-200/60 shadow-md shadow-blue-200/50"
                        : theme === "dark"
                          ? "bg-slate-800/50 border border-slate-600/30"
                          : "bg-gray-50/50 border border-gray-200/60"
                    }`}
                  >
                    {/* Connector Line */}
                    {index < state.steps.length - 1 && (
                      <div className={`absolute left-5 top-full w-0.5 h-2 bg-gradient-to-b ${
                        theme === "dark" ? "from-slate-500 to-slate-600" : "from-gray-300 to-gray-400"
                      }`} />
                    )}

                    {/* Status Icon */}
                    <div className={`flex-shrink-0 w-6 h-6 rounded-full flex items-center justify-center mr-2 ${
                      isCompleted 
                        ? theme === "dark"
                          ? "bg-gradient-to-br from-green-500 to-emerald-600 shadow-lg shadow-green-500/30"
                          : "bg-gradient-to-br from-green-500 to-emerald-600 shadow-md shadow-green-200"
                        : isCurrentPending
                        ? theme === "dark"
                          ? "bg-gradient-to-br from-blue-500 to-purple-600 shadow-lg shadow-blue-500/30"
                          : "bg-gradient-to-br from-blue-500 to-purple-600 shadow-md shadow-blue-200"
                        : theme === "dark"
                          ? "bg-slate-700 border border-slate-600"
                          : "bg-gray-300 border border-gray-400"
                    }`}>
                      {isCompleted ? (
                        <CheckIcon />
                      ) : isCurrentPending ? (
                        <SpinnerIcon />
                      ) : (
                        <ClockIcon theme={theme} />
                      )}
                    </div>

                    {/* Step Content */}
                    <div className="flex-1 min-w-0">
                      <div 
                      data-testid="task-step-text"
                      className={`font-semibold transition-all duration-300 text-sm ${
                        isCompleted 
                          ? theme === "dark" ? "text-green-300" : "text-green-700"
                          : isCurrentPending
                          ? theme === "dark" ? "text-blue-300 text-base" : "text-blue-700 text-base"
                          : theme === "dark" ? "text-slate-400" : "text-gray-500"
                      }`}>
                        {step.description}
                      </div>
                      {isCurrentPending && (
                        <div className={`text-sm mt-1 animate-pulse ${
                          theme === "dark" ? "text-blue-400" : "text-blue-600"
                        }`}>
                          Processing...
                        </div>
                      )}
                    </div>

                    {/* Animated Background for Current Step */}
                    {isCurrentPending && (
                      <div className={`absolute inset-0 rounded-lg bg-gradient-to-r animate-pulse ${
                        theme === "dark" 
                          ? "from-blue-500/10 to-purple-500/10" 
                          : "from-blue-100/50 to-purple-100/50"
                      }`} />
                    )}
                  </div>
                );
              })}
            </div>

            {/* Decorative Elements */}
            <div className={`absolute top-3 right-3 w-16 h-16 rounded-full blur-xl ${
              theme === "dark" 
                ? "bg-gradient-to-br from-blue-500/10 to-purple-500/10" 
                : "bg-gradient-to-br from-blue-200/30 to-purple-200/30"
            }`} />
            <div className={`absolute bottom-3 left-3 w-12 h-12 rounded-full blur-xl ${
              theme === "dark" 
                ? "bg-gradient-to-br from-green-500/10 to-emerald-500/10" 
                : "bg-gradient-to-br from-green-200/30 to-emerald-200/30"
            }`} />
          </div>
        </div>
      );
    },
  });

  return (
    <div className="flex justify-center items-center h-full w-full">
      <div className="h-full w-full md:w-8/10 md:h-8/10 rounded-lg">
        <CopilotChat
          className="h-full rounded-2xl"
          labels={{
            initial:
              "Hi, I'm an agent! I can help you with anything you need and will show you progress as I work. What can I do for you?",
          }}
        />
      </div>
    </div>
  );
};

// Enhanced Icons
function CheckIcon() {
  return (
    <svg className="w-4 h-4 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={3} d="M5 13l4 4L19 7" />
    </svg>
  );
}

function SpinnerIcon() {
  return (
    <svg
      className="w-4 h-4 animate-spin text-white"
      xmlns="http://www.w3.org/2000/svg"
      fill="none"
      viewBox="0 0 24 24"
    >
      <circle
        className="opacity-25"
        cx="12"
        cy="12"
        r="10"
        stroke="currentColor"
        strokeWidth="4"
      />
      <path
        className="opacity-75"
        fill="currentColor"
        d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
      />
    </svg>
  );
}

function ClockIcon({ theme }: { theme?: string }) {
  return (
    <svg className={`w-3 h-3 ${theme === "dark" ? "text-slate-400" : "text-gray-600"}`} fill="none" stroke="currentColor" viewBox="0 0 24 24">
      <circle cx="12" cy="12" r="10" strokeWidth="2"/>
      <polyline points="12,6 12,12 16,14" strokeWidth="2"/>
    </svg>
  );
}

export default AgenticGenerativeUI;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/agentic_generative_ui/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}

.copilotKitChat {
  background-color: #fff !important;
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/human_in_the_loop/README.mdx
================================================
# 🤝 Human-in-the-Loop Task Planner

## What This Demo Shows

This demo showcases CopilotKit's **human-in-the-loop** capabilities:

1. **Collaborative Planning**: The Copilot generates task steps and lets you
   decide which ones to perform
2. **Interactive Decision Making**: Select or deselect steps to customize the
   execution plan
3. **Adaptive Responses**: The Copilot adapts its execution based on your
   choices, even handling missing steps

## How to Interact

Try these steps to experience the demo:

1. Ask your Copilot to help with a task, such as:

   - "Make me a sandwich"
   - "Plan a weekend trip"
   - "Organize a birthday party"
   - "Start a garden"

2. Review the suggested steps provided by your Copilot

3. Select or deselect steps using the checkboxes to customize the plan

   - Try removing essential steps to see how the Copilot adapts!

4. Click "Execute Plan" to see the outcome based on your selections

## ✨ Human-in-the-Loop Magic in Action

**What's happening technically:**

- The agent analyzes your request and breaks it down into logical steps
- These steps are presented to you through a dynamic UI component
- Your selections are captured as user input
- The agent considers your choices when executing the plan
- The agent adapts to missing steps with creative problem-solving

**What you'll see in this demo:**

- The Copilot provides a detailed, step-by-step plan for your task
- You have complete control over which steps to include
- If you remove essential steps, the Copilot provides entertaining and creative
  workarounds
- The final execution reflects your choices, showing how human input shapes the
  outcome
- Each response is tailored to your specific selections

This human-in-the-loop pattern creates a powerful collaborative experience where
both human judgment and AI capabilities work together to achieve better results
than either could alone!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/human_in_the_loop/page.tsx
================================================
"use client";
import React, { useState, useEffect } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCopilotAction, useLangGraphInterrupt } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";
import { useTheme } from "next-themes";

interface HumanInTheLoopProps {
  params: Promise<{
    integrationId: string;
  }>;
}

const HumanInTheLoop: React.FC<HumanInTheLoopProps> = ({ params }) => {
  const { integrationId } = React.use(params);

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="human_in_the_loop"
    >
      <Chat integrationId={integrationId} />
    </CopilotKit>
  );
};

interface Step {
  description: string;
  status: "disabled" | "enabled" | "executing";
}

// Shared UI Components
const StepContainer = ({ theme, children }: { theme?: string; children: React.ReactNode }) => (
  <div 
  data-testid="select-steps"
  className="flex">
    <div className={`relative rounded-xl w-[600px] p-6 shadow-lg backdrop-blur-sm ${
      theme === "dark" 
        ? "bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900 text-white border border-slate-700/50 shadow-2xl"
        : "bg-gradient-to-br from-white via-gray-50 to-white text-gray-800 border border-gray-200/80"
    }`}>
      {children}
    </div>
  </div>
);

const StepHeader = ({ 
  theme, 
  enabledCount, 
  totalCount, 
  status, 
  showStatus = false 
}: { 
  theme?: string; 
  enabledCount: number; 
  totalCount: number; 
  status?: string;
  showStatus?: boolean;
}) => (
  <div className="mb-5">
    <div className="flex items-center justify-between mb-3">
      <h2 className="text-xl font-bold bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
        Select Steps
      </h2>
      <div className="flex items-center gap-3">
        <div className={`text-sm ${theme === "dark" ? "text-slate-400" : "text-gray-500"}`}>
          {enabledCount}/{totalCount} Selected
        </div>
        {showStatus && (
          <div className={`text-xs px-2 py-1 rounded-full font-medium ${
            status === "executing" 
              ? theme === "dark" 
                ? "bg-blue-900/30 text-blue-300 border border-blue-500/30"
                : "bg-blue-50 text-blue-600 border border-blue-200"
              : theme === "dark"
                ? "bg-slate-700 text-slate-300"
                : "bg-gray-100 text-gray-600"
          }`}>
            {status === "executing" ? "Ready" : "Waiting"}
          </div>
        )}
      </div>
    </div>
    
    <div className={`relative h-2 rounded-full overflow-hidden ${theme === "dark" ? "bg-slate-700" : "bg-gray-200"}`}>
      <div 
        className="absolute top-0 left-0 h-full bg-gradient-to-r from-blue-500 to-purple-500 rounded-full transition-all duration-500 ease-out"
        style={{ width: `${totalCount > 0 ? (enabledCount / totalCount) * 100 : 0}%` }}
      />
    </div>
  </div>
);

const StepItem = ({ 
  step, 
  theme, 
  status, 
  onToggle, 
  disabled = false 
}: { 
  step: { description: string; status: string }; 
  theme?: string; 
  status?: string;
  onToggle: () => void;
  disabled?: boolean;
}) => (
  <div className={`flex items-center p-3 rounded-lg transition-all duration-300 ${
    step.status === "enabled"
      ? theme === "dark" 
        ? "bg-gradient-to-r from-blue-900/20 to-purple-900/10 border border-blue-500/30"
        : "bg-gradient-to-r from-blue-50 to-purple-50 border border-blue-200/60"
      : theme === "dark"
        ? "bg-slate-800/30 border border-slate-600/30"
        : "bg-gray-50/50 border border-gray-200/40"
  }`}>
    <label 
    data-testid="step-item" 
    className="flex items-center cursor-pointer w-full">
      <div className="relative">
        <input
          type="checkbox"
          checked={step.status === "enabled"}
          onChange={onToggle}
          className="sr-only"
          disabled={disabled}
        />
        <div className={`w-5 h-5 rounded border-2 flex items-center justify-center transition-all duration-200 ${
          step.status === "enabled"
            ? "bg-gradient-to-br from-blue-500 to-purple-600 border-blue-500"
            : theme === "dark"
              ? "border-slate-400 bg-slate-700"
              : "border-gray-300 bg-white"
        } ${disabled ? "opacity-60" : ""}`}>
          {step.status === "enabled" && (
            <svg className="w-3 h-3 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={3} d="M5 13l4 4L19 7" />
            </svg>
          )}
        </div>
      </div>
      <span 
       data-testid="step-text"
       className={`ml-3 font-medium transition-all duration-300 ${
        step.status !== "enabled" && status != "inProgress"
          ? `line-through ${theme === "dark" ? "text-slate-500" : "text-gray-400"}`
          : theme === "dark" ? "text-white" : "text-gray-800"
      } ${disabled ? "opacity-60" : ""}`}>
        {step.description}
      </span>
    </label>
  </div>
);

const ActionButton = ({ 
  variant, 
  theme, 
  disabled, 
  onClick, 
  children 
}: { 
  variant: "primary" | "secondary" | "success" | "danger";
  theme?: string;
  disabled?: boolean;
  onClick: () => void;
  children: React.ReactNode;
}) => {
  const baseClasses = "px-6 py-3 rounded-lg font-semibold transition-all duration-200";
  const enabledClasses = "hover:scale-105 shadow-md hover:shadow-lg";
  const disabledClasses = "opacity-50 cursor-not-allowed";
  
  const variantClasses = {
    primary: "bg-gradient-to-r from-purple-500 to-purple-700 hover:from-purple-600 hover:to-purple-800 text-white shadow-lg hover:shadow-xl",
    secondary: theme === "dark"
      ? "bg-slate-700 hover:bg-slate-600 text-white border border-slate-600 hover:border-slate-500"
      : "bg-gray-100 hover:bg-gray-200 text-gray-800 border border-gray-300 hover:border-gray-400",
    success: "bg-gradient-to-r from-green-500 to-emerald-600 hover:from-green-600 hover:to-emerald-700 text-white shadow-lg hover:shadow-xl",
    danger: "bg-gradient-to-r from-red-500 to-red-600 hover:from-red-600 hover:to-red-700 text-white shadow-lg hover:shadow-xl"
  };

  return (
    <button
      className={`${baseClasses} ${disabled ? disabledClasses : enabledClasses} ${
        disabled && variant === "secondary" ? "bg-gray-200 text-gray-500" : 
        disabled && variant === "success" ? "bg-gray-400" :
        variantClasses[variant]
      }`}
      disabled={disabled}
      onClick={onClick}
    >
      {children}
    </button>
  );
};

const DecorativeElements = ({ 
  theme, 
  variant = "default" 
}: { 
  theme?: string; 
  variant?: "default" | "success" | "danger" 
}) => (
  <>
    <div className={`absolute top-3 right-3 w-16 h-16 rounded-full blur-xl ${
      variant === "success"
        ? theme === "dark" 
          ? "bg-gradient-to-br from-green-500/10 to-emerald-500/10" 
          : "bg-gradient-to-br from-green-200/30 to-emerald-200/30"
        : variant === "danger"
          ? theme === "dark" 
            ? "bg-gradient-to-br from-red-500/10 to-pink-500/10" 
            : "bg-gradient-to-br from-red-200/30 to-pink-200/30"
          : theme === "dark" 
            ? "bg-gradient-to-br from-blue-500/10 to-purple-500/10" 
            : "bg-gradient-to-br from-blue-200/30 to-purple-200/30"
    }`} />
    <div className={`absolute bottom-3 left-3 w-12 h-12 rounded-full blur-xl ${
      variant === "default"
        ? theme === "dark" 
          ? "bg-gradient-to-br from-purple-500/10 to-pink-500/10" 
          : "bg-gradient-to-br from-purple-200/30 to-pink-200/30"
        : "opacity-50"
    }`} />
  </>
);
const InterruptHumanInTheLoop: React.FC<{
  event: { value: { steps: Step[] } };
  resolve: (value: string) => void;
}> = ({ event, resolve }) => {
  const { theme } = useTheme();
  
  // Parse and initialize steps data
  let initialSteps: Step[] = [];
  if (event.value && event.value.steps && Array.isArray(event.value.steps)) {
    initialSteps = event.value.steps.map((step: any) => ({
      description: typeof step === "string" ? step : step.description || "",
      status: typeof step === "object" && step.status ? step.status : "enabled",
    }));
  }

  const [localSteps, setLocalSteps] = useState<Step[]>(initialSteps);
  const enabledCount = localSteps.filter(step => step.status === "enabled").length;

  const handleStepToggle = (index: number) => {
    setLocalSteps((prevSteps) =>
      prevSteps.map((step, i) =>
        i === index
          ? { ...step, status: step.status === "enabled" ? "disabled" : "enabled" }
          : step,
      ),
    );
  };

  const handlePerformSteps = () => {
    const selectedSteps = localSteps
      .filter((step) => step.status === "enabled")
      .map((step) => step.description);
    resolve("The user selected the following steps: " + selectedSteps.join(", "));
  };

  return (
    <StepContainer theme={theme}>
      <StepHeader theme={theme} enabledCount={enabledCount} totalCount={localSteps.length} />
      
      <div className="space-y-3 mb-6">
        {localSteps.map((step, index) => (
          <StepItem
            key={index}
            step={step}
            theme={theme}
            onToggle={() => handleStepToggle(index)}
          />
        ))}
      </div>

      <div className="flex justify-center">
        <ActionButton
          variant="primary"
          theme={theme}
          onClick={handlePerformSteps}
        >
          <span className="text-lg">✨</span>
          Perform Steps
          <span className={`ml-1 px-2 py-1 rounded-full text-xs font-bold ${
            theme === "dark" ? "bg-purple-800/50" : "bg-purple-600/20"
          }`}>
            {enabledCount}
          </span>
        </ActionButton>
      </div>

      <DecorativeElements theme={theme} />
    </StepContainer>
  );
};

const Chat = ({ integrationId }: { integrationId: string }) => {
  // Langgraph uses it's own hook to handle human-in-the-loop interactions via langgraph interrupts,
  // This hook won't do anything for other integrations.
  useLangGraphInterrupt({
    render: ({ event, resolve }) => <InterruptHumanInTheLoop event={event} resolve={resolve} />,
  });
  useCopilotAction({
    name: "generate_task_steps",
    description: "Generates a list of steps for the user to perform",
    parameters: [
      {
        name: "steps",
        type: "object[]",
        attributes: [
          {
            name: "description",
            type: "string",
          },
          {
            name: "status",
            type: "string",
            enum: ["enabled", "disabled", "executing"],
          },
        ],
      },
    ],
    // Langgraph uses it's own hook to handle human-in-the-loop interactions via langgraph interrupts,
    // so don't use this action for langgraph integration.
    available: ['langgraph', 'langgraph-fastapi', 'langgraph-typescript'].includes(integrationId) ? 'disabled' : 'enabled',
    renderAndWaitForResponse: ({ args, respond, status }) => {
      return <StepsFeedback args={args} respond={respond} status={status} />;
    },
  });

  return (
    <div className="flex justify-center items-center h-full w-full">
      <div className="h-full w-full md:w-8/10 md:h-8/10 rounded-lg">
        <CopilotChat
          className="h-full rounded-2xl"
          labels={{
            initial:
              "Hi, I'm an agent specialized in helping you with your tasks. How can I help you?",
          }}
        />
      </div>
    </div>
  );
};

const StepsFeedback = ({ args, respond, status }: { args: any; respond: any; status: any }) => {
  const { theme } = useTheme();
  const [localSteps, setLocalSteps] = useState<Step[]>([]);
  const [accepted, setAccepted] = useState<boolean | null>(null);

  useEffect(() => {
    if (status === "executing" && localSteps.length === 0) {
      setLocalSteps(args.steps);
    }
  }, [status, args.steps, localSteps]);

  if (args.steps === undefined || args.steps.length === 0) {
    return <></>;
  }

  const steps = localSteps.length > 0 ? localSteps : args.steps;
  const enabledCount = steps.filter((step: any) => step.status === "enabled").length;

  const handleStepToggle = (index: number) => {
    setLocalSteps((prevSteps) =>
      prevSteps.map((step, i) =>
        i === index
          ? { ...step, status: step.status === "enabled" ? "disabled" : "enabled" }
          : step,
      ),
    );
  };

  const handleReject = () => {
    if (respond) {
      setAccepted(false);
      respond({ accepted: false });
    }
  };

  const handleConfirm = () => {
    if (respond) {
      setAccepted(true);
      respond({ accepted: true, steps: localSteps.filter(step => step.status === "enabled")});
    }
  };

  return (
    <StepContainer theme={theme}>
      <StepHeader 
        theme={theme} 
        enabledCount={enabledCount} 
        totalCount={steps.length} 
        status={status}
        showStatus={true}
      />
      
      <div className="space-y-3 mb-6">
        {steps.map((step: any, index: any) => (
          <StepItem
            key={index}
            step={step}
            theme={theme}
            status={status}
            onToggle={() => handleStepToggle(index)}
            disabled={status !== "executing"}
          />
        ))}
      </div>

      {/* Action Buttons - Different logic from InterruptHumanInTheLoop */}
      {accepted === null && (
        <div className="flex justify-center gap-4">
          <ActionButton
            variant="secondary"
            theme={theme}
            disabled={status !== "executing"}
            onClick={handleReject}
          >
            <span className="mr-2">✗</span>
            Reject
          </ActionButton>
          <ActionButton
            variant="success"
            theme={theme}
            disabled={status !== "executing"}
            onClick={handleConfirm}
          >
            <span className="mr-2">✓</span>
            Confirm
            <span className={`ml-2 px-2 py-1 rounded-full text-xs font-bold ${
              theme === "dark" ? "bg-green-800/50" : "bg-green-600/20"
            }`}>
              {enabledCount}
            </span>
          </ActionButton>
        </div>
      )}

      {/* Result State - Unique to StepsFeedback */}
      {accepted !== null && (
        <div className="flex justify-center">
          <div className={`px-6 py-3 rounded-lg font-semibold flex items-center gap-2 ${
            accepted 
              ? theme === "dark"
                ? "bg-green-900/30 text-green-300 border border-green-500/30"
                : "bg-green-50 text-green-700 border border-green-200"
              : theme === "dark"
                ? "bg-red-900/30 text-red-300 border border-red-500/30"
                : "bg-red-50 text-red-700 border border-red-200"
          }`}>
            <span className="text-lg">{accepted ? "✓" : "✗"}</span>
            {accepted ? "Accepted" : "Rejected"}
          </div>
        </div>
      )}

      <DecorativeElements theme={theme} variant={
        accepted === true ? "success" : accepted === false ? "danger" : "default"
      } />
    </StepContainer>
  );
};


export default HumanInTheLoop;



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/human_in_the_loop/style.css
================================================
.copilotKitInput {
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
  border-top-left-radius: 0.75rem;
  border-top-right-radius: 0.75rem;
  border: 1px solid var(--copilot-kit-separator-color) !important;
}

.copilotKitChat {
  background-color: #fff !important;
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/predictive_state_updates/README.mdx
================================================
# 📝 Predictive State Updates Document Editor

## What This Demo Shows

This demo showcases CopilotKit's **predictive state updates** for real-time
document collaboration:

1. **Live Document Editing**: Watch as your Copilot makes changes to a document
   in real-time
2. **Diff Visualization**: See exactly what's being changed as it happens
3. **Streaming Updates**: Changes are displayed character-by-character as the
   Copilot works

## How to Interact

Try these interactions with the collaborative document editor:

- "Fix the grammar and typos in this document"
- "Make this text more professional"
- "Add a section about [topic]"
- "Summarize this content in bullet points"
- "Change the tone to be more casual"

Watch as the Copilot processes your request and edits the document in real-time
right before your eyes.

## ✨ Predictive State Updates in Action

**What's happening technically:**

- The document state is shared between your UI and the Copilot
- As the Copilot generates content, changes are streamed to the UI
- Each modification is visualized with additions and deletions
- The UI renders these changes progressively, without waiting for completion
- All edits are tracked and displayed in a visually intuitive way

**What you'll see in this demo:**

- Text changes are highlighted in different colors (green for additions, red for
  deletions)
- The document updates character-by-character, creating a typing-like effect
- You can see the Copilot's thought process as it refines the content
- The final document seamlessly incorporates all changes
- The experience feels collaborative, as if someone is editing alongside you

This pattern of real-time collaborative editing with diff visualization is
perfect for document editors, code review tools, content creation platforms, or
any application where users benefit from seeing exactly how content is being
transformed!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/predictive_state_updates/page.tsx
================================================
"use client";
import "@copilotkit/react-ui/styles.css";
import "./style.css";

import MarkdownIt from "markdown-it";
import React from "react";

import { diffWords } from "diff";
import { useEditor, EditorContent } from "@tiptap/react";
import StarterKit from "@tiptap/starter-kit";
import { useEffect, useState } from "react";
import { CopilotKit, useCoAgent, useCopilotAction, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat, CopilotSidebar } from "@copilotkit/react-ui";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

const extensions = [StarterKit];

interface PredictiveStateUpdatesProps {
  params: Promise<{
    integrationId: string;
  }>;
}

export default function PredictiveStateUpdates({ params }: PredictiveStateUpdatesProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();
  const defaultChatHeight = 50
  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight)
  const chatTitle = 'AI Document Editor'
  const chatDescription = 'Ask me to create or edit a document'
  const initialLabel = 'Hi 👋 How can I help with your document?'

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="predictive_state_updates"
    >
      <div
        className="min-h-screen w-full"
        style={
          {
            // "--copilot-kit-primary-color": "#222",
            // "--copilot-kit-separator-color": "#CCC",
          } as React.CSSProperties
        }
      >
        {isMobile ? (
          <>
            {/* Chat Toggle Button */}
            <div className="fixed bottom-0 left-0 right-0 z-50">
              <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
              <div
                className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
                onClick={() => {
                  if (!isChatOpen) {
                    setChatHeight(defaultChatHeight); // Reset to good default when opening
                  }
                  setIsChatOpen(!isChatOpen);
                }}
              >
                <div className="flex items-center gap-3">
                  <div>
                    <div className="font-medium text-gray-900">{chatTitle}</div>
                    <div className="text-sm text-gray-500">{chatDescription}</div>
                  </div>
                </div>
                <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
                  <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                  </svg>
                </div>
              </div>
            </div>

            {/* Pull-Up Chat Container */}
            <div
              className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${
                isChatOpen ? 'translate-y-0' : 'translate-y-full'
              } ${isDragging ? 'transition-none' : ''}`}
              style={{
                height: `${chatHeight}vh`,
                paddingBottom: 'env(safe-area-inset-bottom)' // Handle iPhone bottom padding
              }}
            >
              {/* Drag Handle Bar */}
              <div
                className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
                onMouseDown={handleDragStart}
              >
                <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
              </div>

              {/* Chat Header */}
              <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
                  </div>
                  <button
                    onClick={() => setIsChatOpen(false)}
                    className="p-2 hover:bg-gray-100 rounded-full transition-colors"
                  >
                    <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  </button>
                </div>
              </div>

              {/* Chat Content - Flexible container for messages and input */}
              <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
                <CopilotChat
                  className="h-full flex flex-col"
                  labels={{
                    initial: initialLabel,
                  }}
                />
              </div>
            </div>

            {/* Backdrop */}
            {isChatOpen && (
              <div
                className="fixed inset-0 z-30"
                onClick={() => setIsChatOpen(false)}
              />
            )}
          </>
        ) : (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}
        <DocumentEditor />
      </div>
    </CopilotKit>
  );
}

interface AgentState {
  document: string;
}

const DocumentEditor = () => {
  const editor = useEditor({
    extensions,
    immediatelyRender: false,
    editorProps: {
      attributes: { class: "min-h-screen p-10" },
    },
  });
  const [placeholderVisible, setPlaceholderVisible] = useState(false);
  const [currentDocument, setCurrentDocument] = useState("");
  const { isLoading } = useCopilotChat();

  const {
    state: agentState,
    setState: setAgentState,
    nodeName,
  } = useCoAgent<AgentState>({
    name: "predictive_state_updates",
    initialState: {
      document: "",
    },
  });

  useEffect(() => {
    if (isLoading) {
      setCurrentDocument(editor?.getText() || "");
    }
    editor?.setEditable(!isLoading);
  }, [isLoading]);

  useEffect(() => {
    if (nodeName == "end") {
      // set the text one final time when loading is done
      if (currentDocument.trim().length > 0 && currentDocument !== agentState?.document) {
        const newDocument = agentState?.document || "";
        const diff = diffPartialText(currentDocument, newDocument, true);
        const markdown = fromMarkdown(diff);
        editor?.commands.setContent(markdown);
      }
    }
  }, [nodeName]);

  useEffect(() => {
    if (isLoading) {
      if (currentDocument.trim().length > 0) {
        const newDocument = agentState?.document || "";
        const diff = diffPartialText(currentDocument, newDocument);
        const markdown = fromMarkdown(diff);
        editor?.commands.setContent(markdown);
      } else {
        const markdown = fromMarkdown(agentState?.document || "");
        editor?.commands.setContent(markdown);
      }
    }
  }, [agentState?.document]);

  const text = editor?.getText() || "";

  useEffect(() => {
    setPlaceholderVisible(text.length === 0);

    if (!isLoading) {
      setCurrentDocument(text);
      setAgentState({
        document: text,
      });
    }
  }, [text]);

  // TODO(steve): Remove this when all agents have been updated to use write_document tool.
  useCopilotAction({
    name: "confirm_changes",
    renderAndWaitForResponse: ({ args, respond, status }) => (
      <ConfirmChanges
        args={args}
        respond={respond}
        status={status}
        onReject={() => {
          editor?.commands.setContent(fromMarkdown(currentDocument));
          setAgentState({ document: currentDocument });
        }}
        onConfirm={() => {
          editor?.commands.setContent(fromMarkdown(agentState?.document || ""));
          setCurrentDocument(agentState?.document || "");
          setAgentState({ document: agentState?.document || "" });
        }}
      />
    ),
  }, [agentState?.document]);

  // Action to write the document.
  useCopilotAction({
    name: "write_document",
    description: `Present the proposed changes to the user for review`,
    parameters: [
      {
        name: "document",
        type: "string",
        description: "The full updated document in markdown format",
      },
    ],
    renderAndWaitForResponse({ args, status, respond }) {
      if (status === "executing") {
        return (
          <ConfirmChanges
            args={args}
            respond={respond}
            status={status}
            onReject={() => {
              editor?.commands.setContent(fromMarkdown(currentDocument));
              setAgentState({ document: currentDocument });
            }}
            onConfirm={() => {
              editor?.commands.setContent(fromMarkdown(agentState?.document || ""));
              setCurrentDocument(agentState?.document || "");
              setAgentState({ document: agentState?.document || "" });
            }}
          />
        );
      }
      return <></>;
    },
  }, [agentState?.document]);

  return (
    <div className="relative min-h-screen w-full">
      {placeholderVisible && (
        <div className="absolute top-6 left-6 m-4 pointer-events-none text-gray-400">
          Write whatever you want here in Markdown format...
        </div>
      )}
      <EditorContent editor={editor} />
    </div>
  );
};

interface ConfirmChangesProps {
  args: any;
  respond: any;
  status: any;
  onReject: () => void;
  onConfirm: () => void;
}

function ConfirmChanges({ args, respond, status, onReject, onConfirm }: ConfirmChangesProps) {
  const [accepted, setAccepted] = useState<boolean | null>(null);
  return (
    <div 
    data-testid="confirm-changes-modal"
    className="bg-white p-6 rounded shadow-lg border border-gray-200 mt-5 mb-5">
      <h2 className="text-lg font-bold mb-4">Confirm Changes</h2>
      <p className="mb-6">Do you want to accept the changes?</p>
      {accepted === null && (
        <div className="flex justify-end space-x-4">
          <button
            data-testid="reject-button"
            className={`bg-gray-200 text-black py-2 px-4 rounded disabled:opacity-50 ${
              status === "executing" ? "cursor-pointer" : "cursor-default"
            }`}
            disabled={status !== "executing"}
            onClick={() => {
              if (respond) {
                setAccepted(false);
                onReject();
                respond({ accepted: false });
              }
            }}
          >
            Reject
          </button>
          <button
            data-testid="confirm-button"
            className={`bg-black text-white py-2 px-4 rounded disabled:opacity-50 ${
              status === "executing" ? "cursor-pointer" : "cursor-default"
            }`}
            disabled={status !== "executing"}
            onClick={() => {
              if (respond) {
                setAccepted(true);
                onConfirm();
                respond({ accepted: true });
              }
            }}
          >
            Confirm
          </button>
        </div>
      )}
      {accepted !== null && (
        <div className="flex justify-end">
          <div 
          data-testid="status-display"
          className="mt-4 bg-gray-200 text-black py-2 px-4 rounded inline-block">
            {accepted ? "✓ Accepted" : "✗ Rejected"}
          </div>
        </div>
      )}
    </div>
  );
}

function fromMarkdown(text: string) {
  const md = new MarkdownIt({
    typographer: true,
    html: true,
  });

  return md.render(text);
}

function diffPartialText(oldText: string, newText: string, isComplete: boolean = false) {
  let oldTextToCompare = oldText;
  if (oldText.length > newText.length && !isComplete) {
    // make oldText shorter
    oldTextToCompare = oldText.slice(0, newText.length);
  }

  const changes = diffWords(oldTextToCompare, newText);

  let result = "";
  changes.forEach((part) => {
    if (part.added) {
      result += `<em>${part.value}</em>`;
    } else if (part.removed) {
      result += `<s>${part.value}</s>`;
    } else {
      result += part.value;
    }
  });

  if (oldText.length > newText.length && !isComplete) {
    result += oldText.slice(newText.length);
  }

  return result;
}

function isAlpha(text: string) {
  return /[a-zA-Z\u00C0-\u017F]/.test(text.trim());
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/predictive_state_updates/style.css
================================================
/* Basic editor styles */
.tiptap-container {
  height: 100vh; /* Full viewport height */
  width: 100vw; /* Full viewport width */
  display: flex;
  flex-direction: column;
}

.tiptap {
  flex: 1; /* Take up remaining space */
  overflow: auto; /* Allow scrolling if content overflows */
}

.tiptap :first-child {
  margin-top: 0;
}

/* List styles */
.tiptap ul,
.tiptap ol {
  padding: 0 1rem;
  margin: 1.25rem 1rem 1.25rem 0.4rem;
}

.tiptap ul li p,
.tiptap ol li p {
  margin-top: 0.25em;
  margin-bottom: 0.25em;
}

/* Heading styles */
.tiptap h1,
.tiptap h2,
.tiptap h3,
.tiptap h4,
.tiptap h5,
.tiptap h6 {
  line-height: 1.1;
  margin-top: 2.5rem;
  text-wrap: pretty;
  font-weight: bold;
}

.tiptap h1,
.tiptap h2,
.tiptap h3,
.tiptap h4,
.tiptap h5,
.tiptap h6 {
  margin-top: 3.5rem;
  margin-bottom: 1.5rem;
}

.tiptap p {
  margin-bottom: 1rem;
}

.tiptap h1 {
  font-size: 1.4rem;
}

.tiptap h2 {
  font-size: 1.2rem;
}

.tiptap h3 {
  font-size: 1.1rem;
}

.tiptap h4,
.tiptap h5,
.tiptap h6 {
  font-size: 1rem;
}

/* Code and preformatted text styles */
.tiptap code {
  background-color: var(--purple-light);
  border-radius: 0.4rem;
  color: var(--black);
  font-size: 0.85rem;
  padding: 0.25em 0.3em;
}

.tiptap pre {
  background: var(--black);
  border-radius: 0.5rem;
  color: var(--white);
  font-family: "JetBrainsMono", monospace;
  margin: 1.5rem 0;
  padding: 0.75rem 1rem;
}

.tiptap pre code {
  background: none;
  color: inherit;
  font-size: 0.8rem;
  padding: 0;
}

.tiptap blockquote {
  border-left: 3px solid var(--gray-3);
  margin: 1.5rem 0;
  padding-left: 1rem;
}

.tiptap hr {
  border: none;
  border-top: 1px solid var(--gray-2);
  margin: 2rem 0;
}

.tiptap s {
  background-color: #f9818150;
  padding: 2px;
  font-weight: bold;
  color: rgba(0, 0, 0, 0.7);
}

.tiptap em {
  background-color: #b2f2bb;
  padding: 2px;
  font-weight: bold;
  font-style: normal;
}

.copilotKitWindow {
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}




================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/shared_state/README.mdx
================================================
# 🍳 Shared State Recipe Creator

## What This Demo Shows

This demo showcases CopilotKit's **shared state** functionality - a powerful
feature that enables bidirectional data flow between:

1. **Frontend → Agent**: UI controls update the agent's context in real-time
2. **Agent → Frontend**: The Copilot's recipe creations instantly update the UI
   components

It's like having a cooking buddy who not only listens to what you want but also
updates your recipe card as you chat - no refresh needed! ✨

## How to Interact

Mix and match any of these parameters (or none at all - it's up to you!):

- **Skill Level**: Beginner to expert 👨‍🍳
- **Cooking Time**: Quick meals or slow cooking ⏱️
- **Special Preferences**: Dietary needs, flavor profiles, health goals 🥗
- **Ingredients**: Items you want to include 🧅🥩🍄
- **Instructions**: Any specific steps

Then chat with your Copilot chef with prompts like:

- "I'm a beginner cook. Can you make me a quick dinner?"
- "I need something spicy with chicken that takes under 30 minutes!"

## ✨ Shared State Magic in Action

**What's happening technically:**

- The UI and Copilot agent share the same state object (**Agent State = UI
  State**)
- Changes from either side automatically update the other
- Neither side needs to manually request updates from the other

**What you'll see in this demo:**

- Set cooking time to 20 minutes in the UI and watch the Copilot immediately
  respect your time constraint
- Add ingredients through the UI and see them appear in your recipe
- When the Copilot suggests new ingredients, watch them automatically appear in
  the UI ingredients list
- Change your skill level and see how the Copilot adapts its instructions in
  real-time

This synchronized state creates a seamless experience where the agent always has
your current preferences, and any updates to the recipe are instantly reflected
in both places.

This shared state pattern can be applied to any application where you want your
UI and Copilot to work together in perfect harmony!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/shared_state/page.tsx
================================================
"use client";
import { CopilotKit, useCoAgent, useCopilotChat } from "@copilotkit/react-core";
import { CopilotChat, CopilotSidebar } from "@copilotkit/react-ui";
import React, { useState, useEffect, useRef } from "react";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

interface SharedStateProps {
  params: Promise<{
    integrationId: string;
  }>;
}

export default function SharedState({ params }: SharedStateProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();
  const defaultChatHeight = 50
  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight)

  const chatTitle = 'AI Recipe Assistant'
  const chatDescription = 'Ask me to craft recipes'
  const initialLabel = 'Hi 👋 How can I help with your recipe?'

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      // agent lock to the relevant agent
      agent="shared_state"
    >
      <div
        className="min-h-screen w-full flex items-center justify-center"
        style={
          {
            backgroundImage: "url('/shared_state_background.png')",
            backgroundSize: "cover",
            backgroundPosition: "center",
            backgroundRepeat: "no-repeat",
          } as React.CSSProperties
        }
      >
        <Recipe />
        {isMobile ? (
          <>
            {/* Chat Toggle Button */}
            <div className="fixed bottom-0 left-0 right-0 z-50">
              <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
              <div
                className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
                onClick={() => {
                  if (!isChatOpen) {
                    setChatHeight(defaultChatHeight); // Reset to good default when opening
                  }
                  setIsChatOpen(!isChatOpen);
                }}
              >
                <div className="flex items-center gap-3">
                  <div>
                    <div className="font-medium text-gray-900">{chatTitle}</div>
                    <div className="text-sm text-gray-500">{chatDescription}</div>
                  </div>
                </div>
                <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
                  <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                  </svg>
                </div>
              </div>
            </div>

            {/* Pull-Up Chat Container */}
            <div
              className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${
                isChatOpen ? 'translate-y-0' : 'translate-y-full'
              } ${isDragging ? 'transition-none' : ''}`}
              style={{
                height: `${chatHeight}vh`,
                paddingBottom: 'env(safe-area-inset-bottom)' // Handle iPhone bottom padding
              }}
            >
              {/* Drag Handle Bar */}
              <div
                className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
                onMouseDown={handleDragStart}
              >
                <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
              </div>

              {/* Chat Header */}
              <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
                  </div>
                  <button
                    onClick={() => setIsChatOpen(false)}
                    className="p-2 hover:bg-gray-100 rounded-full transition-colors"
                  >
                    <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  </button>
                </div>
              </div>

              {/* Chat Content - Flexible container for messages and input */}
              <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
                <CopilotChat
                  className="h-full flex flex-col"
                  labels={{
                    initial: initialLabel,
                  }}
                />
              </div>
            </div>

            {/* Backdrop */}
            {isChatOpen && (
              <div
                className="fixed inset-0 z-30"
                onClick={() => setIsChatOpen(false)}
              />
            )}
          </>
        ) : (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}
      </div>
    </CopilotKit>
  );
}

enum SkillLevel {
  BEGINNER = "Beginner",
  INTERMEDIATE = "Intermediate",
  ADVANCED = "Advanced",
}

enum CookingTime {
  FiveMin = "5 min",
  FifteenMin = "15 min",
  ThirtyMin = "30 min",
  FortyFiveMin = "45 min",
  SixtyPlusMin = "60+ min",
}

const cookingTimeValues = [
  { label: CookingTime.FiveMin, value: 0 },
  { label: CookingTime.FifteenMin, value: 1 },
  { label: CookingTime.ThirtyMin, value: 2 },
  { label: CookingTime.FortyFiveMin, value: 3 },
  { label: CookingTime.SixtyPlusMin, value: 4 },
];

enum SpecialPreferences {
  HighProtein = "High Protein",
  LowCarb = "Low Carb",
  Spicy = "Spicy",
  BudgetFriendly = "Budget-Friendly",
  OnePotMeal = "One-Pot Meal",
  Vegetarian = "Vegetarian",
  Vegan = "Vegan",
}

interface Ingredient {
  icon: string;
  name: string;
  amount: string;
}

interface Recipe {
  title: string;
  skill_level: SkillLevel;
  cooking_time: CookingTime;
  special_preferences: string[];
  ingredients: Ingredient[];
  instructions: string[];
}

interface RecipeAgentState {
  recipe: Recipe;
}

const INITIAL_STATE: RecipeAgentState = {
  recipe: {
    title: "Make Your Recipe",
    skill_level: SkillLevel.INTERMEDIATE,
    cooking_time: CookingTime.FortyFiveMin,
    special_preferences: [],
    ingredients: [
      { icon: "🥕", name: "Carrots", amount: "3 large, grated" },
      { icon: "🌾", name: "All-Purpose Flour", amount: "2 cups" },
    ],
    instructions: ["Preheat oven to 350°F (175°C)"],
  },
};

function Recipe() {
  const { isMobile } = useMobileView();
  const { state: agentState, setState: setAgentState } = useCoAgent<RecipeAgentState>({
    name: "shared_state",
    initialState: INITIAL_STATE,
  });

  const [recipe, setRecipe] = useState(INITIAL_STATE.recipe);
  const { appendMessage, isLoading } = useCopilotChat();
  const [editingInstructionIndex, setEditingInstructionIndex] = useState<number | null>(null);
  const newInstructionRef = useRef<HTMLTextAreaElement>(null);

  const updateRecipe = (partialRecipe: Partial<Recipe>) => {
    setAgentState({
      ...agentState,
      recipe: {
        ...recipe,
        ...partialRecipe,
      },
    });
    setRecipe({
      ...recipe,
      ...partialRecipe,
    });
  };

  const newRecipeState = { ...recipe };
  const newChangedKeys = [];
  const changedKeysRef = useRef<string[]>([]);

  for (const key in recipe) {
    if (
      agentState &&
      agentState.recipe &&
      (agentState.recipe as any)[key] !== undefined &&
      (agentState.recipe as any)[key] !== null
    ) {
      let agentValue = (agentState.recipe as any)[key];
      const recipeValue = (recipe as any)[key];

      // Check if agentValue is a string and replace \n with actual newlines
      if (typeof agentValue === "string") {
        agentValue = agentValue.replace(/\\n/g, "\n");
      }

      if (JSON.stringify(agentValue) !== JSON.stringify(recipeValue)) {
        (newRecipeState as any)[key] = agentValue;
        newChangedKeys.push(key);
      }
    }
  }

  if (newChangedKeys.length > 0) {
    changedKeysRef.current = newChangedKeys;
  } else if (!isLoading) {
    changedKeysRef.current = [];
  }

  useEffect(() => {
    setRecipe(newRecipeState);
  }, [JSON.stringify(newRecipeState)]);

  const handleTitleChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    updateRecipe({
      title: event.target.value,
    });
  };

  const handleSkillLevelChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    updateRecipe({
      skill_level: event.target.value as SkillLevel,
    });
  };

  const handleDietaryChange = (preference: string, checked: boolean) => {
    if (checked) {
      updateRecipe({
        special_preferences: [...recipe.special_preferences, preference],
      });
    } else {
      updateRecipe({
        special_preferences: recipe.special_preferences.filter((p) => p !== preference),
      });
    }
  };

  const handleCookingTimeChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    updateRecipe({
      cooking_time: cookingTimeValues[Number(event.target.value)].label,
    });
  };

  const addIngredient = () => {
    // Pick a random food emoji from our valid list
    updateRecipe({
      ingredients: [...recipe.ingredients, { icon: "🍴", name: "", amount: "" }],
    });
  };

  const updateIngredient = (index: number, field: keyof Ingredient, value: string) => {
    const updatedIngredients = [...recipe.ingredients];
    updatedIngredients[index] = {
      ...updatedIngredients[index],
      [field]: value,
    };
    updateRecipe({ ingredients: updatedIngredients });
  };

  const removeIngredient = (index: number) => {
    const updatedIngredients = [...recipe.ingredients];
    updatedIngredients.splice(index, 1);
    updateRecipe({ ingredients: updatedIngredients });
  };

  const addInstruction = () => {
    const newIndex = recipe.instructions.length;
    updateRecipe({
      instructions: [...recipe.instructions, ""],
    });
    // Set the new instruction as the editing one
    setEditingInstructionIndex(newIndex);

    // Focus the new instruction after render
    setTimeout(() => {
      const textareas = document.querySelectorAll(".instructions-container textarea");
      const newTextarea = textareas[textareas.length - 1] as HTMLTextAreaElement;
      if (newTextarea) {
        newTextarea.focus();
      }
    }, 50);
  };

  const updateInstruction = (index: number, value: string) => {
    const updatedInstructions = [...recipe.instructions];
    updatedInstructions[index] = value;
    updateRecipe({ instructions: updatedInstructions });
  };

  const removeInstruction = (index: number) => {
    const updatedInstructions = [...recipe.instructions];
    updatedInstructions.splice(index, 1);
    updateRecipe({ instructions: updatedInstructions });
  };

  // Simplified icon handler that defaults to a fork/knife for any problematic icons
  const getProperIcon = (icon: string | undefined): string => {
    // If icon is undefined  return the default
    if (!icon) {
      return "🍴";
    }

    return icon;
  };

  return (
    <form 
    data-testid="recipe-card"
    style={isMobile ? { marginBottom: "100px" } : {}}
    className="recipe-card">
      {/* Recipe Title */}
      <div className="recipe-header">
        <input
          type="text"
          value={recipe.title || ""}
          onChange={handleTitleChange}
          className="recipe-title-input"
        />

        <div className="recipe-meta">
          <div className="meta-item">
            <span className="meta-icon">🕒</span>
            <select
              className="meta-select"
              value={cookingTimeValues.find((t) => t.label === recipe.cooking_time)?.value || 3}
              onChange={handleCookingTimeChange}
              style={{
                backgroundImage:
                  "url(\"data:image/svg+xml;charset=UTF-8,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='none' stroke='%23555' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3e%3cpolyline points='6 9 12 15 18 9'%3e%3c/polyline%3e%3c/svg%3e\")",
                backgroundRepeat: "no-repeat",
                backgroundPosition: "right 0px center",
                backgroundSize: "12px",
                appearance: "none",
                WebkitAppearance: "none",
              }}
            >
              {cookingTimeValues.map((time) => (
                <option key={time.value} value={time.value}>
                  {time.label}
                </option>
              ))}
            </select>
          </div>

          <div className="meta-item">
            <span className="meta-icon">🏆</span>
            <select
              className="meta-select"
              value={recipe.skill_level}
              onChange={handleSkillLevelChange}
              style={{
                backgroundImage:
                  "url(\"data:image/svg+xml;charset=UTF-8,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24' fill='none' stroke='%23555' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3e%3cpolyline points='6 9 12 15 18 9'%3e%3c/polyline%3e%3c/svg%3e\")",
                backgroundRepeat: "no-repeat",
                backgroundPosition: "right 0px center",
                backgroundSize: "12px",
                appearance: "none",
                WebkitAppearance: "none",
              }}
            >
              {Object.values(SkillLevel).map((level) => (
                <option key={level} value={level}>
                  {level}
                </option>
              ))}
            </select>
          </div>
        </div>
      </div>

      {/* Dietary Preferences */}
      <div className="section-container relative">
        {changedKeysRef.current.includes("special_preferences") && <Ping />}
        <h2 className="section-title">Dietary Preferences</h2>
        <div className="dietary-options">
          {Object.values(SpecialPreferences).map((option) => (
            <label key={option} className="dietary-option">
              <input
                type="checkbox"
                checked={recipe.special_preferences.includes(option)}
                onChange={(e: React.ChangeEvent<HTMLInputElement>) =>
                  handleDietaryChange(option, e.target.checked)
                }
              />
              <span>{option}</span>
            </label>
          ))}
        </div>
      </div>

      {/* Ingredients */}
      <div className="section-container relative">
        {changedKeysRef.current.includes("ingredients") && <Ping />}
        <div className="section-header">
          <h2 className="section-title">Ingredients</h2>
          <button
            data-testid="add-ingredient-button"
            type="button"
            className="add-button"
            onClick={addIngredient}
          >
            + Add Ingredient
          </button>
        </div>
        <div
          data-testid="ingredients-container"
          className="ingredients-container"
        >
          {recipe.ingredients.map((ingredient, index) => (
            <div key={index} 
             data-testid="ingredient-card"
             className="ingredient-card">
              <div className="ingredient-icon">{getProperIcon(ingredient.icon)}</div>
              <div className="ingredient-content">
                <input
                  type="text"
                  value={ingredient.name || ""}
                  onChange={(e) => updateIngredient(index, "name", e.target.value)}
                  placeholder="Ingredient name"
                  className="ingredient-name-input"
                />
                <input
                  type="text"
                  value={ingredient.amount || ""}
                  onChange={(e) => updateIngredient(index, "amount", e.target.value)}
                  placeholder="Amount"
                  className="ingredient-amount-input"
                />
              </div>
              <button
                type="button"
                className="remove-button"
                onClick={() => removeIngredient(index)}
                aria-label="Remove ingredient"
              >
                ×
              </button>
            </div>
          ))}
        </div>
      </div>

      {/* Instructions */}
      <div className="section-container relative">
        {changedKeysRef.current.includes("instructions") && <Ping />}
        <div className="section-header">
          <h2 className="section-title">Instructions</h2>
          <button type="button" className="add-step-button" onClick={addInstruction}>
            + Add Step
          </button>
        </div>
        <div 
          data-testid="instructions-container"
          className="instructions-container">
          {recipe.instructions.map((instruction, index) => (
            <div key={index} className="instruction-item">
              {/* Number Circle */}
              <div className="instruction-number">{index + 1}</div>

              {/* Vertical Line */}
              {index < recipe.instructions.length - 1 && <div className="instruction-line" />}

              {/* Instruction Content */}
              <div
                className={`instruction-content ${
                  editingInstructionIndex === index
                    ? "instruction-content-editing"
                    : "instruction-content-default"
                }`}
                onClick={() => setEditingInstructionIndex(index)}
              >
                <textarea
                  className="instruction-textarea"
                  value={instruction || ""}
                  onChange={(e) => updateInstruction(index, e.target.value)}
                  placeholder={!instruction ? "Enter cooking instruction..." : ""}
                  onFocus={() => setEditingInstructionIndex(index)}
                  onBlur={(e) => {
                    // Only blur if clicking outside this instruction
                    if (!e.relatedTarget || !e.currentTarget.contains(e.relatedTarget as Node)) {
                      setEditingInstructionIndex(null);
                    }
                  }}
                />

                {/* Delete Button (only visible on hover) */}
                <button
                  type="button"
                  className={`instruction-delete-btn ${
                    editingInstructionIndex === index
                      ? "instruction-delete-btn-editing"
                      : "instruction-delete-btn-default"
                  } remove-button`}
                  onClick={(e) => {
                    e.stopPropagation(); // Prevent triggering parent onClick
                    removeInstruction(index);
                  }}
                  aria-label="Remove instruction"
                >
                  ×
                </button>
              </div>
            </div>
          ))}
        </div>
      </div>

      {/* Improve with AI Button */}
      <div className="action-container">
        <button
          data-testid="improve-button"
          className={isLoading ? "improve-button loading" : "improve-button"}
          type="button"
          onClick={() => {
            if (!isLoading) {
              appendMessage(
                new TextMessage({
                  content: "Improve the recipe",
                  role: Role.User,
                }),
              );
            }
          }}
          disabled={isLoading}
        >
          {isLoading ? "Please Wait..." : "Improve with AI"}
        </button>
      </div>
    </form>
  );
}

function Ping() {
  return (
    <span className="ping-animation">
      <span className="ping-circle"></span>
      <span className="ping-dot"></span>
    </span>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/shared_state/style.css
================================================
.copilotKitWindow {
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.copilotKitHeader {
  border-top-left-radius: 5px !important;
  background-color: #fff;
  color: #000;
  border-bottom: 0px;
}

/* Recipe App Styles */
.app-container {
  min-height: 100vh;
  width: 100%;
  display: flex;
  align-items: center;
  justify-content: center;
  background-size: cover;
  background-position: center;
  background-repeat: no-repeat;
  background-attachment: fixed;
  position: relative;
  overflow: auto;
}

.recipe-card {
  background-color: rgba(255, 255, 255, 0.97);
  border-radius: 16px;
  box-shadow: 0 15px 30px rgba(0, 0, 0, 0.25), 0 5px 15px rgba(0, 0, 0, 0.15);
  width: 100%;
  max-width: 750px;
  margin: 20px auto;
  padding: 14px 32px;
  position: relative;
  z-index: 1;
  backdrop-filter: blur(5px);
  border: 1px solid rgba(255, 255, 255, 0.3);
  transition: transform 0.2s ease, box-shadow 0.2s ease;
  animation: fadeIn 0.5s ease-out forwards;
  box-sizing: border-box;
  overflow: hidden;
}

.recipe-card:hover {
  transform: translateY(-5px);
  box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3), 0 10px 20px rgba(0, 0, 0, 0.2);
}

/* Recipe Header */
.recipe-header {
  margin-bottom: 24px;
}

.recipe-title-input {
  width: 100%;
  font-size: 24px;
  font-weight: bold;
  border: none;
  outline: none;
  padding: 8px 0;
  margin-bottom: 0px;
}

.recipe-meta {
  display: flex;
  align-items: center;
  gap: 20px;
  margin-top: 5px;
  margin-bottom: 14px;
}

.meta-item {
  display: flex;
  align-items: center;
  gap: 8px;
  color: #555;
}

.meta-icon {
  font-size: 20px;
  color: #777;
}

.meta-text {
  font-size: 15px;
}

/* Recipe Meta Selects */
.meta-item select {
  border: none;
  background: transparent;
  font-size: 15px;
  color: #555;
  cursor: pointer;
  outline: none;
  padding-right: 18px;
  transition: color 0.2s, transform 0.1s;
  font-weight: 500;
}

.meta-item select:hover,
.meta-item select:focus {
  color: #FF5722;
}

.meta-item select:active {
  transform: scale(0.98);
}

.meta-item select option {
  color: #333;
  background-color: white;
  font-weight: normal;
  padding: 8px;
}

/* Section Container */
.section-container {
  margin-bottom: 20px;
  position: relative;
  width: 100%;
}

.section-title {
  font-size: 20px;
  font-weight: 700;
  margin-bottom: 20px;
  color: #333;
  position: relative;
  display: inline-block;
}

.section-title:after {
  content: "";
  position: absolute;
  bottom: -8px;
  left: 0;
  width: 40px;
  height: 3px;
  background-color: #ff7043;
  border-radius: 3px;
}

/* Dietary Preferences */
.dietary-options {
  display: flex;
  flex-wrap: wrap;
  gap: 10px 16px;
  margin-bottom: 16px;
  width: 100%;
}

.dietary-option {
  display: flex;
  align-items: center;
  gap: 6px;
  font-size: 14px;
  cursor: pointer;
  margin-bottom: 4px;
}

.dietary-option input {
  cursor: pointer;
}

/* Ingredients */
.ingredients-container {
  display: flex;
  flex-wrap: wrap;
  gap: 10px;
  margin-bottom: 15px;
  width: 100%;
  box-sizing: border-box;
}

.ingredient-card {
  display: flex;
  align-items: center;
  background-color: rgba(255, 255, 255, 0.9);
  border-radius: 12px;
  padding: 12px;
  margin-bottom: 10px;
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.08);
  position: relative;
  transition: all 0.2s ease;
  border: 1px solid rgba(240, 240, 240, 0.8);
  width: calc(33.333% - 7px);
  box-sizing: border-box;
}

.ingredient-card:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 15px rgba(0, 0, 0, 0.12);
}

.ingredient-card .remove-button {
  position: absolute;
  right: 10px;
  top: 10px;
  background: none;
  border: none;
  color: #ccc;
  font-size: 16px;
  cursor: pointer;
  display: none;
  padding: 0;
  width: 24px;
  height: 24px;
  line-height: 1;
}

.ingredient-card:hover .remove-button {
  display: block;
}

.ingredient-icon {
  font-size: 24px;
  margin-right: 12px;
  display: flex;
  align-items: center;
  justify-content: center;
  width: 40px;
  height: 40px;
  background-color: #f7f7f7;
  border-radius: 50%;
  flex-shrink: 0;
}

.ingredient-content {
  flex: 1;
  display: flex;
  flex-direction: column;
  gap: 3px;
  min-width: 0;
}

.ingredient-name-input,
.ingredient-amount-input {
  border: none;
  background: transparent;
  outline: none;
  width: 100%;
  padding: 0;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.ingredient-name-input {
  font-weight: 500;
  font-size: 14px;
}

.ingredient-amount-input {
  font-size: 13px;
  color: #666;
}

.ingredient-name-input::placeholder,
.ingredient-amount-input::placeholder {
  color: #aaa;
}

.remove-button {
  background: none;
  border: none;
  color: #999;
  font-size: 20px;
  cursor: pointer;
  padding: 0;
  width: 28px;
  height: 28px;
  display: flex;
  align-items: center;
  justify-content: center;
  margin-left: 10px;
}

.remove-button:hover {
  color: #FF5722;
}

/* Instructions */
.instructions-container {
  display: flex;
  flex-direction: column;
  gap: 6px;
  position: relative;
  margin-bottom: 12px;
  width: 100%;
}

.instruction-item {
  position: relative;
  display: flex;
  width: 100%;
  box-sizing: border-box;
  margin-bottom: 8px;
  align-items: flex-start;
}

.instruction-number {
  display: flex;
  align-items: center;
  justify-content: center;
  min-width: 26px;
  height: 26px;
  background-color: #ff7043;
  color: white;
  border-radius: 50%;
  font-weight: 600;
  flex-shrink: 0;
  box-shadow: 0 2px 4px rgba(255, 112, 67, 0.3);
  z-index: 1;
  font-size: 13px;
  margin-top: 2px;
}

.instruction-line {
  position: absolute;
  left: 13px; /* Half of the number circle width */
  top: 22px;
  bottom: -18px;
  width: 2px;
  background: linear-gradient(to bottom, #ff7043 60%, rgba(255, 112, 67, 0.4));
  z-index: 0;
}

.instruction-content {
  background-color: white;
  border-radius: 10px;
  padding: 10px 14px;
  margin-left: 12px;
  flex-grow: 1;
  transition: all 0.2s ease;
  box-shadow: 0 2px 6px rgba(0, 0, 0, 0.08);
  border: 1px solid rgba(240, 240, 240, 0.8);
  position: relative;
  width: calc(100% - 38px);
  box-sizing: border-box;
  display: flex;
  align-items: center;
}

.instruction-content-editing {
  background-color: #fff9f6;
  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12), 0 0 0 2px rgba(255, 112, 67, 0.2);
}

.instruction-content:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12);
}

.instruction-textarea {
  width: 100%;
  background: transparent;
  border: none;
  resize: vertical;
  font-family: inherit;
  font-size: 14px;
  line-height: 1.4;
  min-height: 20px;
  outline: none;
  padding: 0;
  margin: 0;
}

.instruction-delete-btn {
  position: absolute;
  background: none;
  border: none;
  color: #ccc;
  font-size: 16px;
  cursor: pointer;
  display: none;
  padding: 0;
  width: 20px;
  height: 20px;
  line-height: 1;
  top: 50%;
  transform: translateY(-50%);
  right: 8px;
}

.instruction-content:hover .instruction-delete-btn {
  display: flex;
  align-items: center;
  justify-content: center;
}

/* Action Button */
.action-container {
  display: flex;
  justify-content: center;
  margin-top: 40px;
  padding-bottom: 20px;
  position: relative;
}

.improve-button {
  background-color: #ff7043;
  border: none;
  color: white;
  border-radius: 30px;
  font-size: 18px;
  font-weight: 600;
  padding: 14px 28px;
  cursor: pointer;
  transition: all 0.3s ease;
  box-shadow: 0 4px 15px rgba(255, 112, 67, 0.4);
  display: flex;
  align-items: center;
  justify-content: center;
  text-align: center;
  position: relative;
  min-width: 180px;
}

.improve-button:hover {
  background-color: #ff5722;
  transform: translateY(-2px);
  box-shadow: 0 8px 20px rgba(255, 112, 67, 0.5);
}

.improve-button.loading {
  background-color: #ff7043;
  opacity: 0.8;
  cursor: not-allowed;
  padding-left: 42px; /* Reduced padding to bring text closer to icon */
  padding-right: 22px; /* Balance the button */
  justify-content: flex-start; /* Left align text for better alignment with icon */
}

.improve-button.loading:after {
  content: ""; /* Add space between icon and text */
  display: inline-block;
  width: 8px; /* Width of the space */
}

.improve-button:before {
  content: "";
  background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='white' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpath d='M12 2v4M12 18v4M4.93 4.93l2.83 2.83M16.24 16.24l2.83 2.83M2 12h4M18 12h4M4.93 19.07l2.83-2.83M16.24 7.76l2.83-2.83'/%3E%3C/svg%3E");
  width: 20px; /* Slightly smaller icon */
  height: 20px;
  background-repeat: no-repeat;
  background-size: contain;
  position: absolute;
  left: 16px; /* Slightly adjusted */
  top: 50%;
  transform: translateY(-50%);
  display: none;
}

.improve-button.loading:before {
  display: block;
  animation: spin 1.5s linear infinite;
}

@keyframes spin {
  0% { transform: translateY(-50%) rotate(0deg); }
  100% { transform: translateY(-50%) rotate(360deg); }
}

/* Ping Animation */
.ping-animation {
  position: absolute;
  display: flex;
  width: 12px;
  height: 12px;
  top: 0;
  right: 0;
}

.ping-circle {
  position: absolute;
  display: inline-flex;
  width: 100%;
  height: 100%;
  border-radius: 50%;
  background-color: #38BDF8;
  opacity: 0.75;
  animation: ping 1.5s cubic-bezier(0, 0, 0.2, 1) infinite;
}

.ping-dot {
  position: relative;
  display: inline-flex;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background-color: #0EA5E9;
}

@keyframes ping {
  75%, 100% {
    transform: scale(2);
    opacity: 0;
  }
}

/* Instruction hover effects */
.instruction-item:hover .instruction-delete-btn {
  display: flex !important;
}

/* Add some subtle animations */
@keyframes fadeIn {
  from { opacity: 0; transform: translateY(20px); }
  to { opacity: 1; transform: translateY(0); }
}

/* Better center alignment for the recipe card */
.recipe-card-container {
  display: flex;
  justify-content: center;
  width: 100%;
  position: relative;
  z-index: 1;
  margin: 0 auto;
  box-sizing: border-box;
}

/* Add Buttons */
.add-button {
  background-color: transparent;
  color: #FF5722;
  border: 1px dashed #FF5722;
  border-radius: 8px;
  padding: 10px 16px;
  cursor: pointer;
  font-weight: 500;
  display: inline-block;
  font-size: 14px;
  margin-bottom: 0;
}

.add-step-button {
  background-color: transparent;
  color: #FF5722;
  border: 1px dashed #FF5722;
  border-radius: 6px;
  padding: 6px 12px;
  cursor: pointer;
  font-weight: 500;
  font-size: 13px;
}

/* Section Headers */
.section-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 12px;
}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/subgraphs/README.mdx
================================================
# LangGraph Subgraphs Demo: Travel Planning Assistant ✈️

This demo showcases **LangGraph subgraphs** through an interactive travel planning assistant. Watch as specialized AI agents collaborate to plan your perfect trip!

## What are LangGraph Subgraphs? 🤖

**Subgraphs** are the key to building modular, scalable AI systems in LangGraph. A subgraph is essentially "a graph that is used as a node in another graph" - enabling powerful encapsulation and reusability.
For more info, check out the [LangGraph docs](https://langchain-ai.github.io/langgraph/concepts/subgraphs/).

### Key Concepts

- **Encapsulation**: Each subgraph handles a specific domain with its own expertise
- **Modularity**: Subgraphs can be developed, tested, and maintained independently  
- **Reusability**: The same subgraph can be used across multiple parent graphs
- **State Communication**: Subgraphs can share state or use different schemas with transformations

## Demo Architecture 🗺️

This travel planner demonstrates **supervisor-coordinated subgraphs** with **human-in-the-loop** decision making:

### Parent Graph: Travel Supervisor
- **Role**: Coordinates the travel planning process and routes to specialized agents
- **State Management**: Maintains a shared itinerary object across all subgraphs
- **Intelligence**: Determines what's needed and when each agent should be called

### Subgraph 1: ✈️ Flights Agent
- **Specialization**: Finding and booking flight options
- **Process**: Presents flight options from Amsterdam to San Francisco with recommendations
- **Interaction**: Uses interrupts to let users choose their preferred flight
- **Data**: Static flight options (KLM, United) with pricing and duration

### Subgraph 2: 🏨 Hotels Agent  
- **Specialization**: Finding and booking accommodation
- **Process**: Shows hotel options in San Francisco with different price points
- **Interaction**: Uses interrupts for user to select their preferred hotel
- **Data**: Static hotel options (Hotel Zephyr, Ritz-Carlton, Hotel Zoe)

### Subgraph 3: 🎯 Experiences Agent
- **Specialization**: Curating restaurants and activities
- **Process**: AI-powered recommendations based on selected flights and hotels
- **Features**: Combines 2 restaurants and 2 activities with location-aware suggestions
- **Data**: Static experiences (Pier 39, Golden Gate Bridge, Swan Oyster Depot, Tartine Bakery)

## How It Works 🔄

1. **User Request**: "Help me plan a trip to San Francisco"
2. **Supervisor Analysis**: Determines what travel components are needed
3. **Sequential Routing**: Routes to each agent in logical order:
   - First: Flights Agent (get transportation sorted)
   - Then: Hotels Agent (book accommodation)  
   - Finally: Experiences Agent (plan activities)
4. **Human Decisions**: Each agent presents options and waits for user choice via interrupts
5. **State Building**: Selected choices are stored in the shared itinerary object
6. **Completion**: All agents report back to supervisor for final coordination

## State Communication Patterns 📊

### Shared State Schema
All subgraph agents share and contribute to a common state object. When any agent updates the shared state, these changes are immediately reflected in the frontend through real-time syncing. This ensures that:

- **Flight selections** from the Flights Agent are visible to subsequent agents
- **Hotel choices** influence the Experiences Agent's recommendations  
- **All updates** are synchronized with the frontend UI in real-time
- **State persistence** maintains the travel itinerary throughout the workflow

### Human-in-the-Loop Pattern
Two of the specialist agents use **interrupts** to pause execution and gather user preferences:

- **Flights Agent**: Presents options → interrupt → waits for selection → continues
- **Hotels Agent**: Shows hotels → interrupt → waits for choice → continues

## Try These Examples! 💡

### Getting Started
- "Help me plan a trip to San Francisco"
- "I want to visit San Francisco from Amsterdam"
- "Plan my travel itinerary"

### During the Process
When the Flights Agent presents options:
- Choose between KLM ($650, 11h 30m) or United ($720, 12h 15m)

When the Hotels Agent shows accommodations:
- Select from Hotel Zephyr, The Ritz-Carlton, or Hotel Zoe

The Experiences Agent will then provide tailored recommendations based on your choices!

## Frontend Capabilities 👁️

- **Human-in-the-loop with interrupts** from subgraphs for user decision making
- **Subgraphs detection and streaming** to show which agent is currently active
- **Real-time state updates** as the shared itinerary is built across agents



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/subgraphs/page.tsx
================================================
"use client";
import React, { useState, useEffect } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import { CopilotKit, useCoAgent, useLangGraphInterrupt } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

interface SubgraphsProps {
  params: Promise<{
    integrationId: string;
  }>;
}

// Travel planning data types
interface Flight {
  airline: string;
  arrival: string;
  departure: string;
  duration: string;
  price: string;
}

interface Hotel {
  location: string;
  name: string;
  price_per_night: string;
  rating: string;
}

interface Experience {
  name: string;
  description: string;
  location: string;
  type: string;
}

interface Itinerary {
  hotel?: Hotel;
  flight?: Flight;
  experiences?: Experience[];
}

type AvailableAgents = 'flights' | 'hotels' | 'experiences' | 'supervisor'

interface TravelAgentState {
  experiences: Experience[],
  flights: Flight[],
  hotels: Hotel[],
  itinerary: Itinerary
  planning_step: string
  active_agent: AvailableAgents
}

const INITIAL_STATE: TravelAgentState = {
  itinerary: {},
  experiences: [],
  flights: [],
  hotels: [],
  planning_step: "start",
  active_agent: 'supervisor'
};

interface InterruptEvent<TAgent extends AvailableAgents> {
  message: string;
  options: TAgent extends 'flights' ? Flight[] : TAgent extends 'hotels' ? Hotel[] : never,
  recommendation: TAgent extends 'flights' ? Flight : TAgent extends 'hotels' ? Hotel : never,
  agent: TAgent
}

function InterruptHumanInTheLoop<TAgent extends AvailableAgents>({
  event,
  resolve,
}: {
  event: { value: InterruptEvent<TAgent> };
  resolve: (value: string) => void;
}) {
  const { message, options, agent, recommendation } = event.value;

  // Format agent name with emoji
  const formatAgentName = (agent: string) => {
    switch (agent) {
      case 'flights': return 'Flights Agent';
      case 'hotels': return 'Hotels Agent';
      case 'experiences': return 'Experiences Agent';
      default: return `${agent} Agent`;
    }
  };

  const handleOptionSelect = (option: any) => {
    resolve(JSON.stringify(option));
  };

  return (
    <div className="interrupt-container">
      <p>{formatAgentName(agent)}: {message}</p>

      <div className="interrupt-options">
        {options.map((opt, idx) => {
          if ('airline' in opt) {
            const isRecommended = (recommendation as Flight).airline === opt.airline;
            // Flight options
            return (
              <button
                key={idx}
                className={`option-card flight-option ${isRecommended ? 'recommended' : ''}`}
                onClick={() => handleOptionSelect(opt)}
              >
                {isRecommended && <span className="recommendation-badge">⭐ Recommended</span>}
                <div className="option-header">
                  <span className="airline-name">{opt.airline}</span>
                  <span className="price">{opt.price}</span>
                </div>
                <div className="route-info">
                  {opt.departure} → {opt.arrival}
                </div>
                <div className="duration-info">
                  {opt.duration}
                </div>
              </button>
            );
          }
          const isRecommended = (recommendation as Hotel).name === opt.name;

          // Hotel options
          return (
            <button
              key={idx}
              className={`option-card hotel-option ${isRecommended ? 'recommended' : ''}`}
              onClick={() => handleOptionSelect(opt)}
            >
              {isRecommended && <span className="recommendation-badge">⭐ Recommended</span>}
              <div className="option-header">
                <span className="hotel-name">{opt.name}</span>
                <span className="rating">{opt.rating}</span>
              </div>
              <div className="location-info">
                📍 {opt.location}
              </div>
              <div className="price-info">
                {opt.price_per_night}
              </div>
            </button>
          );
        })}
      </div>
    </div>
  )
}

export default function Subgraphs({ params }: SubgraphsProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();
  const defaultChatHeight = 50;
  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight);

  const chatTitle = 'Travel Planning Assistant';
  const chatDescription = 'Plan your perfect trip with AI specialists';
  const initialLabel = 'Hi! ✈️ Ready to plan an amazing trip? Try saying "Plan a trip to Paris" or "Find me flights to Tokyo"';

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      agent="subgraphs"
    >
      <div className="travel-planner-container">
        <TravelPlanner />
        {isMobile ? (
          <>
            {/* Chat Toggle Button */}
            <div className="fixed bottom-0 left-0 right-0 z-50">
              <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
              <div
                className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
                onClick={() => {
                  if (!isChatOpen) {
                    setChatHeight(defaultChatHeight);
                  }
                  setIsChatOpen(!isChatOpen);
                }}
              >
                <div className="flex items-center gap-3">
                  <div>
                    <div className="font-medium text-gray-900">{chatTitle}</div>
                    <div className="text-sm text-gray-500">{chatDescription}</div>
                  </div>
                </div>
                <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
                  <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
                  </svg>
                </div>
              </div>
            </div>

            {/* Pull-Up Chat Container */}
            <div
              className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${
                isChatOpen ? 'translate-y-0' : 'translate-y-full'
              } ${isDragging ? 'transition-none' : ''}`}
              style={{
                height: `${chatHeight}vh`,
                paddingBottom: 'env(safe-area-inset-bottom)'
              }}
            >
              {/* Drag Handle Bar */}
              <div
                className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
                onMouseDown={handleDragStart}
              >
                <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
              </div>

              {/* Chat Header */}
              <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
                <div className="flex items-center justify-between">
                  <div className="flex items-center gap-3">
                    <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
                  </div>
                  <button
                    onClick={() => setIsChatOpen(false)}
                    className="p-2 hover:bg-gray-100 rounded-full transition-colors"
                  >
                    <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                    </svg>
                  </button>
                </div>
              </div>

              {/* Chat Content */}
              <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
                <CopilotSidebar
                  defaultOpen={true}
                  labels={{
                    title: chatTitle,
                    initial: initialLabel,
                  }}
                  clickOutsideToClose={false}
                />
              </div>
            </div>

            {/* Backdrop */}
            {isChatOpen && (
              <div
                className="fixed inset-0 z-30"
                onClick={() => setIsChatOpen(false)}
              />
            )}
          </>
        ) : (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}
      </div>
    </CopilotKit>
  );
}

function TravelPlanner() {
  const { isMobile } = useMobileView();
  const { state: agentState, nodeName } = useCoAgent<TravelAgentState>({
    name: "subgraphs",
    initialState: INITIAL_STATE,
    config: {
      streamSubgraphs: true,
    }
  });

  useLangGraphInterrupt({
    render: ({ event, resolve }) => <InterruptHumanInTheLoop event={event} resolve={resolve} />,
  });

  // Current itinerary strip
  const ItineraryStrip = () => {
    const selectedFlight = agentState?.itinerary?.flight;
    const selectedHotel = agentState?.itinerary?.hotel;
    const hasExperiences = agentState?.experiences?.length > 0;

    return (
      <div className="itinerary-strip">
        <div className="itinerary-label">Current Itinerary:</div>
        <div className="itinerary-items">
          <div className="itinerary-item">
            <span className="item-icon">📍</span>
            <span>Amsterdam → San Francisco</span>
          </div>
          {selectedFlight && (
            <div className="itinerary-item" data-testid="selected-flight">
              <span className="item-icon">✈️</span>
              <span>{selectedFlight.airline} - {selectedFlight.price}</span>
            </div>
          )}
          {selectedHotel && (
            <div className="itinerary-item" data-testid="selected-hotel">
              <span className="item-icon">🏨</span>
              <span>{selectedHotel.name}</span>
            </div>
          )}
          {hasExperiences && (
            <div className="itinerary-item">
              <span className="item-icon">🎯</span>
              <span>{agentState.experiences.length} experiences planned</span>
            </div>
          )}
        </div>
      </div>
    );
  };

  // Compact agent status
  const AgentStatus = () => {
    let activeAgent = 'supervisor';
    if (nodeName?.includes('flights_agent')) {
      activeAgent = 'flights';
    }
    if (nodeName?.includes('hotels_agent')) {
      activeAgent = 'hotels';
    }
    if (nodeName?.includes('experiences_agent')) {
      activeAgent = 'experiences';
    }
    return (
      <div className="agent-status">
        <div className="status-label">Active Agent:</div>
        <div className="agent-indicators">
          <div className={`agent-indicator ${activeAgent === 'supervisor' ? 'active' : ''}`} data-testid="supervisor-indicator">
            <span>👨‍💼</span>
            <span>Supervisor</span>
          </div>
          <div className={`agent-indicator ${activeAgent === 'flights' ? 'active' : ''}`} data-testid="flights-agent-indicator">
            <span>✈️</span>
            <span>Flights</span>
          </div>
          <div className={`agent-indicator ${activeAgent === 'hotels' ? 'active' : ''}`} data-testid="hotels-agent-indicator">
            <span>🏨</span>
            <span>Hotels</span>
          </div>
          <div className={`agent-indicator ${activeAgent === 'experiences' ? 'active' : ''}`} data-testid="experiences-agent-indicator">
            <span>🎯</span>
            <span>Experiences</span>
          </div>
        </div>
      </div>
    )
  };

  // Travel details component
  const TravelDetails = () => (
    <div className="travel-details">
      <div className="details-section">
        <h4>✈️ Flight Options</h4>
        <div className="detail-items">
          {agentState?.flights?.length > 0 ? (
            agentState.flights.map((flight, index) => (
              <div key={index} className="detail-item">
                <strong>{flight.airline}:</strong>
                <span>{flight.departure} → {flight.arrival} ({flight.duration}) - {flight.price}</span>
              </div>
            ))
          ) : (
            <p className="no-activities">No flights found yet</p>
          )}
          {agentState?.itinerary?.flight && (
            <div className="detail-tips">
              <strong>Selected:</strong> {agentState.itinerary.flight.airline} - {agentState.itinerary.flight.price}
            </div>
          )}
        </div>
      </div>

      <div className="details-section">
        <h4>🏨 Hotel Options</h4>
        <div className="detail-items">
          {agentState?.hotels?.length > 0 ? (
            agentState.hotels.map((hotel, index) => (
              <div key={index} className="detail-item">
                <strong>{hotel.name}:</strong>
                <span>{hotel.location} - {hotel.price_per_night} ({hotel.rating})</span>
              </div>
            ))
          ) : (
            <p className="no-activities">No hotels found yet</p>
          )}
          {agentState?.itinerary?.hotel && (
            <div className="detail-tips">
              <strong>Selected:</strong> {agentState.itinerary.hotel.name} - {agentState.itinerary.hotel.price_per_night}
            </div>
          )}
        </div>
      </div>

      <div className="details-section">
        <h4>🎯 Experiences</h4>
        <div className="detail-items">
          {agentState?.experiences?.length > 0 ? (
            agentState.experiences.map((experience, index) => (
              <div key={index} className="activity-item">
                <div className="activity-name">{experience.name}</div>
                <div className="activity-category">{experience.type}</div>
                <div className="activity-description">{experience.description}</div>
                <div className="activity-meta">Location: {experience.location}</div>
              </div>
            ))
          ) : (
            <p className="no-activities">No experiences planned yet</p>
          )}
        </div>
      </div>
    </div>
  );

  return (
    <div className="travel-content">
      <ItineraryStrip />
      <AgentStatus />
      <TravelDetails />
    </div>
  );
}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/subgraphs/style.css
================================================
/* Travel Planning Subgraphs Demo Styles */
/* Essential styles that cannot be achieved with Tailwind classes */

/* Main container with CopilotSidebar layout */
.travel-planner-container {
  min-height: 100vh;
  padding: 2rem;
  background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
}

/* Travel content area styles */
.travel-content {
  max-width: 1200px;
  margin: 0 auto;
  padding: 0 1rem;
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

/* Itinerary strip */
.itinerary-strip {
  background: white;
  border-radius: 0.5rem;
  padding: 1rem;
  border: 1px solid #e5e7eb;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
}

.itinerary-label {
  font-size: 0.875rem;
  font-weight: 600;
  color: #6b7280;
  margin-bottom: 0.5rem;
}

.itinerary-items {
  display: flex;
  flex-wrap: wrap;
  gap: 1rem;
}

.itinerary-item {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.5rem 0.75rem;
  background: #f9fafb;
  border-radius: 0.375rem;
  font-size: 0.875rem;
}

.item-icon {
  font-size: 1rem;
}

/* Agent status */
.agent-status {
  background: white;
  border-radius: 0.5rem;
  padding: 1rem;
  border: 1px solid #e5e7eb;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
}

.status-label {
  font-size: 0.875rem;
  font-weight: 600;
  color: #6b7280;
  margin-bottom: 0.5rem;
}

.agent-indicators {
  display: flex;
  gap: 0.75rem;
}

.agent-indicator {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.5rem 0.75rem;
  border-radius: 0.375rem;
  font-size: 0.875rem;
  background: #f9fafb;
  border: 1px solid #e5e7eb;
  transition: all 0.2s ease;
}

.agent-indicator.active {
  background: #dbeafe;
  border-color: #3b82f6;
  color: #1d4ed8;
  box-shadow: 0 0 0 2px rgba(59, 130, 246, 0.1);
}

/* Travel details sections */
.travel-details {
  background: white;
  border-radius: 0.5rem;
  padding: 1rem;
  border: 1px solid #e5e7eb;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  display: grid;
  gap: 1rem;
}

.details-section h4 {
  font-size: 1rem;
  font-weight: 600;
  color: #1f2937;
  margin-bottom: 0.5rem;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.detail-items {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.detail-item {
  padding: 0.5rem;
  background: #f9fafb;
  border-radius: 0.25rem;
  font-size: 0.875rem;
  display: flex;
  justify-content: space-between;
}

.detail-item strong {
  color: #6b7280;
  font-weight: 500;
}

.detail-tips {
  padding: 0.5rem;
  background: #eff6ff;
  border-radius: 0.25rem;
  font-size: 0.75rem;
  color: #1d4ed8;
}

.activity-item {
  padding: 0.75rem;
  background: #f0f9ff;
  border-radius: 0.25rem;
  border-left: 2px solid #0ea5e9;
}

.activity-name {
  font-weight: 600;
  color: #1f2937;
  font-size: 0.875rem;
  margin-bottom: 0.25rem;
}

.activity-category {
  font-size: 0.75rem;
  color: #0ea5e9;
  margin-bottom: 0.25rem;
}

.activity-description {
  color: #4b5563;
  font-size: 0.75rem;
  margin-bottom: 0.25rem;
}

.activity-meta {
  font-size: 0.75rem;
  color: #6b7280;
}

.no-activities {
  text-align: center;
  color: #9ca3af;
  font-style: italic;
  padding: 1rem;
  font-size: 0.875rem;
}

/* Interrupt UI for Chat Sidebar (Generative UI) */
.interrupt-container {
  display: flex;
  flex-direction: column;
  gap: 1rem;
  max-width: 100%;
  padding-top: 34px;
}

.interrupt-header {
  margin-bottom: 0.5rem;
}

.agent-name {
  font-size: 0.875rem;
  font-weight: 600;
  color: #1f2937;
  margin: 0 0 0.25rem 0;
}

.agent-message {
  font-size: 0.75rem;
  color: #6b7280;
  margin: 0;
  line-height: 1.4;
}

.interrupt-options {
    padding: 0.75rem;
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
  max-height: 300px;
  overflow-y: auto;
}

.option-card {
  display: flex;
  flex-direction: column;
  gap: 0.25rem;
  padding: 0.75rem;
  background: #f9fafb;
  border: 1px solid #e5e7eb;
  border-radius: 0.5rem;
  cursor: pointer;
  transition: all 0.2s ease;
  text-align: left;
  position: relative;
  min-height: auto;
}

.option-card:hover {
  background: #f3f4f6;
  border-color: #d1d5db;
}

.option-card:active {
  background: #e5e7eb;
}

.option-card.recommended {
  background: #eff6ff;
  border-color: #3b82f6;
  box-shadow: 0 0 0 1px rgba(59, 130, 246, 0.1);
}

.option-card.recommended:hover {
  background: #dbeafe;
}

.recommendation-badge {
  position: absolute;
  top: -2px;
  right: -2px;
  background: #3b82f6;
  color: white;
  font-size: 0.625rem;
  padding: 0.125rem 0.375rem;
  border-radius: 0.75rem;
  font-weight: 500;
}

.option-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 0.125rem;
}

.airline-name, .hotel-name {
  font-weight: 600;
  font-size: 0.8rem;
  color: #1f2937;
}

.price, .rating {
  font-weight: 600;
  font-size: 0.75rem;
  color: #059669;
}

.route-info, .location-info {
  font-size: 0.7rem;
  color: #6b7280;
  margin-bottom: 0.125rem;
}

.duration-info, .price-info {
  font-size: 0.7rem;
  color: #9ca3af;
}

/* Mobile responsive adjustments */
@media (max-width: 768px) {
  .travel-planner-container {
    padding: 0.5rem;
    padding-bottom: 120px; /* Space for mobile chat */
  }
  
  .travel-content {
    padding: 0;
    gap: 0.75rem;
  }
  
  .itinerary-items {
    flex-direction: column;
    gap: 0.5rem;
  }
  
  .agent-indicators {
    flex-direction: column;
    gap: 0.5rem;
  }
  
  .agent-indicator {
    padding: 0.75rem;
  }
  
  .travel-details {
    padding: 0.75rem;
  }

  .interrupt-container {
    padding: 0.5rem;
  }

  .option-card {
    padding: 0.625rem;
  }

  .interrupt-options {
    max-height: 250px;
  }
}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/tool_based_generative_ui/README.mdx
================================================
# 🪶 Tool-Based Generative UI Haiku Creator

## What This Demo Shows

This demo showcases CopilotKit's **tool-based generative UI** capabilities:

1. **Frontend Rendering of Tool Calls**: Backend tool calls are automatically
   rendered in the UI
2. **Dynamic UI Generation**: The UI updates in real-time as the agent generates
   content
3. **Elegant Content Presentation**: Complex structured data (haikus) are
   beautifully displayed

## How to Interact

Chat with your Copilot and ask for haikus about different topics:

- "Create a haiku about nature"
- "Write a haiku about technology"
- "Generate a haiku about the changing seasons"
- "Make a humorous haiku about programming"

Each request will trigger the agent to generate a haiku and display it in a
visually appealing card format in the UI.

## ✨ Tool-Based Generative UI in Action

**What's happening technically:**

- The agent processes your request and determines it should create a haiku
- It calls a backend tool that returns structured haiku data
- CopilotKit automatically renders this tool call in the frontend
- The rendering is handled by the registered tool component in your React app
- No manual state management is required to display the results

**What you'll see in this demo:**

- As you request a haiku, a beautifully formatted card appears in the UI
- The haiku follows the traditional 5-7-5 syllable structure
- Each haiku is presented with consistent styling
- Multiple haikus can be generated in sequence
- The UI adapts to display each new piece of content

This pattern of tool-based generative UI can be extended to create any kind of
dynamic content - from data visualizations to interactive components, all driven
by your Copilot's tool calls!



================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/tool_based_generative_ui/page.tsx
================================================
"use client";
import { CopilotKit, useCopilotAction } from "@copilotkit/react-core";
import { CopilotKitCSSProperties, CopilotSidebar, CopilotChat } from "@copilotkit/react-ui";
import { Dispatch, SetStateAction, useState, useEffect } from "react";
import "@copilotkit/react-ui/styles.css";
import "./style.css";
import React, { useMemo } from "react";
import { useMobileView } from "@/utils/use-mobile-view";
import { useMobileChat } from "@/utils/use-mobile-chat";

interface ToolBasedGenerativeUIProps {
  params: Promise<{
    integrationId: string;
  }>;
}

interface GenerateHaiku {
  japanese: string[] | [],
  english: string[] | [],
  image_names: string[] | [],
  selectedImage: string | null,
}

interface HaikuCardProps {
  generatedHaiku: GenerateHaiku | Partial<GenerateHaiku>
  setHaikus: Dispatch<SetStateAction<GenerateHaiku[]>>
  haikus: GenerateHaiku[]
}

export default function ToolBasedGenerativeUI({ params }: ToolBasedGenerativeUIProps) {
  const { integrationId } = React.use(params);
  const { isMobile } = useMobileView();


  const chatTitle = 'Haiku Generator'
  const chatDescription = 'Ask me to create haikus'
  const initialLabel = 'I\'m a haiku generator 👋. How can I help you?'

  return (
    <CopilotKit
      runtimeUrl={`/api/copilotkit/${integrationId}`}
      showDevConsole={false}
      agent="tool_based_generative_ui"
    >
      <div
        className={`${isMobile ? 'h-screen' : 'min-h-full flex'} w-full relative overflow-hidden`}
      >
        <Haiku />

        {/* Desktop Sidebar */}
        {!isMobile && (
          <CopilotSidebar
            defaultOpen={true}
            labels={{
              title: chatTitle,
              initial: initialLabel,
            }}
            clickOutsideToClose={false}
          />
        )}

        {/* Mobile Pull-Up Chat */}
        {isMobile && <MobileChat chatTitle={chatTitle} chatDescription={chatDescription} initialLabel={initialLabel} />}
      </div>
    </CopilotKit>
  );
}

function MobileChat({ chatTitle, chatDescription, initialLabel }: { chatTitle: string, chatDescription: string, initialLabel: string }) {
  const defaultChatHeight = 50

  const {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  } = useMobileChat(defaultChatHeight)
  return (
    <>
      {/* Chat Toggle Button */}
      <div className="fixed bottom-0 left-0 right-0 z-50">
        <div className="bg-gradient-to-t from-white via-white to-transparent h-6"></div>
        <div
          className="bg-white border-t border-gray-200 px-4 py-3 flex items-center justify-between cursor-pointer shadow-lg"
          onClick={() => {
            if (!isChatOpen) {
              setChatHeight(defaultChatHeight); // Reset to good default when opening
            }
            setIsChatOpen(!isChatOpen);
          }}
        >
          <div className="flex items-center gap-3">
            <div>
              <div className="font-medium text-gray-900">{chatTitle}</div>
              <div className="text-sm text-gray-500">{chatDescription}</div>
            </div>
          </div>
          <div className={`transform transition-transform duration-300 ${isChatOpen ? 'rotate-180' : ''}`}>
            <svg className="w-6 h-6 text-gray-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 15l7-7 7 7" />
            </svg>
          </div>
        </div>
      </div>

      {/* Pull-Up Chat Container */}
      <div
        className={`fixed inset-x-0 bottom-0 z-40 bg-white rounded-t-2xl shadow-[0px_0px_20px_0px_rgba(0,0,0,0.15)] transform transition-all duration-300 ease-in-out flex flex-col ${isChatOpen ? 'translate-y-0' : 'translate-y-full'
          } ${isDragging ? 'transition-none' : ''}`}
        style={{
          height: `${chatHeight}vh`,
          paddingBottom: 'env(safe-area-inset-bottom)' // Handle iPhone bottom padding
        }}
      >
        {/* Drag Handle Bar */}
        <div
          className="flex justify-center pt-3 pb-2 flex-shrink-0 cursor-grab active:cursor-grabbing"
          onMouseDown={handleDragStart}
        >
          <div className="w-12 h-1 bg-gray-400 rounded-full hover:bg-gray-500 transition-colors"></div>
        </div>

        {/* Chat Header */}
        <div className="px-4 py-3 border-b border-gray-100 flex-shrink-0">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-3">
              <h3 className="font-semibold text-gray-900">{chatTitle}</h3>
            </div>
            <button
              onClick={() => setIsChatOpen(false)}
              className="p-2 hover:bg-gray-100 rounded-full transition-colors"
            >
              <svg className="w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          </div>
        </div>

        {/* Chat Content - Flexible container for messages and input */}
        <div className="flex-1 flex flex-col min-h-0 overflow-hidden pb-16">
          <CopilotChat
            className="h-full flex flex-col"
            labels={{
              initial: initialLabel,
            }}
          />
        </div>
      </div>

      {/* Backdrop */}
      {isChatOpen && (
        <div
          className="fixed inset-0 z-30"
          onClick={() => setIsChatOpen(false)}
        />
      )}
    </>
  )
}

const VALID_IMAGE_NAMES = [
  "Osaka_Castle_Turret_Stone_Wall_Pine_Trees_Daytime.jpg",
  "Tokyo_Skyline_Night_Tokyo_Tower_Mount_Fuji_View.jpg",
  "Itsukushima_Shrine_Miyajima_Floating_Torii_Gate_Sunset_Long_Exposure.jpg",
  "Takachiho_Gorge_Waterfall_River_Lush_Greenery_Japan.jpg",
  "Bonsai_Tree_Potted_Japanese_Art_Green_Foliage.jpeg",
  "Shirakawa-go_Gassho-zukuri_Thatched_Roof_Village_Aerial_View.jpg",
  "Ginkaku-ji_Silver_Pavilion_Kyoto_Japanese_Garden_Pond_Reflection.jpg",
  "Senso-ji_Temple_Asakusa_Cherry_Blossoms_Kimono_Umbrella.jpg",
  "Cherry_Blossoms_Sakura_Night_View_City_Lights_Japan.jpg",
  "Mount_Fuji_Lake_Reflection_Cherry_Blossoms_Sakura_Spring.jpg"
];

function getRandomImage(): string {
  return VALID_IMAGE_NAMES[Math.floor(Math.random() * VALID_IMAGE_NAMES.length)];
}

const validateAndCorrectImageNames = (rawNames: string[] | undefined): string[] | null => {
  if (!rawNames || rawNames.length !== 3) {
    return null;
  }

  const correctedNames: string[] = [];
  const usedValidNames = new Set<string>();

  for (const name of rawNames) {
    if (VALID_IMAGE_NAMES.includes(name) && !usedValidNames.has(name)) {
      correctedNames.push(name);
      usedValidNames.add(name);
      if (correctedNames.length === 3) break;
    }
  }

  while (correctedNames.length < 3) {
    const nextImage = getRandomImage();
    if (!usedValidNames.has(nextImage)) {
      correctedNames.push(nextImage);
      usedValidNames.add(nextImage);
    }
  }

  return correctedNames.slice(0, 3);
};

function HaikuCard({ generatedHaiku, setHaikus, haikus }: HaikuCardProps) {
  return (
    <div
      data-testid="haiku-card"
      className="suggestion-card text-left rounded-md p-4 mt-4 mb-4 flex flex-col bg-gray-100">
      <div className="mb-4 pb-4">
        {generatedHaiku?.japanese?.map((line, index) => (
          <div className="flex items-center gap-3 mb-2" data-testid="haiku-line" key={index}>
            <p className="text-lg font-bold">{line}</p>
            <p className="text-sm font-light">
              {generatedHaiku.english?.[index]}
            </p>
          </div>
        ))}
        {generatedHaiku?.japanese && generatedHaiku.japanese.length >= 2 && (
          <div className="mt-3 flex gap-2 justify-between w-full suggestion-image-container">
            {(() => {
              const firstLine = generatedHaiku?.japanese?.[0];
              if (!firstLine) return null;
              const haikuIndex = haikus.findIndex((h: any) => h.japanese[0] === firstLine);
              const haiku = haikus[haikuIndex];
              if (!haiku?.image_names) return null;

              return haiku.image_names.map((imageName, imgIndex) => (
                <img
                  key={haikus.length + "_" + imageName}
                  src={`/images/${imageName}`}
                  alt={imageName}
                  tabIndex={0}
                  className={`${haiku.selectedImage === imageName ? "suggestion-card-image-focus" : "suggestion-card-image"}`}
                  onClick={() => {
                    setHaikus(prevHaikus => {
                      const newHaikus = prevHaikus.map((h, idx) => {
                        if (idx === haikuIndex) {
                          return {
                            ...h,
                            selectedImage: imageName
                          };
                        }
                        return h;
                      });
                      return newHaikus;
                    });
                  }}
                />
              ));
            })()}
          </div>
        )}
      </div>
    </div>
  );
}

interface Haiku {
  japanese: string[];
  english: string[];
  image_names: string[];
  selectedImage: string | null;
}

function Haiku() {
  const [haikus, setHaikus] = useState<Haiku[]>([{
    japanese: ["仮の句よ", "まっさらながら", "花を呼ぶ"],
    english: [
      "A placeholder verse—",
      "even in a blank canvas,",
      "it beckons flowers.",
    ],
    image_names: [],
    selectedImage: null,
  }])
  const [activeIndex, setActiveIndex] = useState(0);
  const [isJustApplied, setIsJustApplied] = useState(false);

  useCopilotAction({
    name: "generate_haiku",
    parameters: [
      {
        name: "japanese",
        type: "string[]",
      },
      {
        name: "english",
        type: "string[]",
      },
      {
        name: "image_names",
        type: "string[]",
        description: `Names of 3 relevant images selected from the following: \n  -${VALID_IMAGE_NAMES.join('\n  -')}`,
      },
    ],
    followUp: false,
    handler: async ({ japanese, english, image_names }: { japanese: string[], english: string[], image_names: string[] }) => {
      const finalCorrectedImages = validateAndCorrectImageNames(image_names);
      const newHaiku = {
        japanese: japanese || [],
        english: english || [],
        image_names: finalCorrectedImages || [],
        selectedImage: finalCorrectedImages?.[0] || null,
      };
      setHaikus(prev => [newHaiku, ...prev].filter(h => h.english[0] !== "A placeholder verse—"));
      setActiveIndex(haikus.length - 1);
      setIsJustApplied(true);
      setTimeout(() => setIsJustApplied(false), 600);
      return "Haiku generated.";
    },
    render: ({ args: generatedHaiku }: { args: Partial<GenerateHaiku> }) => {
      return (
        <HaikuCard generatedHaiku={generatedHaiku} setHaikus={setHaikus} haikus={haikus} />
      );
    },
  }, [haikus]);

  const { isMobile } = useMobileView();

  return (
    <div className="flex h-full w-full">
      <Thumbnails haikus={haikus} activeIndex={activeIndex} setActiveIndex={setActiveIndex} isMobile={isMobile} />

      {/* Main Display */}
      <div className={`flex-1 flex items-center justify-center h-full ${isMobile
        ? 'px-6'
        : 'p-8'
        }`} style={{ marginLeft: isMobile ? '0' : '-48px' }}>
        <div className="haiku-stack w-full max-w-lg">
          {haikus.map((haiku, index) => (
            (haikus.length == 1 || index == activeIndex) && (

              <div
                key={index}
                data-testid="main-haiku-display"
                className={`haiku-card animated-fade-in ${isJustApplied && index === activeIndex ? 'applied-flash' : ''} ${index === activeIndex ? 'active' : ''}`}
                style={{
                  zIndex: index === activeIndex ? haikus.length : index,
                  transform: `translateY(${index === activeIndex ? '0' : `${(index - activeIndex) * 20}px`}) scale(${index === activeIndex ? '1' : '0.95'})`,
                }}
              >
                {haiku.japanese.map((line, lineIndex) => (
                  <div
                    data-testid="main-haiku-line"
                    className={`flex items-start mb-4 haiku-line ${isMobile
                      ? 'flex-col gap-1'
                      : 'gap-4'
                      }`}
                    key={lineIndex}
                    style={{ animationDelay: `${lineIndex * 0.1}s` }}
                  >
                    <p className={`font-bold text-gray-600 w-auto ${isMobile
                      ? 'text-2xl leading-tight'
                      : 'text-4xl'
                      }`}>
                      {line}
                    </p>
                    <p className={`font-light text-gray-500 w-auto ${isMobile
                      ? 'text-sm ml-2'
                      : 'text-base'
                      }`}>
                      {haiku.english?.[lineIndex]}
                    </p>
                  </div>
                ))}
                {haiku.image_names && haiku.image_names.length === 3 && (
                  <div className={`flex justify-center ${isMobile
                    ? 'mt-4 gap-2 flex-wrap'
                    : 'mt-6 gap-4'
                    }`}>
                    {haiku.image_names.map((imageName, imgIndex) => (
                      <img
                        key={imageName}
                        src={`/images/${imageName}`}
                        alt={imageName || ""}
                        style={{
                          width: isMobile ? '90px' : '130px',
                          height: isMobile ? '90px' : '130px',
                          objectFit: 'cover',
                          marginTop: 0,
                        }}
                        className={(haiku.selectedImage === imageName) ? `suggestion-card-image-focus ` : `haiku-card-image`}
                        onClick={() => setHaikus((prevHaikus) => {
                          return prevHaikus.map((h, idx) => {
                            if (idx === index) {
                              return { ...h, selectedImage: imageName }
                            } else {
                              return { ...h }
                            }
                          })
                        })}
                      />
                    ))}
                  </div>
                )}
              </div>
            )
          ))}
        </div>
      </div>
    </div>
  );
}

function Thumbnails({ haikus, activeIndex, setActiveIndex, isMobile }: { haikus: Haiku[], activeIndex: number, setActiveIndex: (index: number) => void, isMobile: boolean }) {
  if (haikus.length == 0 || isMobile) { return null }
  return (
    <div className="w-40 p-4 border-r border-gray-200 overflow-y-auto overflow-x-hidden">
      {haikus.map((haiku, index) => (
        <div
          key={index}
          data-testid="thumbnail-haiku"
          className={`haiku-card animated-fade-in mb-4 cursor-pointer ${index === activeIndex ? 'active' : ''}`}
          style={{
            width: '80px',
            transform: 'scale(0.2)',
            transformOrigin: 'top left',
            marginBottom: '-340px',
            opacity: index === activeIndex ? 1 : 0.5,
            transition: 'opacity 0.2s',
          }}
          onClick={() => setActiveIndex(index)}
        >
          {haiku.japanese.map((line, lineIndex) => (
            <div
              className="flex items-start gap-2 mb-2 haiku-line"
              key={lineIndex}
            >
              <p className="text-2xl font-bold text-gray-600 w-auto">{line}</p>
              <p className="text-xs font-light text-gray-500 w-auto">{haiku.english?.[lineIndex]}</p>
            </div>
          ))}
          {haiku.image_names && haiku.image_names.length === 3 && (
            <div className="mt-2 flex gap-2 justify-center">
              {haiku.image_names.map((imageName, imgIndex) => (
                <img
                  style={{
                    width: '110px',
                    height: '110px',
                    objectFit: 'cover',
                  }}
                  key={imageName}
                  src={`/images/${imageName}`}
                  alt={imageName || ""}
                  className="haiku-card-image w-12 h-12 object-cover"
                />
              ))}
            </div>
          )}
        </div>
      ))}
    </div>
  )

}


================================================
FILE: typescript-sdk/apps/dojo/src/app/[integrationId]/feature/tool_based_generative_ui/style.css
================================================
.copilotKitWindow {
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.copilotKitHeader {
  border-top-left-radius: 5px !important;
}

.page-background {
  /* Darker gradient background */
  background: linear-gradient(170deg, #e9ecef 0%, #ced4da 100%);
}

@keyframes fade-scale-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.98);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

/* Updated card entry animation */
@keyframes pop-in {
  0% {
    opacity: 0;
    transform: translateY(15px) scale(0.95);
  }
  70% {
    opacity: 1;
    transform: translateY(-2px) scale(1.02);
  }
  100% {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

/* Animation for subtle background gradient movement */
@keyframes animated-gradient {
  0% {
    background-position: 0% 50%;
  }
  50% {
    background-position: 100% 50%;
  }
  100% {
    background-position: 0% 50%;
  }
}

/* Animation for flash effect on apply */
@keyframes flash-border-glow {
  0% {
    /* Start slightly intensified */
    border-top-color: #ff5b4a !important;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.07),
    inset 0 1px 2px rgba(0, 0, 0, 0.01),
    0 0 25px rgba(255, 91, 74, 0.5);
  }
  50% {
    /* Peak intensity */
    border-top-color: #ff4733 !important;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.08),
    inset 0 1px 2px rgba(0, 0, 0, 0.01),
    0 0 35px rgba(255, 71, 51, 0.7);
  }
  100% {
    /* Return to default state appearance */
    border-top-color: #ff6f61 !important;
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.07),
    inset 0 1px 2px rgba(0, 0, 0, 0.01),
    0 0 10px rgba(255, 111, 97, 0.15);
  }
}

/* Existing animation for haiku lines */
@keyframes fade-slide-in {
  from {
    opacity: 0;
    transform: translateX(-15px);
  }
  to {
    opacity: 1;
    transform: translateX(0);
  }
}

.animated-fade-in {
  /* Use the new pop-in animation */
  animation: pop-in 0.6s ease-out forwards;
}

.haiku-card {
  /* Subtle animated gradient background */
  background: linear-gradient(120deg, #ffffff 0%, #fdfdfd 50%, #ffffff 100%);
  background-size: 200% 200%;
  animation: animated-gradient 10s ease infinite;

  /* === Explicit Border Override Attempt === */
  /* 1. Set the default grey border for all sides */
  border: 1px solid #dee2e6;

  /* 2. Explicitly override the top border immediately after */
  border-top: 10px solid #ff6f61 !important; /* Orange top - Added !important */
  /* === End Explicit Border Override Attempt === */

  padding: 2.5rem 3rem;
  border-radius: 20px;

  /* Default glow intensity */
  box-shadow: 0 10px 30px rgba(0, 0, 0, 0.07),
  inset 0 1px 2px rgba(0, 0, 0, 0.01),
  0 0 15px rgba(255, 111, 97, 0.25);
  text-align: left;
  max-width: 745px;
  margin: 3rem auto;
  min-width: 600px;

  /* Transition */
  transition: transform 0.35s ease, box-shadow 0.35s ease, border-top-width 0.35s ease, border-top-color 0.35s ease;
}

.haiku-card:hover {
  transform: translateY(-8px) scale(1.03);
  /* Enhanced shadow + Glow */
  box-shadow: 0 15px 35px rgba(0, 0, 0, 0.1),
  inset 0 1px 2px rgba(0, 0, 0, 0.01),
  0 0 25px rgba(255, 91, 74, 0.5);
  /* Modify only top border properties */
  border-top-width: 14px !important; /* Added !important */
  border-top-color: #ff5b4a !important; /* Added !important */
}

.haiku-card .flex {
  margin-bottom: 1.5rem;
}

.haiku-card .flex.haiku-line { /* Target the lines specifically */
  margin-bottom: 1.5rem;
  opacity: 0; /* Start hidden for animation */
  animation: fade-slide-in 0.5s ease-out forwards;
  /* animation-delay is set inline in page.tsx */
}

/* Remove previous explicit color overrides - rely on Tailwind */
/* .haiku-card p.text-4xl {
  color: #212529;
}

.haiku-card p.text-base {
  color: #495057;
} */

.haiku-card.applied-flash {
  /* Apply the flash animation once */
  /* Note: animation itself has !important on border-top-color */
  animation: flash-border-glow 0.6s ease-out forwards;
}

/* Styling for images within the main haiku card */
.haiku-card-image {
  width: 9.5rem; /* Increased size (approx w-48) */
  height: 9.5rem; /* Increased size (approx h-48) */
  object-fit: cover;
  border-radius: 1.5rem; /* rounded-xl */
  border: 1px solid #e5e7eb;
  /* Enhanced shadow with subtle orange hint */
  box-shadow: 0 8px 15px rgba(0, 0, 0, 0.1),
  0 3px 6px rgba(0, 0, 0, 0.08),
  0 0 10px rgba(255, 111, 97, 0.2);
  /* Inherit animation delay from inline style */
  animation-name: fadeIn;
  animation-duration: 0.5s;
  animation-fill-mode: both;
}

/* Styling for images within the suggestion card */
.suggestion-card-image {
  width: 6.5rem; /* Increased slightly (w-20) */
  height: 6.5rem; /* Increased slightly (h-20) */
  object-fit: cover;
  border-radius: 1rem; /* Equivalent to rounded-md */
  border: 1px solid #d1d5db; /* Equivalent to border (using Tailwind gray-300) */
  margin-top: 0.5rem;
  /* Added shadow for suggestion images */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1),
  0 2px 4px rgba(0, 0, 0, 0.06);
  transition: all 0.2s ease-in-out; /* Added for smooth deselection */
}

/* Styling for the focused suggestion card image */
.suggestion-card-image-focus {
  width: 6.5rem;
  height: 6.5rem;
  object-fit: cover;
  border-radius: 1rem;
  margin-top: 0.5rem;
  /* Highlight styles */
  border: 2px solid #ff6f61; /* Thicker, themed border */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1), /* Base shadow for depth */
  0 0 12px rgba(255, 111, 97, 0.6); /* Orange glow */
  transform: scale(1.05); /* Slightly scale up */
  transition: all 0.2s ease-in-out; /* Smooth transition for focus */
}

/* Styling for the suggestion card container in the sidebar */
.suggestion-card {
  border: 1px solid #dee2e6; /* Same default border as haiku-card */
  border-top: 10px solid #ff6f61; /* Same orange top border */
  border-radius: 0.375rem; /* Default rounded-md */
  /* Note: background-color is set by Tailwind bg-gray-100 */
  /* Other styles like padding, margin, flex are handled by Tailwind */
}

.suggestion-image-container {
  display: flex;
  gap: 1rem;
  justify-content: space-between;
  width: 100%;
  height: 6.5rem;
}

/* Mobile responsive styles - matches useMobileView hook breakpoint */
@media (max-width: 767px) {
  .haiku-card {
    padding: 1rem 1.5rem; /* Reduced from 2.5rem 3rem */
    min-width: auto; /* Remove min-width constraint */
    max-width: 100%; /* Full width on mobile */
    margin: 1rem auto; /* Reduced margin */
  }

  .haiku-card-image {
    width: 5.625rem; /* 90px - smaller on mobile */
    height: 5.625rem; /* 90px - smaller on mobile */
  }

  .suggestion-card-image {
    width: 5rem; /* Slightly smaller on mobile */
    height: 5rem; /* Slightly smaller on mobile */
  }

  .suggestion-card-image-focus {
    width: 5rem; /* Slightly smaller on mobile */
    height: 5rem; /* Slightly smaller on mobile */
  }
}



================================================
FILE: typescript-sdk/apps/dojo/src/app/api/copilotkit/[integrationId]/route.ts
================================================
import {
  CopilotRuntime,
  ExperimentalEmptyAdapter,
  copilotRuntimeNextJSAppRouterEndpoint,
} from "@copilotkit/runtime";
import { agentsIntegrations } from "@/agents";

import { NextRequest } from "next/server";

export async function POST(request: NextRequest) {
  const integrationId = request.url.split("/").pop();

  const integration = agentsIntegrations.find((i) => i.id === integrationId);
  if (!integration) {
    return new Response("Integration not found", { status: 404 });
  }
  const agents = await integration.agents();
  const runtime = new CopilotRuntime({
    // @ts-ignore for now
    agents,
  });
  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
    runtime,
    serviceAdapter: new ExperimentalEmptyAdapter(),
    endpoint: `/api/copilotkit/${integrationId}`,
  });

  return handleRequest(request);
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/theme-provider.tsx
================================================
"use client";

import * as React from "react";
import { ThemeProvider as NextThemesProvider, ThemeProviderProps as NextThemeProviderProps } from "next-themes";

export function ThemeProvider({ children, ...props }: NextThemeProviderProps) {
  return <NextThemesProvider {...props}>{children}</NextThemesProvider>;
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/code-viewer/code-editor.tsx
================================================
import React from "react";
import Editor from "@monaco-editor/react";
import { useTheme } from "next-themes";
import { FeatureFile } from "@/types/feature";
interface CodeEditorProps {
  file?: FeatureFile;
  onFileChange?: (fileName: string, content: string) => void;
}

export function CodeEditor({ file, onFileChange }: CodeEditorProps) {
  const handleEditorChange = (value: string | undefined) => {
    if (value && onFileChange) {
      onFileChange(file!.name, value);
    }
  };

  const theme = useTheme();

  return file ? (
    <div className="h-full flex flex-col">
      <Editor
        height="100%"
        language={file.language}
        value={file.content}
        onChange={handleEditorChange}
        options={{
          minimap: { enabled: false },
          fontSize: 16,
          lineNumbers: "on",
          readOnly: true,
          wordWrap: "on",
          stickyScroll: {
            enabled: false,
          },
        }}
        theme="vs-dark"
      />
    </div>
  ) : (
    <div className="p-6 text-center text-muted-foreground">
      Select a file from the file tree to view its code
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/code-viewer/code-viewer.tsx
================================================
import { useMemo, useState } from "react";
import { FileTree } from "@/components/file-tree/file-tree";
import { CodeEditor } from './code-editor'
import { FeatureFile } from "@/types/feature";
import { useURLParams } from "@/contexts/url-params-context";

export default function CodeViewer({
  codeFiles
}: {
  codeFiles: FeatureFile[];
}) {
  const { file, setCodeFile } = useURLParams();

  const selectedFile = useMemo(() => (
    codeFiles.find(f => f.name === file) ?? codeFiles[0]
  ), [codeFiles, file])

  return (
    <div className="flex h-full">
      <div className="w-72 border-r flex flex-col bg-background">
        <div className="flex-1 overflow-auto">
          <FileTree
            files={codeFiles}
            selectedFile={selectedFile}
            onFileSelect={setCodeFile}
          />
        </div>
      </div>
      <div className="flex-1 h-full py-5 bg-[#1e1e1e]">
        {selectedFile ? (
          <div className="h-full">
            <CodeEditor
              file={selectedFile}
            />
          </div>
        ) : (
          <div className="flex items-center justify-center h-full text-muted-foreground">
            Select a file to view its content.
          </div>
        )}
      </div>
    </div>
  )
}


================================================
FILE: typescript-sdk/apps/dojo/src/components/demo-list/demo-list.tsx
================================================
import React from "react";
import { FeatureConfig } from "@/types/feature";
import { cn } from "@/lib/utils";
import { Badge } from "@/components/ui/badge";

interface DemoListProps {
  demos: FeatureConfig[];
  selectedDemo?: string;
  onSelect: (demoId: string) => void;
  llmSelector?: React.ReactNode;
}

export function DemoList({ demos, selectedDemo, onSelect, llmSelector }: DemoListProps) {
  return (
    <div className="h-full">
      <div className="px-4 pt-3 pb-2">
        <h2
          className={cn(
            "transition-all duration-300 ease-in-out inline-block whitespace-nowrap paragraphs-Small-Regular-Uppercase text-[10px] text-palette-text-secondary opacity-100 scale-100 w-fit",
          )}
        >
          Demos
        </h2>
        {llmSelector && <div className="mt-2">{llmSelector}</div>}
      </div>
      <ul className="px-2 space-y-1">
        {demos.map((demo) => (
          <li key={demo.id}>
            <button
              className={cn(
                "w-full text-left py-2 px-3 rounded-sm hover:bg-white/50 transition-colors",
                "flex flex-col gap-0.5",
                selectedDemo === demo.id && "bg-white/70",
              )}
              onClick={() => onSelect(demo.id)}
            >
              <div className="text-sm font-medium leading-tight">{demo.name}</div>
              <div className="text-xs text-muted-foreground line-clamp-2 leading-relaxed">
                {demo.description}
              </div>
              {demo.tags && demo.tags.length > 0 && (
                <div className="flex gap-1 flex-wrap mt-0.5">
                  {demo.tags.map((tag) => (
                    <Badge
                      key={tag}
                      className={cn(
                        "text-xs px-1.5 py-0.5 rounded-full bg-white/65 text-primary",
                        selectedDemo === demo.id &&
                        "bg-primary text-primary-foreground border-transparent",
                      )}
                    >
                      {tag}
                    </Badge>
                  ))}
                </div>
              )}
            </button>
          </li>
        ))}
      </ul>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/file-tree/file-tree-nav.tsx
================================================
import React from "react";
import { ChevronRight, FolderOpen } from "lucide-react";
import { Button } from "@/components/ui/button";
import { cn } from "@/lib/utils";
import { relative } from "path";

interface FileTreeNavProps {
  path: string;
  rootPath: string; // The demo's root path
  onNavigate?: (path: string) => void;
}

export function FileTreeNav({ path, rootPath, onNavigate }: FileTreeNavProps) {
  const folderName = rootPath.split("/").pop();

  return (
    <div className="flex items-center gap-1 p-2 text-sm border-b overflow-x-auto">
      <Button variant="ghost" size="sm" className="h-6 px-2" onClick={() => onNavigate?.(rootPath)}>
        <FolderOpen className="h-4 w-4" />
      </Button>
      <Button
        variant="ghost"
        size="sm"
        className={cn("h-6 px-2 truncate", "font-medium text-foreground")}
      >
        {folderName}
      </Button>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/file-tree/file-tree.tsx
================================================
import React from "react";
import { ChevronDown, ChevronRight, File, Folder } from "lucide-react";
import { cn } from "@/lib/utils";
import { FeatureFile } from "@/types/feature";

interface FileTreeProps {
  files: FeatureFile[];
  onFileSelect: (fileName: string) => void;
  selectedFile?: FeatureFile;
}

function FileTreeNode({
  entry,
  depth = 0,
  onFileSelect,
  selectedFileName,
}: {
  entry: FeatureFile;
  depth?: number;
  onFileSelect: (fileName: string) => void;
  selectedFileName?: string;
}) {
  const [isOpen, setIsOpen] = React.useState(true);
  const isDirectory = entry.type === "directory";
  const isSelected = entry.name === selectedFileName;

  return (
    <div className={cn("relative", depth > 0 && "pl-2")}>
      {depth > 0 && <div className="absolute left-0 top-0 h-full w-px bg-border" />}
      <button
        className={cn(
          "flex w-full items-center gap-2 rounded-sm px-2 py-1 text-sm hover:bg-accent/50",
          isSelected && "bg-accent",
          depth === 1 && "ml-0.5",
          depth === 2 && "ml-1",
          depth === 3 && "ml-1.5",
          depth === 4 && "ml-2",
          depth > 4 && "ml-2.5",
        )}
        onClick={() => {
          if (isDirectory) {
            setIsOpen(!isOpen);
          } else {
            onFileSelect(entry.name);
          }
        }}
      >
        {isDirectory ? (
          <>
            {isOpen ? <ChevronDown className="h-4 w-4" /> : <ChevronRight className="h-4 w-4" />}
            <Folder className="h-4 w-4" />
          </>
        ) : (
          <>
            <span className="w-4" />
            <File className="h-4 w-4" />
          </>
        )}
        <span className="truncate">{entry.name}</span>
      </button>
    </div>
  );
}

export function FileTree({ files, onFileSelect, selectedFile }: FileTreeProps) {
  return (
    <div className="p-2">
      {files.map((entry) => (
        <FileTreeNode
          key={entry.name}
          entry={entry}
          onFileSelect={onFileSelect}
          selectedFileName={selectedFile?.name}
        />
      ))}
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/layout/main-layout.tsx
================================================
"use client";

import React, { Suspense, useState, useEffect } from "react";
import { ViewerLayout } from "@/components/layout/viewer-layout";
import { Sidebar } from "@/components/sidebar/sidebar";
import { Menu, X } from "lucide-react";
import { Button } from "@/components/ui/button";

import { useURLParams } from "@/contexts/url-params-context";
import { getTitleForCurrentDomain } from "@/utils/domain-config";

export function MainLayout({ children }: { children: React.ReactNode }) {
  const [isMobileSidebarOpen, setIsMobileSidebarOpen] = useState(false);
  const [isMobile, setIsMobile] = useState(false);

  // Check if we're on mobile
  useEffect(() => {
    const checkMobile = () => {
      const mobile = window.innerWidth < 768; // md breakpoint
      setIsMobile(mobile);
      // Auto-close sidebar when switching to desktop
      if (!mobile) {
        setIsMobileSidebarOpen(false);
      }
    };

    // Initial check
    if (typeof window !== 'undefined') {
      checkMobile();
    }

    // Listen for resize events
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  const toggleMobileSidebar = () => {
    setIsMobileSidebarOpen(!isMobileSidebarOpen);
  };

  return (
    <ViewerLayout>
      <div className="flex h-full w-full overflow-hidden relative gap-2">
        {/* Mobile Header with Hamburger Menu */}
        {isMobile && (
          <div className="absolute top-0 left-0 right-0 z-50 bg-background border-b p-2 md:hidden">
            <div className="flex items-center justify-between">
              <Button
                variant="ghost"
                size="sm"
                onClick={toggleMobileSidebar}
                className="p-2"
              >
                {isMobileSidebarOpen ? <X className="h-5 w-5" /> : <Menu className="h-5 w-5" />}
              </Button>
              <h1 className="text-sm font-medium text-center flex-1">{getTitleForCurrentDomain() || "AG-UI Dojo"}</h1>
              <div className="w-9" /> {/* Spacer for centering */}
            </div>
          </div>
        )}

        {/* Mobile Overlay */}
        {isMobile && isMobileSidebarOpen && (
          <div
            className="absolute inset-0 bg-black/50 z-40 md:hidden"
            onClick={toggleMobileSidebar}
          />
        )}
        {/* Sidebar */}
        <Suspense>
          <MaybeSidebar
            isMobile={isMobile}
            isMobileSidebarOpen={isMobileSidebarOpen}
            onMobileClose={() => setIsMobileSidebarOpen(false)}
          />
        </Suspense>

        {/* Content */}
        <div className={`flex-1 overflow-auto ${isMobile ? 'pt-12' : ''}`}>
          <div className="h-full">{children}</div>
        </div>
      </div>
    </ViewerLayout>
  );
}

interface MaybeSidebarProps {
  isMobile: boolean;
  isMobileSidebarOpen: boolean;
  onMobileClose: () => void;
}

function MaybeSidebar({ isMobile, isMobileSidebarOpen, onMobileClose }: MaybeSidebarProps) {
  const { sidebarHidden } = useURLParams();

  // Don't render sidebar if disabled by query param
  if (sidebarHidden) return null;

  // On mobile, only show if open
  if (isMobile && !isMobileSidebarOpen) return null;

  return (
    <div className={`
      ${isMobile
        ? 'absolute left-0 top-0 z-50 h-full w-80 transform transition-transform duration-300 ease-in-out'
        : 'relative'
      }
    `}>
      <Sidebar
        isMobile={isMobile}
        onMobileClose={onMobileClose}
      />
    </div>
  );
}


================================================
FILE: typescript-sdk/apps/dojo/src/components/layout/viewer-layout.tsx
================================================
import React from "react";
import { ViewerConfig } from "@/types/feature";
import { cn } from "@/lib/utils";
import { useMobileView } from "@/utils/use-mobile-view";

interface ViewerLayoutProps extends ViewerConfig {
  className?: string;
  children?: React.ReactNode;
  codeEditor?: React.ReactNode;
  fileTree?: React.ReactNode;
  sidebarHeader?: React.ReactNode;
}

export function ViewerLayout({
  className,
  children,
}: ViewerLayoutProps) {
  const { isMobile } = useMobileView();

  return (
    <div className={cn("relative flex h-screen overflow-hidden bg-palette-surface-main", className, {
      "p-spacing-2": !isMobile,
    })}>
      <div className="flex flex-1 overflow-hidden z-1">
        <main className="flex-1 overflow-auto">
          <div className="h-full">{children}</div>
        </main>
      </div>
      {/* Background blur circles - Figma exact specs */}
      {/* Ellipse 1351 */}
      <div className="absolute w-[445.84px] h-[445.84px] left-[1040px] top-[11px] rounded-full z-0" 
           style={{ background: 'rgba(255, 172, 77, 0.2)', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1347 */}
      <div className="absolute w-[609.35px] h-[609.35px] left-[1338.97px] top-[624.5px] rounded-full z-0"
           style={{ background: '#C9C9DA', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1350 */}
      <div className="absolute w-[609.35px] h-[609.35px] left-[670px] top-[-365px] rounded-full z-0"
           style={{ background: '#C9C9DA', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1348 */}
      <div className="absolute w-[609.35px] h-[609.35px] left-[507.87px] top-[702.14px] rounded-full z-0"
           style={{ background: '#F3F3FC', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1346 */}
      <div className="absolute w-[445.84px] h-[445.84px] left-[127.91px] top-[331px] rounded-full z-0"
           style={{ background: 'rgba(255, 243, 136, 0.3)', filter: 'blur(103.196px)' }} />
      
      {/* Ellipse 1268 */}
      <div className="absolute w-[445.84px] h-[445.84px] left-[-205px] top-[802.72px] rounded-full z-0"
           style={{ background: 'rgba(255, 172, 77, 0.2)', filter: 'blur(103.196px)' }} />
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/readme/readme.tsx
================================================
"use client";

import { MDXRenderer } from "@/utils/mdx-utils";

export default function Readme({ content }: { content: string }) {
  return (
    <div className="flex-1 h-screen w-full flex flex-col items-center justify-start pt-24 px-8">
      <div className="w-full max-w-4xl">{<MDXRenderer content={content} />}</div>
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/sidebar/sidebar.tsx
================================================
"use client";

import React, { useState, useEffect } from "react";
import { EyeIcon as Eye, CodeIcon as Code, BookOpenTextIcon as Book } from "@phosphor-icons/react";
import { cn } from "@/lib/utils";
import { useRouter, usePathname } from "next/navigation";
import { DemoList } from "@/components/demo-list/demo-list";
import { ThemeToggle } from "@/components/ui/theme-toggle";
import { ChevronDown } from "lucide-react";
import featureConfig from "@/config";
import {
  DropdownMenu,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuItem,
} from "../ui/dropdown-menu";
import { Tabs, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { Button } from "../ui/button";
import { menuIntegrations } from "@/menu";
import { Feature } from "@/types/integration";
import { useURLParams } from "@/contexts/url-params-context";
import { View } from "@/types/interface";
import { getTitleForCurrentDomain } from "@/utils/domain-config";
import { useTheme } from "next-themes";

interface SidebarProps {
  isMobile?: boolean;
  onMobileClose?: () => void;
}

export function Sidebar({ isMobile, onMobileClose }: SidebarProps) {
  const router = useRouter();
  const pathname = usePathname();
  const { theme, setTheme } = useTheme();
  const isDarkTheme = theme === "dark"
  const { view, frameworkPickerHidden, viewPickerHidden, featurePickerHidden, setView} = useURLParams();

  // Extract the current integration ID from the pathname
  const pathParts = pathname.split("/");
  const currentIntegrationId = pathParts[1]; // First segment after root
  const currentDemoId = pathParts[pathParts.length - 1];

  // Find the current integration (only if we have a valid integration ID)
  const currentIntegration =
    currentIntegrationId && currentIntegrationId !== ""
      ? menuIntegrations.find((integration) => integration.id === currentIntegrationId)
      : null;

  // Filter demos based on current integration's features
  const filteredDemos = currentIntegration
    ? featureConfig.filter((demo) =>
        currentIntegration.features.includes(demo.id as unknown as Feature),
      )
    : []; // Show no demos if no integration is selected

  // Handle selecting a demo
  const handleDemoSelect = (demoId: string) => {
    if (currentIntegration) {
      router.push(`/${currentIntegration.id}/feature/${demoId}`);
      // Close mobile sidebar when demo is selected
      if (isMobile && onMobileClose) {
        onMobileClose();
      }
    }
  };

  // Handle integration selection
  const handleIntegrationSelect = (integrationId: string) => {
    router.push(`/${integrationId}`);
  };

  const tabClass = `cursor-pointer flex-1 h-8 px-2 text-sm text-primary shadow-none bg-none border-none font-medium gap-1 rounded-lg data-[state=active]:bg-white data-[state=active]:text-primary data-[state=active]:shadow-none`

  return (
    <div className={`flex flex-col h-full border-2 border-palette-border-default
      ${isMobile ? 'w-80 shadow-xl bg-white z-99' : 'bg-white/50 w-74 min-w-[296px] flex-shrink-0 rounded-lg overflow-hidden'}
    `}>
      {/* Sidebar Header */}
      <div className="p-4">
        <div className="flex items-center justify-between ml-1">
          <div className="flex items-start flex-col">
            <h1 className={`text-lg font-light ${isDarkTheme ? "text-white" : "text-gray-900"}`}>
              {getTitleForCurrentDomain() || "AG-UI Interactive Dojo"}
            </h1>
          </div>

          {/*<ThemeToggle />*/}
        </div>
      </div>

      {/* Controls Section */}
      {(!frameworkPickerHidden|| !viewPickerHidden) && (
      <div className="p-4 border-b">
        {/* Integration picker */}
        {!frameworkPickerHidden&& (
          <div className="mb-spacing-4">
            <SectionTitle title="Integrations" />
            <DropdownMenu>
              <DropdownMenuTrigger asChild>
                <div className="flex items-center justify-between h-spacing-8 rounded-sm gap-spacing-2 px-spacing-3 transition-colors hover:bg-palette-surface-containerHovered cursor-pointer">
                  <span className="pb-[2px] text-palette-text-primary font-medium leading-[22px] inline-block truncate">
                    {currentIntegration ? currentIntegration.name : "Select Integration"}
                  </span>
                  <ChevronDown className="text-palette-icon-default transition-transform" size={16} />
                </div>
              </DropdownMenuTrigger>
              <DropdownMenuContent className="w-64 bg-palette-surface-container border-palette-border-container shadow-elevation-md">
                {menuIntegrations.map((integration) => (
                  <DropdownMenuItem
                    key={integration.id}
                    onClick={() => handleIntegrationSelect(integration.id)}
                    className="cursor-pointer hover:bg-palette-grey-200 text-palette-text-primary text-base h-10 rounded-sm"
                  >
                    <span>{integration.name}</span>
                  </DropdownMenuItem>
                ))}
              </DropdownMenuContent>
            </DropdownMenu>
          </div>
        )}

        {/* Preview/Code Tabs */}
        {!viewPickerHidden &&
        <div className="mb-1">
          <SectionTitle title="View" />
          <Tabs
            value={view}
            onValueChange={tab => setView(tab as View)}
            className="w-full rounded-lg bg-none border-none"
          >
            <TabsList className="w-full rounded-lg h-8 p-0 bg-transparent border-none">
              <TabsTrigger
                value="preview"
                className={tabClass}
              >
                <Eye className="h-3 w-3" />
                <span>Preview</span>
              </TabsTrigger>
              <TabsTrigger
                value="code"
                className={tabClass}
              >
                <Code className="h-3 w-3" />
                <span>Code</span>
              </TabsTrigger>
              <TabsTrigger
                value="readme"
                className={tabClass}
              >
                <Book className="h-3 w-3" />
                <span>Docs</span>
              </TabsTrigger>
            </TabsList>
          </Tabs>
        </div>
        }
      </div>
      )}

      {/* Demo List */}
      <div className="flex-1 overflow-auto">
        {(currentIntegration && !featurePickerHidden) ? (
          <DemoList
            demos={filteredDemos}
            selectedDemo={currentDemoId}
            onSelect={handleDemoSelect}
          />
        ) : (
          <div className="flex items-center justify-center h-full p-8">
            <p className="text-muted-foreground text-center"></p>
          </div>
        )}
      </div>
    </div>
  );
}

function SectionTitle({ title }: { title: string }) {
  return (
    <div
      className={cn(
        "items-center",
        "flex px-spacing-1 gap-spacing-2 mb-2",
      )}
    >
      <label
        className={cn(
          "transition-all duration-300 ease-in-out inline-block whitespace-nowrap paragraphs-Small-Regular-Uppercase text-[10px] text-palette-text-secondary opacity-100 scale-100 w-fit",
        )}
      >
        {title}
      </label>
      <div
        className={cn(
          "h-[1px] bg-palette-border-container transition-all duration-300 ease-[cubic-bezier(0.36,0.01,0.22,1)]",
          "w-full",
        )}
      />
    </div>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/badge.tsx
================================================
import * as React from "react";
import { Slot } from "@radix-ui/react-slot";
import { cva, type VariantProps } from "class-variance-authority";

import { cn } from "@/lib/utils";

const badgeVariants = cva(
  "inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden",
  {
    variants: {
      variant: {
        default: "border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90",
        destructive:
          "border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40",
        outline: "text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  },
);

function Badge({
  className,
  variant,
  asChild = false,
  ...props
}: React.ComponentProps<"span"> & VariantProps<typeof badgeVariants> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "span";

  return (
    <Comp data-slot="badge" className={cn(badgeVariants({ variant }), className)} {...props} />
  );
}

export { Badge, badgeVariants };



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/button.tsx
================================================
import * as React from "react";
import { Slot } from "@radix-ui/react-slot";
import { cva, type VariantProps } from "class-variance-authority";

import { cn } from "@/lib/utils";

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-[color,box-shadow] disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
  {
    variants: {
      variant: {
        default: "bg-primary text-primary-foreground shadow-xs hover:bg-primary/90",
        destructive:
          "bg-destructive text-white shadow-xs hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40",
        outline:
          "border border-input bg-background shadow-xs hover:bg-accent hover:text-accent-foreground",
        secondary: "bg-secondary text-secondary-foreground shadow-xs hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2 has-[>svg]:px-3",
        sm: "h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5",
        lg: "h-10 rounded-md px-6 has-[>svg]:px-4",
        icon: "size-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  },
);

function Button({
  className,
  variant,
  size,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> &
  VariantProps<typeof buttonVariants> & {
    asChild?: boolean;
  }) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      {...props}
    />
  );
}

export { Button, buttonVariants };



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/dropdown-menu.tsx
================================================
"use client";

import * as React from "react";
import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu";
import { CheckIcon, ChevronRightIcon, CircleIcon } from "lucide-react";

import { cn } from "@/lib/utils";

function DropdownMenu({ ...props }: React.ComponentProps<typeof DropdownMenuPrimitive.Root>) {
  return <DropdownMenuPrimitive.Root data-slot="dropdown-menu" {...props} />;
}

function DropdownMenuPortal({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Portal>) {
  return <DropdownMenuPrimitive.Portal data-slot="dropdown-menu-portal" {...props} />;
}

function DropdownMenuTrigger({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Trigger>) {
  return <DropdownMenuPrimitive.Trigger data-slot="dropdown-menu-trigger" {...props} />;
}

function DropdownMenuContent({
  className,
  sideOffset = 4,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Content>) {
  return (
    <DropdownMenuPrimitive.Portal>
      <DropdownMenuPrimitive.Content
        data-slot="dropdown-menu-content"
        sideOffset={sideOffset}
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 max-h-(--radix-dropdown-menu-content-available-height) min-w-[8rem] overflow-x-hidden overflow-y-auto rounded-md border p-1 shadow-md",
          className,
        )}
        {...props}
      />
    </DropdownMenuPrimitive.Portal>
  );
}

function DropdownMenuGroup({ ...props }: React.ComponentProps<typeof DropdownMenuPrimitive.Group>) {
  return <DropdownMenuPrimitive.Group data-slot="dropdown-menu-group" {...props} />;
}

function DropdownMenuItem({
  className,
  inset,
  variant = "default",
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Item> & {
  inset?: boolean;
  variant?: "default" | "destructive";
}) {
  return (
    <DropdownMenuPrimitive.Item
      data-slot="dropdown-menu-item"
      data-inset={inset}
      data-variant={variant}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[variant=destructive]:text-destructive-foreground data-[variant=destructive]:focus:bg-destructive/10 dark:data-[variant=destructive]:focus:bg-destructive/40 data-[variant=destructive]:focus:text-destructive-foreground data-[variant=destructive]:*:[svg]:!text-destructive-foreground [&_svg:not([class*='text-'])]:text-muted-foreground relative flex cursor-default items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 data-[inset]:pl-8 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function DropdownMenuCheckboxItem({
  className,
  children,
  checked,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.CheckboxItem>) {
  return (
    <DropdownMenuPrimitive.CheckboxItem
      data-slot="dropdown-menu-checkbox-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      checked={checked}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <DropdownMenuPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </DropdownMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </DropdownMenuPrimitive.CheckboxItem>
  );
}

function DropdownMenuRadioGroup({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.RadioGroup>) {
  return <DropdownMenuPrimitive.RadioGroup data-slot="dropdown-menu-radio-group" {...props} />;
}

function DropdownMenuRadioItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.RadioItem>) {
  return (
    <DropdownMenuPrimitive.RadioItem
      data-slot="dropdown-menu-radio-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <DropdownMenuPrimitive.ItemIndicator>
          <CircleIcon className="size-2 fill-current" />
        </DropdownMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </DropdownMenuPrimitive.RadioItem>
  );
}

function DropdownMenuLabel({
  className,
  inset,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Label> & {
  inset?: boolean;
}) {
  return (
    <DropdownMenuPrimitive.Label
      data-slot="dropdown-menu-label"
      data-inset={inset}
      className={cn("px-2 py-1.5 text-sm font-medium data-[inset]:pl-8", className)}
      {...props}
    />
  );
}

function DropdownMenuSeparator({
  className,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Separator>) {
  return (
    <DropdownMenuPrimitive.Separator
      data-slot="dropdown-menu-separator"
      className={cn("bg-border -mx-1 my-1 h-px", className)}
      {...props}
    />
  );
}

function DropdownMenuShortcut({ className, ...props }: React.ComponentProps<"span">) {
  return (
    <span
      data-slot="dropdown-menu-shortcut"
      className={cn("text-muted-foreground ml-auto text-xs tracking-widest", className)}
      {...props}
    />
  );
}

function DropdownMenuSub({ ...props }: React.ComponentProps<typeof DropdownMenuPrimitive.Sub>) {
  return <DropdownMenuPrimitive.Sub data-slot="dropdown-menu-sub" {...props} />;
}

function DropdownMenuSubTrigger({
  className,
  inset,
  children,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.SubTrigger> & {
  inset?: boolean;
}) {
  return (
    <DropdownMenuPrimitive.SubTrigger
      data-slot="dropdown-menu-sub-trigger"
      data-inset={inset}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex cursor-default items-center rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[inset]:pl-8",
        className,
      )}
      {...props}
    >
      {children}
      <ChevronRightIcon className="ml-auto size-4" />
    </DropdownMenuPrimitive.SubTrigger>
  );
}

function DropdownMenuSubContent({
  className,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.SubContent>) {
  return (
    <DropdownMenuPrimitive.SubContent
      data-slot="dropdown-menu-sub-content"
      className={cn(
        "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 min-w-[8rem] overflow-hidden rounded-md border p-1 shadow-lg",
        className,
      )}
      {...props}
    />
  );
}

export {
  DropdownMenu,
  DropdownMenuPortal,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuGroup,
  DropdownMenuLabel,
  DropdownMenuItem,
  DropdownMenuCheckboxItem,
  DropdownMenuRadioGroup,
  DropdownMenuRadioItem,
  DropdownMenuSeparator,
  DropdownMenuShortcut,
  DropdownMenuSub,
  DropdownMenuSubTrigger,
  DropdownMenuSubContent,
};



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/markdown-components.tsx
================================================
import React from "react";
import { cn } from "@/lib/utils";

export const MarkdownComponents = {
  // Header components
  h1: ({ className, children, ...props }: React.HTMLAttributes<HTMLHeadingElement>) => {
    return (
      <h1
        className={cn(
          "text-3xl font-bold mt-8 mb-6 text-gray-900 dark:text-gray-50 border-b pb-2",
          className,
        )}
        {...props}
      >
        {children}
      </h1>
    );
  },

  h2: ({ className, children, ...props }: React.HTMLAttributes<HTMLHeadingElement>) => {
    return (
      <h2
        className={cn("text-2xl font-bold mt-8 mb-4 text-gray-900 dark:text-gray-50", className)}
        {...props}
      >
        {children}
      </h2>
    );
  },

  h3: ({ className, children, ...props }: React.HTMLAttributes<HTMLHeadingElement>) => {
    return (
      <h3
        className={cn("text-xl font-bold mt-6 mb-3 text-gray-900 dark:text-gray-50", className)}
        {...props}
      >
        {children}
      </h3>
    );
  },

  // Paragraph component
  p: ({ className, children, ...props }: React.HTMLAttributes<HTMLParagraphElement>) => {
    return (
      <p
        className={cn("my-4 text-gray-700 dark:text-gray-300 leading-relaxed", className)}
        {...props}
      >
        {children}
      </p>
    );
  },

  // List components
  ul: ({ className, children, ...props }: React.HTMLAttributes<HTMLUListElement>) => {
    return (
      <ul className={cn("my-4 pl-6 list-disc space-y-2", className)} {...props}>
        {children}
      </ul>
    );
  },

  ol: ({ className, children, ...props }: React.HTMLAttributes<HTMLOListElement>) => {
    return (
      <ol className={cn("my-4 pl-6 list-decimal space-y-2", className)} {...props}>
        {children}
      </ol>
    );
  },

  li: ({ className, children, ...props }: React.HTMLAttributes<HTMLLIElement>) => {
    return (
      <li className={cn("text-gray-700 dark:text-gray-300 my-1", className)} {...props}>
        {children}
      </li>
    );
  },

  // Custom code block rendering
  code: ({ className, children, ...props }: React.HTMLAttributes<HTMLElement>) => {
    const match = /language-(\w+)/.exec(className || "");
    const language = match ? match[1] : "";

    // If it's an inline code block (no language specified and no line breaks)
    if (!match && typeof children === "string" && !children.includes("\n")) {
      return (
        <code
          className={cn(
            "bg-gray-100 dark:bg-gray-800 text-gray-800 dark:text-gray-200 px-1.5 py-0.5 rounded text-sm font-mono",
            className,
          )}
          {...props}
        >
          {children}
        </code>
      );
    }

    return (
      <div className="relative group my-6">
        {language && (
          <div className="absolute right-2 top-2 text-xs text-gray-500 dark:text-gray-400 font-mono bg-gray-100 dark:bg-gray-800 px-2 py-1 rounded">
            {language}
          </div>
        )}
        <pre
          className={cn(
            "p-4 rounded-lg overflow-x-auto border border-gray-200 dark:border-gray-700 bg-gray-100 dark:bg-gray-800",
            className,
          )}
        >
          <code {...props} className="text-sm font-mono">
            {children}
          </code>
        </pre>
      </div>
    );
  },

  // Custom link rendering
  a: ({ className, children, ...props }: React.AnchorHTMLAttributes<HTMLAnchorElement>) => {
    return (
      <a
        className={cn(
          "text-blue-600 dark:text-blue-400 font-medium underline underline-offset-2 hover:text-blue-800 dark:hover:text-blue-300 transition-colors",
          className,
        )}
        target="_blank"
        rel="noopener noreferrer"
        {...props}
      >
        {children}
      </a>
    );
  },

  // Custom table rendering
  table: ({ className, children, ...props }: React.TableHTMLAttributes<HTMLTableElement>) => {
    return (
      <div className="overflow-x-auto my-6">
        <table
          className={cn(
            "w-full border-collapse border border-gray-300 dark:border-gray-700",
            className,
          )}
          {...props}
        >
          {children}
        </table>
      </div>
    );
  },

  // Custom image rendering
  img: ({ className, alt, ...props }: React.ImgHTMLAttributes<HTMLImageElement>) => {
    return (
      <img
        className={cn("rounded-lg mx-auto my-6 max-w-full h-auto", className)}
        alt={alt || ""}
        {...props}
      />
    );
  },

  // Blockquote component
  blockquote: ({ className, children, ...props }: React.HTMLAttributes<HTMLQuoteElement>) => {
    return (
      <blockquote
        className={cn(
          "border-l-4 border-gray-300 dark:border-gray-700 pl-4 py-1 my-4 italic text-gray-700 dark:text-gray-300",
          className,
        )}
        {...props}
      >
        {children}
      </blockquote>
    );
  },

  // Horizontal rule
  hr: ({ className, ...props }: React.HTMLAttributes<HTMLHRElement>) => {
    return (
      <hr
        className={cn("my-8 border-t border-gray-300 dark:border-gray-700", className)}
        {...props}
      />
    );
  },

  // Strong/bold text
  strong: ({ className, children, ...props }: React.HTMLAttributes<HTMLElement>) => {
    return (
      <strong className={cn("font-bold text-gray-900 dark:text-white", className)} {...props}>
        {children}
      </strong>
    );
  },

  // Emphasis/italic text
  em: ({ className, children, ...props }: React.HTMLAttributes<HTMLElement>) => {
    return (
      <em className={cn("italic text-gray-800 dark:text-gray-200", className)} {...props}>
        {children}
      </em>
    );
  },
};



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/mdx-components.tsx
================================================
import React from "react";
import { cn } from "@/lib/utils";
import { MarkdownComponents } from "./markdown-components";
import type { Components } from "react-markdown";

// Video component specifically for MDX
export const VideoPlayer = ({
  src,
  width = "100%",
  className,
  ...props
}: React.VideoHTMLAttributes<HTMLVideoElement> & { src: string }) => {
  return (
    <div className="my-8">
      <video controls width={width} className={cn("rounded-lg w-full", className)} {...props}>
        <source src={src} type="video/mp4" />
        Your browser does not support the video tag.
      </video>
    </div>
  );
};

// Type definition for MDX components that includes our custom components
type CustomMDXComponents = Components & {
  Video: typeof VideoPlayer;
  video: typeof VideoPlayer;
};

// Combine all components for MDX
export const MDXComponents: CustomMDXComponents = {
  ...MarkdownComponents,
  // Custom components for MDX
  Video: VideoPlayer,
  video: VideoPlayer,
} as CustomMDXComponents;



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/tabs.tsx
================================================
"use client";

import * as React from "react";
import * as TabsPrimitive from "@radix-ui/react-tabs";

import { cn } from "@/lib/utils";

function Tabs({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.Root>) {
  return (
    <TabsPrimitive.Root data-slot="tabs" className={cn("flex flex-col", className)} {...props} />
  );
}

function TabsList({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.List>) {
  return (
    <TabsPrimitive.List
      data-slot="tabs-list"
      className={cn(
        "bg-muted text-muted-foreground inline-flex h-9 w-fit items-center justify-center rounded-lg p-1",
        className,
      )}
      {...props}
    />
  );
}

function TabsTrigger({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.Trigger>) {
  return (
    <TabsPrimitive.Trigger
      data-slot="tabs-trigger"
      className={cn(
        "data-[state=active]:bg-background data-[state=active]:text-foreground focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:outline-ring inline-flex flex-1 items-center justify-center gap-1.5 rounded-md px-2 py-1 text-sm font-medium whitespace-nowrap transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:shadow-sm [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function TabsContent({ className, ...props }: React.ComponentProps<typeof TabsPrimitive.Content>) {
  return (
    <TabsPrimitive.Content
      data-slot="tabs-content"
      className={cn("flex-1 outline-none", className)}
      {...props}
    />
  );
}

export { Tabs, TabsList, TabsTrigger, TabsContent };



================================================
FILE: typescript-sdk/apps/dojo/src/components/ui/theme-toggle.tsx
================================================
"use client";

import * as React from "react";
import { Moon, Sun } from "lucide-react";
import { useTheme } from "next-themes";

import { Button } from "@/components/ui/button";

export function ThemeToggle() {
  const { theme, setTheme } = useTheme();

  return (
    <Button
      variant="ghost"
      size="icon"
      onClick={() => setTheme(theme === "light" ? "dark" : "light")}
      className="h-8 w-8 px-0"
    >
      <Sun className="h-4 w-4 rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0" />
      <Moon className="absolute h-4 w-4 rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100" />
      <span className="sr-only">Toggle theme</span>
    </Button>
  );
}



================================================
FILE: typescript-sdk/apps/dojo/src/contexts/url-params-context.tsx
================================================
'use client';

import React, { createContext, useContext, useState, useEffect, ReactNode } from 'react';
import { useRouter, usePathname, useSearchParams } from 'next/navigation';
import { View } from "@/types/interface";

interface URLParamsState {
  view: View;
  sidebarHidden: boolean;
  frameworkPickerHidden: boolean;
  viewPickerHidden: boolean;
  featurePickerHidden: boolean;
  file?: string;
}

interface URLParamsContextType extends URLParamsState {
  setView: (view: View) => void;
  setSidebarHidden: (disabled: boolean) => void;
  setFrameworkPickerHidden: (disabled: boolean) => void;
  setViewPickerHidden: (disabled: boolean) => void;
  setFeaturePickerHidden: (disabled: boolean) => void;
  setCodeFile: (fileName: string) => void;
}

const URLParamsContext = createContext<URLParamsContextType | undefined>(undefined);

interface URLParamsProviderProps {
  children: ReactNode;
}

export function URLParamsProvider({ children }: URLParamsProviderProps) {
  const router = useRouter();
  const pathname = usePathname();
  const searchParams = useSearchParams();

  // Initialize state from URL params
  const [state, setState] = useState<URLParamsState>(() => ({
    view: (searchParams.get("view") as View) || "preview",
    sidebarHidden: searchParams.get("sidebar") === "false",
    frameworkPickerHidden: searchParams.get("frameworkPicker") === "false",
    viewPickerHidden: searchParams.get("viewPicker") === "false",
    featurePickerHidden: searchParams.get("featurePicker") === "false",
  }));

  // Update URL when state changes
  const updateURL = (newState: Partial<URLParamsState>) => {
    const params = new URLSearchParams(searchParams.toString());

    // Update view param
    if (newState.view !== undefined) {
      if (newState.view === "preview") {
        params.delete("view"); // Remove default value to keep URL clean
      } else {
        params.set("view", newState.view);
      }
    }

    // Update sidebar param
    if (newState.sidebarHidden !== undefined) {
      if (newState.sidebarHidden) {
        params.set("sidebar", "false");
      } else {
        params.delete("sidebar");
      }
    }

    // Update frameworkPicker param
    if (newState.frameworkPickerHidden !== undefined) {
      if (newState.frameworkPickerHidden) {
        params.set("frameworkPicker", "false");
      } else {
        params.delete("frameworkPicker");
      }
    }

    // Update viewPicker param
    if (newState.viewPickerHidden !== undefined) {
      if (newState.viewPickerHidden) {
        params.set("viewPicker", "false");
      } else {
        params.delete("viewPicker");
      }
    }
    // Update featurePicker param
    if (newState.featurePickerHidden !== undefined) {
      if (newState.featurePickerHidden) {
        params.set("featurePicker", "false");
      } else {
        params.delete("features");
      }
    }

    const queryString = params.toString();
    router.push(pathname + (queryString ? '?' + queryString : ''));
  };

  // Sync state with URL changes (e.g., browser back/forward)
  useEffect(() => {
    const newState: URLParamsState = {
      view: (searchParams.get("view") as View) || "preview",
      sidebarHidden: searchParams.get("sidebar") === "false",
      frameworkPickerHidden: searchParams.get("frameworkPicker") === "false",
      viewPickerHidden: searchParams.get("viewPicker") === "false",
      featurePickerHidden: searchParams.get("featurePicker") === "false",
    };

    setState(newState);
  }, [searchParams]);

  // Context methods
  const setView = (view: View) => {
    const newState = { ...state, view };
    setState(newState);
    updateURL({ view });
  };

  const setSidebarHidden = (sidebarHidden: boolean) => {
    const newState = { ...state, sidebarHidden };
    setState(newState);
    updateURL({ sidebarHidden });
  };

  const setFrameworkPickerHidden = (frameworkPickerHidden: boolean) => {
    const newState = { ...state, frameworkPickerHidden };
    setState(newState);
    updateURL({ frameworkPickerHidden });
  };

  const setViewPickerHidden = (viewPickerHidden: boolean) => {
    const newState = { ...state, viewPickerHidden };
    setState(newState);
    updateURL({ viewPickerHidden });
  };

  const setFeaturePickerHidden = (featurePickerHidden: boolean) => {
    const newState = { ...state, featurePickerHidden };
    setState(newState);
    updateURL({ featurePickerHidden });
  };

  const setCodeFile = (fileName: string) => {
    const newState = { ...state, file: fileName };
    setState(newState);
    updateURL({ file: fileName });
  };

  const contextValue: URLParamsContextType = {
    ...state,
    setView,
    setSidebarHidden,
    setFrameworkPickerHidden,
    setViewPickerHidden,
    setFeaturePickerHidden,
    setCodeFile,
  };

  return (
    <URLParamsContext.Provider value={contextValue}>
      {children}
    </URLParamsContext.Provider>
  );
}

export function useURLParams(): URLParamsContextType {
  const context = useContext(URLParamsContext);
  if (context === undefined) {
    throw new Error('useURLParams must be used within a URLParamsProvider');
  }
  return context;
}



================================================
FILE: typescript-sdk/apps/dojo/src/lib/utils.ts
================================================
import { type ClassValue, clsx } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}



================================================
FILE: typescript-sdk/apps/dojo/src/mastra/index.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { DynamoDBStore } from "@mastra/dynamodb";

import { Mastra } from "@mastra/core";
import { createTool } from "@mastra/core";
import { z } from "zod";



function getStorage(): LibSQLStore | DynamoDBStore {
  if (process.env.DYNAMODB_TABLE_NAME) {
    return new DynamoDBStore({
    name: "dynamodb",
    config: {
      tableName: process.env.DYNAMODB_TABLE_NAME
    },
  });
  } else {
    return new LibSQLStore({ url: "file::memory:" });
  }
}



export const mastra = new Mastra({
  agents: {
    agentic_chat: new Agent({
      name: "agentic_chat",
      instructions: `
        You are a helpful weather assistant that provides accurate weather information.

        Your primary function is to help users get weather details for specific locations. When responding:
        - Always ask for a location if none is provided
        - If the location name isn’t in English, please translate it
        - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
        - Include relevant details like humidity, wind conditions, and precipitation
        - Keep responses concise but informative

        Use the weatherTool to fetch current weather data.
  `,
      model: openai("gpt-4o"),
      memory: new Memory({
        storage: getStorage(),
        options: {
          workingMemory: {
            enabled: true,
            schema: z.object({
              firstName: z.string(),
            }),
          },
        },
      }),
    }),
    shared_state: new Agent({
      name: "shared_state",
      instructions: `
        You are a helpful assistant for creating recipes.

        IMPORTANT:
        1. Create a recipe using the existing ingredients and instructions. Make sure the recipe is complete.
        2. For ingredients, append new ingredients to the existing ones.
        3. For instructions, append new steps to the existing ones.
        4. 'ingredients' is always an array of objects with 'icon', 'name', and 'amount' fields
        5. 'instructions' is always an array of strings

        If you have just created or modified the recipe, just answer in one sentence what you did. dont describe the recipe, just say what you did. Do not mention "working memory", "memory", or "state" in your answer.
      `,
      model: openai("gpt-4o"),
      memory: new Memory({
        storage: getStorage(),
        options: {
          workingMemory: {
            enabled: true,
            schema: z.object({
              recipe: z.object({
                skill_level: z
                  .enum(["Beginner", "Intermediate", "Advanced"])
                  .describe("The skill level required for the recipe"),
                special_preferences: z
                  .array(
                    z.enum([
                      "High Protein",
                      "Low Carb",
                      "Spicy",
                      "Budget-Friendly",
                      "One-Pot Meal",
                      "Vegetarian",
                      "Vegan",
                    ]),
                  )
                  .describe("A list of special preferences for the recipe"),
                cooking_time: z
                  .enum(["5 min", "15 min", "30 min", "45 min", "60+ min"])
                  .describe("The cooking time of the recipe"),
                ingredients: z
                  .array(
                    z.object({
                      icon: z
                        .string()
                        .describe(
                          "The icon emoji (not emoji code like '\x1f35e', but the actual emoji like 🥕) of the ingredient",
                        ),
                      name: z.string().describe("The name of the ingredient"),
                      amount: z.string().describe("The amount of the ingredient"),
                    }),
                  )
                  .describe(
                    "Entire list of ingredients for the recipe, including the new ingredients and the ones that are already in the recipe",
                  ),
                instructions: z
                  .array(z.string())
                  .describe(
                    "Entire list of instructions for the recipe, including the new instructions and the ones that are already there",
                  ),
                changes: z.string().describe("A description of the changes made to the recipe"),
              }),
            }),
          },
        },
      }),
    }),
    tool_based_generative_ui: new Agent({
      name: "tool_based_generative_ui",
      instructions: `
        You are a helpful assistant for creating haikus.
      `,
      model: openai("gpt-4o"),
      tools: {
        generate_haiku: createTool({
          id: "generate_haiku",
          description:
            "Generate a haiku in Japanese and its English translation. Also select exactly 3 relevant images from the provided list based on the haiku's theme.",
          inputSchema: z.object({
            japanese: z
              .array(z.string())
              .describe("An array of three lines of the haiku in Japanese"),
            english: z
              .array(z.string())
              .describe("An array of three lines of the haiku in English"),
          }),
          outputSchema: z.string(),
          execute: async ({ context }) => {
            return "Haiku generated.";
          },
        }),
      },
    }),
  },
});



================================================
FILE: typescript-sdk/apps/dojo/src/styles/typography.css
================================================
/* CopilotCloud Typography Components */

/* Headings */
.H1-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 56px;
  line-height: 64px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H1-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 56px;
  line-height: 64px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H2-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 40px;
  line-height: 46px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H2-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 40px;
  line-height: 46px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H3-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 32px;
  line-height: 36px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H3-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 32px;
  line-height: 36px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H4-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 24px;
  line-height: 28px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H4-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 24px;
  line-height: 28px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H5-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 20px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H5-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 20px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 500;
}

.H6-SemiBold {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 18px;
  line-height: 20px;
  letter-spacing: 0px;
  font-weight: 600;
}

.H6-Medium {
  font-family: "Plus Jakarta Sans", sans-serif;
  font-size: 18px;
  line-height: 20px;
  letter-spacing: 0px;
  font-weight: 500;
}

/* Paragraphs */
.paragraphs-Large-Bold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 700;
}

.paragraphs-Large-SemiBold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 600;
}

.paragraphs-Large-Medium {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 500;
}

.paragraphs-Large-Regular {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 16px;
  line-height: 24px;
  letter-spacing: 0px;
  font-weight: 400;
}

.paragraphs-Medium-SemiBold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 14px;
  line-height: 22px;
  letter-spacing: 0px;
  font-weight: 600;
}

.paragraphs-Medium-Medium {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 14px;
  line-height: 22px;
  letter-spacing: 0px;
  font-weight: 500;
}

.paragraphs-Medium-Regular {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 14px;
  line-height: 22px;
  letter-spacing: 0px;
  font-weight: 400;
}

.paragraphs-Small-SemiBold {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 600;
}

.paragraphs-Small-Medium {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 500;
}

.paragraphs-Small-Regular {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 400;
}

.paragraphs-Small-Regular-Uppercase {
  font-family: "Plus Jakarta Sans", ui-sans-serif, system-ui, sans-serif;
  font-size: 12px;
  line-height: 16px;
  letter-spacing: 0px;
  font-weight: 400;
  text-transform: uppercase;
}

/* Details */
.details-Medium-Medium {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 14px;
  line-height: 14px;
  letter-spacing: 0px;
  font-weight: 500;
}

.details-Medium-Medium-Uppercase {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 14px;
  line-height: 14px;
  letter-spacing: 0px;
  font-weight: 500;
  text-transform: uppercase;
}

.details-Small-Medium {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 12px;
  line-height: 12px;
  letter-spacing: 0px;
  font-weight: 500;
}

.details-Small-Medium-Uppercase {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 12px;
  line-height: 12px;
  letter-spacing: 0px;
  font-weight: 500;
  text-transform: uppercase;
}

.details-ExtraSmall-Medium {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 10px;
  line-height: 10px;
  letter-spacing: 0px;
  font-weight: 500;
}

.details-ExtraSmall-Medium-Uppercase {
  font-family: "Spline Sans Mono", ui-monospace, SFMono-Regular, monospace;
  font-size: 10px;
  line-height: 10px;
  letter-spacing: 0px;
  font-weight: 500;
  text-transform: uppercase;
}


================================================
FILE: typescript-sdk/apps/dojo/src/types/feature.ts
================================================
export interface ViewerConfig {
  showCodeEditor?: boolean;
  showFileTree?: boolean;
  showLLMSelector?: boolean;
}

export interface FeatureFile {
  name: string;
  content: string;
  // path: string;
  language: string;
  type: string;
}

export interface FeatureConfig {
  id: string;
  name: string;
  description: string;
  path: string;
  tags?: string[];
}



================================================
FILE: typescript-sdk/apps/dojo/src/types/integration.ts
================================================
import { AbstractAgent } from "@ag-ui/client";

export type Feature =
  | "agentic_chat"
  | "agentic_generative_ui"
  | "human_in_the_loop"
  | "predictive_state_updates"
  | "shared_state"
  | "tool_based_generative_ui"
  | "agentic_chat_reasoning"
  | "subgraphs";

export interface MenuIntegrationConfig {
  id: string;
  name: string;
  features: Feature[];
}

export interface AgentIntegrationConfig {
  id: string;
  agents: () => Promise<Partial<Record<Feature, AbstractAgent>>>;
}



================================================
FILE: typescript-sdk/apps/dojo/src/types/interface.ts
================================================
export type View = "preview" | "code" | "readme";



================================================
FILE: typescript-sdk/apps/dojo/src/utils/domain-config.ts
================================================
import getEnvVars from "@/env";


export function getTitleForCurrentDomain(): string | undefined {
  const envVars = getEnvVars();

  // Check if we're in the browser
  if (typeof window == "undefined") {
    return undefined;
  }

  const host = window.location.hostname;
  return envVars.customDomainTitle[host] || undefined;
}


================================================
FILE: typescript-sdk/apps/dojo/src/utils/mdx-utils.tsx
================================================
import React from "react";
import { MDXComponents } from "@/components/ui/mdx-components";
import ReactMarkdown from "react-markdown";

/**
 * Enhanced MDX content renderer component
 */
export const MDXRenderer: React.FC<{
  content: string;
  demoId?: string;
}> = ({ content, demoId }) => {
  // Process content to enhance video tags
  const processedVideos = React.useMemo(() => {
    if (!content) return "";

    // Extract and process video tags
    const videoRegex = /<Video\s+src="([^"]+)"([^>]*)>/gi;
    let match;
    let processedHtml = "";

    while ((match = videoRegex.exec(content)) !== null) {
      const [fullMatch, src, attrs] = match;
      let videoHtml = "";

      // Process the video source based on demoId
      if (demoId && !src.startsWith("http") && !src.startsWith("/")) {
        videoHtml = `<div class="video-wrapper"><video controls width="100%" src="/api/demo-assets?demoId=${demoId}&fileName=${src}"${attrs}></video></div>`;
      } else {
        videoHtml = `<div class="video-wrapper"><video controls width="100%" src="${src}"${attrs}></video></div>`;
      }

      processedHtml += videoHtml;
    }

    return processedHtml;
  }, [content, demoId]);

  // Early return if no content
  if (!content) return null;

  return (
      <div className="mdx-content">
        {/* Render the markdown content with proper formatting */}
        <ReactMarkdown components={MDXComponents}>{content}</ReactMarkdown>

        {/* Insert processed video elements if any */}
        {processedVideos && (
          <div className="mt-4" dangerouslySetInnerHTML={{ __html: processedVideos }} />
        )}
      </div>
  );
};

/**
 * Safe component rendering with error boundary
 */
export const SafeComponent: React.FC<{
  component: React.ComponentType | (() => React.ReactNode);
  fallback?: React.ReactNode;
}> = ({
  component: Component,
  fallback = <div className="p-4 text-amber-600">Content could not be displayed</div>,
}) => {
  if (!Component) return <>{fallback}</>;

  try {
    return typeof Component === "function" ? (
      typeof Component.prototype?.render === "function" ? (
        <Component />
      ) : (
        <>{(Component as () => React.ReactNode)()}</>
      )
    ) : (
      <>{Component}</>
    );
  } catch (error) {
    console.error("Error rendering component:", error);
    return <>{fallback}</>;
  }
};



================================================
FILE: typescript-sdk/apps/dojo/src/utils/use-mobile-chat.ts
================================================
import { CopilotKitCSSProperties, CopilotSidebar } from "@copilotkit/react-ui";
import React, { useEffect, useState } from "react";


export function useMobileChat(defaultChatHeight = 50) {
  const [isChatOpen, setIsChatOpen] = useState(false);
  const [chatHeight, setChatHeight] = useState(defaultChatHeight); // Initial height as percentage
  const [isDragging, setIsDragging] = useState(false);
  const [dragStartY, setDragStartY] = useState(0);
  const [dragStartHeight, setDragStartHeight] = useState(defaultChatHeight);

  // Drag functionality for chat resize
  useEffect(() => {
    const handleMouseMove = (e: MouseEvent) => {
      if (!isDragging) return;

      const deltaY = dragStartY - e.clientY;
      const windowHeight = window.innerHeight;
      const newHeightPx = (dragStartHeight / 100) * windowHeight + deltaY;
      const newHeightPercent = (newHeightPx / windowHeight) * 100;

      // Clamp between 50% and 100%
      const clampedHeight = Math.max(50, Math.min(100, newHeightPercent));
      setChatHeight(clampedHeight);
    };

    const handleMouseUp = () => {
      if (isDragging) {
        // Close if dragged below 50%
        if (chatHeight < 50) {
          setIsChatOpen(false);
          setChatHeight(defaultChatHeight); // Reset to default
        }
        setIsDragging(false);
      }
    };

    if (isDragging) {
      document.addEventListener('mousemove', handleMouseMove);
      document.addEventListener('mouseup', handleMouseUp);
      document.body.style.userSelect = 'none'; // Prevent text selection while dragging
    }

    return () => {
      document.removeEventListener('mousemove', handleMouseMove);
      document.removeEventListener('mouseup', handleMouseUp);
      document.body.style.userSelect = '';
    };
  }, [isDragging, dragStartY, dragStartHeight, chatHeight]);

  const handleDragStart = (e: React.MouseEvent) => {
    setIsDragging(true);
    setDragStartY(e.clientY);
    setDragStartHeight(chatHeight);
  };

  return {
    isChatOpen,
    setChatHeight,
    setIsChatOpen,
    isDragging,
    chatHeight,
    handleDragStart
  }
}


================================================
FILE: typescript-sdk/apps/dojo/src/utils/use-mobile-view.ts
================================================
import { useEffect, useState } from "react";

export function useMobileView() {
  const [isMobile, setIsMobile] = useState(false);

  useEffect(() => {
    const checkMobile = () => {
      setIsMobile(window.innerWidth < 768);
    };

    checkMobile();
    window.addEventListener('resize', checkMobile);
    return () => window.removeEventListener('resize', checkMobile);
  }, []);

  return {
    isMobile,
  }
}


================================================
FILE: typescript-sdk/integrations/adk-middleware/README.md
================================================
# ADK Middleware for AG-UI Protocol

This Python middleware enables [Google ADK](https://google.github.io/adk-docs/) agents to be used with the AG-UI Protocol, providing a bridge between the two frameworks.

## Prerequisites

The examples use ADK Agents using various Gemini models along with the AG-UI Dojo.

- A [Gemini API Key](https://makersuite.google.com/app/apikey). The examples assume that this is exported via the GOOGLE_API_KEY environment variable.

## Quick Start

To use this integration you need to:

1. Clone the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui).

    ```bash
    git clone https://github.com/ag-ui-protocol/ag-ui.git
    ```

2. Change to the `typescript-sdk/integrations/adk-middleware` directory.

    ```bash
    cd typescript-sdk/integrations/adk-middleware
    ```

3. Install the `adk-middleware` package from the local directory.  For example,

    ```bash
    pip install .
    ```

    or 

    ```bash
    uv pip install .
    ```
    
    This installs the package from the current directory which contains:
    - `src/adk_middleware/` - The middleware source code
    - `examples/` - Example servers and agents
    - `tests/` - Test suite

4. Install the requirements for the `examples`, for example:

    ```bash
    uv pip install -r requirements.txt
    ```

5. Run the example fast_api server.

    ```bash
    export GOOGLE_API_KEY=<My API Key>
    cd examples
    uv sync
    uv run dev
    ```

6. Open another terminal in the root directory of the ag-ui repository clone.

7. Start the integration ag-ui dojo:

    ```bash
    cd typescript-sdk
    pnpm install && pnpm run dev
    ```

8. Visit [http://localhost:3000/adk-middleware](http://localhost:3000/adk-middleware).

9. Select View `ADK Middleware` from the sidebar.

### Development Setup

If you want to contribute to ADK Middleware development, you'll need to take some additional steps.  You can either use the following script of the manual development setup.

```bash
# From the adk-middleware directory
chmod +x setup_dev.sh
./setup_dev.sh
```

### Manual Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install this package in editable mode
pip install -e .

# For development (includes testing and linting tools)
pip install -e ".[dev]"
# OR
pip install -r requirements-dev.txt
```

This installs the ADK middleware in editable mode for development.

## Testing

```bash
# Run tests (271 comprehensive tests)
pytest

# With coverage
pytest --cov=src/adk_middleware

# Specific test file
pytest tests/test_adk_agent.py
```
## Usage options

### Option 1: Direct Usage
```python
from adk_middleware import ADKAgent
from google.adk.agents import Agent

# 1. Create your ADK agent
my_agent = Agent(
    name="assistant",
    instruction="You are a helpful assistant."
)

# 2. Create the middleware with direct agent embedding
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app", 
    user_id="user123"
)

# 3. Use directly with AG-UI RunAgentInput
async for event in agent.run(input_data):
    print(f"Event: {event.type}")
```

### Option 2: FastAPI Server

```python
from fastapi import FastAPI
from adk_middleware import ADKAgent, add_adk_fastapi_endpoint
from google.adk.agents import Agent

# 1. Create your ADK agent
my_agent = Agent(
    name="assistant",
    instruction="You are a helpful assistant."
)

# 2. Create the middleware with direct agent embedding
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app", 
    user_id="user123"
)

# 3. Create FastAPI app
app = FastAPI()
add_adk_fastapi_endpoint(app, agent, path="/chat")

# Run with: uvicorn your_module:app --host 0.0.0.0 --port 8000
```

For detailed configuration options, see [CONFIGURATION.md](./CONFIGURATION.md)


## Running the ADK Backend Server for Dojo App

To run the ADK backend server that works with the Dojo app, use the following command:

```bash
python -m examples.fastapi_server
```

This will start a FastAPI server that connects your ADK middleware to the Dojo application.

## Examples

### Simple Conversation

```python
import asyncio
from adk_middleware import ADKAgent
from google.adk.agents import Agent
from ag_ui.core import RunAgentInput, UserMessage

async def main():
    # Setup
    my_agent = Agent(name="assistant", instruction="You are a helpful assistant.")
    
    agent = ADKAgent(
        adk_agent=my_agent,
        app_name="demo_app", 
        user_id="demo"
    )
    
    # Create input
    input = RunAgentInput(
        thread_id="thread_001",
        run_id="run_001",
        messages=[
            UserMessage(id="1", role="user", content="Hello!")
        ],
        context=[],
        state={},
        tools=[],
        forwarded_props={}
    )
    
    # Run and handle events
    async for event in agent.run(input):
        print(f"Event: {event.type}")
        if hasattr(event, 'delta'):
            print(f"Content: {event.delta}")

asyncio.run(main())
```

### Multi-Agent Setup

```python
# Create multiple agent instances with different ADK agents
general_agent_wrapper = ADKAgent(
    adk_agent=general_agent,
    app_name="demo_app",
    user_id="demo"
)

technical_agent_wrapper = ADKAgent(
    adk_agent=technical_agent,
    app_name="demo_app",
    user_id="demo"
)

creative_agent_wrapper = ADKAgent(
    adk_agent=creative_agent,
    app_name="demo_app",
    user_id="demo"
)

# Use different endpoints for each agent
from fastapi import FastAPI
from adk_middleware import add_adk_fastapi_endpoint

app = FastAPI()
add_adk_fastapi_endpoint(app, general_agent_wrapper, path="/agents/general")
add_adk_fastapi_endpoint(app, technical_agent_wrapper, path="/agents/technical")
add_adk_fastapi_endpoint(app, creative_agent_wrapper, path="/agents/creative")
```

## Tool Support

The middleware provides complete bidirectional tool support, enabling AG-UI Protocol tools to execute within Google ADK agents. All tools supplied by the client are currently implemented as long-running tools that emit events to the client for execution and can be combined with backend tools provided by the agent to create a hybrid combined toolset.

For detailed information about tool support, see [TOOLS.md](./TOOLS.md).

## Additional Documentation

- **[CONFIGURATION.md](./CONFIGURATION.md)** - Complete configuration guide
- **[TOOLS.md](./TOOLS.md)** - Tool support documentation
- **[USAGE.md](./USAGE.md)** - Usage examples and patterns
- **[ARCHITECTURE.md](./ARCHITECTURE.md)** - Technical architecture and design details



================================================
FILE: typescript-sdk/integrations/adk-middleware/package.json
================================================
{
  "name": "@ag-ui/adk",
  "author": "Mark Fogle <mark@contextable.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",

    "@types/node": "^20.11.19",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/adk-middleware/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/adk-middleware/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/README.md
================================================
# ADK Middleware for AG-UI Protocol

This Python middleware enables [Google ADK](https://google.github.io/adk-docs/) agents to be used with the AG-UI Protocol, providing a bridge between the two frameworks.

## Prerequisites

The examples use ADK Agents using various Gemini models along with the AG-UI Dojo.

- A [Gemini API Key](https://makersuite.google.com/app/apikey). The examples assume that this is exported via the GOOGLE_API_KEY environment variable.

## Quick Start

To use this integration you need to:

1. Clone the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui).

    ```bash
    git clone https://github.com/ag-ui-protocol/ag-ui.git
    ```

2. Change to the `typescript-sdk/integrations/adk-middleware` directory.

    ```bash
    cd typescript-sdk/integrations/adk-middleware
    ```

3. Install the `adk-middleware` package from the local directory.  For example,

    ```bash
    pip install .
    ```

    or

    ```bash
    uv pip install .
    ```

    This installs the package from the current directory which contains:
    - `src/ag_ui_adk/` - The middleware source code
    - `examples/` - Example servers and agents
    - `tests/` - Test suite

4. Install the requirements for the `examples`, for example:

    ```bash
    uv pip install -r requirements.txt
    ```

5. Run the example fast_api server.

    ```bash
    export GOOGLE_API_KEY=<My API Key>
    cd examples
    uv sync
    uv run dev
    ```

6. Open another terminal in the root directory of the ag-ui repository clone.

7. Start the integration ag-ui dojo:

    ```bash
    cd typescript-sdk
    pnpm install && pnpm run dev
    ```

8. Visit [http://localhost:3000/adk-middleware](http://localhost:3000/adk-middleware).

9. Select View `ADK Middleware` from the sidebar.

### Development Setup

If you want to contribute to ADK Middleware development, you'll need to take some additional steps.  You can either use the following script of the manual development setup.

```bash
# From the adk-middleware directory
chmod +x setup_dev.sh
./setup_dev.sh
```

### Manual Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install this package in editable mode
pip install -e .

# For development (includes testing and linting tools)
pip install -e ".[dev]"
# OR
pip install -r requirements-dev.txt
```

This installs the ADK middleware in editable mode for development.

## Testing

```bash
# Run tests (271 comprehensive tests)
pytest

# With coverage
pytest --cov=src/ag_ui_adk

# Specific test file
pytest tests/test_adk_agent.py
```
## Usage options

### Option 1: Direct Usage
```python
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent

# 1. Create your ADK agent
my_agent = Agent(
    name="assistant",
    instruction="You are a helpful assistant."
)

# 2. Create the middleware with direct agent embedding
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123"
)

# 3. Use directly with AG-UI RunAgentInput
async for event in agent.run(input_data):
    print(f"Event: {event.type}")
```

### Option 2: FastAPI Server

```python
from fastapi import FastAPI
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
from google.adk.agents import Agent

# 1. Create your ADK agent
my_agent = Agent(
    name="assistant",
    instruction="You are a helpful assistant."
)

# 2. Create the middleware with direct agent embedding
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123"
)

# 3. Create FastAPI app
app = FastAPI()
add_adk_fastapi_endpoint(app, agent, path="/chat")

# Run with: uvicorn your_module:app --host 0.0.0.0 --port 8000
```

For detailed configuration options, see [CONFIGURATION.md](./CONFIGURATION.md)


## Running the ADK Backend Server for Dojo App

To run the ADK backend server that works with the Dojo app, use the following command:

```bash
python -m examples.fastapi_server
```

This will start a FastAPI server that connects your ADK middleware to the Dojo application.

## Examples

### Simple Conversation

```python
import asyncio
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent
from ag_ui.core import RunAgentInput, UserMessage

async def main():
    # Setup
    my_agent = Agent(name="assistant", instruction="You are a helpful assistant.")

    agent = ADKAgent(
        adk_agent=my_agent,
        app_name="demo_app",
        user_id="demo"
    )

    # Create input
    input = RunAgentInput(
        thread_id="thread_001",
        run_id="run_001",
        messages=[
            UserMessage(id="1", role="user", content="Hello!")
        ],
        context=[],
        state={},
        tools=[],
        forwarded_props={}
    )

    # Run and handle events
    async for event in agent.run(input):
        print(f"Event: {event.type}")
        if hasattr(event, 'delta'):
            print(f"Content: {event.delta}")

asyncio.run(main())
```

### Multi-Agent Setup

```python
# Create multiple agent instances with different ADK agents
general_agent_wrapper = ADKAgent(
    adk_agent=general_agent,
    app_name="demo_app",
    user_id="demo"
)

technical_agent_wrapper = ADKAgent(
    adk_agent=technical_agent,
    app_name="demo_app",
    user_id="demo"
)

creative_agent_wrapper = ADKAgent(
    adk_agent=creative_agent,
    app_name="demo_app",
    user_id="demo"
)

# Use different endpoints for each agent
from fastapi import FastAPI
from ag_ui_adk import add_adk_fastapi_endpoint

app = FastAPI()
add_adk_fastapi_endpoint(app, general_agent_wrapper, path="/agents/general")
add_adk_fastapi_endpoint(app, technical_agent_wrapper, path="/agents/technical")
add_adk_fastapi_endpoint(app, creative_agent_wrapper, path="/agents/creative")
```

## Tool Support

The middleware provides complete bidirectional tool support, enabling AG-UI Protocol tools to execute within Google ADK agents. All tools supplied by the client are currently implemented as long-running tools that emit events to the client for execution and can be combined with backend tools provided by the agent to create a hybrid combined toolset.

For detailed information about tool support, see [TOOLS.md](./TOOLS.md).

## Additional Documentation

- **[CONFIGURATION.md](./CONFIGURATION.md)** - Complete configuration guide
- **[TOOLS.md](./TOOLS.md)** - Tool support documentation
- **[USAGE.md](./USAGE.md)** - Usage examples and patterns
- **[ARCHITECTURE.md](./ARCHITECTURE.md)** - Technical architecture and design details



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/ARCHITECTURE.md
================================================
# ADK Middleware Architecture

This document describes the architecture and design of the ADK Middleware that bridges Google ADK agents with the AG-UI Protocol.

## High-Level Architecture

```
AG-UI Protocol          ADK Middleware           Google ADK
     │                        │                       │
RunAgentInput ──────> ADKAgent.run() ──────> Runner.run_async()
     │                        │                       │
     │                 EventTranslator                │
     │                        │                       │
BaseEvent[] <──────── translate events <──────── Event[]
```

## Core Components

### ADKAgent (`adk_agent.py`)
The main orchestrator that:
- Manages agent lifecycle and session state
- Handles the bridge between AG-UI Protocol and ADK
- Coordinates tool execution through proxy tools
- Implements direct agent embedding pattern

### EventTranslator (`event_translator.py`)
Converts between event formats:
- ADK events → AG-UI protocol events (16 standard event types)
- Maintains proper message boundaries
- Handles streaming text content
- Per-session instances for thread safety

### SessionManager (`session_manager.py`)
Singleton pattern for centralized session control:
- Automatic session cleanup with configurable timeouts
- Session isolation per user
- Memory service integration for session persistence
- Resource management and limits

### ExecutionState (`execution_state.py`)
Tracks background ADK executions:
- Manages asyncio tasks running ADK agents
- Event queue for streaming results
- Execution timing and completion tracking
- Tool call state management

### ClientProxyTool (`client_proxy_tool.py`)
Individual tool proxy implementation:
- Wraps AG-UI tools for ADK compatibility
- Emits tool events to client
- Currently all tools are long-running
- Integrates with ADK's tool system

### ClientProxyToolset (`client_proxy_toolset.py`)
Manages collections of proxy tools:
- Dynamic toolset creation per request
- Fresh tool instances for each execution
- Combines client and backend tools

## Event Flow

1. **Client Request**: AG-UI Protocol `RunAgentInput` received
2. **Session Resolution**: SessionManager finds or creates session
3. **Agent Execution**: ADK Runner executes agent with context
4. **Tool Handling**: ClientProxyTools emit events for client-side execution
5. **Event Translation**: ADK events converted to AG-UI events
6. **Streaming Response**: Events streamed back via SSE or other transport

## Key Design Patterns

### Direct Agent Embedding
```python
# Agents are directly embedded in ADKAgent instances
agent = ADKAgent(
    adk_agent=my_adk_agent,  # Direct reference
    app_name="my_app",
    user_id="user123"
)
```

### Service Dependency Injection
The middleware uses dependency injection for ADK services:
- Session service (default: InMemorySessionService)
- Memory service (optional, enables session persistence)
- Artifact service (default: InMemoryArtifactService)
- Credential service (default: InMemoryCredentialService)

### Tool Proxy Pattern
All client-supplied tools are wrapped as long-running ADK tools:
- Emit events for client-side execution
- Can be combined with backend tools
- Unified tool handling interface

### Session Lifecycle
1. Session created on first request
2. Maintained across multiple runs
3. Automatic cleanup after timeout
4. Optional persistence to memory service

## Thread Safety

- Per-session EventTranslator instances
- Singleton SessionManager with proper locking
- Isolated execution states per thread
- Thread-safe event queues

## Error Handling

- RunErrorEvent for various failure scenarios
- Proper async exception handling
- Resource cleanup on errors
- Timeout management at multiple levels

## Performance Considerations

- Async/await throughout for non-blocking operations
- Event streaming for real-time responses
- Configurable concurrent execution limits
- Automatic stale execution cleanup
- Efficient event queue management

## Future Enhancements

- Additional tool execution modes
- Enhanced state synchronization
- More sophisticated error recovery
- Performance optimizations
- Extended protocol support


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/CHANGELOG.md
================================================
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

## [0.6.0] - 2025-08-07

### Changed
- **CONFIG**: Made ADK middleware base URL configurable via `ADK_MIDDLEWARE_URL` environment variable in dojo app
- **CONFIG**: Added `adkMiddlewareUrl` configuration to environment variables (defaults to `http://localhost:8000`)
- **DEPENDENCIES**: Upgraded Google ADK from 1.6.1 to 1.9.0 - all 271 tests pass without modification
- **DOCUMENTATION**: Extensive documentation restructuring for improved organization and clarity

## [0.5.0] - 2025-08-05

### Breaking Changes
- **BREAKING**: ADKAgent constructor now requires `adk_agent` parameter instead of `agent_id` for direct agent embedding
- **BREAKING**: Removed AgentRegistry dependency - agents are now directly embedded in middleware instances
- **BREAKING**: Removed `agent_id` parameter from `ADKAgent.run()` method
- **BREAKING**: Endpoint registration no longer extracts agent_id from URL path
- **BREAKING**: AgentRegistry class removed from public API

### Architecture Improvements
- **ARCHITECTURE**: Eliminated AgentRegistry entirely - simplified architecture by embedding ADK agents directly
- **ARCHITECTURE**: Cleaned up agent registration/instantiation redundancy (issue #24)
- **ARCHITECTURE**: Removed confusing indirection where endpoint agent didn't determine execution
- **ARCHITECTURE**: Each ADKAgent instance now directly holds its ADK agent instance
- **ARCHITECTURE**: Simplified method signatures and removed agent lookup overhead

### Fixed
- **FIXED**: All 271 tests now pass with new simplified architecture
- **TESTS**: Updated all test fixtures to match new ADKAgent.run(input_data) signature without agent_id parameter
- **TESTS**: Fixed test expectations in test_endpoint.py to work with direct agent embedding architecture
- **TESTS**: Updated all test fixtures to work with new agent embedding pattern
- **EXAMPLES**: Updated examples to demonstrate direct agent embedding pattern

### Added
- **NEW**: SystemMessage support for ADK agents (issue #22) - SystemMessages as first message are now appended to agent instructions
- **NEW**: Comprehensive tests for SystemMessage functionality including edge cases
- **NEW**: Long running tools can be defined in backend side as well
- **NEW**: Predictive state demo is added in dojo App

### Fixed  
- **FIXED**: Race condition in tool result processing causing "No pending tool calls found" warnings
- **FIXED**: Tool call removal now happens after pending check to prevent race conditions
- **IMPROVED**: Better handling of empty tool result content with graceful JSON parsing fallback
- **FIXED**: Pending tool call state management now uses SessionManager methods (issue #25)
- **FIXED**: Pending tools issue for normal backend tools is now fixed (issue #32)
- **FIXED**: TestEventTranslatorComprehensive unit test cases fixed

### Enhanced
- **LOGGING**: Added debug logging for tool result processing to aid in troubleshooting
- **ARCHITECTURE**: Consolidated agent copying logic to avoid creating multiple unnecessary copies
- **CLEANUP**: Removed unused toolset parameter from `_run_adk_in_background` method
- **REFACTOR**: Replaced direct session service access with SessionManager state management methods for pending tool calls

## [0.4.1] - 2025-07-13

### Fixed
- **CRITICAL**: Fixed memory persistence across sessions by ensuring consistent user ID extraction
- **CRITICAL**: Fixed ADK tool call ID mapping to prevent mismatch between ADK and AG-UI protocols

### Enhanced  
- **ARCHITECTURE**: Simplified SessionManager._delete_session() to accept session object directly, eliminating redundant lookups
- **TESTING**: Added comprehensive memory integration test suite (8 tests) for memory service functionality without requiring API keys
- **DOCUMENTATION**: Updated README with memory tools integration guidance and testing configuration instructions

### Added
- Memory integration tests covering service initialization, sharing, and cross-session persistence
- PreloadMemoryTool import support in FastAPI server examples
- Documentation for proper tool placement on ADK agents vs middleware

### Technical Improvements
- Consistent user ID generation for memory testing ("test_user" instead of dynamic anonymous IDs)
- Optimized session deletion to use session objects directly
- Enhanced tool call ID extraction from ADK context for proper protocol bridging
- Cleaned up debug logging statements throughout codebase


## [0.4.0] - 2025-07-11

### Bug Fixes
- **CRITICAL**: Fixed tool result accumulation causing Gemini API errors about function response count mismatch
- **FIXED**: `_extract_tool_results()` now only extracts the most recent tool message instead of all tool messages from conversation history
- **RELIABILITY**: Prevents multiple tool responses being passed to Gemini when only one function call is expected

### Major Architecture Change
- **BREAKING**: Simplified to all-long-running tool execution model, removing hybrid blocking/long-running complexity
- **REMOVED**: Eliminated blocking tool execution mode - all tools now use long-running behavior for consistency
- **REMOVED**: Removed tool futures, execution resumption, and hybrid execution state management
- **REMOVED**: Eliminated per-tool execution mode configuration (`tool_long_running_config`)

### Simplified Architecture
- **SIMPLIFIED**: `ClientProxyTool` now always returns `None` immediately after emitting events, wrapping `LongRunningFunctionTool` for proper ADK behavior
- **SIMPLIFIED**: `ClientProxyToolset` constructor simplified - removed `is_long_running` and `tool_futures` parameters
- **SIMPLIFIED**: `ExecutionState` cleaned up - removed tool future resolution and hybrid execution logic
- **SIMPLIFIED**: `ADKAgent.run()` method streamlined - removed commented hybrid model code
- **IMPROVED**: Agent tool combination now uses `model_copy()` to avoid mutating original agent instances

### Human-in-the-Loop (HITL) Support
- **NEW**: Session-based pending tool call tracking for HITL scenarios using ADK session state
- **NEW**: Sessions with pending tool calls are preserved during cleanup (no timeout for HITL workflows)
- **NEW**: Automatic tool call tracking when tools emit events and tool response tracking when results are received
- **NEW**: Standalone tool result handling - tool results without active executions start new executions
- **IMPROVED**: Session cleanup logic now checks for pending tool calls before deletion, enabling indefinite HITL workflows

### Enhanced Testing
- **TESTING**: Comprehensive test suite refactored for all-long-running architecture
- **TESTING**: 272 tests passing with 93% overall code coverage (increased from previous 269 tests)
- **TESTING**: Added comprehensive HITL tool call tracking tests (`test_tool_tracking_hitl.py`)
- **TESTING**: Removed obsolete test files for hybrid functionality (`test_hybrid_flow_integration.py`, `test_execution_resumption.py`)
- **TESTING**: Fixed all integration tests to work with simplified architecture and HITL support
- **TESTING**: Updated tool result flow tests to handle new standalone tool result behavior

### Performance & Reliability
- **PERFORMANCE**: Eliminated complex execution state tracking and tool future management overhead
- **RELIABILITY**: Removed potential deadlocks and race conditions from hybrid execution model
- **CONSISTENCY**: All tools now follow the same execution pattern, reducing cognitive load and bugs

### Technical Architecture (HITL)
- **Session State**: Pending tool calls tracked in ADK session state via `session.state["pending_tool_calls"]` array
- **Event-Driven Tracking**: `ToolCallEndEvent` events automatically add tool calls to pending list via `append_event()` with `EventActions.stateDelta`
- **Result Processing**: `ToolMessage` responses automatically remove tool calls from pending list with proper ADK session persistence
- **Session Persistence**: Sessions with pending tool calls bypass timeout-based cleanup for indefinite HITL workflows
- **Standalone Results**: Tool results without active executions start new ADK executions for proper session continuity
- **State Persistence**: Uses ADK's `append_event()` with `EventActions(stateDelta={})` for proper session state persistence

### Breaking Changes
- **API**: `ClientProxyToolset` constructor no longer accepts `is_long_running`, `tool_futures`, or `tool_long_running_config` parameters
- **BEHAVIOR**: All tools now behave as long-running tools - emit events and return `None` immediately
- **BEHAVIOR**: Standalone tool results now start new executions instead of being silently ignored
- **TESTING**: Test expectations updated for all-long-running behavior and HITL support

### Merged from adk-middleware (PR #7)
- **TESTING**: Comprehensive test coverage improvements - fixed all failing tests across the test suite
- **MOCK CONTEXT**: Added proper mock_tool_context fixtures to fix pydantic validation errors in test files
- **TOOLSET CLEANUP**: Fixed ClientProxyToolset.close() to properly cancel pending futures and clear resources
- **EVENT STREAMING**: Updated tests to expect RUN_FINISHED events that are now automatically emitted by enhanced _stream_events method
- **TEST SIGNATURES**: Fixed mock function signatures to match updated _stream_events method parameters (execution, run_id)
- **TOOL RESULT FLOW**: Updated tests to account for RunStartedEvent being emitted for tool result submissions
- **ERROR HANDLING**: Fixed malformed tool message test to correctly expect graceful handling of empty content (not errors)
- **ARCHITECTURE**: Enhanced toolset resource management - toolsets now properly clean up blocking tool futures on close
- **TEST RELIABILITY**: Improved test isolation and mock context consistency across all test files
- **TESTING**: Improved test coverage to 93% overall with comprehensive unit tests for previously untested modules
- **COMPLIANCE**: Tool execution now fully compliant with ADK behavioral expectations
- **OBSERVABILITY**: Enhanced logging for tool call ID tracking and validation throughout execution flow

### Error Handling Improvements
- **ENHANCED**: Better tool call ID mismatch detection with warnings when tool results don't match pending tools
- **ENHANCED**: Improved JSON parsing error handling with detailed error information including line/column numbers
- **ENHANCED**: More specific error codes for better debugging and error reporting
- **ENHANCED**: Better error messages in tool result processing with specific failure reasons

## [0.3.2] - 2025-07-08

### Added
- **NEW**: Hybrid tool execution model bridging AG-UI's stateless runs with ADK's stateful execution
- **NEW**: Per-tool execution mode configuration via `tool_long_running_config` parameter in `ClientProxyToolset`
- **NEW**: Mixed execution mode support - combine long-running and blocking tools in the same toolset
- **NEW**: Execution resumption functionality using `ToolMessage` for paused executions
- **NEW**: 13 comprehensive execution resumption tests covering hybrid model core functionality
- **NEW**: 13 integration tests for complete hybrid flow with minimal mocking
- **NEW**: Comprehensive documentation for hybrid tool execution model in README.md and CLAUDE.md
- **NEW**: `test_toolset_mixed_execution_modes()` - validates per-tool configuration functionality

### Enhanced
- **ARCHITECTURE**: `ClientProxyToolset` now supports per-tool `is_long_running` configuration
- **TESTING**: Expanded test suite to 185 tests with comprehensive coverage of both execution modes
- **DOCUMENTATION**: Added detailed hybrid execution flow examples and technical implementation guides
- **FLEXIBILITY**: Tools can now be individually configured for different execution behaviors within the same toolset

### Fixed
- **BEHAVIOR**: Improved timeout behavior for mixed execution modes
- **INTEGRATION**: Enhanced integration test reliability for complex tool scenarios
- **RESOURCE MANAGEMENT**: Better cleanup of tool futures and execution state across execution modes

### Technical Architecture
- **Hybrid Model**: Solves architecture mismatch between AG-UI's stateless runs and ADK's stateful execution
- **Tool Futures**: Enhanced `asyncio.Future` management for execution resumption across runs
- **Per-Tool Config**: `Dict[str, bool]` mapping enables granular control over tool execution modes
- **Execution State**: Improved tracking of paused executions and tool result resolution
- **Event Flow**: Maintains proper AG-UI protocol compliance during execution pause/resume cycles

### Breaking Changes
- **API**: `ClientProxyToolset` constructor now accepts `tool_long_running_config` parameter
- **BEHAVIOR**: Default tool execution mode remains `is_long_running=True` for backward compatibility

## [0.3.1] - 2025-07-08

### Added
- **NEW**: Tool-based generative UI demo for ADK in dojo application
- **NEW**: Multiple ADK agent support via `add_adk_fastapi_endpoint()` with proper agent_id handling
- **NEW**: Human-in-the-loop (HITL) support for long-running tools - `ClientProxyTool` with `is_long_running=True` no longer waits for tool responses
- **NEW**: Comprehensive test coverage for `is_long_running` functionality in `ClientProxyTool`
- **NEW**: `test_client_proxy_tool_long_running_no_timeout()` - verifies long-running tools ignore timeout settings
- **NEW**: `test_client_proxy_tool_long_running_vs_regular_timeout_behavior()` - compares timeout behavior between regular and long-running tools
- **NEW**: `test_client_proxy_tool_long_running_cleanup_on_error()` - ensures proper cleanup on event emission errors
- **NEW**: `test_client_proxy_tool_long_running_multiple_concurrent()` - tests multiple concurrent long-running tools
- **NEW**: `test_client_proxy_tool_long_running_event_emission_sequence()` - validates correct event emission order
- **NEW**: `test_client_proxy_tool_is_long_running_property()` - tests property access and default values

### Fixed
- **CRITICAL**: Fixed `agent_id` handling in `ADKAgent` wrapper to support multiple ADK agents properly
- **BEHAVIOR**: Disabled automatic tool response waiting in `ClientProxyTool` when `is_long_running=True` for HITL workflows

### Enhanced
- **ARCHITECTURE**: Long-running tools now properly support human-in-the-loop patterns where responses are provided by users
- **SCALABILITY**: Multiple ADK agents can now be deployed simultaneously with proper isolation
- **TESTING**: Enhanced test suite with 6 additional test cases specifically covering long-running tool behavior

### Technical Architecture
- **HITL Support**: Long-running tools emit events and return immediately without waiting for tool execution completion
- **Multi-Agent**: Proper agent_id management enables multiple ADK agents in single FastAPI application
- **Tool Response Flow**: Regular tools wait for responses, long-running tools delegate response handling to external systems
- **Event Emission**: All tools maintain proper AG-UI protocol compliance regardless of execution mode

## [0.3.0] - 2025-07-07

### Added
- **NEW**: Complete bidirectional tool support enabling AG-UI Protocol tools to execute within Google ADK agents
- **NEW**: `ExecutionState` class for managing background ADK execution with tool futures and event queues
- **NEW**: `ClientProxyTool` class that bridges AG-UI tools to ADK tools with proper event emission
- **NEW**: `ClientProxyToolset` class for dynamic toolset creation from `RunAgentInput.tools`
- **NEW**: Background execution support via asyncio tasks with proper timeout management
- **NEW**: Tool future management system for asynchronous tool result delivery
- **NEW**: Comprehensive timeout configuration: execution-level (600s default) and tool-level (300s default)
- **NEW**: Concurrent execution limits with configurable maximum concurrent executions and automatic cleanup
- **NEW**: 138+ comprehensive tests covering all tool support scenarios with 100% pass rate
- **NEW**: Advanced test coverage for tool timeouts, concurrent limits, error handling, and integration flows
- **NEW**: Production-ready error handling with proper resource cleanup and timeout management

### Enhanced
- **ARCHITECTURE**: ADK agents now run in background asyncio tasks while client handles tools asynchronously
- **OBSERVABILITY**: Enhanced logging throughout tool execution flow with detailed event tracking
- **SCALABILITY**: Configurable concurrent execution limits prevent resource exhaustion

### Technical Architecture
- **Tool Execution Flow**: AG-UI RunAgentInput → ADKAgent.run() → Background execution → ClientProxyTool → Event emission → Tool result futures
- **Event Communication**: Asynchronous event queues for communication between background execution and tool handler
- **Tool State Management**: ExecutionState tracks asyncio tasks, event queues, tool futures, and execution timing
- **Protocol Compliance**: All tool events follow AG-UI protocol specifications (TOOL_CALL_START, TOOL_CALL_ARGS, TOOL_CALL_END)
- **Resource Management**: Automatic cleanup of expired executions, futures, and background tasks
- **Error Propagation**: Comprehensive error handling with proper exception propagation and resource cleanup

### Breaking Changes
- **BEHAVIOR**: `ADKAgent.run()` now supports background execution when tools are provided
- **API**: Added `submit_tool_result()` method for delivering tool execution results
- **API**: Added `get_active_executions()` method for monitoring background executions
- **TIMEOUTS**: Added `tool_timeout_seconds` and `execution_timeout_seconds` parameters to ADKAgent constructor

## [0.2.1] - 2025-07-06

### Changed
- **SIMPLIFIED**: Converted from custom component logger system to standard Python logging
- **IMPROVED**: Logging configuration now uses Python's built-in `logging.getLogger()` pattern
- **STREAMLINED**: Removed proprietary `logging_config.py` module and related complexity
- **STANDARDIZED**: All modules now follow Python community best practices for logging
- **UPDATED**: Documentation (LOGGING.md) with standard Python logging examples

### Removed
- Custom `logging_config.py` module (replaced with standard Python logging)
- `configure_logging.py` interactive tool (no longer needed)
- `test_logging.py` (testing standard Python logging is unnecessary)

## [0.2.0] - 2025-07-06

### Added
- **NEW**: Automatic session memory option - expired sessions automatically preserved in ADK memory service
- **NEW**: Optional `memory_service` parameter in `SessionManager` for seamless session history preservation  
- **NEW**: 7 comprehensive unit tests for session memory functionality (61 total tests, up from 54)
- **NEW**: Updated default app name to "AG-UI ADK Agent" for better branding

### Changed
- **PERFORMANCE**: Enhanced session management to better leverage ADK's native session capabilities

### Added (Previous Release Features)
- **NEW**: Full pytest compatibility with standard pytest commands (`pytest`, `pytest --cov=src`)
- **NEW**: Pytest configuration (pytest.ini) with proper Python path and async support  
- **NEW**: Async test support with `@pytest.mark.asyncio` for all async test functions
- **NEW**: Test isolation with proper fixtures and session manager resets
- **NEW**: 54 comprehensive automated tests with 67% code coverage (100% pass rate)
- **NEW**: Organized all tests into dedicated tests/ directory for better project structure
- **NEW**: Default `app_name` behavior using agent name from registry when not explicitly specified
- **NEW**: Added `app_name` as required first parameter to `ADKAgent` constructor for clarity
- **NEW**: Comprehensive logging system with component-specific loggers (adk_agent, event_translator, endpoint)
- **NEW**: Configurable logging levels per component via `logging_config.py`
- **NEW**: `SessionLifecycleManager` singleton pattern for centralized session management
- **NEW**: Session encapsulation - session service now embedded within session manager
- **NEW**: Proper error handling in HTTP endpoints with specific error types and SSE fallback
- **NEW**: Thread-safe event translation with per-session `EventTranslator` instances
- **NEW**: Automatic session cleanup with configurable timeouts and limits
- **NEW**: Support for `InMemoryCredentialService` with intelligent defaults
- **NEW**: Proper streaming implementation based on ADK `finish_reason` detection
- **NEW**: Force-close mechanism for unterminated streaming messages
- **NEW**: User ID extraction system with multiple strategies (static, dynamic, fallback)
- **NEW**: Complete development environment setup with virtual environment support
- **NEW**: Test infrastructure with `run_tests.py` and comprehensive test coverage

### Changed
- **BREAKING**: `app_name` and `app_name_extractor` parameters are now optional - defaults to using agent name from registry
- **BREAKING**: `ADKAgent` constructor now requires `app_name` as first parameter
- **BREAKING**: Removed `session_service`, `session_timeout_seconds`, `cleanup_interval_seconds`, `max_sessions_per_user`, and `auto_cleanup` parameters from `ADKAgent` constructor (now managed by singleton session manager)
- **BREAKING**: Renamed `agent_id` parameter to `app_name` throughout session management for consistency
- **BREAKING**: `SessionInfo` dataclass now uses `app_name` field instead of `agent_id`
- **BREAKING**: Updated method signatures: `get_or_create_session()`, `_track_session()`, `track_activity()` now use `app_name`
- **BREAKING**: Replaced deprecated `TextMessageChunkEvent` with `TextMessageContentEvent`
- **MAJOR**: Refactored session lifecycle to use singleton pattern for global session management
- **MAJOR**: Improved event translation with proper START/CONTENT/END message boundaries
- **MAJOR**: Enhanced error handling with specific error codes and proper fallback mechanisms
- **MAJOR**: Updated dependency management to use proper package installation instead of path manipulation
- **MAJOR**: Removed hardcoded sys.path manipulations for cleaner imports

### Fixed
- **CRITICAL**: Fixed EventTranslator concurrency issues by creating per-session instances
- **CRITICAL**: Fixed session deletion to include missing `user_id` parameter
- **CRITICAL**: Fixed TEXT_MESSAGE_START ordering to ensure proper event sequence
- **CRITICAL**: Fixed session creation parameter consistency (app_name vs agent_id mismatch)
- **CRITICAL**: Fixed "SessionInfo not subscriptable" errors in session cleanup
- Fixed broad exception handling in endpoints that was silencing errors
- Fixed test validation logic for message event patterns
- Fixed runtime session creation errors with proper parameter passing
- Fixed logging to use proper module loggers instead of print statements
- Fixed event bookending to ensure messages have proper START/END boundaries

### Removed
- **DEPRECATED**: Removed custom `run_tests.py` test runner in favor of standard pytest commands

### Enhanced
- **Project Structure**: Moved all tests to tests/ directory with proper import resolution and PYTHONPATH configuration
- **Usability**: Simplified agent creation - no longer need to specify app_name in most cases
- **Performance**: Session management now uses singleton pattern for better resource utilization
- **Testing**: Comprehensive test suite with 54 automated tests and 67% code coverage (100% pass rate)
- **Observability**: Implemented structured logging with configurable levels per component
- **Error Handling**: Proper error propagation with specific error types and user-friendly messages
- **Development**: Complete development environment with virtual environment and proper dependency management
- **Documentation**: Updated README with proper setup instructions and usage examples
- **Streaming**: Improved streaming behavior based on ADK finish_reason for better real-time responses

### Technical Architecture Changes
- Implemented singleton `SessionLifecycleManager` for centralized session control
- Session service encapsulation within session manager (no longer exposed in ADKAgent)
- Per-session EventTranslator instances for thread safety
- Proper streaming detection using ADK event properties (`partial`, `turn_complete`, `finish_reason`)
- Enhanced error handling with fallback mechanisms and specific error codes
- Component-based logging architecture with configurable levels

## [0.1.0] - 2025-07-04

### Added
- Initial implementation of ADK Middleware for AG-UI Protocol
- Core `ADKAgent` class for bridging Google ADK agents with AG-UI
- Agent registry for managing multiple ADK agents
- Event translation between ADK and AG-UI protocols
- Session lifecycle management with configurable timeouts
- FastAPI integration with streaming SSE support
- Comprehensive test suite with 7 passing tests
- Example FastAPI server implementation
- Support for both in-memory and custom service implementations
- Automatic session cleanup and user session limits
- State management with JSON Patch support
- Tool call translation between protocols

### Fixed
- Import paths changed from relative to absolute for cleaner code
- RUN_STARTED event now emitted at the beginning of run() method
- Proper async context handling with auto_cleanup parameter

### Dependencies
- google-adk >= 0.1.0
- ag-ui (python-sdk)
- pydantic >= 2.0
- fastapi >= 0.100.0
- uvicorn >= 0.27.0


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/CONFIGURATION.md
================================================
# ADK Middleware Configuration Guide

This guide covers all configuration options for the ADK Middleware.

## Table of Contents

- [Basic Configuration](#basic-configuration)
- [App and User Identification](#app-and-user-identification)
- [Session Management](#session-management)
- [Service Configuration](#service-configuration)
- [Memory Configuration](#memory-configuration)
- [Timeout Configuration](#timeout-configuration)
- [Concurrent Execution Limits](#concurrent-execution-limits)

## Basic Configuration

The ADKAgent class is the main entry point for configuring the middleware. Here are the key parameters:

```python
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent

# Create your ADK agent
my_agent = Agent(
    name="assistant",
    instruction="You are a helpful assistant."
)

# Basic middleware configuration
agent = ADKAgent(
    adk_agent=my_agent,              # Required: The ADK agent to embed
    app_name="my_app",               # Required: Application identifier
    user_id="user123",               # Required: User identifier
    session_timeout_seconds=1200,    # Optional: Session timeout (default: 20 minutes)
    cleanup_interval_seconds=300,    # Optional: Cleanup interval (default: 5 minutes)
    max_sessions_per_user=10,        # Optional: Max sessions per user (default: 10)
    use_in_memory_services=True,     # Optional: Use in-memory services (default: True)
    execution_timeout_seconds=600,   # Optional: Execution timeout (default: 10 minutes)
    tool_timeout_seconds=300,        # Optional: Tool timeout (default: 5 minutes)
    max_concurrent_executions=5      # Optional: Max concurrent executions (default: 5)
)
```

## App and User Identification

There are two approaches for identifying applications and users:

### Static Identification

Best for single-tenant applications:

```python
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",      # Static app name
    user_id="static_user"   # Static user ID
)
```

### Dynamic Identification

Recommended for multi-tenant applications:

```python
from ag_ui.core import RunAgentInput

def extract_app(input: RunAgentInput) -> str:
    """Extract app name from request context."""
    for ctx in input.context:
        if ctx.description == "app":
            return ctx.value
    return "default_app"

def extract_user(input: RunAgentInput) -> str:
    """Extract user ID from request context."""
    for ctx in input.context:
        if ctx.description == "user":
            return ctx.value
    return f"anonymous_{input.thread_id}"

agent = ADKAgent(
    adk_agent=my_agent,
    app_name_extractor=extract_app,
    user_id_extractor=extract_user
)
```

## Session Management

Sessions are managed automatically by the singleton `SessionManager`. Configuration options include:

```python
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",

    # Session configuration
    session_timeout_seconds=1200,    # Session expires after 20 minutes of inactivity
    cleanup_interval_seconds=300,    # Cleanup runs every 5 minutes
    max_sessions_per_user=10         # Maximum concurrent sessions per user
)
```

### Session Lifecycle

1. **Creation**: New session created on first request from a user
2. **Maintenance**: Session kept alive with each interaction
3. **Timeout**: Session marked for cleanup after timeout period
4. **Cleanup**: Expired sessions removed during cleanup intervals
5. **Memory**: If memory service configured, expired sessions saved before deletion

## Service Configuration

The middleware supports both in-memory (development) and persistent (production) services:

### Development Configuration

Uses in-memory implementations for all services:

```python
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    use_in_memory_services=True  # Default behavior
)
```

### Production Configuration

Use persistent Google Cloud services:

```python
from google.adk.artifacts import GCSArtifactService
from google.adk.memory import VertexAIMemoryService
from google.adk.auth.credential_service import SecretManagerService

agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    artifact_service=GCSArtifactService(),        # Google Cloud Storage
    memory_service=VertexAIMemoryService(),       # Vertex AI Memory
    credential_service=SecretManagerService(),    # Secret Manager
    use_in_memory_services=False                  # Don't use in-memory defaults
)
```

### Custom Service Implementation

You can also provide custom service implementations:

```python
from google.adk.sessions import BaseSessionService
from google.adk.artifacts import BaseArtifactService
from google.adk.memory import BaseMemoryService
from google.adk.auth.credential_service import BaseCredentialService

class CustomSessionService(BaseSessionService):
    # Your implementation
    pass

agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    session_service=CustomSessionService(),
    use_in_memory_services=False
)
```

## Memory Configuration

### Automatic Session Memory

When a memory service is provided, expired sessions are automatically preserved:

```python
from google.adk.memory import VertexAIMemoryService

agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    memory_service=VertexAIMemoryService(),  # Enables automatic session memory
    use_in_memory_services=False
)

# Session preservation flow:
# 1. Session expires after timeout
# 2. Session data added to memory via memory_service.add_session_to_memory()
# 3. Session removed from active storage
# 4. Historical context available for future conversations
```

### Memory Tools Integration

To enable memory functionality in your agents, add ADK's memory tools:

```python
from google.adk.agents import Agent
from google.adk import tools as adk_tools

# Add memory tools to the ADK agent (not ADKAgent)
my_agent = Agent(
    name="assistant",
    model="gemini-2.0-flash",
    instruction="You are a helpful assistant.",
    tools=[adk_tools.preload_memory_tool.PreloadMemoryTool()]  # Memory tools here
)

# Create middleware with memory service
adk_agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    memory_service=VertexAIMemoryService()  # Memory service for session storage
)
```

**⚠️ Important**: The `tools` parameter belongs to the ADK agent, not the ADKAgent middleware.

### Testing Memory Configuration

For testing memory functionality with shorter timeouts:

```python
# Testing configuration with quick timeouts
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    memory_service=VertexAIMemoryService(),
    session_timeout_seconds=60,      # 1 minute timeout for testing
    cleanup_interval_seconds=30      # 30 second cleanup for testing
)
```

## Timeout Configuration

Configure various timeout settings:

```python
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",

    # Timeout settings
    session_timeout_seconds=1200,     # Session inactivity timeout (default: 20 min)
    execution_timeout_seconds=600,    # Max execution time (default: 10 min)
    tool_timeout_seconds=300          # Tool execution timeout (default: 5 min)
)
```

### Timeout Hierarchy

1. **Tool Timeout**: Applied to individual tool executions
2. **Execution Timeout**: Applied to entire agent execution
3. **Session Timeout**: Applied to user session inactivity

## Concurrent Execution Limits

Control resource usage with execution limits:

```python
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",

    # Concurrency settings
    max_concurrent_executions=5,     # Max concurrent agent executions (default: 5)
    max_sessions_per_user=10         # Max sessions per user (default: 10)
)
```

### Resource Management

- Prevents resource exhaustion from runaway executions
- Automatic cleanup of stale executions
- Queue management for tool events
- Proper task cancellation on timeout

## Environment Variables

Some configurations can be set via environment variables:

```bash
# Google API credentials
export GOOGLE_API_KEY="your-api-key"

# ADK middleware URL (for Dojo app)
export ADK_MIDDLEWARE_URL="http://localhost:8000"
```

## FastAPI Integration

When using with FastAPI, configure the endpoint:

```python
from fastapi import FastAPI
from ag_ui_adk import add_adk_fastapi_endpoint

app = FastAPI()

# Add endpoint with custom path
add_adk_fastapi_endpoint(
    app,
    agent,
    path="/chat"  # Custom endpoint path
)

# Multiple agents on different endpoints
add_adk_fastapi_endpoint(app, general_agent, path="/agents/general")
add_adk_fastapi_endpoint(app, technical_agent, path="/agents/technical")
```

## Logging Configuration

Configure logging for debugging:

```python
import logging

# Configure logging level
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Component-specific loggers
logging.getLogger('adk_agent').setLevel(logging.DEBUG)
logging.getLogger('event_translator').setLevel(logging.INFO)
logging.getLogger('session_manager').setLevel(logging.WARNING)
logging.getLogger('endpoint').setLevel(logging.ERROR)
```

See [LOGGING.md](./LOGGING.md) for detailed logging configuration.

## Best Practices

1. **Development**: Use in-memory services with default timeouts
2. **Testing**: Use shorter timeouts for faster iteration
3. **Production**: Use persistent services with appropriate timeouts
4. **Multi-tenant**: Use dynamic app/user extraction
5. **Resource Management**: Set appropriate concurrent execution limits
6. **Monitoring**: Configure logging appropriately for your environment

## Related Documentation

- [USAGE.md](./USAGE.md) - Usage examples and patterns
- [ARCHITECTURE.md](./ARCHITECTURE.md) - Technical architecture details
- [README.md](./README.md) - Quick start guide


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/LOGGING.md
================================================
# 🔧 ADK Middleware Logging Configuration

The ADK middleware uses standard Python logging. By default, most verbose logging is disabled for a cleaner experience.

## Quick Start

### 🔇 Default (Quiet Mode)
```bash
./quickstart.sh
# Only shows main agent info and errors
```

### 🔍 Debug Specific Components

Add this to your script or setup code:

```python
import logging

# Debug session management
logging.getLogger('session_manager').setLevel(logging.DEBUG)

# Debug event translation
logging.getLogger('event_translator').setLevel(logging.DEBUG)

# Debug HTTP endpoint responses
logging.getLogger('endpoint').setLevel(logging.DEBUG)

# Debug main agent logic
logging.getLogger('adk_agent').setLevel(logging.DEBUG)
```

### 🐛 Debug Everything
```python
import logging

# Set root logger to DEBUG
logging.getLogger().setLevel(logging.DEBUG)

# Or configure specific components
components = ['adk_agent', 'event_translator', 'endpoint', 'session_manager']
for component in components:
    logging.getLogger(component).setLevel(logging.DEBUG)
```

## Available Components

| Component | Description | Default Level |
|-----------|-------------|---------------|
| `event_translator` | Event conversion logic | WARNING |
| `endpoint` | HTTP endpoint responses | WARNING |
| `adk_agent` | Main agent logic | INFO |
| `session_manager` | Session management | WARNING |

## Python API

### Setting Individual Component Levels
```python
import logging

# Enable specific debugging
logging.getLogger('event_translator').setLevel(logging.DEBUG)
logging.getLogger('endpoint').setLevel(logging.DEBUG)

# Quiet mode
logging.getLogger('event_translator').setLevel(logging.ERROR)
logging.getLogger('endpoint').setLevel(logging.ERROR)
```

### Global Configuration
```python
import logging

# Configure basic logging format
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Set component-specific levels
logging.getLogger('session_manager').setLevel(logging.DEBUG)
```

## Common Use Cases

### 🔍 Debugging Streaming Issues
```python
logging.getLogger('event_translator').setLevel(logging.DEBUG)
```
Shows: partial events, turn_complete, is_final_response, TEXT_MESSAGE_* events

### 🌐 Debugging Client Connection Issues  
```python
logging.getLogger('endpoint').setLevel(logging.DEBUG)
```
Shows: HTTP responses, SSE data being sent to clients

### 📊 Debugging Session Management
```python
logging.getLogger('session_manager').setLevel(logging.DEBUG)
```
Shows: Session creation, deletion, cleanup, memory operations

### 🔇 Production Mode
```python
# Default behavior - only errors and main agent info
# No additional configuration needed
```

## Log Levels

- **DEBUG**: Verbose details for development
- **INFO**: Important operational information  
- **WARNING**: Warnings and recoverable issues (default for most components)
- **ERROR**: Only errors and critical issues

## Environment-Based Configuration

You can also set logging levels via environment variables by modifying your startup script:

```python
import os
import logging

# Check environment variables for log levels
components = {
    'adk_agent': os.getenv('LOG_ADK_AGENT', 'INFO'),
    'event_translator': os.getenv('LOG_EVENT_TRANSLATOR', 'WARNING'),
    'endpoint': os.getenv('LOG_ENDPOINT', 'WARNING'),
    'session_manager': os.getenv('LOG_SESSION_MANAGER', 'WARNING')
}

for component, level in components.items():
    logging.getLogger(component).setLevel(getattr(logging, level.upper()))
```

Then use:
```bash
LOG_SESSION_MANAGER=DEBUG ./quickstart.sh
```


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/pyproject.toml
================================================
[project]
name = "ag_ui_adk"
version = "0.3.1"
readme = "README.md"
authors = [
    { name = "Mark Fogle", email = "mark@contextable.com" }
]
requires-python = ">=3.12"
dependencies = [
    "ag-ui-protocol>=0.1.7",
    "aiohttp>=3.12.0",
    "asyncio>=3.4.3",
    "fastapi>=0.115.2",
    "google-adk>=1.14.0",
    "pydantic>=2.11.7",
    "uvicorn>=0.35.0",
]

[build-system]
requires = ["uv_build>=0.8.0,<0.9"]
build-backend = "uv_build"

[dependency-groups]
dev = [
    "black>=25.1.0",
    "flake8>=7.3.0",
    "isort>=6.0.1",
    "mypy>=1.16.1",
    "pluggy>=1.6.0",
    "pytest>=8.4.1",
    "pytest-asyncio>=1.0.0",
    "pytest-cov>=6.2.1",
]



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/pytest.ini
================================================
[pytest]
# Configure pytest for the ADK middleware project
pythonpath = src
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = auto
addopts = --tb=short -v
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
# Exclude server files and utilities that aren't actual tests
ignore = tests/server_setup.py tests/run_tests.py


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/TOOLS.md
================================================
# ADK Middleware Tool Support Guide

This guide covers the tool support functionality in the ADK Middleware.

## Overview

The middleware provides complete bidirectional tool support, enabling AG-UI Protocol tools to execute within Google ADK agents. All tools supplied by the client are currently implemented as long-running tools that emit events to the client for execution and can be combined with backend tools provided by the agent to create a hybrid combined toolset.

### Execution Flow

```
1. Initial AG-UI Run → ADK Agent starts execution
2. ADK Agent requests tool use → Execution pauses
3. Tool events emitted → Client receives tool call information
4. Client executes tools → Results prepared asynchronously
5. Subsequent AG-UI Run with ToolMessage → Tool execution resumes
6. ADK Agent execution resumes → Continues with tool results
7. Final response → Execution completes
```

## Tool Execution Modes

The middleware currently implements all client-supplied tools as long-running:

### Long-Running Tools (Current Implementation)
**Perfect for Human-in-the-Loop (HITL) workflows**

- **Fire-and-forget pattern**: Returns `None` immediately without waiting
- **No timeout applied**: Execution continues until tool result is provided
- **Ideal for**: User approval workflows, document review, manual input collection
- **ADK Pattern**: Established pattern where tools pause execution for human interaction

```python
# Long-running tool example
approval_tool = Tool(
    name="request_approval",
    description="Request human approval for sensitive operations",
    parameters={"type": "object", "properties": {"action": {"type": "string"}}}
)

# Tool execution returns immediately
# Client provides result via ToolMessage in subsequent run
```

## Tool Configuration Examples

### Creating Tools

```python
from ag_ui_adk import ADKAgent
from google.adk.agents import LlmAgent
from ag_ui.core import RunAgentInput, UserMessage, Tool

# 1. Create tools for different purposes
# Tool for human approval
task_approval_tool = Tool(
    name="request_approval",
    description="Request human approval for task execution",
    parameters={
        "type": "object",
        "properties": {
            "task": {"type": "string", "description": "Task requiring approval"},
            "risk_level": {"type": "string", "enum": ["low", "medium", "high"]}
        },
        "required": ["task"]
    }
)

# Tool for calculations
calculator_tool = Tool(
    name="calculate",
    description="Perform mathematical calculations",
    parameters={
        "type": "object",
        "properties": {
            "expression": {"type": "string", "description": "Mathematical expression"}
        },
        "required": ["expression"]
    }
)

# Tool for API calls
weather_tool = Tool(
    name="get_weather",
    description="Get current weather information",
    parameters={
        "type": "object",
        "properties": {
            "location": {"type": "string", "description": "City name"}
        },
        "required": ["location"]
    }
)

# 2. Set up ADK agent with tool support
agent = LlmAgent(
    name="assistant",
    model="gemini-2.0-flash",
    instruction="""You are a helpful assistant that can request approvals and perform calculations.
    Use request_approval for sensitive operations that need human review.
    Use calculate for math operations and get_weather for weather information."""
)

# 3. Create middleware
adk_agent = ADKAgent(
    adk_agent=agent,
    user_id="user123",
    tool_timeout_seconds=60,       # Timeout configuration
    execution_timeout_seconds=300  # Overall execution timeout
)

# 4. Include tools in RunAgentInput
user_input = RunAgentInput(
    thread_id="thread_123",
    run_id="run_456",
    messages=[UserMessage(
        id="1",
        role="user",
        content="Calculate 15 * 8 and then request approval for the result"
    )],
    tools=[task_approval_tool, calculator_tool, weather_tool],
    context=[],
    state={},
    forwarded_props={}
)
```

## Tool Execution Flow Example

Example showing how tools are handled across multiple AG-UI runs:

```python
async def demonstrate_tool_execution():
    """Example showing tool execution flow."""

    # Step 1: Initial run - starts execution with tools
    print("🚀 Starting execution with tools...")

    initial_events = []
    async for event in adk_agent.run(user_input):
        initial_events.append(event)

        if event.type == "TOOL_CALL_START":
            print(f"🔧 Tool call: {event.tool_call_name} (ID: {event.tool_call_id})")
        elif event.type == "TEXT_MESSAGE_CONTENT":
            print(f"💬 Assistant: {event.delta}", end="", flush=True)

    print("\n📊 Initial execution completed - tools awaiting results")

    # Step 2: Handle tool results
    tool_results = []

    # Extract tool calls from events
    for event in initial_events:
        if event.type == "TOOL_CALL_START":
            tool_call_id = event.tool_call_id
            tool_name = event.tool_call_name

            if tool_name == "calculate":
                # Execute calculation
                result = {"result": 120, "expression": "15 * 8"}
                tool_results.append((tool_call_id, result))

            elif tool_name == "request_approval":
                # Handle human approval
                result = await handle_human_approval(tool_call_id)
                tool_results.append((tool_call_id, result))

    # Step 3: Submit tool results and resume execution
    if tool_results:
        print(f"\n🔄 Resuming execution with {len(tool_results)} tool results...")

        # Create ToolMessage entries for resumption
        tool_messages = []
        for tool_call_id, result in tool_results:
            tool_messages.append(
                ToolMessage(
                    id=f"tool_{tool_call_id}",
                    role="tool",
                    content=json.dumps(result),
                    tool_call_id=tool_call_id
                )
            )

        # Resume execution with tool results
        resume_input = RunAgentInput(
            thread_id=user_input.thread_id,
            run_id=f"{user_input.run_id}_resume",
            messages=tool_messages,
            tools=[],  # No new tools needed
            context=[],
            state={},
            forwarded_props={}
        )

        # Continue execution with results
        async for event in adk_agent.run(resume_input):
            if event.type == "TEXT_MESSAGE_CONTENT":
                print(f"💬 Assistant: {event.delta}", end="", flush=True)
            elif event.type == "RUN_FINISHED":
                print(f"\n✅ Execution completed successfully!")

async def handle_human_approval(tool_call_id):
    """Simulate human approval workflow for long-running tools."""
    print(f"\n👤 Human approval requested for call {tool_call_id}")
    print("⏳ Waiting for human input...")

    # Simulate user interaction delay
    await asyncio.sleep(2)

    return {
        "approved": True,
        "approver": "user123",
        "timestamp": time.time(),
        "comments": "Approved after review"
    }
```

## Tool Categories

### Human-in-the-Loop Tools
Perfect for workflows requiring human approval, review, or input:

```python
# Tools that pause execution for human interaction
approval_tools = [
    Tool(name="request_approval", description="Request human approval for actions"),
    Tool(name="collect_feedback", description="Collect user feedback on generated content"),
    Tool(name="review_document", description="Submit document for human review")
]
```

### Generative UI Tools
Enable dynamic UI generation based on tool results:

```python
# Tools that generate UI components
ui_generation_tools = [
    Tool(name="generate_form", description="Generate dynamic forms"),
    Tool(name="create_dashboard", description="Create data visualization dashboards"),
    Tool(name="build_workflow", description="Build interactive workflow UIs")
]
```

## Real-World Example: Tool-Based Generative UI

The `examples/tool_based_generative_ui/` directory contains an example that integrates with the existing haiku app in the Dojo:

### Haiku Generator with Image Selection

```python
# Tool for generating haiku with complementary images
haiku_tool = Tool(
    name="generate_haiku",
    description="Generate a traditional Japanese haiku with selected images",
    parameters={
        "type": "object",
        "properties": {
            "japanese_haiku": {
                "type": "string",
                "description": "Traditional 5-7-5 syllable haiku in Japanese"
            },
            "english_translation": {
                "type": "string",
                "description": "Poetic English translation"
            },
            "selected_images": {
                "type": "array",
                "items": {"type": "string"},
                "description": "Exactly 3 image filenames that complement the haiku"
            },
            "theme": {
                "type": "string",
                "description": "Theme or mood of the haiku"
            }
        },
        "required": ["japanese_haiku", "english_translation", "selected_images"]
    }
)
```

### Key Features Demonstrated
- **ADK Agent Integration**: ADK agent creates haiku with structured output
- **Structured Tool Output**: Tool returns JSON with haiku, translation, and image selections
- **Generative UI**: Client can dynamically render UI based on tool results

### Usage Pattern
```python
# 1. User generates request
# 2. ADK agent analyzes request and calls generate_haiku tool
# 3. Tool returns structured data with haiku and image selections
# 4. Client renders UI with haiku text and selected images
# 5. User can request variations or different themes
```

This example showcases applications where:
- **AI agents** generate structured content
- **Dynamic UI** adapts based on tool output
- **Interactive workflows** allow refinement and iteration
- **Rich media** combines text, images, and user interface elements

## Working Examples

See the `examples/` directory for working examples:

- **`tool_based_generative_ui/`**: Generative UI example integrating with Dojo
  - Structured output for UI generation
  - Dynamic UI rendering based on tool results
  - Interactive workflows with user refinement
  - Real-world application patterns

## Tool Events

The middleware emits the following AG-UI events for tools:

| Event Type | Description |
|------------|-------------|
| `TOOL_CALL_START` | Tool execution begins |
| `TOOL_CALL_ARGS` | Tool arguments provided |
| `TOOL_CALL_END` | Tool execution completes |

## Best Practices

1. **Tool Design**: Create tools with clear, single responsibilities
2. **Parameter Validation**: Use JSON schema for robust parameter validation
3. **Error Handling**: Implement proper error handling in tool implementations
4. **Event Monitoring**: Monitor tool events for debugging and observability
5. **Tool Documentation**: Provide clear descriptions for tool discovery

## Related Documentation

- [CONFIGURATION.md](./CONFIGURATION.md) - Tool timeout configuration
- [ARCHITECTURE.md](./ARCHITECTURE.md) - Technical details on tool proxy implementation
- [USAGE.md](./USAGE.md) - General usage examples
- [README.md](./README.md) - Quick start guide


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/USAGE.md
================================================
# ADK Middleware Usage Guide

This guide provides detailed usage instructions and configuration options for the ADK Middleware.

## Configuration Options

### App and User Identification

```python
# Static app name and user ID (single-tenant apps)
agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app", 
    user_id="static_user"
)

# Dynamic extraction from context (recommended for multi-tenant)
def extract_app(input: RunAgentInput) -> str:
    # Extract from context
    for ctx in input.context:
        if ctx.description == "app":
            return ctx.value
    return "default_app"

def extract_user(input: RunAgentInput) -> str:
    # Extract from context
    for ctx in input.context:
        if ctx.description == "user":
            return ctx.value
    return f"anonymous_{input.thread_id}"

agent = ADKAgent(
    adk_agent=my_agent,
    app_name_extractor=extract_app,
    user_id_extractor=extract_user
)
```

### Session Management

Session management is handled automatically by the singleton `SessionManager`. The middleware uses sensible defaults, but you can configure session behavior if needed by accessing the session manager directly:

```python
from ag_ui_adk.session_manager import SessionManager

# Session management is automatic, but you can access the manager if needed
session_mgr = SessionManager.get_instance()

# Create your ADK agent normally
agent = ADKAgent(
    app_name="my_app",
    user_id="user123",
    use_in_memory_services=True
)
```

### Service Configuration

```python
# Development (in-memory services) - Default
agent = ADKAgent(
    app_name="my_app",
    user_id="user123",
    use_in_memory_services=True  # Default behavior
)

# Production with custom services
agent = ADKAgent(
    app_name="my_app", 
    user_id="user123",
    artifact_service=GCSArtifactService(),
    memory_service=VertexAIMemoryService(),  
    credential_service=SecretManagerService(),
    use_in_memory_services=False
)
```

### Automatic Session Memory

When you provide a `memory_service`, the middleware automatically preserves expired sessions in ADK's memory service before deletion. This enables powerful conversation history and context retrieval features.

```python
from google.adk.memory import VertexAIMemoryService

# Enable automatic session memory
agent = ADKAgent(
    app_name="my_app",
    user_id="user123", 
    memory_service=VertexAIMemoryService(),  # Sessions auto-saved here on expiration
    use_in_memory_services=False
)

# Now when sessions expire (default 20 minutes), they're automatically:
# 1. Added to memory via memory_service.add_session_to_memory()
# 2. Then deleted from active session storage
# 3. Available for retrieval and context in future conversations
```

## Memory Tools Integration

To enable memory functionality in your ADK agents, you need to add Google ADK's memory tools to your agents (not to the ADKAgent middleware):

```python
from google.adk.agents import Agent
from google.adk import tools as adk_tools

# Create agent with memory tools - THIS IS CORRECT
my_agent = Agent(
    name="assistant",
    model="gemini-2.0-flash", 
    instruction="You are a helpful assistant.",
    tools=[adk_tools.preload_memory_tool.PreloadMemoryTool()]  # Add memory tools here
)

# Create middleware with direct agent embedding
adk_agent = ADKAgent(
    adk_agent=my_agent,
    app_name="my_app",
    user_id="user123",
    memory_service=shared_memory_service  # Memory service enables automatic session memory
)
```

**⚠️ Important**: The `tools` parameter belongs to the ADK agent (like `Agent` or `LlmAgent`), **not** to the `ADKAgent` middleware. The middleware automatically handles any tools defined on the embedded agents.

**Testing Memory Workflow:**

1. Start a conversation and provide information (e.g., "My name is John")
2. Wait for session timeout + cleanup interval (up to 90 seconds with testing config: 60s timeout + up to 30s for next cleanup cycle)
3. Start a new conversation and ask about the information ("What's my name?").
4. The agent should remember the information from the previous session.

## Examples

### Simple Conversation

```python
import asyncio
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent
from ag_ui.core import RunAgentInput, UserMessage

async def main():
    # Setup
    my_agent = Agent(name="assistant", instruction="You are a helpful assistant.")
    
    agent = ADKAgent(
        adk_agent=my_agent,
        app_name="demo_app", 
        user_id="demo"
    )
    
    # Create input
    input = RunAgentInput(
        thread_id="thread_001",
        run_id="run_001",
        messages=[
            UserMessage(id="1", role="user", content="Hello!")
        ],
        context=[],
        state={},
        tools=[],
        forwarded_props={}
    )
    
    # Run and handle events
    async for event in agent.run(input):
        print(f"Event: {event.type}")
        if hasattr(event, 'delta'):
            print(f"Content: {event.delta}")

asyncio.run(main())
```

### Multi-Agent Setup

```python
# Create multiple agent instances with different ADK agents
general_agent_wrapper = ADKAgent(
    adk_agent=general_agent,
    app_name="demo_app",
    user_id="demo"
)

technical_agent_wrapper = ADKAgent(
    adk_agent=technical_agent,
    app_name="demo_app",
    user_id="demo"
)

creative_agent_wrapper = ADKAgent(
    adk_agent=creative_agent,
    app_name="demo_app",
    user_id="demo"
)

# Use different endpoints for each agent
from fastapi import FastAPI
from ag_ui_adk import add_adk_fastapi_endpoint

app = FastAPI()
add_adk_fastapi_endpoint(app, general_agent_wrapper, path="/agents/general")
add_adk_fastapi_endpoint(app, technical_agent_wrapper, path="/agents/technical")
add_adk_fastapi_endpoint(app, creative_agent_wrapper, path="/agents/creative")
```

## Event Translation

The middleware translates between AG-UI and ADK event formats:

| AG-UI Event | ADK Event | Description |
|-------------|-----------|-------------|
| TEXT_MESSAGE_* | Event with content.parts[].text | Text messages |
| RUN_STARTED/FINISHED | Runner lifecycle | Execution flow |

## Additional Resources

- For configuration options, see [CONFIGURATION.md](./CONFIGURATION.md)
- For architecture details, see [ARCHITECTURE.md](./ARCHITECTURE.md)
- For development setup, see the main [README.md](./README.md)
- For API documentation, refer to the source code docstrings


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/README.md
================================================
# ADK Middleware Examples

This directory contains example implementations of the ADK middleware with FastAPI.

## Setup

1. Install dependencies:
   ```bash
   uv sync
   ```

2. Run the development server:
   ```bash
   uv run dev
   ```

## Available Endpoints

- `/` - Root endpoint with basic information
- `/chat` - Basic chat agent
- `/adk-tool-based-generative-ui` - Tool-based generative UI example
- `/adk-human-in-loop-agent` - Human-in-the-loop example
- `/adk-shared-state-agent` - Shared state example
- `/adk-predictive-state-agent` - Predictive state updates example
- `/docs` - FastAPI documentation

## Features Demonstrated

- **Basic Chat**: Simple conversational agent
- **Tool Based Generative UI**: Agent that generates haiku with image selection
- **Human in the Loop**: Task planning with human oversight
- **Shared State**: Recipe management with persistent state
- **Predictive State Updates**: Document writing with state awareness

## Requirements

- Python 3.9+
- Google ADK (google.adk)
- ADK Middleware package



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/pyproject.toml
================================================
tool.uv.package = true

[project]
name = "adk-middleware-examples"
version = "0.1.0"
description = "Example usage of the ADK middleware with FastAPI"
license = "MIT"

readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
    "ag_ui_adk",
]

[project.scripts]
dev = "server:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["server"]

[tool.hatch.metadata]
allow-direct-references = true

[tool.uv.sources]
ag_ui_adk = { path = "../" }



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/other/complete_setup.py
================================================
#!/usr/bin/env python
"""Complete setup example for ADK middleware with AG-UI."""

import logging

import asyncio
import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# Set up basic logging format
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Configure component-specific logging levels using standard Python logging
# Can be overridden with PYTHONPATH or programmatically
logging.getLogger('adk_agent').setLevel(logging.WARNING)
logging.getLogger('event_translator').setLevel(logging.WARNING)
logging.getLogger('endpoint').setLevel(logging.WARNING)
logging.getLogger('session_manager').setLevel(logging.WARNING)
logging.getLogger('agent_registry').setLevel(logging.WARNING)

# from adk_agent import ADKAgent
# from agent_registry import AgentRegistry
# from endpoint import add_adk_fastapi_endpoint
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
# Import Google ADK components
from google.adk.agents import Agent
from google.adk import tools as adk_tools
import os

# Ensure session_manager logger is set to DEBUG after import
logging.getLogger('ag_ui_adk.session_manager').setLevel(logging.DEBUG)
# Also explicitly set adk_agent logger to DEBUG
logging.getLogger('ag_ui_adk.adk_agent').setLevel(logging.DEBUG)


async def setup_and_run():
    """Complete setup and run the server."""

    # Step 1: Configure Google ADK authentication
    # Google ADK uses environment variables for authentication:
    # export GOOGLE_API_KEY="your-api-key-here"
    #
    # Or use Application Default Credentials (ADC):
    # gcloud auth application-default login

    # The API key will be automatically picked up from the environment


    # Step 2: Create shared memory service
    print("🧠 Creating shared memory service...")
    from google.adk.memory import InMemoryMemoryService
    shared_memory_service = InMemoryMemoryService()

    # Step 3: Create your ADK agent(s)
    print("🤖 Creating ADK agents...")

    # Create a versatile assistant
    assistant = Agent(
        name="ag_ui_assistant",
        model="gemini-2.0-flash",
        instruction="""You are a helpful AI assistant integrated with AG-UI protocol.

        Your capabilities:
        - Answer questions accurately and concisely
        - Help with coding and technical topics
        - Provide step-by-step explanations
        - Admit when you don't know something

        Always be friendly and professional.""",
        tools=[adk_tools.preload_memory_tool.PreloadMemoryTool()]
    )

    # Try to import haiku generator agent
    print("🎋 Attempting to import haiku generator agent...")
    haiku_generator_agent = None
    try:
        from tool_based_generative_ui.agent import haiku_generator_agent
        print(f"   ✅ Successfully imported haiku_generator_agent")
        print(f"   Type: {type(haiku_generator_agent)}")
        print(f"   Name: {getattr(haiku_generator_agent, 'name', 'NO NAME')}")
        print(f"   ✅ Available for use")
    except Exception as e:
        print(f"   ❌ Failed to import haiku_generator_agent: {e}")

    print(f"\n📋 Available agents:")
    print(f"   - assistant: {assistant.name}")
    if haiku_generator_agent:
        print(f"   - haiku_generator: {haiku_generator_agent.name}")


    # Step 4: Configure ADK middleware
    print("⚙️ Configuring ADK middleware...")

    # Option A: Static app name and user ID (simple testing)
    # adk_agent = ADKAgent(
    #     app_name="demo_app",
    #     user_id="demo_user",
    #     use_in_memory_services=True
    # )

    # Option B: Dynamic extraction from context (recommended)
    def extract_user_id(input_data):
        """Extract user ID from context."""
        for ctx in input_data.context:
            if ctx.description == "user":
                return ctx.value
        return "test_user"  # Static user ID for memory testing

    def extract_app_name(input_data):
        """Extract app name from context."""
        for ctx in input_data.context:
            if ctx.description == "app":
                return ctx.value
        return "default_app"

    # Create ADKAgent instances for different agents
    assistant_adk_agent = ADKAgent(
        adk_agent=assistant,
        app_name_extractor=extract_app_name,
        user_id_extractor=extract_user_id,
        use_in_memory_services=True,
        memory_service=shared_memory_service,  # Use the same memory service as the ADK agent
        # Defaults: 1200s timeout (20 min), 300s cleanup (5 min)
    )

    haiku_adk_agent = None
    if haiku_generator_agent:
        haiku_adk_agent = ADKAgent(
            adk_agent=haiku_generator_agent,
            app_name_extractor=extract_app_name,
            user_id_extractor=extract_user_id,
            use_in_memory_services=True,
            memory_service=shared_memory_service,
        )

    # Step 5: Create FastAPI app
    print("🌐 Creating FastAPI app...")
    app = FastAPI(
        title="ADK-AG-UI Integration Server",
        description="Google ADK agents exposed via AG-UI protocol"
    )

    # Add CORS for browser clients
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["http://localhost:3000", "http://localhost:5173"],  # Add your client URLs
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )


    # Step 6: Add endpoints
    # Each endpoint uses its specific ADKAgent instance
    add_adk_fastapi_endpoint(app, assistant_adk_agent, path="/chat")

    # Add haiku generator endpoint if available
    if haiku_adk_agent:
        add_adk_fastapi_endpoint(app, haiku_adk_agent, path="/adk-tool-based-generative-ui")
        print("   ✅ Added endpoint: /adk-tool-based-generative-ui")
    else:
        print("   ❌ Skipped haiku endpoint - agent not available")

    # Agent-specific endpoints (optional) - each would use its own ADKAgent instance
    # assistant_adk_agent = ADKAgent(adk_agent=assistant, ...)
    # add_adk_fastapi_endpoint(app, assistant_adk_agent, path="/agents/assistant")
    # code_helper_adk_agent = ADKAgent(adk_agent=code_helper, ...)
    # add_adk_fastapi_endpoint(app, code_helper_adk_agent, path="/agents/code-helper")

    @app.get("/")
    async def root():
        available_agents = ["assistant"]
        endpoints = {"chat": "/chat", "docs": "/docs", "health": "/health"}
        if haiku_generator_agent:
            available_agents.append("haiku-generator")
            endpoints["adk-tool-based-generative-ui"] = "/adk-tool-based-generative-ui"

        return {
            "service": "ADK-AG-UI Integration",
            "version": "0.1.0",
            "agents": {
                "default": "assistant",
                "available": available_agents
            },
            "endpoints": endpoints
        }

    @app.get("/health")
    async def health():
        agent_count = 1  # assistant
        if haiku_generator_agent:
            agent_count += 1
        return {
            "status": "healthy",
            "agents_available": agent_count,
            "default_agent": "assistant"
        }

    @app.get("/agents")
    async def list_agents():
        """List available agents."""
        available_agents = ["assistant"]
        if haiku_generator_agent:
            available_agents.append("haiku-generator")
        return {
            "agents": available_agents,
            "default": "assistant"
        }


    # Step 7: Run the server
    print("\n✅ Setup complete! Starting server...\n")
    print("🔗 Chat endpoint: http://localhost:8000/chat")
    print("📚 API documentation: http://localhost:8000/docs")
    print("🏥 Health check: http://localhost:8000/health")
    print("\n🔧 Logging Control:")
    print("   # Set logging level for specific components:")
    print("   logging.getLogger('event_translator').setLevel(logging.DEBUG)")
    print("   logging.getLogger('endpoint').setLevel(logging.DEBUG)")
    print("   logging.getLogger('session_manager').setLevel(logging.DEBUG)")
    print("\n🧪 Test with curl:")
    print('curl -X POST http://localhost:8000/chat \\')
    print('  -H "Content-Type: application/json" \\')
    print('  -H "Accept: text/event-stream" \\')
    print('  -d \'{')
    print('    "thread_id": "test-123",')
    print('    "run_id": "run-456",')
    print('    "messages": [{"role": "user", "content": "Hello! What can you do?"}],')
    print('    "context": [')
    print('      {"description": "user", "value": "john_doe"},')
    print('      {"description": "app", "value": "my_app_v1"}')
    print('    ]')
    print('  }\'')

    # Run with uvicorn
    config = uvicorn.Config(app, host="0.0.0.0", port=8000, log_level="info")
    server = uvicorn.Server(config)
    await server.serve()


if __name__ == "__main__":
    # Check for API key
    if not os.getenv("GOOGLE_API_KEY"):
        print("⚠️  Warning: GOOGLE_API_KEY environment variable not set!")
        print("   Set it with: export GOOGLE_API_KEY='your-key-here'")
        print("   Get a key from: https://makersuite.google.com/app/apikey")
        print()

    # Run the async setup
    asyncio.run(setup_and_run())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/other/configure_adk_agent.py
================================================
#!/usr/bin/env python
"""Example of configuring and registering Google ADK agents."""

import os
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# from agent_registry import AgentRegistry
from ag_ui_adk import AgentRegistry
from google.adk.agents import Agent
from google.adk.tools import Tool
from google.genai import types

# Example 1: Simple conversational agent
def create_simple_agent():
    """Create a basic conversational agent."""
    agent = Agent(
        name="simple_assistant",
        instruction="""You are a helpful AI assistant.
        Be concise and friendly in your responses.
        If you don't know something, say so honestly."""
    )
    return agent


# Example 2: Agent with specific model configuration
def create_configured_agent():
    """Create an agent with specific model settings."""
    agent = Agent(
        name="advanced_assistant",
        model="gemini-2.0-flash",
        instruction="""You are an expert technical assistant.
        Provide detailed, accurate technical information.
        Use examples when explaining complex concepts.""",
        # Optional: Add generation config
        generation_config=types.GenerationConfig(
            temperature=0.7,
            top_p=0.95,
            top_k=40,
            max_output_tokens=2048,
        )
    )
    return agent


# Example 3: Agent with tools
def create_agent_with_tools():
    """Create an agent with custom tools."""

    # Define a simple tool
    def get_current_time():
        """Get the current time."""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def calculate(expression: str):
        """Safely evaluate a mathematical expression."""
        try:
            # In production, use a proper math parser
            result = eval(expression, {"__builtins__": {}}, {})
            return f"Result: {result}"
        except Exception as e:
            return f"Error: {str(e)}"

    # Create tools
    time_tool = Tool(
        name="get_time",
        description="Get the current date and time",
        func=get_current_time
    )

    calc_tool = Tool(
        name="calculator",
        description="Calculate mathematical expressions",
        func=calculate
    )

    # Create agent with tools
    agent = Agent(
        name="assistant_with_tools",
        instruction="""You are a helpful assistant with access to tools.
        Use the get_time tool when asked about the current time or date.
        Use the calculator tool for mathematical calculations.""",
        tools=[time_tool, calc_tool]
    )
    return agent


# Example 4: Domain-specific agent
def create_domain_agent():
    """Create a domain-specific agent (e.g., for customer support)."""
    agent = Agent(
        name="support_agent",
        instruction="""You are a customer support specialist.

        Your responsibilities:
        1. Help users troubleshoot technical issues
        2. Provide information about products and services
        3. Escalate complex issues when needed

        Always:
        - Be empathetic and patient
        - Ask clarifying questions
        - Provide step-by-step solutions
        - Follow up to ensure issues are resolved""",
        model="gemini-1.5-pro",
    )
    return agent


# Example 5: Multi-agent setup
def setup_multi_agent_system():
    """Set up multiple agents for different purposes."""
    registry = AgentRegistry.get_instance()

    # Create different agents
    general_agent = create_simple_agent()
    technical_agent = create_configured_agent()
    support_agent = create_domain_agent()

    # Register agents with specific IDs
    registry.register_agent("general", general_agent)
    registry.register_agent("technical", technical_agent)
    registry.register_agent("support", support_agent)

    # Set default agent
    registry.set_default_agent(general_agent)

    print("Registered agents:")
    print("- general: General purpose assistant")
    print("- technical: Technical expert")
    print("- support: Customer support specialist")
    print(f"\nDefault agent: {registry.get_default_agent().name}")


# Example 6: Loading agent configuration from environment
def create_agent_from_env():
    """Create an agent using environment variables for configuration."""
    agent = Agent(
        name=os.getenv("ADK_AGENT_NAME", "assistant"),
        model=os.getenv("ADK_MODEL", "gemini-2.0-flash"),
        instruction=os.getenv("ADK_INSTRUCTIONS", "You are a helpful assistant."),
        # API key would be handled by Google ADK's auth system
    )
    return agent


# Main setup function
def setup_adk_agents():
    """Main function to set up ADK agents for the middleware."""
    registry = AgentRegistry.get_instance()

    # Choose your setup approach:

    # Option 1: Single simple agent
    agent = create_simple_agent()
    registry.set_default_agent(agent)

    # Option 2: Multiple agents
    # setup_multi_agent_system()

    # Option 3: Agent with tools
    # agent = create_agent_with_tools()
    # registry.set_default_agent(agent)

    return registry


if __name__ == "__main__":
    # Test the setup
    setup_adk_agents()

    # Test retrieval
    registry = AgentRegistry.get_instance()
    default_agent = registry.get_default_agent()
    print(f"Default agent configured: {default_agent.name}")


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/other/simple_agent.py
================================================
# examples/simple_agent.py

"""Simple example of using ADK middleware with AG-UI protocol.

This example demonstrates the basic setup and usage of the ADK middleware
for a simple conversational agent.
"""

import asyncio
import logging
from typing import AsyncGenerator

from ag_ui_adk import ADKAgent, AgentRegistry
from google.adk.agents import LlmAgent
from ag_ui.core import RunAgentInput, BaseEvent, Message, UserMessage, Context

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def main():
    """Main function demonstrating simple agent usage."""

    # Step 1: Create an ADK agent
    simple_adk_agent = LlmAgent(
        name="assistant",
        model="gemini-2.0-flash",
        instruction="You are a helpful AI assistant. Be concise and friendly."
    )

    # Step 2: Register the agent
    registry = AgentRegistry.get_instance()
    registry.set_default_agent(simple_adk_agent)

    # Step 3: Create the middleware agent
    # Note: app_name will default to the agent name ("assistant")
    agent = ADKAgent(
        user_id="demo_user",  # Static user for this example
    )

    # Step 4: Create a sample input
    run_input = RunAgentInput(
        thread_id="demo_thread_001",
        run_id="run_001",
        messages=[
            UserMessage(
                id="msg_001",
                role="user",
                content="Hello! Can you tell me about the weather?"
            )
        ],
        context=[
            Context(description="demo_mode", value="true")
        ],
        state={},
        tools=[],
        forwarded_props={}
    )

    # Step 5: Run the agent and print events
    print("Starting agent conversation...")
    print("-" * 50)

    async for event in agent.run(run_input):
        handle_event(event)

    print("-" * 50)
    print("Conversation complete!")

    # Cleanup
    await agent.close()


def handle_event(event: BaseEvent):
    """Handle and display AG-UI events."""
    event_type = event.type.value if hasattr(event.type, 'value') else str(event.type)

    if event_type == "RUN_STARTED":
        print("🚀 Agent run started")
    elif event_type == "RUN_FINISHED":
        print("✅ Agent run finished")
    elif event_type == "RUN_ERROR":
        print(f"❌ Error: {event.message}")
    elif event_type == "TEXT_MESSAGE_START":
        print("💬 Assistant: ", end="", flush=True)
    elif event_type == "TEXT_MESSAGE_CONTENT":
        print(event.delta, end="", flush=True)
    elif event_type == "TEXT_MESSAGE_END":
        print()  # New line after message
    elif event_type == "TEXT_MESSAGE_CONTENT":
        print(f"💬 Assistant: {event.delta}")
    else:
        print(f"📋 Event: {event_type}")


async def advanced_example():
    """Advanced example with multiple messages and state."""

    # Create a more sophisticated agent
    advanced_agent = LlmAgent(
        name="research_assistant",
        model="gemini-2.0-flash",
        instruction="""You are a research assistant.
        Keep track of topics the user is interested in.
        Be thorough but well-organized in your responses."""
    )

    # Register with a specific ID
    registry = AgentRegistry.get_instance()
    registry.register_agent("researcher", advanced_agent)

    # Create middleware with custom user extraction
    def extract_user_from_context(input: RunAgentInput) -> str:
        for ctx in input.context:
            if ctx.description == "user_email":
                return ctx.value.split("@")[0]  # Use email prefix as user ID
        return "anonymous"

    agent = ADKAgent(
        user_id_extractor=extract_user_from_context,
        # app_name will default to the agent name ("research_assistant")
    )

    # Simulate a conversation with history
    messages = [
        UserMessage(id="1", role="user", content="I'm interested in quantum computing"),
        # In a real scenario, you'd have assistant responses here
        UserMessage(id="2", role="user", content="Can you explain quantum entanglement?")
    ]

    run_input = RunAgentInput(
        thread_id="research_thread_001",
        run_id="run_002",
        messages=messages,
        context=[
            Context(description="user_email", value="researcher@example.com"),
            Context(description="agent_id", value="researcher")
        ],
        state={"topics_of_interest": ["quantum computing"]},
        tools=[],
        forwarded_props={}
    )

    print("\nAdvanced Example - Research Assistant")
    print("=" * 50)

    async for event in agent.run(run_input):
        handle_event(event)

    await agent.close()


if __name__ == "__main__":
    # Run the simple example
    asyncio.run(main())

    # Uncomment to run the advanced example
    # asyncio.run(advanced_example())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/__init__.py
================================================
"""Example usage of the ADK middleware with FastAPI.

This provides a FastAPI application that demonstrates how to use the
ADK middleware with various agent types. It includes examples for
each of the ADK middleware features:
- Agentic Chat Agent
- Tool Based Generative UI
- Human in the Loop
- Shared State
- Predictive State Updates
"""

from __future__ import annotations

from fastapi import FastAPI
import uvicorn
import os


from .api import (
    agentic_chat_app,
    tool_based_generative_ui_app,
    human_in_the_loop_app,
    shared_state_app,
    # predictive_state_updates_app,
)

app = FastAPI(title='ADK Middleware Demo')

# Include routers instead of mounting apps to show routes in docs
app.include_router(agentic_chat_app.router, prefix='/chat', tags=['Agentic Chat'])
app.include_router(tool_based_generative_ui_app.router, prefix='/adk-tool-based-generative-ui', tags=['Tool Based Generative UI'])
app.include_router(human_in_the_loop_app.router, prefix='/adk-human-in-loop-agent', tags=['Human in the Loop'])
app.include_router(shared_state_app.router, prefix='/adk-shared-state-agent', tags=['Shared State'])
# app.include_router(predictive_state_updates_app.router, prefix='/adk-predictive-state-agent', tags=['Predictive State Updates'])


@app.get("/")
async def root():
    return {
        "message": "ADK Middleware is running!",
        "endpoints": {
            "chat": "/chat",
            "tool_based_generative_ui": "/adk-tool-based-generative-ui",
            "human_in_the_loop": "/adk-human-in-loop-agent",
            "shared_state": "/adk-shared-state-agent",
            # "predictive_state_updates": "/adk-predictive-state-agent",
            "docs": "/docs"
        }
    }


def main():
    """Main function to start the FastAPI server."""
    # Check for authentication credentials
    google_api_key = os.getenv("GOOGLE_API_KEY")
    google_app_creds = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

    if not google_api_key and not google_app_creds:
        print("⚠️  Warning: No Google authentication credentials found!")
        print()
        print("   Google ADK uses environment variables for authentication:")
        print("   - API Key:")
        print("     ```")
        print("     export GOOGLE_API_KEY='your-api-key-here'")
        print("     ```")
        print("     Get a key from: https://makersuite.google.com/app/apikey")
        print()
        print("   - Or use Application Default Credentials (ADC):")
        print("     ```")
        print("     gcloud auth application-default login")
        print("     export GOOGLE_APPLICATION_CREDENTIALS='path/to/service-account.json'")
        print("     ```")
        print("     See docs here: https://cloud.google.com/docs/authentication/application-default-credentials")
        print()
        print("   The credentials will be automatically picked up from the environment")
        print()

    port = int(os.getenv("PORT", "8000"))
    print("Starting ADK Middleware server...")
    print(f"Available endpoints:")
    print(f"  • Chat: http://localhost:{port}/chat")
    print(f"  • Tool Based Generative UI: http://localhost:{port}/adk-tool-based-generative-ui")
    print(f"  • Human in the Loop: http://localhost:{port}/adk-human-in-loop-agent")
    print(f"  • Shared State: http://localhost:{port}/adk-shared-state-agent")
    # print(f"  • Predictive State Updates: http://localhost:{port}/adk-predictive-state-agent")
    print(f"  • API docs: http://localhost:{port}/docs")
    uvicorn.run(app, host="0.0.0.0", port=port)


if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/api/__init__.py
================================================
"""API modules for ADK middleware examples."""

from .agentic_chat import app as agentic_chat_app
from .tool_based_generative_ui import app as tool_based_generative_ui_app
from .human_in_the_loop import app as human_in_the_loop_app
from .shared_state import app as shared_state_app
from .predictive_state_updates import app as predictive_state_updates_app

__all__ = [
    "agentic_chat_app",
    "tool_based_generative_ui_app",
    "human_in_the_loop_app",
    "shared_state_app",
    "predictive_state_updates_app",
]



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/api/agentic_chat.py
================================================
"""Basic Chat feature."""

from __future__ import annotations

from fastapi import FastAPI
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
from google.adk.agents import LlmAgent
from google.adk import tools as adk_tools

# Create a sample ADK agent (this would be your actual agent)
sample_agent = LlmAgent(
    name="assistant",
    model="gemini-2.0-flash",
    instruction="""
    You are a helpful assistant. Help users by answering their questions and assisting with their needs.
    - If the user greets you, please greet them back with specifically with "Hello".
    - If the user greets you and does not make any request, greet them and ask "how can I assist you?"
    - If the user makes a statement without making a request, you do not need to tell them you can't do anything about it.
      Try to say something conversational about it in response, making sure to mention the topic directly.
    - If the user asks you a question, if possible you can answer it using previous context without telling them that you cannot look it up.
      Only tell the user that you cannot search if you do not have enough information already to answer.
    """,
    tools=[adk_tools.preload_memory_tool.PreloadMemoryTool()]
)

# Create ADK middleware agent instance
chat_agent = ADKAgent(
    adk_agent=sample_agent,
    app_name="demo_app",
    user_id="demo_user",
    session_timeout_seconds=3600,
    use_in_memory_services=True
)

# Create FastAPI app
app = FastAPI(title="ADK Middleware Basic Chat")

# Add the ADK endpoint
add_adk_fastapi_endpoint(app, chat_agent, path="/")



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/api/human_in_the_loop.py
================================================
"""Human in the Loop feature."""

from __future__ import annotations

from fastapi import FastAPI
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
from google.adk.agents import Agent
from google.genai import types

DEFINE_TASK_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_task_steps",
        "description": "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in imperative form (i.e. Dig hole, Open door, ...)",
        "parameters": {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "description": {
                                "type": "string",
                                "description": "The text of the step in imperative form"
                            },
                            "status": {
                                "type": "string",
                                "enum": ["enabled"],
                                "description": "The status of the step, always 'enabled'"
                            }
                        },
                        "required": ["description", "status"]
                    },
                    "description": "An array of 10 step objects, each containing text and status"
                }
            },
            "required": ["steps"]
        }
    }
}

human_in_loop_agent = Agent(
    model='gemini-2.5-flash',
    name='human_in_loop_agent',
    instruction=f"""
        You are a human-in-the-loop task planning assistant that helps break down complex tasks into manageable steps with human oversight and approval.

**Your Primary Role:**
- Generate clear, actionable task steps for any user request
- Facilitate human review and modification of generated steps
- Execute only human-approved steps

**When a user requests a task:**
1. ALWAYS call the `generate_task_steps` function to create 10 step breakdown
2. Each step must be:
   - Written in imperative form (e.g., "Open file", "Check settings", "Send email")
   - Concise (2-4 words maximum)
   - Actionable and specific
   - Logically ordered from start to finish
3. Initially set all steps to "enabled" status
4. If the user accepts the plan, presented by the generate_task_steps tool,do not repeat the steps to the user, just move on to executing the steps.
5. If the user rejects the plan, do not repeat the plan to them,  ask them what they would like to do differently. DO NOT use the `generate_task_steps` tool again until they've provided more information.


**When executing steps:**
- Only execute steps with "enabled" status.
- For each step you are executing, tell the user what you are doing.
  - Pretend you are executing the step in real life and refer to it in the current tense. End each step with an ellipsis.
  - Each step MUST be on a new line. DO NOT combine steps into one line.
  - For example for the following steps:
    - Inhale deeply
    - Exhale forcefully
    - Produce sound
    a good response would be:
    ```
     Inhaling deeply...
     Exhaling forcefully...
     Producing sound...
    ```
    a bad response would be `Inhaling deeply... Exhaling forcefully... Producing sound...` because it is on one line.
- Skip any steps marked as "disabled"
- Afterwards, confirm the execution of the steps to the user, e.g. if the user asked for a plan to go to mars, respond like "I have completed the plan and gone to mars"
- EVERY STEP AND THE CONFIRMATION MUST BE ON A NEW LINE. DO NOT COMBINE THEM INTO ONE LINE. USE A <br> TAG TO SEPARATE THEM.

**Key Guidelines:**
- Always generate exactly 10 steps
- Make steps granular enough to be independently enabled/disabled

Tool reference: {DEFINE_TASK_TOOL}
    """,
    generate_content_config=types.GenerateContentConfig(
        temperature=0.7,  # Slightly higher temperature for creativity
        top_p=0.9,
        top_k=40
    ),
)

# Create ADK middleware agent instance
adk_human_in_loop_agent = ADKAgent(
    adk_agent=human_in_loop_agent,
    app_name="demo_app",
    user_id="demo_user",
    session_timeout_seconds=3600,
    use_in_memory_services=True
)

# Create FastAPI app
app = FastAPI(title="ADK Middleware Human in the Loop")

# Add the ADK endpoint
add_adk_fastapi_endpoint(app, adk_human_in_loop_agent, path="/")



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/api/predictive_state_updates.py
================================================
"""Predictive State Updates feature."""

from __future__ import annotations

from dotenv import load_dotenv
load_dotenv()

import json
import uuid
from typing import Dict, List, Any, Optional
from fastapi import FastAPI
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint

from google.adk.agents import LlmAgent
from google.adk.agents.callback_context import CallbackContext
from google.adk.sessions import InMemorySessionService, Session
from google.adk.runners import Runner
from google.adk.events import Event, EventActions
from google.adk.tools import FunctionTool, ToolContext
from google.genai.types import Content, Part, FunctionDeclaration
from google.adk.models import LlmResponse, LlmRequest
from google.genai import types


def write_document(
    tool_context: ToolContext,
    document: str
) -> Dict[str, str]:
    """
    Write a document. Use markdown formatting to format the document.
    It's good to format the document extensively so it's easy to read.
    You can use all kinds of markdown.
    However, do not use italic or strike-through formatting, it's reserved for another purpose.
    You MUST write the full document, even when changing only a few words.
    When making edits to the document, try to make them minimal - do not change every word.
    Keep stories SHORT!

    Args:
        document: The document content to write in markdown format

    Returns:
        Dict indicating success status and message
    """
    try:
        # Update the session state with the new document
        tool_context.state["document"] = document

        return {"status": "success", "message": "Document written successfully"}

    except Exception as e:
        return {"status": "error", "message": f"Error writing document: {str(e)}"}


def on_before_agent(callback_context: CallbackContext):
    """
    Initialize document state if it doesn't exist.
    """
    if "document" not in callback_context.state:
        # Initialize with empty document
        callback_context.state["document"] = None

    return None


def before_model_modifier(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> Optional[LlmResponse]:
    """
    Modifies the LLM request to include the current document state.
    This enables predictive state updates by providing context about the current document.
    """
    agent_name = callback_context.agent_name
    if agent_name == "DocumentAgent":
        current_document = "No document yet"
        if "document" in callback_context.state and callback_context.state["document"] is not None:
            try:
                current_document = callback_context.state["document"]
            except Exception as e:
                current_document = f"Error retrieving document: {str(e)}"

        # Modify the system instruction to include current document state
        original_instruction = llm_request.config.system_instruction or types.Content(role="system", parts=[])
        prefix = f"""You are a helpful assistant for writing documents.
        To write the document, you MUST use the write_document tool.
        You MUST write the full document, even when changing only a few words.
        When you wrote the document, DO NOT repeat it as a message.
        Just briefly summarize the changes you made. 2 sentences max.
        This is the current state of the document: ----
        {current_document}
        -----"""

        # Ensure system_instruction is Content and parts list exists
        if not isinstance(original_instruction, types.Content):
            original_instruction = types.Content(role="system", parts=[types.Part(text=str(original_instruction))])
        if not original_instruction.parts:
            original_instruction.parts.append(types.Part(text=""))

        # Modify the text of the first part
        modified_text = prefix + (original_instruction.parts[0].text or "")
        original_instruction.parts[0].text = modified_text
        llm_request.config.system_instruction = original_instruction

    return None


# Create the predictive state updates agent
predictive_state_updates_agent = LlmAgent(
    name="DocumentAgent",
    model="gemini-2.5-pro",
    instruction="""
    You are a helpful assistant for writing documents.
    To write the document, you MUST use the write_document tool.
    You MUST write the full document, even when changing only a few words.
    When you wrote the document, DO NOT repeat it as a message.
    Just briefly summarize the changes you made. 2 sentences max.

    IMPORTANT RULES:
    1. Always use the write_document tool for any document writing or editing requests
    2. Write complete documents, not fragments
    3. Use markdown formatting for better readability
    4. Keep stories SHORT and engaging
    5. After using the tool, provide a brief summary of what you created or changed
    6. Do not use italic or strike-through formatting

    Examples of when to use the tool:
    - "Write a story about..." → Use tool with complete story in markdown
    - "Edit the document to..." → Use tool with the full edited document
    - "Add a paragraph about..." → Use tool with the complete updated document

    Always provide complete, well-formatted documents that users can read and use.
    """,
    tools=[write_document],
    before_agent_callback=on_before_agent,
    before_model_callback=before_model_modifier
)

# Create ADK middleware agent instance
adk_predictive_state_agent = ADKAgent(
    adk_agent=predictive_state_updates_agent,
    app_name="demo_app",
    user_id="demo_user",
    session_timeout_seconds=3600,
    use_in_memory_services=True
)

# Create FastAPI app
app = FastAPI(title="ADK Middleware Predictive State Updates")

# Add the ADK endpoint
add_adk_fastapi_endpoint(app, adk_predictive_state_agent, path="/")



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/api/shared_state.py
================================================
"""Shared State feature."""

from __future__ import annotations

from dotenv import load_dotenv
load_dotenv()
import json
from enum import Enum
from typing import Dict, List, Any, Optional
from fastapi import FastAPI
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint

# ADK imports
from google.adk.agents import LlmAgent
from google.adk.agents.callback_context import CallbackContext
from google.adk.sessions import InMemorySessionService, Session
from google.adk.runners import Runner
from google.adk.events import Event, EventActions
from google.adk.tools import FunctionTool, ToolContext
from google.genai.types import Content, Part , FunctionDeclaration
from google.adk.models import LlmResponse, LlmRequest
from google.genai import types

from pydantic import BaseModel, Field
from typing import List, Optional
from enum import Enum

class SkillLevel(str, Enum):
    # Add your skill level values here
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"

class SpecialPreferences(str, Enum):
    # Add your special preferences values here
    VEGETARIAN = "vegetarian"
    VEGAN = "vegan"
    GLUTEN_FREE = "gluten_free"
    DAIRY_FREE = "dairy_free"
    KETO = "keto"
    LOW_CARB = "low_carb"

class CookingTime(str, Enum):
    # Add your cooking time values here
    QUICK = "under_30_min"
    MEDIUM = "30_60_min"
    LONG = "over_60_min"

class Ingredient(BaseModel):
    icon: str = Field(..., description="The icon emoji of the ingredient")
    name: str
    amount: str

class Recipe(BaseModel):
    skill_level: SkillLevel = Field(..., description="The skill level required for the recipe")
    special_preferences: Optional[List[SpecialPreferences]] = Field(
        None,
        description="A list of special preferences for the recipe"
    )
    cooking_time: Optional[CookingTime] = Field(
        None,
        description="The cooking time of the recipe"
    )
    ingredients: List[Ingredient] = Field(..., description="Entire list of ingredients for the recipe")
    instructions: List[str] = Field(..., description="Entire list of instructions for the recipe")
    changes: Optional[str] = Field(
        None,
        description="A description of the changes made to the recipe"
    )

def generate_recipe(
    tool_context: ToolContext,
    skill_level: str,
    title: str,
    special_preferences: List[str] = [],
    cooking_time: str = "",
    ingredients: List[dict] = [],
    instructions: List[str] = [],
    changes: str = ""
) -> Dict[str, str]:
    """
    Generate or update a recipe using the provided recipe data.

    Args:
        "title": {
            "type": "string",
            "description": "**REQUIRED** - The title of the recipe."
        },
        "skill_level": {
            "type": "string",
            "enum": ["Beginner","Intermediate","Advanced"],
            "description": "**REQUIRED** - The skill level required for the recipe. Must be one of the predefined skill levels (Beginner, Intermediate, Advanced)."
        },
        "special_preferences": {
            "type": "array",
            "items": {"type": "string"},
            "enum": ["High Protein","Low Carb","Spicy","Budget-Friendly","One-Pot Meal","Vegetarian","Vegan"],
            "description": "**OPTIONAL** - Special dietary preferences for the recipe as comma-separated values. Example: 'High Protein, Low Carb, Gluten Free'. Leave empty array if no special preferences."
        },
        "cooking_time": {
            "type": "string",
            "enum": [5 min, 15 min, 30 min, 45 min, 60+ min],
            "description": "**OPTIONAL** - The total cooking time for the recipe. Must be one of the predefined time slots (5 min, 15 min, 30 min, 45 min, 60+ min). Omit if time is not specified."
        },
        "ingredients": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "icon": {"type": "string", "description": "The icon emoji (not emoji code like '\x1f35e', but the actual emoji like 🥕) of the ingredient"},
                    "name": {"type": "string"},
                    "amount": {"type": "string"}
                }
            },
            "description": "Entire list of ingredients for the recipe, including the new ingredients and the ones that are already in the recipe"
        },
        "instructions": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Entire list of instructions for the recipe, including the new instructions and the ones that are already there"
            },
        "changes": {
            "type": "string",
            "description": "**OPTIONAL** - A brief description of what changes were made to the recipe compared to the previous version. Example: 'Added more spices for flavor', 'Reduced cooking time', 'Substituted ingredient X for Y'. Omit if this is a new recipe."
        }

    Returns:
        Dict indicating success status and message
    """
    try:


        # Create RecipeData object to validate structure
        recipe = {
            "title": title,
            "skill_level": skill_level,
            "special_preferences": special_preferences ,
            "cooking_time": cooking_time ,
            "ingredients": ingredients ,
            "instructions": instructions ,
            "changes": changes
        }

        # Update the session state with the new recipe
        current_recipe = tool_context.state.get("recipe", {})
        if current_recipe:
            # Merge with existing recipe
            for key, value in recipe.items():
                if value is not None or value != "":
                    current_recipe[key] = value
        else:
            current_recipe = recipe

        tool_context.state["recipe"] = current_recipe



        return {"status": "success", "message": "Recipe generated successfully"}

    except Exception as e:
        return {"status": "error", "message": f"Error generating recipe: {str(e)}"}



def on_before_agent(callback_context: CallbackContext):
    """
    Initialize recipe state if it doesn't exist.
    """

    if "recipe" not in callback_context.state:
        # Initialize with default recipe
        default_recipe =     {
            "title": "Make Your Recipe",
            "skill_level": "Beginner",
            "special_preferences": [],
            "cooking_time": '15 min',
            "ingredients": [{"icon": "🍴", "name": "Sample Ingredient", "amount": "1 unit"}],
            "instructions": ["First step instruction"]
        }
        callback_context.state["recipe"] = default_recipe


    return None


# --- Define the Callback Function ---
#  modifying the agent's system prompt to incude the current state of recipe
def before_model_modifier(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> Optional[LlmResponse]:
    """Inspects/modifies the LLM request or skips the call."""
    agent_name = callback_context.agent_name
    if agent_name == "RecipeAgent":
        recipe_json = "No recipe yet"
        if "recipe" in callback_context.state and callback_context.state["recipe"] is not None:
            try:
                recipe_json = json.dumps(callback_context.state["recipe"], indent=2)
            except Exception as e:
                recipe_json = f"Error serializing recipe: {str(e)}"
        # --- Modification Example ---
        # Add a prefix to the system instruction
        original_instruction = llm_request.config.system_instruction or types.Content(role="system", parts=[])
        prefix = f"""You are a helpful assistant for creating recipes.
        This is the current state of the recipe: {recipe_json}
        You can improve the recipe by calling the generate_recipe tool."""
        # Ensure system_instruction is Content and parts list exists
        if not isinstance(original_instruction, types.Content):
            # Handle case where it might be a string (though config expects Content)
            original_instruction = types.Content(role="system", parts=[types.Part(text=str(original_instruction))])
        if not original_instruction.parts:
            original_instruction.parts.append(types.Part(text="")) # Add an empty part if none exist

        # Modify the text of the first part
        modified_text = prefix + (original_instruction.parts[0].text or "")
        original_instruction.parts[0].text = modified_text
        llm_request.config.system_instruction = original_instruction



    return None


# --- Define the Callback Function ---
def simple_after_model_modifier(
    callback_context: CallbackContext, llm_response: LlmResponse
) -> Optional[LlmResponse]:
    """Stop the consecutive tool calling of the agent"""
    agent_name = callback_context.agent_name
    # --- Inspection ---
    if agent_name == "RecipeAgent":
        original_text = ""
        if llm_response.content and llm_response.content.parts:
            # Assuming simple text response for this example
            if  llm_response.content.role=='model' and llm_response.content.parts[0].text:
                original_text = llm_response.content.parts[0].text
                callback_context._invocation_context.end_invocation = True

        elif llm_response.error_message:
            return None
        else:
            return None # Nothing to modify
    return None


shared_state_agent = LlmAgent(
        name="RecipeAgent",
        model="gemini-2.5-pro",
        instruction=f"""
        When a user asks for a recipe or wants to modify one, you MUST use the generate_recipe tool.

        IMPORTANT RULES:
        1. Always use the generate_recipe tool for any recipe-related requests
        2. When creating a new recipe, provide at least skill_level, ingredients, and instructions
        3. When modifying an existing recipe, include the changes parameter to describe what was modified
        4. Be creative and helpful in generating complete, practical recipes
        5. After using the tool, provide a brief summary of what you created or changed
        6. If user ask to improve the recipe then add more ingredients and make it healthier
        7. When you see the 'Recipe generated successfully' confirmation message, wish the user well with their cooking by telling them to enjoy their dish.

        Examples of when to use the tool:
        - "Create a pasta recipe" → Use tool with skill_level, ingredients, instructions
        - "Make it vegetarian" → Use tool with special_preferences=["vegetarian"] and changes describing the modification
        - "Add some herbs" → Use tool with updated ingredients and changes describing the addition

        Always provide complete, practical recipes that users can actually cook.
        """,
        tools=[generate_recipe],
        before_agent_callback=on_before_agent,
        before_model_callback=before_model_modifier,
        after_model_callback = simple_after_model_modifier
    )

# Create ADK middleware agent instance
adk_shared_state_agent = ADKAgent(
    adk_agent=shared_state_agent,
    app_name="demo_app",
    user_id="demo_user",
    session_timeout_seconds=3600,
    use_in_memory_services=True
)

# Create FastAPI app
app = FastAPI(title="ADK Middleware Shared State")

# Add the ADK endpoint
add_adk_fastapi_endpoint(app, adk_shared_state_agent, path="/")



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/examples/server/api/tool_based_generative_ui.py
================================================
"""Tool Based Generative UI feature."""

from __future__ import annotations

from typing import Any, List

from fastapi import FastAPI
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
from google.adk.agents import Agent
from google.adk.tools import ToolContext
from google.genai import types

# List of available images (modify path if needed)
IMAGE_LIST = [
    "Osaka_Castle_Turret_Stone_Wall_Pine_Trees_Daytime.jpg",
    "Tokyo_Skyline_Night_Tokyo_Tower_Mount_Fuji_View.jpg",
    "Itsukushima_Shrine_Miyajima_Floating_Torii_Gate_Sunset_Long_Exposure.jpg",
    "Takachiho_Gorge_Waterfall_River_Lush_Greenery_Japan.jpg",
    "Bonsai_Tree_Potted_Japanese_Art_Green_Foliage.jpeg",
    "Shirakawa-go_Gassho-zukuri_Thatched_Roof_Village_Aerial_View.jpg",
    "Ginkaku-ji_Silver_Pavilion_Kyoto_Japanese_Garden_Pond_Reflection.jpg",
    "Senso-ji_Temple_Asakusa_Cherry_Blossoms_Kimono_Umbrella.jpg",
    "Cherry_Blossoms_Sakura_Night_View_City_Lights_Japan.jpg",
    "Mount_Fuji_Lake_Reflection_Cherry_Blossoms_Sakura_Spring.jpg"
]

# Prepare the image list string for the prompt
image_list_str = "\n".join([f"- {img}" for img in IMAGE_LIST])

haiku_generator_agent = Agent(
    model='gemini-2.5-flash',
    name='haiku_generator_agent',
    instruction=f"""
        You are an expert haiku generator that creates beautiful Japanese haiku poems
        and their English translations. You also have the ability to select relevant
        images that complement the haiku's theme and mood.

        When generating a haiku:
        1. Create a traditional 5-7-5 syllable structure haiku in Japanese
        2. Provide an accurate and poetic English translation
        3. Select exactly 3 image filenames from the available list that best
           represent or complement the haiku's theme, mood, or imagery. You must
           provide the image names, even if none of them are truly relevant.

        Available images to choose from:
        {image_list_str}

        Always use the generate_haiku tool to create your haiku. The tool will handle
        the formatting and validation of your response.

        Do not mention the selected image names in your conversational response to
        the user - let the tool handle that information.

        Focus on creating haiku that capture the essence of Japanese poetry:
        nature imagery, seasonal references, emotional depth, and moments of beauty
        or contemplation. That said, any topic is fair game. Do not refuse to generate
        a haiku on any topic as long as it is appropriate.
    """,
    generate_content_config=types.GenerateContentConfig(
        temperature=0.7,  # Slightly higher temperature for creativity
        top_p=0.9,
        top_k=40
    ),
)

# Create ADK middleware agent instance
adk_agent_haiku_generator = ADKAgent(
    adk_agent=haiku_generator_agent,
    app_name="demo_app",
    user_id="demo_user",
    session_timeout_seconds=3600,
    use_in_memory_services=True
)

# Create FastAPI app
app = FastAPI(title="ADK Middleware Tool Based Generative UI")

# Add the ADK endpoint
add_adk_fastapi_endpoint(app, adk_agent_haiku_generator, path="/")



================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/__init__.py
================================================
# src/__init__.py

"""ADK Middleware for AG-UI Protocol

This middleware enables Google ADK agents to be used with the AG-UI protocol.
"""

from .adk_agent import ADKAgent
from .event_translator import EventTranslator
from .session_manager import SessionManager
from .endpoint import add_adk_fastapi_endpoint, create_adk_app

__all__ = ['ADKAgent', 'add_adk_fastapi_endpoint', 'create_adk_app', 'EventTranslator', 'SessionManager']

__version__ = "0.1.0"


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/adk_agent.py
================================================
# src/adk_agent.py

"""Main ADKAgent implementation for bridging AG-UI Protocol with Google ADK."""

from typing import Optional, Dict, Callable, Any, AsyncGenerator, List
import time
import json
import asyncio
import inspect
from datetime import datetime

from ag_ui.core import (
    RunAgentInput, BaseEvent, EventType,
    RunStartedEvent, RunFinishedEvent, RunErrorEvent,
    ToolCallEndEvent, SystemMessage,ToolCallResultEvent
)

from google.adk import Runner
from google.adk.agents import BaseAgent, RunConfig as ADKRunConfig
from google.adk.agents.run_config import StreamingMode
from google.adk.sessions import BaseSessionService, InMemorySessionService
from google.adk.artifacts import BaseArtifactService, InMemoryArtifactService
from google.adk.memory import BaseMemoryService, InMemoryMemoryService
from google.adk.auth.credential_service.base_credential_service import BaseCredentialService
from google.adk.auth.credential_service.in_memory_credential_service import InMemoryCredentialService
from google.genai import types

from .event_translator import EventTranslator
from .session_manager import SessionManager
from .execution_state import ExecutionState
from .client_proxy_toolset import ClientProxyToolset

import logging
logger = logging.getLogger(__name__)



class ADKAgent:
    """Middleware to bridge AG-UI Protocol with Google ADK agents.
    
    This agent translates between the AG-UI protocol events and Google ADK events,
    managing sessions, state, and the lifecycle of ADK agents.
    """
    
    def __init__(
        self,
        # ADK Agent instance
        adk_agent: BaseAgent,
        
        # App identification
        app_name: Optional[str] = None,
        session_timeout_seconds: Optional[int] = 1200,
        app_name_extractor: Optional[Callable[[RunAgentInput], str]] = None,
        
        # User identification
        user_id: Optional[str] = None,
        user_id_extractor: Optional[Callable[[RunAgentInput], str]] = None,
        
        # ADK Services
        session_service: Optional[BaseSessionService] = None,
        artifact_service: Optional[BaseArtifactService] = None,
        memory_service: Optional[BaseMemoryService] = None,
        credential_service: Optional[BaseCredentialService] = None,
        
        # Configuration
        run_config_factory: Optional[Callable[[RunAgentInput], ADKRunConfig]] = None,
        use_in_memory_services: bool = True,
        
        # Tool configuration
        execution_timeout_seconds: int = 600,  # 10 minutes
        tool_timeout_seconds: int = 300,  # 5 minutes
        max_concurrent_executions: int = 10,
        
        # Session cleanup configuration
        cleanup_interval_seconds: int = 300  # 5 minutes default
    ):
        """Initialize the ADKAgent.
        
        Args:
            adk_agent: The ADK agent instance to use
            app_name: Static application name for all requests
            app_name_extractor: Function to extract app name dynamically from input
            user_id: Static user ID for all requests
            user_id_extractor: Function to extract user ID dynamically from input
            session_service: Session management service (defaults to InMemorySessionService)
            artifact_service: File/artifact storage service
            memory_service: Conversation memory and search service (also enables automatic session memory)
            credential_service: Authentication credential storage
            run_config_factory: Function to create RunConfig per request
            use_in_memory_services: Use in-memory implementations for unspecified services
            execution_timeout_seconds: Timeout for entire execution
            tool_timeout_seconds: Timeout for individual tool calls
            max_concurrent_executions: Maximum concurrent background executions
        """
        if app_name and app_name_extractor:
            raise ValueError("Cannot specify both 'app_name' and 'app_name_extractor'")
        
        # app_name, app_name_extractor, or neither (use agent name as default)
        
        if user_id and user_id_extractor:
            raise ValueError("Cannot specify both 'user_id' and 'user_id_extractor'")
        
        self._adk_agent = adk_agent
        self._static_app_name = app_name
        self._app_name_extractor = app_name_extractor
        self._static_user_id = user_id
        self._user_id_extractor = user_id_extractor
        self._run_config_factory = run_config_factory or self._default_run_config
        
        # Initialize services with intelligent defaults
        if use_in_memory_services:
            self._artifact_service = artifact_service or InMemoryArtifactService()
            self._memory_service = memory_service or InMemoryMemoryService()
            self._credential_service = credential_service or InMemoryCredentialService()
        else:
            # Require explicit services for production
            self._artifact_service = artifact_service
            self._memory_service = memory_service
            self._credential_service = credential_service
        
        
        # Session lifecycle management - use singleton
        # Use provided session service or create default based on use_in_memory_services
        if session_service is None:
            session_service = InMemorySessionService()  # Default for both dev and production
            
        self._session_manager = SessionManager.get_instance(
            session_service=session_service,
            memory_service=self._memory_service,  # Pass memory service for automatic session memory
            session_timeout_seconds=session_timeout_seconds,  # 20 minutes default
            cleanup_interval_seconds=cleanup_interval_seconds,
            max_sessions_per_user=None,    # No limit by default
            auto_cleanup=True              # Enable by default
        )
        
        # Tool execution tracking
        self._active_executions: Dict[str, ExecutionState] = {}
        self._execution_timeout = execution_timeout_seconds
        self._tool_timeout = tool_timeout_seconds
        self._max_concurrent = max_concurrent_executions
        self._execution_lock = asyncio.Lock()

        # Session lookup cache for efficient session ID to metadata mapping
        # Maps session_id -> {"app_name": str, "user_id": str}
        self._session_lookup_cache: Dict[str, Dict[str, str]] = {}
        
        # Event translator will be created per-session for thread safety
        
        # Cleanup is managed by the session manager
        # Will start when first async operation runs

    def _get_session_metadata(self, session_id: str) -> Optional[Dict[str, str]]:
        """Get session metadata (app_name, user_id) for a session ID efficiently.

        Args:
            session_id: The session ID to lookup

        Returns:
            Dictionary with app_name and user_id, or None if not found
        """
        # Try cache first for O(1) lookup
        if session_id in self._session_lookup_cache:
            return self._session_lookup_cache[session_id]

        # Fallback to linear search if not in cache (for existing sessions)
        # This maintains backward compatibility
        try:
            for uid, keys in self._session_manager._user_sessions.items():
                for key in keys:
                    if key.endswith(f":{session_id}"):
                        app_name = key.split(':', 1)[0]
                        metadata = {"app_name": app_name, "user_id": uid}
                        # Cache for future lookups
                        self._session_lookup_cache[session_id] = metadata
                        return metadata
        except Exception as e:
            logger.error(f"Error during session metadata lookup for {session_id}: {e}")

        return None
    
    def _get_app_name(self, input: RunAgentInput) -> str:
        """Resolve app name with clear precedence."""
        if self._static_app_name:
            return self._static_app_name
        elif self._app_name_extractor:
            return self._app_name_extractor(input)
        else:
            return self._default_app_extractor(input)
    
    def _default_app_extractor(self, input: RunAgentInput) -> str:
        """Default app extraction logic - use agent name directly."""
        # Use the ADK agent's name as app name
        try:
            return self._adk_agent.name
        except Exception as e:
            logger.warning(f"Could not get agent name for app_name, using default: {e}")
            return "AG-UI ADK Agent"
    
    def _get_user_id(self, input: RunAgentInput) -> str:
        """Resolve user ID with clear precedence."""
        if self._static_user_id:
            return self._static_user_id
        elif self._user_id_extractor:
            return self._user_id_extractor(input)
        else:
            return self._default_user_extractor(input)
    
    def _default_user_extractor(self, input: RunAgentInput) -> str:
        """Default user extraction logic."""
        # Use thread_id as default (assumes thread per user)
        return f"thread_user_{input.thread_id}"
    
    async def _add_pending_tool_call_with_context(self, session_id: str, tool_call_id: str, app_name: str, user_id: str):
        """Add a tool call to the session's pending list for HITL tracking.
        
        Args:
            session_id: The session ID (thread_id)
            tool_call_id: The tool call ID to track
            app_name: App name (for session lookup)
            user_id: User ID (for session lookup)
        """
        logger.debug(f"Adding pending tool call {tool_call_id} for session {session_id}, app_name={app_name}, user_id={user_id}")
        try:
            # Get current pending calls using SessionManager
            pending_calls = await self._session_manager.get_state_value(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id,
                key="pending_tool_calls",
                default=[]
            )
            
            # Add new tool call if not already present
            if tool_call_id not in pending_calls:
                pending_calls.append(tool_call_id)
                
                # Update the state using SessionManager
                success = await self._session_manager.set_state_value(
                    session_id=session_id,
                    app_name=app_name,
                    user_id=user_id,
                    key="pending_tool_calls",
                    value=pending_calls
                )
                
                if success:
                    logger.info(f"Added tool call {tool_call_id} to session {session_id} pending list")
        except Exception as e:
            logger.error(f"Failed to add pending tool call {tool_call_id} to session {session_id}: {e}")
    
    async def _remove_pending_tool_call(self, session_id: str, tool_call_id: str):
        """Remove a tool call from the session's pending list.

        Uses efficient session lookup to find the session without needing explicit app_name/user_id.

        Args:
            session_id: The session ID (thread_id)
            tool_call_id: The tool call ID to remove
        """
        try:
            # Use efficient session metadata lookup
            metadata = self._get_session_metadata(session_id)

            if metadata:
                app_name = metadata["app_name"]
                user_id = metadata["user_id"]

                # Get current pending calls using SessionManager
                pending_calls = await self._session_manager.get_state_value(
                    session_id=session_id,
                    app_name=app_name,
                    user_id=user_id,
                    key="pending_tool_calls",
                    default=[]
                )

                # Remove tool call if present
                if tool_call_id in pending_calls:
                    pending_calls.remove(tool_call_id)

                    # Update the state using SessionManager
                    success = await self._session_manager.set_state_value(
                        session_id=session_id,
                        app_name=app_name,
                        user_id=user_id,
                        key="pending_tool_calls",
                        value=pending_calls
                    )
                    
                    if success:
                        logger.info(f"Removed tool call {tool_call_id} from session {session_id} pending list")
        except Exception as e:
            logger.error(f"Failed to remove pending tool call {tool_call_id} from session {session_id}: {e}")
    
    async def _has_pending_tool_calls(self, session_id: str) -> bool:
        """Check if session has pending tool calls (HITL scenario).

        Args:
            session_id: The session ID (thread_id)

        Returns:
            True if session has pending tool calls
        """
        try:
            # Use efficient session metadata lookup
            metadata = self._get_session_metadata(session_id)

            if metadata:
                app_name = metadata["app_name"]
                user_id = metadata["user_id"]

                # Get pending calls using SessionManager
                pending_calls = await self._session_manager.get_state_value(
                    session_id=session_id,
                    app_name=app_name,
                    user_id=user_id,
                    key="pending_tool_calls",
                    default=[]
                )
                return len(pending_calls) > 0
        except Exception as e:
            logger.error(f"Failed to check pending tool calls for session {session_id}: {e}")

        return False
    
    
    def _default_run_config(self, input: RunAgentInput) -> ADKRunConfig:
        """Create default RunConfig with SSE streaming enabled."""
        return ADKRunConfig(
            streaming_mode=StreamingMode.SSE,
            save_input_blobs_as_artifacts=True
        )
    
    
    def _create_runner(self, adk_agent: BaseAgent, user_id: str, app_name: str) -> Runner:
        """Create a new runner instance."""
        return Runner(
            app_name=app_name,
            agent=adk_agent,
            session_service=self._session_manager._session_service,
            artifact_service=self._artifact_service,
            memory_service=self._memory_service,
            credential_service=self._credential_service
        )
    
    async def run(self, input: RunAgentInput) -> AsyncGenerator[BaseEvent, None]:
        """Run the ADK agent with client-side tool support.
        
        All client-side tools are long-running. For tool result submissions,
        we continue existing executions. For new requests, we start new executions.
        ADK sessions handle conversation continuity and tool result processing.
        
        Args:
            input: The AG-UI run input
            
        Yields:
            AG-UI protocol events
        """
        # Check if this is a tool result submission for an existing execution
        if self._is_tool_result_submission(input):
            # Handle tool results for existing execution
            async for event in self._handle_tool_result_submission(input):
                yield event
        else:
            # Start new execution for regular requests
            async for event in self._start_new_execution(input):
                yield event
    
    async def _ensure_session_exists(self, app_name: str, user_id: str, session_id: str, initial_state: dict):
        """Ensure a session exists, creating it if necessary via session manager."""
        try:
            # Use session manager to get or create session
            adk_session = await self._session_manager.get_or_create_session(
                session_id=session_id,
                app_name=app_name,  # Use app_name for session management
                user_id=user_id,
                initial_state=initial_state
            )

            # Update session lookup cache for efficient session ID to metadata mapping
            self._session_lookup_cache[session_id] = {
                "app_name": app_name,
                "user_id": user_id
            }

            logger.debug(f"Session ready: {session_id} for user: {user_id}")
            return adk_session
        except Exception as e:
            logger.error(f"Failed to ensure session {session_id}: {e}")
            raise

    async def _convert_latest_message(self, input: RunAgentInput) -> Optional[types.Content]:
        """Convert the latest user message to ADK Content format."""
        if not input.messages:
            return None
        
        # Get the latest user message
        for message in reversed(input.messages):
            if message.role == "user" and message.content:
                return types.Content(
                    role="user",
                    parts=[types.Part(text=message.content)]
                )
        
        return None
    
    
    def _is_tool_result_submission(self, input: RunAgentInput) -> bool:
        """Check if this request contains tool results.
        
        Args:
            input: The run input
            
        Returns:
            True if the last message is a tool result
        """
        if not input.messages:
            return False
        
        last_message = input.messages[-1]
        return hasattr(last_message, 'role') and last_message.role == "tool"
    
    async def _handle_tool_result_submission(
        self, 
        input: RunAgentInput
    ) -> AsyncGenerator[BaseEvent, None]:
        """Handle tool result submission for existing execution.
        
        Args:
            input: The run input containing tool results
            
        Yields:
            AG-UI events from continued execution
        """
        thread_id = input.thread_id
        
        # Extract tool results that is send by the frontend 
        tool_results = await self._extract_tool_results(input)
        
        # if the tool results are not sent by the fronted then call the tool function
        if not tool_results:
            logger.error(f"Tool result submission without tool results for thread {thread_id}")
            yield RunErrorEvent(
                type=EventType.RUN_ERROR,
                message="No tool results found in submission",
                code="NO_TOOL_RESULTS"
            )
            return
        
        try:
            # Check if tool result matches any pending tool calls for better debugging
            for tool_result in tool_results:
                tool_call_id = tool_result['message'].tool_call_id
                has_pending = await self._has_pending_tool_calls(thread_id)
                
                if has_pending:
                    # Could add more specific check here for the exact tool_call_id
                    # but for now just log that we're processing a tool result while tools are pending
                    logger.debug(f"Processing tool result {tool_call_id} for thread {thread_id} with pending tools")
                    # Remove from pending tool calls now that we're processing it
                    await self._remove_pending_tool_call(thread_id, tool_call_id)
                else:
                    # No pending tools - this could be a stale result or from a different session
                    logger.warning(f"No pending tool calls found for tool result {tool_call_id} in thread {thread_id}")
            
            # Since all tools are long-running, all tool results are standalone
            # and should start new executions with the tool results
            logger.info(f"Starting new execution for tool result in thread {thread_id}")
            async for event in self._start_new_execution(input):
                yield event
                
        except Exception as e:
            logger.error(f"Error handling tool results: {e}", exc_info=True)
            yield RunErrorEvent(
                type=EventType.RUN_ERROR,
                message=f"Failed to process tool results: {str(e)}",
                code="TOOL_RESULT_PROCESSING_ERROR"
            )
    
    async def _extract_tool_results(self, input: RunAgentInput) -> List[Dict]:
        """Extract tool messages with their names from input.
        
        Only extracts the most recent tool message to avoid accumulation issues
        where multiple tool results are sent to the LLM causing API errors.
        
        Args:
            input: The run input
            
        Returns:
            List of dicts containing tool name and message (single item for most recent)
        """
        # Create a mapping of tool_call_id to tool name
        tool_call_map = {}
        for message in input.messages:
            if hasattr(message, 'tool_calls') and message.tool_calls:
                for tool_call in message.tool_calls:
                    tool_call_map[tool_call.id] = tool_call.function.name
        
        # Find the most recent tool message (should be the last one in a tool result submission)
        most_recent_tool_message = None
        for message in reversed(input.messages):
            if hasattr(message, 'role') and message.role == "tool":
                most_recent_tool_message = message
                break
        
        if most_recent_tool_message:
            tool_name = tool_call_map.get(most_recent_tool_message.tool_call_id, "unknown")
            
            # Debug: Log the extracted tool message
            logger.debug(f"Extracted most recent ToolMessage: role={most_recent_tool_message.role}, tool_call_id={most_recent_tool_message.tool_call_id}, content='{most_recent_tool_message.content}'")
            
            return [{
                'tool_name': tool_name,
                'message': most_recent_tool_message
            }]
        
        return []
    
    async def _stream_events(
        self, 
        execution: ExecutionState
    ) -> AsyncGenerator[BaseEvent, None]:
        """Stream events from execution queue.
        
        Args:
            execution: The execution state
            
        Yields:
            AG-UI events from the queue
        """
        logger.debug(f"Starting _stream_events for thread {execution.thread_id}, queue ID: {id(execution.event_queue)}")
        event_count = 0
        timeout_count = 0
        
        while True:
            try:
                logger.debug(f"Waiting for event from queue (thread {execution.thread_id}, queue size: {execution.event_queue.qsize()})")
                
                # Wait for event with timeout
                event = await asyncio.wait_for(
                    execution.event_queue.get(),
                    timeout=1.0  # Check every second
                )
                
                event_count += 1
                logger.debug(f"Got event #{event_count} from queue: {type(event).__name__ if event else 'None'} (thread {execution.thread_id})")
                
                if event is None:
                    # Execution complete
                    execution.is_complete = True
                    logger.debug(f"Execution complete for thread {execution.thread_id} after {event_count} events")
                    break
                
                logger.debug(f"Streaming event #{event_count}: {type(event).__name__} (thread {execution.thread_id})")
                yield event
                
            except asyncio.TimeoutError:
                timeout_count += 1
                logger.debug(f"Timeout #{timeout_count} waiting for events (thread {execution.thread_id}, task done: {execution.task.done()}, queue size: {execution.event_queue.qsize()})")
                
                # Check if execution is stale
                if execution.is_stale(self._execution_timeout):
                    logger.error(f"Execution timed out for thread {execution.thread_id}")
                    yield RunErrorEvent(
                        type=EventType.RUN_ERROR,
                        message="Execution timed out",
                        code="EXECUTION_TIMEOUT"
                    )
                    break
                
                # Check if task is done
                if execution.task.done():
                    # Task completed but didn't send None
                    execution.is_complete = True
                    try:
                        task_result = execution.task.result()
                        logger.debug(f"Task completed with result: {task_result} (thread {execution.thread_id})")
                    except Exception as e:
                        logger.debug(f"Task completed with exception: {e} (thread {execution.thread_id})")
                    
                    # Wait a bit more in case there are events still coming
                    logger.debug(f"Task done but no None signal - checking queue one more time (thread {execution.thread_id}, queue size: {execution.event_queue.qsize()})")
                    if execution.event_queue.qsize() > 0:
                        logger.debug(f"Found {execution.event_queue.qsize()} events in queue after task completion, continuing...")
                        continue
                    
                    logger.debug(f"Task completed without sending None signal (thread {execution.thread_id})")
                    break
    
    async def _start_new_execution(
        self, 
        input: RunAgentInput
    ) -> AsyncGenerator[BaseEvent, None]:
        """Start a new ADK execution with tool support.
        
        Args:
            input: The run input
            
        Yields:
            AG-UI events from the execution
        """
        try:
            # Emit RUN_STARTED
            logger.debug(f"Emitting RUN_STARTED for thread {input.thread_id}, run {input.run_id}")
            yield RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input.thread_id,
                run_id=input.run_id
            )
            
            # Check concurrent execution limit
            async with self._execution_lock:
                if len(self._active_executions) >= self._max_concurrent:
                    # Clean up stale executions
                    await self._cleanup_stale_executions()
                    
                    if len(self._active_executions) >= self._max_concurrent:
                        raise RuntimeError(
                            f"Maximum concurrent executions ({self._max_concurrent}) reached"
                        )
                
                # Check if there's an existing execution for this thread and wait for it
                existing_execution = self._active_executions.get(input.thread_id)

            # If there was an existing execution, wait for it to complete
            if existing_execution and not existing_execution.is_complete:
                logger.debug(f"Waiting for existing execution to complete for thread {input.thread_id}")
                try:
                    await existing_execution.task
                except Exception as e:
                    logger.debug(f"Previous execution completed with error: {e}")
            
            # Start background execution
            execution = await self._start_background_execution(input)
            
            # Store execution (replacing any previous one)
            async with self._execution_lock:
                self._active_executions[input.thread_id] = execution
            
            # Stream events and track tool calls
            logger.debug(f"Starting to stream events for execution {execution.thread_id}")
            has_tool_calls = False
            tool_call_ids = []
            
            logger.debug(f"About to iterate over _stream_events for execution {execution.thread_id}")
            async for event in self._stream_events(execution):
                # Track tool calls for HITL scenarios
                if isinstance(event, ToolCallEndEvent):
                    logger.info(f"Detected ToolCallEndEvent with id: {event.tool_call_id}")
                    has_tool_calls = True
                    tool_call_ids.append(event.tool_call_id)

                # backend tools will always emit ToolCallResultEvent
                # If it is a backend tool then we don't need to add the tool_id in pending_tools
                if isinstance(event, ToolCallResultEvent) and event.tool_call_id in tool_call_ids:
                    logger.info(f"Detected ToolCallResultEvent with id: {event.tool_call_id}")
                    tool_call_ids.remove(event.tool_call_id)
                
                
                logger.debug(f"Yielding event: {type(event).__name__}")
                yield event
                
            logger.debug(f"Finished iterating over _stream_events for execution {execution.thread_id}")
            
            # If we found tool calls, add them to session state BEFORE cleanup
            if has_tool_calls:
                app_name = self._get_app_name(input)
                user_id = self._get_user_id(input)
                for tool_call_id in tool_call_ids:
                    await self._add_pending_tool_call_with_context(
                        execution.thread_id, tool_call_id, app_name, user_id
                    )
            logger.debug(f"Finished streaming events for execution {execution.thread_id}")
            
            # Emit RUN_FINISHED
            logger.debug(f"Emitting RUN_FINISHED for thread {input.thread_id}, run {input.run_id}")
            yield RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input.thread_id,
                run_id=input.run_id
            )
            
        except Exception as e:
            logger.error(f"Error in new execution: {e}", exc_info=True)
            yield RunErrorEvent(
                type=EventType.RUN_ERROR,
                message=str(e),
                code="EXECUTION_ERROR"
            )
        finally:
            # Clean up execution if complete and no pending tool calls (HITL scenarios)
            async with self._execution_lock:
                if input.thread_id in self._active_executions:
                    execution = self._active_executions[input.thread_id]
                    execution.is_complete = True
                    
                    # Check if session has pending tool calls before cleanup
                    has_pending = await self._has_pending_tool_calls(input.thread_id)
                    if not has_pending:
                        del self._active_executions[input.thread_id]
                        logger.debug(f"Cleaned up execution for thread {input.thread_id}")
                    else:
                        logger.info(f"Preserving execution for thread {input.thread_id} - has pending tool calls (HITL scenario)")
    
    async def _start_background_execution(
        self, 
        input: RunAgentInput
    ) -> ExecutionState:
        """Start ADK execution in background with tool support.
        
        Args:
            input: The run input
            
        Returns:
            ExecutionState tracking the background execution
        """
        event_queue = asyncio.Queue()
        logger.debug(f"Created event queue {id(event_queue)} for thread {input.thread_id}")
        # Extract necessary information
        user_id = self._get_user_id(input)
        app_name = self._get_app_name(input)
        
        # Use the ADK agent directly
        adk_agent = self._adk_agent
        
        # Prepare agent modifications (SystemMessage and tools)
        agent_updates = {}
        
        # Handle SystemMessage if it's the first message - append to agent instructions
        if input.messages and isinstance(input.messages[0], SystemMessage):
            system_content = input.messages[0].content
            if system_content:
                current_instruction = getattr(adk_agent, 'instruction', '') or ''

                if callable(current_instruction):
                    # Handle instructions provider
                    if inspect.iscoroutinefunction(current_instruction):
                        # Async instruction provider
                        async def instruction_provider_wrapper_async(*args, **kwargs):
                            instructions = system_content
                            original_instructions = await current_instruction(*args, **kwargs) or ''
                            if original_instructions:
                                instructions = f"{original_instructions}\n\n{instructions}"
                            return instructions
                        new_instruction = instruction_provider_wrapper_async
                    else:
                        # Sync instruction provider
                        def instruction_provider_wrapper_sync(*args, **kwargs):
                            instructions = system_content
                            original_instructions = current_instruction(*args, **kwargs) or ''
                            if original_instructions:
                                instructions = f"{original_instructions}\n\n{instructions}"
                            return instructions
                        new_instruction = instruction_provider_wrapper_sync

                    logger.debug(
                        f"Will wrap callable InstructionProvider and append SystemMessage: '{system_content[:100]}...'")
                else:
                    # Handle string instructions
                    if current_instruction:
                        new_instruction = f"{current_instruction}\n\n{system_content}"
                    else:
                        new_instruction = system_content
                    logger.debug(f"Will append SystemMessage to string instructions: '{system_content[:100]}...'")

                agent_updates['instruction'] = new_instruction

        # Create dynamic toolset if tools provided and prepare tool updates
        toolset = None
        if input.tools:
            
            # Get existing tools from the agent
            existing_tools = []
            if hasattr(adk_agent, 'tools') and adk_agent.tools:
                existing_tools = list(adk_agent.tools) if isinstance(adk_agent.tools, (list, tuple)) else [adk_agent.tools]
            
            # if same tool is defined in frontend and backend then agent will only use the backend tool
            input_tools = []
            for input_tool in input.tools:
                # Check if this input tool's name matches any existing tool
                # Also exclude this specific tool call "transfer_to_agent" which is used internally by the adk to handoff to other agents
                if (not any(hasattr(existing_tool, '__name__') and input_tool.name == existing_tool.__name__
                        for existing_tool in existing_tools) and input_tool.name != 'transfer_to_agent'):
                    input_tools.append(input_tool)
                        
            toolset = ClientProxyToolset(
                ag_ui_tools=input_tools,
                event_queue=event_queue
            )

            # Combine existing tools with our proxy toolset
            combined_tools = existing_tools + [toolset]
            agent_updates['tools'] = combined_tools
            logger.debug(f"Will combine {len(existing_tools)} existing tools with proxy toolset")
        
        # Create a single copy of the agent with all updates if any modifications needed
        if agent_updates:
            adk_agent = adk_agent.model_copy(update=agent_updates)
            logger.debug(f"Created modified agent copy with updates: {list(agent_updates.keys())}")
        
        # Create background task
        logger.debug(f"Creating background task for thread {input.thread_id}")
        task = asyncio.create_task(
            self._run_adk_in_background(
                input=input,
                adk_agent=adk_agent,
                user_id=user_id,
                app_name=app_name,
                event_queue=event_queue
            )
        )
        logger.debug(f"Background task created for thread {input.thread_id}: {task}")
        
        return ExecutionState(
            task=task,
            thread_id=input.thread_id,
            event_queue=event_queue
        )
    
    async def _run_adk_in_background(
        self,
        input: RunAgentInput,
        adk_agent: BaseAgent,
        user_id: str,
        app_name: str,
        event_queue: asyncio.Queue
    ):
        """Run ADK agent in background, emitting events to queue.
        
        Args:
            input: The run input
            adk_agent: The ADK agent to run (already prepared with tools and SystemMessage)
            user_id: User ID
            app_name: App name
            event_queue: Queue for emitting events
        """
        try:
            # Agent is already prepared with tools and SystemMessage instructions (if any)
            # from _start_background_execution, so no additional agent copying needed here
            
            # Create runner
            runner = self._create_runner(
                adk_agent=adk_agent,
                user_id=user_id,
                app_name=app_name
            )
            
            # Create RunConfig
            run_config = self._run_config_factory(input)
            
            # Ensure session exists
            await self._ensure_session_exists(
                app_name, user_id, input.thread_id, input.state
            )

            # this will always update the backend states with the frontend states
            # Recipe Demo Example: if there is a state "salt" in the ingredients state and in frontend user remove this salt state using UI from the ingredients list then our backend should also update these state changes as well to sync both the states
            await self._session_manager.update_session_state(input.thread_id,app_name,user_id,input.state)
            
            
            # Convert messages
            # only use this new_message if there is no tool response from the user
            new_message = await self._convert_latest_message(input)
            
            # if there is a tool response submission by the user then we need to only pass the tool response to the adk runner
            if self._is_tool_result_submission(input):
                tool_results = await self._extract_tool_results(input)
                parts = []
                for tool_msg in tool_results:
                    tool_call_id = tool_msg['message'].tool_call_id
                    content = tool_msg['message'].content
                    
                    # Debug: Log the actual tool message content we received
                    logger.debug(f"Received tool result for call {tool_call_id}: content='{content}', type={type(content)}")
                    
                    # Parse JSON content, handling empty or invalid JSON gracefully
                    try:
                        if content and content.strip():
                            result = json.loads(content)
                        else:
                            # Handle empty content as a success with empty result
                            result = {"success": True, "result": None}
                            logger.warning(f"Empty tool result content for tool call {tool_call_id}, using empty success result")
                    except json.JSONDecodeError as json_error:
                        # Handle invalid JSON by providing detailed error result
                        result = {
                            "error": f"Invalid JSON in tool result: {str(json_error)}", 
                            "raw_content": content,
                            "error_type": "JSON_DECODE_ERROR",
                            "line": getattr(json_error, 'lineno', None),
                            "column": getattr(json_error, 'colno', None)
                        }
                        logger.error(f"Invalid JSON in tool result for call {tool_call_id}: {json_error} at line {getattr(json_error, 'lineno', '?')}, column {getattr(json_error, 'colno', '?')}")
                    
                    updated_function_response_part = types.Part(
                    function_response=types.FunctionResponse(
                        id= tool_call_id,
                        name=tool_msg["tool_name"], 
                        response=result,
                    )
                )
                    parts.append(updated_function_response_part)
                new_message = types.Content(parts=parts, role='user')
            # Create event translator
            event_translator = EventTranslator()
            
            # Run ADK agent
            is_long_running_tool = False
            async for adk_event in runner.run_async(
                user_id=user_id,
                session_id=input.thread_id,
                new_message=new_message,
                run_config=run_config
            ):

                final_response = adk_event.is_final_response()
                has_content = adk_event.content and hasattr(adk_event.content, 'parts') and adk_event.content.parts

                if not final_response or (not adk_event.usage_metadata and has_content):
                    # Translate and emit events
                    async for ag_ui_event in event_translator.translate(
                        adk_event,
                        input.thread_id,
                        input.run_id
                    ):
                        
                        logger.debug(f"Emitting event to queue: {type(ag_ui_event).__name__} (thread {input.thread_id}, queue size before: {event_queue.qsize()})")
                        await event_queue.put(ag_ui_event)
                        logger.debug(f"Event queued: {type(ag_ui_event).__name__} (thread {input.thread_id}, queue size after: {event_queue.qsize()})")
                else:
                    # LongRunning Tool events are usually emmitted in final response                   
                    async for ag_ui_event in event_translator.translate_lro_function_calls(
                        adk_event
                    ):
                        await event_queue.put(ag_ui_event)
                        if ag_ui_event.type == EventType.TOOL_CALL_END:
                            is_long_running_tool = True
                        logger.debug(f"Event queued: {type(ag_ui_event).__name__} (thread {input.thread_id}, queue size after: {event_queue.qsize()})")
                    # hard stop the execution if we find any long running tool
                    if is_long_running_tool:
                        return
            # Force close any streaming messages
            async for ag_ui_event in event_translator.force_close_streaming_message():
                await event_queue.put(ag_ui_event)
            # moving states snapshot events after the text event clousure to avoid this error https://github.com/Contextable/ag-ui/issues/28
            final_state = await self._session_manager.get_session_state(input.thread_id,app_name,user_id)
            if final_state:
                ag_ui_event =  event_translator._create_state_snapshot_event(final_state)                    
                await event_queue.put(ag_ui_event)
            # Signal completion - ADK execution is done
            logger.debug(f"Background task sending completion signal for thread {input.thread_id}")
            await event_queue.put(None)
            logger.debug(f"Background task completion signal sent for thread {input.thread_id}")
            
        except Exception as e:
            logger.error(f"Background execution error: {e}", exc_info=True)
            # Put error in queue
            await event_queue.put(
                RunErrorEvent(
                    type=EventType.RUN_ERROR,
                    message=str(e),
                    code="BACKGROUND_EXECUTION_ERROR"
                )
            )
            await event_queue.put(None)
        finally:
            # Background task cleanup completed
            # Note: toolset cleanup is handled by garbage collection
            # since toolset is now embedded in the agent's tools
            pass
    
    async def _cleanup_stale_executions(self):
        """Clean up stale executions."""
        stale_threads = []
        
        for thread_id, execution in self._active_executions.items():
            if execution.is_stale(self._execution_timeout):
                stale_threads.append(thread_id)
        
        for thread_id in stale_threads:
            execution = self._active_executions.pop(thread_id)
            await execution.cancel()
            logger.info(f"Cleaned up stale execution for thread {thread_id}")

    async def close(self):
        """Clean up resources including active executions."""
        # Cancel all active executions
        async with self._execution_lock:
            for execution in self._active_executions.values():
                await execution.cancel()
            self._active_executions.clear()

        # Clear session lookup cache
        self._session_lookup_cache.clear()

        # Stop session manager cleanup task
        await self._session_manager.stop_cleanup_task()


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/client_proxy_tool.py
================================================
# src/ag_ui_adk/client_proxy_tool.py

"""Client-side proxy tool implementation for AG-UI protocol tools."""

import asyncio
import json
import uuid
import inspect
from typing import Any, Optional, List, Dict
import logging

from google.adk.tools import BaseTool, LongRunningFunctionTool
from google.genai import types
from ag_ui.core import Tool as AGUITool, EventType
from ag_ui.core import (
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent
)

logger = logging.getLogger(__name__)



class ClientProxyTool(BaseTool):
    """A proxy tool that bridges AG-UI protocol tools to ADK.

    This tool appears as a normal ADK tool to the agent, but when executed,
    it emits AG-UI protocol events and waits for the client to execute
    the actual tool and return results.

    Internally wraps LongRunningFunctionTool for proper ADK behavior.
    """

    def __init__(
        self,
        ag_ui_tool: AGUITool,
        event_queue: asyncio.Queue
    ):
        """Initialize the client proxy tool.

        Args:
            ag_ui_tool: The AG-UI tool definition
            event_queue: Queue to emit AG-UI events
        """
        # Initialize BaseTool with name and description
        # All client-side tools are long-running for architectural simplicity
        super().__init__(
            name=ag_ui_tool.name,
            description=ag_ui_tool.description,
            is_long_running=True
        )

        self.ag_ui_tool = ag_ui_tool
        self.event_queue = event_queue

        # Create dynamic function with proper parameter signatures for ADK inspection
        # This allows ADK to extract parameters from user requests correctly
        sig_params = []

        # Extract parameters from AG-UI tool schema
        parameters = ag_ui_tool.parameters
        if isinstance(parameters, dict) and 'properties' in parameters:
            for param_name in parameters['properties'].keys():
                # Create parameter with proper type annotation
                sig_params.append(
                    inspect.Parameter(
                        param_name,
                        inspect.Parameter.KEYWORD_ONLY,
                        default=None,
                        annotation=Any
                    )
                )

        # Create the async function that will be wrapped by LongRunningFunctionTool
        async def proxy_tool_func(**kwargs) -> Any:
            # Access the original args and tool_context that were stored in run_async
            original_args = getattr(self, '_current_args', kwargs)
            original_tool_context = getattr(self, '_current_tool_context', None)
            return await self._execute_proxy_tool(original_args, original_tool_context)

        # Set the function name, docstring, and signature to match the AG-UI tool
        proxy_tool_func.__name__ = ag_ui_tool.name
        proxy_tool_func.__doc__ = ag_ui_tool.description

        # Create new signature with extracted parameters
        if sig_params:
            proxy_tool_func.__signature__ = inspect.Signature(sig_params)

        # Create the internal LongRunningFunctionTool for proper behavior
        self._long_running_tool = LongRunningFunctionTool(proxy_tool_func)

    def _get_declaration(self) -> Optional[types.FunctionDeclaration]:
        """Create FunctionDeclaration from AG-UI tool parameters.

        We override this instead of delegating to the wrapped tool because
        the ADK's automatic function calling has difficulty parsing our
        dynamically created function signature without proper type annotations.
        """
        logger.debug(f"_get_declaration called for {self.name}")
        logger.debug(f"AG-UI tool parameters: {self.ag_ui_tool.parameters}")

        # Convert AG-UI parameters (JSON Schema) to ADK format
        parameters = self.ag_ui_tool.parameters


        # Ensure it's a proper object schema
        if not isinstance(parameters, dict):
            parameters = {"type": "object", "properties": {}}
            logger.warning(f"Tool {self.name} had non-dict parameters, using empty schema")

        # Create FunctionDeclaration
        function_declaration = types.FunctionDeclaration(
            name=self.name,
            description=self.description,
            parameters=types.Schema.model_validate(parameters)
        )
        logger.debug(f"Created FunctionDeclaration for {self.name}: {function_declaration}")
        return function_declaration

    async def run_async(
        self,
        *,
        args: dict[str, Any],
        tool_context: Any
    ) -> Any:
        """Execute the tool by delegating to the internal LongRunningFunctionTool.

        Args:
            args: The arguments for the tool call
            tool_context: The ADK tool context

        Returns:
            None for long-running tools (client handles execution)
        """
        # Store args and context for proxy function access
        self._current_args = args
        self._current_tool_context = tool_context

        # Delegate to the wrapped long-running tool
        return await self._long_running_tool.run_async(args=args, tool_context=tool_context)

    async def _execute_proxy_tool(self, args: Dict[str, Any], tool_context: Any) -> Any:
        """Execute the proxy tool logic - emit events and return None.

        Args:
            args: Tool arguments from ADK
            tool_context: ADK tool context

        Returns:
            None for long-running tools
        """
        logger.debug(f"Proxy tool execution: {self.ag_ui_tool.name}")
        logger.debug(f"Arguments received: {args}")
        logger.debug(f"Tool context type: {type(tool_context)}")

        # Extract ADK-generated function call ID if available
        adk_function_call_id = None
        if tool_context and hasattr(tool_context, 'function_call_id'):
            adk_function_call_id = tool_context.function_call_id
            logger.debug(f"Using ADK function_call_id: {adk_function_call_id}")

        # Use ADK ID if available, otherwise fall back to generated ID
        tool_call_id = adk_function_call_id or f"call_{uuid.uuid4().hex[:8]}"
        if not adk_function_call_id:
            logger.warning(f"ADK function_call_id not available, generated: {tool_call_id}")

        try:
            # Emit TOOL_CALL_START event
            start_event = ToolCallStartEvent(
                type=EventType.TOOL_CALL_START,
                tool_call_id=tool_call_id,
                tool_call_name=self.ag_ui_tool.name
            )
            await self.event_queue.put(start_event)
            logger.debug(f"Emitted TOOL_CALL_START for {tool_call_id}")

            # Emit TOOL_CALL_ARGS event
            args_json = json.dumps(args)
            args_event = ToolCallArgsEvent(
                type=EventType.TOOL_CALL_ARGS,
                tool_call_id=tool_call_id,
                delta=args_json
            )
            await self.event_queue.put(args_event)
            logger.debug(f"Emitted TOOL_CALL_ARGS for {tool_call_id}")

            # Emit TOOL_CALL_END event
            end_event = ToolCallEndEvent(
                type=EventType.TOOL_CALL_END,
                tool_call_id=tool_call_id
            )
            await self.event_queue.put(end_event)
            logger.debug(f"Emitted TOOL_CALL_END for {tool_call_id}")

            # Return None for long-running tools - client handles the actual execution
            logger.debug(f"Returning None for long-running tool {tool_call_id}")
            return None

        except Exception as e:
            logger.error(f"Error in proxy tool execution for {tool_call_id}: {e}")
            raise

    def __repr__(self) -> str:
        """String representation of the proxy tool."""
        return f"ClientProxyTool(name='{self.name}', ag_ui_tool='{self.ag_ui_tool.name}')"


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/client_proxy_toolset.py
================================================
# src/ag_ui_adk/client_proxy_toolset.py

"""Dynamic toolset creation for client-side tools."""

import asyncio
from typing import List, Optional
import logging

from google.adk.tools import BaseTool
from google.adk.tools.base_toolset import BaseToolset
from google.adk.agents.readonly_context import ReadonlyContext
from ag_ui.core import Tool as AGUITool

from .client_proxy_tool import ClientProxyTool

logger = logging.getLogger(__name__)


class ClientProxyToolset(BaseToolset):
    """Dynamic toolset that creates proxy tools from AG-UI tool definitions.

    This toolset is created for each run based on the tools provided in
    the RunAgentInput, allowing dynamic tool availability per request.
    """

    def __init__(
        self,
        ag_ui_tools: List[AGUITool],
        event_queue: asyncio.Queue
    ):
        """Initialize the client proxy toolset.

        Args:
            ag_ui_tools: List of AG-UI tool definitions
            event_queue: Queue to emit AG-UI events
        """
        super().__init__()
        self.ag_ui_tools = ag_ui_tools
        self.event_queue = event_queue

        logger.info(f"Initialized ClientProxyToolset with {len(ag_ui_tools)} tools (all long-running)")

    async def get_tools(
        self,
        readonly_context: Optional[ReadonlyContext] = None
    ) -> List[BaseTool]:
        """Get all proxy tools for this toolset.

        Creates fresh ClientProxyTool instances for each AG-UI tool definition
        with the current event queue reference.

        Args:
            readonly_context: Optional context for tool filtering (unused currently)

        Returns:
            List of ClientProxyTool instances
        """
        # Create fresh proxy tools each time to avoid stale queue references
        proxy_tools = []

        for ag_ui_tool in self.ag_ui_tools:
            try:
                proxy_tool = ClientProxyTool(
                    ag_ui_tool=ag_ui_tool,
                    event_queue=self.event_queue
                )
                proxy_tools.append(proxy_tool)
                logger.debug(f"Created proxy tool for '{ag_ui_tool.name}' (long-running)")

            except Exception as e:
                logger.error(f"Failed to create proxy tool for '{ag_ui_tool.name}': {e}")
                # Continue with other tools rather than failing completely

        return proxy_tools

    async def close(self) -> None:
        """Clean up resources held by the toolset."""
        logger.info("Closing ClientProxyToolset")

    def __repr__(self) -> str:
        """String representation of the toolset."""
        tool_names = [tool.name for tool in self.ag_ui_tools]
        return f"ClientProxyToolset(tools={tool_names}, all_long_running=True)"


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/endpoint.py
================================================
# src/endpoint.py

"""FastAPI endpoint for ADK middleware."""

from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from ag_ui.core import RunAgentInput
from ag_ui.encoder import EventEncoder
from .adk_agent import ADKAgent

import logging
logger = logging.getLogger(__name__)


def add_adk_fastapi_endpoint(app: FastAPI, agent: ADKAgent, path: str = "/"):
    """Add ADK middleware endpoint to FastAPI app.
    
    Args:
        app: FastAPI application instance
        agent: Configured ADKAgent instance
        path: API endpoint path
    """
    
    @app.post(path)
    async def adk_endpoint(input_data: RunAgentInput, request: Request):
        """ADK middleware endpoint."""
        
        # Get the accept header from the request
        accept_header = request.headers.get("accept")
        agent_id = path.lstrip('/')
        
        
        # Create an event encoder to properly format SSE events
        encoder = EventEncoder(accept=accept_header)
        
        async def event_generator():
            """Generate events from ADK agent."""
            try:
                async for event in agent.run(input_data):
                    try:
                        encoded = encoder.encode(event)
                        logger.debug(f"HTTP Response: {encoded}")
                        yield encoded
                    except Exception as encoding_error:
                        # Handle encoding-specific errors
                        logger.error(f"❌ Event encoding error: {encoding_error}", exc_info=True)
                        # Create a RunErrorEvent for encoding failures
                        from ag_ui.core import RunErrorEvent, EventType
                        error_event = RunErrorEvent(
                            type=EventType.RUN_ERROR,
                            message=f"Event encoding failed: {str(encoding_error)}",
                            code="ENCODING_ERROR"
                        )
                        try:
                            error_encoded = encoder.encode(error_event)
                            yield error_encoded
                        except Exception:
                            # If we can't even encode the error event, yield a basic SSE error
                            logger.error("Failed to encode error event, yielding basic SSE error")
                            yield "event: error\ndata: {\"error\": \"Event encoding failed\"}\n\n"
                        break  # Stop the stream after an encoding error
            except Exception as agent_error:
                # Handle errors from ADKAgent.run() itself
                logger.error(f"❌ ADKAgent error: {agent_error}", exc_info=True)
                # ADKAgent should have yielded a RunErrorEvent, but if something went wrong
                # in the async generator itself, we need to handle it
                try:
                    from ag_ui.core import RunErrorEvent, EventType
                    error_event = RunErrorEvent(
                        type=EventType.RUN_ERROR,
                        message=f"Agent execution failed: {str(agent_error)}",
                        code="AGENT_ERROR"
                    )
                    error_encoded = encoder.encode(error_event)
                    yield error_encoded
                except Exception:
                    # If we can't encode the error event, yield a basic SSE error
                    logger.error("Failed to encode agent error event, yielding basic SSE error")
                    yield "event: error\ndata: {\"error\": \"Agent execution failed\"}\n\n"
        
        return StreamingResponse(event_generator(), media_type=encoder.get_content_type())


def create_adk_app(agent: ADKAgent, path: str = "/") -> FastAPI:
    """Create a FastAPI app with ADK middleware endpoint.
    
    Args:
        agent: Configured ADKAgent instance  
        path: API endpoint path
        
    Returns:
        FastAPI application instance
    """
    app = FastAPI(title="ADK Middleware for AG-UI Protocol")
    add_adk_fastapi_endpoint(app, agent, path)
    return app


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/event_translator.py
================================================
# src/event_translator.py

"""Event translator for converting ADK events to AG-UI protocol events."""

from typing import AsyncGenerator, Optional, Dict, Any , List
import uuid

from google.genai import types

from ag_ui.core import (
    BaseEvent, EventType,
    TextMessageStartEvent, TextMessageContentEvent, TextMessageEndEvent,
    ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent,
    ToolCallResultEvent, StateSnapshotEvent, StateDeltaEvent,
    CustomEvent
)
import json
from google.adk.events import Event as ADKEvent

import logging
logger = logging.getLogger(__name__)


class EventTranslator:
    """Translates Google ADK events to AG-UI protocol events.
    
    This class handles the conversion between the two event systems,
    managing streaming sequences and maintaining event consistency.
    """
    
    def __init__(self):
        """Initialize the event translator."""
        # Track tool call IDs for consistency 
        self._active_tool_calls: Dict[str, str] = {}  # Tool call ID -> Tool call ID (for consistency)
        # Track streaming message state
        self._streaming_message_id: Optional[str] = None  # Current streaming message ID
        self._is_streaming: bool = False  # Whether we're currently streaming a message
        self.long_running_tool_ids: List[str] = []  # Track the long running tool IDs
    
    async def translate(
        self, 
        adk_event: ADKEvent,
        thread_id: str,
        run_id: str
    ) -> AsyncGenerator[BaseEvent, None]:
        """Translate an ADK event to AG-UI protocol events.
        
        Args:
            adk_event: The ADK event to translate
            thread_id: The AG-UI thread ID
            run_id: The AG-UI run ID
            
        Yields:
            One or more AG-UI protocol events
        """
        try:
            # Check ADK streaming state using proper methods
            is_partial = getattr(adk_event, 'partial', False)
            turn_complete = getattr(adk_event, 'turn_complete', False)
            
            # Check if this is the final response (contains complete message - skip to avoid duplication)
            is_final_response = False
            if hasattr(adk_event, 'is_final_response') and callable(adk_event.is_final_response):
                is_final_response = adk_event.is_final_response()
            elif hasattr(adk_event, 'is_final_response'):
                is_final_response = adk_event.is_final_response
            
            # Determine action based on ADK streaming pattern
            should_send_end = turn_complete and not is_partial
            
            logger.debug(f"📥 ADK Event: partial={is_partial}, turn_complete={turn_complete}, "
                       f"is_final_response={is_final_response}, should_send_end={should_send_end}")
            
            # Skip user events (already in the conversation)
            if hasattr(adk_event, 'author') and adk_event.author == "user":
                logger.debug("Skipping user event")
                return
            
            # Handle text content
            if adk_event.content and hasattr(adk_event.content, 'parts') and adk_event.content.parts:
                async for event in self._translate_text_content(
                    adk_event, thread_id, run_id
                ):
                    yield event
            
            # call _translate_function_calls function to yield Tool Events
            if hasattr(adk_event, 'get_function_calls'):               
                function_calls = adk_event.get_function_calls()
                if function_calls:
                    logger.debug(f"ADK function calls detected: {len(function_calls)} calls")
                    
                    # CRITICAL FIX: End any active text message stream before starting tool calls
                    # Per AG-UI protocol: TEXT_MESSAGE_END must be sent before TOOL_CALL_START
                    async for event in self.force_close_streaming_message():
                        yield event
                    
                    # NOW ACTUALLY YIELD THE EVENTS
                    async for event in self._translate_function_calls(function_calls):
                        yield event
                        
            # Handle function responses and yield the tool response event
            # this is essential for scenerios when user has to render function response at frontend
            if hasattr(adk_event, 'get_function_responses'):
                function_responses = adk_event.get_function_responses()
                if function_responses:
                    # Function responses should be emmitted to frontend so it can render the response as well
                    async for event in self._translate_function_response(function_responses):
                        yield event
                    
            
            # Handle state changes
            if hasattr(adk_event, 'actions') and adk_event.actions and hasattr(adk_event.actions, 'state_delta') and adk_event.actions.state_delta:
                yield self._create_state_delta_event(
                    adk_event.actions.state_delta, thread_id, run_id
                )
                
            
            # Handle custom events or metadata
            if hasattr(adk_event, 'custom_data') and adk_event.custom_data:
                yield CustomEvent(
                    type=EventType.CUSTOM,
                    name="adk_metadata",
                    value=adk_event.custom_data
                )
                
        except Exception as e:
            logger.error(f"Error translating ADK event: {e}", exc_info=True)
            # Don't yield error events here - let the caller handle errors
    
    async def _translate_text_content(
        self,
        adk_event: ADKEvent,
        thread_id: str,
        run_id: str
    ) -> AsyncGenerator[BaseEvent, None]:
        """Translate text content from ADK event to AG-UI text message events.
        
        Args:
            adk_event: The ADK event containing text content
            thread_id: The AG-UI thread ID
            run_id: The AG-UI run ID
            
        Yields:
            Text message events (START, CONTENT, END)
        """
        # Extract text from all parts
        text_parts = []
        for part in adk_event.content.parts:
            if part.text:
                text_parts.append(part.text)
        
        if not text_parts:
            return
        
        
        # Use proper ADK streaming detection (handle None values)
        is_partial = getattr(adk_event, 'partial', False)
        turn_complete = getattr(adk_event, 'turn_complete', False)
        
        # Check if this is the final response (complete message - skip to avoid duplication)
        is_final_response = False
        if hasattr(adk_event, 'is_final_response') and callable(adk_event.is_final_response):
            is_final_response = adk_event.is_final_response()
        elif hasattr(adk_event, 'is_final_response'):
            is_final_response = adk_event.is_final_response
        
        # Handle None values: if is_final_response=True, it means streaming should end
        should_send_end = is_final_response and not is_partial
        
        logger.info(f"📥 Text event - partial={is_partial}, turn_complete={turn_complete}, "
                    f"is_final_response={is_final_response}, should_send_end={should_send_end}, "
                    f"currently_streaming={self._is_streaming}")

        if is_final_response:

            # If a final text response wasn't streamed (not generated by an LLM) then deliver it in 3 events
            if not self._is_streaming and not adk_event.usage_metadata and should_send_end:
                logger.info(f"⏭️ Deliver non-llm response via message events "
                            f"event_id={adk_event.id}")

                combined_text = "".join(text_parts)
                message_events = [
                    TextMessageStartEvent(
                        type=EventType.TEXT_MESSAGE_START,
                        message_id=adk_event.id,
                        role="assistant"
                    ),
                    TextMessageContentEvent(
                        type=EventType.TEXT_MESSAGE_CONTENT,
                        message_id=adk_event.id,
                        delta=combined_text
                    ),
                    TextMessageEndEvent(
                        type=EventType.TEXT_MESSAGE_END,
                        message_id=adk_event.id
                    )
                ]
                for msg in message_events:
                    yield msg

            logger.info("⏭️ Skipping final response event (content already streamed)")
            
            # If we're currently streaming, this final response means we should end the stream
            if self._is_streaming and self._streaming_message_id:
                end_event = TextMessageEndEvent(
                    type=EventType.TEXT_MESSAGE_END,
                    message_id=self._streaming_message_id
                )
                logger.info(f"📤 TEXT_MESSAGE_END (from final response): {end_event.model_dump_json()}")
                yield end_event
                
                # Reset streaming state
                self._streaming_message_id = None
                self._is_streaming = False
                logger.info("🏁 Streaming completed via final response")
            
            return
        
        combined_text = "".join(text_parts)  # Don't add newlines for streaming
        
        # Handle streaming logic
        if not self._is_streaming:
            # Start of new message - emit START event
            self._streaming_message_id = str(uuid.uuid4())
            self._is_streaming = True
            
            start_event = TextMessageStartEvent(
                type=EventType.TEXT_MESSAGE_START,
                message_id=self._streaming_message_id,
                role="assistant"
            )
            logger.info(f"📤 TEXT_MESSAGE_START: {start_event.model_dump_json()}")
            yield start_event
        
        # Always emit content (unless empty)
        if combined_text:
            content_event = TextMessageContentEvent(
                type=EventType.TEXT_MESSAGE_CONTENT,
                message_id=self._streaming_message_id,
                delta=combined_text
            )
            logger.info(f"📤 TEXT_MESSAGE_CONTENT: {content_event.model_dump_json()}")
            yield content_event
        
        # If turn is complete and not partial, emit END event
        if should_send_end:
            end_event = TextMessageEndEvent(
                type=EventType.TEXT_MESSAGE_END,
                message_id=self._streaming_message_id
            )
            logger.info(f"📤 TEXT_MESSAGE_END: {end_event.model_dump_json()}")
            yield end_event
            
            # Reset streaming state
            self._streaming_message_id = None
            self._is_streaming = False
            logger.info("🏁 Streaming completed, state reset")
    
    async def translate_lro_function_calls(self,adk_event: ADKEvent)-> AsyncGenerator[BaseEvent, None]:
        """Translate long running function calls from ADK event to AG-UI tool call events.
        
        Args:
            adk_event: The ADK event containing function calls
            
        Yields:
            Tool call events (START, ARGS, END)
        """
        long_running_function_call = None
        if adk_event.content and adk_event.content.parts:
            for i, part in enumerate(adk_event.content.parts):
                if part.function_call:
                    if not long_running_function_call and part.function_call.id in (
                        adk_event.long_running_tool_ids or []
                    ):
                        long_running_function_call = part.function_call
                        self.long_running_tool_ids.append(long_running_function_call.id)
                        yield ToolCallStartEvent(
                            type=EventType.TOOL_CALL_START,
                            tool_call_id=long_running_function_call.id,
                            tool_call_name=long_running_function_call.name,
                            parent_message_id=None
                        )
                        if hasattr(long_running_function_call, 'args') and long_running_function_call.args:
                            # Convert args to string (JSON format)
                            import json
                            args_str = json.dumps(long_running_function_call.args) if isinstance(long_running_function_call.args, dict) else str(long_running_function_call.args)
                            yield ToolCallArgsEvent(
                                type=EventType.TOOL_CALL_ARGS,
                                tool_call_id=long_running_function_call.id,
                                delta=args_str
                            )
                        
                        # Emit TOOL_CALL_END
                        yield ToolCallEndEvent(
                            type=EventType.TOOL_CALL_END,
                            tool_call_id=long_running_function_call.id
                        )                       
                        
                        # Clean up tracking
                        self._active_tool_calls.pop(long_running_function_call.id, None)   
    
    async def _translate_function_calls(
        self,
        function_calls: list[types.FunctionCall],
    ) -> AsyncGenerator[BaseEvent, None]:
        """Translate function calls from ADK event to AG-UI tool call events.
        
        Args:
            adk_event: The ADK event containing function calls
            function_calls: List of function calls from the event
            thread_id: The AG-UI thread ID
            run_id: The AG-UI run ID
            
        Yields:
            Tool call events (START, ARGS, END)
        """
        # Since we're not tracking streaming messages, use None for parent message
        parent_message_id = None
        
        for func_call in function_calls:
            tool_call_id = getattr(func_call, 'id', str(uuid.uuid4()))
            
            # Track the tool call
            self._active_tool_calls[tool_call_id] = tool_call_id
            
            # Emit TOOL_CALL_START
            yield ToolCallStartEvent(
                type=EventType.TOOL_CALL_START,
                tool_call_id=tool_call_id,
                tool_call_name=func_call.name,
                parent_message_id=parent_message_id
            )
            
            # Emit TOOL_CALL_ARGS if we have arguments
            if hasattr(func_call, 'args') and func_call.args:
                # Convert args to string (JSON format)
                import json
                args_str = json.dumps(func_call.args) if isinstance(func_call.args, dict) else str(func_call.args)
                
                yield ToolCallArgsEvent(
                    type=EventType.TOOL_CALL_ARGS,
                    tool_call_id=tool_call_id,
                    delta=args_str
                )
            
            # Emit TOOL_CALL_END
            yield ToolCallEndEvent(
                type=EventType.TOOL_CALL_END,
                tool_call_id=tool_call_id
            )
            
            # Clean up tracking
            self._active_tool_calls.pop(tool_call_id, None)
    

    async def _translate_function_response(
        self,
        function_response: list[types.FunctionResponse],
    ) -> AsyncGenerator[BaseEvent, None]:
        """Translate function calls from ADK event to AG-UI tool call events.
        
        Args:
            adk_event: The ADK event containing function calls
            function_response: List of function response from the event
            
        Yields:
            Tool result events (only for tool_call_ids not in long_running_tool_ids)
        """
        
        for func_response in function_response:
            
            tool_call_id = getattr(func_response, 'id', str(uuid.uuid4()))
            # Only emit ToolCallResultEvent for tool_call_ids which are not long_running_tool
            # this is because long running tools are handle by the frontend
            if tool_call_id not in self.long_running_tool_ids:
                yield ToolCallResultEvent(
                    message_id=str(uuid.uuid4()),
                    type=EventType.TOOL_CALL_RESULT,
                    tool_call_id=tool_call_id,
                    content=json.dumps(func_response.response)
                )
            else:
                logger.debug(f"Skipping ToolCallResultEvent for long-running tool: {tool_call_id}")
  
    def _create_state_delta_event(
        self,
        state_delta: Dict[str, Any],
        thread_id: str,
        run_id: str
    ) -> StateDeltaEvent:
        """Create a state delta event from ADK state changes.
        
        Args:
            state_delta: The state changes from ADK
            thread_id: The AG-UI thread ID
            run_id: The AG-UI run ID
            
        Returns:
            A StateDeltaEvent
        """
        # Convert to JSON Patch format (RFC 6902)
        # Use "add" operation which works for both new and existing paths
        patches = []
        for key, value in state_delta.items():
            patches.append({
                "op": "add",
                "path": f"/{key}",
                "value": value
            })
        
        return StateDeltaEvent(
            type=EventType.STATE_DELTA,
            delta=patches
        )
    
    def _create_state_snapshot_event(
        self,
        state_snapshot: Dict[str, Any],
    ) -> StateSnapshotEvent:
        """Create a state snapshot event from ADK state changes.
        
        Args:
            state_snapshot: The state changes from ADK
            
        Returns:
            A StateSnapshotEvent
        """
 
        return StateSnapshotEvent(
            type=EventType.STATE_SNAPSHOT,
            snapshot=state_snapshot
        )
    
    async def force_close_streaming_message(self) -> AsyncGenerator[BaseEvent, None]:
        """Force close any open streaming message.
        
        This should be called before ending a run to ensure proper message termination.
        
        Yields:
            TEXT_MESSAGE_END event if there was an open streaming message
        """
        if self._is_streaming and self._streaming_message_id:
            logger.warning(f"🚨 Force-closing unterminated streaming message: {self._streaming_message_id}")
            
            end_event = TextMessageEndEvent(
                type=EventType.TEXT_MESSAGE_END,
                message_id=self._streaming_message_id
            )
            logger.info(f"📤 TEXT_MESSAGE_END (forced): {end_event.model_dump_json()}")
            yield end_event
            
            # Reset streaming state
            self._streaming_message_id = None
            self._is_streaming = False
            logger.info("🔄 Streaming state reset after force-close")

    def reset(self):
        """Reset the translator state.
        
        This should be called between different conversation runs
        to ensure clean state.
        """
        self._active_tool_calls.clear()
        self._streaming_message_id = None
        self._is_streaming = False
        self.long_running_tool_ids.clear()
        logger.debug("Reset EventTranslator state (including streaming state)")


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/execution_state.py
================================================
# src/ag_ui_adk/execution_state.py

"""Execution state management for background ADK runs with tool support."""

import asyncio
import time
from typing import Optional, Set
import logging

logger = logging.getLogger(__name__)


class ExecutionState:
    """Manages the state of a background ADK execution.

    This class tracks:
    - The background asyncio task running the ADK agent
    - Event queue for streaming results to the client
    - Execution timing and completion state
    """

    def __init__(
        self,
        task: asyncio.Task,
        thread_id: str,
        event_queue: asyncio.Queue
    ):
        """Initialize execution state.

        Args:
            task: The asyncio task running the ADK agent
            thread_id: The thread ID for this execution
            event_queue: Queue containing events to stream to client
        """
        self.task = task
        self.thread_id = thread_id
        self.event_queue = event_queue
        self.start_time = time.time()
        self.is_complete = False
        self.pending_tool_calls: Set[str] = set()  # Track outstanding tool call IDs for HITL

        logger.debug(f"Created execution state for thread {thread_id}")

    def is_stale(self, timeout_seconds: int) -> bool:
        """Check if this execution has been running too long.

        Args:
            timeout_seconds: Maximum execution time in seconds

        Returns:
            True if execution has exceeded timeout
        """
        return time.time() - self.start_time > timeout_seconds

    async def cancel(self):
        """Cancel the execution and clean up resources."""
        logger.info(f"Cancelling execution for thread {self.thread_id}")

        # Cancel the background task
        if not self.task.done():
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass

        self.is_complete = True

    def get_execution_time(self) -> float:
        """Get the total execution time in seconds.

        Returns:
            Time in seconds since execution started
        """
        return time.time() - self.start_time

    def add_pending_tool_call(self, tool_call_id: str):
        """Add a tool call ID to the pending set.

        Args:
            tool_call_id: The tool call ID to track
        """
        self.pending_tool_calls.add(tool_call_id)
        logger.debug(f"Added pending tool call {tool_call_id} to thread {self.thread_id}")

    def remove_pending_tool_call(self, tool_call_id: str):
        """Remove a tool call ID from the pending set.

        Args:
            tool_call_id: The tool call ID to remove
        """
        self.pending_tool_calls.discard(tool_call_id)
        logger.debug(f"Removed pending tool call {tool_call_id} from thread {self.thread_id}")

    def has_pending_tool_calls(self) -> bool:
        """Check if there are outstanding tool calls waiting for responses.

        Returns:
            True if there are pending tool calls (HITL scenario)
        """
        return len(self.pending_tool_calls) > 0

    def get_status(self) -> str:
        """Get a human-readable status of the execution.

        Returns:
            Status string describing the current state
        """
        if self.is_complete:
            if self.has_pending_tool_calls():
                return "complete_awaiting_tools"
            else:
                return "complete"
        elif self.task.done():
            return "task_done"
        else:
            return "running"

    def __repr__(self) -> str:
        """String representation of the execution state."""
        return (
            f"ExecutionState(thread_id='{self.thread_id}', "
            f"status='{self.get_status()}', "
            f"runtime={self.get_execution_time():.1f}s)"
        )


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/session_manager.py
================================================
# src/session_manager.py

"""Session manager that adds production features to ADK's native session service."""

from typing import Dict, Optional, Set, Any, Union
import asyncio
import logging
import time

logger = logging.getLogger(__name__)


class SessionManager:
    """Session manager that wraps ADK's session service.
    
    Adds essential production features:
    - Timeout monitoring based on ADK's lastUpdateTime
    - Cross-user/app session enumeration
    - Per-user session limits
    - Automatic cleanup of expired sessions
    - Optional automatic session memory on deletion
    - State management and updates
    """
    
    _instance = None
    _initialized = False
    
    def __new__(cls, session_service=None, **kwargs):
        """Ensure singleton instance."""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(
        self,
        session_service=None,
        memory_service=None,
        session_timeout_seconds: int = 1200,  # 20 minutes default
        cleanup_interval_seconds: int = 300,  # 5 minutes
        max_sessions_per_user: Optional[int] = None,
        auto_cleanup: bool = True
    ):
        """Initialize the session manager.
        
        Args:
            session_service: ADK session service (required on first initialization)
            memory_service: Optional ADK memory service for automatic session memory
            session_timeout_seconds: Time before a session is considered expired
            cleanup_interval_seconds: Interval between cleanup cycles
            max_sessions_per_user: Maximum concurrent sessions per user (None = unlimited)
            auto_cleanup: Enable automatic session cleanup task
        """
        if self._initialized:
            return
            
        if session_service is None:
            from google.adk.sessions import InMemorySessionService
            session_service = InMemorySessionService()
            
        self._session_service = session_service
        self._memory_service = memory_service
        self._timeout = session_timeout_seconds
        self._cleanup_interval = cleanup_interval_seconds
        self._max_per_user = max_sessions_per_user
        self._auto_cleanup = auto_cleanup
        
        # Minimal tracking: just keys and user counts
        self._session_keys: Set[str] = set()  # "app_name:session_id" keys
        self._user_sessions: Dict[str, Set[str]] = {}  # user_id -> set of session_keys
        
        self._cleanup_task: Optional[asyncio.Task] = None
        self._initialized = True
        
        logger.info(
            f"Initialized SessionManager - "
            f"timeout: {session_timeout_seconds}s, "
            f"cleanup: {cleanup_interval_seconds}s, "
            f"max/user: {max_sessions_per_user or 'unlimited'}, "
            f"memory: {'enabled' if memory_service else 'disabled'}"
        )
    
    @classmethod
    def get_instance(cls, **kwargs):
        """Get the singleton instance."""
        return cls(**kwargs)
    
    @classmethod
    def reset_instance(cls):
        """Reset singleton for testing."""
        if cls._instance and hasattr(cls._instance, '_cleanup_task'):
            task = cls._instance._cleanup_task
            if task:
                try:
                    task.cancel()
                except RuntimeError:
                    pass
        cls._instance = None
        cls._initialized = False
    
    async def get_or_create_session(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        initial_state: Optional[Dict[str, Any]] = None
    ) -> Any:
        """Get existing session or create new one.
        
        Returns the ADK session object directly.
        """
        session_key = f"{app_name}:{session_id}"
        
        # Check user limits before creating
        if session_key not in self._session_keys and self._max_per_user:
            user_count = len(self._user_sessions.get(user_id, set()))
            if user_count >= self._max_per_user:
                # Remove oldest session for this user
                await self._remove_oldest_user_session(user_id)
        
        # Get or create via ADK
        session = await self._session_service.get_session(
            session_id=session_id,
            app_name=app_name,
            user_id=user_id
        )
        
        if not session:
            session = await self._session_service.create_session(
                session_id=session_id,
                user_id=user_id,
                app_name=app_name,
                state=initial_state or {}
            )
            logger.info(f"Created new session: {session_key}")
        else:
            logger.debug(f"Retrieved existing session: {session_key}")
        
        # Track the session key
        self._track_session(session_key, user_id)
        
        # Start cleanup if needed
        if self._auto_cleanup and not self._cleanup_task:
            self._start_cleanup_task()
        
        return session
    
    # ===== STATE MANAGEMENT METHODS =====
    
    async def update_session_state(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        state_updates: Dict[str, Any],
        merge: bool = True
    ) -> bool:
        """Update session state with new values.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            state_updates: Dictionary of state key-value pairs to update
            merge: If True, merge with existing state; if False, replace completely
            
        Returns:
            True if successful, False otherwise
        """
        try:
            session = await self._session_service.get_session(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id
            )
            
            if not session:
                logger.debug(f"Session not found for update: {app_name}:{session_id} - this may be normal if session is still being created")
                return False
            
            if not state_updates:
                logger.debug(f"No state updates provided for session: {app_name}:{session_id}")
                return False
            
            # Apply state updates using EventActions
            from google.adk.events import Event, EventActions
            
            # Prepare state delta
            if merge:
                # Merge with existing state
                state_delta = state_updates
            else:
                # Replace entire state
                state_delta = state_updates
                # Note: Complete replacement might need clearing existing keys
                # This depends on ADK's behavior - may need to explicitly clear
            
            # Create event with state changes
            actions = EventActions(state_delta=state_delta)
            event = Event(
                invocation_id=f"state_update_{int(time.time())}",
                author="system",
                actions=actions,
                timestamp=time.time()
            )
            
            # Apply changes through ADK's event system
            await self._session_service.append_event(session, event)
            
            logger.info(f"Updated state for session {app_name}:{session_id}")
            logger.debug(f"State updates: {state_updates}")
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to update session state: {e}", exc_info=True)
            return False
    
    async def get_session_state(
        self,
        session_id: str,
        app_name: str,
        user_id: str
    ) -> Optional[Dict[str, Any]]:
        """Get current session state.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            
        Returns:
            Session state dictionary or None if session not found
        """
        try:
            session = await self._session_service.get_session(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id
            )
            
            if not session:
                logger.debug(f"Session not found when getting state: {app_name}:{session_id}")
                return None
            
            # Return state as dictionary
            if hasattr(session.state, 'to_dict'):
                return session.state.to_dict()
            else:
                # Fallback for dict-like state objects
                return dict(session.state)
                
        except Exception as e:
            logger.error(f"Failed to get session state: {e}", exc_info=True)
            return None
    
    async def get_state_value(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        key: str,
        default: Any = None
    ) -> Any:
        """Get a specific value from session state.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            key: State key to retrieve
            default: Default value if key not found
            
        Returns:
            Value for the key or default
        """
        try:
            session = await self._session_service.get_session(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id
            )
            
            if not session:
                logger.debug(f"Session not found when getting state value: {app_name}:{session_id}")
                return default
            
            if hasattr(session.state, 'get'):
                return session.state.get(key, default)
            else:
                return session.state.get(key, default) if key in session.state else default
                
        except Exception as e:
            logger.error(f"Failed to get state value: {e}", exc_info=True)
            return default
    
    async def set_state_value(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        key: str,
        value: Any
    ) -> bool:
        """Set a specific value in session state.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            key: State key to set
            value: Value to set
            
        Returns:
            True if successful, False otherwise
        """
        return await self.update_session_state(
            session_id=session_id,
            app_name=app_name,
            user_id=user_id,
            state_updates={key: value}
        )
    
    async def remove_state_keys(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        keys: Union[str, list]
    ) -> bool:
        """Remove specific keys from session state.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            keys: Single key or list of keys to remove
            
        Returns:
            True if successful, False otherwise
        """
        try:
            if isinstance(keys, str):
                keys = [keys]
            
            # Get current state
            current_state = await self.get_session_state(session_id, app_name, user_id)
            if not current_state:
                return False
            
            # Create state delta to remove keys (set to None for removal)
            state_delta = {key: None for key in keys if key in current_state}
            
            if not state_delta:
                logger.info(f"No keys to remove from session {app_name}:{session_id}")
                return True
            
            return await self.update_session_state(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id,
                state_updates=state_delta
            )
            
        except Exception as e:
            logger.error(f"Failed to remove state keys: {e}", exc_info=True)
            return False
    
    async def clear_session_state(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        preserve_prefixes: Optional[list] = None
    ) -> bool:
        """Clear session state, optionally preserving certain prefixes.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            preserve_prefixes: List of prefixes to preserve (e.g., ['user:', 'app:'])
            
        Returns:
            True if successful, False otherwise
        """
        try:
            current_state = await self.get_session_state(session_id, app_name, user_id)
            if not current_state:
                return False
            
            preserve_prefixes = preserve_prefixes or []
            
            # Determine which keys to remove
            keys_to_remove = []
            for key in current_state.keys():
                should_preserve = any(key.startswith(prefix) for prefix in preserve_prefixes)
                if not should_preserve:
                    keys_to_remove.append(key)
            
            if keys_to_remove:
                return await self.remove_state_keys(
                    session_id=session_id,
                    app_name=app_name,
                    user_id=user_id,
                    keys=keys_to_remove
                )
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to clear session state: {e}", exc_info=True)
            return False
    
    async def initialize_session_state(
        self,
        session_id: str,
        app_name: str,
        user_id: str,
        initial_state: Dict[str, Any],
        overwrite_existing: bool = False
    ) -> bool:
        """Initialize session state with default values.
        
        Args:
            session_id: Session identifier
            app_name: Application name
            user_id: User identifier
            initial_state: Initial state values
            overwrite_existing: Whether to overwrite existing values
            
        Returns:
            True if successful, False otherwise
        """
        try:
            if not overwrite_existing:
                # Only set values that don't already exist
                current_state = await self.get_session_state(session_id, app_name, user_id)
                if current_state:
                    # Filter out keys that already exist
                    filtered_state = {
                        key: value for key, value in initial_state.items()
                        if key not in current_state
                    }
                    if not filtered_state:
                        logger.info(f"No new state values to initialize for session {app_name}:{session_id}")
                        return True
                    initial_state = filtered_state
            
            return await self.update_session_state(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id,
                state_updates=initial_state
            )
            
        except Exception as e:
            logger.error(f"Failed to initialize session state: {e}", exc_info=True)
            return False
    
    # ===== BULK STATE OPERATIONS =====
    
    async def bulk_update_user_state(
        self,
        user_id: str,
        state_updates: Dict[str, Any],
        app_name_filter: Optional[str] = None
    ) -> Dict[str, bool]:
        """Update state across all sessions for a user.
        
        Args:
            user_id: User identifier
            state_updates: State updates to apply
            app_name_filter: Optional filter for specific app
            
        Returns:
            Dictionary mapping session_key to success status
        """
        results = {}
        
        if user_id not in self._user_sessions:
            logger.info(f"No sessions found for user {user_id}")
            return results
        
        for session_key in self._user_sessions[user_id]:
            app_name, session_id = session_key.split(':', 1)
            
            # Apply filter if specified
            if app_name_filter and app_name != app_name_filter:
                continue
            
            success = await self.update_session_state(
                session_id=session_id,
                app_name=app_name,
                user_id=user_id,
                state_updates=state_updates
            )
            
            results[session_key] = success
        
        return results
    
    # ===== EXISTING METHODS (unchanged) =====
    
    def _track_session(self, session_key: str, user_id: str):
        """Track a session key for enumeration."""
        self._session_keys.add(session_key)
        
        if user_id not in self._user_sessions:
            self._user_sessions[user_id] = set()
        self._user_sessions[user_id].add(session_key)
    
    def _untrack_session(self, session_key: str, user_id: str):
        """Remove session tracking."""
        self._session_keys.discard(session_key)
        
        if user_id in self._user_sessions:
            self._user_sessions[user_id].discard(session_key)
            if not self._user_sessions[user_id]:
                del self._user_sessions[user_id]
    
    async def _remove_oldest_user_session(self, user_id: str):
        """Remove the oldest session for a user based on lastUpdateTime."""
        if user_id not in self._user_sessions:
            return
        
        oldest_session = None
        oldest_time = float('inf')
        
        # Find oldest session by checking ADK's lastUpdateTime
        for session_key in self._user_sessions[user_id]:
            app_name, session_id = session_key.split(':', 1)
            try:
                session = await self._session_service.get_session(
                    session_id=session_id,
                    app_name=app_name,
                    user_id=user_id
                )
                if session and hasattr(session, 'last_update_time'):
                    update_time = session.last_update_time
                    if update_time < oldest_time:
                        oldest_time = update_time
                        oldest_session = session
            except Exception as e:
                logger.error(f"Error checking session {session_key}: {e}")
        
        if oldest_session:
            session_key = f"{oldest_session.app_name}:{oldest_session.id}"
            await self._delete_session(oldest_session)
            logger.info(f"Removed oldest session for user {user_id}: {session_key}")
    
    async def _delete_session(self, session):
        """Delete a session using the session object directly.
        
        Args:
            session: The ADK session object to delete
        """
        if not session:
            logger.warning("Cannot delete None session")
            return
            
        session_key = f"{session.app_name}:{session.id}"
        
        # If memory service is available, add session to memory before deletion
        logger.debug(f"Deleting session {session_key}, memory_service: {self._memory_service is not None}")
        if self._memory_service:
            try:
                await self._memory_service.add_session_to_memory(session)
                logger.debug(f"Added session {session_key} to memory before deletion")
            except Exception as e:
                logger.error(f"Failed to add session {session_key} to memory: {e}")
        
        try:
            await self._session_service.delete_session(
                session_id=session.id,
                app_name=session.app_name,
                user_id=session.user_id
            )
            logger.debug(f"Deleted session: {session_key}")
        except Exception as e:
            logger.error(f"Failed to delete session {session_key}: {e}")
        
        self._untrack_session(session_key, session.user_id)
    
    def _start_cleanup_task(self):
        """Start the cleanup task if not already running."""
        try:
            loop = asyncio.get_running_loop()
            self._cleanup_task = loop.create_task(self._cleanup_loop())
            logger.debug(f"Started session cleanup task {id(self._cleanup_task)} for SessionManager {id(self)}")
        except RuntimeError:
            logger.debug("No event loop, cleanup will start later")
    
    async def _cleanup_loop(self):
        """Periodically clean up expired sessions."""
        logger.debug(f"Cleanup loop started for SessionManager {id(self)}")
        while True:
            try:
                await asyncio.sleep(self._cleanup_interval)
                logger.debug(f"Running cleanup on SessionManager {id(self)}")
                await self._cleanup_expired_sessions()
            except asyncio.CancelledError:
                logger.info("Cleanup task cancelled")
                break
            except Exception as e:
                logger.error(f"Cleanup error: {e}", exc_info=True)
    
    async def _cleanup_expired_sessions(self):
        """Find and remove expired sessions based on lastUpdateTime."""
        current_time = time.time()
        expired_count = 0
        
        # Check all tracked sessions
        for session_key in list(self._session_keys):  # Copy to avoid modification during iteration
            app_name, session_id = session_key.split(':', 1)
            
            # Find user_id for this session
            user_id = None
            for uid, keys in self._user_sessions.items():
                if session_key in keys:
                    user_id = uid
                    break
            
            if not user_id:
                continue
            
            try:
                session = await self._session_service.get_session(
                    session_id=session_id,
                    app_name=app_name,
                    user_id=user_id
                )
                
                if session and hasattr(session, 'last_update_time'):
                    age = current_time - session.last_update_time
                    if age > self._timeout:
                        # Check for pending tool calls before deletion (HITL scenarios)
                        pending_calls = session.state.get("pending_tool_calls", []) if session.state else []
                        if pending_calls:
                            logger.info(f"Preserving expired session {session_key} - has {len(pending_calls)} pending tool calls (HITL)")
                        else:
                            await self._delete_session(session)
                            expired_count += 1
                elif not session:
                    # Session doesn't exist, just untrack it
                    self._untrack_session(session_key, user_id)
                    
            except Exception as e:
                logger.error(f"Error checking session {session_key}: {e}")
        
        if expired_count > 0:
            logger.info(f"Cleaned up {expired_count} expired sessions")
    
    def get_session_count(self) -> int:
        """Get total number of tracked sessions."""
        return len(self._session_keys)
    
    def get_user_session_count(self, user_id: str) -> int:
        """Get number of sessions for a user."""
        return len(self._user_sessions.get(user_id, set()))
    
    async def stop_cleanup_task(self):
        """Stop the cleanup task."""
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass
            self._cleanup_task = None


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/utils/__init__.py
================================================
# src/utils/__init__.py

"""Utility functions for ADK middleware."""

from .converters import (
    convert_ag_ui_messages_to_adk,
    convert_adk_event_to_ag_ui_message,
    convert_state_to_json_patch,
    convert_json_patch_to_state
)

__all__ = [
    'convert_ag_ui_messages_to_adk',
    'convert_adk_event_to_ag_ui_message',
    'convert_state_to_json_patch',
    'convert_json_patch_to_state'
]


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/src/ag_ui_adk/utils/converters.py
================================================
# src/utils/converters.py

"""Conversion utilities between AG-UI and ADK formats."""

from typing import List, Dict, Any, Optional
import json
import logging

from ag_ui.core import (
    Message, UserMessage, AssistantMessage, SystemMessage, ToolMessage,
    ToolCall, FunctionCall
)
from google.adk.events import Event as ADKEvent
from google.genai import types

logger = logging.getLogger(__name__)


def convert_ag_ui_messages_to_adk(messages: List[Message]) -> List[ADKEvent]:
    """Convert AG-UI messages to ADK events.
    
    Args:
        messages: List of AG-UI messages
        
    Returns:
        List of ADK events
    """
    adk_events = []
    
    for message in messages:
        try:
            # Create base event
            event = ADKEvent(
                id=message.id,
                author=message.role,
                content=None
            )
            
            # Convert content based on message type
            if isinstance(message, (UserMessage, SystemMessage)):
                if message.content:
                    event.content = types.Content(
                        role=message.role,
                        parts=[types.Part(text=message.content)]
                    )
            
            elif isinstance(message, AssistantMessage):
                parts = []
                
                # Add text content if present
                if message.content:
                    parts.append(types.Part(text=message.content))
                
                # Add tool calls if present
                if message.tool_calls:
                    for tool_call in message.tool_calls:
                        parts.append(types.Part(
                            function_call=types.FunctionCall(
                                name=tool_call.function.name,
                                args=json.loads(tool_call.function.arguments) if isinstance(tool_call.function.arguments, str) else tool_call.function.arguments,
                                id=tool_call.id
                            )
                        ))
                
                if parts:
                    event.content = types.Content(
                        role="model",  # ADK uses "model" for assistant
                        parts=parts
                    )
            
            elif isinstance(message, ToolMessage):
                # Tool messages become function responses
                event.content = types.Content(
                    role="function",
                    parts=[types.Part(
                        function_response=types.FunctionResponse(
                            name=message.tool_call_id, 
                            response={"result": message.content} if isinstance(message.content, str) else message.content,
                            id=message.tool_call_id
                        )
                    )]
                )
            
            adk_events.append(event)
            
        except Exception as e:
            logger.error(f"Error converting message {message.id}: {e}")
            continue
    
    return adk_events


def convert_adk_event_to_ag_ui_message(event: ADKEvent) -> Optional[Message]:
    """Convert an ADK event to an AG-UI message.
    
    Args:
        event: ADK event
        
    Returns:
        AG-UI message or None if not convertible
    """
    try:
        # Skip events without content
        if not event.content or not event.content.parts:
            return None
        
        # Determine message type based on author/role
        if event.author == "user":
            # Extract text content
            text_parts = [part.text for part in event.content.parts if part.text]
            if text_parts:
                return UserMessage(
                    id=event.id,
                    role="user",
                    content="\n".join(text_parts)
                )
        
        else:  # Assistant/model response
            # Extract text and tool calls
            text_parts = []
            tool_calls = []
            
            for part in event.content.parts:
                if part.text:
                    text_parts.append(part.text)
                elif part.function_call:
                    tool_calls.append(ToolCall(
                        id=getattr(part.function_call, 'id', event.id),
                        type="function",
                        function=FunctionCall(
                            name=part.function_call.name,
                            arguments=json.dumps(part.function_call.args) if hasattr(part.function_call, 'args') else "{}"
                        )
                    ))
            
            return AssistantMessage(
                id=event.id,
                role="assistant",
                content="\n".join(text_parts) if text_parts else None,
                tool_calls=tool_calls if tool_calls else None
            )
        
    except Exception as e:
        logger.error(f"Error converting ADK event {event.id}: {e}")
    
    return None


def convert_state_to_json_patch(state_delta: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Convert a state delta to JSON Patch format (RFC 6902).
    
    Args:
        state_delta: Dictionary of state changes
        
    Returns:
        List of JSON Patch operations
    """
    patches = []
    
    for key, value in state_delta.items():
        # Determine operation type
        if value is None:
            # Remove operation
            patches.append({
                "op": "remove",
                "path": f"/{key}"
            })
        else:
            # Add/replace operation
            # We use "replace" as it works for both existing and new keys
            patches.append({
                "op": "replace",
                "path": f"/{key}",
                "value": value
            })
    
    return patches


def convert_json_patch_to_state(patches: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Convert JSON Patch operations to a state delta dictionary.
    
    Args:
        patches: List of JSON Patch operations
        
    Returns:
        Dictionary of state changes
    """
    state_delta = {}
    
    for patch in patches:
        op = patch.get("op")
        path = patch.get("path", "")
        
        # Extract key from path (remove leading slash)
        key = path.lstrip("/")
        
        if op == "remove":
            state_delta[key] = None
        elif op in ["add", "replace"]:
            state_delta[key] = patch.get("value")
        # Ignore other operations for now (copy, move, test)
    
    return state_delta


def extract_text_from_content(content: types.Content) -> str:
    """Extract all text from ADK Content object.
    
    Args:
        content: ADK Content object
        
    Returns:
        Combined text from all text parts
    """
    if not content or not content.parts:
        return ""
    
    text_parts = []
    for part in content.parts:
        if part.text:
            text_parts.append(part.text)
    
    return "\n".join(text_parts)


def create_error_message(error: Exception, context: str = "") -> str:
    """Create a user-friendly error message.
    
    Args:
        error: The exception
        context: Additional context about where the error occurred
        
    Returns:
        Formatted error message
    """
    error_type = type(error).__name__
    error_msg = str(error)
    
    if context:
        return f"{context}: {error_type} - {error_msg}"
    else:
        return f"{error_type}: {error_msg}"


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/__init__.py
================================================
# tests/__init__.py

"""Test suite for ADK Middleware."""


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/run_all_tests.sh
================================================
#!/bin/bash

# Script to run all Python tests
# This script will execute all test_*.py files using pytest

echo "Running all Python tests..."
echo "=========================="

# Get all test files
test_files=$(ls test_*.py 2>/dev/null)

if [ -z "$test_files" ]; then
    echo "No test files found (test_*.py pattern)"
    exit 1
fi

# Count total test files
total_tests=$(echo "$test_files" | wc -l)
echo "Found $total_tests test files"
echo

# Run all tests at once (recommended approach)
echo "Running all tests together:"
pytest test_*.py -v

echo
echo "=========================="
echo "All tests completed!"

# Alternative: Run each test file individually (uncomment if needed)
# echo
# echo "Running tests individually:"
# echo "=========================="
# 
# current=1
# for test_file in $test_files; do
#     echo "[$current/$total_tests] Running $test_file..."
#     pytest "$test_file" -v
#     echo
#     ((current++))
# done


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/server_setup.py
================================================
#!/usr/bin/env python
"""Test server for ADK middleware with AG-UI client."""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / "src"))

import uvicorn
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware


from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint

# Import your ADK agent - adjust based on what you have
from google.adk.agents import Agent

# Create FastAPI app
app = FastAPI(title="ADK Middleware Test Server")

# Add CORS middleware for browser-based AG-UI clients
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Set up agent registry
registry = AgentRegistry.get_instance()

# Create a simple test agent
test_agent = Agent(
    name="test_assistant",
    instruction="You are a helpful AI assistant for testing the ADK middleware."
)

# Register the agent
registry.register_agent("test-agent", test_agent)
registry.set_default_agent(test_agent)

# Create ADK middleware instance
adk_agent = ADKAgent(
    app_name="test_app",
    user_id="test_user",  # Or use user_id_extractor for dynamic user resolution
    use_in_memory_services=True,
)

# Add the chat endpoint
add_adk_fastapi_endpoint(app, adk_agent, path="/chat")

@app.get("/")
async def root():
    return {
        "service": "ADK Middleware",
        "status": "ready",
        "endpoints": {
            "chat": "/chat",
            "docs": "/docs"
        }
    }

@app.get("/health")
async def health():
    return {"status": "healthy"}

if __name__ == "__main__":
    print("🚀 Starting ADK Middleware Test Server")
    print("📍 Chat endpoint: http://localhost:8000/chat")
    print("📚 API docs: http://localhost:8000/docs")
    print("\nTo test with curl:")
    print('curl -X POST http://localhost:8000/chat \\')
    print('  -H "Content-Type: application/json" \\')
    print('  -H "Accept: text/event-stream" \\')
    print('  -d \'{"thread_id": "test-thread", "run_id": "test-run", "messages": [{"role": "user", "content": "Hello!"}]}\'')

    uvicorn.run(app, host="0.0.0.0", port=8000)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_adk_agent.py
================================================
# tests/test_adk_agent.py

"""Tests for ADKAgent middleware."""

import pytest
import asyncio
from unittest.mock import Mock, MagicMock, AsyncMock, patch


from ag_ui_adk import ADKAgent, SessionManager
from ag_ui.core import (
    RunAgentInput, EventType, UserMessage, Context,
    RunStartedEvent, RunFinishedEvent, TextMessageChunkEvent, SystemMessage
)
from google.adk.agents import Agent


class TestADKAgent:
    """Test cases for ADKAgent."""

    @pytest.fixture
    def mock_agent(self):
        """Create a mock ADK agent."""
        agent = Mock(spec=Agent)
        agent.name = "test_agent"
        return agent


    @pytest.fixture(autouse=True)
    def reset_session_manager(self):
        """Reset session manager before each test."""
        try:
            SessionManager.reset_instance()
        except RuntimeError:
            # Event loop may be closed - ignore
            pass
        yield
        # Cleanup after test
        try:
            SessionManager.reset_instance()
        except RuntimeError:
            # Event loop may be closed - ignore
            pass

    @pytest.fixture
    def adk_agent(self, mock_agent):
        """Create an ADKAgent instance."""
        return ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True
        )

    @pytest.fixture
    def sample_input(self):
        """Create a sample RunAgentInput."""
        return RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                UserMessage(
                    id="msg1",
                    role="user",
                    content="Hello, test!"
                )
            ],
            context=[
                Context(description="test", value="true")
            ],
            state={},
            tools=[],
            forwarded_props={}
        )

    @pytest.mark.asyncio
    async def test_agent_initialization(self, adk_agent):
        """Test ADKAgent initialization."""
        assert adk_agent._static_user_id == "test_user"
        assert adk_agent._static_app_name == "test_app"
        assert adk_agent._session_manager is not None

    @pytest.mark.asyncio
    async def test_user_extraction(self, adk_agent, sample_input):
        """Test user ID extraction."""
        # Test static user ID
        assert adk_agent._get_user_id(sample_input) == "test_user"

        # Test custom extractor
        def custom_extractor(input):
            return "custom_user"

        # Create a test agent for the custom instance
        test_agent_custom = Mock(spec=Agent)
        test_agent_custom.name = "custom_test_agent"

        adk_agent_custom = ADKAgent(adk_agent=test_agent_custom, app_name="test_app", user_id_extractor=custom_extractor)
        assert adk_agent_custom._get_user_id(sample_input) == "custom_user"

    @pytest.mark.asyncio
    async def test_adk_agent_has_direct_reference(self, adk_agent, sample_input):
        """Test that ADK agent has direct reference to underlying agent."""
        # Test that the agent is directly accessible
        assert adk_agent._adk_agent is not None
        assert adk_agent._adk_agent.name == "test_agent"

    @pytest.mark.asyncio
    async def test_run_basic_flow(self, adk_agent, sample_input, mock_agent):
        """Test basic run flow with mocked runner."""
        with patch.object(adk_agent, '_create_runner') as mock_create_runner:
            # Create a mock runner
            mock_runner = AsyncMock()
            mock_event = Mock()
            mock_event.id = "event1"
            mock_event.author = "test_agent"
            mock_event.content = Mock()
            mock_event.content.parts = [Mock(text="Hello from agent!")]
            mock_event.partial = False
            mock_event.actions = None
            mock_event.get_function_calls = Mock(return_value=[])
            mock_event.get_function_responses = Mock(return_value=[])

            # Configure mock runner to yield our mock event
            async def mock_run_async(*args, **kwargs):
                yield mock_event

            mock_runner.run_async = mock_run_async
            mock_create_runner.return_value = mock_runner

            # Collect events
            events = []
            async for event in adk_agent.run(sample_input):
                events.append(event)

            # Verify events
            assert len(events) >= 2  # At least RUN_STARTED and RUN_FINISHED
            assert events[0].type == EventType.RUN_STARTED
            assert events[-1].type == EventType.RUN_FINISHED

    @pytest.mark.asyncio
    async def test_session_management(self, adk_agent):
        """Test session lifecycle management."""
        session_mgr = adk_agent._session_manager

        # Create a session through get_or_create_session
        await session_mgr.get_or_create_session(
            session_id="session1",
            app_name="agent1",
            user_id="user1"
        )

        assert session_mgr.get_session_count() == 1

        # Add another session
        await session_mgr.get_or_create_session(
            session_id="session2",
            app_name="agent1",
            user_id="user1"
        )
        assert session_mgr.get_session_count() == 2

    @pytest.mark.asyncio
    async def test_error_handling(self, adk_agent, sample_input):
        """Test error handling in run method."""
        # Force an error by making the underlying agent fail
        adk_agent._adk_agent = None  # This will cause an error

        events = []
        async for event in adk_agent.run(sample_input):
            events.append(event)

        # Should get RUN_STARTED, RUN_ERROR, and RUN_FINISHED
        assert len(events) == 3
        assert events[0].type == EventType.RUN_STARTED
        assert events[1].type == EventType.RUN_ERROR
        assert events[2].type == EventType.RUN_FINISHED
        # Check that it's an error with meaningful content
        assert len(events[1].message) > 0
        assert events[1].code == 'BACKGROUND_EXECUTION_ERROR'

    @pytest.mark.asyncio
    async def test_cleanup(self, adk_agent):
        """Test cleanup method."""
        # Add a mock execution
        mock_execution = Mock()
        mock_execution.cancel = AsyncMock()

        async with adk_agent._execution_lock:
            adk_agent._active_executions["test_thread"] = mock_execution

        await adk_agent.close()

        # Verify execution was cancelled and cleaned up
        mock_execution.cancel.assert_called_once()
        assert len(adk_agent._active_executions) == 0

    @pytest.mark.asyncio
    async def test_system_message_appended_to_instructions(self):
        """Test that SystemMessage as first message gets appended to agent instructions."""
        # Create an agent with initial instructions
        mock_agent = Agent(
            name="test_agent",
            instruction="You are a helpful assistant."
        )

        adk_agent = ADKAgent(adk_agent=mock_agent, app_name="test_app", user_id="test_user")

        # Create input with SystemMessage as first message
        system_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                SystemMessage(id="sys_1", role="system", content="Be very concise in responses."),
                UserMessage(id="msg_1", role="user", content="Hello")
            ],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        # Mock the background execution to capture the modified agent
        captured_agent = None
        original_run_background = adk_agent._run_adk_in_background

        async def mock_run_background(input, adk_agent, user_id, app_name, event_queue):
            nonlocal captured_agent
            captured_agent = adk_agent
            # Just put a completion event in the queue and return
            await event_queue.put(None)

        with patch.object(adk_agent, '_run_adk_in_background', side_effect=mock_run_background):
            # Start execution to trigger agent modification
            execution = await adk_agent._start_background_execution(system_input)

            # Wait briefly for the background task to start
            await asyncio.sleep(0.01)

        # Verify the agent's instruction was modified
        assert captured_agent is not None
        expected_instruction = "You are a helpful assistant.\n\nBe very concise in responses."
        assert captured_agent.instruction == expected_instruction

    @pytest.mark.asyncio
    async def test_system_message_appended_to_instruction_provider(self):
        """Test that SystemMessage as first message gets appended to agent instructions
        when they are set via instruction provider."""
        # Create an agent with initial instructions
        received_context = None

        async def instruction_provider(context) -> str:
            nonlocal received_context
            received_context = context
            return "You are a helpful assistant."

        mock_agent = Agent(
            name="test_agent",
            instruction=instruction_provider
        )

        adk_agent = ADKAgent(adk_agent=mock_agent, app_name="test_app", user_id="test_user")

        # Create input with SystemMessage as first message
        system_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                SystemMessage(id="sys_1", role="system", content="Be very concise in responses."),
                UserMessage(id="msg_1", role="user", content="Hello")
            ],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        # Mock the background execution to capture the modified agent
        captured_agent = None
        original_run_background = adk_agent._run_adk_in_background

        async def mock_run_background(input, adk_agent, user_id, app_name, event_queue):
            nonlocal captured_agent
            captured_agent = adk_agent
            # Just put a completion event in the queue and return
            await event_queue.put(None)

        with patch.object(adk_agent, '_run_adk_in_background', side_effect=mock_run_background):
            # Start execution to trigger agent modification
            execution = await adk_agent._start_background_execution(system_input)

            # Wait briefly for the background task to start
            await asyncio.sleep(0.01)

        # Verify the agent's instruction was wrapped correctly
        assert captured_agent is not None
        assert callable(captured_agent.instruction) is True

        # Test that the context object received in instruction provider is the same
        test_context = {"test": "value"}
        expected_instruction = "You are a helpful assistant.\n\nBe very concise in responses."
        agent_instruction = await captured_agent.instruction(test_context)
        assert agent_instruction == expected_instruction
        assert received_context is test_context

    @pytest.mark.asyncio
    async def test_system_message_appended_to_instruction_provider_with_none(self):
        """Test that SystemMessage as first message gets appended to agent instructions
        when they are set via instruction provider."""
        # Create an agent with initial instructions, but return None
        async def instruction_provider(context) -> str:
            return None

        mock_agent = Agent(
            name="test_agent",
            instruction=instruction_provider
        )

        adk_agent = ADKAgent(adk_agent=mock_agent, app_name="test_app", user_id="test_user")

        # Create input with SystemMessage as first message
        system_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                SystemMessage(id="sys_1", role="system", content="Be very concise in responses."),
                UserMessage(id="msg_1", role="user", content="Hello")
            ],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        # Mock the background execution to capture the modified agent
        captured_agent = None
        original_run_background = adk_agent._run_adk_in_background

        async def mock_run_background(input, adk_agent, user_id, app_name, event_queue):
            nonlocal captured_agent
            captured_agent = adk_agent
            # Just put a completion event in the queue and return
            await event_queue.put(None)

        with patch.object(adk_agent, '_run_adk_in_background', side_effect=mock_run_background):
            # Start execution to trigger agent modification
            execution = await adk_agent._start_background_execution(system_input)

            # Wait briefly for the background task to start
            await asyncio.sleep(0.01)

        # Verify the agent's instruction was wrapped correctly
        assert captured_agent is not None
        assert callable(captured_agent.instruction) is True

        # No empty new lines should be added before the instructions
        expected_instruction = "Be very concise in responses."
        agent_instruction = await captured_agent.instruction({})
        assert agent_instruction == expected_instruction

    @pytest.mark.asyncio
    async def test_system_message_appended_to_sync_instruction_provider(self):
        """Test that SystemMessage as first message gets appended to agent instructions
        when they are set via sync instruction provider."""
        # Create an agent with initial instructions
        received_context = None

        def instruction_provider(context) -> str:
            nonlocal received_context
            received_context = context
            return "You are a helpful assistant."

        mock_agent = Agent(
            name="test_agent",
            instruction=instruction_provider
        )

        adk_agent = ADKAgent(adk_agent=mock_agent, app_name="test_app", user_id="test_user")

        # Create input with SystemMessage as first message
        system_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                SystemMessage(id="sys_1", role="system", content="Be very concise in responses."),
                UserMessage(id="msg_1", role="user", content="Hello")
            ],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        # Mock the background execution to capture the modified agent
        captured_agent = None
        original_run_background = adk_agent._run_adk_in_background

        async def mock_run_background(input, adk_agent, user_id, app_name, event_queue):
            nonlocal captured_agent
            captured_agent = adk_agent
            # Just put a completion event in the queue and return
            await event_queue.put(None)

        with patch.object(adk_agent, '_run_adk_in_background', side_effect=mock_run_background):
            # Start execution to trigger agent modification
            execution = await adk_agent._start_background_execution(system_input)

            # Wait briefly for the background task to start
            await asyncio.sleep(0.01)

        # Verify agent was captured
        assert captured_agent is not None
        assert callable(captured_agent.instruction)

        # Test that the context object received in instruction provider is the same
        test_context = {"test": "value"}
        expected_instruction = "You are a helpful assistant.\n\nBe very concise in responses."
        agent_instruction = captured_agent.instruction(test_context)  # Note: no await for sync function
        assert agent_instruction == expected_instruction
        assert received_context is test_context

    @pytest.mark.asyncio
    async def test_system_message_not_first_ignored(self):
        """Test that SystemMessage not as first message is ignored."""
        mock_agent = Agent(
            name="test_agent",
            instruction="You are a helpful assistant."
        )

        adk_agent = ADKAgent(adk_agent=mock_agent, app_name="test_app", user_id="test_user")

        # Create input with SystemMessage as second message
        system_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                UserMessage(id="msg_1", role="user", content="Hello"),
                SystemMessage(id="sys_1", role="system", content="Be very concise in responses.")
            ],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        # Mock the background execution to capture the agent
        captured_agent = None

        async def mock_run_background(input, adk_agent, user_id, app_name, event_queue):
            nonlocal captured_agent
            captured_agent = adk_agent
            await event_queue.put(None)

        with patch.object(adk_agent, '_run_adk_in_background', side_effect=mock_run_background):
            execution = await adk_agent._start_background_execution(system_input)
            await asyncio.sleep(0.01)

        # Verify the agent's instruction was NOT modified
        assert captured_agent.instruction == "You are a helpful assistant."

    @pytest.mark.asyncio
    async def test_system_message_with_no_existing_instruction(self):
        """Test SystemMessage handling when agent has no existing instruction."""
        mock_agent = Agent(name="test_agent")  # No instruction

        adk_agent = ADKAgent(adk_agent=mock_agent, app_name="test_app", user_id="test_user")

        system_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                SystemMessage(id="sys_1", role="system", content="You are a math tutor.")
            ],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        captured_agent = None

        async def mock_run_background(input, adk_agent, user_id, app_name, event_queue):
            nonlocal captured_agent
            captured_agent = adk_agent
            await event_queue.put(None)

        with patch.object(adk_agent, '_run_adk_in_background', side_effect=mock_run_background):
            execution = await adk_agent._start_background_execution(system_input)
            await asyncio.sleep(0.01)

        # Verify the SystemMessage became the instruction
        assert captured_agent.instruction == "You are a math tutor."





================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_adk_agent_memory_integration.py
================================================
#!/usr/bin/env python
"""Test ADKAgent memory service integration functionality."""

import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, Mock, patch

from ag_ui_adk import ADKAgent, SessionManager
from ag_ui.core import RunAgentInput, UserMessage, Context
from google.adk.agents import Agent


class TestADKAgentMemoryIntegration:
    """Test cases for ADKAgent memory service integration."""

    @pytest.fixture
    def mock_agent(self):
        """Create a mock ADK agent."""
        agent = Mock(spec=Agent)
        agent.name = "memory_test_agent"
        agent.model_copy = Mock(return_value=agent)
        return agent


    @pytest.fixture(autouse=True)
    def reset_session_manager(self):
        """Reset session manager before each test."""
        SessionManager.reset_instance()
        yield
        SessionManager.reset_instance()

    @pytest.fixture
    def mock_memory_service(self):
        """Create a mock memory service."""
        service = AsyncMock()
        service.add_session_to_memory = AsyncMock()
        return service

    @pytest.fixture
    def simple_input(self):
        """Create a simple RunAgentInput for testing."""
        return RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[UserMessage(id="msg_1", role="user", content="Hello")],
            state={},
            context=[Context(description="user", value="test_user")],
            tools=[],
            forwarded_props={}
        )

    def test_adk_agent_memory_service_initialization_explicit(self, mock_memory_service, mock_agent):
        """Test ADKAgent properly stores explicit memory service."""
        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            memory_service=mock_memory_service,
            use_in_memory_services=True
        )

        # Verify the memory service is stored
        assert adk_agent._memory_service is mock_memory_service

    def test_adk_agent_memory_service_initialization_in_memory(self, mock_agent):
        """Test ADKAgent creates in-memory memory service when use_in_memory_services=True."""
        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True
        )

        # Verify an in-memory memory service was created
        assert adk_agent._memory_service is not None
        # Should be InMemoryMemoryService type
        assert "InMemoryMemoryService" in str(type(adk_agent._memory_service))

    def test_adk_agent_memory_service_initialization_disabled(self, mock_agent):
        """Test ADKAgent doesn't create memory service when use_in_memory_services=False."""
        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            memory_service=None,
            use_in_memory_services=False
        )

        # Verify memory service is None
        assert adk_agent._memory_service is None

    def test_adk_agent_passes_memory_service_to_session_manager(self, mock_memory_service, mock_agent):
        """Test that ADKAgent passes memory service to SessionManager."""
        with patch.object(SessionManager, 'get_instance') as mock_get_instance:
            mock_session_manager = Mock()
            mock_get_instance.return_value = mock_session_manager

            adk_agent = ADKAgent(
                adk_agent=mock_agent,
                app_name="test_app",
                user_id="test_user",
                memory_service=mock_memory_service,
                use_in_memory_services=True
            )

            # Verify SessionManager.get_instance was called with the memory service
            mock_get_instance.assert_called_once()
            call_args = mock_get_instance.call_args
            assert call_args[1]['memory_service'] is mock_memory_service

    def test_adk_agent_memory_service_sharing_same_instance(self, mock_memory_service, mock_agent):
        """Test that the same memory service instance is used across components."""
        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            memory_service=mock_memory_service,
            use_in_memory_services=True
        )

        # The ADKAgent should store the same instance
        assert adk_agent._memory_service is mock_memory_service

        # The SessionManager should also have the same instance
        session_manager = adk_agent._session_manager
        assert session_manager._memory_service is mock_memory_service

    @patch('ag_ui_adk.adk_agent.Runner')
    def test_adk_agent_creates_runner_with_memory_service(self, mock_runner_class, mock_memory_service, mock_agent, simple_input):
        """Test that ADKAgent creates Runner with the correct memory service."""
        # Setup mock runner
        mock_runner = AsyncMock()
        mock_runner.run_async = AsyncMock()
        # Create an async generator that yields no events and then stops
        async def mock_run_async(*args, **kwargs):
            # Yield no events - just return immediately
            if False:  # This makes it an async generator that yields nothing
                yield
        mock_runner.run_async.return_value = mock_run_async()
        mock_runner_class.return_value = mock_runner

        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            memory_service=mock_memory_service,
            use_in_memory_services=True
        )

        # Mock the _create_runner method to capture its call
        with patch.object(adk_agent, '_create_runner', return_value=mock_runner) as mock_create_runner:
            # Start the execution (it will fail due to mocking but we just want to see the Runner creation)
            gen = adk_agent.run(simple_input)

            # Start the async generator to trigger runner creation
            try:
                async def run_test():
                    async for event in gen:
                        break  # Just get the first event to trigger runner creation

                # We expect this to fail due to mocking, but it should call _create_runner
                asyncio.create_task(run_test())
                asyncio.get_event_loop().run_until_complete(asyncio.sleep(0.1))
            except:
                pass  # Expected to fail due to mocking

            # Verify that _create_runner was called and Runner was created with memory service
            # We can check this by verifying the Runner constructor was called with memory_service
            if mock_runner_class.called:
                call_args = mock_runner_class.call_args
                assert call_args[1]['memory_service'] is mock_memory_service

    def test_adk_agent_memory_service_configuration_inheritance(self, mock_memory_service, mock_agent):
        """Test that memory service configuration is properly inherited by all components."""
        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            memory_service=mock_memory_service,
            use_in_memory_services=True
        )

        # Test the memory service ID is consistent across components
        agent_memory_service_id = id(adk_agent._memory_service)
        session_manager_memory_service_id = id(adk_agent._session_manager._memory_service)

        assert agent_memory_service_id == session_manager_memory_service_id

        # Both should point to the same mock object
        assert adk_agent._memory_service is mock_memory_service
        assert adk_agent._session_manager._memory_service is mock_memory_service

    def test_adk_agent_in_memory_memory_service_defaults(self, mock_agent):
        """Test that in-memory memory service defaults work correctly."""
        adk_agent = ADKAgent(
            adk_agent=mock_agent,
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True  # Should create InMemoryMemoryService
        )

        # Should have created an InMemoryMemoryService
        assert adk_agent._memory_service is not None
        assert "InMemoryMemoryService" in str(type(adk_agent._memory_service))

        # SessionManager should have the same instance
        assert adk_agent._session_manager._memory_service is adk_agent._memory_service

        # Should be the same object (not just same type)
        assert id(adk_agent._memory_service) == id(adk_agent._session_manager._memory_service)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_app_name_extractor.py
================================================
#!/usr/bin/env python
"""Test app name extraction functionality."""

import asyncio
from ag_ui.core import RunAgentInput, UserMessage, Context
from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
from google.adk.agents import Agent

async def test_static_app_name():
    """Test static app name configuration."""
    print("🧪 Testing static app name...")

    # Create a test ADK agent
    test_agent = Agent(name="test_agent", instruction="You are a test agent.")

    # Create agent with static app name
    adk_agent = ADKAgent(
        adk_agent=test_agent,
        app_name="static_test_app",
        user_id="test_user",
        use_in_memory_services=True
    )

    # Create test input
    test_input = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        state={},
        context=[],
        tools=[],
        forwarded_props={}
    )

    # Get app name
    app_name = adk_agent._get_app_name(test_input)
    print(f"   App name: {app_name}")

    if app_name == "static_test_app":
        print("✅ Static app name works correctly")
        return True
    else:
        print("❌ Static app name not working")
        return False

async def test_custom_extractor():
    """Test custom app_name_extractor function."""
    print("\n🧪 Testing custom app_name_extractor...")

    # Create custom extractor
    def extract_app_from_context(input_data):
        for ctx in input_data.context:
            if ctx.description == "app":
                return ctx.value
        return "fallback_app"

    # Create a test ADK agent
    test_agent = Agent(name="test_agent", instruction="You are a test agent.")

    # Create agent with custom extractor
    adk_agent = ADKAgent(
        adk_agent=test_agent,
        app_name_extractor=extract_app_from_context,
        user_id="test_user",
        use_in_memory_services=True
    )

    # Test with context containing app
    test_input_with_app = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        state={},
        context=[
            Context(description="app", value="my_custom_app"),
            Context(description="user", value="john_doe")
        ],
        tools=[],
        forwarded_props={}
    )

    app_name = adk_agent._get_app_name(test_input_with_app)
    print(f"   App name from context: {app_name}")

    # Test fallback
    test_input_no_app = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        state={},
        context=[Context(description="user", value="john_doe")],
        tools=[],
        forwarded_props={}
    )

    app_name_fallback = adk_agent._get_app_name(test_input_no_app)
    print(f"   App name fallback: {app_name_fallback}")

    if app_name == "my_custom_app" and app_name_fallback == "fallback_app":
        print("✅ Custom app_name_extractor works correctly")
        return True
    else:
        print("❌ Custom app_name_extractor not working")
        return False

async def test_default_extractor():
    """Test default app extraction logic - should use agent name."""
    print("\n🧪 Testing default app extraction...")

    # Create a test ADK agent with a specific name
    test_agent = Agent(name="default_app_agent", instruction="You are a test agent.")

    # Create agent without specifying app_name or extractor
    # This should now use the agent name as app_name
    adk_agent = ADKAgent(
        adk_agent=test_agent,
        user_id="test_user",
        use_in_memory_services=True
    )

    # Create test input
    test_input = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        state={},
        context=[],
        tools=[],
        forwarded_props={}
    )

    # Get app name - should use agent name from registry
    app_name = adk_agent._get_app_name(test_input)
    print(f"   App name from agent: {app_name}")

    # Should be the agent name from registry (test_agent)
    if app_name == "test_agent":
        print("✅ Default app extraction using agent name works correctly")
        return True
    else:
        print(f"❌ Expected 'test_agent', got '{app_name}'")
        return False

async def test_conflicting_config():
    """Test that specifying both app_name and app_name_extractor raises error."""
    print("\n🧪 Testing conflicting configuration...")

    def dummy_extractor(input_data):
        return "extracted_app"

    # Create a test ADK agent
    test_agent = Agent(name="conflict_test_agent", instruction="You are a test agent.")

    try:
        adk_agent = ADKAgent(
            adk_agent=test_agent,
            app_name="static_app",
            app_name_extractor=dummy_extractor,
            user_id="test_user",
            use_in_memory_services=True
        )
        print("❌ Should have raised ValueError")
        return False
    except ValueError as e:
        print(f"✅ Correctly raised error: {e}")
        return True

async def test_combined_extractors():
    """Test using both app and user extractors together."""
    print("\n🧪 Testing combined app and user extractors...")

    def extract_app(input_data):
        for ctx in input_data.context:
            if ctx.description == "app":
                return ctx.value
        return "AG-UI ADK Agent"

    def extract_user(input_data):
        for ctx in input_data.context:
            if ctx.description == "user":
                return ctx.value
        return "anonymous"

    # Create a test ADK agent
    test_agent = Agent(name="combined_test_agent", instruction="You are a test agent.")

    # Create agent with both extractors
    adk_agent = ADKAgent(
        adk_agent=test_agent,
        app_name_extractor=extract_app,
        user_id_extractor=extract_user,
        use_in_memory_services=True
    )

    # Test with full context
    test_input = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        state={},
        context=[
            Context(description="app", value="production_app"),
            Context(description="user", value="alice_smith")
        ],
        tools=[],
        forwarded_props={}
    )

    app_name = adk_agent._get_app_name(test_input)
    user_id = adk_agent._get_user_id(test_input)

    print(f"   App name: {app_name}")
    print(f"   User ID: {user_id}")

    if app_name == "production_app" and user_id == "alice_smith":
        print("✅ Combined extractors work correctly")
        return True
    else:
        print("❌ Combined extractors not working")
        return False

async def test_no_app_config():
    """Test that ADKAgent works without any app configuration."""
    print("\n🧪 Testing no app configuration (should use agent name)...")

    try:
        # This should work now - no app_name or app_name_extractor needed
        adk_agent = ADKAgent(
            user_id="test_user",
            use_in_memory_services=True
        )

        # Create test input
        test_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[UserMessage(id="1", role="user", content="Test")],
            state={},
            context=[],
            tools=[],
            forwarded_props={}
        )

        app_name = adk_agent._get_app_name(test_input)
        print(f"   App name: {app_name}")

        if app_name:  # Should get some valid app name
            print("✅ ADKAgent works without app configuration")
            return True
        else:
            print("❌ No app name returned")
            return False

    except Exception as e:
        print(f"❌ Failed to create ADKAgent without app config: {e}")
        return False

async def main():
    print("🚀 Testing App Name Extraction")
    print("========================================")

    # Set up a mock agent in registry to avoid errors
    agent = Agent(name="test_agent", instruction="Test agent")
    registry = AgentRegistry.get_instance()
    registry.clear()
    registry.set_default_agent(agent)

    tests = [
        ("test_static_app_name", test_static_app_name),
        ("test_custom_extractor", test_custom_extractor),
        ("test_default_extractor", test_default_extractor),
        ("test_conflicting_config", test_conflicting_config),
        ("test_combined_extractors", test_combined_extractors),
        ("test_no_app_config", test_no_app_config)
    ]

    results = []
    for test_name, test_func in tests:
        try:
            result = await test_func()
            results.append(result)
        except Exception as e:
            print(f"❌ Test {test_name} failed with exception: {e}")
            import traceback
            traceback.print_exc()
            results.append(False)

    print("\n========================================")
    print("📊 Test Results:")

    for i, (test_name, result) in enumerate(zip([name for name, _ in tests], results), 1):
        status = "✅ PASS" if result else "❌ FAIL"
        print(f"  {i}. {test_name}: {status}")

    passed = sum(results)
    total = len(results)

    if passed == total:
        print(f"\n🎉 All {total} tests passed!")
        print("💡 App name extraction functionality is working correctly")
    else:
        print(f"\n⚠️ {passed}/{total} tests passed")

if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_basic.py
================================================
#!/usr/bin/env python
"""Basic test to verify ADK setup works."""

import pytest
from google.adk.agents import Agent
from google.adk import Runner
from ag_ui_adk import ADKAgent


def test_google_adk_imports():
    """Test that Google ADK imports work correctly."""
    # If we got here, imports were successful
    assert Agent is not None
    assert Runner is not None


def test_adk_middleware_imports():
    """Test that ADK middleware imports work correctly."""
    # If we got here, imports were successful
    assert ADKAgent is not None


def test_agent_creation():
    """Test that we can create ADK agents."""
    agent = Agent(
        name="test_agent",
        instruction="You are a test agent."
    )
    assert agent.name == "test_agent"
    assert "test agent" in agent.instruction.lower()


def test_adk_agent_creation():
    """Test ADKAgent creation with direct agent embedding."""
    # Create test agent
    agent = Agent(
        name="test_agent",
        instruction="You are a test agent."
    )

    # Create ADKAgent with the test agent
    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True
    )
    assert adk_agent._adk_agent.name == "test_agent"


def test_adk_middleware_creation():
    """Test that ADK middleware can be created."""
    # Create test agent first
    agent = Agent(name="middleware_test_agent", instruction="Test agent.")

    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="test_app",
        user_id="test",
        use_in_memory_services=True,
    )
    assert adk_agent is not None
    assert adk_agent._static_app_name == "test_app"
    assert adk_agent._static_user_id == "test"


def test_full_integration():
    """Test full integration of components."""
    # Create agent
    agent = Agent(
        name="integration_test_agent",
        instruction="You are a test agent for integration testing."
    )

    # Create middleware with direct agent embedding
    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="integration_test_app",
        user_id="integration_test_user",
        use_in_memory_services=True,
    )

    # Verify components work together
    assert adk_agent._adk_agent.name == "integration_test_agent"
    assert adk_agent._static_app_name == "integration_test_app"


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_chunk_event.py
================================================
#!/usr/bin/env python
"""Test TextMessageContentEvent creation."""

from pathlib import Path

from ag_ui.core import TextMessageContentEvent, EventType

def test_content_event():
    """Test that TextMessageContentEvent can be created with correct parameters."""
    print("🧪 Testing TextMessageContentEvent creation...")
    
    try:
        # Test the event creation with the parameters we're using
        event = TextMessageContentEvent(
            type=EventType.TEXT_MESSAGE_CONTENT,
            message_id="test_msg_123",
            delta="Hello, this is a test message!"
        )
        
        print(f"✅ Event created successfully!")
        print(f"   Type: {event.type}")
        print(f"   Message ID: {event.message_id}")
        # Note: TextMessageContentEvent doesn't have a role field
        print(f"   Delta: {event.delta}")
        
        # Verify serialization works
        event_dict = event.model_dump()
        print(f"✅ Event serializes correctly: {len(event_dict)} fields")
        
        return True
        
    except Exception as e:
        print(f"❌ Failed to create TextMessageContentEvent: {e}")
        return False

def test_wrong_parameters():
    """Test that wrong parameters are rejected."""
    print("\n🧪 Testing parameter validation...")
    
    try:
        # This should fail - content is not a valid parameter
        event = TextMessageContentEvent(
            type=EventType.TEXT_MESSAGE_CONTENT,
            message_id="test_msg_123",
            content="This should fail!"  # Wrong parameter name
        )
        print("❌ Event creation should have failed but didn't!")
        return False
        
    except Exception as e:
        print(f"✅ Correctly rejected invalid parameter 'content': {type(e).__name__}")
        return True

if __name__ == "__main__":
    print("🚀 Testing TextMessageContentEvent Parameters")
    print("============================================")
    
    test1_passed = test_content_event()
    test2_passed = test_wrong_parameters()
    
    if test1_passed and test2_passed:
        print("\n🎉 All TextMessageContentEvent tests passed!")
        print("💡 Using correct 'delta' parameter instead of 'content'")
    else:
        print("\n⚠️ Some tests failed")


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_client_proxy_tool.py
================================================
#!/usr/bin/env python
"""Test ClientProxyTool class functionality."""

import pytest
import asyncio
import json
import uuid
from unittest.mock import AsyncMock, MagicMock, patch

from ag_ui.core import Tool as AGUITool, EventType
from ag_ui.core import ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent

from ag_ui_adk.client_proxy_tool import ClientProxyTool


class TestClientProxyTool:
    """Test cases for ClientProxyTool class."""

    @pytest.fixture
    def sample_tool_definition(self):
        """Create a sample AG-UI tool definition."""
        return AGUITool(
            name="test_calculator",
            description="Performs basic arithmetic operations",
            parameters={
                "type": "object",
                "properties": {
                    "operation": {
                        "type": "string",
                        "enum": ["add", "subtract", "multiply", "divide"],
                        "description": "The arithmetic operation to perform"
                    },
                    "a": {
                        "type": "number",
                        "description": "First number"
                    },
                    "b": {
                        "type": "number",
                        "description": "Second number"
                    }
                },
                "required": ["operation", "a", "b"]
            }
        )

    @pytest.fixture
    def mock_event_queue(self):
        """Create a mock event queue."""
        return AsyncMock()


    @pytest.fixture
    def proxy_tool(self, sample_tool_definition, mock_event_queue):
        """Create a ClientProxyTool instance."""
        return ClientProxyTool(
            ag_ui_tool=sample_tool_definition,
            event_queue=mock_event_queue
        )

    def test_initialization(self, proxy_tool, sample_tool_definition, mock_event_queue):
        """Test ClientProxyTool initialization."""
        assert proxy_tool.name == "test_calculator"
        assert proxy_tool.description == "Performs basic arithmetic operations"
        assert proxy_tool.ag_ui_tool == sample_tool_definition
        assert proxy_tool.event_queue == mock_event_queue

    def test_get_declaration(self, proxy_tool):
        """Test _get_declaration method."""
        declaration = proxy_tool._get_declaration()

        assert declaration is not None
        assert declaration.name == "test_calculator"
        assert declaration.description == "Performs basic arithmetic operations"
        assert declaration.parameters is not None

        # Check that parameters schema was converted properly
        params = declaration.parameters
        assert hasattr(params, 'type')

    def test_get_declaration_with_invalid_parameters(self, mock_event_queue):
        """Test _get_declaration with invalid parameters."""
        invalid_tool = AGUITool(
            name="invalid_tool",
            description="Tool with invalid params",
            parameters="invalid_schema"  # Should be dict
        )

        proxy_tool = ClientProxyTool(
            ag_ui_tool=invalid_tool,
            event_queue=mock_event_queue
        )

        declaration = proxy_tool._get_declaration()

        # Should default to empty object schema
        assert declaration is not None
        assert declaration.parameters is not None

    @pytest.mark.asyncio
    async def test_run_async_success(self, proxy_tool, mock_event_queue):
        """Test successful tool execution with long-running behavior."""
        args = {"operation": "add", "a": 5, "b": 3}
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        # Mock UUID generation for predictable tool_call_id
        with patch('uuid.uuid4') as mock_uuid:
            mock_uuid.return_value = MagicMock()
            mock_uuid.return_value.hex = "abc123456789abcdef012345"  # Valid hex string

            # Execute the tool - should return None immediately (long-running)
            result = await proxy_tool.run_async(args=args, tool_context=mock_context)

            # All client tools are long-running and return None
            assert result is None

            # Verify events were emitted in correct order
            assert mock_event_queue.put.call_count == 3

            # Check TOOL_CALL_START event
            start_event = mock_event_queue.put.call_args_list[0][0][0]
            assert isinstance(start_event, ToolCallStartEvent)
            assert start_event.tool_call_id == "test_function_call_id"  # Uses ADK function call ID
            assert start_event.tool_call_name == "test_calculator"

            # Check TOOL_CALL_ARGS event
            args_event = mock_event_queue.put.call_args_list[1][0][0]
            assert isinstance(args_event, ToolCallArgsEvent)
            assert args_event.tool_call_id == "test_function_call_id"  # Uses ADK function call ID
            assert json.loads(args_event.delta) == args

            # Check TOOL_CALL_END event
            end_event = mock_event_queue.put.call_args_list[2][0][0]
            assert isinstance(end_event, ToolCallEndEvent)
            assert end_event.tool_call_id == "test_function_call_id"  # Uses ADK function call ID


    @pytest.mark.asyncio
    async def test_run_async_event_queue_error(self, proxy_tool):
        """Test handling of event queue errors."""
        args = {"operation": "add", "a": 5, "b": 3}
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        # Mock event queue to raise error
        error_queue = AsyncMock()
        error_queue.put.side_effect = RuntimeError("Queue error")

        proxy_tool.event_queue = error_queue

        with pytest.raises(RuntimeError) as exc_info:
            await proxy_tool.run_async(args=args, tool_context=mock_context)

        assert "Queue error" in str(exc_info.value)


    def test_string_representation(self, proxy_tool):
        """Test __repr__ method."""
        repr_str = repr(proxy_tool)

        assert "ClientProxyTool" in repr_str
        assert "test_calculator" in repr_str
        # The repr shows the tool name, not the description
        assert "name='test_calculator'" in repr_str
        assert "ag_ui_tool='test_calculator'" in repr_str

    @pytest.mark.asyncio
    async def test_multiple_concurrent_executions(self, proxy_tool, mock_event_queue):
        """Test multiple concurrent tool executions with long-running behavior."""
        args1 = {"operation": "add", "a": 1, "b": 2}
        args2 = {"operation": "subtract", "a": 10, "b": 5}
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        # Start two concurrent executions - both should return None immediately
        task1 = asyncio.create_task(
            proxy_tool.run_async(args=args1, tool_context=mock_context)
        )
        task2 = asyncio.create_task(
            proxy_tool.run_async(args=args2, tool_context=mock_context)
        )

        # Both should complete successfully with None (long-running)
        result1 = await task1
        result2 = await task2

        assert result1 is None
        assert result2 is None

        # Should have emitted events for both executions
        # Each execution emits 3 events, so 6 total
        assert mock_event_queue.put.call_count == 6

    @pytest.mark.asyncio
    async def test_json_serialization_in_args(self, proxy_tool, mock_event_queue):
        """Test that complex arguments are properly JSON serialized."""
        complex_args = {
            "operation": "custom",
            "config": {
                "precision": 2,
                "rounding": "up",
                "metadata": ["tag1", "tag2"]
            },
            "values": [1.5, 2.7, 3.9]
        }
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        with patch('uuid.uuid4') as mock_uuid:
            mock_uuid.return_value = MagicMock()
            mock_uuid.return_value.__str__ = MagicMock(return_value="complex-test")

            # Execute the tool - should return None immediately
            result = await proxy_tool.run_async(args=complex_args, tool_context=mock_context)

            # Should return None (long-running behavior)
            assert result is None

            # Check that args were properly serialized in the event
            args_event = mock_event_queue.put.call_args_list[1][0][0]
            serialized_args = json.loads(args_event.delta)
            assert serialized_args == complex_args


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_client_proxy_toolset.py
================================================
#!/usr/bin/env python
"""Test ClientProxyToolset class functionality."""

import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch

from ag_ui.core import Tool as AGUITool
from ag_ui_adk.client_proxy_toolset import ClientProxyToolset
from ag_ui_adk.client_proxy_tool import ClientProxyTool
from google.adk.tools import FunctionTool, LongRunningFunctionTool


class TestClientProxyToolset:
    """Test cases for ClientProxyToolset class."""

    @pytest.fixture
    def sample_tools(self):
        """Create sample AG-UI tool definitions."""
        return [
            AGUITool(
                name="calculator",
                description="Basic arithmetic operations",
                parameters={
                    "type": "object",
                    "properties": {
                        "operation": {"type": "string"},
                        "a": {"type": "number"},
                        "b": {"type": "number"}
                    }
                }
            ),
            AGUITool(
                name="weather",
                description="Get weather information",
                parameters={
                    "type": "object",
                    "properties": {
                        "location": {"type": "string"},
                        "units": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                    }
                }
            ),
            AGUITool(
                name="simple_tool",
                description="A simple tool with no parameters",
                parameters={}
            )
        ]

    @pytest.fixture
    def mock_event_queue(self):
        """Create a mock event queue."""
        return AsyncMock()

    @pytest.fixture
    def toolset(self, sample_tools, mock_event_queue):
        """Create a ClientProxyToolset instance."""
        return ClientProxyToolset(
            ag_ui_tools=sample_tools,
            event_queue=mock_event_queue
        )

    def test_initialization(self, toolset, sample_tools, mock_event_queue):
        """Test ClientProxyToolset initialization."""
        assert toolset.ag_ui_tools == sample_tools
        assert toolset.event_queue == mock_event_queue

    @pytest.mark.asyncio
    async def test_get_tools_first_call(self, toolset, sample_tools):
        """Test get_tools creates proxy tools."""
        tools = await toolset.get_tools()

        # Should have created 3 proxy tools
        assert len(tools) == 3

        # All should be ClientProxyTool instances
        for tool in tools:
            assert isinstance(tool, ClientProxyTool)

        # Should have correct names
        tool_names = [tool.name for tool in tools]
        assert "calculator" in tool_names
        assert "weather" in tool_names
        assert "simple_tool" in tool_names

    @pytest.mark.asyncio
    async def test_get_tools_fresh_instances(self, toolset):
        """Test get_tools creates fresh tool instances on each call."""
        # First call
        tools1 = await toolset.get_tools()

        # Second call
        tools2 = await toolset.get_tools()

        # Should create fresh instances (no caching)
        assert tools1 is not tools2
        assert len(tools1) == 3
        assert len(tools2) == 3

        # But should have same tool names
        names1 = {tool.name for tool in tools1}
        names2 = {tool.name for tool in tools2}
        assert names1 == names2

    @pytest.mark.asyncio
    async def test_get_tools_with_readonly_context(self, toolset):
        """Test get_tools with readonly_context parameter."""
        mock_context = MagicMock()

        tools = await toolset.get_tools(readonly_context=mock_context)

        # Should work (parameter is currently unused but part of interface)
        assert len(tools) == 3

    @pytest.mark.asyncio
    async def test_get_tools_empty_list(self, mock_event_queue):
        """Test get_tools with empty tool list."""
        empty_toolset = ClientProxyToolset(
            ag_ui_tools=[],
            event_queue=mock_event_queue
        )

        tools = await empty_toolset.get_tools()

        assert len(tools) == 0
        assert tools == []

    @pytest.mark.asyncio
    async def test_get_tools_with_invalid_tool(self, mock_event_queue):
        """Test get_tools handles invalid tool definitions gracefully."""
        # Create a tool that might cause issues
        problematic_tool = AGUITool(
            name="problematic",
            description="Tool that might fail",
            parameters={"invalid": "schema"}
        )

        # Mock ClientProxyTool creation to raise exception
        with patch('ag_ui_adk.client_proxy_toolset.ClientProxyTool') as mock_tool_class:
            mock_tool_class.side_effect = [
                Exception("Failed to create tool"),  # First tool fails
                MagicMock(),  # Second tool succeeds
            ]

            toolset = ClientProxyToolset(
                ag_ui_tools=[problematic_tool, AGUITool(name="good", description="Good tool", parameters={})],
                event_queue=mock_event_queue
            )

            tools = await toolset.get_tools()

            # Should continue with other tools despite one failing
            assert len(tools) == 1  # Only the successful tool

    @pytest.mark.asyncio
    async def test_close_no_pending_futures(self, toolset):
        """Test close method completes successfully."""
        await toolset.close()

        # Close should complete without error
        # No cached tools to clean up in new architecture

    @pytest.mark.asyncio
    async def test_close_with_pending_futures(self, toolset):
        """Test close method completes successfully."""
        await toolset.close()

        # Close should complete without error
        # No tool futures to clean up in new architecture

    @pytest.mark.asyncio
    async def test_close_idempotent(self, toolset):
        """Test that close can be called multiple times safely."""
        await toolset.close()
        await toolset.close()  # Should not raise
        await toolset.close()  # Should not raise

        # All calls should complete without error

    def test_string_representation(self, toolset):
        """Test __repr__ method."""
        repr_str = repr(toolset)

        assert "ClientProxyToolset" in repr_str
        assert "calculator" in repr_str
        assert "weather" in repr_str
        assert "simple_tool" in repr_str

    def test_string_representation_empty(self, mock_event_queue):
        """Test __repr__ method with empty toolset."""
        empty_toolset = ClientProxyToolset(
            ag_ui_tools=[],
            event_queue=mock_event_queue
        )

        repr_str = repr(empty_toolset)

        assert "ClientProxyToolset" in repr_str
        assert "tools=[]" in repr_str

    @pytest.mark.asyncio
    async def test_tool_properties_preserved(self, toolset, sample_tools):
        """Test that tool properties are correctly preserved in proxy tools."""
        tools = await toolset.get_tools()

        # Find calculator tool
        calc_tool = next(tool for tool in tools if tool.name == "calculator")

        assert calc_tool.name == "calculator"
        assert calc_tool.description == "Basic arithmetic operations"
        assert calc_tool.ag_ui_tool == sample_tools[0]  # Should reference original

    @pytest.mark.asyncio
    async def test_shared_state_between_tools(self, toolset, mock_event_queue):
        """Test that all proxy tools share the same event queue."""
        tools = await toolset.get_tools()

        # All tools should share the same references
        for tool in tools:
            assert tool.event_queue is mock_event_queue

    @pytest.mark.asyncio
    async def test_tool_timeout_configuration(self, sample_tools, mock_event_queue):
        """Test that tool timeout is properly configured."""
        # Tool timeout configuration was removed in all-long-running architecture
        toolset = ClientProxyToolset(
            ag_ui_tools=sample_tools,
            event_queue=mock_event_queue
        )

        tools = await toolset.get_tools()

        # All tools should be created successfully
        assert len(tools) == len(sample_tools)

    @pytest.mark.asyncio
    async def test_lifecycle_get_tools_then_close(self, toolset):
        """Test complete lifecycle: get tools, then close."""
        # Get tools (creates proxy tools)
        tools = await toolset.get_tools()
        assert len(tools) == 3

        # Close should complete without error
        await toolset.close()

        # Can still get tools after close (creates fresh instances)
        tools_after_close = await toolset.get_tools()
        assert len(tools_after_close) == 3

    @pytest.mark.asyncio
    async def test_multiple_toolsets_isolation(self, sample_tools):
        """Test that multiple toolsets don't interfere with each other."""
        queue1 = AsyncMock()
        queue2 = AsyncMock()

        toolset1 = ClientProxyToolset(sample_tools, queue1)
        toolset2 = ClientProxyToolset(sample_tools, queue2)

        tools1 = await toolset1.get_tools()
        tools2 = await toolset2.get_tools()

        # Should have different tool instances
        assert tools1 is not tools2
        assert len(tools1) == len(tools2) == 3

        # Tools should reference their respective queues
        for tool in tools1:
            assert tool.event_queue is queue1

        for tool in tools2:
            assert tool.event_queue is queue2


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_concurrency.py
================================================
#!/usr/bin/env python
"""Test concurrent session handling to ensure no event interference."""

import asyncio
from pathlib import Path

from ag_ui.core import RunAgentInput, UserMessage, EventType
from ag_ui_adk import ADKAgent, EventTranslator
from google.adk.agents import Agent
from unittest.mock import MagicMock, AsyncMock

async def simulate_concurrent_requests():
    """Test that concurrent requests don't interfere with each other's event tracking."""
    print("🧪 Testing concurrent request handling...")

    # Create a real ADK agent
    agent = Agent(
        name="concurrent_test_agent",
        instruction="Test agent for concurrency"
    )

    registry = AgentRegistry.get_instance()
    registry.clear()
    registry.set_default_agent(agent)

    # Create ADK middleware
    adk_agent = ADKAgent(
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True,
    )

    # Mock the get_or_create_runner method to return controlled mock runners
    def create_mock_runner(session_id):
        mock_runner = MagicMock()
        mock_events = [
            MagicMock(type=f"TEXT_MESSAGE_START_{session_id}"),
            MagicMock(type=f"TEXT_MESSAGE_CONTENT_{session_id}", content=f"Response from {session_id}"),
            MagicMock(type=f"TEXT_MESSAGE_END_{session_id}"),
        ]

        async def mock_run_async(*args, **kwargs):
            print(f"🔄 Mock runner for {session_id} starting...")
            for event in mock_events:
                await asyncio.sleep(0.1)  # Simulate some delay
                yield event
            print(f"✅ Mock runner for {session_id} completed")

        mock_runner.run_async = mock_run_async
        return mock_runner

    # Create separate mock runners for each session
    mock_runners = {}
    def get_mock_runner(agent_id, adk_agent_obj, user_id):
        key = f"{agent_id}:{user_id}"
        if key not in mock_runners:
            mock_runners[key] = create_mock_runner(f"session_{len(mock_runners)}")
        return mock_runners[key]

    adk_agent._get_or_create_runner = get_mock_runner

    # Create multiple concurrent requests
    async def run_session(session_id, delay=0):
        if delay:
            await asyncio.sleep(delay)

        test_input = RunAgentInput(
            thread_id=f"thread_{session_id}",
            run_id=f"run_{session_id}",
            messages=[
                UserMessage(
                    id=f"msg_{session_id}",
                    role="user",
                    content=f"Hello from session {session_id}"
                )
            ],
            state={},
            context=[],
            tools=[],
            forwarded_props={}
        )

        events = []
        session_name = f"Session-{session_id}"
        try:
            print(f"🚀 {session_name} starting...")
            async for event in adk_agent.run(test_input):
                events.append(event)
                print(f"📧 {session_name}: {event.type}")
        except Exception as e:
            print(f"❌ {session_name} error: {e}")

        print(f"✅ {session_name} completed with {len(events)} events")
        return session_id, events

    # Run 3 concurrent sessions with slight delays
    print("🚀 Starting 3 concurrent sessions...")

    tasks = [
        run_session("A", 0),
        run_session("B", 0.05),  # Start slightly later
        run_session("C", 0.1),   # Start even later
    ]

    results = await asyncio.gather(*tasks)

    # Analyze results
    print(f"\n📊 Concurrency Test Results:")
    all_passed = True

    for session_id, events in results:
        start_events = [e for e in events if e.type == EventType.RUN_STARTED]
        finish_events = [e for e in events if e.type == EventType.RUN_FINISHED]

        print(f"   Session {session_id}: {len(events)} events")
        print(f"     - RUN_STARTED: {len(start_events)}")
        print(f"     - RUN_FINISHED: {len(finish_events)}")

        if len(start_events) != 1 or len(finish_events) != 1:
            print(f"     ❌ Invalid event count for session {session_id}")
            all_passed = False
        else:
            print(f"     ✅ Session {session_id} event flow correct")

    if all_passed:
        print("\n🎉 All concurrent sessions completed correctly!")
        print("💡 No event interference detected - EventTranslator isolation working!")
        return True
    else:
        print("\n❌ Some sessions had incorrect event flows")
        return False

async def test_event_translator_isolation():
    """Test that EventTranslator instances don't share state."""
    print("\n🧪 Testing EventTranslator isolation...")


    # Create two separate translators
    translator1 = EventTranslator()
    translator2 = EventTranslator()

    # Verify they have separate state (using current EventTranslator attributes)
    assert translator1._active_tool_calls is not translator2._active_tool_calls
    # Both start with streaming_message_id=None, but are separate objects
    assert translator1._streaming_message_id is None and translator2._streaming_message_id is None

    # Add state to each
    translator1._active_tool_calls["test"] = "tool1"
    translator2._active_tool_calls["test"] = "tool2"
    translator1._streaming_message_id = "msg1"
    translator2._streaming_message_id = "msg2"

    # Verify isolation
    assert translator1._active_tool_calls["test"] == "tool1"
    assert translator2._active_tool_calls["test"] == "tool2"
    assert translator1._streaming_message_id == "msg1"
    assert translator2._streaming_message_id == "msg2"

    print("✅ EventTranslator instances properly isolated")
    return True

async def main():
    print("🚀 Testing ADK Middleware Concurrency")
    print("=====================================")

    test1_passed = await simulate_concurrent_requests()
    test2_passed = await test_event_translator_isolation()

    print(f"\n📊 Final Results:")
    print(f"   Concurrent requests: {'✅ PASS' if test1_passed else '❌ FAIL'}")
    print(f"   EventTranslator isolation: {'✅ PASS' if test2_passed else '❌ FAIL'}")

    if test1_passed and test2_passed:
        print("\n🎉 All concurrency tests passed!")
        print("💡 The EventTranslator concurrency issue is fixed!")
    else:
        print("\n⚠️ Some concurrency tests failed")

if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_concurrent_limits.py
================================================
#!/usr/bin/env python
"""Test concurrent execution limits in ADKAgent."""

import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch

from ag_ui.core import (
    RunAgentInput, BaseEvent, EventType, Tool as AGUITool,
    UserMessage, RunStartedEvent, RunFinishedEvent, RunErrorEvent
)

from ag_ui_adk import ADKAgent


class TestConcurrentLimits:
    """Test cases for concurrent execution limits."""


    @pytest.fixture
    def mock_adk_agent(self):
        """Create a mock ADK agent."""
        from google.adk.agents import LlmAgent
        return LlmAgent(
            name="test_agent",
            model="gemini-2.0-flash",
            instruction="Test agent for concurrent testing"
        )

    @pytest.fixture
    def adk_middleware(self, mock_adk_agent):
        """Create ADK middleware with low concurrent limits."""
        return ADKAgent(
            adk_agent=mock_adk_agent,
            user_id="test_user",
            execution_timeout_seconds=60,
            tool_timeout_seconds=30,
            max_concurrent_executions=2  # Low limit for testing
        )

    @pytest.fixture
    def sample_input(self):
        """Create sample run input."""
        return RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

    @pytest.mark.asyncio
    async def test_concurrent_execution_limit_enforcement(self, adk_middleware):
        """Test that concurrent execution limits are enforced."""
        # Use lighter mocking - just mock the ADK runner to avoid external dependencies
        async def mock_run_adk_in_background(*args, **_kwargs):
            # Simulate a long-running background task
            await asyncio.sleep(10)  # Long enough to test concurrency

        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=mock_run_adk_in_background):
            # Start first execution
            input1 = RunAgentInput(
                thread_id="thread_1", run_id="run_1",
                messages=[UserMessage(id="1", role="user", content="First")],
                tools=[], context=[], state={}, forwarded_props={}
            )

            # Start execution as a task (don't await - let it run in background)
            async def consume_events(execution_generator):
                events = []
                async for event in execution_generator:
                    events.append(event)
                    # Consume a few events to let execution get stored
                    if len(events) >= 3:
                        break
                return events

            task1 = asyncio.create_task(
                consume_events(adk_middleware._start_new_execution(input1))
            )

            # Wait for first execution to start and be stored
            await asyncio.sleep(0.1)

            # Start second execution
            input2 = RunAgentInput(
                thread_id="thread_2", run_id="run_2",
                messages=[UserMessage(id="2", role="user", content="Second")],
                tools=[], context=[], state={}, forwarded_props={}
            )

            task2 = asyncio.create_task(
                consume_events(adk_middleware._start_new_execution(input2))
            )

            # Wait for second execution to start
            await asyncio.sleep(0.1)

            # Should have 2 active executions now
            print(f"Active executions: {len(adk_middleware._active_executions)}")
            print(f"Execution keys: {list(adk_middleware._active_executions.keys())}")

            # Try third execution - should fail due to limit
            input3 = RunAgentInput(
                thread_id="thread_3", run_id="run_3",
                messages=[UserMessage(id="3", role="user", content="Third")],
                tools=[], context=[], state={}, forwarded_props={}
            )

            events = []
            async for event in adk_middleware._start_new_execution(input3):
                events.append(event)
                # Look for error events
                if any(isinstance(e, RunErrorEvent) for e in events):
                    break
                if len(events) >= 5:  # Safety limit
                    break

            # Should get an error about max concurrent executions
            error_events = [e for e in events if isinstance(e, RunErrorEvent)]
            if not error_events:
                print(f"No error events found. Events: {[type(e).__name__ for e in events]}")
                print(f"Active executions after third attempt: {len(adk_middleware._active_executions)}")

            assert len(error_events) >= 1, f"Expected error event, got events: {[type(e).__name__ for e in events]}"
            assert "Maximum concurrent executions" in error_events[0].message

            # Clean up
            task1.cancel()
            task2.cancel()
            try:
                await task1
            except asyncio.CancelledError:
                pass
            try:
                await task2
            except asyncio.CancelledError:
                pass

    @pytest.mark.asyncio
    async def test_stale_execution_cleanup_frees_slots(self, adk_middleware):
        """Test that cleaning up stale executions frees slots for new ones."""
        # Create stale executions manually
        mock_execution1 = MagicMock()
        mock_execution1.thread_id = "stale_thread_1"
        mock_execution1.is_stale.return_value = True
        mock_execution1.cancel = AsyncMock()

        mock_execution2 = MagicMock()
        mock_execution2.thread_id = "stale_thread_2"
        mock_execution2.is_stale.return_value = True
        mock_execution2.cancel = AsyncMock()

        # Add to active executions
        adk_middleware._active_executions["stale_thread_1"] = mock_execution1
        adk_middleware._active_executions["stale_thread_2"] = mock_execution2

        # Should be at limit
        assert len(adk_middleware._active_executions) == 2

        # Cleanup should remove stale executions
        await adk_middleware._cleanup_stale_executions()

        # Should be empty now
        assert len(adk_middleware._active_executions) == 0

        # Should have called cancel on both
        mock_execution1.cancel.assert_called_once()
        mock_execution2.cancel.assert_called_once()

    @pytest.mark.asyncio
    async def test_mixed_stale_and_active_executions(self, adk_middleware):
        """Test cleanup with mix of stale and active executions."""
        # Create one stale and one active execution
        stale_execution = MagicMock()
        stale_execution.thread_id = "stale_thread"
        stale_execution.is_stale.return_value = True
        stale_execution.cancel = AsyncMock()

        active_execution = MagicMock()
        active_execution.thread_id = "active_thread"
        active_execution.is_stale.return_value = False
        active_execution.cancel = AsyncMock()

        adk_middleware._active_executions["stale_thread"] = stale_execution
        adk_middleware._active_executions["active_thread"] = active_execution

        await adk_middleware._cleanup_stale_executions()

        # Only stale should be removed
        assert "stale_thread" not in adk_middleware._active_executions
        assert "active_thread" in adk_middleware._active_executions

        # Only stale should be cancelled
        stale_execution.cancel.assert_called_once()
        active_execution.cancel.assert_not_called()

    @pytest.mark.asyncio
    async def test_zero_concurrent_limit(self):
        """Test behavior with zero concurrent execution limit."""
        # Create ADK middleware with zero limit
        from google.adk.agents import LlmAgent
        mock_agent = LlmAgent(name="test", model="gemini-2.0-flash", instruction="test")

        zero_limit_middleware = ADKAgent(
            adk_agent=mock_agent,
            user_id="test_user",
            max_concurrent_executions=0
        )

        input_data = RunAgentInput(
            thread_id="thread_1", run_id="run_1",
            messages=[UserMessage(id="1", role="user", content="Test")],
            tools=[], context=[], state={}, forwarded_props={}
        )

        # Should immediately fail
        events = []
        async for event in zero_limit_middleware._start_new_execution(input_data):
            events.append(event)
            if len(events) >= 2:
                break

        error_events = [e for e in events if isinstance(e, RunErrorEvent)]
        assert len(error_events) >= 1
        assert "Maximum concurrent executions (0) reached" in error_events[0].message

    @pytest.mark.asyncio
    async def test_execution_completion_frees_slot(self, adk_middleware):
        """Test that completing an execution frees up a slot."""
        # Use lighter mocking - just mock the ADK background execution
        async def mock_run_adk_in_background(*args, **_kwargs):
            # Put completion events in queue then signal completion
            execution = args[0]
            await execution.event_queue.put(RunStartedEvent(type=EventType.RUN_STARTED, thread_id="thread_1", run_id="run_1"))
            await execution.event_queue.put(RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id="thread_1", run_id="run_1"))
            await execution.event_queue.put(None)  # Completion signal

        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=mock_run_adk_in_background):
            input_data = RunAgentInput(
                thread_id="thread_1", run_id="run_1",
                messages=[UserMessage(id="1", role="user", content="Test")],
                tools=[], context=[], state={}, forwarded_props={}
            )

            # Execute and collect events
            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Should have completed successfully
            assert len(events) == 2
            assert isinstance(events[0], RunStartedEvent)
            assert isinstance(events[1], RunFinishedEvent)

            # Execution should be cleaned up (not in active executions)
            assert len(adk_middleware._active_executions) == 0

    @pytest.mark.asyncio
    async def test_execution_with_pending_tools_not_cleaned(self, adk_middleware):
        """Test that executions with pending tools are not cleaned up."""
        mock_execution = MagicMock()
        mock_execution.thread_id = "thread_1"
        mock_execution.is_complete = True
        mock_execution.has_pending_tools.return_value = True  # Still has pending tools

        adk_middleware._active_executions["thread_1"] = mock_execution

        # Simulate end of _start_new_execution method
        # The finally block should not clean up executions with pending tools
        input_data = RunAgentInput(
            thread_id="thread_1", run_id="run_1",
            messages=[UserMessage(id="1", role="user", content="Test")],
            tools=[], context=[], state={}, forwarded_props={}
        )

        # Manually trigger the cleanup logic from the finally block
        async with adk_middleware._execution_lock:
            if input_data.thread_id in adk_middleware._active_executions:
                execution = adk_middleware._active_executions[input_data.thread_id]
                if execution.is_complete and not execution.has_pending_tools():
                    del adk_middleware._active_executions[input_data.thread_id]

        # Should still be in active executions
        assert "thread_1" in adk_middleware._active_executions

    @pytest.mark.asyncio
    async def test_high_concurrent_limit(self):
        """Test behavior with very high concurrent limit."""
        from google.adk.agents import LlmAgent
        mock_agent = LlmAgent(name="test", model="gemini-2.0-flash", instruction="test")

        high_limit_middleware = ADKAgent(
            adk_agent=mock_agent,
            user_id="test_user",
            max_concurrent_executions=1000  # Very high limit
        )

        # Should be able to start many executions (limited by other factors)
        assert high_limit_middleware._max_concurrent == 1000

        # Add some mock executions
        for i in range(10):
            mock_execution = MagicMock()
            mock_execution.is_stale.return_value = False
            high_limit_middleware._active_executions[f"thread_{i}"] = mock_execution

        # Should not hit the limit
        assert len(high_limit_middleware._active_executions) == 10
        assert len(high_limit_middleware._active_executions) < high_limit_middleware._max_concurrent

    @pytest.mark.asyncio
    async def test_cleanup_during_limit_check(self, adk_middleware):
        """Test that cleanup is triggered when limit is reached."""
        # Create real ExecutionState objects that will actually be stale
        import time
        from ag_ui_adk.execution_state import ExecutionState

        # Create stale executions
        for i in range(2):  # At the limit (max_concurrent_executions=2)
            mock_task = MagicMock()
            mock_queue = AsyncMock()
            execution = ExecutionState(
                task=mock_task,
                thread_id=f"stale_{i}",
                event_queue=mock_queue
            )
            # Make them stale by setting an old start time
            execution.start_time = time.time() - 1000  # 1000 seconds ago, definitely stale
            execution.cancel = AsyncMock()  # Mock the cancel method
            adk_middleware._active_executions[f"stale_{i}"] = execution

        # Use lighter mocking - just mock the ADK background execution
        async def mock_run_adk_in_background(*args, **_kwargs):
            # Put a simple event to show it started
            execution = args[0]
            await execution.event_queue.put(RunStartedEvent(type=EventType.RUN_STARTED, thread_id="new_thread", run_id="run_1"))
            await execution.event_queue.put(None)  # Completion signal

        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=mock_run_adk_in_background):
            input_data = RunAgentInput(
                thread_id="new_thread", run_id="run_1",
                messages=[UserMessage(id="1", role="user", content="Test")],
                tools=[], context=[], state={}, forwarded_props={}
            )

            # This should trigger cleanup and then succeed
            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Should succeed (cleanup freed up space)
            assert len(events) >= 1
            assert isinstance(events[0], RunStartedEvent)

            # Old stale executions should be gone
            assert "stale_0" not in adk_middleware._active_executions
            assert "stale_1" not in adk_middleware._active_executions


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_credential_service_defaults.py
================================================
#!/usr/bin/env python
"""Test that InMemoryCredentialService defaults work correctly."""

def test_credential_service_import():
    """Test that InMemoryCredentialService can be imported."""
    print("🧪 Testing InMemoryCredentialService import...")
    
    try:
        from google.adk.auth.credential_service.in_memory_credential_service import InMemoryCredentialService
        print("✅ InMemoryCredentialService imported successfully")
        
        # Try to create an instance
        credential_service = InMemoryCredentialService()
        print(f"✅ InMemoryCredentialService instance created: {type(credential_service).__name__}")
        return True
        
    except ImportError as e:
        print(f"❌ Failed to import InMemoryCredentialService: {e}")
        return False
    except Exception as e:
        print(f"❌ Failed to create InMemoryCredentialService: {e}")
        return False

def test_adk_agent_defaults():
    """Test that ADKAgent defaults to InMemoryCredentialService when use_in_memory_services=True."""
    print("\n🧪 Testing ADKAgent credential service defaults...")
    
    try:
        from adk_agent import ADKAgent
        
        # Test with use_in_memory_services=True (should default credential service)
        print("📝 Creating ADKAgent with use_in_memory_services=True...")
        agent = ADKAgent(
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True
        )
        
        # Check that credential service was defaulted
        if agent._credential_service is not None:
            service_type = type(agent._credential_service).__name__
            print(f"✅ Credential service defaulted to: {service_type}")
            
            if "InMemoryCredentialService" in service_type:
                print("✅ Correctly defaulted to InMemoryCredentialService")
                return True
            else:
                print(f"⚠️ Defaulted to unexpected service type: {service_type}")
                return False
        else:
            print("❌ Credential service is None (should have defaulted)")
            return False
            
    except Exception as e:
        print(f"❌ Failed to create ADKAgent: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_adk_agent_explicit_none():
    """Test that ADKAgent respects explicit None for credential service."""
    print("\n🧪 Testing ADKAgent with explicit credential_service=None...")
    
    try:
        from adk_agent import ADKAgent
        
        # Test with explicit credential_service=None (should not default)
        agent = ADKAgent(
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True,
            credential_service=None
        )
        
        # Check that credential service still defaults even with explicit None
        service_type = type(agent._credential_service).__name__
        print(f"📝 With explicit None, got: {service_type}")
        
        if "InMemoryCredentialService" in service_type:
            print("✅ Correctly defaulted even with explicit None")
            return True
        else:
            print(f"❌ Expected InMemoryCredentialService even with explicit None, got: {service_type}")
            return False
            
    except Exception as e:
        print(f"❌ Failed with explicit None: {e}")
        return False

def test_all_service_defaults():
    """Test that all services get proper defaults."""
    print("\n🧪 Testing all service defaults...")
    
    try:
        from adk_agent import ADKAgent
        
        agent = ADKAgent(
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True
        )
        
        services = {
            'session_manager': agent._session_manager,  # Session service is now encapsulated
            'artifact_service': agent._artifact_service,
            'memory_service': agent._memory_service,
            'credential_service': agent._credential_service
        }
        
        print("📊 Service defaults:")
        all_defaulted = True
        
        for service_name, service_instance in services.items():
            if service_instance is not None:
                service_type = type(service_instance).__name__
                print(f"  {service_name}: {service_type}")
                
                if service_name == "session_manager":
                    # Session manager is singleton, just check it exists
                    if service_type == "SessionLifecycleManager":
                        print(f"    ✅ SessionLifecycleManager correctly instantiated")
                    else:
                        print(f"    ⚠️ Expected SessionLifecycleManager but got: {service_type}")
                        all_defaulted = False
                elif "InMemory" not in service_type:
                    print(f"    ⚠️ Expected InMemory service but got: {service_type}")
                    all_defaulted = False
            else:
                print(f"  {service_name}: None ❌")
                all_defaulted = False
        
        if all_defaulted:
            print("✅ All services correctly defaulted")
        else:
            print("❌ Some services did not default correctly")
            
        return all_defaulted
        
    except Exception as e:
        print(f"❌ Failed to test service defaults: {e}")
        return False

def main():
    """Run all credential service tests."""
    print("🚀 Testing InMemoryCredentialService Defaults")
    print("=" * 50)
    
    tests = [
        test_credential_service_import,
        test_adk_agent_defaults,
        test_adk_agent_explicit_none,
        test_all_service_defaults
    ]
    
    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"❌ Test {test.__name__} failed with exception: {e}")
            results.append(False)
    
    print("\n" + "=" * 50)
    print("📊 Test Results:")
    
    for i, (test, result) in enumerate(zip(tests, results), 1):
        status = "✅ PASS" if result else "❌ FAIL"
        print(f"  {i}. {test.__name__}: {status}")
    
    passed = sum(results)
    total = len(results)
    
    if passed == total:
        print(f"\n🎉 All {total} tests passed!")
        print("💡 InMemoryCredentialService defaults are working correctly")
    else:
        print(f"\n⚠️ {passed}/{total} tests passed")
        print("🔧 Some credential service defaults may need fixing")
    
    return passed == total

if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_endpoint.py
================================================
#!/usr/bin/env python
"""Tests for FastAPI endpoint functionality."""

import pytest
import asyncio
from unittest.mock import MagicMock, patch, AsyncMock
from fastapi import FastAPI
from fastapi.testclient import TestClient
from fastapi.responses import StreamingResponse

from ag_ui.core import RunAgentInput, UserMessage, RunStartedEvent, RunErrorEvent, EventType
from ag_ui.encoder import EventEncoder
from ag_ui_adk.endpoint import add_adk_fastapi_endpoint, create_adk_app
from ag_ui_adk.adk_agent import ADKAgent


class TestAddADKFastAPIEndpoint:
    """Tests for add_adk_fastapi_endpoint function."""

    @pytest.fixture
    def mock_agent(self):
        """Create a mock ADKAgent."""
        agent = MagicMock(spec=ADKAgent)
        return agent

    @pytest.fixture
    def app(self):
        """Create a FastAPI app."""
        return FastAPI()

    @pytest.fixture
    def sample_input(self):
        """Create sample RunAgentInput."""
        return RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[
                UserMessage(id="1", role="user", content="Hello")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

    def test_add_endpoint_default_path(self, app, mock_agent):
        """Test adding endpoint with default path."""
        add_adk_fastapi_endpoint(app, mock_agent)

        # Check that endpoint was added
        routes = [route.path for route in app.routes]
        assert "/" in routes

    def test_add_endpoint_custom_path(self, app, mock_agent):
        """Test adding endpoint with custom path."""
        add_adk_fastapi_endpoint(app, mock_agent, path="/custom")

        # Check that endpoint was added
        routes = [route.path for route in app.routes]
        assert "/custom" in routes

    def test_endpoint_method_is_post(self, app, mock_agent):
        """Test that endpoint accepts POST requests."""
        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        # Find the route
        route = next(route for route in app.routes if route.path == "/test")
        assert "POST" in route.methods

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_endpoint_creates_event_encoder(self, mock_encoder_class, app, mock_agent, sample_input):
        """Test that endpoint creates EventEncoder with correct accept header."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "encoded_event"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )
        mock_agent.run = AsyncMock(return_value=AsyncMock(__aiter__=AsyncMock(return_value=iter([mock_event]))))

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post(
            "/test",
            json=sample_input.model_dump(),
            headers={"accept": "text/event-stream"}
        )

        # EventEncoder should be created with accept header
        mock_encoder_class.assert_called_once_with(accept="text/event-stream")
        assert response.status_code == 200

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_endpoint_agent_id_extraction(self, mock_encoder_class, app, mock_agent, sample_input):
        """Test that agent_id is extracted from path."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "encoded_event"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )
        mock_agent.run = AsyncMock(return_value=AsyncMock(__aiter__=AsyncMock(return_value=iter([mock_event]))))

        add_adk_fastapi_endpoint(app, mock_agent, path="/agent123")

        client = TestClient(app)
        response = client.post("/agent123", json=sample_input.model_dump())

        # Agent should be called with just the input data
        mock_agent.run.assert_called_once_with(sample_input)
        assert response.status_code == 200

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_endpoint_root_path_agent_id(self, mock_encoder_class, app, mock_agent, sample_input):
        """Test agent_id extraction for root path."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "encoded_event"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )
        mock_agent.run = AsyncMock(return_value=AsyncMock(__aiter__=AsyncMock(return_value=iter([mock_event]))))

        add_adk_fastapi_endpoint(app, mock_agent, path="/")

        client = TestClient(app)
        response = client.post("/", json=sample_input.model_dump())

        # Agent should be called with just the input data
        mock_agent.run.assert_called_once_with(sample_input)
        assert response.status_code == 200

    @patch('ag_ui_adk.endpoint.EventEncoder')
    @patch('ag_ui_adk.endpoint.logger')
    def test_endpoint_successful_event_streaming(self, mock_logger, mock_encoder_class, app, mock_agent, sample_input):
        """Test successful event streaming."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: encoded_event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return multiple events
        mock_event1 = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )
        mock_event2 = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )

        async def mock_agent_run(input_data):
            yield mock_event1
            yield mock_event2

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        assert response.status_code == 200
        assert response.headers["content-type"].startswith("text/event-stream")

        # Check that events were encoded and logged
        assert mock_encoder.encode.call_count == 2
        assert mock_logger.debug.call_count == 2

    @patch('ag_ui_adk.endpoint.EventEncoder')
    @patch('ag_ui_adk.endpoint.logger')
    def test_endpoint_encoding_error_handling(self, mock_logger, mock_encoder_class, app, mock_agent, sample_input):
        """Test handling of encoding errors."""
        mock_encoder = MagicMock()
        mock_encoder.encode.side_effect = [
            ValueError("Encoding failed"),
            "data: error_event\n\n"  # Error event encoding succeeds
        ]
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )

        async def mock_agent_run(input_data):
            yield mock_event

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        assert response.status_code == 200

        # Should log encoding error
        mock_logger.error.assert_called_once()
        assert "Event encoding error" in str(mock_logger.error.call_args)

        # Should create and encode RunErrorEvent
        assert mock_encoder.encode.call_count == 2

        # Check that second call was for error event
        error_event_call = mock_encoder.encode.call_args_list[1]
        error_event = error_event_call[0][0]
        assert isinstance(error_event, RunErrorEvent)
        assert error_event.code == "ENCODING_ERROR"

    @patch('ag_ui_adk.endpoint.EventEncoder')
    @patch('ag_ui_adk.endpoint.logger')
    def test_endpoint_encoding_error_double_failure(self, mock_logger, mock_encoder_class, app, mock_agent, sample_input):
        """Test handling when both event and error event encoding fail."""
        mock_encoder = MagicMock()
        mock_encoder.encode.side_effect = ValueError("Always fails")
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )

        async def mock_agent_run(input_data):
            yield mock_event

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        assert response.status_code == 200

        # Should log both encoding errors
        assert mock_logger.error.call_count == 2
        assert "Event encoding error" in str(mock_logger.error.call_args_list[0])
        assert "Failed to encode error event" in str(mock_logger.error.call_args_list[1])

        # Should yield basic SSE error
        response_text = response.text
        assert 'event: error\ndata: {"error": "Event encoding failed"}\n\n' in response_text

    @patch('ag_ui_adk.endpoint.EventEncoder')
    @patch('ag_ui_adk.endpoint.logger')
    def test_endpoint_agent_error_handling(self, mock_logger, mock_encoder_class, app, mock_agent, sample_input):
        """Test handling of agent execution errors."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: error_event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to raise an error
        async def mock_agent_run(input_data):
            raise RuntimeError("Agent failed")

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        assert response.status_code == 200

        # Should log agent error
        mock_logger.error.assert_called_once()
        assert "ADKAgent error" in str(mock_logger.error.call_args)

        # Should create and encode RunErrorEvent
        error_event_call = mock_encoder.encode.call_args
        error_event = error_event_call[0][0]
        assert isinstance(error_event, RunErrorEvent)
        assert error_event.code == "AGENT_ERROR"
        assert "Agent execution failed" in error_event.message

    @patch('ag_ui_adk.endpoint.EventEncoder')
    @patch('ag_ui_adk.endpoint.logger')
    def test_endpoint_agent_error_encoding_failure(self, mock_logger, mock_encoder_class, app, mock_agent, sample_input):
        """Test handling when agent error event encoding fails."""
        mock_encoder = MagicMock()
        mock_encoder.encode.side_effect = ValueError("Encoding failed")
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to raise an error
        async def mock_agent_run(input_data):
            raise RuntimeError("Agent failed")

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        assert response.status_code == 200

        # Should log both errors
        assert mock_logger.error.call_count == 2
        assert "ADKAgent error" in str(mock_logger.error.call_args_list[0])
        assert "Failed to encode agent error event" in str(mock_logger.error.call_args_list[1])

        # Should yield basic SSE error
        response_text = response.text
        assert 'event: error\ndata: {"error": "Agent execution failed"}\n\n' in response_text

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_endpoint_returns_streaming_response(self, mock_encoder_class, app, mock_agent, sample_input):
        """Test that endpoint returns StreamingResponse."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )

        async def mock_agent_run(input_data):
            yield mock_event

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        assert response.status_code == 200
        assert response.headers["content-type"].startswith("text/event-stream")

    def test_endpoint_input_validation(self, app, mock_agent):
        """Test that endpoint validates input as RunAgentInput."""
        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)

        # Send invalid JSON
        response = client.post("/test", json={"invalid": "data"})

        # Should return 422 for validation error
        assert response.status_code == 422

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_endpoint_no_accept_header(self, mock_encoder_class, app, mock_agent, sample_input):
        """Test endpoint behavior when no accept header is provided."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )

        async def mock_agent_run(input_data):
            yield mock_event

        mock_agent.run = mock_agent_run

        add_adk_fastapi_endpoint(app, mock_agent, path="/test")

        client = TestClient(app)
        response = client.post("/test", json=sample_input.model_dump())

        # EventEncoder should be created with default accept header from TestClient
        mock_encoder_class.assert_called_once_with(accept="*/*")
        assert response.status_code == 200


class TestCreateADKApp:
    """Tests for create_adk_app function."""

    @pytest.fixture
    def mock_agent(self):
        """Create a mock ADKAgent."""
        return MagicMock(spec=ADKAgent)

    def test_create_app_basic(self, mock_agent):
        """Test creating app with basic configuration."""
        app = create_adk_app(mock_agent)

        assert isinstance(app, FastAPI)
        assert app.title == "ADK Middleware for AG-UI Protocol"

        # Check that endpoint was added
        routes = [route.path for route in app.routes]
        assert "/" in routes

    def test_create_app_custom_path(self, mock_agent):
        """Test creating app with custom path."""
        app = create_adk_app(mock_agent, path="/custom")

        assert isinstance(app, FastAPI)

        # Check that endpoint was added with custom path
        routes = [route.path for route in app.routes]
        assert "/custom" in routes

    @patch('ag_ui_adk.endpoint.add_adk_fastapi_endpoint')
    def test_create_app_calls_add_endpoint(self, mock_add_endpoint, mock_agent):
        """Test that create_adk_app calls add_adk_fastapi_endpoint."""
        app = create_adk_app(mock_agent, path="/test")

        # Should call add_adk_fastapi_endpoint with correct parameters
        mock_add_endpoint.assert_called_once_with(app, mock_agent, "/test")

    def test_create_app_default_path(self, mock_agent):
        """Test creating app with default path."""
        app = create_adk_app(mock_agent)

        routes = [route.path for route in app.routes]
        assert "/" in routes

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_create_app_functional_test(self, mock_encoder_class, mock_agent):
        """Test that created app is functional."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return an event
        mock_event = RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id="test_thread",
            run_id="test_run"
        )

        async def mock_agent_run(input_data):
            yield mock_event

        mock_agent.run = mock_agent_run

        app = create_adk_app(mock_agent)

        client = TestClient(app)
        sample_input = RunAgentInput(
            thread_id="test_thread",
            run_id="test_run",
            messages=[UserMessage(id="1", role="user", content="Hello")],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        response = client.post("/", json=sample_input.model_dump())

        assert response.status_code == 200
        assert response.headers["content-type"].startswith("text/event-stream")


class TestEndpointIntegration:
    """Integration tests for endpoint functionality."""

    @pytest.fixture
    def mock_agent(self):
        """Create a mock ADKAgent."""
        return MagicMock(spec=ADKAgent)

    @pytest.fixture
    def sample_input(self):
        """Create sample RunAgentInput."""
        return RunAgentInput(
            thread_id="integration_thread",
            run_id="integration_run",
            messages=[
                UserMessage(id="1", role="user", content="Integration test message")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_full_endpoint_flow(self, mock_encoder_class, mock_agent, sample_input):
        """Test complete endpoint flow from request to response."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: test_event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return multiple events
        events = [
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id="integration_thread",
                run_id="integration_run"
            ),
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id="integration_thread",
                run_id="integration_run"
            )
        ]

        call_args = []

        async def mock_agent_run(input_data):
            call_args.append(input_data)
            for event in events:
                yield event

        mock_agent.run = mock_agent_run

        app = create_adk_app(mock_agent, path="/integration")

        client = TestClient(app)
        response = client.post(
            "/integration",
            json=sample_input.model_dump(),
            headers={"accept": "text/event-stream"}
        )

        # Verify response
        assert response.status_code == 200
        assert response.headers["content-type"].startswith("text/event-stream")

        # Verify agent was called correctly
        assert len(call_args) == 1
        assert call_args[0] == sample_input

        # Verify events were encoded
        assert mock_encoder.encode.call_count == len(events)

    def test_endpoint_with_different_http_methods(self, mock_agent):
        """Test that endpoint only accepts POST requests."""
        app = create_adk_app(mock_agent, path="/test")

        client = TestClient(app)

        # POST should work
        response = client.post("/test", json={})
        assert response.status_code in [200, 422]  # 422 for validation error

        # GET should not work
        response = client.get("/test")
        assert response.status_code == 405  # Method not allowed

        # PUT should not work
        response = client.put("/test", json={})
        assert response.status_code == 405

        # DELETE should not work
        response = client.delete("/test")
        assert response.status_code == 405

    @patch('ag_ui_adk.endpoint.EventEncoder')
    def test_endpoint_with_long_running_stream(self, mock_encoder_class, mock_agent, sample_input):
        """Test endpoint with long-running event stream."""
        mock_encoder = MagicMock()
        mock_encoder.encode.return_value = "data: event\n\n"
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Mock agent to return many events
        async def mock_agent_run(input_data):
            for i in range(10):
                yield RunStartedEvent(
                    type=EventType.RUN_STARTED,
                    thread_id=f"thread_{i}",
                    run_id=f"run_{i}"
                )

        mock_agent.run = mock_agent_run

        app = create_adk_app(mock_agent, path="/long_stream")

        client = TestClient(app)
        response = client.post("/long_stream", json=sample_input.model_dump())

        assert response.status_code == 200
        assert response.headers["content-type"].startswith("text/event-stream")

        # Should have encoded 10 events
        assert mock_encoder.encode.call_count == 10


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_endpoint_error_handling.py
================================================
#!/usr/bin/env python
"""Test endpoint error handling improvements."""

import asyncio
from unittest.mock import AsyncMock, MagicMock, patch
from fastapi import FastAPI
from fastapi.testclient import TestClient


from ag_ui_adk import ADKAgent, add_adk_fastapi_endpoint
from ag_ui.core import RunAgentInput, UserMessage, RunErrorEvent, EventType


async def test_encoding_error_handling():
    """Test that encoding errors are properly handled."""
    print("🧪 Testing encoding error handling...")

    # Create a mock ADK agent
    mock_agent = AsyncMock(spec=ADKAgent)

    # Create a mock event that will cause encoding issues
    mock_event = MagicMock()
    mock_event.type = EventType.RUN_STARTED
    mock_event.thread_id = "test"
    mock_event.run_id = "test"

    # Mock the agent to yield the problematic event
    async def mock_run(input_data):
        yield mock_event

    mock_agent.run = mock_run

    # Create FastAPI app with endpoint
    app = FastAPI()
    add_adk_fastapi_endpoint(app, mock_agent, path="/test")

    # Create test input
    test_input = {
        "thread_id": "test_thread",
        "run_id": "test_run",
        "messages": [
            {
                "id": "msg1",
                "role": "user",
                "content": "Test message"
            }
        ],
        "context": [],
        "state": {},
        "tools": [],
        "forwarded_props": {}
    }

    # Mock the encoder to simulate encoding failure
    with patch('ag_ui_adk.endpoint.EventEncoder') as mock_encoder_class:
        mock_encoder = MagicMock()
        mock_encoder.encode.side_effect = Exception("Encoding failed!")
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Test the endpoint
        with TestClient(app) as client:
            response = client.post(
                "/test",
                json=test_input,
                headers={"Accept": "text/event-stream"}
            )

            print(f"📊 Response status: {response.status_code}")

            if response.status_code == 200:
                # Read the response content
                content = response.text
                print(f"📄 Response content preview: {content[:100]}...")

                # Check if error handling worked
                if "Event encoding failed" in content or "ENCODING_ERROR" in content:
                    print("✅ Encoding error properly handled and communicated")
                    return True
                else:
                    print("⚠️ Error handling may not be working as expected")
                    print(f"   Full content: {content}")
                    return False
            else:
                print(f"❌ Unexpected status code: {response.status_code}")
                return False


async def test_agent_error_handling():
    """Test that agent errors are properly handled."""
    print("\n🧪 Testing agent error handling...")

    # Create a mock ADK agent that raises an error
    mock_agent = AsyncMock(spec=ADKAgent)

    async def mock_run_error(input_data):
        raise Exception("Agent failed!")
        yield  # This will never be reached

    mock_agent.run = mock_run_error

    # Create FastAPI app with endpoint
    app = FastAPI()
    add_adk_fastapi_endpoint(app, mock_agent, path="/test")

    # Create test input
    test_input = {
        "thread_id": "test_thread",
        "run_id": "test_run",
        "messages": [
            {
                "id": "msg1",
                "role": "user",
                "content": "Test message"
            }
        ],
        "context": [],
        "state": {},
        "tools": [],
        "forwarded_props": {}
    }

    # Test the endpoint
    with TestClient(app) as client:
        response = client.post(
            "/test",
            json=test_input,
            headers={"Accept": "text/event-stream"}
        )

        print(f"📊 Response status: {response.status_code}")

        if response.status_code == 200:
            # Read the response content
            content = response.text
            print(f"📄 Response content preview: {content[:100]}...")

            # Check if error handling worked
            if "Agent execution failed" in content or "AGENT_ERROR" in content:
                print("✅ Agent error properly handled and communicated")
                return True
            else:
                print("⚠️ Agent error handling may not be working as expected")
                print(f"   Full content: {content}")
                return False
        else:
            print(f"❌ Unexpected status code: {response.status_code}")
            return False


async def test_successful_event_handling():
    """Test that normal events are handled correctly."""
    print("\n🧪 Testing successful event handling...")

    # Create a mock ADK agent that yields normal events
    mock_agent = AsyncMock(spec=ADKAgent)

    # Create real event objects instead of mocks
    from ag_ui.core import RunStartedEvent, RunFinishedEvent

    mock_run_started = RunStartedEvent(
        type=EventType.RUN_STARTED,
        thread_id="test",
        run_id="test"
    )

    mock_run_finished = RunFinishedEvent(
        type=EventType.RUN_FINISHED,
        thread_id="test",
        run_id="test"
    )

    async def mock_run_success(input_data):
        yield mock_run_started
        yield mock_run_finished

    mock_agent.run = mock_run_success

    # Create FastAPI app with endpoint
    app = FastAPI()
    add_adk_fastapi_endpoint(app, mock_agent, path="/test")

    # Create test input
    test_input = {
        "thread_id": "test_thread",
        "run_id": "test_run",
        "messages": [
            {
                "id": "msg1",
                "role": "user",
                "content": "Test message"
            }
        ],
        "context": [],
        "state": {},
        "tools": [],
        "forwarded_props": {}
    }

    # Test the endpoint with real encoder
    with TestClient(app) as client:
        response = client.post(
            "/test",
            json=test_input,
            headers={"Accept": "text/event-stream"}
        )

        print(f"📊 Response status: {response.status_code}")

        if response.status_code == 200:
            # Read the response content
            content = response.text
            print(f"📄 Response content preview: {content[:100]}...")

            # Check if normal handling worked
            if "RUN_STARTED" in content and "RUN_FINISHED" in content:
                print("✅ Normal event handling works correctly")
                return True
            else:
                print("⚠️ Normal event handling may not be working")
                print(f"   Full content: {content}")
                return False
        else:
            print(f"❌ Unexpected status code: {response.status_code}")
            return False


async def test_nested_encoding_error_handling():
    """Test handling of errors that occur when encoding error events."""
    print("\n🧪 Testing nested encoding error handling...")

    # Create a mock ADK agent
    mock_agent = AsyncMock(spec=ADKAgent)

    # Create a mock event
    mock_event = MagicMock()
    mock_event.type = EventType.RUN_STARTED
    mock_event.thread_id = "test"
    mock_event.run_id = "test"

    async def mock_run(input_data):
        yield mock_event

    mock_agent.run = mock_run

    # Create FastAPI app with endpoint
    app = FastAPI()
    add_adk_fastapi_endpoint(app, mock_agent, path="/test")

    # Create test input
    test_input = {
        "thread_id": "test_thread",
        "run_id": "test_run",
        "messages": [
            {
                "id": "msg1",
                "role": "user",
                "content": "Test message"
            }
        ],
        "context": [],
        "state": {},
        "tools": [],
        "forwarded_props": {}
    }

    # Mock the encoder to fail on ALL encoding attempts (including error events)
    with patch('ag_ui_adk.endpoint.EventEncoder') as mock_encoder_class:
        mock_encoder = MagicMock()
        mock_encoder.encode.side_effect = Exception("All encoding failed!")
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Test the endpoint
        with TestClient(app) as client:
            response = client.post(
                "/test",
                json=test_input,
                headers={"Accept": "text/event-stream"}
            )

            print(f"📊 Response status: {response.status_code}")

            if response.status_code == 200:
                # Read the response content
                content = response.text
                print(f"📄 Response content preview: {content[:100]}...")

                # Should fallback to basic SSE error format
                if "event: error" in content and "Event encoding failed" in content:
                    print("✅ Nested encoding error properly handled with SSE fallback")
                    return True
                else:
                    print("⚠️ Nested encoding error handling may not be working")
                    print(f"   Full content: {content}")
                    return False
            else:
                print(f"❌ Unexpected status code: {response.status_code}")
                return False


# Alternative approach if the exact module path is unknown
async def test_encoding_error_handling_alternative():
    """Test encoding error handling with alternative patching approach."""
    print("\n🧪 Testing encoding error handling (alternative approach)...")

    # Create a mock ADK agent
    mock_agent = AsyncMock(spec=ADKAgent)

    # Create a mock event that will cause encoding issues
    mock_event = MagicMock()
    mock_event.type = EventType.RUN_STARTED
    mock_event.thread_id = "test"
    mock_event.run_id = "test"

    # Mock the agent to yield the problematic event
    async def mock_run(input_data, agent_id=None):
        yield mock_event

    mock_agent.run = mock_run

    # Create FastAPI app with endpoint
    app = FastAPI()
    add_adk_fastapi_endpoint(app, mock_agent, path="/test")

    # Create test input
    test_input = {
        "thread_id": "test_thread",
        "run_id": "test_run",
        "messages": [
            {
                "id": "msg1",
                "role": "user",
                "content": "Test message"
            }
        ],
        "context": [],
        "state": {},
        "tools": [],
        "forwarded_props": {}
    }

    # The correct patch location based on the import in endpoint.py
    patch_location = 'ag_ui.encoder.EventEncoder'

    with patch(patch_location) as mock_encoder_class:
        mock_encoder = MagicMock()
        mock_encoder.encode.side_effect = Exception("Encoding failed!")
        mock_encoder.get_content_type.return_value = "text/event-stream"
        mock_encoder_class.return_value = mock_encoder

        # Test the endpoint
        with TestClient(app) as client:
            response = client.post(
                "/test",
                json=test_input,
                headers={"Accept": "text/event-stream"}
            )

            print(f"📊 Response status: {response.status_code}")

            if response.status_code == 200:
                # Read the response content
                content = response.text
                print(f"📄 Response content preview: {content[:100]}...")

                # Check if error handling worked
                if "Event encoding failed" in content or "ENCODING_ERROR" in content or "error" in content:
                    print(f"✅ Encoding error properly handled with patch location: {patch_location}")
                    return True
                else:
                    print(f"⚠️ Error handling may not be working with patch location: {patch_location}")
                    return False
            else:
                print(f"❌ Unexpected status code: {response.status_code}")
                return False


async def main():
    """Run error handling tests."""
    print("🚀 Testing Endpoint Error Handling Improvements")
    print("=" * 55)

    tests = [
        test_encoding_error_handling,
        test_agent_error_handling,
        test_successful_event_handling,
        test_nested_encoding_error_handling,
        test_encoding_error_handling_alternative
    ]

    results = []
    for test in tests:
        try:
            result = await test()
            results.append(result)
        except Exception as e:
            print(f"❌ Test {test.__name__} failed with exception: {e}")
            import traceback
            traceback.print_exc()
            results.append(False)

    print("\n" + "=" * 55)
    print("📊 Test Results:")

    test_names = [
        "Encoding error handling",
        "Agent error handling",
        "Successful event handling",
        "Nested encoding error handling",
        "Encoding error handling (alternative)"
    ]

    for i, (name, result) in enumerate(zip(test_names, results), 1):
        status = "✅ PASS" if result else "❌ FAIL"
        print(f"  {i}. {name}: {status}")

    passed = sum(results)
    total = len(results)

    if passed == total:
        print(f"\n🎉 All {total} endpoint error handling tests passed!")
        print("💡 Endpoint now properly handles and communicates all error scenarios")
    else:
        print(f"\n⚠️ {passed}/{total} tests passed")
        print("🔧 Review error handling implementation")

    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
    import sys
    sys.exit(0 if success else 1)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_event_bookending.py
================================================
#!/usr/bin/env python
"""Test that text message events are properly bookended with START/END."""

import asyncio
from pathlib import Path

from ag_ui.core import EventType
from ag_ui_adk import EventTranslator
from unittest.mock import MagicMock

async def test_text_event_bookending():
    """Test that text events are properly bookended."""
    print("🧪 Testing text message event bookending...")

    # Create translator
    translator = EventTranslator()

    # Create streaming events - first partial, then final
    events = []

    # First: streaming content event
    partial_event = MagicMock()
    partial_event.content = MagicMock()
    partial_event.content.parts = [MagicMock(text="Hello from the assistant!")]
    partial_event.author = "assistant"
    partial_event.partial = True  # Streaming
    partial_event.turn_complete = False
    partial_event.is_final_response = lambda: False
    partial_event.candidates = []

    async for event in translator.translate(partial_event, "thread_123", "run_456"):
        events.append(event)
        print(f"📧 {event.type}")

    # Second: final event to trigger END
    final_event = MagicMock()
    final_event.content = MagicMock()
    final_event.content.parts = [MagicMock(text=" (final)")]  # Non-empty text for final
    final_event.author = "assistant"
    final_event.partial = False
    final_event.turn_complete = True
    final_event.is_final_response = lambda: True  # This will trigger END
    final_event.candidates = [MagicMock(finish_reason="STOP")]

    async for event in translator.translate(final_event, "thread_123", "run_456"):
        events.append(event)
        print(f"📧 {event.type}")

    # Analyze the events
    print(f"\n📊 Event Analysis:")
    print(f"   Total events: {len(events)}")

    event_types = [str(event.type) for event in events]

    # Check for proper bookending
    text_events = [e for e in event_types if "TEXT_MESSAGE" in e]
    print(f"   Text message events: {text_events}")

    if len(text_events) >= 3:
        has_start = "EventType.TEXT_MESSAGE_START" in text_events
        has_content = "EventType.TEXT_MESSAGE_CONTENT" in text_events
        has_end = "EventType.TEXT_MESSAGE_END" in text_events

        print(f"   Has START: {has_start}")
        print(f"   Has CONTENT: {has_content}")
        print(f"   Has END: {has_end}")

        # Check order
        if has_start and has_content and has_end:
            start_idx = event_types.index("EventType.TEXT_MESSAGE_START")
            content_idx = event_types.index("EventType.TEXT_MESSAGE_CONTENT")
            end_idx = event_types.index("EventType.TEXT_MESSAGE_END")

            if start_idx < content_idx < end_idx:
                print("✅ Events are properly ordered: START → CONTENT → END")
                return True
            else:
                print(f"❌ Events are out of order: indices {start_idx}, {content_idx}, {end_idx}")
                return False
        else:
            print("❌ Missing required events")
            return False
    else:
        print(f"❌ Expected at least 3 text events, got {len(text_events)}")
        return False

async def test_multiple_messages():
    """Test that multiple messages each get proper bookending."""
    print("\n🧪 Testing multiple message bookending...")

    translator = EventTranslator()

    # Simulate two separate ADK events
    events_all = []

    for i, text in enumerate(["First message", "Second message"]):
        print(f"\n📨 Processing message {i+1}: '{text}'")

        # Create a streaming pattern for each message
        # First: partial content event
        partial_event = MagicMock()
        partial_event.content = MagicMock()
        partial_event.content.parts = [MagicMock(text=text)]
        partial_event.author = "assistant"
        partial_event.partial = True  # Streaming
        partial_event.turn_complete = False
        partial_event.is_final_response = lambda: False
        partial_event.candidates = []

        async for event in translator.translate(partial_event, "thread_123", "run_456"):
            events_all.append(event)
            print(f"   📧 {event.type}")

        # Second: final event to trigger END
        final_event = MagicMock()
        final_event.content = MagicMock()
        final_event.content.parts = [MagicMock(text=" (end)")]
        final_event.author = "assistant"
        final_event.partial = False
        final_event.turn_complete = True
        final_event.is_final_response = lambda: True  # This will trigger END
        final_event.candidates = [MagicMock(finish_reason="STOP")]

        async for event in translator.translate(final_event, "thread_123", "run_456"):
            events_all.append(event)
            print(f"   📧 {event.type}")

    # Check that each message was properly bookended
    event_types = [str(event.type) for event in events_all]
    start_count = event_types.count("EventType.TEXT_MESSAGE_START")
    end_count = event_types.count("EventType.TEXT_MESSAGE_END")

    print(f"\n📊 Multiple Message Analysis:")
    print(f"   Total START events: {start_count}")
    print(f"   Total END events: {end_count}")

    if start_count == 2 and end_count == 2:
        print("✅ Each message properly bookended with START/END")
        return True
    else:
        print("❌ Incorrect number of START/END events")
        return False

async def main():
    print("🚀 Testing ADK Middleware Event Bookending")
    print("==========================================")

    test1_passed = await test_text_event_bookending()
    test2_passed = await test_multiple_messages()

    print(f"\n📊 Final Results:")
    print(f"   Single message bookending: {'✅ PASS' if test1_passed else '❌ FAIL'}")
    print(f"   Multiple message bookending: {'✅ PASS' if test2_passed else '❌ FAIL'}")

    if test1_passed and test2_passed:
        print("\n🎉 All bookending tests passed!")
        print("💡 Events are properly formatted with START/CHUNK/END")
        print("⚠️  Note: Proper streaming for partial ADK events still needs implementation")
    else:
        print("\n⚠️ Some tests failed")

if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_event_translator_comprehensive.py
================================================
#!/usr/bin/env python
"""Comprehensive tests for EventTranslator, focusing on untested paths."""

import pytest
import uuid
from unittest.mock import MagicMock, patch, AsyncMock

from ag_ui.core import (
    EventType, TextMessageStartEvent, TextMessageContentEvent, TextMessageEndEvent,
    ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent, StateDeltaEvent, CustomEvent
)
from google.adk.events import Event as ADKEvent
from ag_ui_adk.event_translator import EventTranslator


class TestEventTranslatorComprehensive:
    """Comprehensive tests for EventTranslator functionality."""

    @pytest.fixture
    def translator(self):
        """Create a fresh EventTranslator instance."""
        return EventTranslator()

    @pytest.fixture
    def mock_adk_event(self):
        """Create a mock ADK event."""
        event = MagicMock(spec=ADKEvent)
        event.id = "test_event_id"
        event.author = "model"
        event.content = None
        event.partial = False
        event.turn_complete = True
        event.is_final_response = False
        return event

    @pytest.fixture
    def mock_adk_event_with_content(self):
        """Create a mock ADK event with content."""
        event = MagicMock(spec=ADKEvent)
        event.id = "test_event_id"
        event.author = "model"

        # Mock content with text parts
        mock_content = MagicMock()
        mock_part = MagicMock()
        mock_part.text = "Test content"
        mock_content.parts = [mock_part]
        event.content = mock_content

        event.partial = False
        event.turn_complete = True
        event.is_final_response = False
        event.usage_metadata = {'tokens': 22}
        return event

    @pytest.mark.asyncio
    async def test_translate_user_event_skipped(self, translator, mock_adk_event):
        """Test that user events are skipped."""
        mock_adk_event.author = "user"

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_translate_event_without_content(self, translator, mock_adk_event):
        """Test translating event without content."""
        mock_adk_event.content = None

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_translate_event_with_empty_parts(self, translator, mock_adk_event):
        """Test translating event with empty parts."""
        mock_content = MagicMock()
        mock_content.parts = []
        mock_adk_event.content = mock_content

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_translate_function_calls_detection(self, translator, mock_adk_event):
        """Test function calls detection and logging."""
        # Mock event with function calls
        mock_function_call = MagicMock()
        mock_function_call.name = "test_function"
        mock_adk_event.get_function_calls = MagicMock(return_value=[mock_function_call])

        with patch('ag_ui_adk.event_translator.logger') as mock_logger:
            events = []
            async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
                events.append(event)

            # Should log function calls detection (along with the ADK Event debug log)
            debug_calls = [str(call) for call in mock_logger.debug.call_args_list]
            assert any("ADK function calls detected: 1 calls" in call for call in debug_calls)

    @pytest.mark.asyncio
    async def test_translate_function_responses_handling(self, translator, mock_adk_event):
        """Test function responses handling."""
        # Mock event with function responses
        mock_function_response = MagicMock()
        mock_adk_event.get_function_responses = MagicMock(return_value=[mock_function_response])

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        # Function responses should be handled but not emit events
        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_translate_state_delta_event(self, translator, mock_adk_event):
        """Test state delta event creation."""
        # Mock event with state delta
        mock_actions = MagicMock()
        mock_actions.state_delta = {"key1": "value1", "key2": "value2"}
        mock_adk_event.actions = mock_actions

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 1
        assert isinstance(events[0], StateDeltaEvent)
        assert events[0].type == EventType.STATE_DELTA

        # Check patches
        patches = events[0].delta
        assert len(patches) == 2
        assert any(patch["path"] == "/key1" and patch["value"] == "value1" for patch in patches)
        assert any(patch["path"] == "/key2" and patch["value"] == "value2" for patch in patches)

    @pytest.mark.asyncio
    async def test_translate_custom_event(self, translator, mock_adk_event):
        """Test custom event creation."""
        mock_adk_event.custom_data = {"custom_key": "custom_value"}

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 1
        assert isinstance(events[0], CustomEvent)
        assert events[0].type == EventType.CUSTOM
        assert events[0].name == "adk_metadata"
        assert events[0].value == {"custom_key": "custom_value"}

    @pytest.mark.asyncio
    async def test_translate_exception_handling(self, translator, mock_adk_event):
        """Test exception handling during translation."""
        # Mock event that will cause an exception during iteration
        mock_adk_event.content = MagicMock()
        mock_adk_event.content.parts = MagicMock()
        # Make parts iteration raise an exception
        mock_adk_event.content.parts.__iter__ = MagicMock(side_effect=ValueError("Test exception"))

        with patch('ag_ui_adk.event_translator.logger') as mock_logger:
            events = []
            async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
                events.append(event)

            # Should log error but not yield error event
            mock_logger.error.assert_called_once()
            assert "Error translating ADK event" in str(mock_logger.error.call_args)
            assert len(events) == 0

    @pytest.mark.asyncio
    async def test_translate_text_content_basic(self, translator, mock_adk_event_with_content):
        """Test basic text content translation."""
        events = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 3  # START, CONTENT , END
        assert isinstance(events[0], TextMessageStartEvent)
        assert isinstance(events[1], TextMessageContentEvent)
        assert isinstance(events[2], TextMessageEndEvent)

        # Check content
        assert events[1].delta == "Test content"

        # Check message IDs are consistent
        message_id = events[0].message_id
        assert events[1].message_id == message_id

    @pytest.mark.asyncio
    async def test_translate_text_content_multiple_parts(self, translator, mock_adk_event):
        """Test text content with multiple parts."""
        mock_content = MagicMock()
        mock_part1 = MagicMock()
        mock_part1.text = "First part"
        mock_part2 = MagicMock()
        mock_part2.text = "Second part"
        mock_content.parts = [mock_part1, mock_part2]
        mock_adk_event.content = mock_content

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 3  # START, CONTENT , END
        assert isinstance(events[1], TextMessageContentEvent)
        assert events[1].delta == "First partSecond part"  # Joined without newlines

    @pytest.mark.asyncio
    async def test_translate_text_content_partial_streaming(self, translator, mock_adk_event_with_content):
        """Test partial streaming (no END event)."""
        mock_adk_event_with_content.partial = True
        mock_adk_event_with_content.turn_complete = False

        events = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 3  # START, CONTENT , END
        assert isinstance(events[0], TextMessageStartEvent)
        assert isinstance(events[1], TextMessageContentEvent)

    @pytest.mark.asyncio
    async def test_translate_text_content_final_response_callable(self, translator, mock_adk_event_with_content):
        """Test final response detection with callable method."""
        mock_adk_event_with_content.is_final_response = MagicMock(return_value=True)

        # Set up streaming state
        translator._is_streaming = True
        translator._streaming_message_id = "test_message_id"

        events = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 1  # Only END event
        assert isinstance(events[0], TextMessageEndEvent)
        assert events[0].message_id == "test_message_id"

        # Should reset streaming state
        assert translator._is_streaming is False
        assert translator._streaming_message_id is None

    @pytest.mark.asyncio
    async def test_translate_text_content_final_response_property(self, translator, mock_adk_event_with_content):
        """Test final response detection with property."""
        mock_adk_event_with_content.is_final_response = True

        # Set up streaming state
        translator._is_streaming = True
        translator._streaming_message_id = "test_message_id"

        events = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 1  # Only END event
        assert isinstance(events[0], TextMessageEndEvent)

    @pytest.mark.asyncio
    async def test_translate_text_content_final_response_no_streaming(self, translator, mock_adk_event_with_content):
        """Test final response when not streaming."""
        mock_adk_event_with_content.is_final_response = True

        # Not streaming
        translator._is_streaming = False

        events = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 0  # No events

    @pytest.mark.asyncio
    async def test_translate_text_content_final_response_from_agent_callback(self, translator, mock_adk_event_with_content):
        """Test final response when it was received from an agent callback function."""
        mock_adk_event_with_content.is_final_response = True
        mock_adk_event_with_content.usage_metadata = None

        # Not streaming
        translator._is_streaming = False

        events = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 3  # START, CONTENT , END
        assert isinstance(events[0], TextMessageStartEvent)
        assert isinstance(events[1], TextMessageContentEvent)
        assert events[1].delta == mock_adk_event_with_content.content.parts[0].text
        assert isinstance(events[2], TextMessageEndEvent)

    @pytest.mark.asyncio
    async def test_translate_text_content_empty_text(self, translator, mock_adk_event):
        """Test text content with empty text."""
        mock_content = MagicMock()
        mock_part = MagicMock()
        mock_part.text = ""
        mock_content.parts = [mock_part]
        mock_adk_event.content = mock_content

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        # Empty text is filtered out by the translator, so no events are generated
        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_translate_text_content_none_text_parts(self, translator, mock_adk_event):
        """Test text content with None text parts."""
        mock_content = MagicMock()
        mock_part1 = MagicMock()
        mock_part1.text = None
        mock_part2 = MagicMock()
        mock_part2.text = None
        mock_content.parts = [mock_part1, mock_part2]
        mock_adk_event.content = mock_content

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 0  # No events for None text

    @pytest.mark.asyncio
    async def test_translate_text_content_mixed_text_parts(self, translator, mock_adk_event):
        """Test text content with mixed text and None parts."""
        mock_content = MagicMock()
        mock_part1 = MagicMock()
        mock_part1.text = "Valid text"
        mock_part2 = MagicMock()
        mock_part2.text = None
        mock_part3 = MagicMock()
        mock_part3.text = "More text"
        mock_content.parts = [mock_part1, mock_part2, mock_part3]
        mock_adk_event.content = mock_content

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        assert len(events) == 3  # START, CONTENT , END
        assert events[1].delta == "Valid textMore text"

    @pytest.mark.asyncio
    async def test_translate_function_calls_basic(self, translator, mock_adk_event):
        """Test basic function call translation."""
        mock_function_call = MagicMock()
        mock_function_call.name = "test_function"
        mock_function_call.args = {"param1": "value1"}
        mock_function_call.id = "call_123"

        events = []
        async for event in translator._translate_function_calls(
             [mock_function_call]
        ):
            events.append(event)

        assert len(events) == 3  # START, ARGS, END
        assert isinstance(events[0], ToolCallStartEvent)
        assert isinstance(events[1], ToolCallArgsEvent)
        assert isinstance(events[2], ToolCallEndEvent)

        # Check details
        assert events[0].tool_call_id == "call_123"
        assert events[0].tool_call_name == "test_function"
        assert events[1].tool_call_id == "call_123"
        assert events[1].delta == '{"param1": "value1"}'
        assert events[2].tool_call_id == "call_123"

    @pytest.mark.asyncio
    async def test_translate_function_calls_no_id(self, translator, mock_adk_event):
        """Test function call translation without ID."""
        mock_function_call = MagicMock()
        mock_function_call.name = "test_function"
        mock_function_call.args = {"param1": "value1"}
        # No id attribute
        delattr(mock_function_call, 'id')

        with patch('uuid.uuid4') as mock_uuid:
            mock_uuid.return_value = "generated_id"

            events = []
            async for event in translator._translate_function_calls(
                 [mock_function_call]
            ):
                events.append(event)

        assert len(events) == 3
        assert events[0].tool_call_id == "generated_id"
        assert events[1].tool_call_id == "generated_id"
        assert events[2].tool_call_id == "generated_id"

    @pytest.mark.asyncio
    async def test_translate_function_calls_no_args(self, translator, mock_adk_event):
        """Test function call translation without args."""
        mock_function_call = MagicMock()
        mock_function_call.name = "test_function"
        mock_function_call.id = "call_123"
        # No args attribute
        delattr(mock_function_call, 'args')

        events = []
        async for event in translator._translate_function_calls(
            [mock_function_call]
        ):
            events.append(event)

        assert len(events) == 2  # START, END (no ARGS)
        assert isinstance(events[0], ToolCallStartEvent)
        assert isinstance(events[1], ToolCallEndEvent)

    @pytest.mark.asyncio
    async def test_translate_function_calls_string_args(self, translator, mock_adk_event):
        """Test function call translation with string args."""
        mock_function_call = MagicMock()
        mock_function_call.name = "test_function"
        mock_function_call.args = "string_args"
        mock_function_call.id = "call_123"

        events = []
        async for event in translator._translate_function_calls(
             [mock_function_call]
        ):
            events.append(event)

        assert len(events) == 3
        assert events[1].delta == "string_args"

    @pytest.mark.asyncio
    async def test_translate_function_calls_multiple(self, translator, mock_adk_event):
        """Test multiple function calls translation."""
        mock_function_call1 = MagicMock()
        mock_function_call1.name = "function1"
        mock_function_call1.args = {"param1": "value1"}
        mock_function_call1.id = "call_1"

        mock_function_call2 = MagicMock()
        mock_function_call2.name = "function2"
        mock_function_call2.args = {"param2": "value2"}
        mock_function_call2.id = "call_2"

        events = []
        async for event in translator._translate_function_calls(
             [mock_function_call1, mock_function_call2]
        ):
            events.append(event)

        assert len(events) == 6  # 3 events per function call

        # Check first function call
        assert events[0].tool_call_id == "call_1"
        assert events[0].tool_call_name == "function1"
        assert events[1].tool_call_id == "call_1"
        assert events[2].tool_call_id == "call_1"

        # Check second function call
        assert events[3].tool_call_id == "call_2"
        assert events[3].tool_call_name == "function2"
        assert events[4].tool_call_id == "call_2"
        assert events[5].tool_call_id == "call_2"

    def test_create_state_delta_event_basic(self, translator):
        """Test basic state delta event creation."""
        state_delta = {"key1": "value1", "key2": "value2"}

        event = translator._create_state_delta_event(state_delta, "thread_1", "run_1")

        assert isinstance(event, StateDeltaEvent)
        assert event.type == EventType.STATE_DELTA
        assert len(event.delta) == 2

        # Check patches
        patches = event.delta
        assert any(patch["op"] == "add" and patch["path"] == "/key1" and patch["value"] == "value1" for patch in patches)
        assert any(patch["op"] == "add" and patch["path"] == "/key2" and patch["value"] == "value2" for patch in patches)

    def test_create_state_delta_event_empty(self, translator):
        """Test state delta event creation with empty delta."""
        event = translator._create_state_delta_event({}, "thread_1", "run_1")

        assert isinstance(event, StateDeltaEvent)
        assert event.delta == []

    def test_create_state_delta_event_nested_objects(self, translator):
        """Test state delta event creation with nested objects."""
        state_delta = {
            "user": {"name": "John", "age": 30},
            "settings": {"theme": "dark", "notifications": True}
        }

        event = translator._create_state_delta_event(state_delta, "thread_1", "run_1")

        assert isinstance(event, StateDeltaEvent)
        assert len(event.delta) == 2

        # Check patches for nested objects
        patches = event.delta
        assert any(patch["op"] == "add" and patch["path"] == "/user" and patch["value"] == {"name": "John", "age": 30} for patch in patches)
        assert any(patch["op"] == "add" and patch["path"] == "/settings" and patch["value"] == {"theme": "dark", "notifications": True} for patch in patches)

    def test_create_state_delta_event_array_values(self, translator):
        """Test state delta event creation with array values."""
        state_delta = {
            "items": ["item1", "item2", "item3"],
            "numbers": [1, 2, 3, 4, 5]
        }

        event = translator._create_state_delta_event(state_delta, "thread_1", "run_1")

        assert isinstance(event, StateDeltaEvent)
        assert len(event.delta) == 2

        # Check patches for arrays
        patches = event.delta
        assert any(patch["op"] == "add" and patch["path"] == "/items" and patch["value"] == ["item1", "item2", "item3"] for patch in patches)
        assert any(patch["op"] == "add" and patch["path"] == "/numbers" and patch["value"] == [1, 2, 3, 4, 5] for patch in patches)

    def test_create_state_delta_event_mixed_types(self, translator):
        """Test state delta event creation with mixed value types."""
        state_delta = {
            "string_val": "text",
            "number_val": 42,
            "boolean_val": True,
            "null_val": None,
            "object_val": {"nested": "value"},
            "array_val": [1, "mixed", {"nested": True}]
        }

        event = translator._create_state_delta_event(state_delta, "thread_1", "run_1")

        assert isinstance(event, StateDeltaEvent)
        assert len(event.delta) == 6

        # Check all patches use "add" operation
        patches = event.delta
        for patch in patches:
            assert patch["op"] == "add"
            assert patch["path"].startswith("/")

        # Verify specific values
        patch_dict = {patch["path"]: patch["value"] for patch in patches}
        assert patch_dict["/string_val"] == "text"
        assert patch_dict["/number_val"] == 42
        assert patch_dict["/boolean_val"] is True
        assert patch_dict["/null_val"] is None
        assert patch_dict["/object_val"] == {"nested": "value"}
        assert patch_dict["/array_val"] == [1, "mixed", {"nested": True}]

    def test_create_state_delta_event_special_characters_in_keys(self, translator):
        """Test state delta event creation with special characters in keys."""
        state_delta = {
            "key-with-dashes": "value1",
            "key_with_underscores": "value2",
            "key.with.dots": "value3",
            "key with spaces": "value4"
        }

        event = translator._create_state_delta_event(state_delta, "thread_1", "run_1")

        assert isinstance(event, StateDeltaEvent)
        assert len(event.delta) == 4

        # Check that all keys are properly escaped in paths
        patches = event.delta
        paths = [patch["path"] for patch in patches]
        assert "/key-with-dashes" in paths
        assert "/key_with_underscores" in paths
        assert "/key.with.dots" in paths
        assert "/key with spaces" in paths

    @pytest.mark.asyncio
    async def test_force_close_streaming_message_with_open_stream(self, translator):
        """Test force closing an open streaming message."""
        translator._is_streaming = True
        translator._streaming_message_id = "test_message_id"

        with patch('ag_ui_adk.event_translator.logger') as mock_logger:
            events = []
            async for event in translator.force_close_streaming_message():
                events.append(event)

        assert len(events) == 1
        assert isinstance(events[0], TextMessageEndEvent)
        assert events[0].message_id == "test_message_id"

        # Should reset streaming state
        assert translator._is_streaming is False
        assert translator._streaming_message_id is None

        # Should log warning
        mock_logger.warning.assert_called_once()
        assert "Force-closing unterminated streaming message" in str(mock_logger.warning.call_args)

    @pytest.mark.asyncio
    async def test_force_close_streaming_message_no_open_stream(self, translator):
        """Test force closing when no stream is open."""
        translator._is_streaming = False
        translator._streaming_message_id = None

        events = []
        async for event in translator.force_close_streaming_message():
            events.append(event)

        assert len(events) == 0

    def test_reset_translator_state(self, translator):
        """Test resetting translator state."""
        # Set up some state
        translator._is_streaming = True
        translator._streaming_message_id = "test_id"
        translator._active_tool_calls = {"call_1": "call_1", "call_2": "call_2"}

        translator.reset()

        # Should reset all state
        assert translator._is_streaming is False
        assert translator._streaming_message_id is None
        assert translator._active_tool_calls == {}

    @pytest.mark.asyncio
    async def test_streaming_state_management(self, translator, mock_adk_event_with_content):
        """Test streaming state management across multiple events."""
        # First event should start streaming
        events1 = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events1.append(event)

        assert len(events1) == 3  # START, CONTENT, END
        message_id = events1[0].message_id

        # streaming is stoped after TextMessageEndEvent
        assert translator._is_streaming is False
        # since the streaming is stopped
        assert translator._streaming_message_id == None

        # Second event should continue streaming (same message ID)
        events2 = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events2.append(event)

        assert len(events2) == 3  # New Streaming (START , CONTENT ,END)
        assert events2[0].message_id != message_id  # Same message ID

    @pytest.mark.asyncio
    async def test_complex_event_with_multiple_features(self, translator, mock_adk_event):
        """Test complex event with text, function calls, state delta, and custom data."""
        # Set up complex event
        mock_content = MagicMock()
        mock_part = MagicMock()
        mock_part.text = "Complex event text"
        mock_content.parts = [mock_part]
        mock_adk_event.content = mock_content

        # Add state delta
        mock_actions = MagicMock()
        mock_actions.state_delta = {"state_key": "state_value"}
        mock_adk_event.actions = mock_actions

        # Add custom data
        mock_adk_event.custom_data = {"custom_key": "custom_value"}

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        # Should have text events, state delta, and custom event
        assert len(events) == 5  # START, CONTENT, STATE_DELTA, CUSTOM , END

        # Check event types
        event_types = [type(event) for event in events]
        assert TextMessageStartEvent in event_types
        assert TextMessageContentEvent in event_types
        assert StateDeltaEvent in event_types
        assert CustomEvent in event_types
        assert TextMessageEndEvent in event_types

    @pytest.mark.asyncio
    async def test_event_logging_coverage(self, translator, mock_adk_event_with_content):
        """Test comprehensive event logging."""
        with patch('ag_ui_adk.event_translator.logger') as mock_logger:
            events = []
            async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
                events.append(event)

            # Should log ADK event processing (now in debug logs)
            mock_logger.debug.assert_called()
            debug_calls = [str(call) for call in mock_logger.debug.call_args_list]
            assert any("ADK Event:" in call for call in debug_calls)

            # Text event logging remains in info
            mock_logger.info.assert_called()
            info_calls = [str(call) for call in mock_logger.info.call_args_list]
            assert any("Text event -" in call for call in info_calls)
            assert any("TEXT_MESSAGE_START:" in call for call in info_calls)
            assert any("TEXT_MESSAGE_CONTENT:" in call for call in info_calls)
            # No TEXT_MESSAGE_END unless is_final_response=True

    @pytest.mark.asyncio
    async def test_attribute_access_patterns(self, translator, mock_adk_event):
        """Test different attribute access patterns for ADK events."""
        # Test event with various attribute patterns
        mock_adk_event.partial = None  # Test None handling
        mock_adk_event.turn_complete = None

        # Remove is_final_response to test missing attribute
        delattr(mock_adk_event, 'is_final_response')

        events = []
        async for event in translator.translate(mock_adk_event, "thread_1", "run_1"):
            events.append(event)

        # Should handle missing/None attributes gracefully
        assert len(events) == 0  # No content to process

    @pytest.mark.asyncio
    async def test_tool_call_tracking_cleanup(self, translator, mock_adk_event):
        """Test that tool call tracking is properly cleaned up."""
        mock_function_call = MagicMock()
        mock_function_call.name = "test_function"
        mock_function_call.args = {"param": "value"}
        mock_function_call.id = "call_123"

        # Before translation
        assert len(translator._active_tool_calls) == 0

        events = []
        async for event in translator._translate_function_calls(
             [mock_function_call]
        ):
            events.append(event)

        # After translation, should be cleaned up
        assert len(translator._active_tool_calls) == 0

    @pytest.mark.asyncio
    async def test_partial_streaming_continuation(self, translator, mock_adk_event_with_content):
        """Test continuation of partial streaming."""
        # First partial event
        mock_adk_event_with_content.partial = True
        mock_adk_event_with_content.turn_complete = False

        events1 = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events1.append(event)

        assert len(events1) == 3  # START, CONTENT , END
        assert translator._is_streaming is False
        message_id = events1[0].message_id

        # Second partial event (should continue streaming)
        mock_adk_event_with_content.partial = True
        mock_adk_event_with_content.turn_complete = False

        events2 = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events2.append(event)

        assert len(events2) == 3  # Will start from begining (START , CONTENT , END)
        assert isinstance(events2[1], TextMessageContentEvent)
        assert events2[0].message_id != message_id  # Not the same message ID Because its a new streaming

        # Final event (should end streaming - requires is_final_response=True)
        mock_adk_event_with_content.partial = False
        mock_adk_event_with_content.turn_complete = True
        mock_adk_event_with_content.is_final_response = True

        events3 = []
        async for event in translator.translate(mock_adk_event_with_content, "thread_1", "run_1"):
            events3.append(event)

        assert len(events3) == 0  # No more message (turn Complete)

        # Should reset streaming state
        assert translator._is_streaming is False
        assert translator._streaming_message_id is None


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_execution_state.py
================================================
#!/usr/bin/env python
"""Test ExecutionState class functionality."""

import pytest
import asyncio
import time
from unittest.mock import MagicMock

from ag_ui_adk.execution_state import ExecutionState


class TestExecutionState:
    """Test cases for ExecutionState class."""

    @pytest.fixture
    def mock_task(self):
        """Create a mock asyncio task."""
        task = MagicMock()
        task.done.return_value = False
        task.cancel = MagicMock()
        return task

    @pytest.fixture
    def mock_queue(self):
        """Create a mock asyncio queue."""
        return MagicMock()

    @pytest.fixture
    def execution_state(self, mock_task, mock_queue):
        """Create a test ExecutionState instance."""
        return ExecutionState(
            task=mock_task,
            thread_id="test_thread_123",
            event_queue=mock_queue
        )

    def test_initialization(self, execution_state, mock_task, mock_queue):
        """Test ExecutionState initialization."""
        assert execution_state.task == mock_task
        assert execution_state.thread_id == "test_thread_123"
        assert execution_state.event_queue == mock_queue
        assert execution_state.is_complete is False
        assert isinstance(execution_state.start_time, float)
        assert execution_state.start_time <= time.time()

    def test_is_stale_fresh_execution(self, execution_state):
        """Test is_stale returns False for fresh execution."""
        # Should not be stale immediately
        assert execution_state.is_stale(600) is False
        assert execution_state.is_stale(1) is False

    def test_is_stale_old_execution(self, execution_state):
        """Test is_stale returns True for old execution."""
        # Artificially age the execution
        execution_state.start_time = time.time() - 700  # 700 seconds ago

        assert execution_state.is_stale(600) is True  # 10 minute timeout
        assert execution_state.is_stale(800) is False  # 13+ minute timeout

    @pytest.mark.asyncio
    async def test_cancel_with_pending_task(self, mock_queue):
        """Test cancelling execution with pending task."""
        # Create a real asyncio task for testing
        async def dummy_task():
            await asyncio.sleep(10)  # Long running task

        real_task = asyncio.create_task(dummy_task())

        execution_state = ExecutionState(
            task=real_task,
            thread_id="test_thread",
            event_queue=mock_queue
        )

        await execution_state.cancel()

        # Should cancel task
        assert real_task.cancelled() is True
        assert execution_state.is_complete is True

    @pytest.mark.asyncio
    async def test_cancel_with_completed_task(self, execution_state, mock_task):
        """Test cancelling execution with already completed task."""
        # Mock task as already done
        mock_task.done.return_value = True

        await execution_state.cancel()

        # Should not try to cancel completed task
        mock_task.cancel.assert_not_called()
        assert execution_state.is_complete is True

    def test_get_execution_time(self, execution_state):
        """Test get_execution_time returns reasonable value."""
        execution_time = execution_state.get_execution_time()

        assert isinstance(execution_time, float)
        assert execution_time >= 0
        assert execution_time < 1.0  # Should be very small for fresh execution

    def test_get_status_complete(self, execution_state):
        """Test get_status when execution is complete."""
        execution_state.is_complete = True

        assert execution_state.get_status() == "complete"

    def test_get_status_task_done(self, execution_state, mock_task):
        """Test get_status when task is done but execution not marked complete."""
        mock_task.done.return_value = True

        assert execution_state.get_status() == "task_done"

    def test_get_status_running(self, execution_state):
        """Test get_status when execution is running normally."""
        status = execution_state.get_status()
        assert status == "running"

    def test_string_representation(self, execution_state):
        """Test __repr__ method."""
        repr_str = repr(execution_state)

        assert "ExecutionState" in repr_str
        assert "test_thread_123" in repr_str
        assert "runtime=" in repr_str
        assert "status=" in repr_str

    def test_execution_time_progression(self, execution_state):
        """Test that execution time increases over time."""
        time1 = execution_state.get_execution_time()
        time.sleep(0.01)  # Small delay
        time2 = execution_state.get_execution_time()

        assert time2 > time1


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_integration.py
================================================
#!/usr/bin/env python
"""Integration test for ADK middleware without requiring API calls."""

import asyncio
from unittest.mock import AsyncMock, MagicMock

from ag_ui.core import RunAgentInput, UserMessage, EventType
from ag_ui_adk import ADKAgent

async def test_session_creation_logic():
    """Test session creation logic with mocked ADK agent."""
    print("🧪 Testing session creation logic...")

    # Create a real ADK agent for testing
    from google.adk.agents import Agent
    mock_adk_agent = Agent(
        name="mock_agent",
        instruction="Mock agent for testing"
    )

    # Mock the runner's run_async method
    mock_runner = MagicMock()
    mock_events = [
        MagicMock(type="TEXT_MESSAGE_START"),
        MagicMock(type="TEXT_MESSAGE_CONTENT", content="Hello from mock!"),
        MagicMock(type="TEXT_MESSAGE_END"),
    ]

    async def mock_run_async(*args, **kwargs):
        for event in mock_events:
            yield event

    mock_runner.run_async = mock_run_async

    # Create ADK middleware with direct agent embedding
    adk_agent = ADKAgent(
        adk_agent=mock_adk_agent,
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True,
    )

    # Mock the get_or_create_runner method to return our mock
    adk_agent._get_or_create_runner = MagicMock(return_value=mock_runner)

    # Create test input
    test_input = RunAgentInput(
        thread_id="test_session_456",
        run_id="test_run_789",
        messages=[
            UserMessage(
                id="msg_1",
                role="user",
                content="Test session creation"
            )
        ],
        state={"test": "data"},
        context=[],
        tools=[],
        forwarded_props={}
    )

    # Run the test
    events = []
    try:
        async for event in adk_agent.run(test_input):
            events.append(event)
            print(f"📧 Event: {event.type}")
    except Exception as e:
        print(f"⚠️ Test completed with exception (expected with mocks): {e}")

    # Check that we got some events
    if events:
        print(f"✅ Got {len(events)} events")
        # Should have at least RUN_STARTED
        if any(event.type == EventType.RUN_STARTED for event in events):
            print("✅ RUN_STARTED event found")
        else:
            print("⚠️ No RUN_STARTED event found")
    else:
        print("❌ No events received")

    return len(events) > 0

async def test_session_service_calls():
    """Test that session service methods are called correctly."""
    print("\n🧪 Testing session service interaction...")

    # Create a test agent first
    from google.adk.agents import Agent
    test_agent = Agent(name="session_test_agent", instruction="Test agent.")

    # Create ADK middleware (session service is now encapsulated in session manager)
    adk_agent = ADKAgent(
        adk_agent=test_agent,
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True,
    )

    # Test the session creation method directly through session manager
    try:
        session = await adk_agent._ensure_session_exists(
            app_name="test_app",
            user_id="test_user",
            session_id="test_session_123",
            initial_state={"key": "value"}
        )

        print("✅ Session creation method completed without error")

        # Verify we got a session object back
        if session:
            print("✅ Session object returned from session manager")
        else:
            print("⚠️ No session object returned, but no error raised")

        print("✅ Session manager integration working correctly")
        return True

    except Exception as e:
        print(f"❌ Session creation test failed: {e}")
        return False

async def main():
    print("🚀 ADK Middleware Integration Tests")
    print("====================================")

    test1_passed = await test_session_creation_logic()
    test2_passed = await test_session_service_calls()

    print(f"\n📊 Test Results:")
    print(f"   Session creation logic: {'✅ PASS' if test1_passed else '❌ FAIL'}")
    print(f"   Session service calls: {'✅ PASS' if test2_passed else '❌ FAIL'}")

    if test1_passed and test2_passed:
        print("\n🎉 All integration tests passed!")
    else:
        print("\n⚠️ Some tests failed - check implementation")

if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_session_cleanup.py
================================================
#!/usr/bin/env python
"""Test session cleanup functionality with minimal session manager."""

import asyncio
import time

from ag_ui_adk import ADKAgent, SessionManager
from google.adk.agents import Agent
from ag_ui.core import RunAgentInput, UserMessage, EventType

async def test_session_cleanup():
    """Test that session cleanup works with the minimal session manager."""
    print("🧪 Testing session cleanup...")

    # Create a test agent
    agent = Agent(
        name="cleanup_test_agent",
        instruction="Test agent for cleanup"
    )

    # Reset singleton and create session manager with short timeout for faster testing
    SessionManager.reset_instance()

    # Create ADK middleware with short timeouts
    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="test_app",
        user_id="cleanup_test_user",
        use_in_memory_services=True
    )

    # Get the session manager (already configured with 1200s timeout by default)
    session_manager = adk_agent._session_manager

    # Create some sessions by running the agent
    print("📊 Creating test sessions...")

    # Create sessions for different users
    for i in range(3):
        test_input = RunAgentInput(
            thread_id=f"thread_{i}",
            run_id=f"run_{i}",
            messages=[UserMessage(id=f"msg_{i}", role="user", content=f"Test message {i}")],
            context=[],
            state={},
            tools=[],
            forwarded_props={}
        )

        # Start streaming to create a session
        async for event in adk_agent.run(test_input):
            if event.type == EventType.RUN_STARTED:
                print(f"  Created session for thread_{i}")
            break  # Just need to start the session

    session_count = session_manager.get_session_count()
    print(f"📊 Created {session_count} test sessions")

    # For testing, we'll manually trigger cleanup since we can't wait 20 minutes
    # The minimal manager tracks sessions and can clean them up
    print("🧹 Testing cleanup mechanism...")

    # The minimal session manager doesn't expose expired sessions directly,
    # but we can verify the cleanup works by checking session count
    initial_count = session_manager.get_session_count()

    # Since we can't easily test timeout without waiting, let's just verify
    # the session manager is properly initialized and tracking sessions
    if initial_count > 0:
        print(f"✅ Session manager is tracking {initial_count} sessions")
        print("✅ Cleanup task would remove expired sessions after timeout")
        return True
    else:
        print("❌ No sessions were tracked")
        return False


async def main():
    """Run the test."""
    try:
        # Cleanup any existing instance
        SessionManager.reset_instance()

        success = await test_session_cleanup()

        # Cleanup
        SessionManager.reset_instance()

        if success:
            print("\n✅ All session cleanup tests passed!")
        else:
            print("\n❌ Session cleanup test failed!")
            exit(1)

    except Exception as e:
        print(f"\n❌ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_session_creation.py
================================================
#!/usr/bin/env python
"""Test session creation functionality."""

import asyncio
from pathlib import Path

from ag_ui.core import RunAgentInput, UserMessage
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent

async def test_session_creation():
    """Test that sessions are created automatically."""
    print("🧪 Testing session creation...")

    try:
        # Setup agent
        agent = Agent(
            name="test_agent",
            instruction="You are a test assistant."
        )

        registry = AgentRegistry.get_instance()
        registry.set_default_agent(agent)

        # Create ADK middleware
        adk_agent = ADKAgent(
            app_name="test_app",
            user_id="test_user",
            use_in_memory_services=True
        )

        # Create a test input that should trigger session creation
        test_input = RunAgentInput(
            thread_id="test_thread_123",
            run_id="test_run_456",
            messages=[
                UserMessage(
                    id="msg_1",
                    role="user",
                    content="Hello! This is a test message."
                )
            ],
            state={},
            context=[],
            tools=[],
            forwarded_props={}
        )

        print(f"🔄 Testing with thread_id: {test_input.thread_id}")

        # Try to run - this should create a session automatically
        events = []
        async for event in adk_agent.run(test_input):
            events.append(event)
            print(f"📧 Received event: {event.type}")

            # Stop after a few events to avoid long-running test
            if len(events) >= 3:
                break

        if events:
            print(f"✅ Session creation test passed! Received {len(events)} events")
            print(f"   First event: {events[0].type}")
            if len(events) > 1:
                print(f"   Last event: {events[-1].type}")
        else:
            print("❌ No events received - session creation may have failed")

    except Exception as e:
        print(f"❌ Session creation test failed: {e}")
        import traceback
        traceback.print_exc()

async def main():
    print("🚀 Testing ADK Middleware Session Creation")
    print("==========================================")
    await test_session_creation()
    print("\nTest complete!")

if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_session_deletion.py
================================================
#!/usr/bin/env python
"""Test session deletion functionality with minimal session manager."""

import asyncio
from unittest.mock import AsyncMock, MagicMock


from ag_ui_adk import SessionManager

async def test_session_deletion():
    """Test that session deletion calls delete_session with correct parameters."""
    print("🧪 Testing session deletion...")

    # Reset singleton for clean test
    SessionManager.reset_instance()

    # Create mock session service
    mock_session_service = AsyncMock()
    mock_session_service.get_session = AsyncMock(return_value=None)
    mock_session_service.create_session = AsyncMock(return_value=MagicMock())
    mock_session_service.delete_session = AsyncMock()

    # Create session manager with mock service
    session_manager = SessionManager.get_instance(
        session_service=mock_session_service,
        auto_cleanup=False
    )

    # Create a session
    test_session_id = "test_session_123"
    test_app_name = "test_app"
    test_user_id = "test_user"

    adk_session = await session_manager.get_or_create_session(
        session_id=test_session_id,
        app_name=test_app_name,
        user_id=test_user_id,
        initial_state={"test": "data"}
    )

    print(f"✅ Created session: {test_session_id}")

    # Verify session exists in tracking
    session_key = f"{test_app_name}:{test_session_id}"
    assert session_key in session_manager._session_keys
    print(f"✅ Session tracked: {session_key}")

    # Create a mock session object for deletion
    mock_session = MagicMock()
    mock_session.id = test_session_id
    mock_session.app_name = test_app_name
    mock_session.user_id = test_user_id

    # Manually delete the session (internal method)
    await session_manager._delete_session(mock_session)

    # Verify session is no longer tracked
    assert session_key not in session_manager._session_keys
    print("✅ Session no longer in tracking")

    # Verify delete_session was called with correct parameters
    mock_session_service.delete_session.assert_called_once_with(
        session_id=test_session_id,
        app_name=test_app_name,
        user_id=test_user_id
    )
    print("✅ delete_session called with correct parameters:")
    print(f"   session_id: {test_session_id}")
    print(f"   app_name: {test_app_name}")
    print(f"   user_id: {test_user_id}")

    return True


async def test_session_deletion_error_handling():
    """Test session deletion error handling."""
    print("\n🧪 Testing session deletion error handling...")

    # Reset singleton for clean test
    SessionManager.reset_instance()

    # Create mock session service that raises an error on delete
    mock_session_service = AsyncMock()
    mock_session_service.get_session = AsyncMock(return_value=None)
    mock_session_service.create_session = AsyncMock(return_value=MagicMock())
    mock_session_service.delete_session = AsyncMock(side_effect=Exception("Delete failed"))

    # Create session manager with mock service
    session_manager = SessionManager.get_instance(
        session_service=mock_session_service,
        auto_cleanup=False
    )

    # Create a session
    test_session_id = "test_session_456"
    test_app_name = "test_app"
    test_user_id = "test_user"

    await session_manager.get_or_create_session(
        session_id=test_session_id,
        app_name=test_app_name,
        user_id=test_user_id
    )

    session_key = f"{test_app_name}:{test_session_id}"
    assert session_key in session_manager._session_keys

    # Try to delete - should handle the error gracefully
    try:
        await session_manager._delete_session(test_session_id, test_app_name, test_user_id)

        # Even if deletion failed, session should be untracked
        assert session_key not in session_manager._session_keys
        print("✅ Session untracked even after deletion error")

        return True
    except Exception as e:
        print(f"❌ Unexpected exception: {e}")
        return False


async def test_user_session_limits():
    """Test per-user session limits."""
    print("\n🧪 Testing per-user session limits...")

    # Reset singleton for clean test
    SessionManager.reset_instance()

    # Create mock session service
    mock_session_service = AsyncMock()

    # Mock session objects with last_update_time and required attributes
    class MockSession:
        def __init__(self, update_time, session_id=None, app_name=None, user_id=None):
            self.last_update_time = update_time
            self.id = session_id
            self.app_name = app_name
            self.user_id = user_id

    created_sessions = {}

    async def mock_get_session(session_id, app_name, user_id):
        key = f"{app_name}:{session_id}"
        return created_sessions.get(key)

    async def mock_create_session(session_id, app_name, user_id, state):
        import time
        session = MockSession(time.time(), session_id, app_name, user_id)
        key = f"{app_name}:{session_id}"
        created_sessions[key] = session
        return session

    mock_session_service.get_session = mock_get_session
    mock_session_service.create_session = mock_create_session
    mock_session_service.delete_session = AsyncMock()

    # Create session manager with limit of 2 sessions per user
    session_manager = SessionManager.get_instance(
        session_service=mock_session_service,
        max_sessions_per_user=2,
        auto_cleanup=False
    )

    test_user = "limited_user"
    test_app = "test_app"

    # Create 3 sessions for the same user
    for i in range(3):
        await session_manager.get_or_create_session(
            session_id=f"session_{i}",
            app_name=test_app,
            user_id=test_user
        )
        # Small delay to ensure different timestamps
        await asyncio.sleep(0.1)

    # Should only have 2 sessions for this user
    user_count = session_manager.get_user_session_count(test_user)
    assert user_count == 2, f"Expected 2 sessions, got {user_count}"
    print(f"✅ User session limit enforced: {user_count} sessions")

    # Verify the oldest session was removed
    assert f"{test_app}:session_0" not in session_manager._session_keys
    assert f"{test_app}:session_1" in session_manager._session_keys
    assert f"{test_app}:session_2" in session_manager._session_keys
    print("✅ Oldest session was removed")

    return True


async def main():
    """Run all tests."""
    try:
        success = await test_session_deletion()
        success = success and await test_session_deletion_error_handling()
        success = success and await test_user_session_limits()

        if success:
            print("\n✅ All session deletion tests passed!")
        else:
            print("\n❌ Some tests failed!")
            exit(1)

    except Exception as e:
        print(f"\n❌ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_session_memory.py
================================================
#!/usr/bin/env python
"""Extended test session memory integration functionality with state management tests."""

import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch
from datetime import datetime
import time

from ag_ui_adk import SessionManager


class TestSessionMemory:
    """Test cases for automatic session memory functionality."""

    @pytest.fixture(autouse=True)
    def reset_session_manager(self):
        """Reset session manager before each test."""
        SessionManager.reset_instance()
        yield
        SessionManager.reset_instance()

    @pytest.fixture
    def mock_session_service(self):
        """Create a mock session service."""
        service = AsyncMock()
        service.get_session = AsyncMock()
        service.create_session = AsyncMock()
        service.delete_session = AsyncMock()
        service.append_event = AsyncMock()
        return service

    @pytest.fixture
    def mock_memory_service(self):
        """Create a mock memory service."""
        service = AsyncMock()
        service.add_session_to_memory = AsyncMock()
        return service

    @pytest.fixture
    def mock_session(self):
        """Create a mock ADK session object."""
        class MockState(dict):
            def to_dict(self):
                return dict(self)

        session = MagicMock()
        session.last_update_time = datetime.fromtimestamp(time.time())
        session.state = MockState({"test": "data", "user_id": "test_user", "counter": 42})
        session.id = "test_session"
        session.app_name = "test_app"
        session.user_id = "test_user"

        return session

    # ===== EXISTING MEMORY TESTS =====

    @pytest.mark.asyncio
    async def test_memory_service_disabled_by_default(self, mock_session_service, mock_session):
        """Test that memory service is disabled when not provided."""
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            auto_cleanup=False
        )

        # Verify memory service is None
        assert manager._memory_service is None

        # Create and delete a session - memory service should not be called
        mock_session_service.get_session.return_value = None
        mock_session_service.create_session.return_value = MagicMock()

        await manager.get_or_create_session("test_session", "test_app", "test_user")
        await manager._delete_session(mock_session)

        # Only session service delete should be called
        mock_session_service.delete_session.assert_called_once()

    @pytest.mark.asyncio
    async def test_memory_service_enabled_with_service(self, mock_session_service, mock_memory_service, mock_session):
        """Test that memory service is called when provided."""
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=mock_memory_service,
            auto_cleanup=False
        )

        # Verify memory service is set
        assert manager._memory_service is mock_memory_service

        # Delete a session using session object
        await manager._delete_session(mock_session)

        # Verify memory service was called with correct parameters
        mock_memory_service.add_session_to_memory.assert_called_once_with(mock_session)

        # Verify session was also deleted from session service
        mock_session_service.delete_session.assert_called_once_with(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user"
        )

    @pytest.mark.asyncio
    async def test_memory_service_error_handling(self, mock_session_service, mock_memory_service, mock_session):
        """Test that memory service errors don't prevent session deletion."""
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=mock_memory_service,
            auto_cleanup=False
        )

        # Make memory service fail
        mock_memory_service.add_session_to_memory.side_effect = Exception("Memory service error")

        # Delete should still succeed despite memory service error
        await manager._delete_session(mock_session)

        # Verify both were called despite memory service error
        mock_memory_service.add_session_to_memory.assert_called_once()
        mock_session_service.delete_session.assert_called_once()

    @pytest.mark.asyncio
    async def test_memory_service_with_missing_session(self, mock_session_service, mock_memory_service):
        """Test memory service behavior when session doesn't exist."""
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=mock_memory_service,
            auto_cleanup=False
        )

        # Delete a None session (simulates session not found)
        await manager._delete_session(None)

        # Memory service should not be called for non-existent session
        mock_memory_service.add_session_to_memory.assert_not_called()

        # Session service delete should also not be called for None session
        mock_session_service.delete_session.assert_not_called()

    @pytest.mark.asyncio
    async def test_memory_service_during_cleanup(self, mock_session_service, mock_memory_service):
        """Test that memory service is used during automatic cleanup."""
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=mock_memory_service,
            session_timeout_seconds=1,  # 1 second timeout
            auto_cleanup=False  # We'll trigger cleanup manually
        )

        # Create an expired session
        old_session = MagicMock()
        old_session.last_update_time = time.time() - 10  # 10 seconds ago
        old_session.state = {}  # No pending tool calls

        # Track a session manually for testing
        manager._track_session("test_app:test_session", "test_user")

        # Mock session retrieval to return the expired session
        mock_session_service.get_session.return_value = old_session

        # Trigger cleanup
        await manager._cleanup_expired_sessions()

        # Verify memory service was called during cleanup
        mock_memory_service.add_session_to_memory.assert_called_once_with(old_session)

    @pytest.mark.asyncio
    async def test_memory_service_during_user_limit_enforcement(self, mock_session_service, mock_memory_service):
        """Test that memory service is used when removing oldest sessions due to user limits."""
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=mock_memory_service,
            max_sessions_per_user=1,  # Limit to 1 session per user
            auto_cleanup=False
        )

        # Create an old session that will be removed
        old_session = MagicMock()
        old_session.last_update_time = time.time() - 60  # 1 minute ago

        # Mock initial session creation and retrieval
        mock_session_service.get_session.return_value = None
        mock_session_service.create_session.return_value = MagicMock()

        # Create first session
        await manager.get_or_create_session("session1", "test_app", "test_user")

        # Now mock the old session for limit enforcement
        def mock_get_session_side_effect(session_id, app_name, user_id):
            if session_id == "session1":
                return old_session
            return None

        mock_session_service.get_session.side_effect = mock_get_session_side_effect

        # Create second session - should trigger removal of first session
        await manager.get_or_create_session("session2", "test_app", "test_user")

        # Verify memory service was called for the removed session
        mock_memory_service.add_session_to_memory.assert_called_once_with(old_session)

    @pytest.mark.asyncio
    async def test_memory_service_configuration(self, mock_session_service, mock_memory_service):
        """Test that memory service configuration is properly stored."""
        # Test with memory service enabled
        SessionManager.reset_instance()
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=mock_memory_service
        )

        assert manager._memory_service is mock_memory_service

        # Test with memory service disabled
        SessionManager.reset_instance()
        manager = SessionManager.get_instance(
            session_service=mock_session_service,
            memory_service=None
        )

        assert manager._memory_service is None


class TestSessionStateManagement:
    """Test cases for session state management functionality."""

    @pytest.fixture(autouse=True)
    def reset_session_manager(self):
        """Reset session manager before each test."""
        SessionManager.reset_instance()
        yield
        SessionManager.reset_instance()

    @pytest.fixture
    def mock_session_service(self):
        """Create a mock session service."""
        service = AsyncMock()
        service.get_session = AsyncMock()
        service.create_session = AsyncMock()
        service.delete_session = AsyncMock()
        service.append_event = AsyncMock()
        return service

    @pytest.fixture
    def mock_session(self):
        """Create a mock ADK session object with state."""

        class MockState(dict):
            def to_dict(self):
                return dict(self)

        session = MagicMock()
        session.last_update_time = datetime.fromtimestamp(time.time())
        session.state = MockState({
            "test": "data",
            "user_id": "test_user",
            "counter": 42,
            "app:setting": "value"
        })
        session.id = "test_session"
        session.app_name = "test_app"
        session.user_id = "test_user"

        return session

    @pytest.fixture
    def manager(self, mock_session_service):
        """Create a session manager instance."""
        return SessionManager.get_instance(
            session_service=mock_session_service,
            auto_cleanup=False
        )

    # ===== UPDATE SESSION STATE TESTS =====

    @pytest.mark.asyncio
    async def test_update_session_state_success(self, manager, mock_session_service, mock_session):
        """Test successful session state update."""
        mock_session_service.get_session.return_value = mock_session

        state_updates = {"new_key": "new_value", "counter": 100}

        with patch('google.adk.events.Event') as mock_event, \
             patch('google.adk.events.EventActions') as mock_actions:

            result = await manager.update_session_state(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                state_updates=state_updates
            )

            assert result is True
            mock_session_service.get_session.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user"
            )
            mock_actions.assert_called_once_with(state_delta=state_updates)
            mock_session_service.append_event.assert_called_once()

    @pytest.mark.asyncio
    async def test_update_session_state_session_not_found(self, manager, mock_session_service):
        """Test update when session doesn't exist."""
        mock_session_service.get_session.return_value = None

        result = await manager.update_session_state(
            session_id="nonexistent",
            app_name="test_app",
            user_id="test_user",
            state_updates={"key": "value"}
        )

        assert result is False
        mock_session_service.append_event.assert_not_called()

    @pytest.mark.asyncio
    async def test_update_session_state_empty_updates(self, manager, mock_session_service, mock_session):
        """Test update with empty state updates."""
        mock_session_service.get_session.return_value = mock_session

        result = await manager.update_session_state(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user",
            state_updates={}
        )

        assert result is False
        mock_session_service.append_event.assert_not_called()

    @pytest.mark.asyncio
    async def test_update_session_state_exception_handling(self, manager, mock_session_service):
        """Test exception handling in state update."""
        mock_session_service.get_session.side_effect = Exception("Database error")

        result = await manager.update_session_state(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user",
            state_updates={"key": "value"}
        )

        assert result is False

    # ===== GET SESSION STATE TESTS =====

    @pytest.mark.asyncio
    async def test_get_session_state_success(self, manager, mock_session_service, mock_session):
        """Test successful session state retrieval."""
        mock_session_service.get_session.return_value = mock_session

        result = await manager.get_session_state(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user"
        )

        assert result == {
            "test": "data",
            "user_id": "test_user",
            "counter": 42,
            "app:setting": "value"
        }
        mock_session_service.get_session.assert_called_once()

    @pytest.mark.asyncio
    async def test_get_session_state_session_not_found(self, manager, mock_session_service):
        """Test get state when session doesn't exist."""
        mock_session_service.get_session.return_value = None

        result = await manager.get_session_state(
            session_id="nonexistent",
            app_name="test_app",
            user_id="test_user"
        )

        assert result is None

    @pytest.mark.asyncio
    async def test_get_session_state_exception_handling(self, manager, mock_session_service):
        """Test exception handling in get state."""
        mock_session_service.get_session.side_effect = Exception("Database error")

        result = await manager.get_session_state(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user"
        )

        assert result is None

    # ===== GET STATE VALUE TESTS =====

    @pytest.mark.asyncio
    async def test_get_state_value_success(self, manager, mock_session_service, mock_session):
        """Test successful retrieval of specific state value."""
        mock_session_service.get_session.return_value = mock_session

        result = await manager.get_state_value(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user",
            key="counter"
        )

        assert result == 42

    @pytest.mark.asyncio
    async def test_get_state_value_with_default(self, manager, mock_session_service, mock_session):
        """Test get state value with default for missing key."""
        mock_session_service.get_session.return_value = mock_session

        result = await manager.get_state_value(
            session_id="test_session",
            app_name="test_app",
            user_id="test_user",
            key="nonexistent_key",
            default="default_value"
        )

        assert result == "default_value"

    @pytest.mark.asyncio
    async def test_get_state_value_session_not_found(self, manager, mock_session_service):
        """Test get state value when session doesn't exist."""
        mock_session_service.get_session.return_value = None

        result = await manager.get_state_value(
            session_id="nonexistent",
            app_name="test_app",
            user_id="test_user",
            key="any_key",
            default="default_value"
        )

        assert result == "default_value"

    # ===== SET STATE VALUE TESTS =====

    @pytest.mark.asyncio
    async def test_set_state_value_success(self, manager, mock_session_service, mock_session):
        """Test successful setting of state value."""
        mock_session_service.get_session.return_value = mock_session

        with patch('google.adk.events.Event') as mock_event, \
             patch('google.adk.events.EventActions') as mock_actions:

            result = await manager.set_state_value(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                key="new_key",
                value="new_value"
            )

            assert result is True
            mock_actions.assert_called_once_with(state_delta={"new_key": "new_value"})

    # ===== REMOVE STATE KEYS TESTS =====

    @pytest.mark.asyncio
    async def test_remove_state_keys_single_key(self, manager, mock_session_service, mock_session):
        """Test removing a single state key."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'get_session_state') as mock_get_state, \
             patch.object(manager, 'update_session_state') as mock_update:

            mock_get_state.return_value = {"test": "data", "counter": 42}
            mock_update.return_value = True

            result = await manager.remove_state_keys(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                keys="test"
            )

            assert result is True
            mock_update.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                state_updates={"test": None}
            )

    @pytest.mark.asyncio
    async def test_remove_state_keys_multiple_keys(self, manager, mock_session_service, mock_session):
        """Test removing multiple state keys."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'get_session_state') as mock_get_state, \
             patch.object(manager, 'update_session_state') as mock_update:

            mock_get_state.return_value = {"test": "data", "counter": 42, "other": "value"}
            mock_update.return_value = True

            result = await manager.remove_state_keys(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                keys=["test", "counter"]
            )

            assert result is True
            mock_update.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                state_updates={"test": None, "counter": None}
            )

    @pytest.mark.asyncio
    async def test_remove_state_keys_nonexistent_keys(self, manager, mock_session_service, mock_session):
        """Test removing keys that don't exist."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'get_session_state') as mock_get_state, \
             patch.object(manager, 'update_session_state') as mock_update:

            mock_get_state.return_value = {"test": "data"}
            mock_update.return_value = True

            result = await manager.remove_state_keys(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                keys=["nonexistent1", "nonexistent2"]
            )

            assert result is True
            mock_update.assert_not_called()  # No keys to remove

    # ===== CLEAR SESSION STATE TESTS =====

    @pytest.mark.asyncio
    async def test_clear_session_state_all_keys(self, manager, mock_session_service, mock_session):
        """Test clearing all session state."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'get_session_state') as mock_get_state, \
             patch.object(manager, 'remove_state_keys') as mock_remove:

            mock_get_state.return_value = {"test": "data", "counter": 42, "app:setting": "value"}
            mock_remove.return_value = True

            result = await manager.clear_session_state(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user"
            )

            assert result is True
            mock_remove.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                keys=["test", "counter", "app:setting"]
            )

    @pytest.mark.asyncio
    async def test_clear_session_state_preserve_prefixes(self, manager, mock_session_service, mock_session):
        """Test clearing state while preserving certain prefixes."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'get_session_state') as mock_get_state, \
             patch.object(manager, 'remove_state_keys') as mock_remove:

            mock_get_state.return_value = {"test": "data", "counter": 42, "app:setting": "value"}
            mock_remove.return_value = True

            result = await manager.clear_session_state(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                preserve_prefixes=["app:"]
            )

            assert result is True
            mock_remove.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                keys=["test", "counter"]  # app:setting should be preserved
            )

    # ===== INITIALIZE SESSION STATE TESTS =====

    @pytest.mark.asyncio
    async def test_initialize_session_state_new_keys_only(self, manager, mock_session_service, mock_session):
        """Test initializing session state with only new keys."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'get_session_state') as mock_get_state, \
             patch.object(manager, 'update_session_state') as mock_update:

            mock_get_state.return_value = {"existing": "value"}
            mock_update.return_value = True

            initial_state = {"existing": "old_value", "new_key": "new_value"}

            result = await manager.initialize_session_state(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                initial_state=initial_state,
                overwrite_existing=False
            )

            assert result is True
            mock_update.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                state_updates={"new_key": "new_value"}  # Only new keys
            )

    @pytest.mark.asyncio
    async def test_initialize_session_state_overwrite_existing(self, manager, mock_session_service, mock_session):
        """Test initializing session state with overwrite enabled."""
        mock_session_service.get_session.return_value = mock_session

        with patch.object(manager, 'update_session_state') as mock_update:
            mock_update.return_value = True

            initial_state = {"existing": "new_value", "new_key": "new_value"}

            result = await manager.initialize_session_state(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                initial_state=initial_state,
                overwrite_existing=True
            )

            assert result is True
            mock_update.assert_called_once_with(
                session_id="test_session",
                app_name="test_app",
                user_id="test_user",
                state_updates=initial_state  # All keys including existing ones
            )

    # ===== BULK UPDATE USER STATE TESTS =====

    @pytest.mark.asyncio
    async def test_bulk_update_user_state_success(self, manager, mock_session_service):
        """Test bulk updating state for all user sessions."""
        # Set up user sessions
        manager._user_sessions = {
            "test_user": {"app1:session1", "app2:session2"}
        }

        with patch.object(manager, 'update_session_state') as mock_update:
            mock_update.return_value = True

            state_updates = {"bulk_key": "bulk_value"}

            result = await manager.bulk_update_user_state(
                user_id="test_user",
                state_updates=state_updates
            )

            assert result == {"app1:session1": True, "app2:session2": True}
            assert mock_update.call_count == 2

    @pytest.mark.asyncio
    async def test_bulk_update_user_state_with_app_filter(self, manager, mock_session_service):
        """Test bulk updating state with app filter."""
        # Set up user sessions
        manager._user_sessions = {
            "test_user": {"app1:session1", "app2:session2"}
        }

        with patch.object(manager, 'update_session_state') as mock_update:
            mock_update.return_value = True

            state_updates = {"bulk_key": "bulk_value"}

            result = await manager.bulk_update_user_state(
                user_id="test_user",
                state_updates=state_updates,
                app_name_filter="app1"
            )

            assert result == {"app1:session1": True}
            assert mock_update.call_count == 1
            mock_update.assert_called_with(
                session_id="session1",
                app_name="app1",
                user_id="test_user",
                state_updates=state_updates
            )

    @pytest.mark.asyncio
    async def test_bulk_update_user_state_no_sessions(self, manager, mock_session_service):
        """Test bulk updating state when user has no sessions."""
        result = await manager.bulk_update_user_state(
            user_id="nonexistent_user",
            state_updates={"key": "value"}
        )

        assert result == {}

    @pytest.mark.asyncio
    async def test_bulk_update_user_state_mixed_results(self, manager, mock_session_service):
        """Test bulk updating state with mixed success/failure results."""
        # Set up user sessions using a set (to maintain compatibility with implementation)
        # but we'll control the order by using a sorted list for iteration
        from collections import OrderedDict

        # Create an ordered set-like structure
        ordered_sessions = ["app1:session1", "app2:session2"]
        manager._user_sessions = {
            "test_user": set(ordered_sessions)
        }

        with patch.object(manager, 'update_session_state') as mock_update:
            # First call succeeds, second fails
            mock_update.side_effect = [True, False]

            state_updates = {"bulk_key": "bulk_value"}

            result = await manager.bulk_update_user_state(
                user_id="test_user",
                state_updates=state_updates
            )

            # The actual order depends on set iteration, so check both possibilities
            # Either app1 gets True and app2 gets False, or vice versa
            assert len(result) == 2
            assert set(result.values()) == {True, False}  # One succeeded, one failed
            assert mock_update.call_count == 2


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_streaming.py
================================================
#!/usr/bin/env python
"""Test the new streaming behavior with finish_reason detection."""

import asyncio
import logging
from pathlib import Path


from ag_ui_adk import EventTranslator

from unittest.mock import MagicMock

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(message)s')

class MockADKEvent:
    """Mock ADK event for testing."""
    def __init__(self, text_content, finish_reason=None):
        self.content = MagicMock()
        self.content.parts = [MagicMock(text=text_content)]
        self.author = "assistant"
        self.finish_reason = finish_reason  # Keep for test display

        # Mock candidates array for finish_reason detection
        if finish_reason == "STOP":
            self.candidates = [MagicMock(finish_reason="STOP")]
            self.partial = False
            self.turn_complete = True
            self.is_final_response = lambda: True
        else:
            self.candidates = [MagicMock(finish_reason=None)]
            self.partial = True
            self.turn_complete = False
            self.is_final_response = lambda: False

async def test_streaming_behavior():
    """Test that streaming works correctly with finish_reason."""
    print("🧪 Testing Streaming Behavior")
    print("=============================")

    translator = EventTranslator()

    # Simulate a streaming conversation
    adk_events = [
        MockADKEvent("Hello", None),           # First partial
        MockADKEvent(" there", None),          # Second partial
        MockADKEvent(", how", None),           # Third partial
        MockADKEvent(" are you", None),        # Fourth partial
        MockADKEvent(" today?", "STOP"),       # Final partial with STOP
    ]

    print("\n📡 Simulating ADK streaming events:")
    for i, event in enumerate(adk_events):
        print(f"  {i+1}. Text: '{event.content.parts[0].text}', finish_reason: {event.finish_reason}")

    print("\n🔄 Processing through EventTranslator:")
    print("-" * 50)

    all_events = []
    for adk_event in adk_events:
        events = []
        async for ag_ui_event in translator.translate(adk_event, "test_thread", "test_run"):
            events.append(ag_ui_event)
            all_events.append(ag_ui_event)

        print(f"ADK: '{adk_event.content.parts[0].text}' → {len(events)} AG-UI events")

    print("\n📊 Summary of Generated Events:")
    print("-" * 50)

    event_types = [event.type for event in all_events]
    for i, event in enumerate(all_events):
        if hasattr(event, 'delta'):
            print(f"  {i+1}. {event.type} - delta: '{event.delta}'")
        else:
            print(f"  {i+1}. {event.type}")

    # Verify correct sequence - the final event with STOP is skipped to avoid duplication
    # but triggers the END event, so we get 4 content events not 5
    expected_sequence = [
        "TEXT_MESSAGE_START",      # First event starts the message
        "TEXT_MESSAGE_CONTENT",    # Content: "Hello"
        "TEXT_MESSAGE_CONTENT",    # Content: " there"
        "TEXT_MESSAGE_CONTENT",    # Content: ", how"
        "TEXT_MESSAGE_CONTENT",    # Content: " are you"
        "TEXT_MESSAGE_END"         # Final event ends the message (triggered by STOP)
    ]

    # Convert enum types to strings for comparison
    event_type_strings = [str(event_type).split('.')[-1] for event_type in event_types]

    if event_type_strings == expected_sequence:
        print("\n✅ Perfect! Streaming sequence is correct:")
        print("   START → CONTENT → CONTENT → CONTENT → CONTENT → END")
        print("   Final event with STOP correctly triggers END (no duplicate content)")
        return True
    else:
        print(f"\n❌ Incorrect sequence!")
        print(f"   Expected: {expected_sequence}")
        print(f"   Got:      {event_type_strings}")
        return False

async def test_non_streaming():
    """Test that complete messages still work."""
    print("\n🧪 Testing Non-Streaming (Complete Messages)")
    print("============================================")

    translator = EventTranslator()

    # Single complete message - this will be detected as is_final_response=True
    # so it will only generate START and END (no content, content is skipped)
    complete_event = MockADKEvent("Hello, this is a complete message!", "STOP")

    events = []
    async for ag_ui_event in translator.translate(complete_event, "test_thread", "test_run"):
        events.append(ag_ui_event)

    event_types = [event.type for event in events]
    event_type_strings = [str(event_type).split('.')[-1] for event_type in event_types]

    # With a STOP finish_reason, the complete message is skipped to avoid duplication
    # but since there's no prior streaming, we just get END (or nothing if no prior stream)
    expected = ["TEXT_MESSAGE_END"]  # Only END event since is_final_response=True skips content

    if event_type_strings == expected:
        print("✅ Complete messages work correctly: END only (content skipped as final response)")
        return True
    elif len(event_type_strings) == 0:
        print("✅ Complete messages work correctly: No events (final response skipped entirely)")
        return True
    else:
        print(f"❌ Complete message failed: {event_type_strings}")
        return False

if __name__ == "__main__":
    async def run_tests():
        test1 = await test_streaming_behavior()
        test2 = await test_non_streaming()

        if test1 and test2:
            print("\n🎉 All streaming tests passed!")
            print("💡 Ready for real ADK integration with proper streaming")
        else:
            print("\n⚠️ Some tests failed")

    asyncio.run(run_tests())


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_text_events.py
================================================
#!/usr/bin/env python
"""Test text message event patterns and validation."""

import os
import asyncio
from pathlib import Path
from unittest.mock import MagicMock
import pytest

from ag_ui.core import RunAgentInput, UserMessage
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent
from google.genai import types


async def test_message_events():
    """Test that we get proper message events with correct START/CONTENT/END patterns."""

    if not os.getenv("GOOGLE_API_KEY"):
        print("⚠️ GOOGLE_API_KEY not set - using mock test")
        return await test_with_mock()

    print("🧪 Testing with real Google ADK agent...")

    # Create real agent
    agent = Agent(
        name="test_agent",
        instruction="You are a helpful assistant. Keep responses brief."
    )

    # Create middleware with direct agent embedding
    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True,
    )

    # Test input
    test_input = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[
            UserMessage(
                id="msg_1",
                role="user",
                content="Say hello in exactly 3 words."
            )
        ],
        state={},
        context=[],
        tools=[],
        forwarded_props={}
    )

    print("🚀 Running test request...")

    events = []
    text_message_events = []

    try:
        async for event in adk_agent.run(test_input):
            events.append(event)
            event_type = str(event.type)
            print(f"📧 {event_type}")

            # Track text message events specifically
            if "TEXT_MESSAGE" in event_type:
                text_message_events.append(event_type)

    except Exception as e:
        print(f"❌ Error during test: {e}")
        return False

    print(f"\n📊 Results:")
    print(f"   Total events: {len(events)}")
    print(f"   Text message events: {text_message_events}")

    # Analyze message event patterns
    start_count = text_message_events.count("EventType.TEXT_MESSAGE_START")
    end_count = text_message_events.count("EventType.TEXT_MESSAGE_END")
    content_count = text_message_events.count("EventType.TEXT_MESSAGE_CONTENT")

    print(f"   START events: {start_count}")
    print(f"   END events: {end_count}")
    print(f"   CONTENT events: {content_count}")

    return validate_message_event_pattern(start_count, end_count, content_count, text_message_events)


async def test_message_events_from_before_agent_callback():
    """Test that we get proper message events with correct START/CONTENT/END patterns,
    even if we return the message from before_agent_callback.
    """

    if not os.getenv("GOOGLE_API_KEY"):
        print("⚠️ GOOGLE_API_KEY not set - using mock test")
        return await test_with_mock()

    print("🧪 Testing with real Google ADK agent...")

    event_message = "This message was not generated."
    def return_predefined_message(callback_context):
        return types.Content(
            parts=[types.Part(text=event_message)],
            role="model"  # Assign model role to the overriding response
        )

    # Create real agent
    agent = Agent(
        name="test_agent",
        instruction="You are a helpful assistant. Keep responses brief.",
        before_agent_callback=return_predefined_message
    )

    # Create middleware with direct agent embedding
    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True,
    )

    # Test input
    test_input = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[
            UserMessage(
                id="msg_1",
                role="user",
                content="Say hello in exactly 3 words."
            )
        ],
        state={},
        context=[],
        tools=[],
        forwarded_props={}
    )

    print("🚀 Running test request...")

    events = []
    text_message_events = []

    try:
        async for event in adk_agent.run(test_input):
            events.append(event)
            event_type = str(event.type)
            print(f"📧 {event_type}")

            # Track text message events specifically
            if "TEXT_MESSAGE" in event_type:
                text_message_events.append(event_type)

    except Exception as e:
        print(f"❌ Error during test: {e}")
        return False

    print(f"\n📊 Results:")
    print(f"   Total events: {len(events)}")
    print(f"   Text message events: {text_message_events}")

    # Analyze message event patterns
    start_count = text_message_events.count("EventType.TEXT_MESSAGE_START")
    end_count = text_message_events.count("EventType.TEXT_MESSAGE_END")
    content_count = text_message_events.count("EventType.TEXT_MESSAGE_CONTENT")

    print(f"   START events: {start_count}")
    print(f"   END events: {end_count}")
    print(f"   CONTENT events: {content_count}")

    pattern_is_valid = validate_message_event_pattern(start_count, end_count, content_count, text_message_events)
    if not pattern_is_valid:
        return False

    expected_text_events = [
        {
            "type": "EventType.TEXT_MESSAGE_START",
        },
        {
            "type": "EventType.TEXT_MESSAGE_CONTENT",
            "delta": event_message
        },
        {
            "type": "EventType.TEXT_MESSAGE_END",
        }
    ]
    return validate_message_events(events, expected_text_events)


def validate_message_events(events, expected_events):
    """Compare expected events by type and delta (if delta exists)."""
    # Filter events to only those specified in expected_events
    event_types_to_check = {expected["type"] for expected in expected_events}

    filtered_events = []
    for event in events:
        event_type_str = f"EventType.{event.type.value}"
        if event_type_str in event_types_to_check:
            filtered_events.append(event)

    if len(filtered_events) != len(expected_events):
        print(f"❌ Event count mismatch: expected {len(expected_events)}, got {len(filtered_events)}")
        return False

    for i, (event, expected) in enumerate(zip(filtered_events, expected_events)):
        # Check event type
        event_type_str = f"EventType.{event.type.value}"
        if event_type_str != expected["type"]:
            print(f"❌ Event {i}: type mismatch - expected {expected['type']}, got {event_type_str}")
            return False

        # Check delta if specified
        if "delta" in expected:
            if not hasattr(event, 'delta'):
                print(f"❌ Event {i}: expected delta field but event has none")
                return False
            if event.delta != expected["delta"]:
                print(f"❌ Event {i}: delta mismatch - expected '{expected['delta']}', got '{event.delta}'")
                return False

    print("✅ All expected events validated successfully")
    return True


def validate_message_event_pattern(start_count, end_count, content_count, text_message_events):
    """Validate that message events follow proper patterns."""

    # Check if we have any text message events at all
    if start_count == 0 and end_count == 0 and content_count == 0:
        print("⚠️ No text message events found - this may be expected for some responses")
        return True

    # Validate proper message boundaries
    if start_count > 0 or end_count > 0:
        # If we have START/END events, they must be balanced
        if start_count != end_count:
            print(f"❌ Unbalanced START/END events: {start_count} START, {end_count} END")
            return False

        # Each message should have: START -> CONTENT(s) -> END
        if start_count > 0 and content_count == 0:
            print("❌ Messages have START/END but no CONTENT events")
            return False

        # Validate sequence pattern
        if not validate_event_sequence(text_message_events):
            return False

        print(f"✅ Proper message event pattern: {start_count} messages with START/CONTENT/END")
        return True

    elif content_count > 0:
        # Only CONTENT events without START/END is not a valid pattern
        print("❌ Found CONTENT events without proper START/END boundaries")
        print("💡 Message events must have START and END boundaries for proper streaming")
        return False

    else:
        print("⚠️ Unexpected message event pattern")
        return False


def validate_event_sequence(text_message_events):
    """Validate that text message events follow proper START->CONTENT->END sequence."""
    if len(text_message_events) < 2:
        return True  # Too short to validate sequence

    # Check for invalid patterns
    prev_event = None
    for event in text_message_events:
        if event == "EventType.TEXT_MESSAGE_START":
            if prev_event == "EventType.TEXT_MESSAGE_START":
                print("❌ Found START->START pattern (invalid)")
                return False
        elif event == "EventType.TEXT_MESSAGE_END":
            if prev_event == "EventType.TEXT_MESSAGE_END":
                print("❌ Found END->END pattern (invalid)")
                return False
            if prev_event is None:
                print("❌ Found END without preceding START")
                return False

        prev_event = event

    print("✅ Event sequence validation passed")
    return True


async def test_with_mock():
    """Test with mock agent to verify basic structure."""
    print("🧪 Testing with mock agent (no API key)...")

    # Create real agent for structure
    agent = Agent(
        name="mock_test_agent",
        instruction="Mock agent for testing"
    )

    # Create middleware with direct agent embedding
    adk_agent = ADKAgent(
        adk_agent=agent,
        app_name="test_app",
        user_id="test_user",
        use_in_memory_services=True,
    )

    # Mock the runner to control output
    mock_runner = MagicMock()

    # Create mock ADK events that should produce proper START/CONTENT/END pattern
    mock_event_1 = MagicMock()
    mock_event_1.content = MagicMock()
    mock_event_1.content.parts = [MagicMock(text="Hello")]
    mock_event_1.author = "assistant"
    mock_event_1.partial = True
    mock_event_1.turn_complete = False
    mock_event_1.is_final_response = lambda: False
    mock_event_1.candidates = []

    mock_event_2 = MagicMock()
    mock_event_2.content = MagicMock()
    mock_event_2.content.parts = [MagicMock(text=" world")]
    mock_event_2.author = "assistant"
    mock_event_2.partial = True
    mock_event_2.turn_complete = False
    mock_event_2.is_final_response = lambda: False
    mock_event_2.candidates = []

    mock_event_3 = MagicMock()
    mock_event_3.content = MagicMock()
    mock_event_3.content.parts = [MagicMock(text="!")]
    mock_event_3.author = "assistant"
    mock_event_3.partial = False
    mock_event_3.turn_complete = True
    mock_event_3.is_final_response = lambda: True
    mock_event_3.candidates = [MagicMock(finish_reason="STOP")]

    async def mock_run_async(*args, **kwargs):
        yield mock_event_1
        yield mock_event_2
        yield mock_event_3

    mock_runner.run_async = mock_run_async
    adk_agent._get_or_create_runner = MagicMock(return_value=mock_runner)

    # Test input
    test_input = RunAgentInput(
        thread_id="mock_test",
        run_id="mock_run",
        messages=[
            UserMessage(
                id="msg_1",
                role="user",
                content="Test message"
            )
        ],
        state={},
        context=[],
        tools=[],
        forwarded_props={}
    )

    print("🚀 Running mock test...")

    events = []
    text_message_events = []

    try:
        async for event in adk_agent.run(test_input):
            events.append(event)
            event_type = str(event.type)

            # Track text message events specifically
            if "TEXT_MESSAGE" in event_type:
                text_message_events.append(event_type)
                print(f"📧 {event_type}")

    except Exception as e:
        print(f"❌ Error during mock test: {e}")
        return False

    print(f"\n📊 Mock Test Results:")
    print(f"   Total events: {len(events)}")
    print(f"   Text message events: {text_message_events}")

    # Validate the mock results
    start_count = text_message_events.count("EventType.TEXT_MESSAGE_START")
    end_count = text_message_events.count("EventType.TEXT_MESSAGE_END")
    content_count = text_message_events.count("EventType.TEXT_MESSAGE_CONTENT")

    print(f"   START events: {start_count}")
    print(f"   END events: {end_count}")
    print(f"   CONTENT events: {content_count}")

    if validate_message_event_pattern(start_count, end_count, content_count, text_message_events):
        print("✅ Mock test passed - proper event patterns generated")
        return True
    else:
        print("❌ Mock test failed - invalid event patterns")
        return False


async def test_edge_cases():
    """Test edge cases for message event patterns."""
    print("\n🧪 Testing edge cases...")

    # Test 1: Empty response (no text events expected)
    print("📝 Test case: Empty/no-text response")
    # This would simulate a case where agent doesn't produce text output
    text_message_events = []
    result1 = validate_message_event_pattern(0, 0, 0, text_message_events)
    print(f"   Empty response validation: {'✅ PASS' if result1 else '❌ FAIL'}")

    # Test 2: Single complete message
    print("📝 Test case: Single complete message")
    text_message_events = [
        "EventType.TEXT_MESSAGE_START",
        "EventType.TEXT_MESSAGE_CONTENT",
        "EventType.TEXT_MESSAGE_CONTENT",
        "EventType.TEXT_MESSAGE_END"
    ]
    result2 = validate_message_event_pattern(1, 1, 2, text_message_events)
    print(f"   Single message validation: {'✅ PASS' if result2 else '❌ FAIL'}")

    # Test 3: Invalid pattern - only CONTENT
    print("📝 Test case: Invalid pattern (only CONTENT events)")
    text_message_events = [
        "EventType.TEXT_MESSAGE_CONTENT",
        "EventType.TEXT_MESSAGE_CONTENT"
    ]
    result3 = validate_message_event_pattern(0, 0, 2, text_message_events)
    # This should fail
    print(f"   Content-only validation: {'✅ PASS (correctly rejected)' if not result3 else '❌ FAIL (should have been rejected)'}")

    # Test 4: Invalid pattern - unbalanced START/END
    print("📝 Test case: Invalid pattern (unbalanced START/END)")
    text_message_events = [
        "EventType.TEXT_MESSAGE_START",
        "EventType.TEXT_MESSAGE_CONTENT",
        "EventType.TEXT_MESSAGE_START"  # Missing END for first message
    ]
    result4 = validate_message_event_pattern(2, 0, 1, text_message_events)
    # This should fail
    print(f"   Unbalanced validation: {'✅ PASS (correctly rejected)' if not result4 else '❌ FAIL (should have been rejected)'}")

    # Return overall result
    return result1 and result2 and not result3 and not result4


@pytest.mark.asyncio
async def test_text_message_events():
    """Test that we get proper message events with correct START/CONTENT/END patterns."""
    result = await test_message_events()
    assert result, "Text message events test failed"


@pytest.mark.asyncio
async def test_text_message_events_from_before_agent_callback():
    """Test that we get proper message events with correct START/CONTENT/END patterns."""
    result = await test_message_events_from_before_agent_callback()
    assert result, "Text message events for before_agent_callback test failed"


@pytest.mark.asyncio
async def test_message_event_edge_cases():
    """Test edge cases for message event patterns."""
    result = await test_edge_cases()
    assert result, "Message event edge cases test failed"


# Keep the standalone script functionality for backwards compatibility
async def main():
    """Run all text message event tests."""
    print("🚀 Testing Text Message Event Patterns")
    print("=" * 45)

    tests = [
        ("Message Events", test_message_events),
        ("Edge Cases", test_edge_cases)
    ]

    results = []
    for test_name, test_func in tests:
        try:
            result = await test_func()
            results.append(result)
        except Exception as e:
            print(f"❌ Test {test_name} failed with exception: {e}")
            import traceback
            traceback.print_exc()
            results.append(False)

    print("\n" + "=" * 45)
    print("📊 Test Results:")

    for i, (test_name, result) in enumerate(zip([name for name, _ in tests], results), 1):
        status = "✅ PASS" if result else "❌ FAIL"
        print(f"  {i}. {test_name}: {status}")

    passed = sum(results)
    total = len(results)

    if passed == total:
        print(f"\n🎉 All {total} text message event tests passed!")
        print("💡 Text message event patterns are working correctly")
    else:
        print(f"\n⚠️ {passed}/{total} tests passed")
        print("🔧 Review text message event implementation")

    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
    import sys
    sys.exit(0 if success else 1)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_tool_error_handling.py
================================================
#!/usr/bin/env python
"""Test error handling scenarios in tool flows."""

import pytest
import asyncio
import json
from unittest.mock import AsyncMock, MagicMock, patch

from ag_ui.core import (
    RunAgentInput, BaseEvent, EventType, Tool as AGUITool,
    UserMessage, ToolMessage, RunStartedEvent, RunErrorEvent, RunFinishedEvent,
    ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent
)

from ag_ui_adk import ADKAgent
from ag_ui_adk.execution_state import ExecutionState
from ag_ui_adk.client_proxy_tool import ClientProxyTool
from ag_ui_adk.client_proxy_toolset import ClientProxyToolset


class TestToolErrorHandling:
    """Test cases for various tool error scenarios."""


    @pytest.fixture
    def mock_adk_agent(self):
        """Create a mock ADK agent."""
        from google.adk.agents import LlmAgent
        return LlmAgent(
            name="test_agent",
            model="gemini-2.0-flash",
            instruction="Test agent for error testing"
        )

    @pytest.fixture
    def adk_middleware(self, mock_adk_agent):
        """Create ADK middleware."""
        return ADKAgent(
            adk_agent=mock_adk_agent,
            user_id="test_user",
            execution_timeout_seconds=60,
            tool_timeout_seconds=30,
            max_concurrent_executions=5
        )

    @pytest.fixture
    def sample_tool(self):
        """Create a sample tool definition."""
        return AGUITool(
            name="error_prone_tool",
            description="A tool that might encounter various errors",
            parameters={
                "type": "object",
                "properties": {
                    "action": {"type": "string"},
                    "data": {"type": "string"}
                },
                "required": ["action"]
            }
        )

    @pytest.mark.asyncio
    async def test_adk_execution_error_during_tool_run(self, adk_middleware, sample_tool):
        """Test error handling when ADK execution fails during tool usage."""
        # Test that the system gracefully handles exceptions from background execution
        async def failing_adk_execution(*_args, **_kwargs):
            raise Exception("ADK execution failed unexpectedly")

        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=failing_adk_execution):
            input_data = RunAgentInput(
                thread_id="test_thread", run_id="run_1",
                messages=[UserMessage(id="1", role="user", content="Use the error prone tool")],
                tools=[sample_tool], context=[], state={}, forwarded_props={}
            )

            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Should get at least a run started event
            assert len(events) >= 1
            assert isinstance(events[0], RunStartedEvent)

            # The exception should be caught and handled (not crash the system)
            # The actual error events depend on the error handling implementation

    @pytest.mark.asyncio
    async def test_tool_result_parsing_error(self, adk_middleware, sample_tool):
        """Test error handling when tool result cannot be parsed."""
        # Create an execution with a pending tool
        mock_task = MagicMock()
        mock_task.done.return_value = False
        event_queue = asyncio.Queue()

        execution = ExecutionState(
            task=mock_task,
            thread_id="test_thread",
            event_queue=event_queue
        )

        # Add to active executions
        adk_middleware._active_executions["test_thread"] = execution

        # Submit invalid JSON as tool result
        input_data = RunAgentInput(
            thread_id="test_thread", run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Test"),
                ToolMessage(
                    id="2",
                    role="tool",
                    tool_call_id="call_1",
                    content="{ invalid json syntax"  # Malformed JSON
                )
            ],
            tools=[sample_tool], context=[], state={}, forwarded_props={}
        )

        # Mock _stream_events to avoid hanging on empty queue
        async def mock_stream_events(execution):
            # Return empty - no events from execution
            return
            yield  # Make it a generator

        with patch.object(adk_middleware, '_stream_events', side_effect=mock_stream_events):
            events = []
            async for event in adk_middleware._handle_tool_result_submission(input_data):
                events.append(event)

            # In the all-long-running architecture, tool results always start new executions
            # Should get RUN_STARTED and RUN_FINISHED events (malformed JSON is handled gracefully)
            assert len(events) == 2
            assert events[0].type == EventType.RUN_STARTED
            assert events[1].type == EventType.RUN_FINISHED

    @pytest.mark.asyncio
    async def test_tool_result_for_nonexistent_call(self, adk_middleware, sample_tool):
        """Test error handling when tool result is for non-existent call."""
        # Create an execution without the expected tool call
        mock_task = MagicMock()
        mock_task.done.return_value = False
        event_queue = asyncio.Queue()

        execution = ExecutionState(
            task=mock_task,
            thread_id="test_thread",
            event_queue=event_queue
        )

        adk_middleware._active_executions["test_thread"] = execution

        # Submit tool result for non-existent call
        input_data = RunAgentInput(
            thread_id="test_thread", run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Test"),
                ToolMessage(
                    id="2",
                    role="tool",
                    tool_call_id="nonexistent_call",
                    content='{"result": "some result"}'
                )
            ],
            tools=[sample_tool], context=[], state={}, forwarded_props={}
        )

        # Mock _stream_events to avoid hanging on empty queue
        async def mock_stream_events(execution):
            # Return empty - no events from execution
            return
            yield  # Make it a generator

        with patch.object(adk_middleware, '_stream_events', side_effect=mock_stream_events):
            events = []
            async for event in adk_middleware._handle_tool_result_submission(input_data):
                events.append(event)

            # The system logs warnings but may not emit error events for unknown tool calls
            # Just check that it doesn't crash the system
            assert len(events) >= 0  # Should not crash

    @pytest.mark.asyncio
    async def test_toolset_creation_error(self, adk_middleware):
        """Test error handling when toolset creation fails."""
        # Create invalid tool definition
        invalid_tool = AGUITool(
            name="",  # Invalid empty name
            description="Invalid tool",
            parameters={"invalid": "schema"}  # Invalid schema
        )

        # Simply test that invalid tools don't crash the system
        async def mock_adk_execution(*_args, **_kwargs):
            raise Exception("Failed to create toolset with invalid tool")

        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=mock_adk_execution):
            input_data = RunAgentInput(
                thread_id="test_thread", run_id="run_1",
                messages=[UserMessage(id="1", role="user", content="Test")],
                tools=[invalid_tool], context=[], state={}, forwarded_props={}
            )

            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Should handle the error gracefully without crashing
            assert len(events) >= 1
            assert isinstance(events[0], RunStartedEvent)

    @pytest.mark.asyncio
    async def test_tool_timeout_during_execution(self, sample_tool):
        """Test that tool timeouts are properly handled."""
        event_queue = AsyncMock()

        # Create proxy tool
        proxy_tool = ClientProxyTool(
            ag_ui_tool=sample_tool,
            event_queue=event_queue
        )

        args = {"action": "slow_action"}
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        # In all-long-running architecture, tools return None immediately
        result = await proxy_tool.run_async(args=args, tool_context=mock_context)

        # Should return None (long-running behavior)
        assert result is None

    @pytest.mark.asyncio
    async def test_execution_state_error_handling(self):
        """Test ExecutionState error handling methods."""
        mock_task = MagicMock()
        mock_task.done.return_value = False  # Ensure it returns False for "running" status
        event_queue = asyncio.Queue()

        execution = ExecutionState(
            task=mock_task,
            thread_id="test_thread",
            event_queue=event_queue
        )

        # Test basic execution state functionality
        assert execution.thread_id == "test_thread"
        assert execution.task == mock_task
        assert execution.event_queue == event_queue
        assert execution.is_complete is False

        # Test status reporting
        assert execution.get_status() == "running"

    @pytest.mark.asyncio
    async def test_multiple_tool_errors_handling(self, adk_middleware, sample_tool):
        """Test handling multiple tool errors in sequence."""
        # Create execution with multiple pending tools
        mock_task = MagicMock()
        mock_task.done.return_value = False  # Ensure it returns False for "running" status
        event_queue = asyncio.Queue()

        execution = ExecutionState(
            task=mock_task,
            thread_id="test_thread",
            event_queue=event_queue
        )

        adk_middleware._active_executions["test_thread"] = execution

        # Submit results for both - one valid, one invalid
        input_data = RunAgentInput(
            thread_id="test_thread", run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Test"),
                ToolMessage(id="2", role="tool", tool_call_id="call_1", content='{"valid": "result"}'),
                ToolMessage(id="3", role="tool", tool_call_id="call_2", content='{ invalid json')
            ],
            tools=[sample_tool], context=[], state={}, forwarded_props={}
        )

        # Mock _stream_events to avoid hanging on empty queue
        async def mock_stream_events(execution):
            # Return empty - no events from execution
            return
            yield  # Make it a generator

        with patch.object(adk_middleware, '_stream_events', side_effect=mock_stream_events):
            events = []
            async for event in adk_middleware._handle_tool_result_submission(input_data):
                events.append(event)

            # In all-long-running architecture, tool results always start new executions
            # Should get RUN_STARTED and RUN_FINISHED events (only most recent tool result processed)
            assert len(events) == 2
            assert events[0].type == EventType.RUN_STARTED
            assert events[1].type == EventType.RUN_FINISHED

    @pytest.mark.asyncio
    async def test_execution_cleanup_on_error(self, adk_middleware, sample_tool):
        """Test that executions are properly cleaned up when errors occur."""
        async def error_adk_execution(*_args, **_kwargs):
            raise Exception("Critical ADK error")

        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=error_adk_execution):
            input_data = RunAgentInput(
                thread_id="test_thread", run_id="run_1",
                messages=[UserMessage(id="1", role="user", content="Test")],
                tools=[sample_tool], context=[], state={}, forwarded_props={}
            )

            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Should handle the error gracefully
            assert len(events) >= 1
            assert isinstance(events[0], RunStartedEvent)

            # System should handle the error without crashing

    @pytest.mark.asyncio
    async def test_toolset_close_error_handling(self):
        """Test error handling during toolset close operations."""
        event_queue = AsyncMock()

        # Create a sample tool for the toolset
        sample_tool = AGUITool(
            name="test_tool",
            description="A test tool",
            parameters={"type": "object", "properties": {}}
        )

        toolset = ClientProxyToolset(
            ag_ui_tools=[sample_tool],
            event_queue=event_queue
        )

        # Close should handle the exception gracefully
        try:
            await toolset.close()
        except Exception:
            # If the mock exception propagates, that's fine for this test
            pass

        # The exception might prevent full cleanup, so just verify close was attempted
        # and didn't crash the system completely
        assert True  # If we get here, close didn't crash

    @pytest.mark.asyncio
    async def test_event_queue_error_during_tool_call_long_running(self, sample_tool):
        """Test error handling when event queue operations fail (long-running tool)."""
        # Create a mock event queue that fails
        event_queue = AsyncMock()
        event_queue.put.side_effect = Exception("Queue operation failed")

        proxy_tool = ClientProxyTool(
            ag_ui_tool=sample_tool,
            event_queue=event_queue
        )

        args = {"action": "test"}
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        # Should handle queue errors gracefully
        with pytest.raises(Exception) as exc_info:
            await proxy_tool.run_async(args=args, tool_context=mock_context)

        assert "Queue operation failed" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_event_queue_error_during_tool_call_blocking(self, sample_tool):
        """Test error handling when event queue operations fail (blocking tool)."""
        # Create a mock event queue that fails
        event_queue = AsyncMock()
        event_queue.put.side_effect = Exception("Queue operation failed")

        proxy_tool = ClientProxyTool(
            ag_ui_tool=sample_tool,
            event_queue=event_queue
        )

        args = {"action": "test"}
        mock_context = MagicMock()
        mock_context.function_call_id = "test_function_call_id"

        # Should handle queue errors gracefully
        with pytest.raises(Exception) as exc_info:
            await proxy_tool.run_async(args=args, tool_context=mock_context)

        assert "Queue operation failed" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_concurrent_tool_errors(self, adk_middleware, sample_tool):
        """Test handling errors when multiple tools fail concurrently."""
        # Create execution with multiple tools
        # Create a real asyncio task for proper cancellation testing
        async def dummy_task():
            await asyncio.sleep(10)  # Long running task

        real_task = asyncio.create_task(dummy_task())
        event_queue = asyncio.Queue()

        execution = ExecutionState(
            task=real_task,
            thread_id="test_thread",
            event_queue=event_queue
        )

        adk_middleware._active_executions["test_thread"] = execution

        # Test concurrent execution state management
        # In the all-long-running architecture, we don't track individual tool futures
        # Instead, we test basic execution state properties
        assert execution.thread_id == "test_thread"
        assert execution.get_status() == "running"
        assert execution.is_complete is False

        # Test that execution can be cancelled
        await execution.cancel()
        assert execution.is_complete is True

    @pytest.mark.asyncio
    async def test_malformed_tool_message_handling(self, adk_middleware, sample_tool):
        """Test handling of malformed tool messages."""
        mock_task = MagicMock()
        mock_task.done.return_value = False
        event_queue = asyncio.Queue()

        execution = ExecutionState(
            task=mock_task,
            thread_id="test_thread",
            event_queue=event_queue
        )

        adk_middleware._active_executions["test_thread"] = execution

        # Submit tool message with empty content (which should be handled gracefully)
        input_data = RunAgentInput(
            thread_id="test_thread", run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Test"),
                ToolMessage(
                    id="2",
                    role="tool",
                    tool_call_id="call_1",
                    content=""  # Empty content instead of None
                )
            ],
            tools=[sample_tool], context=[], state={}, forwarded_props={}
        )

        # Mock _stream_events to avoid hanging on empty queue
        async def mock_stream_events(execution):
            # Return empty - no events from execution
            return
            yield  # Make it a generator

        with patch.object(adk_middleware, '_stream_events', side_effect=mock_stream_events):
            events = []
            async for event in adk_middleware._handle_tool_result_submission(input_data):
                events.append(event)

            # In all-long-running architecture, tool results always start new executions
            # Should get RUN_STARTED and RUN_FINISHED events (empty content handled gracefully)
            assert len(events) == 2
            assert events[0].type == EventType.RUN_STARTED
            assert events[1].type == EventType.RUN_FINISHED

    @pytest.mark.asyncio
    async def test_json_parsing_in_tool_result_submission(self, adk_middleware, sample_tool):
        """Test that JSON parsing errors in tool results are handled gracefully."""
        # Test with empty content
        input_empty = RunAgentInput(
            thread_id="test_thread",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Test"),
                ToolMessage(
                    id="2",
                    role="tool",
                    tool_call_id="call_1",
                    content=""  # Empty content
                )
            ],
            tools=[sample_tool],
            context=[],
            state={},
            forwarded_props={}
        )

        # This should not raise a JSONDecodeError
        events = []
        try:
            async for event in adk_middleware.run(input_empty):
                events.append(event)
                if len(events) >= 5:  # Limit to avoid infinite loop
                    break
        except json.JSONDecodeError:
            pytest.fail("JSONDecodeError should not be raised for empty tool content")
        except Exception:
            # Other exceptions are expected (e.g., from ADK library)
            pass

        # Test with invalid JSON
        input_invalid = RunAgentInput(
            thread_id="test_thread2",
            run_id="run_2",
            messages=[
                UserMessage(id="1", role="user", content="Test"),
                ToolMessage(
                    id="2",
                    role="tool",
                    tool_call_id="call_2",
                    content="{ invalid json"  # Invalid JSON
                )
            ],
            tools=[sample_tool],
            context=[],
            state={},
            forwarded_props={}
        )

        # This should not raise a JSONDecodeError
        events = []
        try:
            async for event in adk_middleware.run(input_invalid):
                events.append(event)
                if len(events) >= 5:  # Limit to avoid infinite loop
                    break
        except json.JSONDecodeError:
            pytest.fail("JSONDecodeError should not be raised for invalid JSON tool content")
        except Exception:
            # Other exceptions are expected (e.g., from ADK library)
            pass


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_tool_result_flow.py
================================================
#!/usr/bin/env python
"""Test tool result submission flow in ADKAgent."""

import pytest
import asyncio
import json
from unittest.mock import AsyncMock, MagicMock, patch

from ag_ui.core import (
    RunAgentInput, BaseEvent, EventType, Tool as AGUITool,
    UserMessage, ToolMessage, RunStartedEvent, RunFinishedEvent, RunErrorEvent
)

from ag_ui_adk import ADKAgent


class TestToolResultFlow:
    """Test cases for tool result submission flow."""


    @pytest.fixture
    def sample_tool(self):
        """Create a sample tool definition."""
        return AGUITool(
            name="test_tool",
            description="A test tool",
            parameters={
                "type": "object",
                "properties": {
                    "input": {"type": "string"}
                }
            }
        )

    @pytest.fixture
    def mock_adk_agent(self):
        """Create a mock ADK agent."""
        from google.adk.agents import LlmAgent
        return LlmAgent(
            name="test_agent",
            model="gemini-2.0-flash",
            instruction="Test agent for tool flow testing"
        )

    @pytest.fixture
    def ag_ui_adk(self, mock_adk_agent):
        """Create ADK middleware with mocked dependencies."""
        return ADKAgent(
            adk_agent=mock_adk_agent,
            user_id="test_user",
            execution_timeout_seconds=60,
            tool_timeout_seconds=30
        )

    def test_is_tool_result_submission_with_tool_message(self, ag_ui_adk):
        """Test detection of tool result submission."""
        # Input with tool message as last message
        input_with_tool = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Do something"),
                ToolMessage(id="2", role="tool", content='{"result": "success"}', tool_call_id="call_1")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        assert ag_ui_adk._is_tool_result_submission(input_with_tool) is True

    def test_is_tool_result_submission_with_user_message(self, ag_ui_adk):
        """Test detection when last message is not a tool result."""
        # Input with user message as last message
        input_without_tool = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello"),
                UserMessage(id="2", role="user", content="How are you?")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        assert ag_ui_adk._is_tool_result_submission(input_without_tool) is False

    def test_is_tool_result_submission_empty_messages(self, ag_ui_adk):
        """Test detection with empty messages."""
        empty_input = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        assert ag_ui_adk._is_tool_result_submission(empty_input) is False

    @pytest.mark.asyncio
    async def test_extract_tool_results_single_tool(self, ag_ui_adk):
        """Test extraction of single tool result."""
        input_data = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello"),
                ToolMessage(id="2", role="tool", content='{"result": "success"}', tool_call_id="call_1")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        tool_results = await ag_ui_adk._extract_tool_results(input_data)

        assert len(tool_results) == 1
        assert tool_results[0]['message'].role == "tool"
        assert tool_results[0]['message'].tool_call_id == "call_1"
        assert tool_results[0]['message'].content == '{"result": "success"}'
        assert tool_results[0]['tool_name'] == "unknown"  # No tool_calls in messages

    @pytest.mark.asyncio
    async def test_extract_tool_results_multiple_tools(self, ag_ui_adk):
        """Test extraction of most recent tool result when multiple exist."""
        input_data = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello"),
                ToolMessage(id="2", role="tool", content='{"result": "first"}', tool_call_id="call_1"),
                ToolMessage(id="3", role="tool", content='{"result": "second"}', tool_call_id="call_2")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        tool_results = await ag_ui_adk._extract_tool_results(input_data)

        # Should only extract the most recent tool result to prevent API errors
        assert len(tool_results) == 1
        assert tool_results[0]['message'].tool_call_id == "call_2"
        assert tool_results[0]['message'].content == '{"result": "second"}'

    @pytest.mark.asyncio
    async def test_extract_tool_results_mixed_messages(self, ag_ui_adk):
        """Test extraction when mixed with other message types."""
        input_data = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello"),
                ToolMessage(id="2", role="tool", content='{"result": "success"}', tool_call_id="call_1"),
                UserMessage(id="3", role="user", content="Thanks"),
                ToolMessage(id="4", role="tool", content='{"result": "done"}', tool_call_id="call_2")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        tool_results = await ag_ui_adk._extract_tool_results(input_data)

        # Should only extract the most recent tool message to prevent API errors
        assert len(tool_results) == 1
        assert tool_results[0]['message'].role == "tool"
        assert tool_results[0]['message'].tool_call_id == "call_2"
        assert tool_results[0]['message'].content == '{"result": "done"}'

    @pytest.mark.asyncio
    async def test_handle_tool_result_submission_no_active_execution(self, ag_ui_adk):
        """Test handling tool result when no active execution exists."""
        input_data = RunAgentInput(
            thread_id="nonexistent_thread",
            run_id="run_1",
            messages=[
                ToolMessage(id="1", role="tool", content='{"result": "success"}', tool_call_id="call_1")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        events = []
        async for event in ag_ui_adk._handle_tool_result_submission(input_data):
            events.append(event)

        # In all-long-running architecture, tool results without active execution
        # are treated as standalone results from LongRunningTools and start new executions
        # However, ADK may error if there's no conversation history for the tool result
        assert len(events) >= 1  # At least RUN_STARTED, potentially RUN_ERROR and RUN_FINISHED

    @pytest.mark.asyncio
    async def test_handle_tool_result_submission_no_active_execution_no_tools(self, ag_ui_adk):
        """Test handling tool result when no tool results exist."""
        input_data = RunAgentInput(
            thread_id="nonexistent_thread",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello")  # No tool messages
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        events = []
        async for event in ag_ui_adk._handle_tool_result_submission(input_data):
            events.append(event)

        # When there are no tool results, should emit error for missing tool results
        assert len(events) == 1
        assert isinstance(events[0], RunErrorEvent)
        assert events[0].code == "NO_TOOL_RESULTS"
        assert "No tool results found in submission" in events[0].message

    @pytest.mark.asyncio
    async def test_handle_tool_result_submission_with_active_execution(self, ag_ui_adk):
        """Test handling tool result - starts new execution regardless of existing executions."""
        thread_id = "test_thread"

        # Mock the _stream_events method to simulate new execution
        mock_events = [
            MagicMock(type=EventType.TEXT_MESSAGE_CONTENT),
            MagicMock(type=EventType.TEXT_MESSAGE_END)
        ]

        async def mock_stream_events(execution):
            for event in mock_events:
                yield event

        with patch.object(ag_ui_adk, '_stream_events', side_effect=mock_stream_events):
            input_data = RunAgentInput(
                thread_id=thread_id,
                run_id="run_1",
                messages=[
                    ToolMessage(id="1", role="tool", content='{"result": "success"}', tool_call_id="call_1")
                ],
                tools=[],
                context=[],
                state={},
                forwarded_props={}
            )

            events = []
            async for event in ag_ui_adk._handle_tool_result_submission(input_data):
                events.append(event)

            # Should receive RUN_STARTED + mock events + RUN_FINISHED (4 total)
            assert len(events) == 4
            assert events[0].type == EventType.RUN_STARTED
            assert events[-1].type == EventType.RUN_FINISHED
            # In all-long-running architecture, tool results start new executions

    @pytest.mark.asyncio
    async def test_handle_tool_result_submission_streaming_error(self, ag_ui_adk):
        """Test handling when streaming events fails."""
        thread_id = "test_thread"

        # Mock _stream_events to raise an exception
        async def mock_stream_events(execution):
            raise RuntimeError("Streaming failed")
            yield  # Make it a generator

        with patch.object(ag_ui_adk, '_stream_events', side_effect=mock_stream_events):
            input_data = RunAgentInput(
                thread_id=thread_id,
                run_id="run_1",
                messages=[
                    ToolMessage(id="1", role="tool", content='{"result": "success"}', tool_call_id="call_1")
                ],
                tools=[],
                context=[],
                state={},
                forwarded_props={}
            )

            events = []
            async for event in ag_ui_adk._handle_tool_result_submission(input_data):
                events.append(event)

            # Should emit RUN_STARTED then error event when streaming fails
            assert len(events) == 2
            assert events[0].type == EventType.RUN_STARTED
            assert isinstance(events[1], RunErrorEvent)
            assert events[1].code == "EXECUTION_ERROR"
            assert "Streaming failed" in events[1].message

    @pytest.mark.asyncio
    async def test_handle_tool_result_submission_invalid_json(self, ag_ui_adk):
        """Test handling tool result with invalid JSON content."""
        thread_id = "test_thread"

        input_data = RunAgentInput(
            thread_id=thread_id,
            run_id="run_1",
            messages=[
                ToolMessage(id="1", role="tool", content='invalid json{', tool_call_id="call_1")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        events = []
        async for event in ag_ui_adk._handle_tool_result_submission(input_data):
            events.append(event)

        # Should start new execution, handle invalid JSON gracefully, and complete
        # Invalid JSON is handled gracefully in _run_adk_in_background by providing error result
        assert len(events) >= 2  # At least RUN_STARTED and some completion
        assert events[0].type == EventType.RUN_STARTED

    @pytest.mark.asyncio
    async def test_handle_tool_result_submission_multiple_results(self, ag_ui_adk):
        """Test handling multiple tool results in one submission - only most recent is extracted."""
        thread_id = "test_thread"

        input_data = RunAgentInput(
            thread_id=thread_id,
            run_id="run_1",
            messages=[
                ToolMessage(id="1", role="tool", content='{"result": "first"}', tool_call_id="call_1"),
                ToolMessage(id="2", role="tool", content='{"result": "second"}', tool_call_id="call_2")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        # Should extract only the most recent tool result to prevent API errors
        tool_results = await ag_ui_adk._extract_tool_results(input_data)
        assert len(tool_results) == 1
        assert tool_results[0]['message'].tool_call_id == "call_2"
        assert tool_results[0]['message'].content == '{"result": "second"}'

    @pytest.mark.asyncio
    async def test_tool_result_flow_integration(self, ag_ui_adk):
        """Test complete tool result flow through run method."""
        # First, simulate a request that would create an execution
        # (This is complex to mock fully, so we test the routing logic)

        # Test tool result routing
        tool_result_input = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                ToolMessage(id="1", role="tool", content='{"result": "success"}', tool_call_id="call_1")
            ],
            tools=[],
            context=[],
            state={},
            forwarded_props={}
        )

        # In the all-long-running architecture, tool result inputs are processed as new executions
        # Mock the background execution to avoid ADK library errors
        async def mock_start_new_execution(input_data):
            yield RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            )
            # In all-long-running architecture, tool results are processed through ADK sessions
            yield RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            )

        with patch.object(ag_ui_adk, '_start_new_execution', side_effect=mock_start_new_execution):
            events = []
            async for event in ag_ui_adk.run(tool_result_input):
                events.append(event)

            # Should get RUN_STARTED and RUN_FINISHED events
            assert len(events) == 2
            assert events[0].type == EventType.RUN_STARTED
            assert events[1].type == EventType.RUN_FINISHED

    @pytest.mark.asyncio
    async def test_new_execution_routing(self, ag_ui_adk, sample_tool):
        """Test that non-tool messages route to new execution."""
        new_request_input = RunAgentInput(
            thread_id="thread_1",
            run_id="run_1",
            messages=[
                UserMessage(id="1", role="user", content="Hello")
            ],
            tools=[sample_tool],
            context=[],
            state={},
            forwarded_props={}
        )

        # Mock the _start_new_execution method
        mock_events = [
            RunStartedEvent(type=EventType.RUN_STARTED, thread_id="thread_1", run_id="run_1"),
            RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id="thread_1", run_id="run_1")
        ]

        async def mock_start_new_execution(input_data):
            for event in mock_events:
                yield event

        with patch.object(ag_ui_adk, '_start_new_execution', side_effect=mock_start_new_execution):
            events = []
            async for event in ag_ui_adk.run(new_request_input):
                events.append(event)

            assert len(events) == 2
            assert isinstance(events[0], RunStartedEvent)
            assert isinstance(events[1], RunFinishedEvent)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_tool_tracking_hitl.py
================================================
#!/usr/bin/env python
"""Test HITL tool call tracking functionality."""

import pytest
import asyncio
from unittest.mock import MagicMock, AsyncMock, patch

from ag_ui.core import (
    RunAgentInput, UserMessage, Tool as AGUITool,
    ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent,
    RunStartedEvent, RunFinishedEvent, EventType
)

from ag_ui_adk import ADKAgent
from ag_ui_adk.execution_state import ExecutionState


class TestHITLToolTracking:
    """Test cases for HITL tool call tracking."""

    @pytest.fixture(autouse=True)
    def reset_session_manager(self):
        """Reset session manager before each test."""
        from ag_ui_adk.session_manager import SessionManager
        SessionManager.reset_instance()
        yield
        SessionManager.reset_instance()

    @pytest.fixture
    def mock_adk_agent(self):
        """Create a mock ADK agent."""
        from google.adk.agents import LlmAgent
        return LlmAgent(
            name="test_agent",
            model="gemini-2.0-flash",
            instruction="Test agent"
        )

    @pytest.fixture
    def adk_middleware(self, mock_adk_agent):
        """Create ADK middleware."""
        return ADKAgent(
            adk_agent=mock_adk_agent,
            app_name="test_app",
            user_id="test_user"
        )

    @pytest.fixture
    def sample_tool(self):
        """Create a sample tool."""
        return AGUITool(
            name="test_tool",
            description="A test tool",
            parameters={
                "type": "object",
                "properties": {
                    "param": {"type": "string"}
                }
            }
        )

    @pytest.mark.asyncio
    async def test_tool_call_tracking(self, adk_middleware, sample_tool):
        """Test that tool calls are tracked in session state."""
        # Create input
        input_data = RunAgentInput(
            thread_id="test_thread",
            run_id="run_1",
            messages=[UserMessage(id="1", role="user", content="Test")],
            tools=[sample_tool],
            context=[],
            state={},
            forwarded_props={}
        )

        # Ensure session exists first
        await adk_middleware._ensure_session_exists(
            app_name="test_app",
            user_id="test_user",
            session_id="test_thread",
            initial_state={}
        )

        # Mock background execution to emit tool events
        async def mock_run_adk_in_background(*args, **kwargs):
            event_queue = kwargs['event_queue']

            # Emit some events including a tool call
            await event_queue.put(RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id="test_thread",
                run_id="run_1"
            ))

            # Emit tool call events
            tool_call_id = "test_tool_call_123"
            await event_queue.put(ToolCallStartEvent(
                type=EventType.TOOL_CALL_START,
                tool_call_id=tool_call_id,
                tool_call_name="test_tool"
            ))
            await event_queue.put(ToolCallArgsEvent(
                type=EventType.TOOL_CALL_ARGS,
                tool_call_id=tool_call_id,
                delta='{"param": "value"}'
            ))
            await event_queue.put(ToolCallEndEvent(
                type=EventType.TOOL_CALL_END,
                tool_call_id=tool_call_id
            ))

            # Signal completion
            await event_queue.put(None)

        # Use the mock
        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=mock_run_adk_in_background):
            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Verify events were emitted
            assert any(isinstance(e, ToolCallEndEvent) for e in events)

            # Check if tool call was tracked
            has_pending = await adk_middleware._has_pending_tool_calls("test_thread")
            assert has_pending, "Tool call should be tracked as pending"

            # Verify session state contains the tool call
            session = await adk_middleware._session_manager._session_service.get_session(
                session_id="test_thread",
                app_name="test_app",
                user_id="test_user"
            )
            assert session is not None
            assert session.state is not None
            assert "pending_tool_calls" in session.state
            assert "test_tool_call_123" in session.state["pending_tool_calls"]

    @pytest.mark.asyncio
    async def test_execution_not_cleaned_up_with_pending_tools(self, adk_middleware, sample_tool):
        """Test that executions with pending tool calls are not cleaned up."""
        # Create input
        input_data = RunAgentInput(
            thread_id="test_thread",
            run_id="run_1",
            messages=[UserMessage(id="1", role="user", content="Test")],
            tools=[sample_tool],
            context=[],
            state={},
            forwarded_props={}
        )

        # Ensure session exists first
        await adk_middleware._ensure_session_exists(
            app_name="test_app",
            user_id="test_user",
            session_id="test_thread",
            initial_state={}
        )

        # Mock background execution to emit tool events
        async def mock_run_adk_in_background(*args, **kwargs):
            event_queue = kwargs['event_queue']

            # Emit tool call events
            tool_call_id = "test_tool_call_456"
            await event_queue.put(ToolCallEndEvent(
                type=EventType.TOOL_CALL_END,
                tool_call_id=tool_call_id
            ))

            # Signal completion
            await event_queue.put(None)

        # Use the mock
        with patch.object(adk_middleware, '_run_adk_in_background', side_effect=mock_run_adk_in_background):
            events = []
            async for event in adk_middleware._start_new_execution(input_data):
                events.append(event)

            # Execution should NOT be cleaned up due to pending tool call
            assert "test_thread" in adk_middleware._active_executions
            execution = adk_middleware._active_executions["test_thread"]
            assert execution.is_complete


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_user_id_extractor.py
================================================
#!/usr/bin/env python
"""Test user_id_extractor functionality."""

from ag_ui.core import RunAgentInput, UserMessage
from ag_ui_adk import ADKAgent
from google.adk.agents import Agent



def test_static_user_id():
    """Test static user ID configuration."""
    print("🧪 Testing static user ID...")

    # Create a test ADK agent
    test_agent = Agent(name="test_agent", instruction="You are a test agent.")

    agent = ADKAgent(adk_agent=test_agent, app_name="test_app", user_id="static_test_user")

    # Create test input
    test_input = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        context=[],
        state={},
        tools=[],
        forwarded_props={}
    )

    user_id = agent._get_user_id(test_input)
    print(f"   User ID: {user_id}")

    assert user_id == "static_test_user", f"Expected 'static_test_user', got '{user_id}'"
    print("✅ Static user ID works correctly")
    return True


def test_custom_extractor():
    """Test custom user_id_extractor."""
    print("\n🧪 Testing custom user_id_extractor...")

    # Define custom extractor that uses state
    def custom_extractor(input: RunAgentInput) -> str:
        # Extract from state
        if hasattr(input.state, 'get') and input.state.get("custom_user"):
            return input.state["custom_user"]
        return "anonymous"

    # Create a test ADK agent
    test_agent_custom = Agent(name="custom_test_agent", instruction="You are a test agent.")

    agent = ADKAgent(adk_agent=test_agent_custom, app_name="test_app", user_id_extractor=custom_extractor)

    # Test with user_id in state
    test_input_with_user = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        context=[],
        state={"custom_user": "state_user_123"},
        tools=[],
        forwarded_props={}
    )

    user_id = agent._get_user_id(test_input_with_user)
    print(f"   User ID from state: {user_id}")
    assert user_id == "state_user_123", f"Expected 'state_user_123', got '{user_id}'"

    # Test without user_id in state
    test_input_no_user = RunAgentInput(
        thread_id="test_thread",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        context=[],
        state={},
        tools=[],
        forwarded_props={}
    )

    user_id = agent._get_user_id(test_input_no_user)
    print(f"   User ID fallback: {user_id}")
    assert user_id == "anonymous", f"Expected 'anonymous', got '{user_id}'"

    print("✅ Custom user_id_extractor works correctly")
    return True


def test_default_extractor():
    """Test default user extraction logic."""
    print("\n🧪 Testing default user extraction...")

    # Create a test ADK agent
    test_agent_default = Agent(name="default_test_agent", instruction="You are a test agent.")

    # No static user_id or custom extractor
    agent = ADKAgent(adk_agent=test_agent_default, app_name="test_app")

    # Test default behavior - should use thread_id
    test_input = RunAgentInput(
        thread_id="test_thread_xyz",
        run_id="test_run",
        messages=[UserMessage(id="1", role="user", content="Test")],
        context=[],
        state={"user_id": "state_user"},  # This should be ignored now
        tools=[],
        forwarded_props={}
    )

    user_id = agent._get_user_id(test_input)
    print(f"   User ID (default): {user_id}")
    assert user_id == "thread_user_test_thread_xyz", f"Expected 'thread_user_test_thread_xyz', got '{user_id}'"

    print("✅ Default user extraction works correctly")
    return True


def test_conflicting_config():
    """Test that conflicting configuration raises error."""
    print("\n🧪 Testing conflicting configuration...")

    # Create a test ADK agent
    test_agent_conflict = Agent(name="conflict_test_agent", instruction="You are a test agent.")

    try:
        # Both static user_id and extractor should raise error
        agent = ADKAgent(
            adk_agent=test_agent_conflict,
            app_name="test_app",
            user_id="static_user",
            user_id_extractor=lambda x: "extracted_user"
        )
        print("❌ Should have raised ValueError")
        return False
    except ValueError as e:
        print(f"✅ Correctly raised error: {e}")
        return True


def main():
    """Run all user_id_extractor tests."""
    print("🚀 Testing User ID Extraction")
    print("=" * 40)

    tests = [
        test_static_user_id,
        test_custom_extractor,
        test_default_extractor,
        test_conflicting_config
    ]

    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"❌ Test {test.__name__} failed: {e}")
            import traceback
            traceback.print_exc()
            results.append(False)

    print("\n" + "=" * 40)
    print("📊 Test Results:")

    for i, (test, result) in enumerate(zip(tests, results), 1):
        status = "✅ PASS" if result else "❌ FAIL"
        print(f"  {i}. {test.__name__}: {status}")

    passed = sum(results)
    total = len(results)

    if passed == total:
        print(f"\n🎉 All {total} tests passed!")
        print("💡 User ID extraction functionality is working correctly")
    else:
        print(f"\n⚠️ {passed}/{total} tests passed")

    return passed == total


if __name__ == "__main__":
    import sys
    success = main()
    sys.exit(0 if success else 1)


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_utils_converters.py
================================================
#!/usr/bin/env python
"""Tests for utility functions in converters.py."""

import pytest
import json
from unittest.mock import MagicMock, patch, PropertyMock

from ag_ui.core import UserMessage, AssistantMessage, SystemMessage, ToolMessage, ToolCall, FunctionCall
from google.adk.events import Event as ADKEvent
from google.genai import types

from ag_ui_adk.utils.converters import (
    convert_ag_ui_messages_to_adk,
    convert_adk_event_to_ag_ui_message,
    convert_state_to_json_patch,
    convert_json_patch_to_state,
    extract_text_from_content,
    create_error_message
)


class TestConvertAGUIMessagesToADK:
    """Tests for convert_ag_ui_messages_to_adk function."""

    def test_convert_user_message(self):
        """Test converting a UserMessage to ADK event."""
        user_msg = UserMessage(
            id="user_1",
            role="user",
            content="Hello, how are you?"
        )

        adk_events = convert_ag_ui_messages_to_adk([user_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        assert event.id == "user_1"
        assert event.author == "user"
        assert event.content.role == "user"
        assert len(event.content.parts) == 1
        assert event.content.parts[0].text == "Hello, how are you?"

    def test_convert_system_message(self):
        """Test converting a SystemMessage to ADK event."""
        system_msg = SystemMessage(
            id="system_1",
            role="system",
            content="You are a helpful assistant."
        )

        adk_events = convert_ag_ui_messages_to_adk([system_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        assert event.id == "system_1"
        assert event.author == "system"
        assert event.content.role == "system"
        assert event.content.parts[0].text == "You are a helpful assistant."

    def test_convert_assistant_message_with_text(self):
        """Test converting an AssistantMessage with text content."""
        assistant_msg = AssistantMessage(
            id="assistant_1",
            role="assistant",
            content="I'm doing well, thank you!"
        )

        adk_events = convert_ag_ui_messages_to_adk([assistant_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        assert event.id == "assistant_1"
        assert event.author == "assistant"
        assert event.content.role == "model"  # ADK uses "model" for assistant
        assert event.content.parts[0].text == "I'm doing well, thank you!"

    def test_convert_assistant_message_with_tool_calls(self):
        """Test converting an AssistantMessage with tool calls."""
        tool_call = ToolCall(
            id="call_123",
            type="function",
            function=FunctionCall(
                name="get_weather",
                arguments='{"location": "New York"}'
            )
        )

        assistant_msg = AssistantMessage(
            id="assistant_2",
            role="assistant",
            content="Let me check the weather for you.",
            tool_calls=[tool_call]
        )

        adk_events = convert_ag_ui_messages_to_adk([assistant_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        assert event.content.role == "model"
        assert len(event.content.parts) == 2  # Text + function call

        # Check text part
        text_part = event.content.parts[0]
        assert text_part.text == "Let me check the weather for you."

        # Check function call part
        func_part = event.content.parts[1]
        assert func_part.function_call.name == "get_weather"
        assert func_part.function_call.args == {"location": "New York"}
        assert func_part.function_call.id == "call_123"

    def test_convert_assistant_message_with_dict_tool_args(self):
        """Test converting tool calls with dict arguments (not JSON string)."""
        tool_call = ToolCall(
            id="call_456",
            type="function",
            function=FunctionCall(
                name="calculate",
                arguments='{"expression": "2 + 2"}'
            )
        )

        assistant_msg = AssistantMessage(
            id="assistant_3",
            role="assistant",
            tool_calls=[tool_call]
        )

        adk_events = convert_ag_ui_messages_to_adk([assistant_msg])

        event = adk_events[0]
        func_part = event.content.parts[0]
        assert func_part.function_call.args == {"expression": "2 + 2"}

    def test_convert_tool_message(self):
        """Test converting a ToolMessage to ADK event."""
        tool_msg = ToolMessage(
            id="tool_1",
            role="tool",
            content='{"temperature": 72, "condition": "sunny"}',
            tool_call_id="call_123"
        )

        adk_events = convert_ag_ui_messages_to_adk([tool_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        assert event.id == "tool_1"
        assert event.author == "tool"
        assert event.content.role == "function"

        func_response = event.content.parts[0].function_response
        assert func_response.name == "call_123"
        assert func_response.id == "call_123"
        assert func_response.response == {"result": '{"temperature": 72, "condition": "sunny"}'}

    def test_convert_tool_message_with_dict_content(self):
        """Test converting a ToolMessage with dict content (not JSON string)."""
        tool_msg = ToolMessage(
            id="tool_2",
            role="tool",
            content='{"result": "success", "value": 42}',  # Must be JSON string
            tool_call_id="call_456"
        )

        adk_events = convert_ag_ui_messages_to_adk([tool_msg])

        event = adk_events[0]
        func_response = event.content.parts[0].function_response
        assert func_response.response == {"result": '{"result": "success", "value": 42}'}

    def test_convert_empty_message_list(self):
        """Test converting an empty message list."""
        adk_events = convert_ag_ui_messages_to_adk([])
        assert adk_events == []

    def test_convert_message_without_content(self):
        """Test converting a message without content."""
        user_msg = UserMessage(id="user_2", role="user", content="")

        adk_events = convert_ag_ui_messages_to_adk([user_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        # Empty content creates content=None because empty string is falsy
        assert event.content is None

    def test_convert_assistant_message_without_content_or_tools(self):
        """Test converting an AssistantMessage without content or tool calls."""
        assistant_msg = AssistantMessage(
            id="assistant_4",
            role="assistant",
            content=None,
            tool_calls=None
        )

        adk_events = convert_ag_ui_messages_to_adk([assistant_msg])

        assert len(adk_events) == 1
        event = adk_events[0]
        assert event.content is None

    def test_convert_multiple_messages(self):
        """Test converting multiple messages."""
        messages = [
            UserMessage(id="1", role="user", content="Hello"),
            AssistantMessage(id="2", role="assistant", content="Hi there!"),
            UserMessage(id="3", role="user", content="How are you?")
        ]

        adk_events = convert_ag_ui_messages_to_adk(messages)

        assert len(adk_events) == 3
        assert adk_events[0].id == "1"
        assert adk_events[1].id == "2"
        assert adk_events[2].id == "3"

    @patch('ag_ui_adk.utils.converters.logger')
    def test_convert_with_exception_handling(self, mock_logger):
        """Test that exceptions during conversion are logged and skipped."""
        # Create a message that will cause an exception
        bad_msg = UserMessage(id="bad", role="user", content="test")

        # Mock the ADKEvent constructor to raise an exception
        with patch('ag_ui_adk.utils.converters.ADKEvent') as mock_adk_event:
            mock_adk_event.side_effect = ValueError("Test exception")

            adk_events = convert_ag_ui_messages_to_adk([bad_msg])

            # Should return empty list and log error
            assert adk_events == []
            mock_logger.error.assert_called_once()
            assert "Error converting message bad" in str(mock_logger.error.call_args)


class TestConvertADKEventToAGUIMessage:
    """Tests for convert_adk_event_to_ag_ui_message function."""

    def test_convert_user_event(self):
        """Test converting ADK user event to AG-UI message."""
        mock_event = MagicMock()
        mock_event.id = "user_1"
        mock_event.author = "user"
        mock_event.content = MagicMock()

        mock_part = MagicMock()
        mock_part.text = "Hello, assistant!"
        mock_event.content.parts = [mock_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert isinstance(result, UserMessage)
        assert result.id == "user_1"
        assert result.role == "user"
        assert result.content == "Hello, assistant!"

    def test_convert_user_event_multiple_text_parts(self):
        """Test converting user event with multiple text parts."""
        mock_event = MagicMock()
        mock_event.id = "user_2"
        mock_event.author = "user"
        mock_event.content = MagicMock()

        mock_part1 = MagicMock()
        mock_part1.text = "First part"
        mock_part2 = MagicMock()
        mock_part2.text = "Second part"
        mock_event.content.parts = [mock_part1, mock_part2]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert result.content == "First part\nSecond part"

    def test_convert_assistant_event_with_text(self):
        """Test converting ADK assistant event with text content."""
        mock_event = MagicMock()
        mock_event.id = "assistant_1"
        mock_event.author = "model"
        mock_event.content = MagicMock()

        mock_part = MagicMock()
        mock_part.text = "I can help you with that."
        mock_part.function_call = None
        mock_event.content.parts = [mock_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert isinstance(result, AssistantMessage)
        assert result.id == "assistant_1"
        assert result.role == "assistant"
        assert result.content == "I can help you with that."
        assert result.tool_calls is None

    def test_convert_assistant_event_with_function_call(self):
        """Test converting assistant event with function call."""
        mock_event = MagicMock()
        mock_event.id = "assistant_2"
        mock_event.author = "model"
        mock_event.content = MagicMock()

        mock_part = MagicMock()
        mock_part.text = None
        mock_part.function_call = MagicMock()
        mock_part.function_call.name = "get_weather"
        mock_part.function_call.args = {"location": "Boston"}
        mock_part.function_call.id = "call_123"
        mock_event.content.parts = [mock_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert isinstance(result, AssistantMessage)
        assert result.content is None
        assert len(result.tool_calls) == 1

        tool_call = result.tool_calls[0]
        assert tool_call.id == "call_123"
        assert tool_call.type == "function"
        assert tool_call.function.name == "get_weather"
        assert tool_call.function.arguments == '{"location": "Boston"}'

    def test_convert_assistant_event_with_text_and_function_call(self):
        """Test converting assistant event with both text and function call."""
        mock_event = MagicMock()
        mock_event.id = "assistant_3"
        mock_event.author = "model"
        mock_event.content = MagicMock()

        mock_text_part = MagicMock()
        mock_text_part.text = "Let me check the weather."
        mock_text_part.function_call = None

        mock_func_part = MagicMock()
        mock_func_part.text = None
        mock_func_part.function_call = MagicMock()
        mock_func_part.function_call.name = "get_weather"
        mock_func_part.function_call.args = {"location": "Seattle"}
        mock_func_part.function_call.id = "call_456"

        mock_event.content.parts = [mock_text_part, mock_func_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert result.content == "Let me check the weather."
        assert len(result.tool_calls) == 1
        assert result.tool_calls[0].function.name == "get_weather"

    def test_convert_function_call_without_args(self):
        """Test converting function call without args."""
        mock_event = MagicMock()
        mock_event.id = "assistant_4"
        mock_event.author = "model"
        mock_event.content = MagicMock()

        mock_part = MagicMock()
        mock_part.text = None
        mock_part.function_call = MagicMock()
        mock_part.function_call.name = "get_time"
        # No args attribute
        delattr(mock_part.function_call, 'args')
        mock_part.function_call.id = "call_789"

        mock_event.content.parts = [mock_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        tool_call = result.tool_calls[0]
        assert tool_call.function.arguments == "{}"

    def test_convert_function_call_without_id(self):
        """Test converting function call without id."""
        mock_event = MagicMock()
        mock_event.id = "assistant_5"
        mock_event.author = "model"
        mock_event.content = MagicMock()

        mock_part = MagicMock()
        mock_part.text = None
        mock_part.function_call = MagicMock()
        mock_part.function_call.name = "get_time"
        mock_part.function_call.args = {}
        # No id attribute
        delattr(mock_part.function_call, 'id')

        mock_event.content.parts = [mock_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        tool_call = result.tool_calls[0]
        assert tool_call.id == "assistant_5"  # Falls back to event ID

    def test_convert_event_without_content(self):
        """Test converting event without content."""
        mock_event = MagicMock()
        mock_event.id = "empty_1"
        mock_event.author = "model"
        mock_event.content = None

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert result is None

    def test_convert_event_without_parts(self):
        """Test converting event without parts."""
        mock_event = MagicMock()
        mock_event.id = "empty_2"
        mock_event.author = "model"
        mock_event.content = MagicMock()
        mock_event.content.parts = []

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert result is None

    def test_convert_user_event_without_text(self):
        """Test converting user event without text content."""
        mock_event = MagicMock()
        mock_event.id = "user_3"
        mock_event.author = "user"
        mock_event.content = MagicMock()

        mock_part = MagicMock()
        mock_part.text = None
        mock_event.content.parts = [mock_part]

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert result is None

    @patch('ag_ui_adk.utils.converters.logger')
    def test_convert_with_exception_handling(self, mock_logger):
        """Test that exceptions during conversion are logged and None returned."""
        mock_event = MagicMock()
        mock_event.id = "bad_event"
        mock_event.author = "user"
        mock_event.content = MagicMock()
        mock_event.content.parts = [MagicMock()]
        # Make parts[0].text raise an exception when accessed
        type(mock_event.content.parts[0]).text = PropertyMock(side_effect=ValueError("Test exception"))

        result = convert_adk_event_to_ag_ui_message(mock_event)

        assert result is None
        mock_logger.error.assert_called_once()
        assert "Error converting ADK event bad_event" in str(mock_logger.error.call_args)


class TestStateConversionFunctions:
    """Tests for state conversion functions."""

    def test_convert_state_to_json_patch_basic(self):
        """Test converting state delta to JSON patch operations."""
        state_delta = {
            "user_name": "John",
            "status": "active",
            "count": 42
        }

        patches = convert_state_to_json_patch(state_delta)

        assert len(patches) == 3

        # Check each patch
        user_patch = next(p for p in patches if p["path"] == "/user_name")
        assert user_patch["op"] == "replace"
        assert user_patch["value"] == "John"

        status_patch = next(p for p in patches if p["path"] == "/status")
        assert status_patch["op"] == "replace"
        assert status_patch["value"] == "active"

        count_patch = next(p for p in patches if p["path"] == "/count")
        assert count_patch["op"] == "replace"
        assert count_patch["value"] == 42

    def test_convert_state_to_json_patch_with_none_values(self):
        """Test converting state delta with None values (remove operations)."""
        state_delta = {
            "keep_this": "value",
            "remove_this": None,
            "also_remove": None
        }

        patches = convert_state_to_json_patch(state_delta)

        assert len(patches) == 3

        keep_patch = next(p for p in patches if p["path"] == "/keep_this")
        assert keep_patch["op"] == "replace"
        assert keep_patch["value"] == "value"

        remove_patch = next(p for p in patches if p["path"] == "/remove_this")
        assert remove_patch["op"] == "remove"
        assert "value" not in remove_patch

        also_remove_patch = next(p for p in patches if p["path"] == "/also_remove")
        assert also_remove_patch["op"] == "remove"

    def test_convert_state_to_json_patch_empty_dict(self):
        """Test converting empty state delta."""
        patches = convert_state_to_json_patch({})
        assert patches == []

    def test_convert_json_patch_to_state_basic(self):
        """Test converting JSON patch operations to state delta."""
        patches = [
            {"op": "replace", "path": "/user_name", "value": "Alice"},
            {"op": "add", "path": "/new_field", "value": "new_value"},
            {"op": "remove", "path": "/old_field"}
        ]

        state_delta = convert_json_patch_to_state(patches)

        assert len(state_delta) == 3
        assert state_delta["user_name"] == "Alice"
        assert state_delta["new_field"] == "new_value"
        assert state_delta["old_field"] is None

    def test_convert_json_patch_to_state_with_nested_paths(self):
        """Test converting patches with nested paths (only first level supported)."""
        patches = [
            {"op": "replace", "path": "/user/name", "value": "Bob"},
            {"op": "add", "path": "/config/theme", "value": "dark"}
        ]

        state_delta = convert_json_patch_to_state(patches)

        # Should extract the first path segment after the slash
        assert state_delta["user/name"] == "Bob"
        assert state_delta["config/theme"] == "dark"

    def test_convert_json_patch_to_state_with_unsupported_ops(self):
        """Test converting patches with unsupported operations."""
        patches = [
            {"op": "replace", "path": "/supported", "value": "yes"},
            {"op": "copy", "path": "/unsupported", "from": "/somewhere"},
            {"op": "move", "path": "/also_unsupported", "from": "/elsewhere"},
            {"op": "test", "path": "/test_op", "value": "test"}
        ]

        state_delta = convert_json_patch_to_state(patches)

        # Should only process the replace operation
        assert len(state_delta) == 1
        assert state_delta["supported"] == "yes"

    def test_convert_json_patch_to_state_empty_list(self):
        """Test converting empty patch list."""
        state_delta = convert_json_patch_to_state([])
        assert state_delta == {}

    def test_convert_json_patch_to_state_malformed_patches(self):
        """Test converting malformed patches."""
        patches = [
            {"op": "replace", "path": "/good", "value": "value"},
            {"op": "replace"},  # No path
            {"path": "/no_op", "value": "value"},  # No op
            {"op": "replace", "path": "", "value": "empty_path"}  # Empty path
        ]

        state_delta = convert_json_patch_to_state(patches)

        # Should only process the good patch
        assert len(state_delta) == 2
        assert state_delta["good"] == "value"
        assert state_delta[""] == "empty_path"  # Empty path becomes empty key

    def test_roundtrip_conversion(self):
        """Test that state -> patches -> state works correctly."""
        original_state = {
            "name": "Test",
            "active": True,
            "count": 100,
            "remove_me": None
        }

        patches = convert_state_to_json_patch(original_state)
        converted_state = convert_json_patch_to_state(patches)

        assert converted_state == original_state


class TestUtilityFunctions:
    """Tests for utility functions."""

    def test_extract_text_from_content_basic(self):
        """Test extracting text from ADK Content object."""
        mock_content = MagicMock()

        mock_part1 = MagicMock()
        mock_part1.text = "Hello"
        mock_part2 = MagicMock()
        mock_part2.text = "World"
        mock_content.parts = [mock_part1, mock_part2]

        result = extract_text_from_content(mock_content)

        assert result == "Hello\nWorld"

    def test_extract_text_from_content_with_none_text(self):
        """Test extracting text when some parts have None text."""
        mock_content = MagicMock()

        mock_part1 = MagicMock()
        mock_part1.text = "Hello"
        mock_part2 = MagicMock()
        mock_part2.text = None
        mock_part3 = MagicMock()
        mock_part3.text = "World"
        mock_content.parts = [mock_part1, mock_part2, mock_part3]

        result = extract_text_from_content(mock_content)

        assert result == "Hello\nWorld"

    def test_extract_text_from_content_no_text_parts(self):
        """Test extracting text when no parts have text."""
        mock_content = MagicMock()

        mock_part1 = MagicMock()
        mock_part1.text = None
        mock_part2 = MagicMock()
        mock_part2.text = None
        mock_content.parts = [mock_part1, mock_part2]

        result = extract_text_from_content(mock_content)

        assert result == ""

    def test_extract_text_from_content_no_parts(self):
        """Test extracting text when content has no parts."""
        mock_content = MagicMock()
        mock_content.parts = []

        result = extract_text_from_content(mock_content)

        assert result == ""

    def test_extract_text_from_content_none_content(self):
        """Test extracting text from None content."""
        result = extract_text_from_content(None)

        assert result == ""

    def test_extract_text_from_content_no_parts_attribute(self):
        """Test extracting text when content has no parts attribute."""
        mock_content = MagicMock()
        mock_content.parts = None

        result = extract_text_from_content(mock_content)

        assert result == ""

    def test_create_error_message_basic(self):
        """Test creating error message from exception."""
        error = ValueError("Something went wrong")

        result = create_error_message(error)

        assert result == "ValueError: Something went wrong"

    def test_create_error_message_with_context(self):
        """Test creating error message with context."""
        error = RuntimeError("Database connection failed")
        context = "During user authentication"

        result = create_error_message(error, context)

        assert result == "During user authentication: RuntimeError - Database connection failed"

    def test_create_error_message_empty_context(self):
        """Test creating error message with empty context."""
        error = TypeError("Invalid type")

        result = create_error_message(error, "")

        assert result == "TypeError: Invalid type"

    def test_create_error_message_custom_exception(self):
        """Test creating error message from custom exception."""
        class CustomError(Exception):
            pass

        error = CustomError("Custom error message")

        result = create_error_message(error)

        assert result == "CustomError: Custom error message"

    def test_create_error_message_exception_without_message(self):
        """Test creating error message from exception without message."""
        error = ValueError()

        result = create_error_message(error)

        assert result == "ValueError: "


================================================
FILE: typescript-sdk/integrations/adk-middleware/python/tests/test_utils_init.py
================================================
#!/usr/bin/env python
"""Tests for utils/__init__.py module."""

import pytest


class TestUtilsInit:
    """Tests for utils module initialization."""

    def test_imports_available(self):
        """Test that all expected imports are available."""
        from ag_ui_adk.utils import (
            convert_ag_ui_messages_to_adk,
            convert_adk_event_to_ag_ui_message,
            convert_state_to_json_patch,
            convert_json_patch_to_state
        )

        # Should be able to import all expected functions
        assert callable(convert_ag_ui_messages_to_adk)
        assert callable(convert_adk_event_to_ag_ui_message)
        assert callable(convert_state_to_json_patch)
        assert callable(convert_json_patch_to_state)

    def test_module_has_all_attribute(self):
        """Test that the module has the correct __all__ attribute."""
        from ag_ui_adk import utils

        expected_all = [
            'convert_ag_ui_messages_to_adk',
            'convert_adk_event_to_ag_ui_message',
            'convert_state_to_json_patch',
            'convert_json_patch_to_state'
        ]

        assert hasattr(utils, '__all__')
        assert utils.__all__ == expected_all

    def test_direct_import_from_utils(self):
        """Test direct import from utils module."""
        from ag_ui_adk.utils import convert_ag_ui_messages_to_adk

        # Should be able to import directly from utils
        assert callable(convert_ag_ui_messages_to_adk)

        # Should be the same function as imported from converters
        from ag_ui_adk.utils.converters import convert_ag_ui_messages_to_adk as direct_import
        assert convert_ag_ui_messages_to_adk is direct_import

    def test_utils_module_docstring(self):
        """Test that the utils module has a proper docstring."""
        from ag_ui_adk import utils

        assert utils.__doc__ is not None
        assert "Utility functions for ADK middleware" in utils.__doc__

    def test_re_export_functionality(self):
        """Test that re-exported functions work correctly."""
        from ag_ui_adk.utils import convert_state_to_json_patch, convert_json_patch_to_state

        # Test basic functionality of re-exported functions
        state_delta = {"test_key": "test_value"}
        patches = convert_state_to_json_patch(state_delta)

        assert len(patches) == 1
        assert patches[0]["op"] == "replace"
        assert patches[0]["path"] == "/test_key"
        assert patches[0]["value"] == "test_value"

        # Test roundtrip
        converted_back = convert_json_patch_to_state(patches)
        assert converted_back == state_delta


================================================
FILE: typescript-sdk/integrations/adk-middleware/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class ADKAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/agno/README.md
================================================
# @ag-ui/agno

Implementation of the AG-UI protocol for Agno.

Connects Agno agents to frontend applications via the AG-UI protocol using HTTP communication.

## Installation

```bash
npm install @ag-ui/agno
pnpm add @ag-ui/agno
yarn add @ag-ui/agno
```

## Usage

```ts
import { AgnoAgent } from "@ag-ui/agno";

// Create an AG-UI compatible agent
const agent = new AgnoAgent({
  url: "https://your-agno-server.com/agent",
  headers: { Authorization: "Bearer your-token" },
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Hello from Agno!" }],
});
```

## Features

- **HTTP connectivity** – Direct connection to Agno agent servers
- **Multi-agent support** – Works with Agno's multi-agent system architecture
- **Streaming responses** – Real-time communication with full AG-UI event support



================================================
FILE: typescript-sdk/integrations/agno/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/agno/package.json
================================================
{
  "name": "@ag-ui/agno",
  "author": "Manu Hortet <manu@agno.com>",
  "version": "0.0.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/agno/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/agno/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/agno/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/agno/examples/README.md
================================================
# Agno Finance Agent

An Agno Agent with Finance tools for AG-UI that researches stock prices, analyst recommendations, and stock fundamentals.

## Setup

This project uses [uv](https://github.com/astral-sh/uv) for dependency management.

### Prerequisites

1. Install uv: `pip install uv`
2. Set your OpenAI API key: `export OPENAI_API_KEY="your-api-key"`

### Installation

```bash
# Install dependencies
uv sync

# Activate the virtual environment
uv shell
```

### Running the Agent

```bash
# Run the agent
uv run python agent.py
```

The agent will be available at `http://localhost:9001` (or the port specified by the `PORT` environment variable).

## Development

```bash
# Install development dependencies
uv sync --extra dev

# Run tests
uv run pytest

# Format code
uv run black .
uv run isort .

# Lint code
uv run flake8 .
```

## Features

- Stock price lookup
- Analyst recommendations
- Stock fundamentals analysis
- AG-UI compatible interface


================================================
FILE: typescript-sdk/integrations/agno/examples/pyproject.toml
================================================
tool.uv.package = true

[project]
name = "server"
version = "0.1.0"
description = "Example usage of the AG-UI adapter for Agno"
license = "MIT"

readme = "README.md"
requires-python = ">=3.12,<4.0"
dependencies = [
    "agno>=1.7.7",
    "openai>=1.99.1",
    "yfinance>=0.2.63",
    "fastapi>=0.116.1",
    "uvicorn>=0.35.0",
    "ag-ui-protocol>=0.1.8",
    "dotenv (>=0.9.9,<0.10.0)",
]
authors = [
    {name = "AG-UI Team"}
]


[project.scripts]
dev = "server:main"


================================================
FILE: typescript-sdk/integrations/agno/examples/requirements.txt
================================================
agno>=1.6.3
openai>=1.88.0
yfinance>=0.2.63
fastapi>=0.115.13
uvicorn>=0.34.3
ag-ui-protocol>=0.1.5


================================================
FILE: typescript-sdk/integrations/agno/examples/server/__init__.py
================================================
"""Example usage of the AG-UI adapter for Agno.

This provides a FastAPI application that demonstrates how to use the
Agno agent with the AG-UI protocol. It includes examples for
AG-UI dojo features:
- Agentic Chat (Investment Analyst with Finance tools)
"""
from __future__ import annotations

from fastapi import FastAPI
import uvicorn
import os
from dotenv import load_dotenv
load_dotenv()

from .api import (
    agentic_chat_app,
    tool_based_generative_ui_app,
)

app = FastAPI(title='Agno AG-UI server')
app.mount('/agentic_chat', agentic_chat_app, 'Agentic Chat')
app.mount('/tool_based_generative_ui', tool_based_generative_ui_app, 'Tool-based Generative UI')

def main():
    """Main function to start the FastAPI server."""
    port = int(os.getenv("PORT", "9001"))
    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/agno/examples/server/api/__init__.py
================================================
"""Example API for a AG-UI compatible Agno Agent UI."""

from __future__ import annotations

from .agentic_chat import app as agentic_chat_app
from .tool_based_generative_ui import app as tool_based_generative_ui_app

__all__ = [
    'agentic_chat_app',
    'tool_based_generative_ui_app',
]


================================================
FILE: typescript-sdk/integrations/agno/examples/server/api/agentic_chat.py
================================================
"""Example: Agno Agent with Finance tools

This example shows how to create an Agno Agent with tools (YFinanceTools) and expose it in an AG-UI compatible way.
"""
from agno.agent.agent import Agent
from agno.app.agui.app import AGUIApp
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from agno.tools import tool


@tool(external_execution=True)
def change_background(background: str) -> str: # pylint: disable=unused-argument
    """
    Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.

    Args:
        background: str: The background color to change to. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc.
    """ # pylint: disable=line-too-long

agent = Agent(
  model=OpenAIChat(id="gpt-4o"),
  tools=[
    YFinanceTools(
      stock_price=True, analyst_recommendations=True, stock_fundamentals=True
    ),
    change_background,
  ],
  description="You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
  instructions="Format your response using markdown and use tables to display data where possible.",
)

agui_app = AGUIApp(
  agent=agent,
  name="Investment Analyst",
  app_id="agentic_chat",
  description="An investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
)

app = agui_app.get_app()


================================================
FILE: typescript-sdk/integrations/agno/examples/server/api/tool_based_generative_ui.py
================================================
"""Example: Tool-based Generative UI Agent

This example shows how to create an Agno Agent with custom tools for haiku generation
and background changing, exposed in an AG-UI compatible way.
"""
from typing import List

from agno.agent.agent import Agent
from agno.app.agui.app import AGUIApp
from agno.models.openai import OpenAIChat
from agno.tools import tool


@tool(external_execution=True)
def generate_haiku(english: List[str], japanese: List[str], image_names: List[str]) -> str: # pylint: disable=unused-argument
    """

    Generate a haiku in Japanese and its English translation.
    YOU MUST PROVIDE THE ENGLISH HAIKU AND THE JAPANESE HAIKU AND THE IMAGE NAMES.
    When picking image names, pick them from the following list:
        - "Osaka_Castle_Turret_Stone_Wall_Pine_Trees_Daytime.jpg",
        - "Tokyo_Skyline_Night_Tokyo_Tower_Mount_Fuji_View.jpg",
        - "Itsukushima_Shrine_Miyajima_Floating_Torii_Gate_Sunset_Long_Exposure.jpg",
        - "Takachiho_Gorge_Waterfall_River_Lush_Greenery_Japan.jpg",
        - "Bonsai_Tree_Potted_Japanese_Art_Green_Foliage.jpeg",
        - "Shirakawa-go_Gassho-zukuri_Thatched_Roof_Village_Aerial_View.jpg",
        - "Ginkaku-ji_Silver_Pavilion_Kyoto_Japanese_Garden_Pond_Reflection.jpg",
        - "Senso-ji_Temple_Asakusa_Cherry_Blossoms_Kimono_Umbrella.jpg",
        - "Cherry_Blossoms_Sakura_Night_View_City_Lights_Japan.jpg",
        - "Mount_Fuji_Lake_Reflection_Cherry_Blossoms_Sakura_Spring.jpg"

    Args:
        english: List[str]: An array of three lines of the haiku in English. YOU MUST PROVIDE THE ENGLISH HAIKU.
        japanese: List[str]: An array of three lines of the haiku in Japanese. YOU MUST PROVIDE THE JAPANESE HAIKU.
        image_names: List[str]: An array of three image names. YOU MUST PROVIDE THE IMAGE NAMES.


    Returns:
        str: A confirmation message.
    """ # pylint: disable=line-too-long
    return "Haiku generated"

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[generate_haiku],
    description="Help the user with writing Haikus. If the user asks for a haiku, use the generate_haiku tool to display the haiku to the user.",
    debug_mode=True,
)

agui_app = AGUIApp(
  agent=agent,
  name="Tool-based Generative UI Agent",
  app_id="tool_based_generative_ui",
  description="A tool-based generative UI agent with haiku generation and background changing capabilities.",
)

app = agui_app.get_app()


================================================
FILE: typescript-sdk/integrations/agno/src/index.ts
================================================
/**
 * Agno is a framework for building Multi-Agent Systems with memory, knowledge and reasoning.
 * Check more about using Agno: https://docs.agno.com/
 */

import { HttpAgent } from "@ag-ui/client";

export class AgnoAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/crewai/README.md
================================================
# @ag-ui/crewai

Implementation of the AG-UI protocol for CrewAI.

Connects CrewAI Flows and Crews to frontend applications via the AG-UI protocol. Supports both TypeScript HTTP clients and Python FastAPI server integration with streaming crew execution.

## Installation

```bash
npm install @ag-ui/crewai
pnpm add @ag-ui/crewai
yarn add @ag-ui/crewai
```

## Usage

```ts
import { CrewAIAgent } from "@ag-ui/crewai";

// Create an AG-UI compatible agent
const agent = new CrewAIAgent({
  url: "http://localhost:8000/crew-endpoint",
  headers: { "Content-Type": "application/json" },
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Execute the research crew" }],
});
```

## Features

- **HTTP connectivity** – Connect to CrewAI FastAPI servers
- **Flow & Crew support** – Works with both CrewAI Flows and traditional Crews
- **Step tracking** – Real-time crew execution progress
- **Python integration** – Full FastAPI server implementation included

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/crewai/python
poetry install && poetry run dev
```



================================================
FILE: typescript-sdk/integrations/crewai/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/crewai/package.json
================================================
{
  "name": "@ag-ui/crewai",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/crewai/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/crewai/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/crewai/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
server
python



================================================
FILE: typescript-sdk/integrations/crewai/python/README.md
================================================
# ag-ui-crewai

Implementation of the AG-UI protocol for CrewAI.

Provides a complete Python integration for CrewAI flows and crews with the AG-UI protocol, including FastAPI endpoint creation and comprehensive event streaming.

## Installation

```bash
pip install ag-ui-crewai
```

## Usage

```python
from crewai.flow.flow import Flow, start
from litellm import completion
from ag_ui_crewai import (
    add_crewai_flow_fastapi_endpoint,
    copilotkit_stream,
    CopilotKitState
)
from fastapi import FastAPI

class MyFlow(Flow[CopilotKitState]):
    @start()
    async def chat(self):
        response = await copilotkit_stream(
            completion(
                model="openai/gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    *self.state.messages
                ],
                tools=self.state.copilotkit.actions,
                stream=True
            )
        )
        self.state.messages.append(response.choices[0].message)

# Add to FastAPI
app = FastAPI()
add_crewai_flow_fastapi_endpoint(app, MyFlow(), "/flow")
```

## Features

- **Native CrewAI integration** – Direct support for CrewAI flows, crews, and multi-agent systems
- **FastAPI endpoint creation** – Automatic HTTP endpoint generation with proper event streaming
- **Predictive state updates** – Real-time state synchronization between backend and frontend
- **Streaming tool calls** – Live streaming of LLM responses and tool execution to the UI

## To run the dojo examples

```bash
cd python/ag_ui_crewai
poetry install
poetry run dev
```



================================================
FILE: typescript-sdk/integrations/crewai/python/pyproject.toml
================================================
[tool.poetry]
name = "ag-ui-crewai"
version = "0.1.4"
description = "Implementation of the AG-UI protocol for CrewAI"
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"
exclude = [
    "ag_ui_crewai/dojo.py",
    "ag_ui_crewai/examples/**",
]

[tool.poetry.dependencies]
python = "<3.14,>=3.10"
ag-ui-protocol = "==0.1.5"
fastapi = "^0.115.12"
uvicorn = "^0.34.3"
crewai = "^0.130.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "ag_ui_crewai.dojo:main"


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/__init__.py
================================================
from .endpoint import add_crewai_flow_fastapi_endpoint
from .sdk import (
  CopilotKitState,
  copilotkit_predict_state,
  copilotkit_emit_state,
  copilotkit_stream
)
# from .enterprise import CrewEnterpriseEventListener

# CREW_ENTERPRISE_EVENT_LISTENER = CrewEnterpriseEventListener()

__all__ = [
  "add_crewai_flow_fastapi_endpoint",
  "CopilotKitState",
  "copilotkit_predict_state",
  "copilotkit_emit_state",
  "copilotkit_stream"
]



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/context.py
================================================
import contextvars
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from crewai.flow.flow import Flow

flow_context: contextvars.ContextVar['Flow'] = contextvars.ContextVar('flow')



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/crews.py
================================================
import uuid
import copy
import json
from typing import Any, cast
from crewai import Crew, Flow
from crewai.flow import start
from crewai.cli.crew_chat import (
  initialize_chat_llm as crew_chat_initialize_chat_llm,
  generate_crew_chat_inputs as crew_chat_generate_crew_chat_inputs,
  generate_crew_tool_schema as crew_chat_generate_crew_tool_schema,
  build_system_message as crew_chat_build_system_message,
  create_tool_function as crew_chat_create_tool_function
)
from litellm import completion
from .sdk import (
  copilotkit_stream,
  copilotkit_exit,
)

_CREW_INPUTS_CACHE = {}


CREW_EXIT_TOOL = {
    "type": "function",
    "function": {
        "name": "crew_exit",
        "description": "Call this when the user has indicated that they are done with the crew",
        "parameters": {
            "type": "object",
            "properties": {},
            "required": [],
        },
    },
}


class ChatWithCrewFlow(Flow):
    """Chat with crew"""

    def __init__(
            self, *,
            crew: Crew
        ):
        super().__init__()


        self.crew = copy.deepcopy(cast(Any, crew).crew())

        if self.crew.chat_llm is None:
            raise ValueError("Crew chat LLM is not set")

        self.crew_name = crew.name
        self.chat_llm = crew_chat_initialize_chat_llm(self.crew)

        if crew.name not in _CREW_INPUTS_CACHE:
            self.crew_chat_inputs = crew_chat_generate_crew_chat_inputs(
                self.crew,
                self.crew_name,
                self.chat_llm
            )
            _CREW_INPUTS_CACHE[ crew.name] = self.crew_chat_inputs
        else:
            self.crew_chat_inputs = _CREW_INPUTS_CACHE[ crew.name]

        self.crew_tool_schema = crew_chat_generate_crew_tool_schema(self.crew_chat_inputs)
        self.system_message = crew_chat_build_system_message(self.crew_chat_inputs)

        super().__init__()

    @start()
    async def chat(self):
        """Chat with the crew"""

        system_message = self.system_message
        if self.state.get("inputs"):
            system_message += "\n\nCurrent inputs: " + json.dumps(self.state["inputs"])

        messages = [
            {
                "role": "system",
                "content": system_message,
                "id": str(uuid.uuid4()) + "-system"
            },
            *self.state["messages"]
        ]

        tools = [action for action in self.state["copilotkit"]["actions"]
                 if action["function"]["name"] != self.crew_name]

        tools += [self.crew_tool_schema, CREW_EXIT_TOOL]

        response = await copilotkit_stream(
            completion(
                model=self.crew.chat_llm,
                messages=messages,
                tools=tools,
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = cast(Any, response).choices[0]["message"]
        self.state["messages"].append(message)

        if message.get("tool_calls"):
            if message["tool_calls"][0]["function"]["name"] == self.crew_name:
                # run the crew
                crew_function = crew_chat_create_tool_function(self.crew, messages)
                args = json.loads(message["tool_calls"][0]["function"]["arguments"])
                result = crew_function(**args)

                if isinstance(result, str):
                    self.state["outputs"] = result
                elif hasattr(result, "json_dict"):
                    self.state["outputs"] = result.json_dict
                elif hasattr(result, "raw"):
                    self.state["outputs"] = result.raw
                else:
                    raise ValueError("Unexpected result type", type(result))

                self.state["messages"].append({
                    "role": "tool",
                    "content": result,
                    "tool_call_id": message["tool_calls"][0]["id"]
                })
            elif message["tool_calls"][0]["function"]["name"] == CREW_EXIT_TOOL["function"]["name"]:
                await copilotkit_exit()
                self.state["messages"].append({
                    "role": "tool",
                    "content": "Crew exited",
                    "tool_call_id": message["tool_calls"][0]["id"]
                })

                response = await copilotkit_stream(
                    completion( # pylint: disable=too-many-arguments
                        model=self.crew.chat_llm,
                        messages = [
                            {
                                "role": "system",
                                "content": "Indicate to the user that the crew has exited",
                                "id": str(uuid.uuid4()) + "-system"
                            },
                            *self.state["messages"]
                        ],
                        tools=tools,
                        parallel_tool_calls=False,
                        stream=True,
                        tool_choice="none"
                    )
                )
                message = cast(Any, response).choices[0]["message"]
                self.state["messages"].append(message)



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/dojo.py
================================================
import os
import uvicorn
from fastapi import FastAPI

from .endpoint import add_crewai_flow_fastapi_endpoint
from .examples.agentic_chat import AgenticChatFlow
from .examples.human_in_the_loop import HumanInTheLoopFlow
from .examples.tool_based_generative_ui import ToolBasedGenerativeUIFlow
from .examples.agentic_generative_ui import AgenticGenerativeUIFlow
from .examples.shared_state import SharedStateFlow
from .examples.predictive_state_updates import PredictiveStateUpdatesFlow

app = FastAPI(title="CrewAI Dojo Example Server")

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=AgenticChatFlow(),
    path="/agentic_chat",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=HumanInTheLoopFlow(),
    path="/human_in_the_loop",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=ToolBasedGenerativeUIFlow(),
    path="/tool_based_generative_ui",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=AgenticGenerativeUIFlow(),
    path="/agentic_generative_ui",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=SharedStateFlow(),
    path="/shared_state",
)

add_crewai_flow_fastapi_endpoint(
    app=app,
    flow=PredictiveStateUpdatesFlow(),
    path="/predictive_state_updates",
)

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "ag_ui_crewai.dojo:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/endpoint.py
================================================
"""
AG-UI FastAPI server for CrewAI.
"""
import copy
import asyncio
from typing import List, Optional
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse

from crewai.utilities.events import (
    FlowStartedEvent,
    FlowFinishedEvent,
    MethodExecutionStartedEvent,
    MethodExecutionFinishedEvent,
)
from crewai.flow.flow import Flow
from crewai.utilities.events.base_event_listener import BaseEventListener
from crewai import Crew

from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    Message,
    Tool
)
from ag_ui.core.events import (
  TextMessageChunkEvent,
  ToolCallChunkEvent,
  StepStartedEvent,
  StepFinishedEvent,
  MessagesSnapshotEvent,
  StateSnapshotEvent,
  CustomEvent,
)
from ag_ui.encoder import EventEncoder

from .events import (
  BridgedTextMessageChunkEvent,
  BridgedToolCallChunkEvent,
  BridgedCustomEvent,
  BridgedStateSnapshotEvent
)
from .context import flow_context
from .sdk import litellm_messages_to_ag_ui_messages
from .crews import ChatWithCrewFlow

QUEUES = {}
QUEUES_LOCK = asyncio.Lock()


async def create_queue(flow: object) -> asyncio.Queue:
    """Create a queue for a flow."""
    queue_id = id(flow)
    async with QUEUES_LOCK:
        queue = asyncio.Queue()
        QUEUES[queue_id] = queue
        return queue


def get_queue(flow: object) -> Optional[asyncio.Queue]:
    """Get the queue for a flow."""
    queue_id = id(flow)
    # not using a lock here should be fine
    return QUEUES.get(queue_id)

async def delete_queue(flow: object) -> None:
    """Delete the queue for a flow."""
    queue_id = id(flow)
    async with QUEUES_LOCK:
        if queue_id in QUEUES:
            del QUEUES[queue_id]

GLOBAL_EVENT_LISTENER = None

class FastAPICrewFlowEventListener(BaseEventListener):
    """FastAPI CrewFlow event listener"""

    def setup_listeners(self, crewai_event_bus):
        """Setup listeners for the FastAPI CrewFlow event listener"""
        @crewai_event_bus.on(FlowStartedEvent)
        def _(source, event):  # pylint: disable=unused-argument
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    RunStartedEvent(
                        type=EventType.RUN_STARTED,
                         # will be replaced by the correct thread_id/run_id when sending the event
                        thread_id="?",
                        run_id="?",
                    ),
                )
        @crewai_event_bus.on(FlowFinishedEvent)
        def _(source, event):  # pylint: disable=unused-argument
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    RunFinishedEvent(
                        type=EventType.RUN_FINISHED,
                        thread_id="?",
                        run_id="?",
                    ),
                )
                queue.put_nowait(None)
        @crewai_event_bus.on(MethodExecutionStartedEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    StepStartedEvent(
                        type=EventType.STEP_STARTED,
                        step_name=event.method_name
                    )
                )
        @crewai_event_bus.on(MethodExecutionFinishedEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                messages = litellm_messages_to_ag_ui_messages(source.state.messages)

                queue.put_nowait(
                    MessagesSnapshotEvent(
                        type=EventType.MESSAGES_SNAPSHOT,
                        messages=messages
                    )
                )
                queue.put_nowait(
                    StateSnapshotEvent(
                        type=EventType.STATE_SNAPSHOT,
                        snapshot=source.state
                    )
                )
                queue.put_nowait(
                    StepFinishedEvent(
                        type=EventType.STEP_FINISHED,
                        step_name=event.method_name
                    )
                )
        @crewai_event_bus.on(BridgedTextMessageChunkEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    TextMessageChunkEvent(
                        type=EventType.TEXT_MESSAGE_CHUNK,
                        message_id=event.message_id,
                        role=event.role,
                        delta=event.delta,
                    )
                )
        @crewai_event_bus.on(BridgedToolCallChunkEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    ToolCallChunkEvent(
                        type=EventType.TOOL_CALL_CHUNK,
                        tool_call_id=event.tool_call_id,
                        tool_call_name=event.tool_call_name,
                        delta=event.delta,
                    )
                )
        @crewai_event_bus.on(BridgedCustomEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    CustomEvent(
                        type=EventType.CUSTOM,
                        name=event.name,
                        value=event.value
                    )
                )
        @crewai_event_bus.on(BridgedStateSnapshotEvent)
        def _(source, event):
            queue = get_queue(source)
            if queue is not None:
                queue.put_nowait(
                    StateSnapshotEvent(
                        type=EventType.STATE_SNAPSHOT,
                        snapshot=event.snapshot
                    )
                )

def add_crewai_flow_fastapi_endpoint(app: FastAPI, flow: Flow, path: str = "/"):
    """Adds a CrewAI endpoint to the FastAPI app."""
    global GLOBAL_EVENT_LISTENER # pylint: disable=global-statement

    # Set up the global event listener singleton
    # we are doing this here because calling add_crewai_flow_fastapi_endpoint is a clear indicator
    # that we are not running on CrewAI enterprise
    if GLOBAL_EVENT_LISTENER is None:
        GLOBAL_EVENT_LISTENER = FastAPICrewFlowEventListener()

    @app.post(path)
    async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
        """Agentic chat endpoint"""

        flow_copy = copy.deepcopy(flow)

        # Get the accept header from the request
        accept_header = request.headers.get("accept")

        # Create an event encoder to properly format SSE events
        encoder = EventEncoder(accept=accept_header)

        inputs = crewai_prepare_inputs(
            state=input_data.state,
            messages=input_data.messages,
            tools=input_data.tools,
        )
        inputs["id"] = input_data.thread_id

        async def event_generator():
            queue = await create_queue(flow_copy)
            token = flow_context.set(flow_copy)
            try:
                asyncio.create_task(flow_copy.kickoff_async(inputs=inputs))

                while True:
                    item = await queue.get()
                    if item is None:
                        break

                    if item.type == EventType.RUN_STARTED or item.type == EventType.RUN_FINISHED:
                        item.thread_id = input_data.thread_id
                        item.run_id = input_data.run_id

                    yield encoder.encode(item)

            except Exception as e:  # pylint: disable=broad-exception-caught
                yield encoder.encode(
                    RunErrorEvent(
                        type=EventType.RUN_ERROR,
                        thread_id=input_data.thread_id,
                        run_id=input_data.run_id,
                        error=str(e),
                    )
                )
            finally:
                await delete_queue(flow_copy)
                flow_context.reset(token)

        return StreamingResponse(event_generator(), media_type=encoder.get_content_type())

def add_crewai_crew_fastapi_endpoint(app: FastAPI, crew: Crew, path: str = "/"):
    """Adds a CrewAI crew endpoint to the FastAPI app."""
    add_crewai_flow_fastapi_endpoint(app, ChatWithCrewFlow(crew=crew), path)


def crewai_prepare_inputs(  # pylint: disable=unused-argument, too-many-arguments
    *,
    state: dict,
    messages: List[Message],
    tools: List[Tool],
):
    """Default merge state for CrewAI"""
    messages = [message.model_dump() for message in messages]

    if len(messages) > 0:
        if "role" in messages[0] and messages[0]["role"] == "system":
            messages = messages[1:]

    actions = [{
        "type": "function",
        "function": {
            **tool.model_dump(),
        }
    } for tool in tools]

    new_state = {
        **state,
        "messages": messages,
        "copilotkit": {
            "actions": actions
        }
    }

    return new_state



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/enterprise.py
================================================
# from typing import Literal, List, Any
# from crewai.utilities.events import (
#     FlowStartedEvent,
#     FlowFinishedEvent,
#     MethodExecutionStartedEvent,
#     MethodExecutionFinishedEvent
# )
# from crewai.utilities.events.base_event_listener import BaseEventListener
# from crewai.utilities.events.base_events import BaseEvent

# from ag_ui.core import EventType, Message, State

# from .sdk import (
#     litellm_messages_to_ag_ui_messages,
#     BridgedTextMessageChunkEvent,
#     BridgedToolCallChunkEvent,
#     BridgedCustomEvent,
#     BridgedStateSnapshotEvent,
# )

# class EnterpriseRunStartedEvent(BaseEvent):
#     """Enterprise run started event"""
#     type: Literal[EventType.RUN_STARTED]

# class EnterpriseRunFinishedEvent(BaseEvent):
#     """Enterprise run finished event"""
#     type: Literal[EventType.RUN_FINISHED]

# class EnterpriseStepStartedEvent(BaseEvent):
#     """Enterprise step started event"""
#     type: Literal[EventType.STEP_STARTED]

# class EnterpriseStepFinishedEvent(BaseEvent):
#     """Enterprise step finished event"""
#     type: Literal[EventType.STEP_FINISHED]

# class EnterpriseMessagesSnapshotEvent(BaseEvent):
#     """Enterprise messages snapshot event"""
#     type: Literal[EventType.MESSAGES_SNAPSHOT]
#     messages: List[Message]

# class EnterpriseStateSnapshotEvent(BaseEvent):
#     """Enterprise state snapshot event"""
#     type: Literal[EventType.STATE_SNAPSHOT]
#     snapshot: State

# class EnterpriseTextMessageChunkEvent(BaseEvent):
#     """Enterprise text message chunk event"""
#     type: Literal[EventType.TEXT_MESSAGE_CHUNK]
#     message_id: str
#     role: Literal["assistant"]
#     delta: str

# class EnterpriseToolCallChunkEvent(BaseEvent):
#     """Enterprise tool call chunk event"""
#     type: Literal[EventType.TOOL_CALL_CHUNK]
#     tool_call_id: str
#     tool_call_name: str
#     delta: str

# class EnterpriseCustomEvent(BaseEvent):
#     """Enterprise custom event"""
#     type: Literal[EventType.CUSTOM]
#     name: str
#     value: Any

# class CrewEnterpriseEventListener(BaseEventListener):
#     """
#     This class is used to produce custom events when running a crewai flow on CrewAI Enterprise.
#     NOTE: These listeners only fire when the Flow is not run on enterprise.
#     """
#     def setup_listeners(self, crewai_event_bus):
#         @crewai_event_bus.on(FlowStartedEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseRunStartedEvent(
#                   type=EventType.RUN_STARTED
#                 )
#             )

#         @crewai_event_bus.on(FlowFinishedEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseRunFinishedEvent(
#                   type=EventType.RUN_FINISHED
#                 )
#             )

#         @crewai_event_bus.on(MethodExecutionStartedEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStepStartedEvent(
#                   type=EventType.STEP_STARTED,
#                   step_name=event.method_name
#                 )
#             )

#         @crewai_event_bus.on(MethodExecutionFinishedEvent)
#         def _(source, event):
#             messages = litellm_messages_to_ag_ui_messages(source.state.messages)

#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseMessagesSnapshotEvent(
#                   type=EventType.MESSAGES_SNAPSHOT,
#                   messages=messages
#                 )
#             )

#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStateSnapshotEvent(
#                   type=EventType.STATE_SNAPSHOT,
#                   snapshot=source.state
#                 )
#             )

#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStepFinishedEvent(
#                   type=EventType.STEP_FINISHED,
#                   step_name=event.method_name
#                 )
#             )

#         @crewai_event_bus.on(BridgedTextMessageChunkEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseTextMessageChunkEvent(
#                   type=EventType.TEXT_MESSAGE_CHUNK,
#                   message_id=event.message_id,
#                   role=event.role,
#                   delta=event.delta
#                 )
#             )

#         @crewai_event_bus.on(BridgedToolCallChunkEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseToolCallChunkEvent(
#                   type=EventType.TOOL_CALL_CHUNK,
#                   tool_call_id=event.tool_call_id,
#                   tool_call_name=event.tool_call_name,
#                   delta=event.delta
#                 )
#             )


#         @crewai_event_bus.on(BridgedCustomEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseCustomEvent(
#                   type=EventType.CUSTOM,
#                   name=event.name,
#                   value=event.value
#                 )
#             )

#         @crewai_event_bus.on(BridgedStateSnapshotEvent)
#         def _(source, event):  # pylint: disable=unused-argument
#             crewai_event_bus.emit(
#                 source,
#                 EnterpriseStateSnapshotEvent(
#                   type=EventType.STATE_SNAPSHOT,
#                   snapshot=event.snapshot
#                 )
#             )



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/events.py
================================================
"""
This file is used to bridge the events from the crewai event bus to the ag-ui event bus.
"""

from crewai.utilities.events.base_events import BaseEvent
from ag_ui.core.events import (
  ToolCallChunkEvent,
  TextMessageChunkEvent,
  CustomEvent,
  StateSnapshotEvent
)

class BridgedToolCallChunkEvent(BaseEvent, ToolCallChunkEvent):
    """Bridged tool call chunk event"""

class BridgedTextMessageChunkEvent(BaseEvent, TextMessageChunkEvent):
    """Bridged text message chunk event"""

class BridgedCustomEvent(BaseEvent, CustomEvent):
    """Bridged custom event"""

class BridgedStateSnapshotEvent(BaseEvent, StateSnapshotEvent):
    """Bridged state snapshot event"""


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/sdk.py
================================================
"""
This is a placeholder for the copilotkit_stream function.
"""

import uuid
from typing import List, Any, Optional, Mapping, Dict, Literal, TypedDict
from litellm.types.utils import (
  ModelResponse,
  Choices,
  Message as LiteLLMMessage,
  ChatCompletionMessageToolCall,
  Function as LiteLLMFunction
)
from litellm.litellm_core_utils.streaming_handler import CustomStreamWrapper
from crewai.flow.flow import FlowState
from crewai.utilities.events import crewai_event_bus
from pydantic import BaseModel, Field, TypeAdapter
from ag_ui.core import EventType, Message
from .context import flow_context
from .events import (
  BridgedTextMessageChunkEvent,
  BridgedToolCallChunkEvent,
  BridgedCustomEvent,
  BridgedStateSnapshotEvent
)
from .utils import yield_control

class CopilotKitProperties(BaseModel):
    """CopilotKit properties"""
    actions: List[Any] = Field(default_factory=list)

class CopilotKitState(FlowState):
    """CopilotKit state"""
    messages: List[Any] = Field(default_factory=list)
    copilotkit: CopilotKitProperties = Field(default_factory=CopilotKitProperties)

class PredictStateConfig(TypedDict):
    """
    Predict State Config
    """
    tool_name: str
    tool_argument: Optional[str]

async def copilotkit_predict_state(
        config: Dict[str, PredictStateConfig]
    ) -> Literal[True]:
    """
    Stream tool calls as state to CopilotKit.

    To emit a tool call as streaming CrewAI state, pass the destination key in state,
    the tool name and optionally the tool argument. (If you don't pass the argument name,
    all arguments are emitted under the state key.)

    ```python
    from copilotkit.crewai import copilotkit_predict_state

    await copilotkit_predict_state(
        {
            "steps": {
                "tool": "SearchTool",
                "tool_argument": "steps",
            },
        }
    )
    ```

    Parameters
    ----------
    config : Dict[str, CopilotKitPredictStateConfig]
        The configuration to predict the state.

    Returns
    -------
    Awaitable[bool]
        Always return True.
    """
    flow = flow_context.get(None)

    value = [
        {
            "state_key": k,
            "tool": v["tool_name"],
            "tool_argument": v["tool_argument"]
        } for k, v in config.items()
    ]
    crewai_event_bus.emit(
        flow,
        BridgedCustomEvent(
            type=EventType.CUSTOM,
            name="PredictState",
            value=value
        )
    )

    await yield_control()

    return True

async def copilotkit_emit_state(state: Any) -> Literal[True]:
    """
    Emits intermediate state to CopilotKit.
    Useful if you have a longer running node and you want to update the user with the current state of the node.

    To install the CopilotKit SDK, run:

    ```bash
    pip install copilotkit[crewai]
    ```

    ### Examples

    ```python
    from copilotkit.crewai import copilotkit_emit_state

    for i in range(10):
        await some_long_running_operation(i)
        await copilotkit_emit_state({"progress": i})
    ```

    Parameters
    ----------
    state : Any
        The state to emit (Must be JSON serializable).

    Returns
    -------
    Awaitable[bool]
        Always return True.

    """
    flow = flow_context.get(None)
    crewai_event_bus.emit(
        flow,
        BridgedStateSnapshotEvent(
            type=EventType.STATE_SNAPSHOT,
            snapshot=state
        )
    )

    await yield_control()

    return True

async def copilotkit_stream(response):
    """
    Stream litellm responses token by token to CopilotKit.

    ```python
    response = await copilotkit_stream(
        completion(
            model="openai/gpt-4o",
            messages=messages,
            tools=tools,
            stream=True # this must be set to True for streaming
        )
    )
    ```
    """
    if isinstance(response, ModelResponse):
        return _copilotkit_stream_response(response)
    if isinstance(response, CustomStreamWrapper):
        return await _copilotkit_stream_custom_stream_wrapper(response)
    raise ValueError("Invalid response type")


async def _copilotkit_stream_custom_stream_wrapper(response: CustomStreamWrapper):
    flow = flow_context.get(None)

    message_id: Optional[str] = None
    tool_call_id: str = ""
    content = ""
    created = 0
    model = ""
    system_fingerprint = ""
    finish_reason=None
    all_tool_calls = []

    async for chunk in response:
        if message_id is None:
            message_id = chunk["id"]

        text_content = chunk["choices"][0]["delta"]["content"] or None

        # Stream text messages
        if text_content is not None:
            # add to the current text message
            content += text_content
            crewai_event_bus.emit(
                flow,
                BridgedTextMessageChunkEvent(
                    type=EventType.TEXT_MESSAGE_CHUNK,
                    message_id=message_id,
                    role="assistant",
                    delta=text_content,
                )
            )
            # yield control to the event loop
            await yield_control()

        # Stream tool calls
        tool_calls = chunk["choices"][0]["delta"]["tool_calls"] or None
        tool_call_id = tool_calls[0].id if tool_calls is not None else None
        tool_call_arguments = tool_calls[0].function["arguments"] if tool_calls is not None else None
        tool_call_name = tool_calls[0].function["name"] if tool_calls is not None else None

        if tool_call_id is not None:
            all_tool_calls.append(
                {
                    "id": tool_call_id,
                    "name": tool_call_name,
                    "arguments": "",
                }
            )

        if tool_call_arguments is not None:
            # add to the current tool call
            all_tool_calls[-1]["arguments"] += tool_call_arguments
            crewai_event_bus.emit(
                flow,
                BridgedToolCallChunkEvent(
                    type=EventType.TOOL_CALL_CHUNK,
                    tool_call_id=tool_call_id,
                    tool_call_name=tool_call_name,
                    delta=tool_call_arguments,
                )
            )
            # yield control to the event loop
            await yield_control()

        # Stream finish reason
        finish_reason = chunk["choices"][0]["finish_reason"]
        created = chunk["created"]
        model = chunk["model"]
        system_fingerprint = chunk["system_fingerprint"]

        if finish_reason is not None:
            break

    tool_calls = [
        ChatCompletionMessageToolCall(
            function=LiteLLMFunction(
                arguments=tool_call["arguments"],
                name=tool_call["name"]
            ),
            id=tool_call["id"],
            type="function"
        )
        for tool_call in all_tool_calls
    ]
    return ModelResponse(
        id=message_id,
        created=created,
        model=model,
        object='chat.completion',
        system_fingerprint=system_fingerprint,
        choices=[
            Choices(
                finish_reason=finish_reason,
                index=0,
                message=LiteLLMMessage(
                    content=content,
                    role='assistant',
                    tool_calls=tool_calls if len(tool_calls) > 0 else None,
                    function_call=None
                )
            )
        ]
    )

def _copilotkit_stream_response(response: ModelResponse):
    return response


message_adapter = TypeAdapter(Message)

def litellm_messages_to_ag_ui_messages(messages: List[LiteLLMMessage]) -> List[Message]:
    """
    Converts a list of LiteLLM messages to a list of ag_ui messages.
    """
    ag_ui_messages: List[Message] = []
    for message in messages:
        message_dict = message.model_dump() if not isinstance(message, Mapping) else message

        # whitelist the fields we want to keep
        whitelist = ["content", "role", "tool_calls", "id", "name", "tool_call_id"]
        message_dict = {k: v for k, v in message_dict.items() if k in whitelist}
        if not "id" in message_dict:
            message_dict["id"] = str(uuid.uuid4())
        # remove all None values
        message_dict = {k: v for k, v in message_dict.items() if v is not None}

        if "tool_calls" in message_dict:
            for tool_call in message_dict["tool_calls"]:
                if "type" not in tool_call:
                    tool_call["type"] = "function"

        ag_ui_message = message_adapter.validate_python(message_dict)
        ag_ui_messages.append(ag_ui_message)

    return ag_ui_messages


async def copilotkit_exit() -> Literal[True]:
    """
    Exits the current agent after the run completes. Calling copilotkit_exit() will
    not immediately stop the agent. Instead, it signals to CopilotKit to stop the agent after
    the run completes.

    ### Examples

    ```python
    from copilotkit.crewai import copilotkit_exit

    def my_function():
        await copilotkit_exit()
        return state
    ```

    Returns
    -------
    Awaitable[bool]
        Always return True.
    """

    flow = flow_context.get(None)

    crewai_event_bus.emit(
        flow,
        BridgedCustomEvent(
            type=EventType.CUSTOM,
            name="Exit",
            value=""
        )
    )

    await yield_control()

    return True


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/utils.py
================================================
import asyncio

async def yield_control():
    """
    Yield control to the event loop.
    """
    loop = asyncio.get_running_loop()
    future = loop.create_future()
    loop.call_soon(future.set_result, None)
    await future



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/agentic_chat.py
================================================
"""
A simple agentic chat flow.
"""

from crewai.flow.flow import Flow, start
from litellm import completion
from ..sdk import copilotkit_stream, CopilotKitState

class AgenticChatFlow(Flow[CopilotKitState]):

    @start()
    async def chat(self):
        system_prompt = "You are a helpful assistant."

        # 1. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 1.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 1.2 Bind the available tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                ],

                # 1.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 2. Append the message to the messages in state
        self.state.messages.append(message)



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/agentic_generative_ui.py
================================================
"""
An example demonstrating agentic generative UI.
"""

import json
import asyncio
from crewai.flow.flow import Flow, start, router, listen, or_
from litellm import completion
from pydantic import BaseModel
from typing import Literal, List

from ..sdk import (
  copilotkit_stream,
  CopilotKitState,
  copilotkit_predict_state,
  copilotkit_emit_state
)

# This tool simulates performing a task on the server.
# The tool call will be streamed to the frontend as it is being generated.
PERFORM_TASK_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_task_steps",
        "description": "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in gerund form (i.e. Digging hole, opening door, ...)",
        "parameters": {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "description": {
                                "type": "string",
                                "description": "The text of the step in gerund form"
                            },
                            "status": {
                                "type": "string",
                                "enum": ["pending"],
                                "description": "The status of the step, always 'pending'"
                            }
                        },
                        "required": ["description", "status"]
                    },
                    "description": "An array of 10 step objects, each containing text and status"
                }
            },
            "required": ["steps"]
        }
    }
}

class TaskStep(BaseModel):
    description: str
    status: Literal["pending", "completed"]

class AgentState(CopilotKitState):
    """
    Here we define the state of the agent

    In this instance, we're inheriting from CopilotKitState, which will bring in
    the CopilotKitState fields. We're also adding a custom field, `steps`,
    which will be used to store the steps of the task.
    """
    steps: List[TaskStep] = []


class AgenticGenerativeUIFlow(Flow[AgentState]):
    """
    This is a sample flow that uses the CopilotKit framework to create a chat agent.
    """

    
    @start()
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """
        self.state.steps = []

    @router(or_(start_flow, "simulate_task"))
    async def chat(self):
        """
        Standard chat node.
        """
        system_prompt = """
        You are a helpful assistant assisting with any task. 
        When asked to do something, you MUST call the function `generate_task_steps`
        that was provided to you.
        If you called the function, you MUST NOT repeat the steps in your next response to the user.
        Just give a very brief summary (one sentence) of what you did with some emojis. 
        Always say you actually did the steps, not merely generated them.
        """

        # 1. Here we specify that we want to stream the tool call to generate_task_steps
        #    to the frontend as state.
        await copilotkit_predict_state({
            "steps": {
                "tool_name": "generate_task_steps",
                "tool_argument": "steps"
            }
        })

        # 2. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 2.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 2.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    PERFORM_TASK_TOOL
                ],

                # 2.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 3. Append the message to the messages in state
        self.state.messages.append(message)

        # 4. Handle tool call
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["function"]["name"]
            tool_call_args = json.loads(tool_call["function"]["arguments"])

            if tool_call_name == "generate_task_steps":
                # Convert each step in the JSON array to a TaskStep instance
                self.state.steps = [TaskStep(**step) for step in tool_call_args["steps"]]

                # 4.1 Append the result to the messages in state
                self.state.messages.append({
                    "role": "tool",
                    "content": "Steps executed.",
                    "tool_call_id": tool_call_id
                })
                return "route_simulate_task"

        # 5. If our tool was not called, return to the end route
        return "route_end"

    @listen("route_simulate_task")
    async def simulate_task(self):
        """
        Simulate the task.
        """
        for step in self.state.steps:
            # simulate executing the step
            await asyncio.sleep(1)
            step.status = "completed"
            await copilotkit_emit_state(self.state)

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/human_in_the_loop.py
================================================
"""
An example demonstrating agentic generative UI.
"""

from crewai.flow.flow import Flow, start, router, listen
from litellm import completion
from pydantic import BaseModel
from typing import Literal, List
from ..sdk import (
  copilotkit_stream,
  CopilotKitState,
)

# This tool simulates performing a task on the server.
# The tool call will be streamed to the frontend as it is being generated.
DEFINE_TASK_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_task_steps",
        "description": "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in imperative form (i.e. Dig hole, Open door, ...)",
        "parameters": {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "description": {
                                "type": "string",
                                "description": "The text of the step in imperative form"
                            },
                            "status": {
                                "type": "string",
                                "enum": ["enabled"],
                                "description": "The status of the step, always 'enabled'"
                            }
                        },
                        "required": ["description", "status"]
                    },
                    "description": "An array of 10 step objects, each containing text and status"
                }
            },
            "required": ["steps"]
        }
    }
}

class TaskStep(BaseModel):
    description: str
    status: Literal["enabled", "disabled"]

class AgentState(CopilotKitState):
    """
    Here we define the state of the agent

    In this instance, we're inheriting from CopilotKitState, which will bring in
    the CopilotKitState fields. We're also adding a custom field, `steps`,
    which will be used to store the steps of the task.
    """
    steps: List[TaskStep] = []


class HumanInTheLoopFlow(Flow[AgentState]):
    """
    This is a sample flow that uses the CopilotKit framework to create a chat agent.
    """

    @start()
    @listen("route_follow_up")
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """

    @router(start_flow)
    async def chat(self):
        """
        Standard chat node.
        """
        system_prompt = """
        You are a helpful assistant that can perform any task.
        You MUST call the `generate_task_steps` function when the user asks you to perform a task.
        When the function `generate_task_steps` is called, the user will decide to enable or disable a step.
        After the user has decided which steps to perform, provide a textual description of how you are performing the task.
        If the user has disabled a step, you are not allowed to perform that step.
        However, you should find a creative workaround to perform the task, and if an essential step is disabled, you can even use
        some humor in the description of how you are performing the task.
        Don't just repeat a list of steps, come up with a creative but short description (3 sentences max) of how you are performing the task.
        """

        # 1. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 1.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 1.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    DEFINE_TASK_TOOL
                ],

                # 1.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 2. Append the message to the messages in state
        self.state.messages.append(message)

        return "route_end"

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/predictive_state_updates.py
================================================
"""
A demo of predictive state updates.
"""

import json
import uuid
from typing import Optional
from litellm import completion
from crewai.flow.flow import Flow, start, router, listen
from ..sdk import (
  copilotkit_stream, 
  copilotkit_predict_state,
  CopilotKitState
)

WRITE_DOCUMENT_TOOL = {
    "type": "function",
    "function": {
        "name": "write_document_local",
        "description": " ".join("""
            Write a document. Use markdown formatting to format the document.
            It's good to format the document extensively so it's easy to read.
            You can use all kinds of markdown.
            However, do not use italic or strike-through formatting, it's reserved for another purpose.
            You MUST write the full document, even when changing only a few words.
            When making edits to the document, try to make them minimal - do not change every word.
            Keep stories SHORT!
            """.split()),
        "parameters": {
            "type": "object",
            "properties": {
                "document": {
                    "type": "string",
                    "description": "The document to write"
                },
            },
        }
    }
}


class AgentState(CopilotKitState):
    """
    The state of the agent.
    """
    document: Optional[str] = None

class PredictiveStateUpdatesFlow(Flow[AgentState]):
    """
    This is a sample flow that demonstrates predictive state updates.
    """

    @start()
    @listen("route_follow_up")
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """

    @router(start_flow)
    async def chat(self):
        """
        Standard chat node.
        """
        system_prompt = f"""
        You are a helpful assistant for writing documents.
        To write the document, you MUST use the write_document_local tool.
        You MUST write the full document, even when changing only a few words.
        When you wrote the document, DO NOT repeat it as a message. 
        Just briefly summarize the changes you made. 2 sentences max.
        This is the current state of the document: ----\n {self.state.document}\n-----
        """

        # 1. Here we specify that we want to stream the tool call to write_document_local
        #    to the frontend as state.
        await copilotkit_predict_state({
            "document": {
                "tool_name": "write_document_local",
                "tool_argument": "document"
            }
        })

        # 2. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 2.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 2.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    WRITE_DOCUMENT_TOOL
                ],

                # 2.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 3. Append the message to the messages in state
        self.state.messages.append(message)

        # 4. Handle tool call
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["function"]["name"]
            tool_call_args = json.loads(tool_call["function"]["arguments"])

            if tool_call_name == "write_document_local":
                self.state.document = tool_call_args["document"]

                # 4.1 Append the result to the messages in state
                self.state.messages.append({
                    "role": "tool",
                    "content": "Document written.",
                    "tool_call_id": tool_call_id
                })

                # 4.2 Append a tool call to confirm changes
                self.state.messages.append({
                    "role": "assistant",
                    "content": "",
                    "tool_calls": [{
                        "id": str(uuid.uuid4()),
                        "function": {
                            "name": "confirm_changes",
                            "arguments": "{}"
                        }
                    }]
                })

                return "route_end"

        # 5. If our tool was not called, return to the end route
        return "route_end"

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/shared_state.py
================================================
"""
A demo of shared state between the agent and CopilotKit.
"""

import json
from enum import Enum
from typing import List, Optional
from litellm import completion
from pydantic import BaseModel, Field
from crewai.flow.flow import Flow, start, router, listen
from ..sdk import (
  copilotkit_stream, 
  copilotkit_predict_state,
  CopilotKitState
)

class SkillLevel(str, Enum):
    """
    The level of skill required for the recipe.
    """
    BEGINNER = "Beginner"
    INTERMEDIATE = "Intermediate"
    ADVANCED = "Advanced"

class CookingTime(str, Enum):
    """
    The cooking time of the recipe.
    """
    FIVE_MIN = "5 min"
    FIFTEEN_MIN = "15 min"
    THIRTY_MIN = "30 min"
    FORTY_FIVE_MIN = "45 min"
    SIXTY_PLUS_MIN = "60+ min"

class Ingredient(BaseModel):
    """
    An ingredient with its details.
    """
    icon: str = Field(..., description="Emoji icon representing the ingredient.")
    name: str = Field(..., description="Name of the ingredient.")
    amount: str = Field(..., description="Amount or quantity of the ingredient.")

GENERATE_RECIPE_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_recipe",
        "description": " ".join("""Generate or modify an existing recipe. 
        When creating a new recipe, specify all fields. 
        When modifying, only fill optional fields if they need changes; 
        otherwise, leave them empty.""".split()),
        "parameters": {
            "type": "object",
            "properties": {
                "recipe": {
                    "description": "The recipe object containing all details.",
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "The title of the recipe."
                        },
                        "skill_level": {
                            "type": "string",
                            "enum": [level.value for level in SkillLevel],
                            "description": "The skill level required for the recipe."
                        },
                        "special_preferences": {
                            "type": "array",
                            "items": {
                                "type": "string"
                            },
                            "description": "A list of dietary preferences (e.g., Vegetarian, Gluten-free)."
                        },
                        "cooking_time": {
                            "type": "string",
                            "enum": [time.value for time in CookingTime],
                            "description": "The estimated cooking time for the recipe."
                        },
                        "ingredients": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "icon": {"type": "string", "description": "Emoji icon for the ingredient."},
                                    "name": {"type": "string", "description": "Name of the ingredient."},
                                    "amount": {"type": "string", "description": "Amount/quantity of the ingredient."}
                                },
                                "required": ["icon", "name", "amount"]
                            },
                            "description": "A list of ingredients required for the recipe."
                        },
                        "instructions": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Step-by-step instructions for preparing the recipe."
                        }
                    },
                    "required": ["title", "skill_level", "cooking_time", "special_preferences", "ingredients", "instructions"]
                }
            },
            "required": ["recipe"]
        }
    }
}

class Recipe(BaseModel):
    """
    A recipe.
    """
    title: str
    skill_level: SkillLevel
    special_preferences: List[str] = Field(default_factory=list)
    cooking_time: CookingTime
    ingredients: List[Ingredient] = Field(default_factory=list)
    instructions: List[str] = Field(default_factory=list)


class AgentState(CopilotKitState):
    """
    The state of the recipe.
    """
    recipe: Optional[Recipe] = None

class SharedStateFlow(Flow[AgentState]):
    """
    This is a sample flow that demonstrates shared state between the agent and CopilotKit.
    """

    @start()
    @listen("route_follow_up")
    async def start_flow(self):
        """
        This is the entry point for the flow.
        """
        print(f"start_flow")
        print(f"self.state: {self.state}")

    @router(start_flow)
    async def chat(self):
        """
        Standard chat node.
        """
 
        system_prompt = f"""You are a helpful assistant for creating recipes. 
        This is the current state of the recipe: {self.state.model_dump_json(indent=2)}
        You can modify the recipe by calling the generate_recipe tool.
        If you have just created or modified the recipe, just answer in one sentence what you did.
        """

        # 1. Here we specify that we want to stream the tool call to generate_recipe
        #    to the frontend as state.
        await copilotkit_predict_state({
            "recipe": {
                "tool_name": "generate_recipe",
                "tool_argument": "recipe"
            }
        })

        # 2. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 2.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 2.2 Bind the tools to the model
                tools=[
                    *self.state.copilotkit.actions,
                    GENERATE_RECIPE_TOOL
                ],

                # 2.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )

        message = response.choices[0].message

        # 3. Append the message to the messages in state
        self.state.messages.append(message)

        # 4. Handle tool call
        if message.get("tool_calls"):
            tool_call = message["tool_calls"][0]
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["function"]["name"]
            tool_call_args = json.loads(tool_call["function"]["arguments"])

            if tool_call_name == "generate_recipe":
                # Attempt to update the recipe state using the data from the tool call
                try:
                    updated_recipe_data = tool_call_args["recipe"]
                    # Validate and update the state. Pydantic will raise an error if the structure is wrong.
                    self.state.recipe = Recipe(**updated_recipe_data)

                    # 4.1 Append the result to the messages in state
                    self.state.messages.append({
                        "role": "tool",
                        "content": "Recipe updated.", # More accurate message
                        "tool_call_id": tool_call_id
                    })
                    return "route_follow_up"
                except Exception as e:
                    # Handle validation or other errors during update
                    print(f"Error updating recipe state: {e}") # Log the error server-side
                    # Optionally inform the user via a tool message, though it might be noisy
                    # self.state.messages.append({"role": "tool", "content": f"Error processing recipe update: {e}", "tool_call_id": tool_call_id})
                    return "route_end" # End the flow on error for now

        # 5. If our tool was not called, return to the end route
        return "route_end"

    @listen("route_end")
    async def end(self):
        """
        End the flow.
        """



================================================
FILE: typescript-sdk/integrations/crewai/python/ag_ui_crewai/examples/tool_based_generative_ui.py
================================================
"""
An example demonstrating tool-based generative UI.
"""

from crewai.flow.flow import Flow, start
from litellm import completion
from ..sdk import copilotkit_stream, CopilotKitState


# This tool generates a haiku on the server.
# The tool call will be streamed to the frontend as it is being generated.
GENERATE_HAIKU_TOOL = {
    "type": "function",
    "function": {
        "name": "generate_haiku",
        "description": "Generate a haiku in Japanese and its English translation",
        "parameters": {
            "type": "object",
            "properties": {
                "japanese": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "An array of three lines of the haiku in Japanese"
                },
                "english": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "An array of three lines of the haiku in English"
                },
                "image_names": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "Names of 3 relevant images from the provided list"
                }
            },
            "required": ["japanese", "english", "image_names"]
        }
    }
}


class ToolBasedGenerativeUIFlow(Flow[CopilotKitState]):
    """
    A flow that demonstrates tool-based generative UI.
    """

    @start()
    async def chat(self):
        """
        The main function handling chat and tool calls.
        """
        system_prompt = "You assist the user in generating a haiku. When generating a haiku using the 'generate_haiku' tool, you MUST also select exactly 3 image filenames from the following list that are most relevant to the haiku's content or theme. Return the filenames in the 'image_names' parameter. Dont provide the relavent image names in your final response to the user. "


        # 1. Run the model and stream the response
        #    Note: In order to stream the response, wrap the completion call in
        #    copilotkit_stream and set stream=True.
        response = await copilotkit_stream(
            completion(

                # 1.1 Specify the model to use
                model="openai/gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": system_prompt
                    },
                    *self.state.messages
                ],

                # 1.2 Bind the available tools to the model
                tools=[ GENERATE_HAIKU_TOOL ],

                # 1.3 Disable parallel tool calls to avoid race conditions,
                #     enable this for faster performance if you want to manage
                #     the complexity of running tool calls in parallel.
                parallel_tool_calls=False,
                stream=True
            )
        )
        message = response.choices[0].message

        # 2. Append the message to the messages in state
        self.state.messages.append(message)

        # 3. If there are tool calls, append a tool message to the messages in state
        if message.tool_calls:
            self.state.messages.append(
                {
                    "tool_call_id": message.tool_calls[0].id,
                    "role": "tool",
                    "content": "Haiku generated."
                }
            )



================================================
FILE: typescript-sdk/integrations/crewai/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/crewai/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class CrewAIAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/langgraph/README.md
================================================
# @ag-ui/langgraph

Implementation of the AG-UI protocol for LangGraph.

Connects LangGraph graphs to frontend applications via the AG-UI protocol. Supports both local TypeScript graphs and remote LangGraph Cloud deployments with full state management and interrupt handling.

## Installation

```bash
npm install @ag-ui/langgraph
pnpm add @ag-ui/langgraph
yarn add @ag-ui/langgraph
```

## Usage

```ts
import { LangGraphAgent } from "@ag-ui/langgraph";

// Create an AG-UI compatible agent
const agent = new LangGraphAgent({
  graphId: "my-graph",
  deploymentUrl: "https://your-langgraph-deployment.com",
  langsmithApiKey: "your-api-key",
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Start the workflow" }],
});
```

## Features

- **Cloud & local support** – Works with LangGraph Cloud and local graph instances
- **State management** – Bidirectional state synchronization with graph nodes
- **Interrupt handling** – Human-in-the-loop workflow support
- **Step tracking** – Real-time node execution progress

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/langgraph/examples
langgraph dev
```



================================================
FILE: typescript-sdk/integrations/langgraph/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/langgraph/package.json
================================================
{
  "name": "@ag-ui/langgraph",
  "version": "0.0.17",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@langchain/core": "^0.3.66",
    "@langchain/langgraph-sdk": "^0.1.2",
    "partial-json": "^0.1.7",
    "rxjs": "7.8.1"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.38",
    "@ag-ui/client": ">=0.0.38"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/langgraph/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/langgraph/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/langgraph/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
examples


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/README.md
================================================
# LangGraph examples

## How to run

First, make sure to create a new .env file from the .env.example and include the required keys.

To run the Python examples for langgraph platform, run:
```
cd typescript-sdk/integrations/langgraph/examples/python
pnpx @langchain/langgraph-cli@latest dev
```

To run the python examples using FastAPI, run:
```
cd typescript-sdk/integrations/langgraph/examples/python
poetry install
poetry run dev
```

Note that when running them both concurrently, poetry and the langgraph-cli will step on eachothers toes and install/uninstall eachothers dependencies.
You can fix this by running the poetry commands with virtualenvs.in-project set to false. You can set this permanently for the project using:
`poetry config virtualenvs.create false --local`, globally using `poetry config virtualenvs.create false`, or temporarily using an environment variable:

```
export POETRY_VIRTUALENVS_IN_PROJECT=false
poetry install
poetry run dev
```
or
```
POETRY_VIRTUALENVS_IN_PROJECT=false poetry install
POETRY_VIRTUALENVS_IN_PROJECT=false poetry run dev
```



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/langgraph.json
================================================
{
  "python_version": "3.12",
  "dockerfile_lines": [],
  "dependencies": ["."],
  "graphs": {
    "agentic_chat": "./agents/agentic_chat/agent.py:graph",
    "agentic_generative_ui": "./agents/agentic_generative_ui/agent.py:graph",
    "human_in_the_loop": "./agents/human_in_the_loop/agent.py:graph",
    "predictive_state_updates": "./agents/predictive_state_updates/agent.py:graph",
    "shared_state": "./agents/shared_state/agent.py:graph",
    "tool_based_generative_ui": "./agents/tool_based_generative_ui/agent.py:graph",
    "agentic_chat_reasoning": "./agents/agentic_chat_reasoning/agent.py:graph",
    "subgraphs": "./agents/subgraphs/agent.py:graph"
  },
  "env": ".env"
}



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/pyproject.toml
================================================
[tool.poetry]
name = "langgraph_agui_dojo"
version = "0.1.0"
description = ""
readme = "README.md"
packages = [{ include = "agents" }]

[project]
name = "agents"
version = "0.0.1"

[tool.poetry.dependencies]
python = ">=3.12,<3.14"
uvicorn = "^0.34.0"
dotenv = "^0.9.9"
langchain = ">=0.1.0"
langchain-anthropic = ">=0.3.18"
langchain-core = ">=0.1.5"
langchain-community = ">=0.0.1"
langchain-experimental = ">=0.0.11"
langchain-google-genai = ">=2.1.9"
langchain-openai = ">=0.0.1"
langgraph = "^0.6.1"
ag-ui-langgraph = { version = "0.0.14a0", extras = ["fastapi"] }
python-dotenv = "^1.0.0"
fastapi = "^0.115.12"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "agents.dojo:main"


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/.env.example
================================================
OPENAI_API_KEY=
LANGSMITH_API_KEY=



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/dojo.py
================================================
import os
import uvicorn
from fastapi import FastAPI

from dotenv import load_dotenv
load_dotenv()

os.environ["LANGGRAPH_FAST_API"] = "true"

from ag_ui_langgraph import LangGraphAgent, add_langgraph_fastapi_endpoint
from .human_in_the_loop.agent import graph as human_in_the_loop_graph
from .predictive_state_updates.agent import graph as predictive_state_updates_graph
from .shared_state.agent import graph as shared_state_graph
from .tool_based_generative_ui.agent import graph as tool_based_generative_ui_graph
from .agentic_chat.agent import graph as agentic_chat_graph
from .agentic_generative_ui.agent import graph as agentic_generative_ui_graph
from .agentic_chat_reasoning.agent import graph as agentic_chat_reasoning_graph
from .subgraphs.agent import graph as subgraphs_graph

app = FastAPI(title="LangGraph Dojo Example Server")

agents = {
    # Register the LangGraph agent using the LangGraphAgent class
    "agentic_chat": LangGraphAgent(
        name="agentic_chat",
        description="An example for an agentic chat flow using LangGraph.",
        graph=agentic_chat_graph
    ),
    "tool_based_generative_ui": LangGraphAgent(
        name="tool_based_generative_ui",
        description="An example for a tool-based generative UI flow.",
        graph=tool_based_generative_ui_graph,
    ),
    "agentic_generative_ui": LangGraphAgent(
        name="agentic_generative_ui",
        description="An example for an agentic generative UI flow.",
        graph=agentic_generative_ui_graph,
    ),
    "human_in_the_loop": LangGraphAgent(
        name="human_in_the_loop",
        description="An example for a human in the loop flow.",
        graph=human_in_the_loop_graph,
    ),
    "shared_state": LangGraphAgent(
        name="shared_state",
        description="An example for a shared state flow.",
        graph=shared_state_graph,
    ),
    "predictive_state_updates": LangGraphAgent(
        name="predictive_state_updates",
        description="An example for a predictive state updates flow.",
        graph=predictive_state_updates_graph,
    ),
    "agentic_chat_reasoning": LangGraphAgent(
        name="agentic_chat_reasoning",
        description="An example for a reasoning chat.",
        graph=agentic_chat_reasoning_graph,
    ),
    "subgraphs": LangGraphAgent(
        name="subgraphs",
        description="A demo of LangGraph subgraphs using a Game Character Creator.",
        graph=subgraphs_graph,
    ),
}

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["agentic_chat"],
    path="/agent/agentic_chat"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["tool_based_generative_ui"],
    path="/agent/tool_based_generative_ui"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["agentic_generative_ui"],
    path="/agent/agentic_generative_ui"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["human_in_the_loop"],
    path="/agent/human_in_the_loop"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["shared_state"],
    path="/agent/shared_state"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["predictive_state_updates"],
    path="/agent/predictive_state_updates"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["agentic_chat_reasoning"],
    path="/agent/agentic_chat_reasoning"
)

add_langgraph_fastapi_endpoint(
    app=app,
    agent=agents["subgraphs"],
    path="/agent/subgraphs"
)

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "agents.dojo:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat/agent.py
================================================
"""
A simple agentic chat flow using LangGraph instead of CrewAI.
"""

from typing import List, Any, Optional
import os

# Updated imports for LangGraph
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.graph import MessagesState
from langgraph.types import Command

class AgentState(MessagesState):
    """
    State of our graph.
    """
    tools: List[Any]

async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node based on the ReAct design pattern. It handles:
    - The model to use (and binds in CopilotKit actions and the tools defined above)
    - The system prompt
    - Getting a response from the model
    - Handling tool calls

    For more about the ReAct design pattern, see: 
    https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
    """

    # 1. Define the model
    model = ChatOpenAI(model="gpt-4o")

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # 2. Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            # your_tool_here
        ],

        # 2.1 Disable parallel tool calls to avoid race conditions,
        #     enable this for faster performance if you want to manage
        #     the complexity of running tool calls in parallel.
        parallel_tool_calls=False,
    )

    # 3. Define the system message by which the chat model will be run
    system_message = SystemMessage(
        content="You are a helpful assistant."
    )

    # 4. Run the model to generate a response
    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)

    # 6. We've handled all tool calls, so we can end the graph.
    return Command(
        goto=END,
        update={
            "messages": response
        }
    )

# Define a new graph
workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("chat_node")

# Add explicit edges, matching the pattern in other examples
workflow.add_edge(START, "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat_reasoning/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_chat_reasoning/agent.py
================================================
"""
A simple agentic chat flow using LangGraph instead of CrewAI.
"""

from typing import List, Any, Optional
import os

from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END, START
from langgraph.graph import MessagesState
from langgraph.types import Command
from langgraph.checkpoint.memory import MemorySaver

class AgentState(MessagesState):
    """
    State of our graph.
    """
    tools: List[Any]
    model: str

async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node based on the ReAct design pattern. It handles:
    - The model to use (and binds in CopilotKit actions and the tools defined above)
    - The system prompt
    - Getting a response from the model
    - Handling tool calls

    For more about the ReAct design pattern, see:
    https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
    """


    # 1. Define the model
    model = ChatOpenAI(model="o3")
    if state["model"] == "Anthropic":
        model = ChatAnthropic(
            model="claude-sonnet-4-20250514",
            thinking={"type": "enabled", "budget_tokens": 2000}
        )
    elif state["model"] == "Gemini":
        model = ChatGoogleGenerativeAI(model="gemini-2.5-pro", thinking_budget=1024)

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # 2. Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            # your_tool_here
        ],
    )

    # 3. Define the system message by which the chat model will be run
    system_message = SystemMessage(
        content="You are a helpful assistant."
    )

    # 4. Run the model to generate a response
    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)

    # 6. We've handled all tool calls, so we can end the graph.
    return Command(
        goto=END,
        update={
            "messages": response
        }
    )

# Define a new graph
workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("chat_node")

# Add explicit edges, matching the pattern in other examples
workflow.add_edge(START, "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_generative_ui/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/agentic_generative_ui/agent.py
================================================
"""
An example demonstrating agentic generative UI using LangGraph.
"""

import asyncio
from typing import List, Any, Optional, Annotated
import os

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langchain_core.callbacks.manager import adispatch_custom_event
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.graph import MessagesState
from pydantic import BaseModel, Field

class Step(BaseModel):
    """
    A step in a task.
    """
    description: str = Field(description="The text of the step in gerund form")
    status: str = Field(description="The status of the step, always 'pending'")



# This tool simulates performing a task on the server.
# The tool call will be streamed to the frontend as it is being generated.
@tool
def generate_task_steps_generative_ui(
    steps: Annotated[ # pylint: disable=unused-argument
        List[Step],
        "An array of 10 step objects, each containing text and status"
    ]
):
    """
    Make up 10 steps (only a couple of words per step) that are required for a task.
    The step should be in gerund form (i.e. Digging hole, opening door, ...).
    """


class AgentState(MessagesState):
    """
    State of the agent.
    """
    steps: List[dict] = []
    tools: List[Any]


async def start_node(state: AgentState, config: RunnableConfig): # pylint: disable=unused-argument
    """
    This is the entry point for the flow.
    """

    if "steps" not in state:
        state["steps"] = []

    return Command(
        goto="chat_node",
        update={
            "messages": state["messages"],
            "steps": state["steps"]
        }
    )


async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node.
    """
    system_prompt = """
    You are a helpful assistant assisting with any task. 
    When asked to do something, you MUST call the function `generate_task_steps_generative_ui`
    that was provided to you.
    If you called the function, you MUST NOT repeat the steps in your next response to the user.
    Just give a very brief summary (one sentence) of what you did with some emojis. 
    Always say you actually did the steps, not merely generated them.
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o")

    # Define config for the model with emit_intermediate_state to stream tool calls to frontend
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document tool
    config["metadata"]["predict_state"] = [{
        "state_key": "steps",
        "tool": "generate_task_steps_generative_ui",
        "tool_argument": "steps",
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            generate_task_steps_generative_ui
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model to generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    messages = state["messages"] + [response]

    # Extract any tool calls from the response
    if hasattr(response, "tool_calls") and response.tool_calls and len(response.tool_calls) > 0:
        # Handle dicts or object (backward compatibility)
        tool_call = (response.tool_calls[0]
                     if isinstance(response.tool_calls[0], dict)
                     else vars(response.tool_calls[0]))

        if tool_call["name"] == "generate_task_steps_generative_ui":
            steps = [
                {"description": step["description"], "status": step["status"]}
                for step in tool_call["args"]["steps"]
            ]

            # Add the tool response to messages
            tool_response = {
                "role": "tool",
                "content": "Steps executed.",
                "tool_call_id": tool_call["id"]
            }

            messages = messages + [tool_response]
            state["steps"] = steps

            # Return Command to route to simulate_task_node
            for i, _ in enumerate(steps):
            # simulate executing the step
                await asyncio.sleep(1)
                steps[i]["status"] = "completed"
                # Update the state with the completed step using config
                await adispatch_custom_event(
                    "manually_emit_state",
                    state,
                    config=config,
                )

            return Command(
                goto='start_node',
                update={
                    "messages": messages,
                    "steps": state["steps"]
                }
            )

    return Command(
        goto=END,
        update={
            "messages": messages,
            "steps": state["steps"]
        }
    )


# Define the graph
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)

# Add edges
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/human_in_the_loop/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/human_in_the_loop/agent.py
================================================
"""
A LangGraph implementation of the human-in-the-loop agent.
"""

from typing import Dict, List, Any, Annotated, Optional
import os

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command, interrupt
from langgraph.graph import MessagesState
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class Step(BaseModel):
    """
    A step in a task.
    """
    description: str = Field(description="The text of the step in imperative form")
    status: str = Field(description="The status of the step, always 'enabled'")

@tool
def plan_execution_steps(
    steps: Annotated[ # pylint: disable=unused-argument
        List[Step],
        "An array of 10 step objects, each containing text and status"
    ]
):
    """
    Make up 10 steps (only a couple of words per step) that are required for a task.
    The step should be in imperative form (i.e. Dig hole, Open door, ...).
    """

class AgentState(MessagesState):
    """
    State of the agent.
    """
    steps: List[Dict[str, str]] = []
    tools: List[Any]

async def start_node(state: Dict[str, Any], config: RunnableConfig): # pylint: disable=unused-argument
    """
    This is the entry point for the flow.
    """

    # Initialize steps list if not exists
    if "steps" not in state:
        state["steps"] = []

    # Return command to route to chat_node
    return Command(
        goto="chat_node",
        update={
            "messages": state["messages"],
            "steps": state["steps"],
        }
    )


async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node where the agent processes messages and generates responses.
    If task steps are defined, the user can enable/disable them using interrupts.
    """
    system_prompt = """
    You are a helpful assistant that can perform any task.
    You MUST call the `plan_execution_steps` function when the user asks you to perform a task.
    Always make sure you will provide tasks based on the user query
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o-mini")

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document tool
    config["metadata"]["predict_state"] = [{
        "state_key": "steps",
        "tool": "plan_execution_steps",
        "tool_argument": "steps"
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            plan_execution_steps
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model and generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    # Update messages with the response
    messages = state["messages"] + [response]

    # Handle tool calls
    if hasattr(response, "tool_calls") and response.tool_calls and len(response.tool_calls) > 0:
        # Handle dicts or object (backward compatibility)
        tool_call = (response.tool_calls[0]
                     if isinstance(response.tool_calls[0], dict)
                     else vars(response.tool_calls[0]))

        if tool_call["name"] == "plan_execution_steps":
            # Get the steps from the tool call
            steps_raw = tool_call["args"]["steps"]

            # Set initial status to "enabled" for all steps
            steps_data = []

            # Handle different potential formats of steps data
            if isinstance(steps_raw, list):
                for step in steps_raw:
                    if isinstance(step, dict) and "description" in step:
                        steps_data.append({
                            "description": step["description"],
                            "status": "enabled"
                        })
                    elif isinstance(step, str):
                        steps_data.append({
                            "description": step,
                            "status": "enabled"
                        })

            # If no steps were processed correctly, return to END with the updated messages
            if not steps_data:
                return Command(
                    goto=END,
                    update={
                        "messages": messages,
                        "steps": state["steps"],
                    }
                )
            # Update steps in state and emit to frontend
            state["steps"] = steps_data

            # Add a tool response to satisfy OpenAI's requirements
            tool_response = {
                "role": "tool",
                "content": "Task steps generated.",
                "tool_call_id": tool_call["id"]
            }

            messages = messages + [tool_response]

            # Move to the process_steps_node which will handle the interrupt and final response
            return Command(
                goto="process_steps_node",
                update={
                    "messages": messages,
                    "steps": state["steps"],
                }
            )

    # If no tool calls or not plan_execution_steps, return to END with the updated messages
    return Command(
        goto=END,
        update={
            "messages": messages,
            "steps": state["steps"],
        }
    )


async def process_steps_node(state: Dict[str, Any], config: RunnableConfig):
    """
    This node handles the user interrupt for step customization and generates the final response.
    """

    # Check if we already have a user_response in the state
    # This happens when the node restarts after an interrupt
    if "user_response" in state and state["user_response"]:
        user_response = state["user_response"]
    else:
        # Use LangGraph interrupt to get user input on steps
        # This will pause execution and wait for user input in the frontend
        user_response = interrupt({"steps": state["steps"]})
        # Store the user response in state for when the node restarts
        state["user_response"] = user_response

    # Generate the creative completion response
    final_prompt = """
    Provide a textual description of how you are performing the task.
    If the user has disabled a step, you are not allowed to perform that step.
    However, you should find a creative workaround to perform the task, and if an essential step is disabled, you can even use
    some humor in the description of how you are performing the task.
    Don't just repeat a list of steps, come up with a creative but short description (3 sentences max) of how you are performing the task.
    """

    final_response = await ChatOpenAI(model="gpt-4o").ainvoke([
        SystemMessage(content=final_prompt),
        {"role": "user", "content": user_response}
    ], config)

    # Add the final response to messages
    messages = state["messages"] + [final_response]

    # Clear the user_response from state to prepare for future interactions
    if "user_response" in state:
        state.pop("user_response")

    # Return to END with the updated messages
    return Command(
        goto=END,
        update={
            "messages": messages,
            "steps": state["steps"],
        }
    )


# Define the graph
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)
workflow.add_node("process_steps_node", process_steps_node)

# Add edges
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("process_steps_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/predictive_state_updates/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/predictive_state_updates/agent.py
================================================
"""
A demo of predictive state updates using LangGraph.
"""

import uuid
from typing import List, Any, Optional
import os

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.graph import MessagesState
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI

@tool
def write_document_local(document: str): # pylint: disable=unused-argument
    """
    Write a document. Use markdown formatting to format the document.
    It's good to format the document extensively so it's easy to read.
    You can use all kinds of markdown.
    However, do not use italic or strike-through formatting, it's reserved for another purpose.
    You MUST write the full document, even when changing only a few words.
    When making edits to the document, try to make them minimal - do not change every word.
    Keep stories SHORT!
    """
    return document

class AgentState(MessagesState):
    """
    The state of the agent.
    """
    document: Optional[str] = None
    tools: List[Any]


async def start_node(state: AgentState, config: RunnableConfig): # pylint: disable=unused-argument
    """
    This is the entry point for the flow.
    """
    return Command(
        goto="chat_node"
    )


async def chat_node(state: AgentState, config: Optional[RunnableConfig] = None):
    """
    Standard chat node.
    """

    system_prompt = f"""
    You are a helpful assistant for writing documents.
    To write the document, you MUST use the write_document_local tool.
    You MUST write the full document, even when changing only a few words.
    When you wrote the document, DO NOT repeat it as a message.
    Just briefly summarize the changes you made. 2 sentences max.
    This is the current state of the document: ----\n {state.get('document')}\n-----
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o")

    # Define config for the model with emit_intermediate_state to stream tool calls to frontend
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document_local tool
    config["metadata"]["predict_state"] = [{
        "state_key": "document",
        "tool": "write_document_local",
        "tool_argument": "document"
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            write_document_local
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model to generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    # Update messages with the response
    messages = state["messages"] + [response]

    # Extract any tool calls from the response
    if hasattr(response, "tool_calls") and response.tool_calls:
        tool_call = response.tool_calls[0]

        # Handle tool_call as a dictionary or an object
        if isinstance(tool_call, dict):
            tool_call_id = tool_call["id"]
            tool_call_name = tool_call["name"]
            tool_call_args = tool_call["args"]
        else:
            # Handle as an object (backward compatibility)
            tool_call_id = tool_call.id
            tool_call_name = tool_call.name
            tool_call_args = tool_call.args

        if tool_call_name == "write_document_local":
            # Add the tool response to messages
            tool_response = {
                "role": "tool",
                "content": "Document written.",
                "tool_call_id": tool_call_id
            }

            # Add confirmation tool call
            confirm_tool_call = {
                "role": "assistant",
                "content": "",
                "tool_calls": [{
                    "id": str(uuid.uuid4()),
                    "function": {
                        "name": "confirm_changes",
                        "arguments": "{}"
                    }
                }]
            }

            messages = messages + [tool_response, confirm_tool_call]

            # Return Command to route to end
            return Command(
                goto=END,
                update={
                    "messages": messages,
                    "document": tool_call_args["document"]
                }
            )

    # If no tool was called, go to end
    return Command(
        goto=END,
        update={
            "messages": messages
        }
    )


# Define the graph
workflow = StateGraph(AgentState)
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()




================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/shared_state/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/shared_state/agent.py
================================================
"""
A demo of shared state between the agent and CopilotKit using LangGraph.
"""

import json
from enum import Enum
from typing import Dict, List, Any, Optional
import os

# LangGraph imports
from pydantic import BaseModel, Field
from langchain_core.runnables import RunnableConfig
from langchain_core.callbacks.manager import adispatch_custom_event
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command
from langgraph.graph import MessagesState
from langgraph.checkpoint.memory import MemorySaver

class SkillLevel(str, Enum):
    """
    The level of skill required for the recipe.
    """
    BEGINNER = "Beginner"
    INTERMEDIATE = "Intermediate"
    ADVANCED = "Advanced"

class SpecialPreferences(str, Enum):
    """
    Special preferences for the recipe.
    """
    HIGH_PROTEIN = "High Protein"
    LOW_CARB = "Low Carb"
    SPICY = "Spicy"
    BUDGET_FRIENDLY = "Budget-Friendly"
    ONE_POT_MEAL = "One-Pot Meal"
    VEGETARIAN = "Vegetarian"
    VEGAN = "Vegan"

class CookingTime(str, Enum):
    """
    The cooking time of the recipe.
    """
    FIVE_MIN = "5 min"
    FIFTEEN_MIN = "15 min"
    THIRTY_MIN = "30 min"
    FORTY_FIVE_MIN = "45 min"
    SIXTY_PLUS_MIN = "60+ min"

class Ingredient(BaseModel):
    """
    An ingredient.
    """
    icon: str = Field(
        description="Icon: the actual emoji like 🥕"
    )
    name: str = Field(description="The name of the ingredient")
    amount: str = Field(description="The amount of the ingredient")

class Recipe(BaseModel):
    """
    A recipe.
    """
    skill_level: SkillLevel = \
        Field(description="The skill level required for the recipe")
    special_preferences: List[SpecialPreferences] = \
        Field(description="A list of special preferences for the recipe")
    cooking_time: CookingTime = \
        Field(description="The cooking time of the recipe")
    ingredients: List[Ingredient] = \
        Field(description=
              """Entire list of ingredients for the recipe, including the new ingredients
              and the ones that are already in the recipe: Icon: the actual emoji like 🥕,
              name and amount.
              Like so: 🥕 Carrots (250g)"""
        )
    instructions: List[str] = \
        Field(description=
              """Entire list of instructions for the recipe,
              including the new instructions and the ones that are already there"""
        )
    changes: str = \
        Field(description="A description of the changes made to the recipe")

class GenerateRecipeArgs(BaseModel): # pylint: disable=missing-class-docstring
    recipe: Recipe

@tool(args_schema=GenerateRecipeArgs)
def generate_recipe(recipe: Recipe): # pylint: disable=unused-argument
    """
    Using the existing (if any) ingredients and instructions, proceed with the recipe to finish it.
    Make sure the recipe is complete. ALWAYS provide the entire recipe, not just the changes.
    """

class AgentState(MessagesState):
    """
    The state of the recipe.
    """
    recipe: Optional[Dict[str, Any]] = None
    tools: List[Any]


async def start_node(state: Dict[str, Any], config: RunnableConfig):
    """
    This is the entry point for the flow.
    """

    # Initialize recipe if not exists
    if "recipe" not in state or state["recipe"] is None:
        state["recipe"] = {
            "skill_level": SkillLevel.BEGINNER.value,
            "special_preferences": [],
            "cooking_time": CookingTime.FIFTEEN_MIN.value,
            "ingredients": [{"icon": "🍴", "name": "Sample Ingredient", "amount": "1 unit"}],
            "instructions": ["First step instruction"]
        }
        # Emit the initial state to ensure it's properly shared with the frontend
        await adispatch_custom_event(
            "manually_emit_intermediate_state",
            state,
            config=config,
        )

    return Command(
        goto="chat_node",
        update={
            "messages": state["messages"],
            "recipe": state["recipe"]
        }
    )

async def chat_node(state: Dict[str, Any], config: RunnableConfig):
    """
    Standard chat node.
    """
    # Create a safer serialization of the recipe
    recipe_json = "No recipe yet"
    if "recipe" in state and state["recipe"] is not None:
        try:
            recipe_json = json.dumps(state["recipe"], indent=2)
        except Exception as e: # pylint: disable=broad-exception-caught
            recipe_json = f"Error serializing recipe: {str(e)}"

    system_prompt = f"""You are a helpful assistant for creating recipes. 
    This is the current state of the recipe: {recipe_json}
    You can improve the recipe by calling the generate_recipe tool.
    
    IMPORTANT:
    1. Create a recipe using the existing ingredients and instructions. Make sure the recipe is complete.
    2. For ingredients, append new ingredients to the existing ones.
    3. For instructions, append new steps to the existing ones.
    4. 'ingredients' is always an array of objects with 'icon', 'name', and 'amount' fields
    5. 'instructions' is always an array of strings

    If you have just created or modified the recipe, just answer in one sentence what you did. dont describe the recipe, just say what you did.
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o-mini")

    # Define config for the model
    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Use "predict_state" metadata to set up streaming for the write_document tool
    config["metadata"]["predict_state"] = [{
        "state_key": "recipe",
        "tool": "generate_recipe",
        "tool_argument": "recipe"
    }]

    # Bind the tools to the model
    model_with_tools = model.bind_tools(
        [
            *state["tools"],
            generate_recipe
        ],
        # Disable parallel tool calls to avoid race conditions
        parallel_tool_calls=False,
    )

    # Run the model and generate a response
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    # Update messages with the response
    messages = state["messages"] + [response]

    # Handle tool calls
    if hasattr(response, "tool_calls") and response.tool_calls:
        # Handle dicts or object (backward compatibility)
        tool_call = (response.tool_calls[0]
                     if isinstance(response.tool_calls[0], dict)
                     else vars(response.tool_calls[0]))

        # Check if args is already a dict or needs to be parsed
        tool_call_args = (tool_call["args"]
                          if isinstance(tool_call["args"], dict)
                          else json.loads(tool_call["args"]))

        if tool_call["name"] == "generate_recipe":
            # Update recipe state with tool_call_args
            recipe_data = tool_call_args["recipe"]

            # If we have an existing recipe, update it
            if "recipe" in state and state["recipe"] is not None:
                recipe = state["recipe"]
                for key, value in recipe_data.items():
                    if value is not None:  # Only update fields that were provided
                        recipe[key] = value
            else:
                # Create a new recipe
                recipe = {
                    "skill_level": recipe_data.get("skill_level", SkillLevel.BEGINNER.value),
                    "special_preferences": recipe_data.get("special_preferences", []),
                    "cooking_time": recipe_data.get("cooking_time", CookingTime.FIFTEEN_MIN.value),
                    "ingredients": recipe_data.get("ingredients", []),
                    "instructions": recipe_data.get("instructions", [])
                }

            # Add tool response to messages
            tool_response = {
                "role": "tool",
                "content": "Recipe generated.",
                "tool_call_id": tool_call["id"]
            }

            messages = messages + [tool_response]

            # Explicitly emit the updated state to ensure it's shared with frontend
            state["recipe"] = recipe
            await adispatch_custom_event(
                "manually_emit_intermediate_state",
                state,
                config=config,
            )

            # Return command with updated recipe
            return Command(
                goto="start_node",
                update={
                    "messages": messages,
                    "recipe": recipe
                }
            )

    return Command(
        goto=END,
        update={
            "messages": messages,
            "recipe": state["recipe"]
        }
    )


# Define the graph
workflow = StateGraph(AgentState)
workflow.add_node("start_node", start_node)
workflow.add_node("chat_node", chat_node)
workflow.set_entry_point("start_node")
workflow.add_edge(START, "start_node")
workflow.add_edge("start_node", "chat_node")
workflow.add_edge("chat_node", END)

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/subgraphs/__init__.py
================================================
# Subgraphs demo module


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/subgraphs/agent.py
================================================
"""
A travel agent supervisor demo showcasing multi-agent architecture with subgraphs.
The supervisor coordinates specialized agents: flights finder, hotels finder, and experiences finder.
"""

from typing import Dict, List, Any, Optional, Annotated, Union
from dataclasses import dataclass
import json
import os
from pydantic import BaseModel, Field

# LangGraph imports
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END, START
from langgraph.types import Command, interrupt
from langgraph.graph import MessagesState

# OpenAI imports
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage

def create_interrupt(message: str, options: List[Any], recommendation: Any, agent: str):
    return interrupt({
        "message": message,
        "options": options,
        "recommendation": recommendation,
        "agent": agent,
    })

# State schema for travel planning
@dataclass
class Flight:
    airline: str
    departure: str
    arrival: str
    price: str
    duration: str

@dataclass
class Hotel:
    name: str
    location: str
    price_per_night: str
    rating: str

@dataclass
class Experience:
    name: str
    type: str  # "restaurant" or "activity"
    description: str
    location: str

def merge_itinerary(left: Union[dict, None] = None, right: Union[dict, None] = None) -> dict:
    """Custom reducer to merge shopping cart updates."""
    if not left:
        left = {}
    if not right:
        right = {}

    return {**left, **right}

class TravelAgentState(MessagesState):
    """Shared state for the travel agent system"""
    # Travel request details
    origin: str = ""
    destination: str = ""

    # Results from each agent
    flights: List[Flight] = None
    hotels: List[Hotel] = None
    experiences: List[Experience] = None

    itinerary: Annotated[dict, merge_itinerary] = None

    # Tools available to all agents
    tools: List[Any] = None

    # Supervisor routing
    next_agent: Optional[str] = None

# Static data for demonstration
STATIC_FLIGHTS = [
    Flight("KLM", "Amsterdam (AMS)", "San Francisco (SFO)", "$650", "11h 30m"),
    Flight("United", "Amsterdam (AMS)", "San Francisco (SFO)", "$720", "12h 15m")
]

STATIC_HOTELS = [
    Hotel("Hotel Zephyr", "Fisherman's Wharf", "$280/night", "4.2 stars"),
    Hotel("The Ritz-Carlton", "Nob Hill", "$550/night", "4.8 stars"),
    Hotel("Hotel Zoe", "Union Square", "$320/night", "4.4 stars")
]

STATIC_EXPERIENCES = [
    Experience("Pier 39", "activity", "Iconic waterfront destination with shops and sea lions", "Fisherman's Wharf"),
    Experience("Golden Gate Bridge", "activity", "World-famous suspension bridge with stunning views", "Golden Gate"),
    Experience("Swan Oyster Depot", "restaurant", "Historic seafood counter serving fresh oysters", "Polk Street"),
    Experience("Tartine Bakery", "restaurant", "Artisanal bakery famous for bread and pastries", "Mission District")
]

# Flights finder subgraph
async def flights_finder(state: TravelAgentState, config: RunnableConfig):
    """Subgraph that finds flight options"""

    # Simulate flight search with static data
    flights = STATIC_FLIGHTS

    selected_flight = state.get('itinerary', {}).get('flight', None)
    if not selected_flight:
        selected_flight = create_interrupt(
            message=f"""
        Found {len(flights)} flight options from {state.get('origin', 'Amsterdam')} to {state.get('destination', 'San Francisco')}.
        I recommend choosing the flight by {flights[0].airline} since it's known to be on time and cheaper.
        """,
            options=flights,
            recommendation=flights[0],
            agent="flights"
        )

    if isinstance(selected_flight, str):
        selected_flight = json.loads(selected_flight)
    return Command(
        goto=END,
        update={
            "flights": flights,
            "itinerary": {
                "flight": selected_flight
            },
            "messages": state["messages"] + [{
                "role": "assistant",
                "content": f"Flights Agent: Great. I'll book you the {selected_flight["airline"]} flight from {selected_flight["departure"]} to {selected_flight["arrival"]}."
            }]
        }
    )

# Hotels finder subgraph
async def hotels_finder(state: TravelAgentState, config: RunnableConfig):
    """Subgraph that finds hotel options"""

    # Simulate hotel search with static data
    hotels = STATIC_HOTELS
    selected_hotel = state.get('itinerary', {}).get('hotel', None)
    if not selected_hotel:
        selected_hotel = create_interrupt(
            message=f"""
        Found {len(hotels)} accommodation options in {state.get('destination', 'San Francisco')}.
        I recommend choosing the {hotels[2].name} since it strikes the balance between rating, price, and location.
        """,
            options=hotels,
            recommendation=hotels[2],
            agent="hotels"
        )

    if isinstance(selected_hotel, str):
        selected_hotel = json.loads(selected_hotel)
    return Command(
            goto=END,
            update={
                "hotels": hotels,
                "itinerary": {
                    "hotel": selected_hotel
                },
                "messages": state["messages"] + [{
                    "role": "assistant",
                    "content": f"Hotels Agent: Excellent choice! You'll like {selected_hotel["name"]}."
                }]
            }
        )

# Experiences finder subgraph
async def experiences_finder(state: TravelAgentState, config: RunnableConfig):
    """Subgraph that finds restaurant and activity recommendations"""

    # Filter experiences (2 restaurants, 2 activities)
    restaurants = [exp for exp in STATIC_EXPERIENCES if exp.type == "restaurant"][:2]
    activities = [exp for exp in STATIC_EXPERIENCES if exp.type == "activity"][:2]
    experiences = restaurants + activities

    model = ChatOpenAI(model="gpt-4o")

    if config is None:
        config = RunnableConfig(recursion_limit=25)

    itinerary = state.get("itinerary", {})

    system_prompt = f"""
    You are the experiences agent. Your job is to find restaurants and activities for the user.
    You already went ahead and found a bunch of experiences. All you have to do now, is to let the user know of your findings.
    
    Current status:
    - Origin: {state.get('origin', 'Amsterdam')}
    - Destination: {state.get('destination', 'San Francisco')}
    - Flight chosen: {itinerary.get("hotel", None)}
    - Hotel chosen: {itinerary.get("hotel", None)}
    - activities found: {activities}
    - restaurants found: {restaurants}
    """

    # Get supervisor decision
    response = await model.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    return Command(
        goto=END,
        update={
            "experiences": experiences,
            "messages": state["messages"] + [response]
        }
    )

class SupervisorResponseFormatter(BaseModel):
    """Always use this tool to structure your response to the user."""
    answer: str = Field(description="The answer to the user")
    next_agent: str | None = Field(description="The agent to go to. Not required if you do not want to route to another agent.")

# Supervisor agent
async def supervisor_agent(state: TravelAgentState, config: RunnableConfig):
    """Main supervisor that coordinates all subgraphs"""

    itinerary = state.get("itinerary", {})

    # Check what's already completed
    has_flights = itinerary.get("flight", None) is not None
    has_hotels = itinerary.get("hotel", None) is not None
    has_experiences = state.get("experiences", None) is not None

    system_prompt = f"""
    You are a travel planning supervisor. Your job is to coordinate specialized agents to help plan a trip.
    
    Current status:
    - Origin: {state.get('origin', 'Amsterdam')}
    - Destination: {state.get('destination', 'San Francisco')}
    - Flights found: {has_flights}
    - Hotels found: {has_hotels}
    - Experiences found: {has_experiences}
    - Itinerary (Things that the user has already confirmed selection on): {json.dumps(itinerary, indent=2)}
    
    Available agents:
    - flights_agent: Finds flight options
    - hotels_agent: Finds hotel options  
    - experiences_agent: Finds restaurant and activity recommendations
    - {END}: Mark task as complete when all information is gathered
    
    You must route to the appropriate agent based on what's missing. Once all agents have completed their tasks, route to 'complete'.
    """

    # Define the model
    model = ChatOpenAI(model="gpt-4o")

    if config is None:
        config = RunnableConfig(recursion_limit=25)

    # Bind the routing tool
    model_with_tools = model.bind_tools(
        [SupervisorResponseFormatter],
        parallel_tool_calls=False,
    )

    # Get supervisor decision
    response = await model_with_tools.ainvoke([
        SystemMessage(content=system_prompt),
        *state["messages"],
    ], config)

    messages = state["messages"] + [response]

    # Handle tool calls for routing
    if hasattr(response, "tool_calls") and response.tool_calls:
        tool_call = response.tool_calls[0]

        if isinstance(tool_call, dict):
            tool_call_args = tool_call["args"]
        else:
            tool_call_args = tool_call.args

        next_agent = tool_call_args["next_agent"]

        # Add tool response
        tool_response = {
            "role": "tool",
            "content": f"Routing to {next_agent} and providing the answer",
            "tool_call_id": tool_call.id if hasattr(tool_call, 'id') else tool_call["id"]
        }

        messages = messages + [tool_response, AIMessage(content=tool_call_args["answer"])]

        if next_agent is not None:
            return Command(goto=next_agent)

    # Fallback if no tool call
    return Command(
        goto=END,
        update={"messages": messages}
    )

# Create subgraphs
flights_graph = StateGraph(TravelAgentState)
flights_graph.add_node("flights_agent_chat_node", flights_finder)
flights_graph.set_entry_point("flights_agent_chat_node")
flights_graph.add_edge(START, "flights_agent_chat_node")
flights_graph.add_edge("flights_agent_chat_node", END)
flights_subgraph = flights_graph.compile()

hotels_graph = StateGraph(TravelAgentState)
hotels_graph.add_node("hotels_agent_chat_node", hotels_finder)
hotels_graph.set_entry_point("hotels_agent_chat_node")
hotels_graph.add_edge(START, "hotels_agent_chat_node")
hotels_graph.add_edge("hotels_agent_chat_node", END)
hotels_subgraph = hotels_graph.compile()

experiences_graph = StateGraph(TravelAgentState)
experiences_graph.add_node("experiences_agent_chat_node", experiences_finder)
experiences_graph.set_entry_point("experiences_agent_chat_node")
experiences_graph.add_edge(START, "experiences_agent_chat_node")
experiences_graph.add_edge("experiences_agent_chat_node", END)
experiences_subgraph = experiences_graph.compile()

# Main supervisor workflow
workflow = StateGraph(TravelAgentState)

# Add supervisor and subgraphs as nodes
workflow.add_node("supervisor", supervisor_agent)
workflow.add_node("flights_agent", flights_subgraph)
workflow.add_node("hotels_agent", hotels_subgraph)
workflow.add_node("experiences_agent", experiences_subgraph)

# Set entry point
workflow.set_entry_point("supervisor")
workflow.add_edge(START, "supervisor")

# Add edges back to supervisor after each subgraph
workflow.add_edge("flights_agent", "supervisor")
workflow.add_edge("hotels_agent", "supervisor")
workflow.add_edge("experiences_agent", "supervisor")

# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/tool_based_generative_ui/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/examples/python/agents/tool_based_generative_ui/agent.py
================================================
"""
An example demonstrating tool-based generative UI using LangGraph.
"""

import os
from typing import Any, List
from typing_extensions import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.types import Command
from langgraph.graph import MessagesState
from langgraph.prebuilt import ToolNode


class AgentState(MessagesState):
    """
    State of the agent.
    """
    tools: List[Any]

async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["tool_node", "__end__"]]:
    """
    Standard chat node based on the ReAct design pattern. It handles:
    - The model to use (and binds in CopilotKit actions and the tools defined above)
    - The system prompt
    - Getting a response from the model
    - Handling tool calls

    For more about the ReAct design pattern, see:
    https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
    """

    model = ChatOpenAI(model="gpt-4o")

    model_with_tools = model.bind_tools(
        [
            *state.get("tools", []), # bind tools defined by ag-ui
        ],
        parallel_tool_calls=False,
    )

    system_message = SystemMessage(
        content=f"Help the user with writing Haikus. If the user asks for a haiku, use the generate_haiku tool to display the haiku to the user."
    )

    response = await model_with_tools.ainvoke([
        system_message,
        *state["messages"],
    ], config)

    return Command(
        goto=END,
        update={
            "messages": [response],
        }
    )

workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
# This is required even though we don't have any backend tools to pass in.
workflow.add_node("tool_node", ToolNode(tools=[]))
workflow.set_entry_point("chat_node")
workflow.add_edge("chat_node", END)


# Conditionally use a checkpointer based on the environment
# Check for multiple indicators that we're running in LangGraph dev/API mode
is_fast_api = os.environ.get("LANGGRAPH_FAST_API", "false").lower() == "true"

# Compile the graph
if is_fast_api:
    # For CopilotKit and other contexts, use MemorySaver
    from langgraph.checkpoint.memory import MemorySaver
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
else:
    # When running in LangGraph API/dev, don't use a custom checkpointer
    graph = workflow.compile()



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/README.md
================================================
# LangGraph TypeScript Examples

This directory contains TypeScript versions of the LangGraph examples, providing the same functionality as the Python examples but implemented in TypeScript.

## How to run

First, make sure to create a new `.env` file from the `.env.example` and include the required keys:

```bash
cp .env.example .env
```

Then edit the `.env` file and add your API keys:
- `OPENAI_API_KEY`: Your OpenAI API key
- `TAVILY_API_KEY`: Your Tavily API key (if needed)

Install dependencies:

```bash
npm install
```

For TypeScript development, run:

```bash
npm run build
pnpx @langchain/langgraph-cli@latest dev
```

## Available Agents

This project includes TypeScript implementations of the following agents:

### 1. Agentic Chat (`agentic_chat`)
A simple agentic chat flow using LangGraph following the ReAct design pattern. Handles tool binding, system prompts, and model responses.

### 2. Agentic Generative UI (`agentic_generative_ui`)
Demonstrates agentic generative UI capabilities. Creates task steps and simulates their execution while streaming updates to the frontend.

### 3. Human in the Loop (`human_in_the_loop`)
Implements human-in-the-loop functionality where users can interact with and modify the agent's proposed steps before execution.

### 4. Predictive State Updates (`predictive_state_updates`)
Shows predictive state updates for document writing with streaming tool calls to the frontend.

### 5. Shared State (`shared_state`)
Demonstrates shared state management between the agent and CopilotKit, focusing on recipe creation and modification.

### 6. Tool-based Generative UI (`tool_based_generative_ui`)
Example of tool-based generative UI for haiku generation with image selection capabilities.

## Project Structure

```
typescript-sdk/integrations/langgraph/examples/typescript/
├── src/
│   └── agents/
│       ├── agentic_chat/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── agentic_generative_ui/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── human_in_the_loop/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── predictive_state_updates/
│       │   ├── agent.ts
│       │   └── index.ts
│       ├── shared_state/
│       │   ├── agent.ts
│       │   └── index.ts
│       └── tool_based_generative_ui/
│           ├── agent.ts
│           └── index.ts
├── package.json
├── tsconfig.json
├── langgraph.json
├── .env.example
└── README.md
```

## Dependencies

- `@langchain/core`: Core LangChain functionality
- `@langchain/openai`: OpenAI integration
- `@langchain/langgraph`: LangGraph for building stateful agents
- `dotenv`: Environment variable management
- `uuid`: UUID generation for tool calls
- `typescript`: TypeScript compiler

## Development

To build the project:

```bash
npm run build
```

To start development with LangGraph CLI:

```bash
npm run dev
```

## Notes

These TypeScript implementations maintain the same functionality as their Python counterparts while following TypeScript/JavaScript conventions and patterns. Each agent is fully typed and includes proper error handling and state management.


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/langgraph.json
================================================
{
  "dependencies": ["."],
  "graphs": {
    "agentic_chat": "./src/agents/agentic_chat/agent.ts:agenticChatGraph",
    "agentic_generative_ui": "./src/agents/agentic_generative_ui/agent.ts:agenticGenerativeUiGraph",
    "human_in_the_loop": "./src/agents/human_in_the_loop/agent.ts:humanInTheLoopGraph",
    "predictive_state_updates": "./src/agents/predictive_state_updates/agent.ts:predictiveStateUpdatesGraph",
    "shared_state": "./src/agents/shared_state/agent.ts:sharedStateGraph",
    "tool_based_generative_ui": "./src/agents/tool_based_generative_ui/agent.ts:toolBasedGenerativeUiGraph",
    "subgraphs": "./src/agents/subgraphs/agent.ts:subGraphsAgentGraph"
  },
  "env": ".env"
}



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/package.json
================================================
{
  "name": "langgraph-agui-dojo-typescript",
  "version": "0.1.0",
  "description": "TypeScript examples for LangGraph agents with CopilotKit integration",
  "type": "module",
  "scripts": {
    "build": "tsc",
    "dev": "pnpx @langchain/langgraph-cli@latest dev",
    "start": "node dist/index.js"
  },
  "dependencies": {
    "@langchain/core": "^0.3.66",
    "@langchain/openai": "^0.6.3",
    "@langchain/langgraph": "^0.2.65",
    "dotenv": "^16.4.5",
    "uuid": "^10.0.0"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "@types/uuid": "^10.0.0",
    "typescript": "^5.0.0"
  }
}


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/pnpm-lock.yaml
================================================
lockfileVersion: '9.0'

settings:
  autoInstallPeers: true
  excludeLinksFromLockfile: false

importers:

  .:
    dependencies:
      '@langchain/core':
        specifier: ^0.3.66
        version: 0.3.66(openai@5.10.2(zod@3.25.76))
      '@langchain/langgraph':
        specifier: ^0.2.65
        version: 0.2.74(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))(zod-to-json-schema@3.24.6(zod@3.25.76))
      '@langchain/openai':
        specifier: ^0.6.3
        version: 0.6.3(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))
      dotenv:
        specifier: ^16.4.5
        version: 16.6.1
      uuid:
        specifier: ^10.0.0
        version: 10.0.0
    devDependencies:
      '@types/node':
        specifier: ^20.0.0
        version: 20.19.9
      '@types/uuid':
        specifier: ^10.0.0
        version: 10.0.0
      typescript:
        specifier: ^5.0.0
        version: 5.8.3

packages:

  '@cfworker/json-schema@4.1.1':
    resolution: {integrity: sha512-gAmrUZSGtKc3AiBL71iNWxDsyUC5uMaKKGdvzYsBoTW/xi42JQHl7eKV2OYzCUqvc+D2RCcf7EXY2iCyFIk6og==}

  '@langchain/core@0.3.66':
    resolution: {integrity: sha512-d3SgSDOlgOjdIbReIXVQl9HaQzKqO/5+E+o3kJwoKXLGP9dxi7+lMyaII7yv7G8/aUxMWLwFES9zc1jFoeJEZw==}
    engines: {node: '>=18'}

  '@langchain/langgraph-checkpoint@0.0.18':
    resolution: {integrity: sha512-IS7zJj36VgY+4pf8ZjsVuUWef7oTwt1y9ylvwu0aLuOn1d0fg05Om9DLm3v2GZ2Df6bhLV1kfWAM0IAl9O5rQQ==}
    engines: {node: '>=18'}
    peerDependencies:
      '@langchain/core': '>=0.2.31 <0.4.0'

  '@langchain/langgraph-sdk@0.0.104':
    resolution: {integrity: sha512-wUO6GMy65Y7DsWtjTJ3dA59enrZy2wN4o48AMYN7dF7u/PMXXYyBjBCKSzgVWqO6uWH2yNpyGDrcMwKuk5kQLA==}
    peerDependencies:
      '@langchain/core': '>=0.2.31 <0.4.0'
      react: ^18 || ^19
      react-dom: ^18 || ^19
    peerDependenciesMeta:
      '@langchain/core':
        optional: true
      react:
        optional: true
      react-dom:
        optional: true

  '@langchain/langgraph@0.2.74':
    resolution: {integrity: sha512-oHpEi5sTZTPaeZX1UnzfM2OAJ21QGQrwReTV6+QnX7h8nDCBzhtipAw1cK616S+X8zpcVOjgOtJuaJhXa4mN8w==}
    engines: {node: '>=18'}
    peerDependencies:
      '@langchain/core': '>=0.2.36 <0.3.0 || >=0.3.40 < 0.4.0'
      zod-to-json-schema: ^3.x
    peerDependenciesMeta:
      zod-to-json-schema:
        optional: true

  '@langchain/openai@0.6.3':
    resolution: {integrity: sha512-dSNuXDTJitDzN8D2wFNqWVELDbBRhMpJiFeiWpHjfPuq7R6wSjzNNY/Uk6x+FLpvbOs/zKNWy5+0q0p3KrCjRQ==}
    engines: {node: '>=18'}
    peerDependencies:
      '@langchain/core': '>=0.3.58 <0.4.0'

  '@types/json-schema@7.0.15':
    resolution: {integrity: sha512-5+fP8P8MFNC+AyZCDxrB2pkZFPGzqQWUzpSeuuVLvm8VMcorNYavBqoFcxK8bQz4Qsbn4oUEEem4wDLfcysGHA==}

  '@types/node@20.19.9':
    resolution: {integrity: sha512-cuVNgarYWZqxRJDQHEB58GEONhOK79QVR/qYx4S7kcUObQvUwvFnYxJuuHUKm2aieN9X3yZB4LZsuYNU1Qphsw==}

  '@types/retry@0.12.0':
    resolution: {integrity: sha512-wWKOClTTiizcZhXnPY4wikVAwmdYHp8q6DmC+EJUzAMsycb7HB32Kh9RN4+0gExjmPmZSAQjgURXIGATPegAvA==}

  '@types/uuid@10.0.0':
    resolution: {integrity: sha512-7gqG38EyHgyP1S+7+xomFtL+ZNHcKv6DwNaCZmJmo1vgMugyF3TCnXVg4t1uk89mLNwnLtnY3TpOpCOyp1/xHQ==}

  ansi-styles@4.3.0:
    resolution: {integrity: sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==}
    engines: {node: '>=8'}

  ansi-styles@5.2.0:
    resolution: {integrity: sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==}
    engines: {node: '>=10'}

  base64-js@1.5.1:
    resolution: {integrity: sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==}

  camelcase@6.3.0:
    resolution: {integrity: sha512-Gmy6FhYlCY7uOElZUSbxo2UCDH8owEk996gkbrpsgGtrJLM3J7jGxl9Ic7Qwwj4ivOE5AWZWRMecDdF7hqGjFA==}
    engines: {node: '>=10'}

  chalk@4.1.2:
    resolution: {integrity: sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==}
    engines: {node: '>=10'}

  color-convert@2.0.1:
    resolution: {integrity: sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==}
    engines: {node: '>=7.0.0'}

  color-name@1.1.4:
    resolution: {integrity: sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==}

  console-table-printer@2.14.6:
    resolution: {integrity: sha512-MCBl5HNVaFuuHW6FGbL/4fB7N/ormCy+tQ+sxTrF6QtSbSNETvPuOVbkJBhzDgYhvjWGrTma4eYJa37ZuoQsPw==}

  decamelize@1.2.0:
    resolution: {integrity: sha512-z2S+W9X73hAUUki+N+9Za2lBlun89zigOyGrsax+KUQ6wKW4ZoWpEYBkGhQjwAjjDCkWxhY0VKEhk8wzY7F5cA==}
    engines: {node: '>=0.10.0'}

  dotenv@16.6.1:
    resolution: {integrity: sha512-uBq4egWHTcTt33a72vpSG0z3HnPuIl6NqYcTrKEg2azoEyl2hpW0zqlxysq2pK9HlDIHyHyakeYaYnSAwd8bow==}
    engines: {node: '>=12'}

  eventemitter3@4.0.7:
    resolution: {integrity: sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw==}

  has-flag@4.0.0:
    resolution: {integrity: sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==}
    engines: {node: '>=8'}

  js-tiktoken@1.0.20:
    resolution: {integrity: sha512-Xlaqhhs8VfCd6Sh7a1cFkZHQbYTLCwVJJWiHVxBYzLPxW0XsoxBy1hitmjkdIjD3Aon5BXLHFwU5O8WUx6HH+A==}

  langsmith@0.3.49:
    resolution: {integrity: sha512-hVLpGzTDq4dFffScKuF9yIuwXqp6LJCsvxK4UjmLae+oEodfnFIQ6yVmNyhxFnm3QuRl1NY8qLFul3k+R1YnGQ==}
    peerDependencies:
      '@opentelemetry/api': '*'
      '@opentelemetry/exporter-trace-otlp-proto': '*'
      '@opentelemetry/sdk-trace-base': '*'
      openai: '*'
    peerDependenciesMeta:
      '@opentelemetry/api':
        optional: true
      '@opentelemetry/exporter-trace-otlp-proto':
        optional: true
      '@opentelemetry/sdk-trace-base':
        optional: true
      openai:
        optional: true

  mustache@4.2.0:
    resolution: {integrity: sha512-71ippSywq5Yb7/tVYyGbkBggbU8H3u5Rz56fH60jGFgr8uHwxs+aSKeqmluIVzM0m0kB7xQjKS6qPfd0b2ZoqQ==}
    hasBin: true

  openai@5.10.2:
    resolution: {integrity: sha512-n+vi74LzHtvlKcDPn9aApgELGiu5CwhaLG40zxLTlFQdoSJCLACORIPC2uVQ3JEYAbqapM+XyRKFy2Thej7bIw==}
    hasBin: true
    peerDependencies:
      ws: ^8.18.0
      zod: ^3.23.8
    peerDependenciesMeta:
      ws:
        optional: true
      zod:
        optional: true

  p-finally@1.0.0:
    resolution: {integrity: sha512-LICb2p9CB7FS+0eR1oqWnHhp0FljGLZCWBE9aix0Uye9W8LTQPwMTYVGWQWIw9RdQiDg4+epXQODwIYJtSJaow==}
    engines: {node: '>=4'}

  p-queue@6.6.2:
    resolution: {integrity: sha512-RwFpb72c/BhQLEXIZ5K2e+AhgNVmIejGlTgiB9MzZ0e93GRvqZ7uSi0dvRF7/XIXDeNkra2fNHBxTyPDGySpjQ==}
    engines: {node: '>=8'}

  p-retry@4.6.2:
    resolution: {integrity: sha512-312Id396EbJdvRONlngUx0NydfrIQ5lsYu0znKVUzVvArzEIt08V1qhtyESbGVd1FGX7UKtiFp5uwKZdM8wIuQ==}
    engines: {node: '>=8'}

  p-timeout@3.2.0:
    resolution: {integrity: sha512-rhIwUycgwwKcP9yTOOFK/AKsAopjjCakVqLHePO3CC6Mir1Z99xT+R63jZxAT5lFZLa2inS5h+ZS2GvR99/FBg==}
    engines: {node: '>=8'}

  retry@0.13.1:
    resolution: {integrity: sha512-XQBQ3I8W1Cge0Seh+6gjj03LbmRFWuoszgK9ooCpwYIrhhoO80pfq4cUkU5DkknwfOfFteRwlZ56PYOGYyFWdg==}
    engines: {node: '>= 4'}

  semver@7.7.2:
    resolution: {integrity: sha512-RF0Fw+rO5AMf9MAyaRXI4AV0Ulj5lMHqVxxdSgiVbixSCXoEmmX/jk0CuJw4+3SqroYO9VoUh+HcuJivvtJemA==}
    engines: {node: '>=10'}
    hasBin: true

  simple-wcswidth@1.1.2:
    resolution: {integrity: sha512-j7piyCjAeTDSjzTSQ7DokZtMNwNlEAyxqSZeCS+CXH7fJ4jx3FuJ/mTW3mE+6JLs4VJBbcll0Kjn+KXI5t21Iw==}

  supports-color@7.2.0:
    resolution: {integrity: sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==}
    engines: {node: '>=8'}

  typescript@5.8.3:
    resolution: {integrity: sha512-p1diW6TqL9L07nNxvRMM7hMMw4c5XOo/1ibL4aAIGmSAt9slTE1Xgw5KWuof2uTOvCg9BY7ZRi+GaF+7sfgPeQ==}
    engines: {node: '>=14.17'}
    hasBin: true

  undici-types@6.21.0:
    resolution: {integrity: sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==}

  uuid@10.0.0:
    resolution: {integrity: sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==}
    hasBin: true

  uuid@9.0.1:
    resolution: {integrity: sha512-b+1eJOlsR9K8HJpow9Ok3fiWOWSIcIzXodvv0rQjVoOVNpWMpxf1wZNpt4y9h10odCNrqnYp1OBzRktckBe3sA==}
    hasBin: true

  zod-to-json-schema@3.24.6:
    resolution: {integrity: sha512-h/z3PKvcTcTetyjl1fkj79MHNEjm+HpD6NXheWjzOekY7kV+lwDYnHw+ivHkijnCSMz1yJaWBD9vu/Fcmk+vEg==}
    peerDependencies:
      zod: ^3.24.1

  zod@3.25.76:
    resolution: {integrity: sha512-gzUt/qt81nXsFGKIFcC3YnfEAx5NkunCfnDlvuBSSFS02bcXu4Lmea0AFIUwbLWxWPx3d9p8S5QoaujKcNQxcQ==}

snapshots:

  '@cfworker/json-schema@4.1.1': {}

  '@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76))':
    dependencies:
      '@cfworker/json-schema': 4.1.1
      ansi-styles: 5.2.0
      camelcase: 6.3.0
      decamelize: 1.2.0
      js-tiktoken: 1.0.20
      langsmith: 0.3.49(openai@5.10.2(zod@3.25.76))
      mustache: 4.2.0
      p-queue: 6.6.2
      p-retry: 4.6.2
      uuid: 10.0.0
      zod: 3.25.76
      zod-to-json-schema: 3.24.6(zod@3.25.76)
    transitivePeerDependencies:
      - '@opentelemetry/api'
      - '@opentelemetry/exporter-trace-otlp-proto'
      - '@opentelemetry/sdk-trace-base'
      - openai

  '@langchain/langgraph-checkpoint@0.0.18(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))':
    dependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))
      uuid: 10.0.0

  '@langchain/langgraph-sdk@0.0.104(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))':
    dependencies:
      '@types/json-schema': 7.0.15
      p-queue: 6.6.2
      p-retry: 4.6.2
      uuid: 9.0.1
    optionalDependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))

  '@langchain/langgraph@0.2.74(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))(zod-to-json-schema@3.24.6(zod@3.25.76))':
    dependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))
      '@langchain/langgraph-checkpoint': 0.0.18(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))
      '@langchain/langgraph-sdk': 0.0.104(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))
      uuid: 10.0.0
      zod: 3.25.76
    optionalDependencies:
      zod-to-json-schema: 3.24.6(zod@3.25.76)
    transitivePeerDependencies:
      - react
      - react-dom

  '@langchain/openai@0.6.3(@langchain/core@0.3.66(openai@5.10.2(zod@3.25.76)))':
    dependencies:
      '@langchain/core': 0.3.66(openai@5.10.2(zod@3.25.76))
      js-tiktoken: 1.0.20
      openai: 5.10.2(zod@3.25.76)
      zod: 3.25.76
    transitivePeerDependencies:
      - ws

  '@types/json-schema@7.0.15': {}

  '@types/node@20.19.9':
    dependencies:
      undici-types: 6.21.0

  '@types/retry@0.12.0': {}

  '@types/uuid@10.0.0': {}

  ansi-styles@4.3.0:
    dependencies:
      color-convert: 2.0.1

  ansi-styles@5.2.0: {}

  base64-js@1.5.1: {}

  camelcase@6.3.0: {}

  chalk@4.1.2:
    dependencies:
      ansi-styles: 4.3.0
      supports-color: 7.2.0

  color-convert@2.0.1:
    dependencies:
      color-name: 1.1.4

  color-name@1.1.4: {}

  console-table-printer@2.14.6:
    dependencies:
      simple-wcswidth: 1.1.2

  decamelize@1.2.0: {}

  dotenv@16.6.1: {}

  eventemitter3@4.0.7: {}

  has-flag@4.0.0: {}

  js-tiktoken@1.0.20:
    dependencies:
      base64-js: 1.5.1

  langsmith@0.3.49(openai@5.10.2(zod@3.25.76)):
    dependencies:
      '@types/uuid': 10.0.0
      chalk: 4.1.2
      console-table-printer: 2.14.6
      p-queue: 6.6.2
      p-retry: 4.6.2
      semver: 7.7.2
      uuid: 10.0.0
    optionalDependencies:
      openai: 5.10.2(zod@3.25.76)

  mustache@4.2.0: {}

  openai@5.10.2(zod@3.25.76):
    optionalDependencies:
      zod: 3.25.76

  p-finally@1.0.0: {}

  p-queue@6.6.2:
    dependencies:
      eventemitter3: 4.0.7
      p-timeout: 3.2.0

  p-retry@4.6.2:
    dependencies:
      '@types/retry': 0.12.0
      retry: 0.13.1

  p-timeout@3.2.0:
    dependencies:
      p-finally: 1.0.0

  retry@0.13.1: {}

  semver@7.7.2: {}

  simple-wcswidth@1.1.2: {}

  supports-color@7.2.0:
    dependencies:
      has-flag: 4.0.0

  typescript@5.8.3: {}

  undici-types@6.21.0: {}

  uuid@10.0.0: {}

  uuid@9.0.1: {}

  zod-to-json-schema@3.24.6(zod@3.25.76):
    dependencies:
      zod: 3.25.76

  zod@3.25.76: {}



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/pnpm-workspace.yaml
================================================
packages:
  - '.'


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "node",
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/.env.example
================================================
OPENAI_API_KEY=your_openai_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/agentic_chat/agent.ts
================================================
/**
 * A simple agentic chat flow using LangGraph instead of CrewAI.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Annotation, MessagesAnnotation, StateGraph, Command, START, END } from "@langchain/langgraph";

const AgentStateAnnotation = Annotation.Root({
  tools: Annotation<any[]>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  ...MessagesAnnotation.spec,
});

type AgentState = typeof AgentStateAnnotation.State;

async function chatNode(state: AgentState, config?: RunnableConfig) {
  /**
   * Standard chat node based on the ReAct design pattern. It handles:
   * - The model to use (and binds in CopilotKit actions and the tools defined above)
   * - The system prompt
   * - Getting a response from the model
   * - Handling tool calls
   *
   * For more about the ReAct design pattern, see: 
   * https://www.perplexity.ai/search/react-agents-NcXLQhreS0WDzpVaS4m9Cg
   */
  
  // 1. Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });
  
  // Define config for the model
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // 2. Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      // your_tool_here
    ],
    {
      // 2.1 Disable parallel tool calls to avoid race conditions,
      //     enable this for faster performance if you want to manage
      //     the complexity of running tool calls in parallel.
      parallel_tool_calls: false,
    }
  );

  // 3. Define the system message by which the chat model will be run
  const systemMessage = new SystemMessage({
    content: "You are a helpful assistant."
  });

  // 4. Run the model to generate a response
  const response = await modelWithTools.invoke([
    systemMessage,
    ...state.messages,
  ], config);

  // 6. We've handled all tool calls, so we can end the graph.
  return new Command({
    goto: END,
    update: {
      messages: [response]
    }
  })
}

// Define a new graph  
const workflow = new StateGraph(AgentStateAnnotation)
  .addNode("chat_node", chatNode)
  .addEdge(START, "chat_node");

// Compile the graph
export const agenticChatGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/agentic_generative_ui/agent.ts
================================================
/**
 * An example demonstrating agentic generative UI using LangGraph.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { dispatchCustomEvent } from "@langchain/core/callbacks/dispatch";
import { Annotation, Command, MessagesAnnotation, StateGraph, END } from "@langchain/langgraph";

// This tool simulates performing a task on the server.
// The tool call will be streamed to the frontend as it is being generated.
const PERFORM_TASK_TOOL = {
  type: "function",
  function: {
    name: "generate_task_steps_generative_ui",
    description: "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in gerund form (i.e. Digging hole, opening door, ...)",
    parameters: {
      type: "object",
      properties: {
        steps: {
          type: "array",
          items: {
            type: "object",
            properties: {
              description: {
                type: "string",
                description: "The text of the step in gerund form"
              },
              status: {
                type: "string",
                enum: ["pending"],
                description: "The status of the step, always 'pending'"
              }
            },
            required: ["description", "status"]
          },
          description: "An array of 10 step objects, each containing text and status"
        }
      },
      required: ["steps"]
    }
  }
};

const AgentStateAnnotation = Annotation.Root({
  steps: Annotation<Array<{ description: string; status: string }>>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  tools: Annotation<any[]>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  ...MessagesAnnotation.spec,
});

type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig) {
  /**
   * This is the entry point for the flow.
   */

  if (!state.steps) {
    state.steps = [];
  }

  return {
    steps: state.steps || []
  };
}

async function chatNode(state: AgentState, config?: RunnableConfig) {
  /**
   * Standard chat node.
   */
  const systemPrompt = `
    You are a helpful assistant assisting with any task. 
    When asked to do something, you MUST call the function \`generate_task_steps_generative_ui\`
    that was provided to you.
    If you called the function, you MUST NOT repeat the steps in your next response to the user.
    Just give a very brief summary (one sentence) of what you did with some emojis. 
    Always say you actually did the steps, not merely generated them.
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });
  
  // Define config for the model with emit_intermediate_state to stream tool calls to frontend
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "steps",
    tool: "generate_task_steps_generative_ui",
    tool_argument: "steps",
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      PERFORM_TASK_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model to generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  const messages = [...state.messages, response];

  // Extract any tool calls from the response
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];
    
    if (toolCall.name === "generate_task_steps_generative_ui") {
      const steps = toolCall.args.steps.map((step: any) => ({
        description: step.description,
        status: step.status
      }));
      
      // Add the tool response to messages
      const toolResponse = {
        role: "tool" as const,
        content: "Steps executed.",
        tool_call_id: toolCall.id
      };

      const updatedMessages = [...messages, toolResponse];

      // Simulate executing the steps
      for (let i = 0; i < steps.length; i++) {
        // simulate executing the step
        await new Promise(resolve => setTimeout(resolve, 1000));
        steps[i].status = "completed";
        // Update the state with the completed step
        state.steps = steps;
        // Emit custom events to update the frontend
        await dispatchCustomEvent("manually_emit_state", state, config);
      }
      
      return new Command({
        goto: "start_flow",
        update: {
          messages: updatedMessages,
          steps: state.steps
        }
      });
    }
  }

  return new Command({
    goto: END,
    update: {
      messages: messages,
      steps: state.steps
    }
  });
}

// Define the graph
const workflow = new StateGraph(AgentStateAnnotation)
  .addNode("start_flow", startFlow)
  .addNode("chat_node", chatNode)
  .addEdge("__start__", "start_flow")
  .addEdge("start_flow", "chat_node")
  .addEdge("chat_node", "__end__");

// Compile the graph
export const agenticGenerativeUiGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/human_in_the_loop/agent.ts
================================================
/**
 * A LangGraph implementation of the human-in-the-loop agent.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Command, interrupt, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";

const DEFINE_TASK_TOOL = {
  type: "function",
  function: {
    name: "plan_execution_steps",
    description: "Make up 10 steps (only a couple of words per step) that are required for a task. The step should be in imperative form (i.e. Dig hole, Open door, ...)",
    parameters: {
      type: "object",
      properties: {
        steps: {
          type: "array",
          items: {
            type: "object",
            properties: {
              description: {
                type: "string",
                description: "The text of the step in imperative form"
              },
              status: {
                type: "string",
                enum: ["enabled"],
                description: "The status of the step, always 'enabled'"
              }
            },
            required: ["description", "status"]
          },
          description: "An array of 10 step objects, each containing text and status"
        }
      },
      required: ["steps"]
    }
  }
};

export const AgentStateAnnotation = Annotation.Root({
  steps: Annotation<Array<{ description: string; status: string }>>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),
  tools: Annotation<any[]>(),
  user_response: Annotation<string | undefined>({
    reducer: (x, y) => y ?? x,
    default: () => undefined
  }),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This is the entry point for the flow.
   */

  // Initialize steps list if not exists
  if (!state.steps) {
    state.steps = [];
  }

  return new Command({
    goto: "chat_node",
    update: {
      messages: state.messages,
      steps: state.steps,
    }
  });
}

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * Standard chat node where the agent processes messages and generates responses.
   * If task steps are defined, the user can enable/disable them using interrupts.
   */
  const systemPrompt = `
    You are a helpful assistant that can perform any task.
    You MUST call the \`plan_execution_steps\` function when the user asks you to perform a task.
    Always make sure you will provide tasks based on the user query
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o-mini" });
  
  // Define config for the model
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "steps",
    tool: "plan_execution_steps",
    tool_argument: "steps"
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      DEFINE_TASK_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model and generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  // Update messages with the response
  const messages = [...state.messages, response];
  
  // Handle tool calls
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];

    if (toolCall.name === "plan_execution_steps") {
      // Get the steps from the tool call
      const stepsRaw = toolCall.args.steps || [];
      
      // Set initial status to "enabled" for all steps
      const stepsData: Array<{ description: string; status: string }> = [];
      
      // Handle different potential formats of steps data
      if (Array.isArray(stepsRaw)) {
        for (const step of stepsRaw) {
          if (typeof step === 'object' && step.description) {
            stepsData.push({
              description: step.description,
              status: "enabled"
            });
          } else if (typeof step === 'string') {
            stepsData.push({
              description: step,
              status: "enabled"
            });
          }
        }
      }
      
      // If no steps were processed correctly, return to END with the updated messages
      if (stepsData.length === 0) {
        return new Command({
          goto: END,
          update: {
            messages: messages,
            steps: state.steps,
          }
        });
      }

      // Update steps in state and emit to frontend
      state.steps = stepsData;
      
      // Add a tool response to satisfy OpenAI's requirements
      const toolResponse = {
        role: "tool" as const,
        content: "Task steps generated.",
        tool_call_id: toolCall.id
      };
      
      const updatedMessages = [...messages, toolResponse];

      // Move to the process_steps_node which will handle the interrupt and final response
      return new Command({
        goto: "process_steps_node",
        update: {
          messages: updatedMessages,
          steps: state.steps,
        }
      });
    }
  }
  
  // If no tool calls or not plan_execution_steps, return to END with the updated messages
  return new Command({
    goto: END,
    update: {
      messages: messages,
      steps: state.steps,
    }
  });
}

async function processStepsNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This node handles the user interrupt for step customization and generates the final response.
   */

  let userResponse: string;

  // Check if we already have a user_response in the state
  // This happens when the node restarts after an interrupt
  if (state.user_response) {
    userResponse = state.user_response;
  } else {
    // Use LangGraph interrupt to get user input on steps
    // This will pause execution and wait for user input in the frontend
    userResponse = interrupt({ steps: state.steps });
    // Store the user response in state for when the node restarts
    state.user_response = userResponse;
  }
  
  // Generate the creative completion response
  const finalPrompt = `
    Provide a textual description of how you are performing the task.
    If the user has disabled a step, you are not allowed to perform that step.
    However, you should find a creative workaround to perform the task, and if an essential step is disabled, you can even use
    some humor in the description of how you are performing the task.
    Don't just repeat a list of steps, come up with a creative but short description (3 sentences max) of how you are performing the task.
    `;
  
  const finalResponse = await new ChatOpenAI({ model: "gpt-4o" }).invoke([
    new SystemMessage({ content: finalPrompt }),
    { role: "user", content: userResponse }
  ], config);

  // Add the final response to messages
  const messages = [...state.messages, finalResponse];
  
  // Clear the user_response from state to prepare for future interactions
  const newState = { ...state };
  delete newState.user_response;
  
  // Return to END with the updated messages
  return new Command({
    goto: END,
    update: {
      messages: messages,
      steps: state.steps,
    }
  });
}

// Define the graph
const workflow = new StateGraph(AgentStateAnnotation);

// Add nodes
workflow.addNode("start_flow", startFlow);
workflow.addNode("chat_node", chatNode);
workflow.addNode("process_steps_node", processStepsNode);

// Add edges
workflow.setEntryPoint("start_flow");
workflow.addEdge(START, "start_flow");
workflow.addEdge("start_flow", "chat_node");
workflow.addEdge("process_steps_node", END);

// Add conditional edges from chat_node
workflow.addConditionalEdges(
  "chat_node",
  (state: AgentState) => {
    // This would be determined by the Command returned from chat_node
    // For now, we'll assume the logic is handled in the Command's goto property
    return "continue";
  },
  {
    "process_steps_node": "process_steps_node",
    "continue": END,
  }
);

// Compile the graph
export const humanInTheLoopGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/predictive_state_updates/agent.ts
================================================
/**
 * A demo of predictive state updates using LangGraph.
 */

import { v4 as uuidv4 } from "uuid";
import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Command, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";

const WRITE_DOCUMENT_TOOL = {
  type: "function",
  function: {
    name: "write_document_local",
    description: [
      "Write a document. Use markdown formatting to format the document.",
      "It's good to format the document extensively so it's easy to read.",
      "You can use all kinds of markdown.",
      "However, do not use italic or strike-through formatting, it's reserved for another purpose.",
      "You MUST write the full document, even when changing only a few words.",
      "When making edits to the document, try to make them minimal - do not change every word.",
      "Keep stories SHORT!"
    ].join(" "),
    parameters: {
      type: "object",
      properties: {
        document: {
          type: "string",
          description: "The document to write"
        },
      },
    }
  }
};

export const AgentStateAnnotation = Annotation.Root({
  document: Annotation<string | undefined>({
    reducer: (x, y) => y ?? x,
    default: () => undefined
  }),
  tools: Annotation<any[]>(),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * Standard chat node.
   */

  const systemPrompt = `
    You are a helpful assistant for writing documents.
    To write the document, you MUST use the write_document_local tool.
    You MUST write the full document, even when changing only a few words.
    When you wrote the document, DO NOT repeat it as a message.
    Just briefly summarize the changes you made. 2 sentences max.
    This is the current state of the document: ----\n ${state.document || ''}\n-----
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });

  // Define config for the model with emit_intermediate_state to stream tool calls to frontend
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document_local tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "document",
    tool: "write_document_local",
    tool_argument: "document"
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      WRITE_DOCUMENT_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model to generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  // Update messages with the response
  const messages = [...state.messages, response];

  // Extract any tool calls from the response
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];

    if (toolCall.name === "write_document_local") {
      // Add the tool response to messages
      const toolResponse = {
        role: "tool" as const,
        content: "Document written.",
        tool_call_id: toolCall.id
      };

      // Add confirmation tool call
      const confirmToolCall = {
        role: "assistant" as const,
        content: "",
        tool_calls: [{
          id: uuidv4(),
          type: "function" as const,
          function: {
            name: "confirm_changes",
            arguments: "{}"
          }
        }]
      };

      const updatedMessages = [...messages, toolResponse, confirmToolCall];

      // Return Command to route to end
      return new Command({
        goto: END,
        update: {
          messages: updatedMessages,
          document: toolCall.args.document
        }
      });
    }
  }

  // If no tool was called, go to end
  return new Command({
    goto: END,
    update: {
      messages: messages
    }
  });
}

// Define the graph
const workflow = new StateGraph(AgentStateAnnotation);

// Add nodes
workflow.addNode("chat_node", chatNode);

// Add edges
workflow.addEdge(START, "chat_node");
workflow.addEdge("chat_node", END);

// Compile the graph
export const predictiveStateUpdatesGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/shared_state/agent.ts
================================================
/**
 * A demo of shared state between the agent and CopilotKit using LangGraph.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { dispatchCustomEvent } from "@langchain/core/callbacks/dispatch";
import { Command, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";

enum SkillLevel {
  BEGINNER = "Beginner",
  INTERMEDIATE = "Intermediate",
  ADVANCED = "Advanced"
}

enum SpecialPreferences {
  HIGH_PROTEIN = "High Protein",
  LOW_CARB = "Low Carb",
  SPICY = "Spicy",
  BUDGET_FRIENDLY = "Budget-Friendly",
  ONE_POT_MEAL = "One-Pot Meal",
  VEGETARIAN = "Vegetarian",
  VEGAN = "Vegan"
}

enum CookingTime {
  FIVE_MIN = "5 min",
  FIFTEEN_MIN = "15 min",
  THIRTY_MIN = "30 min",
  FORTY_FIVE_MIN = "45 min",
  SIXTY_PLUS_MIN = "60+ min"
}

interface Ingredient {
  icon: string;
  name: string;
  amount: string;
}

interface Recipe {
  skill_level: SkillLevel;
  special_preferences: SpecialPreferences[];
  cooking_time: CookingTime;
  ingredients: Ingredient[];
  instructions: string[];
  changes?: string;
}

const GENERATE_RECIPE_TOOL = {
  type: "function",
  function: {
    name: "generate_recipe",
    description: "Using the existing (if any) ingredients and instructions, proceed with the recipe to finish it. Make sure the recipe is complete. ALWAYS provide the entire recipe, not just the changes.",
    parameters: {
      type: "object",
      properties: {
        recipe: {
          type: "object",
          properties: {
            skill_level: {
              type: "string",
              enum: Object.values(SkillLevel),
              description: "The skill level required for the recipe"
            },
            special_preferences: {
              type: "array",
              items: {
                type: "string",
                enum: Object.values(SpecialPreferences)
              },
              description: "A list of special preferences for the recipe"
            },
            cooking_time: {
              type: "string",
              enum: Object.values(CookingTime),
              description: "The cooking time of the recipe"
            },
            ingredients: {
              type: "array",
              items: {
                type: "object",
                properties: {
                  icon: { type: "string", description: "The icon emoji (not emoji code like '\\u1f35e', but the actual emoji like 🥕) of the ingredient" },
                  name: { type: "string" },
                  amount: { type: "string" }
                }
              },
              description: "Entire list of ingredients for the recipe, including the new ingredients and the ones that are already in the recipe"
            },
            instructions: {
              type: "array",
              items: { type: "string" },
              description: "Entire list of instructions for the recipe, including the new instructions and the ones that are already there"
            },
            changes: {
              type: "string",
              description: "A description of the changes made to the recipe"
            }
          },
        }
      },
      required: ["recipe"]
    }
  }
};

export const AgentStateAnnotation = Annotation.Root({
  recipe: Annotation<Recipe | undefined>(),
  tools: Annotation<any[]>(),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function startFlow(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * This is the entry point for the flow.
   */

  // Initialize recipe if not exists
  if (!state.recipe) {
    state.recipe = {
      skill_level: SkillLevel.BEGINNER,
      special_preferences: [],
      cooking_time: CookingTime.FIFTEEN_MIN,
      ingredients: [{ icon: "🍴", name: "Sample Ingredient", amount: "1 unit" }],
      instructions: ["First step instruction"]
    };
    // Emit the initial state to ensure it's properly shared with the frontend
    await dispatchCustomEvent("manually_emit_intermediate_state", state, config);
  }
  
  return new Command({
    goto: "chat_node",
    update: {
      messages: state.messages,
      recipe: state.recipe
    }
  });
}

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  /**
   * Standard chat node.
   */
  // Create a safer serialization of the recipe
  let recipeJson = "No recipe yet";
  if (state.recipe) {
    try {
      recipeJson = JSON.stringify(state.recipe, null, 2);
    } catch (e) {
      recipeJson = `Error serializing recipe: ${e}`;
    }
  }

  const systemPrompt = `You are a helpful assistant for creating recipes. 
    This is the current state of the recipe: ${recipeJson}
    You can improve the recipe by calling the generate_recipe tool.
    
    IMPORTANT:
    1. Create a recipe using the existing ingredients and instructions. Make sure the recipe is complete.
    2. For ingredients, append new ingredients to the existing ones.
    3. For instructions, append new steps to the existing ones.
    4. 'ingredients' is always an array of objects with 'icon', 'name', and 'amount' fields
    5. 'instructions' is always an array of strings

    If you have just created or modified the recipe, just answer in one sentence what you did. dont describe the recipe, just say what you did.
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o-mini" });
  
  // Define config for the model
  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Use "predict_state" metadata to set up streaming for the write_document tool
  if (!config.metadata) config.metadata = {};
  config.metadata.predict_state = [{
    state_key: "recipe",
    tool: "generate_recipe",
    tool_argument: "recipe"
  }];

  // Bind the tools to the model
  const modelWithTools = model.bindTools(
    [
      ...state.tools,
      GENERATE_RECIPE_TOOL
    ],
    {
      // Disable parallel tool calls to avoid race conditions
      parallel_tool_calls: false,
    }
  );

  // Run the model and generate a response
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  // Update messages with the response
  const messages = [...state.messages, response];
  
  // Handle tool calls
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];
    
    if (toolCall.name === "generate_recipe") {
      // Update recipe state with tool_call_args
      const recipeData = toolCall.args.recipe;
      let recipe: Recipe;
      // If we have an existing recipe, update it
      if (state.recipe) {
        recipe = { ...state.recipe };
        for (const [key, value] of Object.entries(recipeData)) {
          if (value !== null && value !== undefined) {  // Only update fields that were provided
            (recipe as any)[key] = value;
          }
        }
      } else {
        // Create a new recipe
        recipe = {
          skill_level: recipeData.skill_level || SkillLevel.BEGINNER,
          special_preferences: recipeData.special_preferences || [],
          cooking_time: recipeData.cooking_time || CookingTime.FIFTEEN_MIN,
          ingredients: recipeData.ingredients || [],
          instructions: recipeData.instructions || []
        };
      }
      
      // Add tool response to messages
      const toolResponse = {
        role: "tool" as const,
        content: "Recipe generated.",
        tool_call_id: toolCall.id
      };
      
      const updatedMessages = [...messages, toolResponse];
      
      // Explicitly emit the updated state to ensure it's shared with frontend
      state.recipe = recipe;
      await dispatchCustomEvent("manually_emit_intermediate_state", state, config);
      
      // Return command with updated recipe
      return new Command({
        goto: "start_flow",
        update: {
          messages: updatedMessages,
          recipe: recipe
        }
      });
    }
  }

  return new Command({
    goto: END,
    update: {
      messages: messages,
      recipe: state.recipe
    }
  });
}

// Define the graph
const workflow = new StateGraph<AgentState>(AgentStateAnnotation);

// Add nodes
workflow.addNode("start_flow", startFlow);
workflow.addNode("chat_node", chatNode);

// Add edges
workflow.setEntryPoint("start_flow");
workflow.addEdge(START, "start_flow");
workflow.addEdge("start_flow", "chat_node");
workflow.addEdge("chat_node", END);

// Compile the graph
export const sharedStateGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/subgraphs/agent.ts
================================================
/**
 * A travel agent supervisor demo showcasing multi-agent architecture with subgraphs.
 * The supervisor coordinates specialized agents: flights finder, hotels finder, and experiences finder.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage, AIMessage, ToolMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { 
  Annotation, 
  MessagesAnnotation, 
  StateGraph, 
  Command, 
  START, 
  END, 
  interrupt 
} from "@langchain/langgraph";

// Travel data interfaces
interface Flight {
  airline: string;
  departure: string;
  arrival: string;
  price: string;
  duration: string;
}

interface Hotel {
  name: string;
  location: string;
  price_per_night: string;
  rating: string;
}

interface Experience {
  name: string;
  type: "restaurant" | "activity";
  description: string;
  location: string;
}

interface Itinerary {
  flight?: Flight;
  hotel?: Hotel;
}

// Custom reducer to merge itinerary updates
function mergeItinerary(left: Itinerary | null, right?: Itinerary | null): Itinerary {
  if (!left) left = {};
  if (!right) right = {};
  return { ...left, ...right };
}

// State annotation for travel agent system
export const TravelAgentStateAnnotation = Annotation.Root({
  origin: Annotation<string>(),
  destination: Annotation<string>(),
  flights: Annotation<Flight[] | null>(),
  hotels: Annotation<Hotel[] | null>(),
  experiences: Annotation<Experience[] | null>(),

  // Itinerary with custom merger
  itinerary: Annotation<Itinerary | null>({
    reducer: mergeItinerary,
    default: () => null
  }),

  // Tools available to all agents
  tools: Annotation<any[]>({
    reducer: (x, y) => y ?? x,
    default: () => []
  }),

  // Supervisor routing
  next_agent: Annotation<string | null>(),
  ...MessagesAnnotation.spec,
});

export type TravelAgentState = typeof TravelAgentStateAnnotation.State;

// Static data for demonstration
const STATIC_FLIGHTS: Flight[] = [
  { airline: "KLM", departure: "Amsterdam (AMS)", arrival: "San Francisco (SFO)", price: "$650", duration: "11h 30m" },
  { airline: "United", departure: "Amsterdam (AMS)", arrival: "San Francisco (SFO)", price: "$720", duration: "12h 15m" }
];

const STATIC_HOTELS: Hotel[] = [
  { name: "Hotel Zephyr", location: "Fisherman's Wharf", price_per_night: "$280/night", rating: "4.2 stars" },
  { name: "The Ritz-Carlton", location: "Nob Hill", price_per_night: "$550/night", rating: "4.8 stars" },
  { name: "Hotel Zoe", location: "Union Square", price_per_night: "$320/night", rating: "4.4 stars" }
];

const STATIC_EXPERIENCES: Experience[] = [
  { name: "Pier 39", type: "activity", description: "Iconic waterfront destination with shops and sea lions", location: "Fisherman's Wharf" },
  { name: "Golden Gate Bridge", type: "activity", description: "World-famous suspension bridge with stunning views", location: "Golden Gate" },
  { name: "Swan Oyster Depot", type: "restaurant", description: "Historic seafood counter serving fresh oysters", location: "Polk Street" },
  { name: "Tartine Bakery", type: "restaurant", description: "Artisanal bakery famous for bread and pastries", location: "Mission District" }
];

function createInterrupt(message: string, options: any[], recommendation: any, agent: string) {
  return interrupt({
    message,
    options,
    recommendation,
    agent,
  });
}

// Flights finder subgraph
async function flightsFinder(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  // Simulate flight search with static data
  const flights = STATIC_FLIGHTS;

  const selectedFlight = state.itinerary?.flight;
  
  let flightChoice: Flight;
  const message = `Found ${flights.length} flight options from ${state.origin || 'Amsterdam'} to ${state.destination || 'San Francisco'}.\n` +
    `I recommend choosing the flight by ${flights[0].airline} since it's known to be on time and cheaper.`
  if (!selectedFlight) {
    const interruptResult = createInterrupt(
      message,
      flights,
      flights[0],
      "flights"
    );
    
    // Parse the interrupt result if it's a string
    flightChoice = typeof interruptResult === 'string' ? JSON.parse(interruptResult) : interruptResult;
  } else {
    flightChoice = selectedFlight;
  }

  return new Command({
    goto: END,
    update: {
      flights: flights,
      itinerary: {
        flight: flightChoice
      },
      // Return all "messages" that the agent was sending
      messages: [
        ...state.messages,
        new AIMessage({
          content: message,
        }),
        new AIMessage({
          content: `Flights Agent: Great. I'll book you the ${flightChoice.airline} flight from ${flightChoice.departure} to ${flightChoice.arrival}.`,
        }),
      ]
    }
  });
}

// Hotels finder subgraph
async function hotelsFinder(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  // Simulate hotel search with static data
  const hotels = STATIC_HOTELS;
  const selectedHotel = state.itinerary?.hotel;
  
  let hotelChoice: Hotel;
  const message = `Found ${hotels.length} accommodation options in ${state.destination || 'San Francisco'}.\n
    I recommend choosing the ${hotels[2].name} since it strikes the balance between rating, price, and location.`
  if (!selectedHotel) {
    const interruptResult = createInterrupt(
      message,
      hotels,
      hotels[2],
      "hotels"
    );
    
    // Parse the interrupt result if it's a string
    hotelChoice = typeof interruptResult === 'string' ? JSON.parse(interruptResult) : interruptResult;
  } else {
    hotelChoice = selectedHotel;
  }

  return new Command({
    goto: END,
    update: {
      hotels: hotels,
      itinerary: {
        hotel: hotelChoice
      },
      // Return all "messages" that the agent was sending
      messages: [
        ...state.messages,
        new AIMessage({
          content: message,
        }),
        new AIMessage({
          content: `Hotels Agent: Excellent choice! You'll like ${hotelChoice.name}.`
        }),
      ]
    }
  });
}

// Experiences finder subgraph
async function experiencesFinder(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  // Filter experiences (2 restaurants, 2 activities)
  const restaurants = STATIC_EXPERIENCES.filter(exp => exp.type === "restaurant").slice(0, 2);
  const activities = STATIC_EXPERIENCES.filter(exp => exp.type === "activity").slice(0, 2);
  const experiences = [...restaurants, ...activities];

  const model = new ChatOpenAI({ model: "gpt-4o" });

  if (!config) {
    config = { recursionLimit: 25 };
  }

  const itinerary = state.itinerary || {};

  const systemPrompt = `
    You are the experiences agent. Your job is to find restaurants and activities for the user.
    You already went ahead and found a bunch of experiences. All you have to do now, is to let the user know of your findings.
    
    Current status:
    - Origin: ${state.origin || 'Amsterdam'}
    - Destination: ${state.destination || 'San Francisco'}
    - Flight chosen: ${JSON.stringify(itinerary.flight) || 'None'}
    - Hotel chosen: ${JSON.stringify(itinerary.hotel) || 'None'}
    - Activities found: ${JSON.stringify(activities)}
    - Restaurants found: ${JSON.stringify(restaurants)}
    `;

  // Get experiences response
  const response = await model.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  return new Command({
    goto: END,
    update: {
      experiences: experiences,
      messages: [...state.messages, response]
    }
  });
}

// Supervisor response tool
const SUPERVISOR_RESPONSE_TOOL = {
  type: "function" as const,
  function: {
    name: "supervisor_response",
    description: "Always use this tool to structure your response to the user.",
    parameters: {
      type: "object",
      properties: {
        answer: {
          type: "string",
          description: "The answer to the user"
        },
        next_agent: {
          type: "string",
          enum: ["flights_agent", "hotels_agent", "experiences_agent", "complete"],
          description: "The agent to go to. Not required if you do not want to route to another agent."
        }
      },
      required: ["answer"]
    }
  }
};

// Supervisor agent
async function supervisorAgent(state: TravelAgentState, config?: RunnableConfig): Promise<Command> {
  const itinerary = state.itinerary || {};

  // Check what's already completed
  const hasFlights = itinerary.flight !== undefined;
  const hasHotels = itinerary.hotel !== undefined;
  const hasExperiences = state.experiences !== null;

  const systemPrompt = `
    You are a travel planning supervisor. Your job is to coordinate specialized agents to help plan a trip.
    
    Current status:
    - Origin: ${state.origin || 'Amsterdam'}
    - Destination: ${state.destination || 'San Francisco'}
    - Flights found: ${hasFlights}
    - Hotels found: ${hasHotels}
    - Experiences found: ${hasExperiences}
    - Itinerary (Things that the user has already confirmed selection on): ${JSON.stringify(itinerary, null, 2)}
    
    Available agents:
    - flights_agent: Finds flight options
    - hotels_agent: Finds hotel options  
    - experiences_agent: Finds restaurant and activity recommendations
    - complete: Mark task as complete when all information is gathered
    
    You must route to the appropriate agent based on what's missing. Once all agents have completed their tasks, route to 'complete'.
    `;

  // Define the model
  const model = new ChatOpenAI({ model: "gpt-4o" });

  if (!config) {
    config = { recursionLimit: 25 };
  }

  // Bind the routing tool
  const modelWithTools = model.bindTools(
    [SUPERVISOR_RESPONSE_TOOL],
    {
      parallel_tool_calls: false,
    }
  );

  // Get supervisor decision
  const response = await modelWithTools.invoke([
    new SystemMessage({ content: systemPrompt }),
    ...state.messages,
  ], config);

  let messages = [...state.messages, response];

  // Handle tool calls for routing
  if (response.tool_calls && response.tool_calls.length > 0) {
    const toolCall = response.tool_calls[0];
    const toolCallArgs = toolCall.args;
    const nextAgent = toolCallArgs.next_agent;

    const toolResponse = new ToolMessage({
      tool_call_id: toolCall.id!,
      content: `Routing to ${nextAgent} and providing the answer`,
    });

    messages = [
      ...messages, 
      toolResponse, 
      new AIMessage({ content: toolCallArgs.answer })
    ];

    if (nextAgent && nextAgent !== "complete") {
      return new Command({ goto: nextAgent });
    }
  }

  // Fallback if no tool call or complete
  return new Command({
    goto: END,
    update: { messages }
  });
}

// Create subgraphs
const flightsGraph = new StateGraph(TravelAgentStateAnnotation);
flightsGraph.addNode("flights_agent_chat_node", flightsFinder);
flightsGraph.setEntryPoint("flights_agent_chat_node");
flightsGraph.addEdge(START, "flights_agent_chat_node");
flightsGraph.addEdge("flights_agent_chat_node", END);
const flightsSubgraph = flightsGraph.compile();

const hotelsGraph = new StateGraph(TravelAgentStateAnnotation);
hotelsGraph.addNode("hotels_agent_chat_node", hotelsFinder);
hotelsGraph.setEntryPoint("hotels_agent_chat_node");
hotelsGraph.addEdge(START, "hotels_agent_chat_node");
hotelsGraph.addEdge("hotels_agent_chat_node", END);
const hotelsSubgraph = hotelsGraph.compile();

const experiencesGraph = new StateGraph(TravelAgentStateAnnotation);
experiencesGraph.addNode("experiences_agent_chat_node", experiencesFinder);
experiencesGraph.setEntryPoint("experiences_agent_chat_node");
experiencesGraph.addEdge(START, "experiences_agent_chat_node");
experiencesGraph.addEdge("experiences_agent_chat_node", END);
const experiencesSubgraph = experiencesGraph.compile();

// Main supervisor workflow
const workflow = new StateGraph(TravelAgentStateAnnotation);

// Add supervisor and subgraphs as nodes
workflow.addNode("supervisor", supervisorAgent, { ends: ['flights_agent', 'hotels_agent', 'experiences_agent', END] });
workflow.addNode("flights_agent", flightsSubgraph);
workflow.addNode("hotels_agent", hotelsSubgraph);
workflow.addNode("experiences_agent", experiencesSubgraph);

// Set entry point
workflow.setEntryPoint("supervisor");
workflow.addEdge(START, "supervisor");

// Add edges back to supervisor after each subgraph
workflow.addEdge("flights_agent", "supervisor");
workflow.addEdge("hotels_agent", "supervisor");
workflow.addEdge("experiences_agent", "supervisor");

// Compile the graph
export const subGraphsAgentGraph = workflow.compile();



================================================
FILE: typescript-sdk/integrations/langgraph/examples/typescript/src/agents/tool_based_generative_ui/agent.ts
================================================
/**
 * An example demonstrating tool-based generative UI using LangGraph.
 */

import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { Command, Annotation, MessagesAnnotation, StateGraph, END, START } from "@langchain/langgraph";


export const AgentStateAnnotation = Annotation.Root({
  tools: Annotation<any[]>(),
  ...MessagesAnnotation.spec,
});
export type AgentState = typeof AgentStateAnnotation.State;

async function chatNode(state: AgentState, config?: RunnableConfig): Promise<Command> {
  const model = new ChatOpenAI({ model: "gpt-4o" });

  const modelWithTools = model.bindTools(
    [
      ...state.tools || []
    ],
    { parallel_tool_calls: false }
  );

  const systemMessage = new SystemMessage({
     content: 'Help the user with writing Haikus. If the user asks for a haiku, use the generate_haiku tool to display the haiku to the user.'
  });

  const response = await modelWithTools.invoke([
    systemMessage,
    ...state.messages,
  ], config);

  return new Command({
    goto: END,
    update: {
      messages: [response]
    }
  });
}

const workflow = new StateGraph<AgentState>(AgentStateAnnotation);
workflow.addNode("chat_node", chatNode);

workflow.addEdge(START, "chat_node");

export const toolBasedGenerativeUiGraph = workflow.compile();


================================================
FILE: typescript-sdk/integrations/langgraph/python/README.md
================================================
# ag-ui-langgraph

Implementation of the AG-UI protocol for LangGraph.

Provides a complete Python integration for LangGraph agents with the AG-UI protocol, including FastAPI endpoint creation and comprehensive event streaming.

## Installation

```bash
pip install ag-ui-langgraph
```

## Usage

```python
from langgraph.graph import StateGraph, MessagesState
from langchain_openai import ChatOpenAI
from ag_ui_langgraph import LangGraphAgent, add_langgraph_fastapi_endpoint
from fastapi import FastAPI
from my_langgraph_workflow import graph

# Add to FastAPI
app = FastAPI()
add_langgraph_fastapi_endpoint(app, graph, "/agent")
```

## Features

- **Native LangGraph integration** – Direct support for LangGraph workflows and state management
- **FastAPI endpoint creation** – Automatic HTTP endpoint generation with proper event streaming
- **Advanced event handling** – Comprehensive support for all AG-UI events including thinking, tool calls, and state updates
- **Message translation** – Seamless conversion between AG-UI and LangChain message formats

## To run the dojo examples

```bash
cd python/ag_ui_langgraph/examples
poetry install
poetry run dev
```



================================================
FILE: typescript-sdk/integrations/langgraph/python/pyproject.toml
================================================
[tool.poetry]
name = "ag-ui-langgraph"
version = "0.0.14"
description = "Implementation of the AG-UI protocol for LangGraph."
authors = ["Ran Shem Tov <ran@copilotkit.ai>"]
readme = "README.md"
exclude = [
    "ag_ui_langgraph/examples/**",
]

[tool.poetry.dependencies]
python = "<3.14,>=3.10"
ag-ui-protocol = "==0.1.9"
fastapi = { version = "^0.115.12", optional = true }
langchain = ">=0.3.0"
langchain-core = ">=0.3.0"
langgraph = ">=0.3.25,<1.1.0"

[tool.poetry.extras]
fastapi = ["fastapi"]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "ag_ui_langgraph.dojo:main"


================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/__init__.py
================================================
from .agent import LangGraphAgent
from .types import (
    LangGraphEventTypes,
    CustomEventNames,
    State,
    SchemaKeys,
    MessageInProgress,
    RunMetadata,
    MessagesInProgressRecord,
    ToolCall,
    BaseLangGraphPlatformMessage,
    LangGraphPlatformResultMessage,
    LangGraphPlatformActionExecutionMessage,
    LangGraphPlatformMessage,
    PredictStateTool
)
from .endpoint import add_langgraph_fastapi_endpoint

__all__ = [
    "LangGraphAgent",
    "LangGraphEventTypes",
    "CustomEventNames",
    "State",
    "SchemaKeys",
    "MessageInProgress",
    "RunMetadata",
    "MessagesInProgressRecord",
    "ToolCall",
    "BaseLangGraphPlatformMessage",
    "LangGraphPlatformResultMessage",
    "LangGraphPlatformActionExecutionMessage",
    "LangGraphPlatformMessage",
    "PredictStateTool",
    "add_langgraph_fastapi_endpoint"
]



================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/agent.py
================================================
import uuid
import json
from typing import Optional, List, Any, Union, AsyncGenerator, Generator, Literal, Dict
import inspect

from langgraph.graph.state import CompiledStateGraph
from langchain.schema import BaseMessage, SystemMessage
from langchain_core.runnables import RunnableConfig, ensure_config
from langchain_core.messages import HumanMessage
from langgraph.types import Command

from .types import (
    State,
    LangGraphPlatformMessage,
    MessagesInProgressRecord,
    SchemaKeys,
    MessageInProgress,
    RunMetadata,
    LangGraphEventTypes,
    CustomEventNames,
    LangGraphReasoning
)
from .utils import (
    agui_messages_to_langchain,
    DEFAULT_SCHEMA_KEYS,
    filter_object_by_schema_keys,
    get_stream_payload_input,
    langchain_messages_to_agui,
    resolve_reasoning_content,
    resolve_message_content,
    camel_to_snake,
    json_safe_stringify,
    make_json_safe
)

from ag_ui.core import (
    EventType,
    CustomEvent,
    MessagesSnapshotEvent,
    RawEvent,
    RunAgentInput,
    RunErrorEvent,
    RunFinishedEvent,
    RunStartedEvent,
    StateDeltaEvent,
    StateSnapshotEvent,
    StepFinishedEvent,
    StepStartedEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    TextMessageStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    ToolCallStartEvent,
    ThinkingTextMessageStartEvent,
    ThinkingTextMessageContentEvent,
    ThinkingTextMessageEndEvent,
    ThinkingStartEvent,
    ThinkingEndEvent,
)
from ag_ui.encoder import EventEncoder

ProcessedEvents = Union[
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    StateSnapshotEvent,
    StateDeltaEvent,
    MessagesSnapshotEvent,
    RawEvent,
    CustomEvent,
    RunStartedEvent,
    RunFinishedEvent,
    RunErrorEvent,
    StepStartedEvent,
    StepFinishedEvent,
]

class LangGraphAgent:
    def __init__(self, *, name: str, graph: CompiledStateGraph, description: Optional[str] = None, config:  Union[Optional[RunnableConfig], dict] = None):
        self.name = name
        self.description = description
        self.graph = graph
        self.config = config or {}
        self.messages_in_process: MessagesInProgressRecord = {}
        self.active_run: Optional[RunMetadata] = None
        self.constant_schema_keys = ['messages', 'tools']

    def _dispatch_event(self, event: ProcessedEvents) -> str:
        if event.type == EventType.RAW:
            event.event = make_json_safe(event.event)
        elif event.raw_event:
            event.raw_event = make_json_safe(event.raw_event)

        return event

    async def run(self, input: RunAgentInput) -> AsyncGenerator[str, None]:
        forwarded_props = {}
        if hasattr(input, "forwarded_props") and input.forwarded_props:
            forwarded_props = {
                camel_to_snake(k): v for k, v in input.forwarded_props.items()
            }
        async for event_str in self._handle_stream_events(input.copy(update={"forwarded_props": forwarded_props})):
            yield event_str

    async def _handle_stream_events(self, input: RunAgentInput) -> AsyncGenerator[str, None]:
        thread_id = input.thread_id or str(uuid.uuid4())
        INITIAL_ACTIVE_RUN = {
            "id": input.run_id,
            "thread_id": thread_id,
            "thinking_process": None,
            "node_name": None,
            "has_function_streaming": False,
        }
        self.active_run = INITIAL_ACTIVE_RUN

        forwarded_props = input.forwarded_props
        node_name_input = forwarded_props.get('node_name', None) if forwarded_props else None

        self.active_run["manually_emitted_state"] = None

        config = ensure_config(self.config.copy() if self.config else {})
        config["configurable"] = {**(config.get('configurable', {})), "thread_id": thread_id}

        agent_state = await self.graph.aget_state(config)
        resume_input = forwarded_props.get('command', {}).get('resume', None)

        if resume_input is None and thread_id and self.active_run.get("node_name") != "__end__" and self.active_run.get("node_name"):
            self.active_run["mode"] = "continue"
        else:
            self.active_run["mode"] = "start"

        prepared_stream_response = await self.prepare_stream(input=input, agent_state=agent_state, config=config)

        yield self._dispatch_event(
            RunStartedEvent(type=EventType.RUN_STARTED, thread_id=thread_id, run_id=self.active_run["id"])
        )
        self.handle_node_change(node_name_input)

        # In case of resume (interrupt), re-start resumed step
        if resume_input and self.active_run.get("node_name"):
            for ev in self.handle_node_change(self.active_run.get("node_name")):
                yield ev

        state = prepared_stream_response["state"]
        stream = prepared_stream_response["stream"]
        config = prepared_stream_response["config"]
        events_to_dispatch = prepared_stream_response.get('events_to_dispatch', None)

        if events_to_dispatch is not None and len(events_to_dispatch) > 0:
            for event in events_to_dispatch:
                yield self._dispatch_event(event)
            return

        should_exit = False
        current_graph_state = state
        
        async for event in stream:
            subgraphs_stream_enabled = input.forwarded_props.get('stream_subgraphs') if input.forwarded_props else False
            is_subgraph_stream = (subgraphs_stream_enabled and (
                event.get("event", "").startswith("events") or 
                event.get("event", "").startswith("values")
            ))
            if event["event"] == "error":
                yield self._dispatch_event(
                    RunErrorEvent(type=EventType.RUN_ERROR, message=event["data"]["message"], raw_event=event)
                )
                break

            current_node_name = event.get("metadata", {}).get("langgraph_node")
            event_type = event.get("event")
            self.active_run["id"] = event.get("run_id")
            exiting_node = False

            if event_type == "on_chain_end" and isinstance(
                    event.get("data", {}).get("output"), dict
            ):
                current_graph_state.update(event["data"]["output"])
                exiting_node = self.active_run["node_name"] == current_node_name

            should_exit = should_exit or (
                    event_type == "on_custom_event" and
                    event["name"] == "exit"
                )

            if current_node_name and current_node_name != self.active_run.get("node_name"):
                for ev in self.handle_node_change(current_node_name):
                    yield ev

            updated_state = self.active_run.get("manually_emitted_state") or current_graph_state
            has_state_diff = updated_state != state
            if exiting_node or (has_state_diff and not self.get_message_in_progress(self.active_run["id"])):
                state = updated_state
                self.active_run["prev_node_name"] = self.active_run["node_name"]
                current_graph_state.update(updated_state)
                yield self._dispatch_event(
                    StateSnapshotEvent(
                        type=EventType.STATE_SNAPSHOT,
                        snapshot=self.get_state_snapshot(state),
                        raw_event=event,
                    )
                )

            yield self._dispatch_event(
                RawEvent(type=EventType.RAW, event=event)
            )

            async for single_event in self._handle_single_event(event, state):
                yield single_event

        state = await self.graph.aget_state(config)

        tasks = state.tasks if len(state.tasks) > 0 else None
        interrupts = tasks[0].interrupts if tasks else []

        writes = state.metadata.get("writes", {}) or {}
        node_name = self.active_run["node_name"] if interrupts else next(iter(writes), None)
        next_nodes = state.next or ()
        is_end_node = len(next_nodes) == 0 and not interrupts

        node_name = "__end__" if is_end_node else node_name

        for interrupt in interrupts:
            yield self._dispatch_event(
                CustomEvent(
                    type=EventType.CUSTOM,
                    name=LangGraphEventTypes.OnInterrupt.value,
                    value=json.dumps(interrupt.value, default=json_safe_stringify) if not isinstance(interrupt.value, str) else interrupt.value,
                    raw_event=interrupt,
                )
            )

        if self.active_run.get("node_name") != node_name:
            for ev in self.handle_node_change(node_name):
                yield ev

        state_values = state.values if state.values else state
        yield self._dispatch_event(
            StateSnapshotEvent(type=EventType.STATE_SNAPSHOT, snapshot=self.get_state_snapshot(state_values))
        )

        yield self._dispatch_event(
            MessagesSnapshotEvent(
                type=EventType.MESSAGES_SNAPSHOT,
                messages=langchain_messages_to_agui(state_values.get("messages", [])),
            )
        )

        for ev in self.handle_node_change(None):
            yield ev

        yield self._dispatch_event(
            RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id=thread_id, run_id=self.active_run["id"])
        )
        # Reset active run to how it was before the stream started
        self.active_run = INITIAL_ACTIVE_RUN


    async def prepare_stream(self, input: RunAgentInput, agent_state: State, config: RunnableConfig):
        state_input = input.state or {}
        messages = input.messages or []
        forwarded_props = input.forwarded_props or {}
        thread_id = input.thread_id

        state_input["messages"] = agent_state.values.get("messages", [])
        self.active_run["current_graph_state"] = agent_state.values.copy()
        langchain_messages = agui_messages_to_langchain(messages)
        state = self.langgraph_default_merge_state(state_input, langchain_messages, input)
        self.active_run["current_graph_state"].update(state)
        config["configurable"]["thread_id"] = thread_id
        interrupts = agent_state.tasks[0].interrupts if agent_state.tasks and len(agent_state.tasks) > 0 else []
        has_active_interrupts = len(interrupts) > 0
        resume_input = forwarded_props.get('command', {}).get('resume', None)

        self.active_run["schema_keys"] = self.get_schema_keys(config)

        non_system_messages = [msg for msg in langchain_messages if not isinstance(msg, SystemMessage)]
        if len(agent_state.values.get("messages", [])) > len(non_system_messages):
            # Find the last user message by working backwards from the last message
            last_user_message = None
            for i in range(len(langchain_messages) - 1, -1, -1):
                if isinstance(langchain_messages[i], HumanMessage):
                    last_user_message = langchain_messages[i]
                    break

            if last_user_message:
                return await self.prepare_regenerate_stream(
                    input=input,
                    message_checkpoint=last_user_message,
                    config=config
                )

        events_to_dispatch = []
        if has_active_interrupts and not resume_input:
            events_to_dispatch.append(
                RunStartedEvent(type=EventType.RUN_STARTED, thread_id=thread_id, run_id=self.active_run["id"])
            )

            for interrupt in interrupts:
                events_to_dispatch.append(
                    CustomEvent(
                        type=EventType.CUSTOM,
                        name=LangGraphEventTypes.OnInterrupt.value,
                        value=json.dumps(interrupt.value) if not isinstance(interrupt.value, str) else interrupt.value,
                        raw_event=interrupt,
                    )
                )

            events_to_dispatch.append(
                RunFinishedEvent(type=EventType.RUN_FINISHED, thread_id=thread_id, run_id=self.active_run["id"])
            )
            return {
                "stream": None,
                "state": None,
                "config": None,
                "events_to_dispatch": events_to_dispatch,
            }

        if self.active_run["mode"] == "continue":
            await self.graph.aupdate_state(config, state, as_node=self.active_run.get("node_name"))

        if resume_input:
            stream_input = Command(resume=resume_input)
        else:
            payload_input = get_stream_payload_input(
                mode=self.active_run["mode"],
                state=state,
                schema_keys=self.active_run["schema_keys"],
            )
            stream_input = {**forwarded_props, **payload_input} if payload_input else None


        subgraphs_stream_enabled = input.forwarded_props.get('stream_subgraphs') if input.forwarded_props else False

        kwargs = self.get_stream_kwargs(
            input=stream_input,
            config=config,
            subgraphs=bool(subgraphs_stream_enabled),
            version="v2",
        )

        stream = self.graph.astream_events(**kwargs)

        return {
            "stream": stream,
            "state": state,
            "config": config
        }

    async def prepare_regenerate_stream( # pylint: disable=too-many-arguments
            self,
            input: RunAgentInput,
            message_checkpoint: HumanMessage,
            config: RunnableConfig
    ):
        tools = input.tools or []
        thread_id = input.thread_id

        time_travel_checkpoint = await self.get_checkpoint_before_message(message_checkpoint.id, thread_id)
        if time_travel_checkpoint is None:
            return None

        fork = await self.graph.aupdate_state(
            time_travel_checkpoint.config,
            time_travel_checkpoint.values,
            as_node=time_travel_checkpoint.next[0] if time_travel_checkpoint.next else "__start__"
        )

        stream_input = self.langgraph_default_merge_state(time_travel_checkpoint.values, [message_checkpoint], input)
        subgraphs_stream_enabled = input.forwarded_props.get('stream_subgraphs') if input.forwarded_props else False

        kwargs = self.get_stream_kwargs(
            input=stream_input,
            fork=fork,
            subgraphs=bool(subgraphs_stream_enabled),
            version="v2",
        )
        stream = self.graph.astream_events(**kwargs)

        return {
            "stream": stream,
            "state": time_travel_checkpoint.values,
            "config": config
        }

    def get_message_in_progress(self, run_id: str) -> Optional[MessageInProgress]:
        return self.messages_in_process.get(run_id)

    def set_message_in_progress(self, run_id: str, data: MessageInProgress):
        current_message_in_progress = self.messages_in_process.get(run_id, {})
        self.messages_in_process[run_id] = {
            **current_message_in_progress,
            **data,
        }

    def get_schema_keys(self, config) -> SchemaKeys:
        try:
            input_schema = self.graph.get_input_jsonschema(config)
            output_schema = self.graph.get_output_jsonschema(config)
            config_schema = self.graph.config_schema().schema()

            input_schema_keys = list(input_schema["properties"].keys()) if "properties" in input_schema else []
            output_schema_keys = list(output_schema["properties"].keys()) if "properties" in output_schema else []
            config_schema_keys = list(config_schema["properties"].keys()) if "properties" in config_schema else []
            context_schema_keys = []

            if hasattr(self.graph, "context_schema") and self.graph.context_schema is not None:
                context_schema = self.graph.context_schema().schema()
                context_schema_keys = list(context_schema["properties"].keys()) if "properties" in context_schema else []


            return {
                "input": [*input_schema_keys, *self.constant_schema_keys],
                "output": [*output_schema_keys, *self.constant_schema_keys],
                "config": config_schema_keys,
                "context": context_schema_keys,
            }
        except Exception:
            return {
                "input": self.constant_schema_keys,
                "output": self.constant_schema_keys,
                "config": [],
                "context": [],
            }

    def langgraph_default_merge_state(self, state: State, messages: List[BaseMessage], input: RunAgentInput) -> State:
        if messages and isinstance(messages[0], SystemMessage):
            messages = messages[1:]

        existing_messages: List[LangGraphPlatformMessage] = state.get("messages", [])
        existing_message_ids = {msg.id for msg in existing_messages}

        new_messages = [msg for msg in messages if msg.id not in existing_message_ids]

        tools = input.tools or []
        tools_as_dicts = []
        if tools:
            for tool in tools:
                if hasattr(tool, "model_dump"):
                    tools_as_dicts.append(tool.model_dump())
                elif hasattr(tool, "dict"):
                    tools_as_dicts.append(tool.dict())
                else:
                    tools_as_dicts.append(tool)

        all_tools = [*state.get("tools", []), *tools_as_dicts]

        # Remove duplicates based on tool name
        seen_names = set()
        unique_tools = []
        for tool in all_tools:
            tool_name = tool.get("name") if isinstance(tool, dict) else getattr(tool, "name", None)
            if tool_name and tool_name not in seen_names:
                seen_names.add(tool_name)
                unique_tools.append(tool)
            elif not tool_name:
                # Keep tools without names (shouldn't happen, but just in case)
                unique_tools.append(tool)

        return {
            **state,
            "messages": new_messages,
            "tools": unique_tools,
            "ag-ui": {
                "tools": unique_tools,
                "context": input.context or []
            }
        }

    def get_state_snapshot(self, state: State) -> State:
        schema_keys = self.active_run["schema_keys"]
        if schema_keys and schema_keys.get("output"):
            state = filter_object_by_schema_keys(state, [*DEFAULT_SCHEMA_KEYS, *schema_keys["output"]])
        return state

    async def _handle_single_event(self, event: Any, state: State) -> AsyncGenerator[str, None]:
        event_type = event.get("event")
        if event_type == LangGraphEventTypes.OnChatModelStream:
            should_emit_messages = event["metadata"].get("emit-messages", True)
            should_emit_tool_calls = event["metadata"].get("emit-tool-calls", True)

            if event["data"]["chunk"].response_metadata.get('finish_reason', None):
                return

            current_stream = self.get_message_in_progress(self.active_run["id"])
            has_current_stream = bool(current_stream and current_stream.get("id"))
            tool_call_data = event["data"]["chunk"].tool_call_chunks[0] if event["data"]["chunk"].tool_call_chunks else None
            predict_state_metadata = event["metadata"].get("predict_state", [])
            tool_call_used_to_predict_state = False
            if tool_call_data and tool_call_data.get("name") and predict_state_metadata:
                tool_call_used_to_predict_state = any(
                    predict_tool.get("tool") == tool_call_data["name"]
                    for predict_tool in predict_state_metadata
                )

            is_tool_call_start_event = not has_current_stream and tool_call_data and tool_call_data.get("name")
            is_tool_call_args_event = has_current_stream and current_stream.get("tool_call_id") and tool_call_data and tool_call_data.get("args")
            is_tool_call_end_event = has_current_stream and current_stream.get("tool_call_id") and not tool_call_data

            if is_tool_call_start_event or is_tool_call_end_event or is_tool_call_args_event:
                self.active_run["has_function_streaming"] = True

            reasoning_data = resolve_reasoning_content(event["data"]["chunk"]) if event["data"]["chunk"] else None
            message_content = resolve_message_content(event["data"]["chunk"].content) if event["data"]["chunk"] and event["data"]["chunk"].content else None
            is_message_content_event = tool_call_data is None and message_content
            is_message_end_event = has_current_stream and not current_stream.get("tool_call_id") and not is_message_content_event

            if reasoning_data:
                self.handle_thinking_event(reasoning_data)
                return

            if reasoning_data is None and self.active_run.get('thinking_process', None) is not None:
                yield self._dispatch_event(
                    ThinkingTextMessageEndEvent(
                        type=EventType.THINKING_TEXT_MESSAGE_END,
                    )
                )
                yield self._dispatch_event(
                    ThinkingEndEvent(
                        type=EventType.THINKING_END,
                    )
                )
                self.active_run["thinking_process"] = None

            if tool_call_used_to_predict_state:
                yield self._dispatch_event(
                    CustomEvent(
                        type=EventType.CUSTOM,
                        name="PredictState",
                        value=predict_state_metadata,
                        raw_event=event
                    )
                )

            if is_tool_call_end_event:
                yield self._dispatch_event(
                    ToolCallEndEvent(type=EventType.TOOL_CALL_END, tool_call_id=current_stream["tool_call_id"], raw_event=event)
                )
                self.messages_in_process[self.active_run["id"]] = None
                return


            if is_message_end_event:
                yield self._dispatch_event(
                    TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=current_stream["id"], raw_event=event)
                )
                self.messages_in_process[self.active_run["id"]] = None
                return

            if is_tool_call_start_event and should_emit_tool_calls:
                yield self._dispatch_event(
                    ToolCallStartEvent(
                        type=EventType.TOOL_CALL_START,
                        tool_call_id=tool_call_data["id"],
                        tool_call_name=tool_call_data["name"],
                        parent_message_id=event["data"]["chunk"].id,
                        raw_event=event,
                    )
                )
                self.set_message_in_progress(
                    self.active_run["id"],
                    MessageInProgress(id=event["data"]["chunk"].id, tool_call_id=tool_call_data["id"], tool_call_name=tool_call_data["name"])
                )
                return

            if is_tool_call_args_event and should_emit_tool_calls:
                yield self._dispatch_event(
                    ToolCallArgsEvent(
                        type=EventType.TOOL_CALL_ARGS,
                        tool_call_id=current_stream["tool_call_id"],
                        delta=tool_call_data["args"],
                        raw_event=event
                    )
                )
                return

            if is_message_content_event and should_emit_messages:
                if bool(current_stream and current_stream.get("id")) == False:
                    yield self._dispatch_event(
                        TextMessageStartEvent(
                            type=EventType.TEXT_MESSAGE_START,
                            role="assistant",
                            message_id=event["data"]["chunk"].id,
                            raw_event=event,
                        )
                    )
                    self.set_message_in_progress(
                        self.active_run["id"],
                        MessageInProgress(
                            id=event["data"]["chunk"].id,
                            tool_call_id=None,
                            tool_call_name=None
                        )
                    )
                    current_stream = self.get_message_in_progress(self.active_run["id"])

                yield self._dispatch_event(
                    TextMessageContentEvent(
                        type=EventType.TEXT_MESSAGE_CONTENT,
                        message_id=current_stream["id"],
                        delta=message_content,
                        raw_event=event,
                    )
                )
                return

        elif event_type == LangGraphEventTypes.OnChatModelEnd:
            if self.get_message_in_progress(self.active_run["id"]) and self.get_message_in_progress(self.active_run["id"]).get("tool_call_id"):
                resolved = self._dispatch_event(
                    ToolCallEndEvent(type=EventType.TOOL_CALL_END, tool_call_id=self.get_message_in_progress(self.active_run["id"])["tool_call_id"], raw_event=event)
                )
                if resolved:
                    self.messages_in_process[self.active_run["id"]] = None
                yield resolved
            elif self.get_message_in_progress(self.active_run["id"]) and self.get_message_in_progress(self.active_run["id"]).get("id"):
                resolved = self._dispatch_event(
                    TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=self.get_message_in_progress(self.active_run["id"])["id"], raw_event=event)
                )
                if resolved:
                    self.messages_in_process[self.active_run["id"]] = None
                yield resolved

        elif event_type == LangGraphEventTypes.OnCustomEvent:
            if event["name"] == CustomEventNames.ManuallyEmitMessage:
                yield self._dispatch_event(
                    TextMessageStartEvent(type=EventType.TEXT_MESSAGE_START, role="assistant", message_id=event["data"]["message_id"], raw_event=event)
                )
                yield self._dispatch_event(
                    TextMessageContentEvent(
                        type=EventType.TEXT_MESSAGE_CONTENT,
                        message_id=event["data"]["message_id"],
                        delta=event["data"]["message"],
                        raw_event=event,
                    )
                )
                yield self._dispatch_event(
                    TextMessageEndEvent(type=EventType.TEXT_MESSAGE_END, message_id=event["data"]["message_id"], raw_event=event)
                )

            elif event["name"] == CustomEventNames.ManuallyEmitToolCall:
                yield self._dispatch_event(
                    ToolCallStartEvent(
                        type=EventType.TOOL_CALL_START,
                        tool_call_id=event["data"]["id"],
                        tool_call_name=event["data"]["name"],
                        parent_message_id=event["data"]["id"],
                        raw_event=event,
                    )
                )
                yield self._dispatch_event(
                    ToolCallArgsEvent(type=EventType.TOOL_CALL_ARGS, tool_call_id=event["data"]["id"], delta=event["data"]["args"], raw_event=event)
                )
                yield self._dispatch_event(
                    ToolCallEndEvent(type=EventType.TOOL_CALL_END, tool_call_id=event["data"]["id"], raw_event=event)
                )

            elif event["name"] == CustomEventNames.ManuallyEmitState:
                self.active_run["manually_emitted_state"] = event["data"]
                yield self._dispatch_event(
                    StateSnapshotEvent(type=EventType.STATE_SNAPSHOT, snapshot=self.get_state_snapshot(self.active_run["manually_emitted_state"]), raw_event=event)
                )
            
            yield self._dispatch_event(
                CustomEvent(type=EventType.CUSTOM, name=event["name"], value=event["data"], raw_event=event)
            )

        elif event_type == LangGraphEventTypes.OnToolEnd:
            if self.active_run["has_function_streaming"]:
                return
            tool_call_output = event["data"]["output"]
            yield self._dispatch_event(
                ToolCallStartEvent(
                    type=EventType.TOOL_CALL_START,
                    tool_call_id=tool_call_output.tool_call_id,
                    tool_call_name=tool_call_output.name,
                    parent_message_id=tool_call_output.id,
                    raw_event=event,
                )
            )
            yield self._dispatch_event(
                ToolCallArgsEvent(
                    type=EventType.TOOL_CALL_ARGS,
                    tool_call_id=tool_call_output.tool_call_id,
                    delta=json.dumps(event["data"]["input"]),
                    raw_event=event
                )
            )
            yield self._dispatch_event(
                ToolCallEndEvent(
                    type=EventType.TOOL_CALL_END,
                    tool_call_id=tool_call_output.tool_call_id,
                    raw_event=event
                )
            )

    def handle_thinking_event(self, reasoning_data: LangGraphReasoning) -> Generator[str, Any, str | None]:
        if not reasoning_data or "type" not in reasoning_data or "text" not in reasoning_data:
            return ""

        thinking_step_index = reasoning_data.get("index")

        if (self.active_run.get("thinking_process") and
                self.active_run["thinking_process"].get("index") and
                self.active_run["thinking_process"]["index"] != thinking_step_index):

            if self.active_run["thinking_process"].get("type"):
                yield self._dispatch_event(
                    ThinkingTextMessageEndEvent(
                        type=EventType.THINKING_TEXT_MESSAGE_END,
                    )
                )
            yield self._dispatch_event(
                ThinkingEndEvent(
                    type=EventType.THINKING_END,
                )
            )
            self.active_run["thinking_process"] = None

        if not self.active_run.get("thinking_process"):
            yield self._dispatch_event(
                ThinkingStartEvent(
                    type=EventType.THINKING_START,
                )
            )
            self.active_run["thinking_process"] = {
                "index": thinking_step_index
            }

        if self.active_run["thinking_process"].get("type") != reasoning_data["type"]:
            yield self._dispatch_event(
                ThinkingTextMessageStartEvent(
                    type=EventType.THINKING_TEXT_MESSAGE_START,
                )
            )
            self.active_run["thinking_process"]["type"] = reasoning_data["type"]

        if self.active_run["thinking_process"].get("type"):
            yield self._dispatch_event(
                ThinkingTextMessageContentEvent(
                    type=EventType.THINKING_TEXT_MESSAGE_CONTENT,
                    delta=reasoning_data["text"]
                )
            )

    async def get_checkpoint_before_message(self, message_id: str, thread_id: str):
        if not thread_id:
            raise ValueError("Missing thread_id in config")

        history_list = []
        async for snapshot in self.graph.aget_state_history({"configurable": {"thread_id": thread_id}}):
            history_list.append(snapshot)

        history_list.reverse()
        for idx, snapshot in enumerate(history_list):
            messages = snapshot.values.get("messages", [])
            if any(getattr(m, "id", None) == message_id for m in messages):
                if idx == 0:
                    # No snapshot before this
                    # Return synthetic "empty before" version
                    empty_snapshot = snapshot
                    empty_snapshot.values["messages"] = []
                    return empty_snapshot

                snapshot_values_without_messages = snapshot.values.copy()
                del snapshot_values_without_messages["messages"]
                checkpoint = history_list[idx - 1]

                merged_values = {**checkpoint.values, **snapshot_values_without_messages}
                checkpoint = checkpoint._replace(values=merged_values)

                return checkpoint

        raise ValueError("Message ID not found in history")

    def handle_node_change(self, node_name: Optional[str]):
        """
        Centralized method to handle node name changes and step transitions.
        Automatically manages step start/end events based on node name changes.
        """
        if node_name == "__end__":
            node_name = None

        if node_name != self.active_run.get("node_name"):
            # End current step if we have one
            if self.active_run.get("node_name"):
                yield self.end_step()

            # Start new step if we have a node name
            if node_name:
                for event in self.start_step(node_name):
                    yield event

        self.active_run["node_name"] = node_name

    def start_step(self, step_name: str):
        """Simple step start event dispatcher - node_name management handled by handle_node_change"""
        yield self._dispatch_event(
            StepStartedEvent(
                type=EventType.STEP_STARTED,
                step_name=step_name
            )
        )

    def end_step(self):
        """Simple step end event dispatcher - node_name management handled by handle_node_change"""
        if not self.active_run.get("node_name"):
            raise ValueError("No active step to end")

        return self._dispatch_event(
            StepFinishedEvent(
                type=EventType.STEP_FINISHED,
                step_name=self.active_run["node_name"]
            )
        )

    # Check if some kwargs are enabled per LG version, to "catch all versions" and backwards compatibility
    def get_stream_kwargs(
            self,
            input: Any,
            subgraphs: bool = False,
            version: Literal["v1", "v2"] = "v2",
            config: Optional[RunnableConfig] = None,
            context: Optional[Dict[str, Any]] = None,
            fork: Optional[Any] = None,
    ):
        kwargs = dict(
            input=input,
            subgraphs=subgraphs,
            version=version,
        )

        # Only add context if supported
        sig = inspect.signature(self.graph.astream_events)
        if 'context' in sig.parameters:
            base_context = {}
            if isinstance(config, dict) and 'configurable' in config and isinstance(config['configurable'], dict):
                base_context.update(config['configurable'])
            if context:  # context might be None or {}
                base_context.update(context)
            if base_context:  # only add if there's something to pass
                kwargs['context'] = base_context

        if config:
            kwargs['config'] = config

        if fork:
            kwargs.update(fork)

        return kwargs



================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/endpoint.py
================================================
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse

from ag_ui.core.types import RunAgentInput
from ag_ui.encoder import EventEncoder

from .agent import LangGraphAgent

def add_langgraph_fastapi_endpoint(app: FastAPI, agent: LangGraphAgent, path: str = "/"):
    """Adds an endpoint to the FastAPI app."""

    @app.post(path)
    async def langgraph_agent_endpoint(input_data: RunAgentInput, request: Request):
        # Get the accept header from the request
        accept_header = request.headers.get("accept")

        # Create an event encoder to properly format SSE events
        encoder = EventEncoder(accept=accept_header)

        async def event_generator():
            async for event in agent.run(input_data):
                yield encoder.encode(event)

        return StreamingResponse(
            event_generator(),
            media_type=encoder.get_content_type()
        )

    @app.get(f"{path}/health")
    def health():
        """Health check."""
        return {
            "status": "ok",
            "agent": {
                "name": agent.name,
            }
        }


================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/types.py
================================================
from typing import TypedDict, Optional, List, Any, Dict, Union, Literal
from typing_extensions import NotRequired
from enum import Enum

class LangGraphEventTypes(str, Enum):
    OnChainStart = "on_chain_start"
    OnChainStream = "on_chain_stream"
    OnChainEnd = "on_chain_end"
    OnChatModelStart = "on_chat_model_start"
    OnChatModelStream = "on_chat_model_stream"
    OnChatModelEnd = "on_chat_model_end"
    OnToolStart = "on_tool_start"
    OnToolEnd = "on_tool_end"
    OnCustomEvent = "on_custom_event"
    OnInterrupt = "on_interrupt"

class CustomEventNames(str, Enum):
    ManuallyEmitMessage = "manually_emit_message"
    ManuallyEmitToolCall = "manually_emit_tool_call"
    ManuallyEmitState = "manually_emit_state"
    Exit = "exit"

State = Dict[str, Any]

SchemaKeys = TypedDict("SchemaKeys", {
    "input": NotRequired[Optional[List[str]]],
    "output": NotRequired[Optional[List[str]]],
    "config": NotRequired[Optional[List[str]]],
    "context": NotRequired[Optional[List[str]]]
})

ThinkingProcess = TypedDict("ThinkingProcess", {
    "index": int,
    "type": NotRequired[Optional[Literal['text']]],
})

MessageInProgress = TypedDict("MessageInProgress", {
    "id": str,
    "tool_call_id": NotRequired[Optional[str]],
    "tool_call_name": NotRequired[Optional[str]]
})

RunMetadata = TypedDict("RunMetadata", {
    "id": str,
    "schema_keys": NotRequired[Optional[SchemaKeys]],
    "node_name": NotRequired[Optional[str]],
    "prev_node_name": NotRequired[Optional[str]],
    "exiting_node": NotRequired[bool],
    "manually_emitted_state": NotRequired[Optional[State]],
    "thread_id": NotRequired[Optional[ThinkingProcess]],
    "thinking_process": NotRequired[Optional[str]],
    "has_function_streaming": NotRequired[bool],
})

MessagesInProgressRecord = Dict[str, Optional[MessageInProgress]]

ToolCall = TypedDict("ToolCall", {
    "id": str,
    "name": str,
    "args": Dict[str, Any]
})

class BaseLangGraphPlatformMessage(TypedDict):
    content: str
    role: str
    additional_kwargs: NotRequired[Dict[str, Any]]
    type: str
    id: str

class LangGraphPlatformResultMessage(BaseLangGraphPlatformMessage):
    tool_call_id: str
    name: str

class LangGraphPlatformActionExecutionMessage(BaseLangGraphPlatformMessage):
    tool_calls: List[ToolCall]

LangGraphPlatformMessage = Union[
    LangGraphPlatformActionExecutionMessage,
    LangGraphPlatformResultMessage,
    BaseLangGraphPlatformMessage,
]

PredictStateTool = TypedDict("PredictStateTool", {
    "tool": str,
    "state_key": str,
    "tool_argument": str
})

LangGraphReasoning = TypedDict("LangGraphReasoning", {
    "type": str,
    "text": str,
    "index": int
})



================================================
FILE: typescript-sdk/integrations/langgraph/python/ag_ui_langgraph/utils.py
================================================
import json
import re
from typing import List, Any, Dict, Union
from dataclasses import is_dataclass, asdict
from datetime import date, datetime

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from ag_ui.core import (
    Message as AGUIMessage,
    UserMessage as AGUIUserMessage,
    AssistantMessage as AGUIAssistantMessage,
    SystemMessage as AGUISystemMessage,
    ToolMessage as AGUIToolMessage,
    ToolCall as AGUIToolCall,
    FunctionCall as AGUIFunctionCall,
)
from .types import State, SchemaKeys, LangGraphReasoning

DEFAULT_SCHEMA_KEYS = ["tools"]

def filter_object_by_schema_keys(obj: Dict[str, Any], schema_keys: List[str]) -> Dict[str, Any]:
    if not obj:
        return {}
    return {k: v for k, v in obj.items() if k in schema_keys}

def get_stream_payload_input(
    *,
    mode: str,
    state: State,
    schema_keys: SchemaKeys,
) -> Union[State, None]:
    input_payload = state if mode == "start" else None
    if input_payload and schema_keys and schema_keys.get("input"):
        input_payload = filter_object_by_schema_keys(input_payload, [*DEFAULT_SCHEMA_KEYS, *schema_keys["input"]])
    return input_payload

def stringify_if_needed(item: Any) -> str:
    if item is None:
        return ''
    if isinstance(item, str):
        return item
    return json.dumps(item)

def langchain_messages_to_agui(messages: List[BaseMessage]) -> List[AGUIMessage]:
    agui_messages: List[AGUIMessage] = []
    for message in messages:
        if isinstance(message, HumanMessage):
            agui_messages.append(AGUIUserMessage(
                id=str(message.id),
                role="user",
                content=stringify_if_needed(resolve_message_content(message.content)),
                name=message.name,
            ))
        elif isinstance(message, AIMessage):
            tool_calls = None
            if message.tool_calls:
                tool_calls = [
                    AGUIToolCall(
                        id=str(tc["id"]),
                        type="function",
                        function=AGUIFunctionCall(
                            name=tc["name"],
                            arguments=json.dumps(tc.get("args", {})),
                        ),
                    )
                    for tc in message.tool_calls
                ]

            agui_messages.append(AGUIAssistantMessage(
                id=str(message.id),
                role="assistant",
                content=stringify_if_needed(resolve_message_content(message.content)),
                tool_calls=tool_calls,
                name=message.name,
            ))
        elif isinstance(message, SystemMessage):
            agui_messages.append(AGUISystemMessage(
                id=str(message.id),
                role="system",
                content=stringify_if_needed(resolve_message_content(message.content)),
                name=message.name,
            ))
        elif isinstance(message, ToolMessage):
            agui_messages.append(AGUIToolMessage(
                id=str(message.id),
                role="tool",
                content=stringify_if_needed(resolve_message_content(message.content)),
                tool_call_id=message.tool_call_id,
            ))
        else:
            raise TypeError(f"Unsupported message type: {type(message)}")
    return agui_messages

def agui_messages_to_langchain(messages: List[AGUIMessage]) -> List[BaseMessage]:
    langchain_messages = []
    for message in messages:
        role = message.role
        if role == "user":
            langchain_messages.append(HumanMessage(
                id=message.id,
                content=message.content,
                name=message.name,
            ))
        elif role == "assistant":
            tool_calls = []
            if hasattr(message, "tool_calls") and message.tool_calls:
                for tc in message.tool_calls:
                    tool_calls.append({
                        "id": tc.id,
                        "name": tc.function.name,
                        "args": json.loads(tc.function.arguments) if hasattr(tc, "function") and tc.function.arguments else {},
                        "type": "tool_call",
                    })
            langchain_messages.append(AIMessage(
                id=message.id,
                content=message.content or "",
                tool_calls=tool_calls,
                name=message.name,
            ))
        elif role == "system":
            langchain_messages.append(SystemMessage(
                id=message.id,
                content=message.content,
                name=message.name,
            ))
        elif role == "tool":
            langchain_messages.append(ToolMessage(
                id=message.id,
                content=message.content,
                tool_call_id=message.tool_call_id,
            ))
        else:
            raise ValueError(f"Unsupported message role: {role}")
    return langchain_messages

def resolve_reasoning_content(chunk: Any) -> LangGraphReasoning | None:
    content = chunk.content
    if not content:
        return None

    # Anthropic reasoning response
    if isinstance(content, list) and content and content[0]:
        if not content[0].get("thinking"):
            return None
        return LangGraphReasoning(
            text=content[0]["thinking"],
            type="text",
            index=content[0].get("index", 0)
        )

    # OpenAI reasoning response
    if hasattr(chunk, "additional_kwargs"):
        reasoning = chunk.additional_kwargs.get("reasoning", {})
        summary = reasoning.get("summary", [])
        if summary:
            data = summary[0]
            if not data or not data.get("text"):
                return None
            return LangGraphReasoning(
                type="text",
                text=data["text"],
                index=data.get("index", 0)
            )

    return None

def resolve_message_content(content: Any) -> str | None:
    if not content:
        return None

    if isinstance(content, str):
        return content

    if isinstance(content, list) and content:
        content_text = next((c.get("text") for c in content if isinstance(c, dict) and c.get("type") == "text"), None)
        return content_text

    return None

def camel_to_snake(name):
    return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()

def json_safe_stringify(o):
    if is_dataclass(o):          # dataclasses like Flight(...)
        return asdict(o)
    if hasattr(o, "model_dump"): # pydantic v2
        return o.model_dump()
    if hasattr(o, "dict"):       # pydantic v1
        return o.dict()
    if hasattr(o, "__dict__"):   # plain objects
        return vars(o)
    if isinstance(o, (datetime, date)):
        return o.isoformat()
    return str(o)                # last resort

def make_json_safe(value: Any) -> Any:
    """
    Recursively convert a value into a JSON-serializable structure.

    - Handles Pydantic models via `model_dump`.
    - Handles LangChain messages via `to_dict`.
    - Recursively walks dicts, lists, and tuples.
    - For arbitrary objects, falls back to `__dict__` if available, else `repr()`.
    """
    # Pydantic models
    if hasattr(value, "model_dump"):
        try:
            return make_json_safe(value.model_dump(by_alias=True, exclude_none=True))
        except Exception:
            pass

    # LangChain-style objects
    if hasattr(value, "to_dict"):
        try:
            return make_json_safe(value.to_dict())
        except Exception:
            pass

    # Dict
    if isinstance(value, dict):
        return {key: make_json_safe(sub_value) for key, sub_value in value.items()}

    # List / tuple
    if isinstance(value, (list, tuple)):
        return [make_json_safe(sub_value) for sub_value in value]

    # Already JSON safe
    if isinstance(value, (str, int, float, bool)) or value is None:
        return value

    # Arbitrary object: try __dict__ first, fallback to repr
    if hasattr(value, "__dict__"):
        return {
            "__type__": type(value).__name__,
            **make_json_safe(value.__dict__),
        }

    return repr(value)


================================================
FILE: typescript-sdk/integrations/langgraph/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/langgraph/src/agent.ts
================================================
import { Observable, Subscriber } from "rxjs";
import {
  Client as LangGraphClient,
  EventsStreamEvent,
  StreamMode,
  Config as LangGraphConfig,
  ThreadState,
  Assistant,
  Message as LangGraphMessage,
  Config,
  Interrupt,
  Thread,
} from "@langchain/langgraph-sdk";
import { randomUUID } from "node:crypto";
import {
  LangGraphPlatformMessage,
  CustomEventNames,
  LangGraphEventTypes,
  State,
  MessagesInProgressRecord,
  ThinkingInProgress,
  SchemaKeys,
  MessageInProgress,
  RunMetadata,
  PredictStateTool,
  LangGraphReasoning,
  StateEnrichment,
  LangGraphToolWithName,
} from "./types";
import {
  AbstractAgent,
  AgentConfig,
  CustomEvent,
  EventType,
  MessagesSnapshotEvent,
  RawEvent,
  RunAgentInput,
  RunErrorEvent,
  RunFinishedEvent,
  RunStartedEvent,
  StateDeltaEvent,
  StateSnapshotEvent,
  StepFinishedEvent,
  StepStartedEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  TextMessageStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallStartEvent,
  ThinkingTextMessageStartEvent,
  ThinkingTextMessageContentEvent,
  ThinkingTextMessageEndEvent,
  ThinkingStartEvent,
  ThinkingEndEvent,
  Message as AGUIMessage,
} from "@ag-ui/client";
import { RunsStreamPayload } from "@langchain/langgraph-sdk/dist/types";
import {
  aguiMessagesToLangChain,
  DEFAULT_SCHEMA_KEYS,
  filterObjectBySchemaKeys,
  getStreamPayloadInput,
  langchainMessagesToAgui,
  resolveMessageContent,
  resolveReasoningContent,
} from "@/utils";

export type ProcessedEvents =
  | TextMessageStartEvent
  | TextMessageContentEvent
  | TextMessageEndEvent
  | ThinkingTextMessageStartEvent
  | ThinkingTextMessageContentEvent
  | ThinkingTextMessageEndEvent
  | ToolCallStartEvent
  | ToolCallArgsEvent
  | ToolCallEndEvent
  | ThinkingStartEvent
  | ThinkingEndEvent
  | StateSnapshotEvent
  | StateDeltaEvent
  | MessagesSnapshotEvent
  | RawEvent
  | CustomEvent
  | RunStartedEvent
  | RunFinishedEvent
  | RunErrorEvent
  | StepStartedEvent
  | StepFinishedEvent;

type RunAgentExtendedInput<
  TStreamMode extends StreamMode | StreamMode[] = StreamMode,
  TSubgraphs extends boolean = false,
> = Omit<RunAgentInput, "forwardedProps"> & {
  forwardedProps?: Omit<RunsStreamPayload<TStreamMode, TSubgraphs>, "input"> & {
    nodeName?: string;
    threadMetadata?: Record<string, any>;
  };
};

interface RegenerateInput extends RunAgentExtendedInput {
  messageCheckpoint: LangGraphMessage;
}

export interface LangGraphAgentConfig extends AgentConfig {
  client?: LangGraphClient;
  deploymentUrl: string;
  langsmithApiKey?: string;
  propertyHeaders?: Record<string, string>;
  assistantConfig?: LangGraphConfig;
  agentName?: string;
  graphId: string;
}

export class LangGraphAgent extends AbstractAgent {
  client: LangGraphClient;
  assistantConfig?: LangGraphConfig;
  agentName?: string;
  graphId: string;
  assistant?: Assistant;
  messagesInProcess: MessagesInProgressRecord;
  thinkingProcess: null | ThinkingInProgress;
  activeRun?: RunMetadata;
  // @ts-expect-error no need to initialize subscriber right now
  subscriber: Subscriber<ProcessedEvents>;
  constantSchemaKeys: string[] = DEFAULT_SCHEMA_KEYS;
  config: LangGraphAgentConfig;

  constructor(config: LangGraphAgentConfig) {
    super(config);
    this.config = config;
    this.messagesInProcess = {};
    this.agentName = config.agentName;
    this.graphId = config.graphId;
    this.assistantConfig = config.assistantConfig;
    this.thinkingProcess = null;
    this.client =
      config?.client ??
      new LangGraphClient({
        apiUrl: config.deploymentUrl,
        apiKey: config.langsmithApiKey,
        defaultHeaders: { ...(config.propertyHeaders ?? {}) },
      });
  }

  public clone() {
    return new LangGraphAgent(this.config);
  }

  dispatchEvent(event: ProcessedEvents) {
    this.subscriber.next(event);
    return true;
  }

  run(input: RunAgentInput) {
    return new Observable<ProcessedEvents>((subscriber) => {
      this.runAgentStream(input, subscriber);
      return () => {};
    });
  }

  async runAgentStream(input: RunAgentExtendedInput, subscriber: Subscriber<ProcessedEvents>) {
    this.activeRun = {
      id: input.runId,
      threadId: input.threadId,
      hasFunctionStreaming: false,
    };
    this.subscriber = subscriber;
    if (!this.assistant) {
      this.assistant = await this.getAssistant();
    }
    const threadId = input.threadId ?? randomUUID();
    const streamMode =
      input.forwardedProps?.streamMode ?? (["events", "values", "updates"] satisfies StreamMode[]);
    const preparedStream = await this.prepareStream({ ...input, threadId }, streamMode);

    if (!preparedStream) {
      return subscriber.error("No stream to regenerate");
    }

    await this.handleStreamEvents(preparedStream, threadId, subscriber, input, Array.isArray(streamMode) ? streamMode : [streamMode]);
  }

  async prepareRegenerateStream(input: RegenerateInput, streamMode: StreamMode | StreamMode[]) {
    const { threadId, messageCheckpoint } = input;

    const timeTravelCheckpoint = await this.getCheckpointByMessage(
      messageCheckpoint!.id!,
      threadId,
    );
    if (!this.assistant) {
      this.assistant = await this.getAssistant();
    }

    if (!timeTravelCheckpoint) {
      return this.subscriber.error("No checkpoint found for message");
    }

    const fork = await this.client.threads.updateState(threadId, {
      values: this.langGraphDefaultMergeState(timeTravelCheckpoint.values, [], input),
      checkpointId: timeTravelCheckpoint.checkpoint.checkpoint_id!,
      asNode: timeTravelCheckpoint.next?.[0] ?? "__start__",
    });

    const payload = {
      ...(input.forwardedProps ?? {}),
      input: this.langGraphDefaultMergeState(
        timeTravelCheckpoint.values,
        [messageCheckpoint],
        input,
      ),
      // @ts-ignore
      checkpointId: fork.checkpoint.checkpoint_id!,
      streamMode,
    };
    return {
      streamResponse: this.client.runs.stream(threadId, this.assistant.assistant_id, payload),
      state: timeTravelCheckpoint as ThreadState<State>,
      streamMode,
    };
  }

  async prepareStream(input: RunAgentExtendedInput, streamMode: StreamMode | StreamMode[]) {
    let {
      threadId: inputThreadId,
      state: inputState,
      messages,
      tools,
      context,
      forwardedProps,
    } = input;
    // If a manual emittance happens, it is the ultimate source of truth of state, unless a node has exited.
    // Therefore, this value should either hold null, or the only edition of state that should be used.
    this.activeRun!.manuallyEmittedState = null;

    const nodeNameInput = forwardedProps?.nodeName;
    const threadId = inputThreadId ?? randomUUID();

    if (!this.assistant) {
      this.assistant = await this.getAssistant();
    }

    const thread = await this.getOrCreateThread(threadId, forwardedProps?.threadMetadata);
    this.activeRun!.threadId = thread.thread_id;

    const agentState: ThreadState<State> =
      (await this.client.threads.getState(thread.thread_id)) ??
      ({ values: {} } as ThreadState<State>);
    const agentStateMessages = agentState.values.messages ?? [];
    const inputMessagesToLangchain = aguiMessagesToLangChain(messages);
    const stateValuesDiff = this.langGraphDefaultMergeState(
      { ...inputState, messages: agentStateMessages },
      inputMessagesToLangchain,
      input,
    );
    // Messages are a combination of existing messages in state + everything that was newly sent
    let threadState = {
      ...agentState,
      values: {
        ...stateValuesDiff,
        messages: [...agentStateMessages, ...(stateValuesDiff.messages ?? [])],
      },
    };
    let stateValues = threadState.values;
    this.activeRun!.schemaKeys = await this.getSchemaKeys();

    if (
      (agentState.values.messages ?? []).length > messages.filter((m) => m.role !== "system").length
    ) {
      let lastUserMessage: LangGraphMessage | null = null;
      // Find the first user message by working backwards from the last message
      for (let i = messages.length - 1; i >= 0; i--) {
        if (messages[i].role === "user") {
          lastUserMessage = aguiMessagesToLangChain([messages[i]])[0];
          break;
        }
      }

      if (!lastUserMessage) {
        return this.subscriber.error("No user message found in messages to regenerate");
      }

      return this.prepareRegenerateStream(
        { ...input, messageCheckpoint: lastUserMessage },
        streamMode,
      );
    }
    this.activeRun!.graphInfo = await this.client.assistants.getGraph(this.assistant.assistant_id);

    const mode =
      !forwardedProps?.command?.resume &&
      threadId &&
      this.activeRun!.nodeName != "__end__" &&
      this.activeRun!.nodeName
        ? "continue"
        : "start";

    if (mode === "continue") {
      const nodeBefore = this.activeRun!.graphInfo.edges.find(
        (e) => e.target === this.activeRun!.nodeName,
      );
      await this.client.threads.updateState(threadId, {
        values: inputState,
        asNode: nodeBefore?.source,
      });
    }

    const payloadInput = getStreamPayloadInput({
      mode,
      state: stateValues,
      schemaKeys: this.activeRun!.schemaKeys,
    });

    let payloadConfig: LangGraphConfig | undefined;
    const configsToMerge = [this.assistantConfig, forwardedProps?.config].filter(
      Boolean,
    ) as LangGraphConfig[];
    if (configsToMerge.length) {
      payloadConfig = await this.mergeConfigs({
        configs: configsToMerge,
        assistant: this.assistant,
        schemaKeys: this.activeRun!.schemaKeys,
      });
    }
    const payload = {
      ...forwardedProps,
      streamMode,
      input: payloadInput,
      config: payloadConfig,
      context: {
        ...context,
        ...(payloadConfig?.configurable ?? {}),
      }
    };

    // If there are still outstanding unresolved interrupts, we must force resolution of them before moving forward
    const interrupts = (agentState.tasks?.[0]?.interrupts ?? []) as Interrupt[];
    if (interrupts?.length && !forwardedProps?.command?.resume) {
      this.dispatchEvent({
        type: EventType.RUN_STARTED,
        threadId,
        runId: input.runId,
      });
      this.handleNodeChange(nodeNameInput)

      interrupts.forEach((interrupt) => {
        this.dispatchEvent({
          type: EventType.CUSTOM,
          name: LangGraphEventTypes.OnInterrupt,
          value:
            typeof interrupt.value === "string" ? interrupt.value : JSON.stringify(interrupt.value),
          rawEvent: interrupt,
        });
      });

      this.dispatchEvent({
        type: EventType.RUN_FINISHED,
        threadId,
        runId: input.runId,
      });
      return this.subscriber.complete();
    }

    return {
      // @ts-ignore
      streamResponse: this.client.runs.stream(threadId, this.assistant.assistant_id, payload),
      state: threadState as ThreadState<State>,
    };
  }

  async handleStreamEvents(
    stream: Awaited<
      ReturnType<typeof this.prepareStream> | ReturnType<typeof this.prepareRegenerateStream>
    >,
    threadId: string,
    subscriber: Subscriber<ProcessedEvents>,
    input: RunAgentExtendedInput,
    streamModes: StreamMode | StreamMode[],
  ) {
    const { forwardedProps } = input;
    const nodeNameInput = forwardedProps?.nodeName;
    this.subscriber = subscriber;
    let shouldExit = false;
    if (!stream) return;

    let { streamResponse, state } = stream;

    this.activeRun!.prevNodeName = null;
    let latestStateValues = {} as ThreadState<State>["values"];
    let updatedState = state;

    try {
      this.dispatchEvent({
        type: EventType.RUN_STARTED,
        threadId,
        runId: this.activeRun!.id,
      });
      this.handleNodeChange(nodeNameInput)

      for await (let streamResponseChunk of streamResponse) {
        const subgraphsStreamEnabled = input.forwardedProps?.streamSubgraphs;
        const isSubgraphStream =
          subgraphsStreamEnabled &&
          (streamResponseChunk.event.startsWith("events") ||
            streamResponseChunk.event.startsWith("values"));

        // @ts-ignore
        if (!streamModes.includes(streamResponseChunk.event as StreamMode) && !isSubgraphStream && streamResponseChunk.event !== 'error') {
          continue;
        }

        // Force event type, as data is not properly defined on the LG side.
        type EventsChunkData = {
          __interrupt__?: any;
          metadata: Record<string, any>;
          event: string;
          data: any;
          [key: string]: unknown;
        };
        const chunk = streamResponseChunk as EventsStreamEvent & { data: EventsChunkData };

        if (streamResponseChunk.event === "error") {
          this.dispatchEvent({
            type: EventType.RUN_ERROR,
            message: streamResponseChunk.data.message,
            rawEvent: streamResponseChunk,
          });
          break;
        }

        if (streamResponseChunk.event === "updates") {
          continue;
        }

        if (streamResponseChunk.event === "values") {
          latestStateValues = chunk.data;
          continue;
        } else if (subgraphsStreamEnabled && chunk.event.startsWith("values|")) {
          latestStateValues = {
            ...latestStateValues,
            ...chunk.data,
          };
          continue;
        }

        const chunkData = chunk.data;
        const metadata = chunkData.metadata ?? {};
        const currentNodeName = metadata.langgraph_node;
        const eventType = chunkData.event;

        this.activeRun!.id = metadata.run_id;

        if (currentNodeName && currentNodeName !== this.activeRun!.nodeName) {
          this.handleNodeChange(currentNodeName)
        }

        shouldExit =
          shouldExit ||
          (eventType === LangGraphEventTypes.OnCustomEvent &&
            chunkData.name === CustomEventNames.Exit);

        this.activeRun!.exitingNode =
          this.activeRun!.nodeName === currentNodeName &&
          eventType === LangGraphEventTypes.OnChainEnd;
        if (this.activeRun!.exitingNode) {
          this.activeRun!.manuallyEmittedState = null;
        }

        // we only want to update the node name under certain conditions
        // since we don't need any internal node names to be sent to the frontend
        if (this.activeRun!.graphInfo?.["nodes"].some((node) => node.id === currentNodeName)) {
          this.handleNodeChange(currentNodeName)
        }

        updatedState.values = this.activeRun!.manuallyEmittedState ?? latestStateValues;

        if (!this.activeRun!.nodeName) {
          continue;
        }

        const hasStateDiff = JSON.stringify(updatedState) !== JSON.stringify(state);
        // We should not update snapshot while a message is in progress.
        if (
          (hasStateDiff ||
            this.activeRun!.prevNodeName != this.activeRun!.nodeName ||
            this.activeRun!.exitingNode) &&
          !Boolean(this.getMessageInProgress(this.activeRun!.id))
        ) {
          state = updatedState;
          this.activeRun!.prevNodeName = this.activeRun!.nodeName;

          this.dispatchEvent({
            type: EventType.STATE_SNAPSHOT,
            snapshot: this.getStateSnapshot(state),
            rawEvent: chunk,
          });
        }

        this.dispatchEvent({
          type: EventType.RAW,
          event: chunkData,
        });

        this.handleSingleEvent(chunkData);
      }

      state = await this.client.threads.getState(threadId);
      const tasks = state.tasks;
      const interrupts = (tasks?.[0]?.interrupts ?? []) as Interrupt[];
      const isEndNode = state.next.length === 0;
      const writes = state.metadata?.writes ?? {};

      // Initialize a new node name to use in the next if block
      let newNodeName = this.activeRun!.nodeName!;

      if (!interrupts?.length) {
        newNodeName = isEndNode ? "__end__" : (state.next[0] ?? Object.keys(writes)[0]);
      }

      interrupts.forEach((interrupt) => {
        this.dispatchEvent({
          type: EventType.CUSTOM,
          name: LangGraphEventTypes.OnInterrupt,
          value:
            typeof interrupt.value === "string" ? interrupt.value : JSON.stringify(interrupt.value),
          rawEvent: interrupt,
        });
      });

      this.handleNodeChange(newNodeName);
      // Immediately turn off new step
      this.handleNodeChange(undefined);

      this.dispatchEvent({
        type: EventType.STATE_SNAPSHOT,
        snapshot: this.getStateSnapshot(state),
      });
      this.dispatchEvent({
        type: EventType.MESSAGES_SNAPSHOT,
        messages: langchainMessagesToAgui((state.values as { messages: any[] }).messages ?? []),
      });

      this.dispatchEvent({
        type: EventType.RUN_FINISHED,
        threadId,
        runId: this.activeRun!.id,
      });
      this.activeRun = undefined;
      return subscriber.complete();
    } catch (e) {
      return subscriber.error(e);
    }
  }

  handleSingleEvent(event: any): void {
    switch (event.event) {
      case LangGraphEventTypes.OnChatModelStream:
        let shouldEmitMessages = event.metadata["emit-messages"] ?? true;
        let shouldEmitToolCalls = event.metadata["emit-tool-calls"] ?? true;

        if (event.data.chunk.response_metadata.finish_reason) return;
        let currentStream = this.getMessageInProgress(this.activeRun!.id);
        const hasCurrentStream = Boolean(currentStream?.id);
        const toolCallData = event.data.chunk.tool_call_chunks?.[0];
        const toolCallUsedToPredictState = event.metadata["predict_state"]?.some(
          (predictStateTool: PredictStateTool) => predictStateTool.tool === toolCallData?.name,
        );

        const isToolCallStartEvent = !hasCurrentStream && toolCallData?.name;
        const isToolCallArgsEvent =
          hasCurrentStream && currentStream?.toolCallId && toolCallData?.args;
        const isToolCallEndEvent = hasCurrentStream && currentStream?.toolCallId && !toolCallData;

        if (isToolCallEndEvent || isToolCallArgsEvent || isToolCallStartEvent) {
          this.activeRun!.hasFunctionStreaming = true;
        }

        const reasoningData = resolveReasoningContent(event.data);
        const messageContent = resolveMessageContent(event.data.chunk.content);
        const isMessageContentEvent = Boolean(!toolCallData && messageContent);

        const isMessageEndEvent =
          hasCurrentStream && !currentStream?.toolCallId && !isMessageContentEvent;

        if (reasoningData) {
          this.handleThinkingEvent(reasoningData);
          break;
        }

        if (!reasoningData && this.thinkingProcess) {
          this.dispatchEvent({
            type: EventType.THINKING_TEXT_MESSAGE_END,
          });
          this.dispatchEvent({
            type: EventType.THINKING_END,
          });
          this.thinkingProcess = null;
        }

        if (toolCallUsedToPredictState) {
          this.dispatchEvent({
            type: EventType.CUSTOM,
            name: "PredictState",
            value: event.metadata["predict_state"],
          });
        }

        if (isToolCallEndEvent) {
          const resolved = this.dispatchEvent({
            type: EventType.TOOL_CALL_END,
            toolCallId: currentStream?.toolCallId!,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }

        if (isMessageEndEvent) {
          const resolved = this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_END,
            messageId: currentStream!.id,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }

        if (isToolCallStartEvent && shouldEmitToolCalls) {
          const resolved = this.dispatchEvent({
            type: EventType.TOOL_CALL_START,
            toolCallId: toolCallData.id,
            toolCallName: toolCallData.name,
            parentMessageId: event.data.chunk.id,
            rawEvent: event,
          });
          if (resolved) {
            this.setMessageInProgress(this.activeRun!.id, {
              id: event.data.chunk.id,
              toolCallId: toolCallData.id,
              toolCallName: toolCallData.name,
            });
          }
          break;
        }

        // Tool call args: emit ActionExecutionArgs
        if (isToolCallArgsEvent && shouldEmitToolCalls) {
          this.dispatchEvent({
            type: EventType.TOOL_CALL_ARGS,
            toolCallId: currentStream?.toolCallId!,
            delta: toolCallData.args,
            rawEvent: event,
          });
          break;
        }

        // Message content: emit TextMessageContent
        if (isMessageContentEvent && shouldEmitMessages) {
          // No existing message yet, also init the message
          if (!currentStream) {
            this.dispatchEvent({
              type: EventType.TEXT_MESSAGE_START,
              role: "assistant",
              messageId: event.data.chunk.id,
              rawEvent: event,
            });
            this.setMessageInProgress(this.activeRun!.id, {
              id: event.data.chunk.id,
              toolCallId: null,
              toolCallName: null,
            });
            currentStream = this.getMessageInProgress(this.activeRun!.id);
          }

          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_CONTENT,
            messageId: currentStream!.id,
            delta: messageContent!,
            rawEvent: event,
          });
          break;
        }

        break;
      case LangGraphEventTypes.OnChatModelEnd:
        if (this.getMessageInProgress(this.activeRun!.id)?.toolCallId) {
          const resolved = this.dispatchEvent({
            type: EventType.TOOL_CALL_END,
            toolCallId: this.getMessageInProgress(this.activeRun!.id)!.toolCallId!,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }
        if (this.getMessageInProgress(this.activeRun!.id)?.id) {
          const resolved = this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_END,
            messageId: this.getMessageInProgress(this.activeRun!.id)!.id,
            rawEvent: event,
          });
          if (resolved) {
            this.messagesInProcess[this.activeRun!.id] = null;
          }
          break;
        }
        break;
      case LangGraphEventTypes.OnCustomEvent:
        if (event.name === CustomEventNames.ManuallyEmitMessage) {
          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_START,
            role: "assistant",
            messageId: event.data.message_id,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_CONTENT,
            messageId: event.data.message_id,
            delta: event.data.message,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TEXT_MESSAGE_END,
            messageId: event.data.message_id,
            rawEvent: event,
          });
          break;
        }

        if (event.name === CustomEventNames.ManuallyEmitToolCall) {
          this.dispatchEvent({
            type: EventType.TOOL_CALL_START,
            toolCallId: event.data.id,
            toolCallName: event.data.name,
            parentMessageId: event.data.id,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TOOL_CALL_ARGS,
            toolCallId: event.data.id,
            delta: event.data.args,
            rawEvent: event,
          });
          this.dispatchEvent({
            type: EventType.TOOL_CALL_END,
            toolCallId: event.data.id,
            rawEvent: event,
          });
          break;
        }

        if (event.name === CustomEventNames.ManuallyEmitState) {
          this.activeRun!.manuallyEmittedState = event.data;
          this.dispatchEvent({
            type: EventType.STATE_SNAPSHOT,
            snapshot: this.getStateSnapshot({
              values: this.activeRun!.manuallyEmittedState!,
            } as ThreadState<State>),
            rawEvent: event,
          });
        }

        this.dispatchEvent({
          type: EventType.CUSTOM,
          name: event.name,
          value: event.data,
          rawEvent: event,
        });
        break;
      case LangGraphEventTypes.OnToolEnd:
        if (this.activeRun!.hasFunctionStreaming) break;
        const toolCallOutput = event.data.output
        this.dispatchEvent({
          type: EventType.TOOL_CALL_START,
          toolCallId: toolCallOutput.tool_call_id,
          toolCallName: toolCallOutput.name,
          parentMessageId: toolCallOutput.id,
          rawEvent: event,
        })
        this.dispatchEvent({
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: toolCallOutput.tool_call_id,
          delta: JSON.stringify(event.data.input),
          rawEvent: event,
        });
        this.dispatchEvent({
          type: EventType.TOOL_CALL_END,
          toolCallId: toolCallOutput.tool_call_id,
          rawEvent: event,
        });
    }
  }

  handleThinkingEvent(reasoningData: LangGraphReasoning) {
    if (!reasoningData || !reasoningData.type || !reasoningData.text) {
      return;
    }

    const thinkingStepIndex = reasoningData.index;

    if (this.thinkingProcess?.index && this.thinkingProcess.index !== thinkingStepIndex) {
      if (this.thinkingProcess.type) {
        this.dispatchEvent({
          type: EventType.THINKING_TEXT_MESSAGE_END,
        });
      }
      this.dispatchEvent({
        type: EventType.THINKING_END,
      });
      this.thinkingProcess = null;
    }

    if (!this.thinkingProcess) {
      // No thinking step yet. Start a new one
      this.dispatchEvent({
        type: EventType.THINKING_START,
      });
      this.thinkingProcess = {
        index: thinkingStepIndex,
      };
    }

    if (this.thinkingProcess.type !== reasoningData.type) {
      this.dispatchEvent({
        type: EventType.THINKING_TEXT_MESSAGE_START,
      });
      this.thinkingProcess.type = reasoningData.type;
    }

    if (this.thinkingProcess.type) {
      this.dispatchEvent({
        type: EventType.THINKING_TEXT_MESSAGE_CONTENT,
        delta: reasoningData.text,
      });
    }
  }

  getStateSnapshot(threadState: ThreadState<State>) {
    let state = threadState.values;
    const schemaKeys = this.activeRun!.schemaKeys!;
    // Do not emit state keys that are not part of the output schema
    if (schemaKeys?.output) {
      state = filterObjectBySchemaKeys(state, [...this.constantSchemaKeys, ...schemaKeys.output]);
    }
    // return state
    return state;
  }

  async getOrCreateThread(threadId: string, threadMetadata?: Record<string, any>): Promise<Thread> {
    let thread: Thread;
    try {
      try {
        thread = await this.getThread(threadId);
      } catch (error) {
        thread = await this.createThread({
          threadId,
          metadata: threadMetadata,
        });
      }
    } catch (error: unknown) {
      throw new Error(`Failed to create thread: ${(error as Error).message}`);
    }

    return thread;
  }

  async getThread(threadId: string) {
    return this.client.threads.get(threadId);
  }

  async createThread(payload?: Parameters<typeof this.client.threads.create>[0]) {
    return this.client.threads.create(payload);
  }

  async mergeConfigs({
    configs,
    assistant,
    schemaKeys,
  }: {
    configs: Config[];
    assistant: Assistant;
    schemaKeys: SchemaKeys;
  }) {
    return configs.reduce((acc, cfg) => {
      let filteredConfigurable = acc.configurable;

      if (cfg.configurable) {
        filteredConfigurable = schemaKeys?.config
          ? filterObjectBySchemaKeys(cfg?.configurable, [
              ...this.constantSchemaKeys,
              ...(schemaKeys?.config ?? []),
            ])
          : cfg?.configurable;
      }

      const newConfig = {
        ...acc,
        ...cfg,
        configurable: filteredConfigurable,
      };

      // LG does not return recursion limit if it's the default, therefore we check: if no recursion limit is currently set, and the user asked for 25, there is no change.
      const isRecursionLimitSetToDefault =
        acc.recursion_limit == null && cfg.recursion_limit === 25;
      // Deep compare configs to avoid unnecessary update calls
      const configsAreDifferent = JSON.stringify(newConfig) !== JSON.stringify(acc);

      // Check if the only difference is the recursion_limit being set to default
      const isOnlyRecursionLimitDifferent =
        isRecursionLimitSetToDefault &&
        JSON.stringify({ ...newConfig, recursion_limit: null }) ===
          JSON.stringify({ ...acc, recursion_limit: null });

      if (configsAreDifferent && !isOnlyRecursionLimitDifferent) {
        return {
          ...acc,
          ...newConfig,
        };
      }

      return acc;
    }, assistant.config);
  }

  getMessageInProgress(runId: string) {
    return this.messagesInProcess[runId];
  }

  setMessageInProgress(runId: string, data: MessageInProgress) {
    this.messagesInProcess = {
      ...this.messagesInProcess,
      [runId]: {
        ...(this.messagesInProcess[runId] as MessageInProgress),
        ...data,
      },
    };
  }

  async getAssistant(): Promise<Assistant> {
    const assistants = await this.client.assistants.search();
    const retrievedAssistant = assistants.find(
      (searchResult) => searchResult.graph_id === this.graphId,
    );
    if (!retrievedAssistant) {
      console.error(`
      No agent found with graph ID ${this.graphId} found..\n
      
      These are the available agents: [${assistants.map((a) => `${a.graph_id} (ID: ${a.assistant_id})`).join(", ")}]
      `);
      throw new Error("No agent id found");
    }

    return retrievedAssistant;
  }

  async getSchemaKeys(): Promise<SchemaKeys> {
    try {
      const graphSchema = await this.client.assistants.getSchemas(this.assistant!.assistant_id);
      let configSchema = null;
      let contextSchema: string[] = []
      if ('context_schema' in graphSchema && graphSchema.context_schema?.properties) {
        contextSchema = Object.keys(graphSchema.context_schema.properties);
      }
      if (graphSchema.config_schema?.properties) {
        configSchema = Object.keys(graphSchema.config_schema.properties);
      }
      if (!graphSchema.input_schema?.properties || !graphSchema.output_schema?.properties) {
        return { config: [], input: null, output: null, context: contextSchema };
      }
      const inputSchema = Object.keys(graphSchema.input_schema.properties);
      const outputSchema = Object.keys(graphSchema.output_schema.properties);

      return {
        input:
          inputSchema && inputSchema.length ? [...inputSchema, ...this.constantSchemaKeys] : null,
        output:
          outputSchema && outputSchema.length
            ? [...outputSchema, ...this.constantSchemaKeys]
            : null,
        context: contextSchema,
        config: configSchema,
      };
    } catch (e) {
      return { config: [], input: this.constantSchemaKeys, output: this.constantSchemaKeys, context: [] };
    }
  }

  langGraphDefaultMergeState(state: State, messages: LangGraphMessage[], input: RunAgentExtendedInput): State<StateEnrichment> {
    if (messages.length > 0 && "role" in messages[0] && messages[0].role === "system") {
      // remove system message
      messages = messages.slice(1);
    }

    // merge with existing messages
    const existingMessages: LangGraphPlatformMessage[] = state.messages || [];
    const existingMessageIds = new Set(existingMessages.map((message) => message.id));

    const newMessages = messages.filter((message) => !existingMessageIds.has(message.id));

    const langGraphTools: LangGraphToolWithName[] = [...(state.tools ?? []), ...(input.tools ?? [])].reduce((acc, tool) => {
      let mappedTool = tool;
      if (!tool.type) {
        mappedTool = {
            type: "function",
            name: tool.name,
            function: {
                name: tool.name,
                description: tool.description,
                parameters: tool.parameters,
            },
        }
      }

      // Verify no duplicated
      if (acc.find((t: LangGraphToolWithName) => (t.name === mappedTool.name) || t.function.name === mappedTool.function.name)) return acc;

      return [...acc, mappedTool];
    }, []);

    return {
      ...state,
      messages: newMessages,
      tools: langGraphTools,
      'ag-ui': {
        tools: langGraphTools,
        context: input.context,
      }
    };
  }

  handleNodeChange(nodeName: string | undefined) {
    if (nodeName === "__end__") {
      nodeName = undefined;
    }
    if (nodeName !== this.activeRun?.nodeName) {
      // End current step
      if (this.activeRun?.nodeName) {
        this.endStep();
      }
      // If we actually got a node name, start a new step
      if (nodeName) {
        this.startStep(nodeName);
      }
    }
    this.activeRun!.nodeName = nodeName;
  }

  startStep(nodeName: string) {
    this.dispatchEvent({
      type: EventType.STEP_STARTED,
      stepName: nodeName,
    });
  }

  endStep() {
    this.dispatchEvent({
      type: EventType.STEP_FINISHED,
      stepName: this.activeRun!.nodeName!,
    });
  }

  async getCheckpointByMessage(
    messageId: string,
    threadId: string,
    checkpoint?: null | {
      checkpoint_id?: null | string;
      checkpoint_ns: string;
    },
  ): Promise<ThreadState> {
    const options = checkpoint?.checkpoint_id
      ? {
          checkpoint: { checkpoint_id: checkpoint.checkpoint_id },
        }
      : undefined;
    const history = await this.client.threads.getHistory(threadId, options);
    const reversed = [...history].reverse(); // oldest → newest

    let targetState = reversed.find((state) =>
      (state.values as State).messages?.some((m: LangGraphPlatformMessage) => m.id === messageId),
    );

    if (!targetState) throw new Error("Message not found");

    const targetStateMessages = (targetState.values as State).messages ?? [];
    const messageIndex = targetStateMessages.findIndex(
      (m: LangGraphPlatformMessage) => m.id === messageId,
    );
    const messagesAfter = targetStateMessages.slice(messageIndex + 1);
    if (messagesAfter.length) {
      return this.getCheckpointByMessage(messageId, threadId, targetState.parent_checkpoint);
    }

    const targetStateIndex = reversed.indexOf(targetState);

    const { messages, ...targetStateValuesWithoutMessages } = targetState.values as State;
    const selectedCheckpoint = reversed[targetStateIndex - 1] ?? { ...targetState, values: {} };
    return {
      ...selectedCheckpoint,
      values: { ...selectedCheckpoint.values, ...targetStateValuesWithoutMessages },
    };
  }
}

export * from "./types";



================================================
FILE: typescript-sdk/integrations/langgraph/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export * from './agent'
export class LangGraphHttpAgent extends HttpAgent {}


================================================
FILE: typescript-sdk/integrations/langgraph/src/types.ts
================================================
import { AssistantGraph, Message as LangGraphMessage, } from "@langchain/langgraph-sdk";
import { MessageType } from "@langchain/core/messages";
import { RunAgentInput } from "@ag-ui/core";

export enum LangGraphEventTypes {
  OnChainStart = "on_chain_start",
  OnChainStream = "on_chain_stream",
  OnChainEnd = "on_chain_end",
  OnChatModelStart = "on_chat_model_start",
  OnChatModelStream = "on_chat_model_stream",
  OnChatModelEnd = "on_chat_model_end",
  OnToolStart = "on_tool_start",
  OnToolEnd = "on_tool_end",
  OnCustomEvent = "on_custom_event",
  OnInterrupt = "on_interrupt",
}

export type LangGraphToolWithName = {
  type: "function";
  name?: string;
  function: {
    name: string;
    description: string;
    parameters: any;
  },
}

export type State<TDefinedState = Record<string, any>> = {
  [k in keyof TDefinedState]: TDefinedState[k] | null;
} & Record<string, any>;
export interface StateEnrichment {
  messages: LangGraphMessage[];
  tools: LangGraphToolWithName[];
  'ag-ui': {
    tools: LangGraphToolWithName[];
    context: RunAgentInput['context']
  }
}

export type SchemaKeys = {
  input: string[] | null;
  output: string[] | null;
  context: string[] | null;
  config: string[] | null;
} | null;

export type MessageInProgress = {
  id: string;
  toolCallId?: string | null;
  toolCallName?: string | null;
};

export type ThinkingInProgress = {
  index: number;
  type?: LangGraphReasoning['type'];
}

export interface RunMetadata {
  id: string;
  schemaKeys?: SchemaKeys;
  nodeName?: string;
  prevNodeName?: string | null;
  exitingNode?: boolean;
  manuallyEmittedState?: State | null;
  threadId?: string;
  graphInfo?: AssistantGraph
  hasFunctionStreaming?: boolean;
}

export type MessagesInProgressRecord = Record<string, MessageInProgress | null>;

// The following types are our own definition to the messages accepted by LangGraph Platform, enhanced with some of our extra data.
export interface ToolCall {
  id: string;
  name: string;
  args: Record<string, unknown>;
}

type BaseLangGraphPlatformMessage = Omit<
  LangGraphMessage,
  | "isResultMessage"
  | "isTextMessage"
  | "isImageMessage"
  | "isActionExecutionMessage"
  | "isAgentStateMessage"
  | "type"
  | "createdAt"
> & {
  content: string;
  role: string;
  additional_kwargs?: Record<string, unknown>;
  type: MessageType;
};

interface LangGraphPlatformResultMessage extends BaseLangGraphPlatformMessage {
  tool_call_id: string;
  name: string;
}

interface LangGraphPlatformActionExecutionMessage extends BaseLangGraphPlatformMessage {
  tool_calls: ToolCall[];
}

export type LangGraphPlatformMessage =
  | LangGraphPlatformActionExecutionMessage
  | LangGraphPlatformResultMessage
  | BaseLangGraphPlatformMessage;

export enum CustomEventNames {
  ManuallyEmitMessage = "manually_emit_message",
  ManuallyEmitToolCall = "manually_emit_tool_call",
  ManuallyEmitState = "manually_emit_state",
  Exit = "exit",
}

export interface PredictStateTool {
  tool: string;
  state_key: string;
  tool_argument: string;
}

export interface LangGraphReasoning {
  type: 'text';
  text: string;
  index: number
}



================================================
FILE: typescript-sdk/integrations/langgraph/src/utils.ts
================================================
import { Message as LangGraphMessage } from "@langchain/langgraph-sdk";
import { State, SchemaKeys, LangGraphReasoning } from "./types";
import { Message, ToolCall } from "@ag-ui/client";

export const DEFAULT_SCHEMA_KEYS = ["messages", "tools"];

export function filterObjectBySchemaKeys(obj: Record<string, any>, schemaKeys: string[]) {
  return Object.fromEntries(Object.entries(obj).filter(([key]) => schemaKeys.includes(key)));
}

export function getStreamPayloadInput({
  mode,
  state,
  schemaKeys,
}: {
  mode: "start" | "continue";
  state: State;
  schemaKeys: SchemaKeys;
}) {
  let input = mode === "start" ? state : null;
  // Do not input keys that are not part of the input schema
  if (input && schemaKeys?.input) {
    input = filterObjectBySchemaKeys(input, [...DEFAULT_SCHEMA_KEYS, ...schemaKeys.input]);
  }

  return input;
}

export function langchainMessagesToAgui(messages: LangGraphMessage[]): Message[] {
  return messages.map((message) => {
    switch (message.type) {
      case "human":
        return {
          id: message.id!,
          role: "user",
          content: stringifyIfNeeded(resolveMessageContent(message.content)),
        };
      case "ai":
        const content = resolveMessageContent(message.content)
        return {
          id: message.id!,
          role: "assistant",
          content: content ? stringifyIfNeeded(content) : '',
          toolCalls: message.tool_calls?.map((tc) => ({
            id: tc.id!,
            type: "function",
            function: {
              name: tc.name,
              arguments: JSON.stringify(tc.args),
            },
          })),
        };
      case "system":
        return {
          id: message.id!,
          role: "system",
          content: stringifyIfNeeded(resolveMessageContent(message.content)),
        };
      case "tool":
        return {
          id: message.id!,
          role: "tool",
          content: stringifyIfNeeded(resolveMessageContent(message.content)),
          toolCallId: message.tool_call_id,
        };
      default:
        throw new Error("message type returned from LangGraph is not supported.");
    }
  });
}

export function aguiMessagesToLangChain(messages: Message[]): LangGraphMessage[] {
  return messages.map((message, index) => {
    switch (message.role) {
      case "user":
        return {
          id: message.id,
          role: message.role,
          content: message.content,
          type: "human",
        };
      case "assistant":
        return {
          id: message.id,
          type: "ai",
          role: message.role,
          content: message.content ?? "",
          tool_calls: (message.toolCalls ?? []).map((tc: ToolCall) => ({
            id: tc.id,
            name: tc.function.name,
            args: JSON.parse(tc.function.arguments),
            type: "tool_call",
          })),
        };
      case "system":
        return {
          id: message.id,
          role: message.role,
          content: message.content,
          type: "system",
        };
      case "tool":
        return {
          content: message.content,
          role: message.role,
          type: message.role,
          tool_call_id: message.toolCallId,
          id: message.id,
        };
      default:
        console.error(`Message role ${message.role} is not implemented`);
        throw new Error("message role is not supported.");
    }
  });
}

function stringifyIfNeeded(item: any) {
  if (typeof item === "string") return item;
  return JSON.stringify(item);
}

export function resolveReasoningContent(eventData: any): LangGraphReasoning | null {
  const content = eventData.chunk?.content

  // Anthropic reasoning response
  if (content && Array.isArray(content) && content.length && content[0]) {
    if (!content[0].thinking) return null
    return {
      text: content[0].thinking,
      type: 'text',
      index: content[0].index,
    }
  }

  /// OpenAI reasoning response
  if (eventData.chunk.additional_kwargs?.reasoning?.summary?.[0]) {
    const data = eventData.chunk.additional_kwargs?.reasoning.summary[0]
    if (!data || !data.text) return null
    return {
      type: 'text',
      text: data.text,
      index: data.index,
    }
  }

  return null
}

export function resolveMessageContent(content?: LangGraphMessage['content']): string | null {
  if (!content) return null;

  if (typeof content === 'string') {
    return content;
  }

  if (Array.isArray(content) && content.length) {
    const contentText = content.find(c => c.type === 'text')?.text
    return contentText ?? null;
  }

  return null
}



================================================
FILE: typescript-sdk/integrations/llamaindex/README.md
================================================
# @ag-ui/llamaindex

Implementation of the AG-UI protocol for LlamaIndex.

Connects LlamaIndex workflows to frontend applications via the AG-UI protocol. Provides HTTP connectivity to LlamaIndex servers with support for RAG pipelines and workflow orchestration.

## Installation

```bash
npm install @ag-ui/llamaindex
pnpm add @ag-ui/llamaindex
yarn add @ag-ui/llamaindex
```

## Usage

```ts
import { LlamaIndexAgent } from "@ag-ui/llamaindex";

// Create an AG-UI compatible agent
const agent = new LlamaIndexAgent({
  url: "http://localhost:9000/agentic_chat",
  headers: { "Content-Type": "application/json" },
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Query my documents" }],
});
```

## Features

- **HTTP connectivity** – Connect to LlamaIndex FastAPI servers
- **Workflow support** – Full integration with LlamaIndex workflow orchestration
- **RAG capabilities** – Document retrieval and reasoning workflows
- **Python integration** – Complete FastAPI server implementation included

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/llamaindex/server-py
uv sync && uv run dev
```



================================================
FILE: typescript-sdk/integrations/llamaindex/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/llamaindex/package.json
================================================
{
  "name": "@ag-ui/llamaindex",
  "author": "Logan Markewich <logan@runllama.ai>",
  "version": "0.1.3",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.39",
    "@ag-ui/client": ">=0.0.39",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/llamaindex/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/llamaindex/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/llamaindex/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/README.md
================================================
# LlamaIndex Python AG-UI Integration

This package provides a FastAPI server that is bootstrapped with several AG-UI+LlamaIndex endpoints. It can be used to communicate with AG-UI compatible frameworks like [CopilotKit](https://docs.copilotkit.ai/).

## Usage

Launch the server with:

```python
uv sync
uv run dev
```

Launch the frontend dojo with:

```bash
cd ../../
pnpm install
turbo run dev
```



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/pyproject.toml
================================================
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "server"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.9, <3.14"
dependencies = [
    "llama-index-core>=0.14.0,<0.15",
    "llama-index-llms-openai>=0.5.0,<0.6.0",
    "llama-index-protocols-ag-ui>=0.2.2,<0.3",
    "jsonpatch>=1.33",
    "uvicorn>=0.27.0",
    "fastapi>=0.100.0",
]
authors = [
    { name = "Logan Markewich", email = "logan@runllama.ai" },
]

[tool.hatch.build.targets.sdist]
include = ["server/"]

[tool.hatch.build.targets.wheel]
include = ["server/"]

[tool.hatch.metadata]
allow-direct-references = true

[project.scripts]
dev = "server:main"



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/__init__.py
================================================
import os
import uvicorn
from fastapi import FastAPI

from .routers.agentic_chat import agentic_chat_router
from .routers.human_in_the_loop import human_in_the_loop_router
from .routers.agentic_generative_ui import agentic_generative_ui_router
from .routers.shared_state import shared_state_router

app = FastAPI(title="AG-UI Llama-Index Endpoint")

app.include_router(agentic_chat_router, prefix="/agentic_chat")
app.include_router(human_in_the_loop_router, prefix="/human_in_the_loop")
app.include_router(agentic_generative_ui_router, prefix="/agentic_generative_ui")
app.include_router(shared_state_router, prefix="/shared_state")

def main():

    """Main function to start the FastAPI server."""
    port = int(os.getenv("PORT", "9000"))

    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/agentic_chat.py
================================================
from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
from typing import Annotated


# This tool has a client-side version that is actually called to change the background
def change_background(
    background: Annotated[str, "The background. Prefer gradients."],
) -> str:
    """Change the background color of the chat. Can be anything that the CSS background attribute accepts. Regular colors, linear of radial gradients etc."""
    return f"Changing background to {background}"

agentic_chat_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[change_background],
)



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/agentic_generative_ui.py
================================================
import asyncio
import copy
import jsonpatch
from pydantic import BaseModel

from llama_index.core.workflow import Context
from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router
from llama_index.protocols.ag_ui.events import StateDeltaWorkflowEvent, StateSnapshotWorkflowEvent

class Step(BaseModel):
    description: str

class Task(BaseModel):
    steps: list[Step]

# Genrative UI demo
async def run_task(
    ctx: Context, task: Task,
) -> str:
    """Execute any list of steps needed to complete a task. Useful for anything the user wants to do."""

    async with ctx.store.edit_state() as global_state:
        state = global_state.get("state", {})
        task = Task.model_validate(task)

        state = {
            "steps": [
                {
                    "description": step.description,
                    "status": "pending"
                }
                for step in task.steps
            ]
        }

        # Send initial state snapshot
        ctx.write_event_to_stream(
            StateSnapshotWorkflowEvent(
                snapshot=state
            )
        )

        # Sleep for 1 second
        await asyncio.sleep(1.0)

        # Create a copy to track changes for JSON patches
        previous_state = copy.deepcopy(state)

        # Update each step and send deltas
        for i, step in enumerate(state["steps"]):
            step["status"] = "completed"
            
            # Generate JSON patch from previous state to current state
            patch = jsonpatch.make_patch(previous_state, state)
            
            # Send state delta event
            ctx.write_event_to_stream(
                StateDeltaWorkflowEvent(
                    delta=patch.patch
                )
            )
            
            # Update previous state for next iteration
            previous_state = copy.deepcopy(state)
            
            # Sleep for 1 second
            await asyncio.sleep(1.0)

        # Optionally send a final snapshot to the client
        ctx.write_event_to_stream(
            StateSnapshotWorkflowEvent(
                snapshot=state
            )
        )

        global_state["state"] = state

    return "Task Done!"


agentic_generative_ui_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    backend_tools=[run_task],
    initial_state={},
    system_prompt=(
        "You are a helpful assistant that can help the user with their task. "
        "If the user asks you to do any task, use the run_task tool to do it. "
        "Use your best judgement to describe the steps."
    )
)



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/human_in_the_loop.py
================================================
from typing import Literal, List
from pydantic import BaseModel

from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router



class Step(BaseModel):
    description: str
    status: Literal["enabled", "disabled", "executing"]


def generate_task_steps(steps: List[Step]) -> str:
    return f"Generated {len(steps)} steps"


human_in_the_loop_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[generate_task_steps],
)



================================================
FILE: typescript-sdk/integrations/llamaindex/server-py/server/routers/shared_state.py
================================================
from typing import Literal, List
from pydantic import BaseModel

from llama_index.core.workflow import Context
from llama_index.llms.openai import OpenAI
from llama_index.protocols.ag_ui.events import StateSnapshotWorkflowEvent
from llama_index.protocols.ag_ui.router import get_ag_ui_workflow_router


class Ingredient(BaseModel):
    icon: str
    name: str
    amount: str

class Recipe(BaseModel):
    skill_level: str
    special_preferences: List[str]
    cooking_time: str
    ingredients: List[Ingredient]
    instructions: List[str]


async def update_recipe(ctx: Context, recipe: Recipe) -> str:
    """Useful for recording a recipe to shared state."""
    recipe = Recipe.model_validate(recipe)

    async with ctx.store.edit_state() as global_state:
        state = global_state.get("state", {})
        if state is None:
            state = {}

        state["recipe"] = recipe.model_dump()

        ctx.write_event_to_stream(
            StateSnapshotWorkflowEvent(
                snapshot=state
            )
        )

        global_state["state"] = state

    return "Recipe updated!"


shared_state_router = get_ag_ui_workflow_router(
    llm=OpenAI(model="gpt-4.1"),
    frontend_tools=[update_recipe],
    initial_state={
        "recipe": None,
    }
)





================================================
FILE: typescript-sdk/integrations/llamaindex/src/index.ts
================================================
/**
 * LlamaIndex is a simple, flexible framework for building agentic generative AI applications that allow large language models to work with your data in any format.
 * Check more about using LlamaIndex: https://docs.llamaindex.ai/
 */

import { HttpAgent } from "@ag-ui/client";

export class LlamaIndexAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/mastra/README.md
================================================
# @ag-ui/mastra

Implementation of the AG-UI protocol for Mastra.

Connects Mastra agents (local and remote) to frontend applications via the AG-UI protocol. Supports streaming responses, memory management, and tool execution.

## Installation

```bash
npm install @ag-ui/mastra
pnpm add @ag-ui/mastra
yarn add @ag-ui/mastra
```

## Usage

```ts
import { MastraAgent } from "@ag-ui/mastra";
import { mastra } from "./mastra"; // Your Mastra instance

// Create an AG-UI compatible agent
const agent = new MastraAgent({
  agent: mastra.getAgent("weather-agent"),
  resourceId: "user-123",
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "What's the weather like?" }],
});
```

## Features

- **Local & remote agents** – Works with in-process and network Mastra agents
- **Memory integration** – Automatic thread and working memory management
- **Tool streaming** – Real-time tool call execution and results
- **State management** – Bidirectional state synchronization

## To run the example server in the dojo

```bash
cd typescript-sdk/integrations/mastra/example
pnpm install
pnpm run dev
```



================================================
FILE: typescript-sdk/integrations/mastra/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/mastra/package.json
================================================
{
  "name": "@ag-ui/mastra",
  "version": "0.0.11",
  "license": "Apache-2.0",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "files": [
    "dist/**",
    "README.md"
  ],
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "import": "./dist/index.mjs",
      "require": "./dist/index.js"
    },
    "./copilotkit": {
      "types": "./dist/copilotkit.d.ts",
      "import": "./dist/copilotkit.mjs",
      "require": "./dist/copilotkit.js"
    }
  },
  "typesVersions": {
    "*": {
      "copilotkit": [
        "dist/copilotkit.d.ts"
      ]
    }
  },
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "tsup": {
    "entry": {
      "index": "src/index.ts",
      "copilotkit": "src/copilotkit.ts"
    },
    "dts": true,
    "format": [
      "cjs",
      "esm"
    ],
    "splitting": false,
    "sourcemap": true,
    "clean": true
  },
  "dependencies": {
    "@ai-sdk/ui-utils": "^1.1.19",
    "@mastra/client-js": "^0.10.18",
    "rxjs": "7.8.1"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "@copilotkit/runtime": "^1.9.3",
    "@mastra/core": ">=0.11.1",
    "zod": "^3.25.67"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@mastra/core": "^0.13.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/mastra/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/mastra/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: {
    index: "src/index.ts",
    copilotkit: "src/copilotkit.ts",
  },
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/mastra/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
example



================================================
FILE: typescript-sdk/integrations/mastra/example/package.json
================================================
{
  "name": "example",
  "version": "1.0.0",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "dev": "mastra dev",
    "build": "mastra build"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "",
  "type": "module",
  "engines": {
    "node": ">=20.9.0"
  },
  "dependencies": {
    "@ai-sdk/openai": "^1.3.24",
    "@mastra/client-js": "^0.10.20",
    "@mastra/core": "^0.13.1",
    "@mastra/libsql": "^0.13.1",
    "@mastra/loggers": "^0.10.6",
    "@mastra/memory": "^0.12.1",
    "zod": "^3.25.48"
  },
  "devDependencies": {
    "@types/node": "^22.15.29",
    "mastra": "^0.10.20",
    "typescript": "^5.8.3"
  }
}



================================================
FILE: typescript-sdk/integrations/mastra/example/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ES2022",
    "moduleResolution": "bundler",
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "skipLibCheck": true,
    "noEmit": true,
    "outDir": "dist"
  },
  "include": [
    "src/**/*"
  ]
}



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/index.ts
================================================
import { Mastra } from "@mastra/core/mastra";
import { PinoLogger } from "@mastra/loggers";
import { LibSQLStore } from "@mastra/libsql";

import { agenticChatAgent } from "./agents/agentic-chat";
import { toolBasedGenerativeUIAgent } from "./agents/tool-based-generative-ui";

export const mastra = new Mastra({
  server: {
    port: process.env.PORT ? parseInt(process.env.PORT) : 4111,
    host: "0.0.0.0",
  },
  agents: { agentic_chat: agenticChatAgent, tool_based_generative_ui: toolBasedGenerativeUIAgent },
  storage: new LibSQLStore({
    // stores telemetry, evals, ... into memory storage, if it needs to persist, change to file:../mastra.db
    url: ":memory:",
  }),
  logger: new PinoLogger({
    name: "Mastra",
    level: "info",
  }),
});



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/agents/agentic-chat.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { weatherTool } from "../tools/weather-tool";

export const agenticChatAgent = new Agent({
  name: "Weather Agent",
  instructions: `
      You are a helpful weather assistant that provides accurate weather information.

      Your primary function is to help users get weather details for specific locations. When responding:
      - Always ask for a location if none is provided
      - If the location name isn’t in English, please translate it
      - If giving a location with multiple parts (e.g. "New York, NY"), use the most relevant part (e.g. "New York")
      - Include relevant details like humidity, wind conditions, and precipitation
      - Keep responses concise but informative

      Use the weatherTool to fetch current weather data.
`,
  model: openai("gpt-4o-mini"),
  tools: { weatherTool },
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db", // path is relative to the .mastra/output directory
    }),
  }),
});



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/agents/tool-based-generative-ui.ts
================================================
import { openai } from "@ai-sdk/openai";
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";
import { createTool } from "@mastra/core";
import z from "zod";

export const toolBasedGenerativeUIAgent = new Agent({
  name: "Haiku Agent",
  instructions: `
      You are a helpful haiku assistant that provides the user with a haiku.
`,
  model: openai("gpt-4o-mini"),
  memory: new Memory({
    storage: new LibSQLStore({
      url: "file:../mastra.db", // path is relative to the .mastra/output directory
    }),
  }),
});



================================================
FILE: typescript-sdk/integrations/mastra/example/src/mastra/tools/weather-tool.ts
================================================
import { createTool } from "@mastra/core/tools";
import { z } from "zod";

interface GeocodingResponse {
  results: {
    latitude: number;
    longitude: number;
    name: string;
  }[];
}
interface WeatherResponse {
  current: {
    time: string;
    temperature_2m: number;
    apparent_temperature: number;
    relative_humidity_2m: number;
    wind_speed_10m: number;
    wind_gusts_10m: number;
    weather_code: number;
  };
}

export const weatherTool = createTool({
  id: "get-weather",
  description: "Get current weather for a location",
  inputSchema: z.object({
    location: z.string().describe("City name"),
  }),
  outputSchema: z.object({
    temperature: z.number(),
    feelsLike: z.number(),
    humidity: z.number(),
    windSpeed: z.number(),
    windGust: z.number(),
    conditions: z.string(),
    location: z.string(),
  }),
  execute: async ({ context }) => {
    return await getWeather(context.location);
  },
});

const getWeather = async (location: string) => {
  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;
  const geocodingResponse = await fetch(geocodingUrl);
  const geocodingData = (await geocodingResponse.json()) as GeocodingResponse;

  if (!geocodingData.results?.[0]) {
    throw new Error(`Location '${location}' not found`);
  }

  const { latitude, longitude, name } = geocodingData.results[0];

  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;

  const response = await fetch(weatherUrl);
  const data = (await response.json()) as WeatherResponse;

  return {
    temperature: data.current.temperature_2m,
    feelsLike: data.current.apparent_temperature,
    humidity: data.current.relative_humidity_2m,
    windSpeed: data.current.wind_speed_10m,
    windGust: data.current.wind_gusts_10m,
    conditions: getWeatherCondition(data.current.weather_code),
    location: name,
  };
};

function getWeatherCondition(code: number): string {
  const conditions: Record<number, string> = {
    0: "Clear sky",
    1: "Mainly clear",
    2: "Partly cloudy",
    3: "Overcast",
    45: "Foggy",
    48: "Depositing rime fog",
    51: "Light drizzle",
    53: "Moderate drizzle",
    55: "Dense drizzle",
    56: "Light freezing drizzle",
    57: "Dense freezing drizzle",
    61: "Slight rain",
    63: "Moderate rain",
    65: "Heavy rain",
    66: "Light freezing rain",
    67: "Heavy freezing rain",
    71: "Slight snow fall",
    73: "Moderate snow fall",
    75: "Heavy snow fall",
    77: "Snow grains",
    80: "Slight rain showers",
    81: "Moderate rain showers",
    82: "Violent rain showers",
    85: "Slight snow showers",
    86: "Heavy snow showers",
    95: "Thunderstorm",
    96: "Thunderstorm with slight hail",
    99: "Thunderstorm with heavy hail",
  };
  return conditions[code] || "Unknown";
}



================================================
FILE: typescript-sdk/integrations/mastra/src/copilotkit.ts
================================================
import { AbstractAgent } from "@ag-ui/client";
import {
  CopilotRuntime,
  copilotRuntimeNodeHttpEndpoint,
  CopilotServiceAdapter,
  ExperimentalEmptyAdapter,
} from "@copilotkit/runtime";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { registerApiRoute } from "@mastra/core/server";
import { MastraAgent } from "./mastra";
export function registerCopilotKit<T extends Record<string, any> | unknown = unknown>({
  path,
  resourceId,
  serviceAdapter = new ExperimentalEmptyAdapter(),
  agents,
  setContext,
}: {
  path: string;
  resourceId: string;
  serviceAdapter?: CopilotServiceAdapter;
  agents?: Record<string, AbstractAgent>;
  setContext?: (c: any, runtimeContext: RuntimeContext<T>) => void | Promise<void>;
}) {
  return registerApiRoute(path, {
    method: `ALL`,
    handler: async (c) => {
      const mastra = c.get("mastra");

      const runtimeContext = new RuntimeContext<T>();

      if (setContext) {
        await setContext(c, runtimeContext);
      }

      const aguiAgents =
        agents ||
        MastraAgent.getLocalAgents({
          resourceId,
          mastra,
          runtimeContext,
        });

      const runtime = new CopilotRuntime({
        agents: aguiAgents,
      });

      const handler = copilotRuntimeNodeHttpEndpoint({
        endpoint: path,
        runtime,
        serviceAdapter,
      });

      return handler.handle(c.req.raw, {});
    },
  });
}



================================================
FILE: typescript-sdk/integrations/mastra/src/index.ts
================================================
export * from "./mastra";
export * from "./utils";



================================================
FILE: typescript-sdk/integrations/mastra/src/mastra.ts
================================================
import type {
  AgentConfig,
  BaseEvent,
  RunAgentInput,
  RunFinishedEvent,
  RunStartedEvent,
  StateSnapshotEvent,
  TextMessageChunkEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  ToolCallStartEvent,
} from "@ag-ui/client";
import { AbstractAgent, EventType } from "@ag-ui/client";
import { processDataStream } from "@ai-sdk/ui-utils";
import type { StorageThreadType } from "@mastra/core";
import { Agent as LocalMastraAgent } from "@mastra/core/agent";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { randomUUID } from "crypto";
import { Observable } from "rxjs";
import { MastraClient } from "@mastra/client-js";
type RemoteMastraAgent = ReturnType<MastraClient["getAgent"]>;
import {
  convertAGUIMessagesToMastra,
  GetLocalAgentsOptions,
  getLocalAgents,
  getRemoteAgents,
  GetRemoteAgentsOptions,
  GetLocalAgentOptions,
  getLocalAgent,
  GetNetworkOptions,
  getNetwork,
} from "./utils";

export interface MastraAgentConfig extends AgentConfig {
  agent: LocalMastraAgent | RemoteMastraAgent;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

interface MastraAgentStreamOptions {
  onTextPart?: (text: string) => void;
  onFinishMessagePart?: () => void;
  onToolCallPart?: (streamPart: { toolCallId: string; toolName: string; args: any }) => void;
  onToolResultPart?: (streamPart: { toolCallId: string; result: any }) => void;
  onError?: (error: Error) => void;
  onRunFinished?: () => Promise<void>;
}

export class MastraAgent extends AbstractAgent {
  agent: LocalMastraAgent | RemoteMastraAgent;
  resourceId?: string;
  runtimeContext?: RuntimeContext;

  constructor({ agent, resourceId, runtimeContext, ...rest }: MastraAgentConfig) {
    super(rest);
    this.agent = agent;
    this.resourceId = resourceId;
    this.runtimeContext = runtimeContext ?? new RuntimeContext();
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    let messageId = randomUUID();

    return new Observable<BaseEvent>((subscriber) => {
      const run = async () => {
        const runStartedEvent: RunStartedEvent = {
          type: EventType.RUN_STARTED,
          threadId: input.threadId,
          runId: input.runId,
        };

        subscriber.next(runStartedEvent);

        // Handle local agent memory management (from Mastra implementation)
        if (this.isLocalMastraAgent(this.agent)) {
          const memory = await this.agent.getMemory();

          if (memory && input.state && Object.keys(input.state || {}).length > 0) {
            let thread: StorageThreadType | null = await memory.getThreadById({
              threadId: input.threadId,
            });

            if (!thread) {
              thread = {
                id: input.threadId,
                title: "",
                metadata: {},
                resourceId: this.resourceId ?? input.threadId,
                createdAt: new Date(),
                updatedAt: new Date(),
              };
            }

            const existingMemory = JSON.parse((thread.metadata?.workingMemory as string) ?? "{}");
            const { messages, ...rest } = input.state;
            const workingMemory = JSON.stringify({ ...existingMemory, ...rest });

            // Update thread metadata with new working memory
            await memory.saveThread({
              thread: {
                ...thread,
                metadata: {
                  ...thread.metadata,
                  workingMemory,
                },
              },
            });
          }
        }

        try {
          await this.streamMastraAgent(input, {
            onTextPart: (text) => {
              const event: TextMessageChunkEvent = {
                type: EventType.TEXT_MESSAGE_CHUNK,
                role: "assistant",
                messageId,
                delta: text,
              };
              subscriber.next(event);
            },
            onToolCallPart: (streamPart) => {
              const startEvent: ToolCallStartEvent = {
                type: EventType.TOOL_CALL_START,
                parentMessageId: messageId,
                toolCallId: streamPart.toolCallId,
                toolCallName: streamPart.toolName,
              };
              subscriber.next(startEvent);

              const argsEvent: ToolCallArgsEvent = {
                type: EventType.TOOL_CALL_ARGS,
                toolCallId: streamPart.toolCallId,
                delta: JSON.stringify(streamPart.args),
              };
              subscriber.next(argsEvent);

              const endEvent: ToolCallEndEvent = {
                type: EventType.TOOL_CALL_END,
                toolCallId: streamPart.toolCallId,
              };
              subscriber.next(endEvent);
            },
            onToolResultPart(streamPart) {
              const toolCallResultEvent: ToolCallResultEvent = {
                type: EventType.TOOL_CALL_RESULT,
                toolCallId: streamPart.toolCallId,
                content: JSON.stringify(streamPart.result),
                messageId: randomUUID(),
                role: "tool",
              };

              subscriber.next(toolCallResultEvent);
            },
            onFinishMessagePart: async () => {
              messageId = randomUUID();
            },
            onError: (error) => {
              console.error("error", error);
              // Handle error
              subscriber.error(error);
            },
            onRunFinished: async () => {
              if (this.isLocalMastraAgent(this.agent)) {
                try {
                  const memory = await this.agent.getMemory();
                  if (memory) {
                    const workingMemory = await memory.getWorkingMemory({
                      threadId: input.threadId,
                      memoryConfig: {
                        workingMemory: {
                          enabled: true,
                        },
                      },
                    });

                    if (typeof workingMemory === "string") {
                      const snapshot = JSON.parse(workingMemory);

                      if (snapshot && !("$schema" in snapshot)) {
                        const stateSnapshotEvent: StateSnapshotEvent = {
                          type: EventType.STATE_SNAPSHOT,
                          snapshot,
                        };

                        subscriber.next(stateSnapshotEvent);
                      }
                    }
                  }
                } catch (error) {
                  console.error("Error sending state snapshot", error);
                }
              }

              // Emit run finished event
              subscriber.next({
                type: EventType.RUN_FINISHED,
                threadId: input.threadId,
                runId: input.runId,
              } as RunFinishedEvent);

              // Complete the observable
              subscriber.complete();
            },
          });
        } catch (error) {
          console.error("Stream error:", error);
          subscriber.error(error);
        }
      };

      run();

      return () => {};
    });
  }

  isLocalMastraAgent(agent: LocalMastraAgent | RemoteMastraAgent): agent is LocalMastraAgent {
    return "getMemory" in agent;
  }

  /**
   * Streams in process or remote mastra agent.
   * @param input - The input for the mastra agent.
   * @param options - The options for the mastra agent.
   * @returns The stream of the mastra agent.
   */
  private async streamMastraAgent(
    { threadId, runId, messages, tools, context: inputContext }: RunAgentInput,
    {
      onTextPart,
      onFinishMessagePart,
      onToolCallPart,
      onToolResultPart,
      onError,
      onRunFinished,
    }: MastraAgentStreamOptions,
  ): Promise<void> {
    const clientTools = tools.reduce(
      (acc, tool) => {
        acc[tool.name as string] = {
          id: tool.name,
          description: tool.description,
          inputSchema: tool.parameters,
        };
        return acc;
      },
      {} as Record<string, any>,
    );
    const resourceId = this.resourceId ?? threadId;
    const convertedMessages = convertAGUIMessagesToMastra(messages);
    this.runtimeContext?.set('ag-ui', { context: inputContext });
    const runtimeContext = this.runtimeContext;

    if (this.isLocalMastraAgent(this.agent)) {
      // Local agent - use the agent's stream method directly
      try {
        const response = await this.agent.stream(convertedMessages, {
          threadId,
          resourceId,
          runId,
          clientTools,
          runtimeContext,
        });

        // For local agents, the response should already be a stream
        // Process it using the agent's built-in streaming mechanism
        if (response && typeof response === "object") {
          // If the response has a toDataStreamResponse method, use it
          if (
            "toDataStreamResponse" in response &&
            typeof response.toDataStreamResponse === "function"
          ) {
            const dataStreamResponse = response.toDataStreamResponse();
            if (dataStreamResponse && dataStreamResponse.body) {
              await processDataStream({
                stream: dataStreamResponse.body,
                onTextPart,
                onToolCallPart,
                onToolResultPart,
                onFinishMessagePart,
              });
              await onRunFinished?.();
            } else {
              throw new Error("Invalid data stream response from local agent");
            }
          } else {
            // If it's already a readable stream, process it directly
            await processDataStream({
              stream: response as any,
              onTextPart,
              onToolCallPart,
              onToolResultPart,
              onFinishMessagePart,
            });
            await onRunFinished?.();
          }
        } else {
          throw new Error("Invalid response from local agent");
        }
      } catch (error) {
        onError?.(error as Error);
      }
    } else {
      // Remote agent - use the remote agent's stream method
      try {
        const response = await this.agent.stream({
          threadId,
          resourceId,
          runId,
          messages: convertedMessages,
          clientTools,
        });

        // Remote agents should have a processDataStream method
        if (response && typeof response.processDataStream === "function") {
          await response.processDataStream({
            onTextPart,
            onToolCallPart,
            onToolResultPart,
            onFinishMessagePart,
          });
          await onRunFinished?.();
        } else {
          throw new Error("Invalid response from remote agent");
        }
      } catch (error) {
        onError?.(error as Error);
      }
    }
  }

  static async getRemoteAgents(
    options: GetRemoteAgentsOptions,
  ): Promise<Record<string, AbstractAgent>> {
    return getRemoteAgents(options);
  }

  static getLocalAgents(options: GetLocalAgentsOptions): Record<string, AbstractAgent> {
    return getLocalAgents(options);
  }

  static getLocalAgent(options: GetLocalAgentOptions) {
    return getLocalAgent(options);
  }

  static getNetwork(options: GetNetworkOptions) {
    return getNetwork(options);
  }
}



================================================
FILE: typescript-sdk/integrations/mastra/src/utils.ts
================================================
import type { Message } from "@ag-ui/client";
import { AbstractAgent } from "@ag-ui/client";
import { MastraClient } from "@mastra/client-js";
import type { CoreMessage, Mastra } from "@mastra/core";
import { Agent as LocalMastraAgent } from "@mastra/core/agent";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { MastraAgent } from "./mastra";

export function convertAGUIMessagesToMastra(messages: Message[]): CoreMessage[] {
  const result: CoreMessage[] = [];

  for (const message of messages) {
    if (message.role === "assistant") {
      const parts: any[] = message.content ? [{ type: "text", text: message.content }] : [];
      for (const toolCall of message.toolCalls ?? []) {
        parts.push({
          type: "tool-call",
          toolCallId: toolCall.id,
          toolName: toolCall.function.name,
          args: JSON.parse(toolCall.function.arguments),
        });
      }
      result.push({
        role: "assistant",
        content: parts,
      });
    } else if (message.role === "user") {
      result.push({
        role: "user",
        content: message.content || "",
      });
    } else if (message.role === "tool") {
      let toolName = "unknown";
      for (const msg of messages) {
        if (msg.role === "assistant") {
          for (const toolCall of msg.toolCalls ?? []) {
            if (toolCall.id === message.toolCallId) {
              toolName = toolCall.function.name;
              break;
            }
          }
        }
      }
      result.push({
        role: "tool",
        content: [
          {
            type: "tool-result",
            toolCallId: message.toolCallId,
            toolName: toolName,
            result: message.content,
          },
        ],
      });
    }
  }

  return result;
}

export interface GetRemoteAgentsOptions {
  mastraClient: MastraClient;
  resourceId?: string;
}

export async function getRemoteAgents({
  mastraClient,
  resourceId,
}: GetRemoteAgentsOptions): Promise<Record<string, AbstractAgent>> {
  const agents = await mastraClient.getAgents();

  return Object.entries(agents).reduce(
    (acc, [agentId]) => {
      const agent = mastraClient.getAgent(agentId);

      acc[agentId] = new MastraAgent({
        agentId,
        agent,
        resourceId,
      });

      return acc;
    },
    {} as Record<string, AbstractAgent>,
  );
}

export interface GetLocalAgentsOptions {
  mastra: Mastra;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

export function getLocalAgents({
  mastra,
  resourceId,
  runtimeContext,
}: GetLocalAgentsOptions): Record<string, AbstractAgent> {
  const agents = mastra.getAgents() || {};
  const networks = mastra.getNetworks() || [];

  const networkAGUI = networks.reduce(
    (acc, network) => {
      acc[network.name!] = new MastraAgent({
        agentId: network.name!,
        agent: network as unknown as LocalMastraAgent,
        resourceId,
        runtimeContext,
      });
      return acc;
    },
    {} as Record<string, AbstractAgent>,
  );

  const agentAGUI = Object.entries(agents).reduce(
    (acc, [agentId, agent]) => {
      acc[agentId] = new MastraAgent({
        agentId,
        agent,
        resourceId,
        runtimeContext,
      });
      return acc;
    },
    {} as Record<string, AbstractAgent>,
  );

  return {
    ...agentAGUI,
    ...networkAGUI,
  };
}

export interface GetLocalAgentOptions {
  mastra: Mastra;
  agentId: string;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

export function getLocalAgent({
  mastra,
  agentId,
  resourceId,
  runtimeContext,
}: GetLocalAgentOptions) {
  const agent = mastra.getAgent(agentId);
  if (!agent) {
    throw new Error(`Agent ${agentId} not found`);
  }
  return new MastraAgent({
    agentId,
    agent,
    resourceId,
    runtimeContext,
  }) as AbstractAgent;
}

export interface GetNetworkOptions {
  mastra: Mastra;
  networkId: string;
  resourceId?: string;
  runtimeContext?: RuntimeContext;
}

export function getNetwork({ mastra, networkId, resourceId, runtimeContext }: GetNetworkOptions) {
  const network = mastra.getNetwork(networkId);
  if (!network) {
    throw new Error(`Network ${networkId} not found`);
  }
  return new MastraAgent({
    agentId: network.name!,
    agent: network as unknown as LocalMastraAgent,
    resourceId,
    runtimeContext,
  }) as AbstractAgent;
}



================================================
FILE: typescript-sdk/integrations/middleware-starter/README.md
================================================
# Middleware Starter

This starter kit demonstrates how to set up a middleware server that can be used to proxy events from the agent to the frontend.

## Tutorial

To learn how to set up your own middleware server, please refer to the [tutorial](https://docs.ag-ui.com/quickstart/middleware).



================================================
FILE: typescript-sdk/integrations/middleware-starter/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/middleware-starter/package.json
================================================
{
  "name": "@ag-ui/middleware-starter",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*"
  },
  "peerDependencies": {
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/middleware-starter/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/middleware-starter/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/middleware-starter/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/middleware-starter/src/index.ts
================================================
import { AbstractAgent, BaseEvent, EventType, RunAgentInput } from "@ag-ui/client";
import { Observable } from "rxjs";

export class MiddlewareStarterAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = Date.now().toString();
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as any);

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
      } as any);

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
      } as any);

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
      } as any);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
      } as any);

      observer.complete();
    });
  }
}



================================================
FILE: typescript-sdk/integrations/pydantic-ai/README.md
================================================
# Pydantic AI

Implementation of the AG-UI protocol for [Pydantic AI](https://ai.pydantic.dev/).

For more information on the Pydantic AI implementation see
the [Pydantic AI AG-UI docs](https://ai.pydantic.dev/ag-ui/).

## Prerequisites

This example uses a Pydantic AI agent using an OpenAI model and the AG-UI dojo.

- An [OpenAI API key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)

## Running

To run this integration you need to:

1. Clone the [AG-UI repository](https://github.com/ag-ui-protocol/ag-ui)

    ```shell
    git clone https://github.com/ag-ui-protocol/ag-ui.git
    ```

2. Change into the `typescript-sdk/integrations/pydantic-ai` directory

    ```shell
    cd typescript-sdk/integrations/pydantic-ai
    ```

3. Install the `pydantic-ai-examples` package, for example:

    ```shell
    pip install pydantic-ai-examples
    ```

    or:

    ```shell
    uv venv
    uv pip install pydantic-ai-examples
    ```

4. Run the example dojo server

    ```shell
    export OPENAI_API_KEY=<your api key>
    python -m pydantic_ai_examples.ag_ui
    ```

    or:

    ```shell
    export OPENAI_API_KEY=<your api key>
    uv run python -m pydantic_ai_examples.ag_ui
    ```

5. Open another terminal in root directory of the `ag-ui` repository clone
6. Start the integration ag-ui dojo:

    ```shell
    cd typescript-sdk
    pnpm install && pnpm run dev
    ```

7. Visit [http://localhost:3000/pydantic-ai](http://localhost:3000/pydantic-ai)
8. Select View `Pydantic AI` from the sidebar


## Feature Examples

### Agentic Chat

This demonstrates a basic agent interaction including Pydantic AI server side
tools and AG-UI client side tools.

View the [Agentic Chat example](http://localhost:3000/pydantic-ai/feature/agentic_chat).

#### Agent Tools

- `time` - Pydantic AI tool to check the current time for a time zone
- `background` - AG-UI tool to set the background color of the client window

#### Agent Prompts

```text
What is the time in New York?
```

```text
Change the background to blue
```

A complex example which mixes both AG-UI and Pydantic AI tools:

```text
Perform the following steps, waiting for the response of each step before continuing:
1. Get the time
2. Set the background to red
3. Get the time
4. Report how long the background set took by diffing the two times
```

### Agentic Generative UI

Demonstrates a long running task where the agent sends updates to the frontend
to let the user know what's happening.

View the [Agentic Generative UI example](http://localhost:3000/pydantic-ai/feature/agentic_generative_ui).

#### Plan Prompts

```text
Create a plan for breakfast and execute it
```

### Human in the Loop

Demonstrates simple human in the loop workflow where the agent comes up with a
plan and the user can approve it using checkboxes.

#### Task Planning Tools

- `generate_task_steps` - AG-UI tool to generate and confirm steps

#### Task Planning Prompt

```text
Generate a list of steps for cleaning a car for me to review
```

### Predictive State Updates

Demonstrates how to use the predictive state updates feature to update the state
of the UI based on agent responses, including user interaction via user
confirmation.

View the [Predictive State Updates example](http://localhost:3000/pydantic-ai/feature/predictive_state_updates).

#### Story Tools

- `write_document` - AG-UI tool to write the document to a window
- `document_predict_state` - Pydantic AI tool that enables document state
  prediction for the `write_document` tool

This also shows how to use custom instructions based on shared state information.

#### Story Example

Starting document text

```markdown
Bruce was a good dog,
```

Agent prompt

```text
Help me complete my story about bruce the dog, is should be no longer than a sentence.
```

### Shared State

Demonstrates how to use the shared state between the UI and the agent.

State sent to the agent is detected by a function based instruction. This then
validates the data using a custom pydantic model before using to create the
instructions for the agent to follow and send to the client using a AG-UI tool.

View the [Shared State example](http://localhost:3000/pydantic-ai/feature/shared_state).

#### Recipe Tools

- `display_recipe` - AG-UI tool to display the recipe in a graphical format

#### Recipe Example

1. Customise the basic settings of your recipe
2. Click `Improve with AI`

### Tool Based Generative UI

Demonstrates customised rendering for tool output with used confirmation.

View the [Tool Based Generative UI example](http://localhost:3000/pydantic-ai/feature/tool_based_generative_ui).

#### Haiku Tools

- `generate_haiku` - AG-UI tool to display a haiku in English and Japanese

#### Haiku Prompt

```text
Generate a haiku about formula 1
```



================================================
FILE: typescript-sdk/integrations/pydantic-ai/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/pydantic-ai/package.json
================================================
{
  "name": "@ag-ui/pydantic-ai",
  "author": "Steven Hartland <steve@rocketscience.gg>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/pydantic-ai/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/pydantic-ai/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/pydantic-ai/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/README.md
================================================
# Pydantic AI AG-UI Examples

This directory contains example usage of the AG-UI adapter for Pydantic AI. It provides a FastAPI application that demonstrates how to use the Pydantic AI agent with the AG-UI protocol.

## Features

The examples include implementations for each of the AG-UI dojo features:
- Agentic Chat
- Human in the Loop
- Agentic Generative UI
- Tool Based Generative UI
- Shared State
- Predictive State Updates

## Setup

1. Install dependencies:
   ```bash
   uv sync
   ```

2. Run the development server:
   ```bash
   uv run dev
   ```

## Usage

Once the server is running, launch the frontend dojo with:

```bash
cd ../../../
pnpm install
turbo run dev
```

and view it at http://localhost:3000.

By default, the agents can be reached at:

- `http://localhost:9000/agentic_chat` - Agentic Chat
- `http://localhost:9000/agentic_generative_ui` - Agentic Generative UI
- `http://localhost:9000/human_in_the_loop` - Human in the Loop
- `http://localhost:9000/predictive_state_updates` - Predictive State Updates
- `http://localhost:9000/shared_state` - Shared State
- `http://localhost:9000/tool_based_generative_ui` - Tool Based Generative UI



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/pyproject.toml
================================================
tool.uv.package = true

[project]
name = "server"
version = "0.1.0"
description = "Example usage of the AG-UI adapter for Pydantic AI"
license = "MIT"

readme = "README.md"
requires-python = ">=3.9"
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "pydantic-ai-slim[openai,ag-ui]>=0.1.0",
]
authors = []

[project.scripts]
dev = "server:main"




================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/__init__.py
================================================
"""Example usage of the AG-UI adapter for Pydantic AI.

This provides a FastAPI application that demonstrates how to use the
Pydantic AI agent with the AG-UI protocol. It includes examples for
each of the AG-UI dojo features:
- Agentic Chat
- Human in the Loop
- Agentic Generative UI
- Tool Based Generative UI
- Shared State
- Predictive State Updates
"""

from __future__ import annotations

from fastapi import FastAPI
import uvicorn
import os


from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

app = FastAPI(title='Pydantic AI AG-UI server')
app.mount('/agentic_chat', agentic_chat_app, 'Agentic Chat')
app.mount('/agentic_generative_ui', agentic_generative_ui_app, 'Agentic Generative UI')
app.mount('/human_in_the_loop', human_in_the_loop_app, 'Human in the Loop')
app.mount(
    '/predictive_state_updates',
    predictive_state_updates_app,
    'Predictive State Updates',
)
app.mount('/shared_state', shared_state_app, 'Shared State')
app.mount(
    '/tool_based_generative_ui',
    tool_based_generative_ui_app,
    'Tool Based Generative UI',
)


def main():
    """Main function to start the FastAPI server."""
    port = int(os.getenv("PORT", "9000"))
    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    main()

__all__ = ["main"]



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/__init__.py
================================================
"""Example API for a AG-UI compatible Pydantic AI Agent UI."""

from __future__ import annotations

from .agentic_chat import app as agentic_chat_app
from .agentic_generative_ui import app as agentic_generative_ui_app
from .human_in_the_loop import app as human_in_the_loop_app
from .predictive_state_updates import app as predictive_state_updates_app
from .shared_state import app as shared_state_app
from .tool_based_generative_ui import app as tool_based_generative_ui_app

__all__ = [
    'agentic_chat_app',
    'agentic_generative_ui_app',
    'human_in_the_loop_app',
    'predictive_state_updates_app',
    'shared_state_app',
    'tool_based_generative_ui_app',
]



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/agentic_chat.py
================================================
"""Agentic Chat feature."""

from __future__ import annotations

from datetime import datetime
from zoneinfo import ZoneInfo

from pydantic_ai import Agent

agent = Agent('openai:gpt-4o-mini')
app = agent.to_ag_ui()


@agent.tool_plain
async def current_time(timezone: str = 'UTC') -> str:
    """Get the current time in ISO format.

    Args:
        timezone: The timezone to use.

    Returns:
        The current time in ISO format string.
    """
    tz: ZoneInfo = ZoneInfo(timezone)
    return datetime.now(tz=tz).isoformat()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/agentic_generative_ui.py
================================================
"""Agentic Generative UI feature."""

from __future__ import annotations

from textwrap import dedent
from typing import Any, Literal

from pydantic import BaseModel, Field

from ag_ui.core import EventType, StateDeltaEvent, StateSnapshotEvent
from pydantic_ai import Agent

StepStatus = Literal['pending', 'completed']


class Step(BaseModel):
    """Represents a step in a plan."""

    description: str = Field(description='The description of the step')
    status: StepStatus = Field(
        default='pending',
        description='The status of the step (e.g., pending, completed)',
    )


class Plan(BaseModel):
    """Represents a plan with multiple steps."""

    steps: list[Step] = Field(default_factory=list, description='The steps in the plan')


class JSONPatchOp(BaseModel):
    """A class representing a JSON Patch operation (RFC 6902)."""

    op: Literal['add', 'remove', 'replace', 'move', 'copy', 'test'] = Field(
        description='The operation to perform: add, remove, replace, move, copy, or test',
    )
    path: str = Field(description='JSON Pointer (RFC 6901) to the target location')
    value: Any = Field(
        default=None,
        description='The value to apply (for add, replace operations)',
    )
    from_: str | None = Field(
        default=None,
        alias='from',
        description='Source path (for move, copy operations)',
    )


agent = Agent(
    'openai:gpt-4o-mini',
    instructions=dedent(
        """
        When planning use tools only, without any other messages.
        IMPORTANT:
        - Use the `create_plan` tool to set the initial state of the steps
        - Use the `update_plan_step` tool to update the status of each step
        - Do NOT repeat the plan or summarise it in a message
        - Do NOT confirm the creation or updates in a message
        - Do NOT ask the user for additional information or next steps
        - Do NOT leave a plan hanging, always complete the plan via `update_plan_step` if one is ongoing.

        Only one plan can be active at a time, so do not call the `create_plan` tool
        again until all the steps in current plan are completed.
        """
    ),
)


@agent.tool_plain
async def create_plan(steps: list[str]) -> StateSnapshotEvent:
    """Create a plan with multiple steps.

    Args:
        steps: List of step descriptions to create the plan.

    Returns:
        StateSnapshotEvent containing the initial state of the steps.
    """
    plan: Plan = Plan(
        steps=[Step(description=step) for step in steps],
    )
    return StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=plan.model_dump(),
    )


@agent.tool_plain
async def update_plan_step(
    index: int, description: str | None = None, status: StepStatus | None = None
) -> StateDeltaEvent:
    """Update the plan with new steps or changes.

    Args:
        index: The index of the step to update.
        description: The new description for the step.
        status: The new status for the step.

    Returns:
        StateDeltaEvent containing the changes made to the plan.
    """
    changes: list[JSONPatchOp] = []
    if description is not None:
        changes.append(
            JSONPatchOp(
                op='replace', path=f'/steps/{index}/description', value=description
            )
        )
    if status is not None:
        changes.append(
            JSONPatchOp(op='replace', path=f'/steps/{index}/status', value=status)
        )
    return StateDeltaEvent(
        type=EventType.STATE_DELTA,
        delta=changes,
    )


app = agent.to_ag_ui()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/human_in_the_loop.py
================================================
"""Human in the Loop Feature.

No special handling is required for this feature.
"""

from __future__ import annotations

from textwrap import dedent

from pydantic_ai import Agent

agent = Agent(
    'openai:gpt-4o-mini',
    instructions=dedent(
        """
        When planning tasks use tools only, without any other messages.
        IMPORTANT:
        - Use the `generate_task_steps` tool to display the suggested steps to the user
        - Do not call the `generate_task_steps` twice in a row, ever.
        - Never repeat the plan, or send a message detailing steps
        - If accepted, confirm the creation of the plan and the number of selected (enabled) steps only
        - If not accepted, ask the user for more information, DO NOT use the `generate_task_steps` tool again
        """
    ),
)

app = agent.to_ag_ui()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/predictive_state_updates.py
================================================
"""Predictive State feature."""

from __future__ import annotations

from textwrap import dedent

from pydantic import BaseModel

from ag_ui.core import CustomEvent, EventType
from pydantic_ai import Agent, RunContext
from pydantic_ai.ag_ui import StateDeps


class DocumentState(BaseModel):
    """State for the document being written."""

    document: str = ''


agent = Agent('openai:gpt-4o-mini', deps_type=StateDeps[DocumentState])


# Tools which return AG-UI events will be sent to the client as part of the
# event stream, single events and iterables of events are supported.
@agent.tool_plain
async def document_predict_state() -> list[CustomEvent]:
    """Enable document state prediction.

    Returns:
        CustomEvent containing the event to enable state prediction.
    """
    return [
        CustomEvent(
            type=EventType.CUSTOM,
            name='PredictState',
            value=[
                {
                    'state_key': 'document',
                    'tool': 'write_document',
                    'tool_argument': 'document',
                },
            ],
        ),
    ]


@agent.instructions()
async def story_instructions(ctx: RunContext[StateDeps[DocumentState]]) -> str:
    """Provide instructions for writing document if present.

    Args:
        ctx: The run context containing document state information.

    Returns:
        Instructions string for the document writing agent.
    """
    return dedent(
        f"""You are a helpful assistant for writing documents.

        Before you start writing, you MUST call the `document_predict_state`
        tool to enable state prediction.

        To present the document to the user for review, you MUST use the
        `write_document` tool.

        When you have written the document, DO NOT repeat it as a message.
        If accepted briefly summarize the changes you made, 2 sentences
        max, otherwise ask the user to clarify what they want to change.

        This is the current document:

        {ctx.deps.state.document}
        """
    )


app = agent.to_ag_ui(deps=StateDeps(DocumentState()))



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/shared_state.py
================================================
"""Shared State feature."""

from __future__ import annotations

from enum import StrEnum
from textwrap import dedent

from pydantic import BaseModel, Field

from ag_ui.core import EventType, StateSnapshotEvent
from pydantic_ai import Agent, RunContext
from pydantic_ai.ag_ui import StateDeps


class SkillLevel(StrEnum):
    """The level of skill required for the recipe."""

    BEGINNER = 'Beginner'
    INTERMEDIATE = 'Intermediate'
    ADVANCED = 'Advanced'


class SpecialPreferences(StrEnum):
    """Special preferences for the recipe."""

    HIGH_PROTEIN = 'High Protein'
    LOW_CARB = 'Low Carb'
    SPICY = 'Spicy'
    BUDGET_FRIENDLY = 'Budget-Friendly'
    ONE_POT_MEAL = 'One-Pot Meal'
    VEGETARIAN = 'Vegetarian'
    VEGAN = 'Vegan'


class CookingTime(StrEnum):
    """The cooking time of the recipe."""

    FIVE_MIN = '5 min'
    FIFTEEN_MIN = '15 min'
    THIRTY_MIN = '30 min'
    FORTY_FIVE_MIN = '45 min'
    SIXTY_PLUS_MIN = '60+ min'


class Ingredient(BaseModel):
    """A class representing an ingredient in a recipe."""

    icon: str = Field(
        default='ingredient',
        description="The icon emoji (not emoji code like '\x1f35e', but the actual emoji like 🥕) of the ingredient",
    )
    name: str
    amount: str


class Recipe(BaseModel):
    """A class representing a recipe."""

    skill_level: SkillLevel = Field(
        default=SkillLevel.BEGINNER,
        description='The skill level required for the recipe',
    )
    special_preferences: list[SpecialPreferences] = Field(
        default_factory=list,
        description='Any special preferences for the recipe',
    )
    cooking_time: CookingTime = Field(
        default=CookingTime.FIVE_MIN, description='The cooking time of the recipe'
    )
    ingredients: list[Ingredient] = Field(
        default_factory=list,
        description='Ingredients for the recipe',
    )
    instructions: list[str] = Field(
        default_factory=list, description='Instructions for the recipe'
    )


class RecipeSnapshot(BaseModel):
    """A class representing the state of the recipe."""

    recipe: Recipe = Field(
        default_factory=Recipe, description='The current state of the recipe'
    )


agent = Agent('openai:gpt-4o-mini', deps_type=StateDeps[RecipeSnapshot])


@agent.tool_plain
async def display_recipe(recipe: Recipe) -> StateSnapshotEvent:
    """Display the recipe to the user.

    Args:
        recipe: The recipe to display.

    Returns:
        StateSnapshotEvent containing the recipe snapshot.
    """
    return StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot={'recipe': recipe},
    )


@agent.instructions
async def recipe_instructions(ctx: RunContext[StateDeps[RecipeSnapshot]]) -> str:
    """Instructions for the recipe generation agent.

    Args:
        ctx: The run context containing recipe state information.

    Returns:
        Instructions string for the recipe generation agent.
    """
    return dedent(
        f"""
        You are a helpful assistant for creating recipes.

        IMPORTANT:
        - Create a complete recipe using the existing ingredients
        - Append new ingredients to the existing ones
        - Use the `display_recipe` tool to present the recipe to the user
        - Do NOT repeat the recipe in the message, use the tool instead
        - Do NOT run the `display_recipe` tool multiple times in a row

        Once you have created the updated recipe and displayed it to the user,
        summarise the changes in one sentence, don't describe the recipe in
        detail or send it as a message to the user.

        The current state of the recipe is:

        {ctx.deps.state.recipe.model_dump_json(indent=2)}
        """,
    )


app = agent.to_ag_ui(deps=StateDeps(RecipeSnapshot()))



================================================
FILE: typescript-sdk/integrations/pydantic-ai/examples/server/api/tool_based_generative_ui.py
================================================
"""Tool Based Generative UI feature.

No special handling is required for this feature.
"""

from __future__ import annotations

from pydantic_ai import Agent

agent = Agent('openai:gpt-4o-mini')
app = agent.to_ag_ui()



================================================
FILE: typescript-sdk/integrations/pydantic-ai/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class PydanticAIAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/server-starter/README.md
================================================
# Server Starter

This starter kit demonstrates sending the minimal set of events that are needed to stream data from the agent to the frontend.

## Running the server

To run the server:

```bash
cd typescript-sdk/integrations/server-starter/server/python

poetry install && poetry run dev
```



================================================
FILE: typescript-sdk/integrations/server-starter/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/server-starter/package.json
================================================
{
  "name": "@ag-ui/server-starter",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*"
  },
  "peerDependencies": {
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/server-starter/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/server-starter/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/server-starter/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
server



================================================
FILE: typescript-sdk/integrations/server-starter/server/python/README.md
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter/server/python/pyproject.toml
================================================
[tool.poetry]
name = "example_server"
version = "0.1.0"
description = ""
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
ag-ui-protocol = "^0.1.5"
fastapi = "^0.115.12"
uvicorn = "^0.34.3"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "example_server:main"


================================================
FILE: typescript-sdk/integrations/server-starter/server/python/example_server/__init__.py
================================================
"""
Example server for the AG-UI protocol.
"""

import os
import uvicorn
import uuid
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
)
from ag_ui.encoder import EventEncoder

app = FastAPI(title="AG-UI Endpoint")

@app.post("/")
async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic chat endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():

        # Send run started event
        yield encoder.encode(
          RunStartedEvent(
            type=EventType.RUN_STARTED,
            thread_id=input_data.thread_id,
            run_id=input_data.run_id
          ),
        )

        message_id = str(uuid.uuid4())

        yield encoder.encode(
            TextMessageStartEvent(
                type=EventType.TEXT_MESSAGE_START,
                message_id=message_id,
                role="assistant"
            )
        )

        yield encoder.encode(
            TextMessageContentEvent(
                type=EventType.TEXT_MESSAGE_CONTENT,
                message_id=message_id,
                delta="Hello world!"
            )
        )

        yield encoder.encode(
            TextMessageEndEvent(
                type=EventType.TEXT_MESSAGE_END,
                message_id=message_id
            )
        )

        # Send run finished event
        yield encoder.encode(
          RunFinishedEvent(
            type=EventType.RUN_FINISHED,
            thread_id=input_data.thread_id,
            run_id=input_data.run_id
          ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )

def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "example_server:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/server-starter/server/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class ServerStarterAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/README.md
================================================
# Server Starter (All Features)

This is a starter kit for demonstrating each feature of AG-UI by sending static events to the frontend.

## Running the server

To run the server:

```bash
cd typescript-sdk/integrations/server-starter-all-features/server/python

poetry install && poetry run dev
```

## Integrations

- **Agentic Chat**:

Demonstrates chatting with an agent and frontend tool calling. (send it a literal "tool" as a chat message to trigger the tool call)

Source: ➡️ [example_server/agentic_chat.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_chat.py)

- **Human in the Loop**:

A simple human in the loop workflow where the agent comes up with a plan and the user can approve it using checkboxes.

Source: ➡️ [example_server/human_in_the_loop.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/human_in_the_loop.py)

- **Agentic Generative UI**:

Simulates a long running task where the agent sends updates to the frontend to let the user know what's happening.

Source: ➡️ [example_server/agentic_generative_ui.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_generative_ui.py)

- **Tool Based Generative UI**:

Simulates a server tool call that is rendered in the frontend.

Source: ➡️ [example_server/tool_based_generative_ui.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/tool_based_generative_ui.py)

- **Shared State**:

Demonstrates how to use the shared state between the user and the agent.

Source: ➡️ [example_server/shared_state.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/shared_state.py)

- **Predictive State Updates**:

Demonstrates how to use the predictive state updates feature to update the state of the agent based on the user's input.

Source: ➡️ [example_server/predictive_state_updates.py](https://github.com/ag-ui-protocol/ag-ui/blob/main/typescript-sdk/integrations/server-starter-all-features/server/python/example_server/predictive_state_updates.py)



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/package.json
================================================
{
  "name": "@ag-ui/server-starter-all-features",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.1",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/client": "workspace:*"
  },
  "peerDependencies": {
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js
server



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/README.md
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/pyproject.toml
================================================
[tool.poetry]
name = "example_server"
version = "0.1.0"
description = ""
authors = ["Markus Ecker <markus.ecker@gmail.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
ag-ui-protocol = {path = "../../../../../python-sdk/"}
fastapi = "^0.115.12"
uvicorn = "^0.34.3"
jsonpatch = "^1.33"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.scripts]
dev = "example_server:main"


================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/__init__.py
================================================
"""
Example server for the AG-UI protocol.
"""

import os
import uvicorn
from fastapi import FastAPI
from .agentic_chat import agentic_chat_endpoint
from .human_in_the_loop import human_in_the_loop_endpoint
from .agentic_generative_ui import agentic_generative_ui_endpoint
from .tool_based_generative_ui import tool_based_generative_ui_endpoint
from .shared_state import shared_state_endpoint
from .predictive_state_updates import predictive_state_updates_endpoint

app = FastAPI(title="AG-UI Endpoint")

# Register the agentic chat endpoint
app.post("/agentic_chat")(agentic_chat_endpoint)

# Register the human in the loop endpoint
app.post("/human_in_the_loop")(human_in_the_loop_endpoint)

# Register the agentic generative UI endpoint
app.post("/agentic_generative_ui")(agentic_generative_ui_endpoint)

# Register the tool-based generative UI endpoint
app.post("/tool_based_generative_ui")(tool_based_generative_ui_endpoint)

# Register the shared state endpoint
app.post("/shared_state")(shared_state_endpoint)

# Register the predictive state updates endpoint
app.post("/predictive_state_updates")(predictive_state_updates_endpoint)


def main():
    """Run the uvicorn server."""
    port = int(os.getenv("PORT", "8000"))
    uvicorn.run(
        "example_server:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_chat.py
================================================
"""
Agentic chat endpoint for the AG-UI protocol.
"""

import uuid
import asyncio
import json
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    MessagesSnapshotEvent,
    ToolMessage,
    ToolCall,
    AssistantMessage
)
from ag_ui.core.events import TextMessageChunkEvent
from ag_ui.encoder import EventEncoder

async def agentic_chat_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic chat endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Get the last message content for conditional logic
        last_message_content = None
        last_message_role = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]
            last_message_content = last_message.content
            last_message_role = getattr(last_message, 'role', None)

        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Conditional logic based on last message
        if last_message_role == "tool":
            async for event in send_tool_result_message_events():
                yield encoder.encode(event)
        elif last_message_content == "tool":
            async for event in send_tool_call_events():
                yield encoder.encode(event)
        elif last_message_content == "backend_tool":
            async for event in send_backend_tool_call_events(input_data.messages):
                yield encoder.encode(event)
        else:
            async for event in send_text_message_events():
                yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_text_message_events():
    """Send text message events with countdown"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Initial content chunk
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="counting down: "
    )

    # Countdown from 10 to 1
    for count in range(10, 0, -1):
        yield TextMessageContentEvent(
            type=EventType.TEXT_MESSAGE_CONTENT,
            message_id=message_id,
            delta=f"{count}  "
        )
        # Sleep for 300ms
        await asyncio.sleep(0.3)

    # Final checkmark
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="✓"
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )


async def send_tool_result_message_events():
    """Send message for tool result"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Content
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="background changed ✓"
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )


async def send_tool_call_events():
    """Send tool call events"""
    tool_call_id = str(uuid.uuid4())
    tool_call_name = "change_background"
    tool_call_args = {
        "background": "linear-gradient(135deg, #667eea 0%, #764ba2 100%)"
    }

    # Tool call start
    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id,
        tool_call_name=tool_call_name
    )

    # Tool call args
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta=json.dumps(tool_call_args)
    )

    # Tool call end
    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id
    )

async def send_backend_tool_call_events(messages):
    """Send backend tool call events"""
    tool_call_id = str(uuid.uuid4())

    new_message = AssistantMessage(
        id=str(uuid.uuid4()),
        role="assistant",
        tool_calls=[
            ToolCall(
                id=tool_call_id,
                type="function",
                function={
                    "name": "lookup_weather",
                    "arguments": json.dumps({"city": "San Francisco", "weather": "sunny"})
                }
            )
        ]
    )

    result_message = ToolMessage(
        id=str(uuid.uuid4()),
        role="tool",
        content="The weather in San Francisco is sunny.",
        tool_call_id=tool_call_id
    )

    all_messages = list(messages) + [new_message, result_message]

    # Send messages snapshot event
    yield MessagesSnapshotEvent(
        type=EventType.MESSAGES_SNAPSHOT,
        messages=all_messages
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/agentic_generative_ui.py
================================================
"""
Agentic generative UI endpoint for the AG-UI protocol.
"""

import asyncio
import copy
import jsonpatch
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    StateSnapshotEvent,
    StateDeltaEvent
)
from ag_ui.encoder import EventEncoder

async def agentic_generative_ui_endpoint(input_data: RunAgentInput, request: Request):
    """Agentic generative UI endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Send state events
        async for event in send_state_events():
            yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_state_events():
    """Send state events with snapshots and deltas"""
    # Initialize state
    state = {
        "steps": [
            {
                "description": f"Step {i + 1}",
                "status": "pending"
            }
            for i in range(10)
        ]
    }

    # Send initial state snapshot
    yield StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=state
    )
    
    # Sleep for 1 second
    await asyncio.sleep(1.0)

    # Create a copy to track changes for JSON patches
    previous_state = copy.deepcopy(state)

    # Update each step and send deltas
    for i, step in enumerate(state["steps"]):
        step["status"] = "completed"
        
        # Generate JSON patch from previous state to current state
        patch = jsonpatch.make_patch(previous_state, state)
        
        # Send state delta event
        yield StateDeltaEvent(
            type=EventType.STATE_DELTA,
            delta=patch.patch
        )
        
        # Update previous state for next iteration
        previous_state = copy.deepcopy(state)
        
        # Sleep for 1 second
        await asyncio.sleep(1.0)

    # Optionally send a final snapshot to the client
    yield StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=state
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/human_in_the_loop.py
================================================
"""
Human in the loop endpoint for the AG-UI protocol.
"""

import uuid
import asyncio
import json
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent
)
from ag_ui.encoder import EventEncoder

async def human_in_the_loop_endpoint(input_data: RunAgentInput, request: Request):
    """Human in the loop endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Get the last message for conditional logic
        last_message = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]

        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Conditional logic based on last message role
        if last_message and getattr(last_message, 'role', None) == "tool":
            async for event in send_text_message_events():
                yield encoder.encode(event)
        else:
            async for event in send_tool_call_events():
                yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_tool_call_events():
    """Send tool call events that generate task steps incrementally"""
    tool_call_id = str(uuid.uuid4())
    tool_call_name = "generate_task_steps"

    # Tool call start
    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id,
        tool_call_name=tool_call_name
    )

    # Start building JSON - opening structure
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta='{"steps":['
    )

    # Generate 10 steps incrementally
    for i in range(10):
        step_data = {
            "description": f"Step {i + 1}",
            "status": "enabled"
        }
        
        # Add comma separator except for the last item
        delta = json.dumps(step_data) + ("," if i != 9 else "")
        
        yield ToolCallArgsEvent(
            type=EventType.TOOL_CALL_ARGS,
            tool_call_id=tool_call_id,
            delta=delta
        )
        
        # Sleep for 200ms
        await asyncio.sleep(0.2)

    # Close JSON structure
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta="]}"
    )

    # Tool call end
    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id
    )


async def send_text_message_events():
    """Send text message events with simple response"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Content
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="Ok! I'm working on it."
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/predictive_state_updates.py
================================================
"""
Predictive state updates endpoint for the AG-UI protocol.
"""

import uuid
import asyncio
import random
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    TextMessageStartEvent,
    TextMessageContentEvent,
    TextMessageEndEvent,
    ToolCallStartEvent,
    ToolCallArgsEvent,
    ToolCallEndEvent,
    CustomEvent
)
from ag_ui.encoder import EventEncoder

async def predictive_state_updates_endpoint(input_data: RunAgentInput, request: Request):
    """Predictive state updates endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Get the last message for conditional logic
        last_message = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]

        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Conditional logic based on last message role
        if last_message and getattr(last_message, 'role', None) == "tool":
            async for event in send_text_message_events():
                yield encoder.encode(event)
        else:
            async for event in send_tool_call_events():
                yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


def make_story(name: str) -> str:
    """Generate a simple dog story"""
    return f"Once upon a time, there was a dog named {name}. {name} was a very good dog."


# List of dog names for random selection
dog_names = ["Rex", "Buddy", "Max", "Charlie", "Buddy", "Max", "Charlie"]


async def send_tool_call_events():
    """Send tool call events with predictive state and incremental story generation"""
    tool_call_id = str(uuid.uuid4())
    tool_call_name = "write_document_local"

    # Generate a random story
    story = make_story(random.choice(dog_names))
    story_chunks = story.split(" ")

    # Send custom predict state event first
    yield CustomEvent(
        type=EventType.CUSTOM,
        name="PredictState",
        value=[
            {
                "state_key": "document",
                "tool": "write_document_local",
                "tool_argument": "document"
            }
        ]
    )

    # First tool call: write_document_local
    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id,
        tool_call_name=tool_call_name
    )

    # Start JSON arguments
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta='{"document":"'
    )

    # Send story chunks incrementally
    for chunk in story_chunks:
        yield ToolCallArgsEvent(
            type=EventType.TOOL_CALL_ARGS,
            tool_call_id=tool_call_id,
            delta=chunk + " "
        )
        await asyncio.sleep(0.2)  # 200ms delay

    # Close JSON arguments
    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id,
        delta='"}'
    )

    # End first tool call
    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id
    )

    # Second tool call: confirm_changes
    tool_call_id_2 = str(uuid.uuid4())
    tool_call_name_2 = "confirm_changes"

    yield ToolCallStartEvent(
        type=EventType.TOOL_CALL_START,
        tool_call_id=tool_call_id_2,
        tool_call_name=tool_call_name_2
    )

    yield ToolCallArgsEvent(
        type=EventType.TOOL_CALL_ARGS,
        tool_call_id=tool_call_id_2,
        delta="{}"
    )

    yield ToolCallEndEvent(
        type=EventType.TOOL_CALL_END,
        tool_call_id=tool_call_id_2
    )


async def send_text_message_events():
    """Send simple text message events"""
    message_id = str(uuid.uuid4())

    # Start of message
    yield TextMessageStartEvent(
        type=EventType.TEXT_MESSAGE_START,
        message_id=message_id,
        role="assistant"
    )

    # Content
    yield TextMessageContentEvent(
        type=EventType.TEXT_MESSAGE_CONTENT,
        message_id=message_id,
        delta="Ok!"
    )

    # End of message
    yield TextMessageEndEvent(
        type=EventType.TEXT_MESSAGE_END,
        message_id=message_id
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/shared_state.py
================================================
"""
Shared state endpoint for the AG-UI protocol.
"""

from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    StateSnapshotEvent
)
from ag_ui.encoder import EventEncoder

async def shared_state_endpoint(input_data: RunAgentInput, request: Request):
    """Shared state endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Send state events
        async for event in send_state_events():
            yield encoder.encode(event)

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )


async def send_state_events():
    """Send state events with recipe data"""
    # Define the recipe state
    state = {
        "recipe": {
            "skill_level": "Advanced",
            "special_preferences": ["Low Carb", "Spicy"],
            "cooking_time": "15 min",
            "ingredients": [
                {
                    "icon": "🍗",
                    "name": "chicken breast",
                    "amount": "1",
                },
                {
                    "icon": "🌶️",
                    "name": "chili powder",
                    "amount": "1 tsp",
                },
                {
                    "icon": "🧂",
                    "name": "Salt",
                    "amount": "a pinch",
                },
                {
                    "icon": "🥬",
                    "name": "Lettuce leaves",
                    "amount": "handful",
                },
            ],
            "instructions": [
                "Season chicken with chili powder and salt.",
                "Sear until fully cooked.",
                "Slice and wrap in lettuce.",
            ]
        }
    }

    # Send state snapshot event
    yield StateSnapshotEvent(
        type=EventType.STATE_SNAPSHOT,
        snapshot=state
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/example_server/tool_based_generative_ui.py
================================================
"""
Tool-based generative UI endpoint for the AG-UI protocol.
"""

import uuid
import json
from fastapi import Request
from fastapi.responses import StreamingResponse
from ag_ui.core import (
    RunAgentInput,
    EventType,
    RunStartedEvent,
    RunFinishedEvent,
    MessagesSnapshotEvent
)
from ag_ui.encoder import EventEncoder

async def tool_based_generative_ui_endpoint(input_data: RunAgentInput, request: Request):
    """Tool-based generative UI endpoint"""
    # Get the accept header from the request
    accept_header = request.headers.get("accept")

    # Create an event encoder to properly format SSE events
    encoder = EventEncoder(accept=accept_header)

    async def event_generator():
        # Send run started event
        yield encoder.encode(
            RunStartedEvent(
                type=EventType.RUN_STARTED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

        # Check if last message was a tool result
        last_message = None
        if input_data.messages and len(input_data.messages) > 0:
            last_message = input_data.messages[-1]

        result_message = None

        # Determine what type of message to send
        if last_message and getattr(last_message, 'content', None) == "thanks":
            # Send text message for tool result
            message_id = str(uuid.uuid4())
            new_message = {
                "id": message_id,
                "role": "assistant",
                "content": "Haiku created"
            }
        else:
            # Send tool call message
            tool_call_id = str(uuid.uuid4())
            message_id = str(uuid.uuid4())

            # Prepare haiku arguments
            haiku_args = {
                "japanese": ["エーアイの", "橋つなぐ道", "コパキット"],
                "english": [
                    "From AI's realm",
                    "A bridge-road linking us—",
                    "CopilotKit."
                ]
            }

            # Create new assistant message with tool call
            new_message = {
                "id": message_id,
                "role": "assistant",
                "tool_calls": [
                    {
                        "id": tool_call_id,
                        "type": "function",
                        "function": {
                            "name": "generate_haiku",
                            "arguments": json.dumps(haiku_args)
                        }
                    }
                ]
            }

            result_message = {
                "id": str(uuid.uuid4()),
                "role": "tool",
                "tool_call_id": tool_call_id,
                "content": "Haiku created"
            }

        # Create messages list with input messages plus the new message
        all_messages = list(input_data.messages) + [new_message]

        if result_message:
            all_messages.append(result_message)

        # Send messages snapshot event
        yield encoder.encode(
            MessagesSnapshotEvent(
                type=EventType.MESSAGES_SNAPSHOT,
                messages=all_messages
            ),
        )

        # Send run finished event
        yield encoder.encode(
            RunFinishedEvent(
                type=EventType.RUN_FINISHED,
                thread_id=input_data.thread_id,
                run_id=input_data.run_id
            ),
        )

    return StreamingResponse(
        event_generator(),
        media_type=encoder.get_content_type()
    )



================================================
FILE: typescript-sdk/integrations/server-starter-all-features/server/python/tests/__init__.py
================================================
[Empty file]


================================================
FILE: typescript-sdk/integrations/server-starter-all-features/src/index.ts
================================================
import { HttpAgent } from "@ag-ui/client";

export class ServerStarterAllFeaturesAgent extends HttpAgent {}



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/README.md
================================================
# @ag-ui/vercel-ai-sdk

Implementation of the AG-UI protocol for Vercel AI SDK.

Connects Vercel AI SDK models and tools to frontend applications via the AG-UI protocol. Provides native TypeScript integration with streamText, tool execution, and multi-step workflows.

## Installation

```bash
npm install @ag-ui/vercel-ai-sdk
pnpm add @ag-ui/vercel-ai-sdk
yarn add @ag-ui/vercel-ai-sdk
```

## Usage

```ts
import { VercelAISDKAgent } from "@ag-ui/vercel-ai-sdk";
import { openai } from "ai/openai";

// Create an AG-UI compatible agent
const agent = new VercelAISDKAgent({
  model: openai("gpt-4"),
  maxSteps: 3,
  toolChoice: "auto",
});

// Run with streaming
const result = await agent.runAgent({
  messages: [{ role: "user", content: "Help me with a task" }],
});
```

## Features

- **Native TypeScript** – Direct integration with Vercel AI SDK models
- **Streaming support** – Real-time text and tool call streaming
- **Multi-step workflows** – Automatic tool execution chains
- **Model flexibility** – Works with OpenAI, Anthropic, and other providers

## To run the example server in the dojo

```bash
# Use directly in TypeScript applications
# No separate server needed
```



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/package.json
================================================
{
  "name": "@ag-ui/vercel-ai-sdk",
  "version": "0.0.2",
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "peerDependencies": {
    "@ag-ui/core": ">=0.0.37",
    "@ag-ui/client": ">=0.0.37",
    "rxjs": "7.8.1"
  },
  "devDependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/client": "workspace:*",
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  },
  "dependencies": {
    "ai": "^4.3.16",
    "zod": "^3.22.4"
  }
}



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/integrations/vercel-ai-sdk/src/index.ts
================================================
import {
  AgentConfig,
  AbstractAgent,
  EventType,
  BaseEvent,
  Message,
  AssistantMessage,
  RunAgentInput,
  MessagesSnapshotEvent,
  RunFinishedEvent,
  RunStartedEvent,
  TextMessageChunkEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallStartEvent,
  ToolCall,
  ToolMessage,
} from "@ag-ui/client";
import { Observable } from "rxjs";
import {
  CoreMessage,
  LanguageModelV1,
  processDataStream,
  streamText,
  tool as createVercelAISDKTool,
  ToolChoice,
  ToolSet,
} from "ai";
import { randomUUID } from "crypto";
import { z } from "zod";

type ProcessedEvent =
  | MessagesSnapshotEvent
  | RunFinishedEvent
  | RunStartedEvent
  | TextMessageChunkEvent
  | ToolCallArgsEvent
  | ToolCallEndEvent
  | ToolCallStartEvent;

interface VercelAISDKAgentConfig extends AgentConfig {
  model: LanguageModelV1;
  maxSteps?: number;
  toolChoice?: ToolChoice<Record<string, unknown>>;
}

export class VercelAISDKAgent extends AbstractAgent {
  model: LanguageModelV1;
  maxSteps: number;
  toolChoice: ToolChoice<Record<string, unknown>>;
  constructor({ model, maxSteps, toolChoice, ...rest }: VercelAISDKAgentConfig) {
    super({ ...rest });
    this.model = model;
    this.maxSteps = maxSteps ?? 1;
    this.toolChoice = toolChoice ?? "auto";
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const finalMessages: Message[] = input.messages;

    return new Observable<ProcessedEvent>((subscriber) => {
      subscriber.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
      } as RunStartedEvent);

      const response = streamText({
        model: this.model,
        messages: convertMessagesToVercelAISDKMessages(input.messages),
        tools: convertToolToVerlAISDKTools(input.tools),
        maxSteps: this.maxSteps,
        toolChoice: this.toolChoice,
      });

      let messageId = randomUUID();
      let assistantMessage: AssistantMessage = {
        id: messageId,
        role: "assistant",
        content: "",
        toolCalls: [],
      };
      finalMessages.push(assistantMessage);

      processDataStream({
        stream: response.toDataStreamResponse().body!,
        onTextPart: (text) => {
          assistantMessage.content += text;
          const event: TextMessageChunkEvent = {
            type: EventType.TEXT_MESSAGE_CHUNK,
            role: "assistant",
            messageId,
            delta: text,
          };
          subscriber.next(event);
        },
        onFinishMessagePart: () => {
          // Emit message snapshot
          const event: MessagesSnapshotEvent = {
            type: EventType.MESSAGES_SNAPSHOT,
            messages: finalMessages,
          };
          subscriber.next(event);

          // Emit run finished event
          subscriber.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
          } as RunFinishedEvent);

          // Complete the observable
          subscriber.complete();
        },
        onToolCallPart(streamPart) {
          let toolCall: ToolCall = {
            id: streamPart.toolCallId,
            type: "function",
            function: {
              name: streamPart.toolName,
              arguments: JSON.stringify(streamPart.args),
            },
          };
          assistantMessage.toolCalls!.push(toolCall);

          const startEvent: ToolCallStartEvent = {
            type: EventType.TOOL_CALL_START,
            parentMessageId: messageId,
            toolCallId: streamPart.toolCallId,
            toolCallName: streamPart.toolName,
          };
          subscriber.next(startEvent);

          const argsEvent: ToolCallArgsEvent = {
            type: EventType.TOOL_CALL_ARGS,
            toolCallId: streamPart.toolCallId,
            delta: JSON.stringify(streamPart.args),
          };
          subscriber.next(argsEvent);

          const endEvent: ToolCallEndEvent = {
            type: EventType.TOOL_CALL_END,
            toolCallId: streamPart.toolCallId,
          };
          subscriber.next(endEvent);
        },
        onToolResultPart(streamPart) {
          const toolMessage: ToolMessage = {
            role: "tool",
            id: randomUUID(),
            toolCallId: streamPart.toolCallId,
            content: JSON.stringify(streamPart.result),
          };
          finalMessages.push(toolMessage);
        },
        onErrorPart(streamPart) {
          subscriber.error(streamPart);
        },
      }).catch((error) => {
        console.error("catch error", error);
        // Handle error
        subscriber.error(error);
      });

      return () => {};
    });
  }
}

export function convertMessagesToVercelAISDKMessages(messages: Message[]): CoreMessage[] {
  const result: CoreMessage[] = [];

  for (const message of messages) {
    if (message.role === "assistant") {
      const parts: any[] = message.content ? [{ type: "text", text: message.content }] : [];
      for (const toolCall of message.toolCalls ?? []) {
        parts.push({
          type: "tool-call",
          toolCallId: toolCall.id,
          toolName: toolCall.function.name,
          args: JSON.parse(toolCall.function.arguments),
        });
      }
      result.push({
        role: "assistant",
        content: parts,
      });
    } else if (message.role === "user") {
      result.push({
        role: "user",
        content: message.content || "",
      });
    } else if (message.role === "tool") {
      let toolName = "unknown";
      for (const msg of messages) {
        if (msg.role === "assistant") {
          for (const toolCall of msg.toolCalls ?? []) {
            if (toolCall.id === message.toolCallId) {
              toolName = toolCall.function.name;
              break;
            }
          }
        }
      }
      result.push({
        role: "tool",
        content: [
          {
            type: "tool-result",
            toolCallId: message.toolCallId,
            toolName: toolName,
            result: message.content,
          },
        ],
      });
    }
  }

  return result;
}

export function convertJsonSchemaToZodSchema(jsonSchema: any, required: boolean): z.ZodSchema {
  if (jsonSchema.type === "object") {
    const spec: { [key: string]: z.ZodSchema } = {};

    if (!jsonSchema.properties || !Object.keys(jsonSchema.properties).length) {
      return !required ? z.object(spec).optional() : z.object(spec);
    }

    for (const [key, value] of Object.entries(jsonSchema.properties)) {
      spec[key] = convertJsonSchemaToZodSchema(
        value,
        jsonSchema.required ? jsonSchema.required.includes(key) : false,
      );
    }
    let schema = z.object(spec).describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "string") {
    let schema = z.string().describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "number") {
    let schema = z.number().describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "boolean") {
    let schema = z.boolean().describe(jsonSchema.description);
    return required ? schema : schema.optional();
  } else if (jsonSchema.type === "array") {
    let itemSchema = convertJsonSchemaToZodSchema(jsonSchema.items, true);
    let schema = z.array(itemSchema).describe(jsonSchema.description);
    return required ? schema : schema.optional();
  }
  throw new Error("Invalid JSON schema");
}

export function convertToolToVerlAISDKTools(tools: RunAgentInput["tools"]): ToolSet {
  return tools.reduce(
    (acc: ToolSet, tool: RunAgentInput["tools"][number]) => ({
      ...acc,
      [tool.name]: createVercelAISDKTool({
        description: tool.description,
        parameters: convertJsonSchemaToZodSchema(tool.parameters, true),
      }),
    }),
    {},
  );
}



================================================
FILE: typescript-sdk/packages/cli/README.md
================================================
# create-ag-ui-app

CLI tool for scaffolding **Agent-User Interaction (AG-UI) Protocol** applications.

`create-ag-ui-app` provides an interactive setup wizard to quickly bootstrap AG-UI projects with your preferred client framework and agent backend. 

Choose from CopilotKit/Next.js for web apps or CLI clients for terminal-based interactions.

## Usage

```bash
npx create-ag-ui-app@latest
pnpx create-ag-ui-app@latest
bunx create-ag-ui-app@latest
```

## Features

- 🎯 **Interactive setup** – Guided prompts for client and framework selection
- 🌐 **Multiple clients** – CopilotKit/Next.js web apps and CLI clients
- 🔧 **Framework integration** – Built-in support for LangGraph, CrewAI, Mastra, Agno, LlamaIndex, and more
- 📦 **Zero config** – Automatically sets up dependencies and project structure
- ⚡ **Quick start** – Get from idea to running app in minutes

## Quick example

```bash
# Interactive setup
npx create-ag-ui-app@latest

# With framework flags
npx create-ag-ui-app@latest --langgraph-py
npx create-ag-ui-app@latest --mastra

# See all options
npx create-ag-ui-app@latest --help
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/events`](https://docs.ag-ui.com/concepts/events)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://github.com/ag-ui-protocol/ag-ui/blob/main/CONTRIBUTING.md) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/cli/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/packages/cli/package.json
================================================
{
  "name": "create-ag-ui-app",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.39",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "bin": "./dist/index.mjs",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@types/inquirer": "^9.0.8",
    "commander": "^12.1.0",
    "inquirer": "^12.6.3",
    "giget": "2.0.0"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/packages/cli/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/cli/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: true,
  minify: true,
});



================================================
FILE: typescript-sdk/packages/cli/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/cli/src/index.ts
================================================
#!/usr/bin/env node
import { Command } from "commander";
import inquirer from "inquirer";
import { spawn } from "child_process";
import fs from "fs";
import path from "path";
import { downloadTemplate } from "giget";

const program = new Command();

// Dark purple color
const PURPLE = "\x1b[35m";
const RESET = "\x1b[0m";

function displayBanner() {
  const banner = `
${PURPLE}   █████╗  ██████╗       ██╗   ██╗ ██╗
  ██╔══██╗██╔════╝       ██║   ██║ ██║
  ███████║██║  ███╗█████╗██║   ██║ ██║
  ██╔══██║██║   ██║╚════╝██║   ██║ ██║
  ██║  ██║╚██████╔╝      ╚██████╔╝ ██║
  ╚═╝  ╚═╝ ╚═════╝        ╚═════╝  ╚═╝
${RESET}
  Agent User Interactivity Protocol
`;
  console.log(banner);
}

const description = `
Quickly scaffold AG-UI enabled applications for your favorite agent frameworks.
`

async function createProject() {
  displayBanner();

  console.log("\n~ Let's get started building an AG-UI powered user interactive agent ~");
  console.log("  Read more about AG-UI at https://ag-ui.com\n");

  const options = program.opts();
  const isFrameworkDefined = [
    "langgraphPy",
    "langgraphJs",
    "crewaiFlows",
    "mastra",
    "ag2",
    "llamaindex",
    "pydanticAi",
    "agno"
  ].some(flag => options[flag]);

  if (isFrameworkDefined) {
    await handleCopilotKitNextJs();
    return;
  } else {
    console.log("");
    console.log("To build an AG-UI app, you need to select a client.");
    console.log("");
  }

  const answers = await inquirer.prompt([
    {
      type: "list",
      name: "client",
      message: "What client do you want to use?",
      choices: [
        "CopilotKit/Next.js",
        "CLI client",
        new inquirer.Separator(" Other clients coming soon (SMS, Whatsapp, Slack ...)"),
      ],
    },
  ]);

  switch (answers.client) {
    case "CopilotKit/Next.js":
      await handleCopilotKitNextJs();
      break;
    case "CLI client":
      await handleCliClient();
      break;
    default:
      break;
  }
}

async function handleCopilotKitNextJs() {
  const options = program.opts();
  const frameworkArgs: string[] = [];

  const projectName = await inquirer.prompt([
    {
      type: "input",
      name: "name",
      message: "What would you like to name your project?",
      default: "my-ag-ui-app",
      validate: (input) => {
        if (!input.trim()) {
          return "Project name cannot be empty";
        }
        if (!/^[a-zA-Z0-9-_]+$/.test(input)) {
          return "Project name can only contain letters, numbers, hyphens, and underscores";
        }
        return true;
      },
    },
  ]);

  // Translate options to CopilotKit framework flags
  if (options.langgraphPy) {
    frameworkArgs.push("-f", "langgraph-py");
  } else if (options.langgraphJs) {
    frameworkArgs.push("-f", "langgraph-js");
  } else if (options.crewiAiFlows) {
    frameworkArgs.push("-f", "flows");
  } else if (options.mastra) {
    frameworkArgs.push("-f", "mastra");
  } else if (options.ag2) {
    frameworkArgs.push("-f", "ag2");
  } else if (options.llamaindex) {
    frameworkArgs.push("-f", "llamaindex");
  } else if (options.agno) {
    frameworkArgs.push("-f", "agno");
  } else if (options.pydanticAi) {
    frameworkArgs.push("-f", "pydantic-ai");
  }

  const copilotkit = spawn("npx", 
    [
      "copilotkit@latest",
      "create",
      "--no-banner",
      "-n", projectName.name,
      ...frameworkArgs,
    ],
    {
      stdio: "inherit",
      shell: true,
    },
  );

  copilotkit.on("close", (code) => {
    if (code !== 0) {
      console.log("\n❌ Project creation failed.");
    }
  });
}

async function handleCliClient() {
  console.log("🔧 Setting up CLI client...\n");

  // Get current package versions from the monorepo
  console.log("🔍 Reading current package versions...");
  const versions = await getCurrentPackageVersions();
  console.log(`📋 Found versions: ${Object.keys(versions).length} packages`);
  Object.entries(versions).forEach(([name, version]) => {
    console.log(`  - ${name}: ${version}`);
  });
  console.log("");

  const projectName = await inquirer.prompt([
    {
      type: "input",
      name: "name",
      message: "What would you like to name your CLI project?",
      default: "my-ag-ui-cli-app",
      validate: (input) => {
        if (!input.trim()) {
          return "Project name cannot be empty";
        }
        if (!/^[a-zA-Z0-9-_]+$/.test(input)) {
          return "Project name can only contain letters, numbers, hyphens, and underscores";
        }
        return true;
      },
    },
  ]);

  try {
    console.log(`📥 Downloading CLI client template: ${projectName.name}\n`);

    await downloadTemplate("gh:ag-ui-protocol/ag-ui/typescript-sdk/apps/client-cli-example", {
      dir: projectName.name,
      install: false,
    });

    console.log("✅ CLI client template downloaded successfully!");

    // Update workspace dependencies with actual versions
    console.log("\n🔄 Updating workspace dependencies...");
    await updateWorkspaceDependencies(projectName.name, versions);

    console.log(`\n📁 Project created in: ${projectName.name}`);
    console.log("\n🚀 Next steps:");
    console.log("   export OPENAI_API_KEY='your-openai-api-key'");
    console.log(`   cd ${projectName.name}`);
    console.log("   npm install");
    console.log("   npm run dev");
    console.log("\n💡 Check the README.md for more information on how to use your CLI client!");
  } catch (error) {
    console.log("❌ Failed to download CLI client template:", error);
    process.exit(1);
  }
}

// Metadata
program
  .name("create-ag-ui-app")
  .description(description)
  .version("0.0.36");

// Add framework flags
program
  .option("--langgraph-py", "Use the LangGraph framework with Python")
  .option("--langgraph-js", "Use the LangGraph framework with JavaScript")
  .option("--crewai-flows", "Use the CrewAI framework with Flows")
  .option("--mastra", "Use the Mastra framework")
  .option("--pydantic-ai", "Use the Pydantic AI framework")
  .option("--llamaindex", "Use the LlamaIndex framework")
  .option("--agno", "Use the Agno framework")
  .option("--ag2", "Use the AG2 framework")

program.action(async () => {
  await createProject();
});

program.parse();

// Utility functions

// Helper function to get package versions from npmjs
async function getCurrentPackageVersions(): Promise<{ [key: string]: string }> {
  const packages = ["@ag-ui/client", "@ag-ui/core", "@ag-ui/mastra"];
  const versions: { [key: string]: string } = {};

  for (const packageName of packages) {
    try {
      // Fetch package info from npm registry
      const response = await fetch(`https://registry.npmjs.org/${packageName}`);
      if (response.ok) {
        const packageInfo = await response.json();
        versions[packageName] = packageInfo["dist-tags"]?.latest || "latest";
        console.log(`  ✓ ${packageName}: ${versions[packageName]}`);
      } else {
        console.log(`  ⚠️  Could not fetch version for ${packageName}`);
        // Fallback to latest
        versions[packageName] = "latest";
      }
    } catch (error) {
      console.log(`  ⚠️  Error fetching ${packageName}: ${error}`);
      // Fallback to latest
      versions[packageName] = "latest";
    }
  }

  return versions;
}

// Function to update workspace dependencies in downloaded project
async function updateWorkspaceDependencies(
  projectPath: string,
  versions: { [key: string]: string },
) {
  const packageJsonPath = path.join(projectPath, "package.json");

  try {
    if (!fs.existsSync(packageJsonPath)) {
      console.log("⚠️  No package.json found in downloaded project");
      return;
    }

    const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, "utf-8"));
    let updated = false;

    // Update workspace dependencies with actual versions
    if (packageJson.dependencies) {
      for (const [depName, depVersion] of Object.entries(packageJson.dependencies)) {
        if (
          typeof depVersion === "string" &&
          depVersion.startsWith("workspace:") &&
          versions[depName]
        ) {
          packageJson.dependencies[depName] = `^${versions[depName]}`;
          updated = true;
          console.log(`  📦 Updated ${depName}: workspace:* → ^${versions[depName]}`);
        }
      }
    }

    if (updated) {
      fs.writeFileSync(packageJsonPath, JSON.stringify(packageJson, null, 2) + "\n");
      console.log("✅ Package.json updated with actual package versions!");
    } else {
      console.log("📄 No workspace dependencies found to update");
    }
  } catch (error) {
    console.log(`❌ Error updating package.json: ${error}`);
  }
}



================================================
FILE: typescript-sdk/packages/client/README.md
================================================
# @ag-ui/client

Client SDK for connecting to **Agent-User Interaction (AG-UI) Protocol** servers.

`@ag-ui/client` provides agent implementations that handle the full lifecycle of AG-UI communication: connecting to servers, processing streaming events, managing state mutations, and providing reactive subscriber hooks.

## Installation

```bash
npm install @ag-ui/client
pnpm add @ag-ui/client
yarn add @ag-ui/client
```

## Features

- 🔗 **HTTP connectivity** – `HttpAgent` for direct server connections with SSE/protobuf support
- 🏗️ **Custom agents** – `AbstractAgent` base class for building your own transport layer
- 📡 **Event streaming** – Full AG-UI event processing with validation and transformation
- 🔄 **State management** – Automatic message/state tracking with reactive updates
- 🪝 **Subscriber system** – Middleware-style hooks for logging, persistence, and custom logic

## Quick example

```ts
import { HttpAgent } from "@ag-ui/client";

const agent = new HttpAgent({
  url: "https://api.example.com/agent",
  headers: { Authorization: "Bearer token" },
});

const result = await agent.runAgent({
  messages: [{ role: "user", content: "Hello!" }],
});

console.log(result.newMessages);
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/client`](https://docs.ag-ui.com/sdk/js/client/overview)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/client/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
  moduleNameMapper: {
    "^@/(.*)$": "<rootDir>/src/$1",
  },
};



================================================
FILE: typescript-sdk/packages/client/package.json
================================================
{
  "name": "@ag-ui/client",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.39",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "files": [
    "dist/**",
    "README.md"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "clean": "rm -rf dist .turbo node_modules",
    "typecheck": "tsc --noEmit",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/proto": "workspace:*",
    "@ag-ui/encoder": "workspace:*",
    "@types/uuid": "^10.0.0",
    "fast-json-patch": "^3.1.1",
    "rxjs": "7.8.1",
    "untruncate-json": "^0.0.1",
    "uuid": "^11.1.0",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^20.11.19",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.3.3"
  }
}



================================================
FILE: typescript-sdk/packages/client/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "stripInternal": true
  },
  "include": ["src", "../core/src/subscriber.ts"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/client/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
  minify: !options.watch, // Don't minify in watch mode for faster builds
}));



================================================
FILE: typescript-sdk/packages/client/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/client/src/index.ts
================================================
export * from "./apply";
export * from "./verify";
export * from "./transform";
export * from "./run";
export * from "./legacy";
export * from "./agent";
export * from "@ag-ui/core";



================================================
FILE: typescript-sdk/packages/client/src/utils.ts
================================================
export const structuredClone_ = <T>(obj: T): T => {
  if (typeof structuredClone === "function") {
    return structuredClone(obj);
  }

  try {
    return JSON.parse(JSON.stringify(obj));
  } catch (err) {
    return { ...obj } as T;
  }
};



================================================
FILE: typescript-sdk/packages/client/src/agent/agent.ts
================================================
import { defaultApplyEvents } from "@/apply/default";
import { Message, State, RunAgentInput, BaseEvent, ToolCall, AssistantMessage } from "@ag-ui/core";

import { AgentConfig, RunAgentParameters } from "./types";
import { v4 as uuidv4 } from "uuid";
import { structuredClone_ } from "@/utils";
import { catchError, map, tap } from "rxjs/operators";
import { finalize } from "rxjs/operators";
import { pipe, Observable, from, of } from "rxjs";
import { verifyEvents } from "@/verify";
import { convertToLegacyEvents } from "@/legacy/convert";
import { LegacyRuntimeProtocolEvent } from "@/legacy/types";
import { lastValueFrom } from "rxjs";
import { transformChunks } from "@/chunks";
import { AgentStateMutation, AgentSubscriber, runSubscribersWithMutation } from "./subscriber";

export interface RunAgentResult {
  result: any;
  newMessages: Message[];
}

export abstract class AbstractAgent {
  public agentId?: string;
  public description: string;
  public threadId: string;
  public messages: Message[];
  public state: State;
  public debug: boolean = false;
  public subscribers: AgentSubscriber[] = [];

  constructor({
    agentId,
    description,
    threadId,
    initialMessages,
    initialState,
    debug,
  }: AgentConfig = {}) {
    this.agentId = agentId;
    this.description = description ?? "";
    this.threadId = threadId ?? uuidv4();
    this.messages = structuredClone_(initialMessages ?? []);
    this.state = structuredClone_(initialState ?? {});
    this.debug = debug ?? false;
  }

  public subscribe(subscriber: AgentSubscriber) {
    this.subscribers.push(subscriber);
    return {
      unsubscribe: () => {
        this.subscribers = this.subscribers.filter((s) => s !== subscriber);
      },
    };
  }

  protected abstract run(input: RunAgentInput): Observable<BaseEvent>;

  public async runAgent(
    parameters?: RunAgentParameters,
    subscriber?: AgentSubscriber,
  ): Promise<RunAgentResult> {
    this.agentId = this.agentId ?? uuidv4();
    const input = this.prepareRunAgentInput(parameters);
    let result: any = undefined;
    const currentMessageIds = new Set(this.messages.map((message) => message.id));

    const subscribers: AgentSubscriber[] = [
      {
        onRunFinishedEvent: (params) => {
          result = params.result;
        },
      },
      ...this.subscribers,
      subscriber ?? {},
    ];

    await this.onInitialize(input, subscribers);

    const pipeline = pipe(
      () => this.run(input),
      transformChunks(this.debug),
      verifyEvents(this.debug),
      (source$) => this.apply(input, source$, subscribers),
      (source$) => this.processApplyEvents(input, source$, subscribers),
      catchError((error) => {
        return this.onError(input, error, subscribers);
      }),
      finalize(() => {
        void this.onFinalize(input, subscribers);
      }),
    );

    return lastValueFrom(pipeline(of(null))).then(() => {
      const newMessages = structuredClone_(this.messages).filter(
        (message: Message) => !currentMessageIds.has(message.id),
      );
      return { result, newMessages };
    });
  }

  public abortRun() {}

  protected apply(
    input: RunAgentInput,
    events$: Observable<BaseEvent>,
    subscribers: AgentSubscriber[],
  ): Observable<AgentStateMutation> {
    return defaultApplyEvents(input, events$, this, subscribers);
  }

  protected processApplyEvents(
    input: RunAgentInput,
    events$: Observable<AgentStateMutation>,
    subscribers: AgentSubscriber[],
  ): Observable<AgentStateMutation> {
    return events$.pipe(
      tap((event) => {
        if (event.messages) {
          this.messages = event.messages;
          subscribers.forEach((subscriber) => {
            subscriber.onMessagesChanged?.({
              messages: this.messages,
              state: this.state,
              agent: this,
              input,
            });
          });
        }
        if (event.state) {
          this.state = event.state;
          subscribers.forEach((subscriber) => {
            subscriber.onStateChanged?.({
              state: this.state,
              messages: this.messages,
              agent: this,
              input,
            });
          });
        }
      }),
    );
  }

  protected prepareRunAgentInput(parameters?: RunAgentParameters): RunAgentInput {
    return {
      threadId: this.threadId,
      runId: parameters?.runId || uuidv4(),
      tools: structuredClone_(parameters?.tools ?? []),
      context: structuredClone_(parameters?.context ?? []),
      forwardedProps: structuredClone_(parameters?.forwardedProps ?? {}),
      state: structuredClone_(this.state),
      messages: structuredClone_(this.messages),
    };
  }

  protected async onInitialize(input: RunAgentInput, subscribers: AgentSubscriber[]) {
    const onRunInitializedMutation = await runSubscribersWithMutation(
      subscribers,
      this.messages,
      this.state,
      (subscriber, messages, state) =>
        subscriber.onRunInitialized?.({ messages, state, agent: this, input }),
    );
    if (
      onRunInitializedMutation.messages !== undefined ||
      onRunInitializedMutation.state !== undefined
    ) {
      if (onRunInitializedMutation.messages) {
        this.messages = onRunInitializedMutation.messages;
        input.messages = onRunInitializedMutation.messages;
        subscribers.forEach((subscriber) => {
          subscriber.onMessagesChanged?.({
            messages: this.messages,
            state: this.state,
            agent: this,
            input,
          });
        });
      }
      if (onRunInitializedMutation.state) {
        this.state = onRunInitializedMutation.state;
        input.state = onRunInitializedMutation.state;
        subscribers.forEach((subscriber) => {
          subscriber.onStateChanged?.({
            state: this.state,
            messages: this.messages,
            agent: this,
            input,
          });
        });
      }
    }
  }

  protected onError(input: RunAgentInput, error: Error, subscribers: AgentSubscriber[]) {
    return from(
      runSubscribersWithMutation(
        subscribers,
        this.messages,
        this.state,
        (subscriber, messages, state) =>
          subscriber.onRunFailed?.({ error, messages, state, agent: this, input }),
      ),
    ).pipe(
      map((onRunFailedMutation) => {
        const mutation = onRunFailedMutation as AgentStateMutation;
        if (mutation.messages !== undefined || mutation.state !== undefined) {
          if (mutation.messages !== undefined) {
            this.messages = mutation.messages;
            subscribers.forEach((subscriber) => {
              subscriber.onMessagesChanged?.({
                messages: this.messages,
                state: this.state,
                agent: this,
                input,
              });
            });
          }
          if (mutation.state !== undefined) {
            this.state = mutation.state;
            subscribers.forEach((subscriber) => {
              subscriber.onStateChanged?.({
                state: this.state,
                messages: this.messages,
                agent: this,
                input,
              });
            });
          }
        }

        if (mutation.stopPropagation !== true) {
          console.error("Agent execution failed:", error);
          throw error;
        }

        // Return an empty mutation instead of null to prevent EmptyError
        return {} as AgentStateMutation;
      }),
    );
  }

  protected async onFinalize(input: RunAgentInput, subscribers: AgentSubscriber[]) {
    const onRunFinalizedMutation = await runSubscribersWithMutation(
      subscribers,
      this.messages,
      this.state,
      (subscriber, messages, state) =>
        subscriber.onRunFinalized?.({ messages, state, agent: this, input }),
    );

    if (
      onRunFinalizedMutation.messages !== undefined ||
      onRunFinalizedMutation.state !== undefined
    ) {
      if (onRunFinalizedMutation.messages !== undefined) {
        this.messages = onRunFinalizedMutation.messages;
        subscribers.forEach((subscriber) => {
          subscriber.onMessagesChanged?.({
            messages: this.messages,
            state: this.state,
            agent: this,
            input,
          });
        });
      }
      if (onRunFinalizedMutation.state !== undefined) {
        this.state = onRunFinalizedMutation.state;
        subscribers.forEach((subscriber) => {
          subscriber.onStateChanged?.({
            state: this.state,
            messages: this.messages,
            agent: this,
            input,
          });
        });
      }
    }
  }

  public clone() {
    const cloned = Object.create(Object.getPrototypeOf(this));

    for (const key of Object.getOwnPropertyNames(this)) {
      const value = (this as any)[key];
      if (typeof value !== "function") {
        cloned[key] = structuredClone_(value);
      }
    }

    return cloned;
  }

  public addMessage(message: Message) {
    // Add message to the messages array
    this.messages.push(message);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onNewMessage sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onNewMessage?.({
          message,
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }

      // Fire onNewToolCall if the message is from assistant and contains tool calls
      if (message.role === "assistant" && message.toolCalls) {
        for (const toolCall of message.toolCalls) {
          for (const subscriber of this.subscribers) {
            await subscriber.onNewToolCall?.({
              toolCall,
              messages: this.messages,
              state: this.state,
              agent: this,
            });
          }
        }
      }

      // Fire onMessagesChanged sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onMessagesChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public addMessages(messages: Message[]) {
    // Add all messages to the messages array
    this.messages.push(...messages);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onNewMessage and onNewToolCall for each message sequentially
      for (const message of messages) {
        // Fire onNewMessage sequentially
        for (const subscriber of this.subscribers) {
          await subscriber.onNewMessage?.({
            message,
            messages: this.messages,
            state: this.state,
            agent: this,
          });
        }

        // Fire onNewToolCall if the message is from assistant and contains tool calls
        if (message.role === "assistant" && message.toolCalls) {
          for (const toolCall of message.toolCalls) {
            for (const subscriber of this.subscribers) {
              await subscriber.onNewToolCall?.({
                toolCall,
                messages: this.messages,
                state: this.state,
                agent: this,
              });
            }
          }
        }
      }

      // Fire onMessagesChanged once at the end sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onMessagesChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public setMessages(messages: Message[]) {
    // Replace the entire messages array
    this.messages = structuredClone_(messages);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onMessagesChanged sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onMessagesChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public setState(state: State) {
    // Replace the entire state
    this.state = structuredClone_(state);

    // Notify subscribers sequentially in the background
    (async () => {
      // Fire onStateChanged sequentially
      for (const subscriber of this.subscribers) {
        await subscriber.onStateChanged?.({
          messages: this.messages,
          state: this.state,
          agent: this,
        });
      }
    })();
  }

  public legacy_to_be_removed_runAgentBridged(
    config?: RunAgentParameters,
  ): Observable<LegacyRuntimeProtocolEvent> {
    this.agentId = this.agentId ?? uuidv4();
    const input = this.prepareRunAgentInput(config);

    return this.run(input).pipe(
      transformChunks(this.debug),
      verifyEvents(this.debug),
      convertToLegacyEvents(this.threadId, input.runId, this.agentId),
      (events$: Observable<LegacyRuntimeProtocolEvent>) => {
        return events$.pipe(
          map((event) => {
            if (this.debug) {
              console.debug("[LEGACY]:", JSON.stringify(event));
            }
            return event;
          }),
        );
      },
    );
  }
}



================================================
FILE: typescript-sdk/packages/client/src/agent/http.ts
================================================
import { AbstractAgent, RunAgentResult } from "./agent";
import { runHttpRequest } from "@/run/http-request";
import { HttpAgentConfig, RunAgentParameters } from "./types";
import { RunAgentInput, BaseEvent } from "@ag-ui/core";
import { structuredClone_ } from "@/utils";
import { transformHttpEventStream } from "@/transform/http";
import { Observable } from "rxjs";
import { AgentSubscriber } from "./subscriber";

interface RunHttpAgentConfig extends RunAgentParameters {
  abortController?: AbortController;
}

export class HttpAgent extends AbstractAgent {
  public url: string;
  public headers: Record<string, string>;
  public abortController: AbortController = new AbortController();

  /**
   * Returns the fetch config for the http request.
   * Override this to customize the request.
   *
   * @returns The fetch config for the http request.
   */
  protected requestInit(input: RunAgentInput): RequestInit {
    return {
      method: "POST",
      headers: {
        ...this.headers,
        "Content-Type": "application/json",
        Accept: "text/event-stream",
      },
      body: JSON.stringify(input),
      signal: this.abortController.signal,
    };
  }

  public runAgent(
    parameters?: RunHttpAgentConfig,
    subscriber?: AgentSubscriber,
  ): Promise<RunAgentResult> {
    this.abortController = parameters?.abortController ?? new AbortController();
    return super.runAgent(parameters, subscriber);
  }

  abortRun() {
    this.abortController.abort();
    super.abortRun();
  }

  constructor(config: HttpAgentConfig) {
    super(config);
    this.url = config.url;
    this.headers = structuredClone_(config.headers ?? {});
  }

  run(input: RunAgentInput): Observable<BaseEvent> {
    const httpEvents = runHttpRequest(this.url, this.requestInit(input));
    return transformHttpEventStream(httpEvents);
  }
}



================================================
FILE: typescript-sdk/packages/client/src/agent/index.ts
================================================
export { AbstractAgent } from "./agent";
export type { RunAgentResult } from "./agent";
export { HttpAgent } from "./http";
export type { AgentConfig, HttpAgentConfig, RunAgentParameters } from "./types";
export type { AgentSubscriber, AgentStateMutation, AgentSubscriberParams} from "./subscriber";


================================================
FILE: typescript-sdk/packages/client/src/agent/subscriber.ts
================================================
import {
  BaseEvent,
  Message,
  RunAgentInput,
  RunErrorEvent,
  RunFinishedEvent,
  RunStartedEvent,
  State,
  StateDeltaEvent,
  StateSnapshotEvent,
  StepFinishedEvent,
  StepStartedEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  TextMessageStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  ToolCallStartEvent,
  MessagesSnapshotEvent,
  RawEvent,
  CustomEvent,
  ToolCall,
} from "@ag-ui/core";
import { AbstractAgent } from "./agent";
import { structuredClone_ } from "@/utils";

export interface AgentStateMutation {
  messages?: Message[];
  state?: State;
  stopPropagation?: boolean;
}

export interface AgentSubscriberParams {
  messages: Message[];
  state: State;
  agent: AbstractAgent;
  input: RunAgentInput;
}

// Utility type to allow callbacks to be implemented either synchronously or asynchronously.
export type MaybePromise<T> = T | Promise<T>;

export interface AgentSubscriber {
  // Request lifecycle
  onRunInitialized?(
    params: AgentSubscriberParams,
  ): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>;
  onRunFailed?(
    params: { error: Error } & AgentSubscriberParams,
  ): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>;
  onRunFinalized?(
    params: AgentSubscriberParams,
  ): MaybePromise<Omit<AgentStateMutation, "stopPropagation"> | void>;

  // Events
  onEvent?(
    params: { event: BaseEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onRunStartedEvent?(
    params: { event: RunStartedEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onRunFinishedEvent?(
    params: { event: RunFinishedEvent; result?: any } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onRunErrorEvent?(
    params: { event: RunErrorEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onStepStartedEvent?(
    params: { event: StepStartedEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onStepFinishedEvent?(
    params: { event: StepFinishedEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onTextMessageStartEvent?(
    params: { event: TextMessageStartEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onTextMessageContentEvent?(
    params: {
      event: TextMessageContentEvent;
      textMessageBuffer: string;
    } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onTextMessageEndEvent?(
    params: { event: TextMessageEndEvent; textMessageBuffer: string } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onToolCallStartEvent?(
    params: { event: ToolCallStartEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onToolCallArgsEvent?(
    params: {
      event: ToolCallArgsEvent;
      toolCallBuffer: string;
      toolCallName: string;
      partialToolCallArgs: Record<string, any>;
    } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;
  onToolCallEndEvent?(
    params: {
      event: ToolCallEndEvent;
      toolCallName: string;
      toolCallArgs: Record<string, any>;
    } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onToolCallResultEvent?(
    params: { event: ToolCallResultEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onStateSnapshotEvent?(
    params: { event: StateSnapshotEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onStateDeltaEvent?(
    params: { event: StateDeltaEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onMessagesSnapshotEvent?(
    params: { event: MessagesSnapshotEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onRawEvent?(
    params: { event: RawEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  onCustomEvent?(
    params: { event: CustomEvent } & AgentSubscriberParams,
  ): MaybePromise<AgentStateMutation | void>;

  // State changes
  onMessagesChanged?(
    params: Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput },
  ): MaybePromise<void>;
  onStateChanged?(
    params: Omit<AgentSubscriberParams, "input"> & { input?: RunAgentInput },
  ): MaybePromise<void>;
  onNewMessage?(
    params: { message: Message } & Omit<AgentSubscriberParams, "input"> & {
        input?: RunAgentInput;
      },
  ): MaybePromise<void>;
  onNewToolCall?(
    params: { toolCall: ToolCall } & Omit<AgentSubscriberParams, "input"> & {
        input?: RunAgentInput;
      },
  ): MaybePromise<void>;
}

export async function runSubscribersWithMutation(
  subscribers: AgentSubscriber[],
  initialMessages: Message[],
  initialState: State,
  executor: (
    subscriber: AgentSubscriber,
    messages: Message[],
    state: State,
  ) => MaybePromise<AgentStateMutation | void>,
): Promise<AgentStateMutation> {
  let messages: Message[] = initialMessages;
  let state: State = initialState;

  let stopPropagation: boolean | undefined = undefined;

  for (const subscriber of subscribers) {
    try {
      const mutation = await executor(
        subscriber,
        structuredClone_(messages),
        structuredClone_(state),
      );

      if (mutation === undefined) {
        // Nothing returned – keep going
        continue;
      }

      // Merge messages/state so next subscriber sees latest view
      if (mutation.messages !== undefined) {
        messages = mutation.messages;
      }

      if (mutation.state !== undefined) {
        state = mutation.state;
      }

      stopPropagation = mutation.stopPropagation;

      if (stopPropagation === true) {
        break;
      }
    } catch (error) {
      // Log subscriber errors but continue processing (silence during tests)
      const isTestEnvironment =
        process.env.NODE_ENV === "test" || process.env.JEST_WORKER_ID !== undefined;

      if (!isTestEnvironment) {
        console.error("Subscriber error:", error);
      }
      // Continue to next subscriber unless we want to stop propagation
      continue;
    }
  }

  return {
    ...(JSON.stringify(messages) !== JSON.stringify(initialMessages) ? { messages } : {}),
    ...(JSON.stringify(state) !== JSON.stringify(initialState) ? { state } : {}),
    ...(stopPropagation !== undefined ? { stopPropagation } : {}),
  };
}



================================================
FILE: typescript-sdk/packages/client/src/agent/types.ts
================================================
import { Message, RunAgentInput, State } from "@ag-ui/core";

export interface AgentConfig {
  agentId?: string;
  description?: string;
  threadId?: string;
  initialMessages?: Message[];
  initialState?: State;
  debug?: boolean;
}

export interface HttpAgentConfig extends AgentConfig {
  url: string;
  headers?: Record<string, string>;
}

export type RunAgentParameters = Partial<
  Pick<RunAgentInput, "runId" | "tools" | "context" | "forwardedProps">
>;



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-concurrent.test.ts
================================================
import { Observable, Subject } from "rxjs";
import { AbstractAgent } from "../agent";
import {
  BaseEvent,
  EventType,
  RunAgentInput,
  RunStartedEvent,
  RunFinishedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  Message,
  AssistantMessage,
} from "@ag-ui/core";

// Mock agent implementation for testing concurrent events
class ConcurrentTestAgent extends AbstractAgent {
  public eventsToEmit: BaseEvent[] = [];
  public currentEventIndex = 0;

  constructor() {
    super();
    this.debug = false;
  }

  // Set the events this agent should emit
  setEventsToEmit(events: BaseEvent[]) {
    this.eventsToEmit = events;
    this.currentEventIndex = 0;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return new Observable((subscriber) => {
      // Emit all the pre-configured events
      for (const event of this.eventsToEmit) {
        subscriber.next(event);
      }
      subscriber.complete();
    });
  }
}

describe("Agent concurrent operations integration", () => {
  let agent: ConcurrentTestAgent;

  beforeEach(() => {
    agent = new ConcurrentTestAgent();
  });

  // Test: Concurrent text messages through full agent pipeline
  it("should handle concurrent text messages through full agent pipeline", async () => {
    // Configure events for concurrent text messages
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg1",
        delta: "First message ",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg2",
        delta: "Second message ",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg1",
        delta: "content",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg2",
        delta: "content",
      } as TextMessageContentEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg2" } as TextMessageEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg1" } as TextMessageEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify messages were created correctly
    expect(result.newMessages.length).toBe(2);

    const msg1 = result.newMessages.find((m) => m.id === "msg1");
    const msg2 = result.newMessages.find((m) => m.id === "msg2");

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.content).toBe("First message content");
    expect(msg2?.content).toBe("Second message content");
    expect(msg1?.role).toBe("assistant");
    expect(msg2?.role).toBe("assistant");
  });

  // Test: Concurrent tool calls through full agent pipeline
  it("should handle concurrent tool calls through full agent pipeline", async () => {
    // Configure events for concurrent tool calls
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "msg1",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool2",
        toolCallName: "calculate",
        parentMessageId: "msg2",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool1",
        delta: '{"query":',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool2",
        delta: '{"expr":',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool1",
        delta: '"test"}',
      } as ToolCallArgsEvent,
      { type: EventType.TOOL_CALL_ARGS, toolCallId: "tool2", delta: '"1+1"}' } as ToolCallArgsEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool1" } as ToolCallEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool2" } as ToolCallEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify tool call messages were created correctly
    expect(result.newMessages.length).toBe(2);

    const msg1 = result.newMessages.find((m) => m.id === "msg1") as AssistantMessage;
    const msg2 = result.newMessages.find((m) => m.id === "msg2") as AssistantMessage;

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.toolCalls?.length).toBe(1);
    expect(msg2?.toolCalls?.length).toBe(1);

    expect(msg1.toolCalls?.[0]?.id).toBe("tool1");
    expect(msg1.toolCalls?.[0]?.function.name).toBe("search");
    expect(msg1.toolCalls?.[0]?.function.arguments).toBe('{"query":"test"}');

    expect(msg2.toolCalls?.[0]?.id).toBe("tool2");
    expect(msg2.toolCalls?.[0]?.function.name).toBe("calculate");
    expect(msg2.toolCalls?.[0]?.function.arguments).toBe('{"expr":"1+1"}');
  });

  // Test: Mixed concurrent text messages and tool calls
  it("should handle mixed concurrent text messages and tool calls", async () => {
    // Configure events for mixed concurrent operations
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      { type: EventType.STEP_STARTED, stepName: "thinking" } as StepStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "thinking",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "search",
        toolCallName: "web_search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "thinking",
        delta: "Let me search ",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "search",
        delta: '{"query":"',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "thinking",
        delta: "for that...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "search",
        delta: 'concurrent"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "status",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "status",
        delta: "Processing...",
      } as TextMessageContentEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "thinking" } as TextMessageEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "search" } as ToolCallEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "status" } as TextMessageEndEvent,
      { type: EventType.STEP_FINISHED, stepName: "thinking" } as StepFinishedEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify all messages were created correctly
    expect(result.newMessages.length).toBe(3);

    const thinkingMsg = result.newMessages.find((m) => m.id === "thinking");
    const statusMsg = result.newMessages.find((m) => m.id === "status");
    const toolMsg = result.newMessages.find((m) => m.id === "tool_msg") as AssistantMessage;

    expect(thinkingMsg).toBeDefined();
    expect(statusMsg).toBeDefined();
    expect(toolMsg).toBeDefined();

    expect(thinkingMsg?.content).toBe("Let me search for that...");
    expect(statusMsg?.content).toBe("Processing...");
    expect(toolMsg?.toolCalls?.length).toBe(1);
    expect(toolMsg.toolCalls?.[0]?.function.name).toBe("web_search");
    expect(toolMsg.toolCalls?.[0]?.function.arguments).toBe('{"query":"concurrent"}');
  });

  // Test: Multiple tool calls on same message through full pipeline
  it("should handle multiple tool calls on same message through full pipeline", async () => {
    // Configure events for multiple tool calls on same message
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "shared_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool2",
        toolCallName: "calculate",
        parentMessageId: "shared_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool3",
        toolCallName: "format",
        parentMessageId: "shared_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool1",
        delta: '{"q":"a"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool2",
        delta: '{"e":"b"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool3",
        delta: '{"f":"c"}',
      } as ToolCallArgsEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool2" } as ToolCallEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool1" } as ToolCallEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "tool3" } as ToolCallEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify one message with three tool calls
    expect(result.newMessages.length).toBe(1);

    const sharedMsg = result.newMessages[0] as AssistantMessage;
    expect(sharedMsg.id).toBe("shared_msg");
    expect(sharedMsg.toolCalls?.length).toBe(3);

    const toolCallIds = sharedMsg.toolCalls?.map((tc) => tc.id).sort();
    expect(toolCallIds).toEqual(["tool1", "tool2", "tool3"]);

    const tool1 = sharedMsg.toolCalls?.find((tc) => tc.id === "tool1");
    const tool2 = sharedMsg.toolCalls?.find((tc) => tc.id === "tool2");
    const tool3 = sharedMsg.toolCalls?.find((tc) => tc.id === "tool3");

    expect(tool1?.function.name).toBe("search");
    expect(tool2?.function.name).toBe("calculate");
    expect(tool3?.function.name).toBe("format");

    expect(tool1?.function.arguments).toBe('{"q":"a"}');
    expect(tool2?.function.arguments).toBe('{"e":"b"}');
    expect(tool3?.function.arguments).toBe('{"f":"c"}');
  });

  // Test: Event ordering is preserved in message creation
  it("should preserve event ordering in message creation", async () => {
    // Configure events to test ordering
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg3",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg1",
        delta: "First",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg2",
        delta: "Second",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg3",
        delta: "Third",
      } as TextMessageContentEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg3" } as TextMessageEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg1" } as TextMessageEndEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "msg2" } as TextMessageEndEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify all messages exist with correct content
    expect(result.newMessages.length).toBe(3);

    // Messages should be in the order they were started
    expect(result.newMessages[0].id).toBe("msg1");
    expect(result.newMessages[1].id).toBe("msg2");
    expect(result.newMessages[2].id).toBe("msg3");

    expect(result.newMessages[0].content).toBe("First");
    expect(result.newMessages[1].content).toBe("Second");
    expect(result.newMessages[2].content).toBe("Third");
  });

  // Test: High-frequency concurrent events through full pipeline
  it("should handle high-frequency concurrent events through full pipeline", async () => {
    const numMessages = 5;
    const numToolCalls = 5;
    const events: BaseEvent[] = [];

    // Build event sequence
    events.push({
      type: EventType.RUN_STARTED,
      threadId: "test",
      runId: "test",
    } as RunStartedEvent);

    // Start all messages
    for (let i = 0; i < numMessages; i++) {
      events.push({
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg${i}`,
        role: "assistant",
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events.push({
        type: EventType.TOOL_CALL_START,
        toolCallId: `tool${i}`,
        toolCallName: `tool_${i}`,
        parentMessageId: `tool_msg${i}`,
      } as ToolCallStartEvent);
    }

    // Add content to all messages
    for (let i = 0; i < numMessages; i++) {
      events.push({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg${i}`,
        delta: `Content ${i}`,
      } as TextMessageContentEvent);
    }

    // Add args to all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events.push({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: `tool${i}`,
        delta: `{"param":"value${i}"}`,
      } as ToolCallArgsEvent);
    }

    // End all messages
    for (let i = numMessages - 1; i >= 0; i--) {
      events.push({
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg${i}`,
      } as TextMessageEndEvent);
    }

    // End all tool calls
    for (let i = numToolCalls - 1; i >= 0; i--) {
      events.push({
        type: EventType.TOOL_CALL_END,
        toolCallId: `tool${i}`,
      } as ToolCallEndEvent);
    }

    events.push({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify all messages and tool calls were processed
    expect(result.newMessages.length).toBe(numMessages + numToolCalls);

    // Verify text messages
    for (let i = 0; i < numMessages; i++) {
      const msg = result.newMessages.find((m) => m.id === `msg${i}`);
      expect(msg).toBeDefined();
      expect(msg?.content).toBe(`Content ${i}`);
    }

    // Verify tool call messages
    for (let i = 0; i < numToolCalls; i++) {
      const toolMsg = result.newMessages.find((m) => m.id === `tool_msg${i}`) as AssistantMessage;
      expect(toolMsg).toBeDefined();
      expect(toolMsg?.toolCalls?.length).toBe(1);
      expect(toolMsg.toolCalls?.[0]?.id).toBe(`tool${i}`);
      expect(toolMsg.toolCalls?.[0]?.function.arguments).toBe(`{"param":"value${i}"}`);
    }
  });

  // Test: Concurrent events with steps
  it("should handle concurrent events with lifecycle steps", async () => {
    const events: BaseEvent[] = [
      { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      { type: EventType.STEP_STARTED, stepName: "analysis" } as StepStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "thinking",
        role: "assistant",
      } as TextMessageStartEvent,
      { type: EventType.STEP_STARTED, stepName: "search" } as StepStartedEvent,
      {
        type: EventType.TOOL_CALL_START,
        toolCallId: "search_tool",
        toolCallName: "search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "thinking",
        delta: "Analyzing...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "search_tool",
        delta: '{"query":"test"}',
      } as ToolCallArgsEvent,
      { type: EventType.STEP_FINISHED, stepName: "search" } as StepFinishedEvent,
      { type: EventType.TEXT_MESSAGE_END, messageId: "thinking" } as TextMessageEndEvent,
      { type: EventType.TOOL_CALL_END, toolCallId: "search_tool" } as ToolCallEndEvent,
      { type: EventType.STEP_FINISHED, stepName: "analysis" } as StepFinishedEvent,
      { type: EventType.RUN_FINISHED } as RunFinishedEvent,
    ];

    agent.setEventsToEmit(events);

    // Run the agent
    const result = await agent.runAgent();

    // Verify messages were created correctly even with concurrent steps
    expect(result.newMessages.length).toBe(2);

    const thinkingMsg = result.newMessages.find((m) => m.id === "thinking");
    const toolMsg = result.newMessages.find((m) => m.id === "tool_msg") as AssistantMessage;

    expect(thinkingMsg?.content).toBe("Analyzing...");
    expect(toolMsg?.toolCalls?.length).toBe(1);
    expect(toolMsg.toolCalls?.[0]?.function.name).toBe("search");
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-multiple-runs.test.ts
================================================
import { AbstractAgent, RunAgentResult } from "../agent";
import { BaseEvent, EventType, Message, RunAgentInput, TextMessageStartEvent, TextMessageContentEvent, TextMessageEndEvent, RunStartedEvent, RunFinishedEvent } from "@ag-ui/core";
import { Observable, of } from "rxjs";

describe("AbstractAgent multiple runs", () => {
  class TestAgent extends AbstractAgent {
    private events: BaseEvent[] = [];

    setEvents(events: BaseEvent[]) {
      this.events = events;
    }

    protected run(input: RunAgentInput): Observable<BaseEvent> {
      return of(...this.events);
    }
  }

  it("should accumulate messages across multiple sequential runs", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    // First run events
    const firstRunEvents: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-1",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Hello from run 1",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    // Execute first run
    agent.setEvents(firstRunEvents);
    const result1 = await agent.runAgent({ runId: "run-1" });

    // Verify first run results
    expect(result1.newMessages.length).toBe(1);
    expect(result1.newMessages[0].content).toBe("Hello from run 1");
    expect(agent.messages.length).toBe(1);
    expect(agent.messages[0].content).toBe("Hello from run 1");

    // Second run events
    const secondRunEvents: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-2",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-2",
        delta: "Hello from run 2",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-2",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    // Execute second run
    agent.setEvents(secondRunEvents);
    const result2 = await agent.runAgent({ runId: "run-2" });

    // Verify second run results
    expect(result2.newMessages.length).toBe(1);
    expect(result2.newMessages[0].content).toBe("Hello from run 2");
    
    // Verify messages are accumulated
    expect(agent.messages.length).toBe(2);
    expect(agent.messages[0].content).toBe("Hello from run 1");
    expect(agent.messages[1].content).toBe("Hello from run 2");
  });

  it("should handle three sequential runs with message accumulation", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const messages = ["First message", "Second message", "Third message"];
    
    for (let i = 0; i < 3; i++) {
      const runEvents: BaseEvent[] = [
        {
          type: EventType.RUN_STARTED,
          threadId: "test-thread",
          runId: `run-${i + 1}`,
        } as RunStartedEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: `msg-${i + 1}`,
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: `msg-${i + 1}`,
          delta: messages[i],
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: `msg-${i + 1}`,
        } as TextMessageEndEvent,
        {
          type: EventType.RUN_FINISHED,
        } as RunFinishedEvent,
      ];

      agent.setEvents(runEvents);
      const result = await agent.runAgent({ runId: `run-${i + 1}` });

      // Verify new messages for this run
      expect(result.newMessages.length).toBe(1);
      expect(result.newMessages[0].content).toBe(messages[i]);

      // Verify total accumulated messages
      expect(agent.messages.length).toBe(i + 1);
      for (let j = 0; j <= i; j++) {
        expect(agent.messages[j].content).toBe(messages[j]);
      }
    }

    // Final verification
    expect(agent.messages.length).toBe(3);
    expect(agent.messages.map(m => m.content)).toEqual(messages);
  });

  it("should handle multiple runs in a single event stream", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    // Create a single event stream with two runs
    const allEvents: BaseEvent[] = [
      // First run
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-1",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Message from run 1",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
      // Second run
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-2",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-2",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-2",
        delta: "Message from run 2",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-2",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    // Execute with the combined event stream
    agent.setEvents(allEvents);
    const result = await agent.runAgent({ runId: "combined-run" });

    // Verify results
    expect(result.newMessages.length).toBe(2);
    expect(result.newMessages[0].content).toBe("Message from run 1");
    expect(result.newMessages[1].content).toBe("Message from run 2");

    // Verify all messages are accumulated
    expect(agent.messages.length).toBe(2);
    expect(agent.messages[0].content).toBe("Message from run 1");
    expect(agent.messages[1].content).toBe("Message from run 2");
  });

  it("should start with initial messages and accumulate new ones", async () => {
    const initialMessages: Message[] = [
      {
        id: "initial-1",
        role: "user",
        content: "Initial message",
      },
    ];

    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages,
    });

    // Run events
    const runEvents: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "run-1",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Response message",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(runEvents);
    const result = await agent.runAgent({ runId: "run-1" });

    // Verify new messages don't include initial messages
    expect(result.newMessages.length).toBe(1);
    expect(result.newMessages[0].content).toBe("Response message");

    // Verify total messages include both initial and new
    expect(agent.messages.length).toBe(2);
    expect(agent.messages[0].content).toBe("Initial message");
    expect(agent.messages[1].content).toBe("Response message");
  });
});


================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-mutations.test.ts
================================================
import { AbstractAgent } from "../agent";
import { AgentSubscriber } from "../subscriber";
import {
  BaseEvent,
  EventType,
  Message,
  RunAgentInput,
  State,
  ToolCall,
  AssistantMessage,
} from "@ag-ui/core";
import { Observable, of } from "rxjs";

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Mock utils
jest.mock("@/utils", () => ({
  structuredClone_: (obj: any) => {
    if (obj === undefined) return undefined;
    const jsonString = JSON.stringify(obj);
    if (jsonString === undefined || jsonString === "undefined") return undefined;
    return JSON.parse(jsonString);
  },
}));

// Helper function to wait for async notifications to complete
const waitForAsyncNotifications = async () => {
  // Wait for the next tick of the event loop to ensure async operations complete
  await new Promise((resolve) => setImmediate(resolve));
};

// Mock the verify and chunks modules
jest.mock("@/verify", () => ({
  verifyEvents: jest.fn(() => (source$: Observable<any>) => source$),
}));

jest.mock("@/chunks", () => ({
  transformChunks: jest.fn(() => (source$: Observable<any>) => source$),
}));

// Create a test agent implementation
class TestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return of();
  }
}

describe("Agent Mutations", () => {
  let agent: TestAgent;
  let mockSubscriber: AgentSubscriber;

  beforeEach(() => {
    jest.clearAllMocks();

    agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [
        {
          id: "initial-msg",
          role: "user",
          content: "Initial message",
        },
      ],
      initialState: { counter: 0 },
    });

    mockSubscriber = {
      onMessagesChanged: jest.fn(),
      onStateChanged: jest.fn(),
      onNewMessage: jest.fn(),
      onNewToolCall: jest.fn(),
    };

    agent.subscribe(mockSubscriber);
  });

  describe("addMessage", () => {
    it("should add a user message and fire appropriate events", async () => {
      const userMessage: Message = {
        id: "user-msg-1",
        role: "user",
        content: "Hello world",
      };

      agent.addMessage(userMessage);

      // Message should be added immediately
      expect(agent.messages).toHaveLength(2);
      expect(agent.messages[1]).toBe(userMessage);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should fire onNewMessage and onMessagesChanged
      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith({
        message: userMessage,
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire onNewToolCall for user messages
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should add an assistant message without tool calls", async () => {
      const assistantMessage: Message = {
        id: "assistant-msg-1",
        role: "assistant",
        content: "How can I help you?",
      };

      agent.addMessage(assistantMessage);

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith({
        message: assistantMessage,
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire onNewToolCall when no tool calls
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should add an assistant message with tool calls and fire onNewToolCall", async () => {
      const toolCalls: ToolCall[] = [
        {
          id: "call-1",
          type: "function",
          function: {
            name: "get_weather",
            arguments: '{"location": "New York"}',
          },
        },
        {
          id: "call-2",
          type: "function",
          function: {
            name: "search_web",
            arguments: '{"query": "latest news"}',
          },
        },
      ];

      const assistantMessage: Message = {
        id: "assistant-msg-2",
        role: "assistant",
        content: "Let me help you with that.",
        toolCalls,
      };

      agent.addMessage(assistantMessage);

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith({
        message: assistantMessage,
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should fire onNewToolCall for each tool call
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledTimes(2);

      expect(mockSubscriber.onNewToolCall).toHaveBeenNthCalledWith(1, {
        toolCall: toolCalls[0],
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onNewToolCall).toHaveBeenNthCalledWith(2, {
        toolCall: toolCalls[1],
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });
    });
  });

  describe("addMessages", () => {
    it("should add multiple messages and fire events correctly", async () => {
      const messages: Message[] = [
        {
          id: "msg-1",
          role: "user",
          content: "First message",
        },
        {
          id: "msg-2",
          role: "assistant",
          content: "Second message",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: {
                name: "test_tool",
                arguments: '{"param": "value"}',
              },
            },
          ],
        },
        {
          id: "msg-3",
          role: "user",
          content: "Third message",
        },
      ];

      const initialLength = agent.messages.length;
      agent.addMessages(messages);

      // Messages should be added immediately
      expect(agent.messages).toHaveLength(initialLength + 3);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should fire onNewMessage for each message
      expect(mockSubscriber.onNewMessage).toHaveBeenCalledTimes(3);

      // Should fire onNewToolCall only for the assistant message with tool calls
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledWith({
        toolCall: (messages[1] as AssistantMessage).toolCalls![0],
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should fire onMessagesChanged only once at the end
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });
    });

    it("should handle empty array gracefully", async () => {
      const initialLength = agent.messages.length;
      agent.addMessages([]);

      expect(agent.messages).toHaveLength(initialLength);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should still fire onMessagesChanged even for empty array
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });
  });

  describe("setMessages", () => {
    it("should replace messages and fire onMessagesChanged only", async () => {
      const newMessages: Message[] = [
        {
          id: "new-msg-1",
          role: "user",
          content: "New conversation start",
        },
        {
          id: "new-msg-2",
          role: "assistant",
          content: "Assistant response",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: {
                name: "some_tool",
                arguments: "{}",
              },
            },
          ],
        },
      ];

      const originalMessage = agent.messages[0];
      agent.setMessages(newMessages);

      // Messages should be replaced immediately
      expect(agent.messages).toHaveLength(2);
      expect(agent.messages).not.toContain(originalMessage); // Original message should be gone
      expect(agent.messages[0]).toEqual(newMessages[0]);
      expect(agent.messages[1]).toEqual(newMessages[1]);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should ONLY fire onMessagesChanged
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire onNewMessage or onNewToolCall
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should handle empty messages array", async () => {
      agent.setMessages([]);

      expect(agent.messages).toHaveLength(0);

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onMessagesChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });
  });

  describe("setState", () => {
    it("should replace state and fire onStateChanged only", async () => {
      const newState: State = {
        counter: 100,
        isActive: true,
        data: { key: "value" },
      };

      agent.setState(newState);

      // State should be replaced immediately
      expect(agent.state).toEqual(newState);
      expect(agent.state).not.toBe(newState); // Should be a clone

      // Wait for async notifications
      await waitForAsyncNotifications();

      // Should ONLY fire onStateChanged
      expect(mockSubscriber.onStateChanged).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onStateChanged).toHaveBeenCalledWith({
        messages: agent.messages,
        state: agent.state,
        agent,
      });

      // Should NOT fire other events
      expect(mockSubscriber.onMessagesChanged).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
    });

    it("should handle empty state object", async () => {
      agent.setState({});

      expect(agent.state).toEqual({});

      // Wait for async notifications
      await waitForAsyncNotifications();

      expect(mockSubscriber.onStateChanged).toHaveBeenCalledTimes(1);
    });
  });

  describe("execution order", () => {
    it("should execute subscriber notifications in registration order", async () => {
      const callOrder: string[] = [];

      const firstSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn().mockImplementation(() => {
          callOrder.push("first-newMessage");
        }),
        onMessagesChanged: jest.fn().mockImplementation(() => {
          callOrder.push("first-messagesChanged");
        }),
      };

      const secondSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn().mockImplementation(() => {
          callOrder.push("second-newMessage");
        }),
        onMessagesChanged: jest.fn().mockImplementation(() => {
          callOrder.push("second-messagesChanged");
        }),
      };

      // Clear the default subscriber and add our test subscribers
      agent.subscribers = [];
      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      const message: Message = {
        id: "test-msg",
        role: "user",
        content: "Test message",
      };

      agent.addMessage(message);

      // Wait for all async operations to complete by polling until all calls are made
      while (callOrder.length < 4) {
        await waitForAsyncNotifications();
      }

      // Verify sequential execution order
      expect(callOrder).toEqual([
        "first-newMessage",
        "second-newMessage",
        "first-messagesChanged",
        "second-messagesChanged",
      ]);
    });
  });

  describe("multiple subscribers", () => {
    it("should notify all subscribers for each event", async () => {
      const subscriber2: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
        onNewToolCall: jest.fn(),
      };

      const subscriber3: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
      };

      agent.subscribe(subscriber2);
      agent.subscribe(subscriber3);

      const message: Message = {
        id: "test-msg",
        role: "assistant",
        content: "Test",
        toolCalls: [
          {
            id: "call-1",
            type: "function",
            function: { name: "test", arguments: "{}" },
          },
        ],
      };

      agent.addMessage(message);

      // Wait for async notifications
      await waitForAsyncNotifications();

      // All subscribers should receive notifications
      [mockSubscriber, subscriber2, subscriber3].forEach((sub) => {
        expect(sub.onNewMessage).toHaveBeenCalledWith(
          expect.objectContaining({
            message,
            agent,
          }),
        );
        expect(sub.onMessagesChanged).toHaveBeenCalled();
      });

      // Only subscribers with onNewToolCall should receive tool call events
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalled();
      expect(subscriber2.onNewToolCall).toHaveBeenCalled();
      // subscriber3 doesn't have onNewToolCall method, so it shouldn't be called
      expect(subscriber3.onNewToolCall).toBeUndefined();
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-result.test.ts
================================================
import { AbstractAgent } from "../agent";
import { AgentSubscriber } from "../subscriber";
import {
  BaseEvent,
  EventType,
  Message,
  RunAgentInput,
  State,
  MessagesSnapshotEvent,
  RunFinishedEvent,
  RunStartedEvent,
} from "@ag-ui/core";
import { Observable, of } from "rxjs";

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Mock utils
jest.mock("@/utils", () => ({
  structuredClone_: (obj: any) => {
    if (obj === undefined) return undefined;
    const jsonString = JSON.stringify(obj);
    if (jsonString === undefined || jsonString === "undefined") return undefined;
    return JSON.parse(jsonString);
  },
}));

// Mock the verify and chunks modules
jest.mock("@/verify", () => ({
  verifyEvents: jest.fn(() => (source$: Observable<any>) => source$),
}));

jest.mock("@/chunks", () => ({
  transformChunks: jest.fn(() => (source$: Observable<any>) => source$),
}));

// Helper function to wait for async notifications to complete
const waitForAsyncNotifications = async () => {
  await new Promise((resolve) => setImmediate(resolve));
};

// Create a test agent implementation that can emit specific events
class TestAgent extends AbstractAgent {
  private eventsToEmit: BaseEvent[] = [];

  setEventsToEmit(events: BaseEvent[]) {
    this.eventsToEmit = events;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return of(...this.eventsToEmit);
  }
}

describe("Agent Result", () => {
  let agent: TestAgent;

  beforeEach(() => {
    jest.clearAllMocks();

    agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [
        {
          id: "existing-msg-1",
          role: "user",
          content: "Existing message 1",
        },
        {
          id: "existing-msg-2",
          role: "assistant",
          content: "Existing message 2",
        },
      ],
      initialState: { counter: 0 },
    });
  });

  describe("result handling", () => {
    it("should return undefined result when no result is set", async () => {
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test-thread",
          runId: "test-run",
        } as RunStartedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBeUndefined();
      expect(result.newMessages).toEqual([]);
    });

    it("should return result set by onRunFinishedEvent", async () => {
      const expectedResult = { success: true, data: "test-data", count: 42 };

      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test-thread",
          runId: "test-run",
        } as RunStartedEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(expectedResult);
      expect(result.newMessages).toEqual([]);
    });

    it("should handle string result", async () => {
      const expectedResult = "Simple string result";

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBe(expectedResult);
    });

    it("should handle null result", async () => {
      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: null,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBeNull();
    });
  });

  describe("newMessages tracking", () => {
    it("should track new messages added during run", async () => {
      const newMessages: Message[] = [
        {
          id: "new-msg-1",
          role: "user",
          content: "New message 1",
        },
        {
          id: "new-msg-2",
          role: "assistant",
          content: "New message 2",
        },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: "success",
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toBe("success");
      expect(result.newMessages).toEqual(newMessages);
      expect(agent.messages).toEqual(allMessages);
    });

    it("should not include existing messages in newMessages", async () => {
      const newMessage: Message = {
        id: "new-msg-only",
        role: "assistant",
        content: "Only this is new",
      };

      // Include existing messages plus new one
      const allMessages = [...agent.messages, newMessage];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual([newMessage]);
      expect(result.newMessages).toHaveLength(1);
      expect(agent.messages).toEqual(allMessages);
    });

    it("should handle no new messages", async () => {
      // Keep same messages as initial
      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: agent.messages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual([]);
      expect(agent.messages).toHaveLength(2); // Original messages
    });

    it("should handle multiple new messages with tool calls", async () => {
      const newMessages: Message[] = [
        {
          id: "new-msg-user",
          role: "user",
          content: "User query",
        },
        {
          id: "new-msg-assistant",
          role: "assistant",
          content: "Let me help you",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: {
                name: "search_tool",
                arguments: '{"query": "test"}',
              },
            },
          ],
        },
        {
          id: "new-msg-tool",
          role: "tool",
          content: "Tool result",
          toolCallId: "call-1",
        },
        {
          id: "new-msg-final",
          role: "assistant",
          content: "Here's the answer",
        },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: { toolsUsed: 1, messagesAdded: 4 },
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual(newMessages);
      expect(result.newMessages).toHaveLength(4);
      expect(result.result).toEqual({ toolsUsed: 1, messagesAdded: 4 });
    });

    it("should preserve message order", async () => {
      const newMessages: Message[] = [
        { id: "new-1", role: "user", content: "First new" },
        { id: "new-2", role: "assistant", content: "Second new" },
        { id: "new-3", role: "user", content: "Third new" },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual(newMessages);
      // Verify order is preserved
      expect(result.newMessages[0].id).toBe("new-1");
      expect(result.newMessages[1].id).toBe("new-2");
      expect(result.newMessages[2].id).toBe("new-3");
    });
  });

  describe("combined result and newMessages", () => {
    it("should return both result and newMessages correctly", async () => {
      const newMessages: Message[] = [
        {
          id: "conversation-msg",
          role: "assistant",
          content: "Here's what I found",
        },
      ];

      const expectedResult = {
        status: "completed",
        messagesGenerated: 1,
        processingTime: 1500,
      };

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(expectedResult);
      expect(result.newMessages).toEqual(newMessages);
      expect(result.newMessages).toHaveLength(1);
    });

    it("should handle empty newMessages with valid result", async () => {
      const expectedResult = { error: false, processed: true };

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: expectedResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(expectedResult);
      expect(result.newMessages).toEqual([]);
    });
  });

  describe("subscriber notifications integration", () => {
    it("should track newMessages without interfering with existing event processing", async () => {
      const mockSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
        onNewToolCall: jest.fn(),
      };

      agent.subscribe(mockSubscriber);

      const newMessages: Message[] = [
        {
          id: "new-msg-1",
          role: "user",
          content: "New user message",
        },
        {
          id: "new-msg-2",
          role: "assistant",
          content: "New assistant message",
          toolCalls: [
            {
              id: "call-1",
              type: "function",
              function: { name: "test_tool", arguments: "{}" },
            },
          ],
        },
      ];

      const allMessages = [...agent.messages, ...newMessages];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual(newMessages);

      // Note: Subscriber notifications are handled by the existing event processing pipeline
      // The newMessages tracking is separate from subscriber notification logic
    });

    it("should return empty newMessages when no messages are added", async () => {
      const mockSubscriber: AgentSubscriber = {
        onNewMessage: jest.fn(),
        onMessagesChanged: jest.fn(),
        onNewToolCall: jest.fn(),
      };

      agent.subscribe(mockSubscriber);

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: "no new messages",
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.newMessages).toEqual([]);

      // Should not fire any new message events since no messages were added
      expect(mockSubscriber.onNewMessage).not.toHaveBeenCalled();
      expect(mockSubscriber.onNewToolCall).not.toHaveBeenCalled();
      expect(mockSubscriber.onMessagesChanged).not.toHaveBeenCalled();
    });
  });

  describe("edge cases", () => {
    it("should handle agent with no initial messages", async () => {
      const emptyAgent = new TestAgent({
        threadId: "empty-thread",
        initialMessages: [],
      });

      const newMessages: Message[] = [{ id: "first-ever", role: "user", content: "First message" }];

      emptyAgent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: newMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await emptyAgent.runAgent();

      expect(result.newMessages).toEqual(newMessages);
      expect(emptyAgent.messages).toEqual(newMessages);
    });

    it("should handle messages with duplicate IDs correctly", async () => {
      // This tests that we're using Set correctly for ID tracking
      const messageWithSameId: Message = {
        id: "existing-msg-1", // Same ID as existing message
        role: "user",
        content: "Updated content",
      };

      const allMessages = [...agent.messages, messageWithSameId];

      agent.setEventsToEmit([
        {
          type: EventType.MESSAGES_SNAPSHOT,
          messages: allMessages,
        } as MessagesSnapshotEvent,
      ]);

      const result = await agent.runAgent();

      // Should not include the duplicate ID in newMessages
      expect(result.newMessages).toEqual([]);
      expect(agent.messages).toEqual(allMessages);
    });

    it("should handle complex result objects", async () => {
      const complexResult = {
        metadata: {
          timestamp: new Date().toISOString(),
          version: "1.0.0",
        },
        data: {
          results: [1, 2, 3],
          nested: {
            deep: {
              value: "test",
            },
          },
        },
        stats: {
          processingTime: 1000,
          tokensUsed: 150,
        },
      };

      agent.setEventsToEmit([
        {
          type: EventType.RUN_FINISHED,
          threadId: "test-thread",
          runId: "test-run",
          result: complexResult,
        } as RunFinishedEvent,
      ]);

      const result = await agent.runAgent();

      expect(result.result).toEqual(complexResult);
      expect(result.result).toMatchObject(complexResult);
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/agent-text-roles.test.ts
================================================
import { AbstractAgent } from "../agent";
import { BaseEvent, EventType, Message, RunAgentInput, TextMessageStartEvent, TextMessageContentEvent, TextMessageEndEvent, TextMessageChunkEvent, RunStartedEvent, RunFinishedEvent, Role } from "@ag-ui/core";
import { Observable, of } from "rxjs";

describe("AbstractAgent text message roles", () => {
  class TestAgent extends AbstractAgent {
    private events: BaseEvent[] = [];

    setEvents(events: BaseEvent[]) {
      this.events = events;
    }

    protected run(input: RunAgentInput): Observable<BaseEvent> {
      return of(...this.events);
    }
  }

  // Text messages can have any role except "tool"
  const textMessageRoles = ["developer", "system", "assistant", "user"] as const;

  it.each(textMessageRoles)("should handle text messages with role '%s'", async (role) => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg-${role}`,
        role: role,
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg-${role}`,
        delta: `Hello from ${role}`,
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg-${role}`,
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify message was created with correct role
    expect(result.newMessages.length).toBe(1);
    expect(result.newMessages[0].role).toBe(role);
    expect(result.newMessages[0].content).toBe(`Hello from ${role}`);
    expect(agent.messages.length).toBe(1);
    expect(agent.messages[0].role).toBe(role);
  });

  it("should handle multiple messages with different roles in a single run", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
    ];

    // Add messages from different roles
    for (const role of textMessageRoles) {
      events.push(
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: `msg-${role}`,
          role: role,
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: `msg-${role}`,
          delta: `Message from ${role}`,
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: `msg-${role}`,
        } as TextMessageEndEvent
      );
    }

    events.push({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify all messages were created with correct roles
    expect(result.newMessages.length).toBe(textMessageRoles.length);
    expect(agent.messages.length).toBe(textMessageRoles.length);

    textMessageRoles.forEach((role, index) => {
      expect(result.newMessages[index].role).toBe(role);
      expect(result.newMessages[index].content).toBe(`Message from ${role}`);
      expect(agent.messages[index].role).toBe(role);
    });
  });

  it("should handle text message chunks with different roles", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    // Test with chunks that specify role
    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-user",
        role: "user",
        delta: "User chunk message",
      } as TextMessageChunkEvent,
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-system",
        role: "system",
        delta: "System chunk message",
      } as TextMessageChunkEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify messages were created from chunks
    expect(result.newMessages.length).toBe(2);
    expect(result.newMessages[0].role).toBe("user");
    expect(result.newMessages[0].content).toBe("User chunk message");
    expect(result.newMessages[1].role).toBe("system");
    expect(result.newMessages[1].content).toBe("System chunk message");
  });

  it("should default to 'assistant' role when not specified", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-default",
        // role not specified - should default to assistant
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-default",
        delta: "Default role message",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-default",
      } as TextMessageEndEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify message was created with default 'assistant' role
    expect(result.newMessages.length).toBe(1);
    expect(result.newMessages[0].role).toBe("assistant");
    expect(result.newMessages[0].content).toBe("Default role message");
  });

  it("should preserve role when mixing regular and chunk events", async () => {
    const agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [],
    });

    const events: BaseEvent[] = [
      {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      } as RunStartedEvent,
      // Regular message with user role
      {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "user",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "User message",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-1",
      } as TextMessageEndEvent,
      // Chunk message with developer role
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-2",
        role: "developer",
        delta: "Developer chunk",
      } as TextMessageChunkEvent,
      {
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent,
    ];

    agent.setEvents(events);
    const result = await agent.runAgent({ runId: "test-run" });

    // Verify both message types preserved their roles
    expect(result.newMessages.length).toBe(2);
    expect(result.newMessages[0].role).toBe("user");
    expect(result.newMessages[0].content).toBe("User message");
    expect(result.newMessages[1].role).toBe("developer");
    expect(result.newMessages[1].content).toBe("Developer chunk");
  });
});


================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/http.test.ts
================================================
import { HttpAgent } from "../http";
import { runHttpRequest, HttpEvent, HttpEventType } from "@/run/http-request";
import { v4 as uuidv4 } from "uuid";
import { Observable, of } from "rxjs";

// Mock the runHttpRequest module
jest.mock("@/run/http-request", () => ({
  runHttpRequest: jest.fn(),
  HttpEventType: {
    HEADERS: "headers",
    DATA: "data",
  },
}));

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-run-id"),
}));

// Mock transformHttpEventStream
jest.mock("@/transform/http", () => ({
  transformHttpEventStream: jest.fn((source$) => source$),
}));

describe("HttpAgent", () => {
  // Reset mocks before each test
  beforeEach(() => {
    jest.clearAllMocks();
  });

  it("should configure and execute HTTP requests correctly", async () => {
    // Setup mock observable for the HTTP response
    const mockObservable = of({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers(),
    });

    // Mock the runHttpRequest function
    (runHttpRequest as jest.Mock).mockReturnValue(mockObservable);

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
      },
    });

    // Setup input data for the agent
    agent.messages = [
      {
        id: uuidv4(),
        role: "user",
        content: "Hello",
      },
    ];

    // Prepare the input that would be used in runAgent
    const input = {
      threadId: agent.threadId,
      runId: "mock-run-id",
      tools: [],
      context: [],
      forwardedProps: {},
      state: agent.state,
      messages: agent.messages,
    };

    // Call run method directly, which should call runHttpRequest
    agent.run(input);

    // Verify runHttpRequest was called with correct config
    expect(runHttpRequest).toHaveBeenCalledWith("https://api.example.com/v1/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
        Accept: "text/event-stream",
      },
      body: JSON.stringify(input),
      signal: expect.any(AbortSignal),
    });
  });

  it("should abort the request when abortRun is called", () => {
    // Setup mock implementation
    (runHttpRequest as jest.Mock).mockReturnValue(of());

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Spy on the abort method of AbortController
    const abortSpy = jest.spyOn(AbortController.prototype, "abort");

    // Trigger runAgent without actually calling it by checking the abortController
    expect(agent.abortController).toBeInstanceOf(AbortController);

    // Call abortRun directly
    agent.abortRun();

    // Verify abort was called
    expect(abortSpy).toHaveBeenCalled();

    // Clean up
    abortSpy.mockRestore();
  });

  it("should use a custom abort controller when provided", () => {
    // Setup mock implementation
    (runHttpRequest as jest.Mock).mockReturnValue(of());

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Create a custom abort controller
    const customController = new AbortController();
    const abortSpy = jest.spyOn(customController, "abort");

    // Set the custom controller
    agent.abortController = customController;

    // Call abortRun directly
    agent.abortRun();

    // Verify the custom controller was used
    expect(abortSpy).toHaveBeenCalled();

    // Clean up
    abortSpy.mockRestore();
  });

  it("should handle transformHttpEventStream correctly", () => {
    // Import the actual transformHttpEventStream function
    const { transformHttpEventStream } = require("../../transform/http");

    // Verify transformHttpEventStream is a function
    expect(typeof transformHttpEventStream).toBe("function");

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Verify that the HttpAgent's run method uses transformHttpEventStream
    // This is an indirect test of implementation details, but useful to verify the pipeline
    const mockObservable = of({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers(),
    });

    (runHttpRequest as jest.Mock).mockReturnValue(mockObservable);

    // Call run with mock input
    const input = {
      threadId: agent.threadId,
      runId: "test-run-id",
      state: {},
      messages: [],
      tools: [],
      context: [],
      forwardedProps: {},
    };

    // Execute the run function
    agent.run(input);

    // Verify that transformHttpEventStream was called with the mock observable
    expect(transformHttpEventStream).toHaveBeenCalledWith(mockObservable);
  });

  it("should process HTTP response data end-to-end", async () => {
    // Create mock headers
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "text/event-stream");

    // Create a mock response data
    const mockResponseObservable = of(
      {
        type: HttpEventType.HEADERS,
        status: 200,
        headers: mockHeaders,
      },
      {
        type: HttpEventType.DATA,
        data: new Uint8Array(
          new TextEncoder().encode(
            'data: {"type": "TEXT_MESSAGE_START", "messageId": "test-id"}\n\n',
          ),
        ),
      },
    );

    // Directly mock runHttpRequest
    (runHttpRequest as jest.Mock).mockReturnValue(mockResponseObservable);

    // Configure test agent
    const agent = new HttpAgent({
      url: "https://api.example.com/v1/chat",
      headers: {},
    });

    // Prepare input for the agent
    const input = {
      threadId: agent.threadId,
      runId: "mock-run-id",
      tools: [],
      context: [],
      forwardedProps: {},
      state: agent.state,
      messages: agent.messages,
    };

    // Call run method directly
    agent.run(input);

    // Verify runHttpRequest was called with correct config
    expect(runHttpRequest).toHaveBeenCalledWith("https://api.example.com/v1/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Accept: "text/event-stream",
      },
      body: JSON.stringify(input),
      signal: expect.any(AbortSignal),
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/legacy-bridged.test.ts
================================================
import { toArray } from "rxjs/operators";
import { EventType, BaseEvent, RunAgentInput } from "@ag-ui/core";
import { AbstractAgent } from "../../agent/agent";
import { Observable, lastValueFrom } from "rxjs";
import { RunAgentParameters } from "../../agent/types";

// Mock uuid
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Create a test agent that extends AbstractAgent
class TestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = "test-message-id";
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId,
        delta: "Hello world!",
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.complete();
    });
  }
}

// Agent that emits text chunks instead of start/content/end events
class ChunkTestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const messageId = "test-chunk-id";
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      // Emit a text message chunk instead of separate start/content/end events
      observer.next({
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId,
        delta: "Hello from chunks!",
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.complete();
    });
  }
}

// Agent that emits tool call events with results
class ToolCallTestAgent extends AbstractAgent {
  protected run(input: RunAgentInput): Observable<BaseEvent> {
    const toolCallId = "test-tool-call-id";
    const toolCallName = "get_weather";
    return new Observable<BaseEvent>((observer) => {
      observer.next({
        type: EventType.RUN_STARTED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      // Start tool call
      observer.next({
        type: EventType.TOOL_CALL_START,
        toolCallId,
        toolCallName,
        timestamp: Date.now(),
      } as BaseEvent);

      // Tool call arguments
      observer.next({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId,
        delta: '{"location": "San Francisco"}',
        timestamp: Date.now(),
      } as BaseEvent);

      // End tool call
      observer.next({
        type: EventType.TOOL_CALL_END,
        toolCallId,
        timestamp: Date.now(),
      } as BaseEvent);

      // Tool call result
      observer.next({
        messageId: "test-message-id",
        type: EventType.TOOL_CALL_RESULT,
        toolCallId,
        content: "The weather in San Francisco is 72°F and sunny.",
        timestamp: Date.now(),
      } as BaseEvent);

      observer.next({
        type: EventType.RUN_FINISHED,
        threadId: input.threadId,
        runId: input.runId,
        timestamp: Date.now(),
      } as BaseEvent);

      observer.complete();
    });
  }
}

describe("AbstractAgent.legacy_to_be_removed_runAgentBridged", () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  it("should correctly convert events to legacy format", async () => {
    // Setup agent with mock IDs
    const agent = new TestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Verify events are in correct legacy format
    expect(legacyEvents).toHaveLength(3); // Start, Content, End

    // TextMessageStart
    expect(legacyEvents[0]).toMatchObject({
      type: "TextMessageStart",
      messageId: "test-message-id",
    });

    // TextMessageContent
    expect(legacyEvents[1]).toMatchObject({
      type: "TextMessageContent",
      messageId: "test-message-id",
      content: "Hello world!",
    });

    // TextMessageEnd
    expect(legacyEvents[2]).toMatchObject({
      type: "TextMessageEnd",
      messageId: "test-message-id",
    });

    // Final AgentStateMessage
    // expect(legacyEvents[3]).toMatchObject({
    //   type: "AgentStateMessage",
    //   threadId: "test-thread-id",
    //   agentName: "test-agent-id",
    //   active: false,
    // });
  });

  it("should pass configuration to the underlying run method", async () => {
    // Setup agent with mock IDs
    const agent = new TestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Spy on the run method
    const runSpy = jest.spyOn(agent as any, "run");

    // Create config with compatible tool format
    const config: RunAgentParameters = {
      tools: [],
      context: [{ value: "test context", description: "Test description" }],
      forwardedProps: { foo: "bar" },
    };

    // Call legacy bridged method with config
    agent.legacy_to_be_removed_runAgentBridged(config);

    // Verify run method was called with correct input
    expect(runSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        threadId: "test-thread-id",
        runId: "mock-uuid",
        tools: config.tools,
        context: config.context,
        forwardedProps: config.forwardedProps,
      }),
    );
  });

  it("should include agent ID in the legacy events when converting", async () => {
    // Setup agent with mock IDs
    const agent = new TestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Set up a state snapshot to test agent state in legacy format
    const runWithStateSnapshot = jest
      .fn()
      .mockImplementation((input: RunAgentInput): Observable<BaseEvent> => {
        return new Observable<BaseEvent>((observer) => {
          observer.next({
            type: EventType.RUN_STARTED,
            threadId: input.threadId,
            runId: input.runId,
            timestamp: Date.now(),
          } as BaseEvent);

          // Add a state snapshot event
          observer.next({
            type: EventType.STATE_SNAPSHOT,
            snapshot: { test: "state" },
            timestamp: Date.now(),
          } as BaseEvent);

          observer.next({
            type: EventType.RUN_FINISHED,
            threadId: input.threadId,
            runId: input.runId,
            timestamp: Date.now(),
          } as BaseEvent);

          observer.complete();
        });
      });

    // Override the run method for this test
    jest.spyOn(agent as any, "run").mockImplementation(runWithStateSnapshot);

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Find AgentStateMessage events
    const stateEvents = legacyEvents.filter((e) => e.type === "AgentStateMessage");

    // Should have at least one state event
    expect(stateEvents.length).toBeGreaterThan(0);

    // All state events should include the agent ID
    stateEvents.forEach((event) => {
      expect(event).toMatchObject({
        agentName: "test-agent-id",
        threadId: "test-thread-id",
        state: expect.any(String),
      });

      // Verify that state was correctly serialized
      if (event.state) {
        const parsedState = JSON.parse(event.state);
        expect(parsedState).toMatchObject({ test: "state" });
      }
    });
  });

  it("should transform text message chunks into legacy text message events", async () => {
    // Setup agent with mock IDs
    const agent = new ChunkTestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Verify events are in correct legacy format
    expect(legacyEvents).toHaveLength(3); // Start, Content, End

    // TextMessageStart
    expect(legacyEvents[0]).toMatchObject({
      type: "TextMessageStart",
      messageId: "test-chunk-id",
    });

    // TextMessageContent
    expect(legacyEvents[1]).toMatchObject({
      type: "TextMessageContent",
      messageId: "test-chunk-id",
      content: "Hello from chunks!",
    });

    // TextMessageEnd
    expect(legacyEvents[2]).toMatchObject({
      type: "TextMessageEnd",
      messageId: "test-chunk-id",
    });

    // Final AgentStateMessage
    // expect(legacyEvents[3]).toMatchObject({
    //   type: "AgentStateMessage",
    //   threadId: "test-thread-id",
    //   agentName: "test-agent-id",
    //   active: false,
    // });
  });

  it("should transform tool call events with results into legacy events with correct tool name", async () => {
    // Setup agent with mock IDs
    const agent = new ToolCallTestAgent({
      threadId: "test-thread-id",
      agentId: "test-agent-id",
    });

    // Get the observable that emits legacy events
    const legacy$ = agent.legacy_to_be_removed_runAgentBridged();

    // Collect all emitted events
    const legacyEvents = await lastValueFrom(legacy$.pipe(toArray()));

    // Verify events are in correct legacy format
    expect(legacyEvents).toHaveLength(4); // ActionExecutionStart, ActionExecutionArgs, ActionExecutionEnd, ActionExecutionResult

    // ActionExecutionStart
    expect(legacyEvents[0]).toMatchObject({
      type: "ActionExecutionStart",
      actionExecutionId: "test-tool-call-id",
      actionName: "get_weather",
    });

    // ActionExecutionArgs
    expect(legacyEvents[1]).toMatchObject({
      type: "ActionExecutionArgs",
      actionExecutionId: "test-tool-call-id",
      args: '{"location": "San Francisco"}',
    });

    // ActionExecutionEnd
    expect(legacyEvents[2]).toMatchObject({
      type: "ActionExecutionEnd",
      actionExecutionId: "test-tool-call-id",
    });

    // ActionExecutionResult - this should include the tool name
    expect(legacyEvents[3]).toMatchObject({
      type: "ActionExecutionResult",
      actionExecutionId: "test-tool-call-id",
      actionName: "get_weather", // This verifies the tool name is correctly included
      result: "The weather in San Francisco is 72°F and sunny.",
    });

    // Final AgentStateMessage
    // expect(legacyEvents[4]).toMatchObject({
    //   type: "AgentStateMessage",
    //   threadId: "test-thread-id",
    //   agentName: "test-agent-id",
    //   active: false,
    // });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/agent/__tests__/subscriber.test.ts
================================================
import { AbstractAgent } from "../agent";
import { AgentSubscriber } from "../subscriber";
import {
  BaseEvent,
  EventType,
  Message,
  RunAgentInput,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  StateSnapshotEvent,
  RunStartedEvent,
  RunFinishedEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  CustomEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";
import { Observable, of, throwError, from } from "rxjs";
import { mergeMap } from "rxjs/operators";

// Mock uuid module
jest.mock("uuid", () => ({
  v4: jest.fn().mockReturnValue("mock-uuid"),
}));

// Mock utils with handling for undefined values
jest.mock("@/utils", () => ({
  structuredClone_: (obj: any) => {
    if (obj === undefined) return undefined;
    const jsonString = JSON.stringify(obj);
    if (jsonString === undefined || jsonString === "undefined") return undefined;
    return JSON.parse(jsonString);
  },
}));

// Mock the verify modules but NOT apply - we want to test against real defaultApplyEvents
jest.mock("@/verify", () => ({
  verifyEvents: jest.fn(() => (source$: Observable<any>) => source$),
}));

jest.mock("@/chunks", () => ({
  transformChunks: jest.fn(() => (source$: Observable<any>) => source$),
}));

// Create a test agent implementation
class TestAgent extends AbstractAgent {
  private eventsToEmit: BaseEvent[] = [];

  setEventsToEmit(events: BaseEvent[]) {
    this.eventsToEmit = events;
  }

  protected run(input: RunAgentInput): Observable<BaseEvent> {
    return of(...this.eventsToEmit);
  }
}

describe("AgentSubscriber", () => {
  let agent: TestAgent;
  let mockSubscriber: AgentSubscriber;

  beforeEach(() => {
    jest.clearAllMocks();

    agent = new TestAgent({
      threadId: "test-thread",
      initialMessages: [
        {
          id: "msg-1",
          role: "user",
          content: "Hello",
        },
      ],
      initialState: { counter: 0 },
    });

    mockSubscriber = {
      onEvent: jest.fn(),
      onRunStartedEvent: jest.fn(),
      onRunFinishedEvent: jest.fn(),
      onTextMessageStartEvent: jest.fn(),
      onTextMessageContentEvent: jest.fn(),
      onTextMessageEndEvent: jest.fn(),
      onToolCallStartEvent: jest.fn(),
      onToolCallArgsEvent: jest.fn(),
      onToolCallEndEvent: jest.fn(),
      onToolCallResultEvent: jest.fn(),
      onCustomEvent: jest.fn(),
      onStateSnapshotEvent: jest.fn(),
      onMessagesChanged: jest.fn(),
      onStateChanged: jest.fn(),
      onNewMessage: jest.fn(),
      onNewToolCall: jest.fn(),
      onRunInitialized: jest.fn(),
      onRunFailed: jest.fn(),
      onRunFinalized: jest.fn(),
    };
  });

  describe("subscribe/unsubscribe functionality", () => {
    it("should allow subscribing and unsubscribing", () => {
      // Initially no subscribers
      expect(agent.subscribers).toHaveLength(0);

      // Subscribe
      const subscription = agent.subscribe(mockSubscriber);
      expect(agent.subscribers).toHaveLength(1);
      expect(agent.subscribers[0]).toBe(mockSubscriber);

      // Unsubscribe
      subscription.unsubscribe();
      expect(agent.subscribers).toHaveLength(0);
    });

    it("should support multiple subscribers", () => {
      const subscriber2: AgentSubscriber = {
        onEvent: jest.fn(),
      };

      agent.subscribe(mockSubscriber);
      agent.subscribe(subscriber2);

      expect(agent.subscribers).toHaveLength(2);
      expect(agent.subscribers[0]).toBe(mockSubscriber);
      expect(agent.subscribers[1]).toBe(subscriber2);
    });

    it("should only remove the specific subscriber on unsubscribe", () => {
      const subscriber2: AgentSubscriber = {
        onEvent: jest.fn(),
      };

      const subscription1 = agent.subscribe(mockSubscriber);
      const subscription2 = agent.subscribe(subscriber2);

      expect(agent.subscribers).toHaveLength(2);

      subscription1.unsubscribe();
      expect(agent.subscribers).toHaveLength(1);
      expect(agent.subscribers[0]).toBe(subscriber2);

      subscription2.unsubscribe();
      expect(agent.subscribers).toHaveLength(0);
    });
  });

  describe("temporary subscribers via runAgent", () => {
    it("should accept a temporary subscriber via runAgent parameter", async () => {
      const temporarySubscriber: AgentSubscriber = {
        onRunStartedEvent: jest.fn(),
        onRunFinishedEvent: jest.fn(),
      };

      const runStartedEvent: RunStartedEvent = {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      };

      const runFinishedEvent: RunFinishedEvent = {
        type: EventType.RUN_FINISHED,
        threadId: "test-thread",
        runId: "test-run",
        result: "test-result",
      };

      agent.setEventsToEmit([runStartedEvent, runFinishedEvent]);

      await agent.runAgent({}, temporarySubscriber);

      // The temporary subscriber should have been called
      expect(temporarySubscriber.onRunStartedEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: runStartedEvent,
          messages: agent.messages,
          state: agent.state,
          agent,
        }),
      );

      expect(temporarySubscriber.onRunFinishedEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: runFinishedEvent,
          result: "test-result",
          messages: agent.messages,
          state: agent.state,
          agent,
        }),
      );
    });

    it("should combine permanent and temporary subscribers", async () => {
      const permanentSubscriber: AgentSubscriber = {
        onRunStartedEvent: jest.fn(),
      };

      const temporarySubscriber: AgentSubscriber = {
        onRunStartedEvent: jest.fn(),
      };

      agent.subscribe(permanentSubscriber);

      const runStartedEvent: RunStartedEvent = {
        type: EventType.RUN_STARTED,
        threadId: "test-thread",
        runId: "test-run",
      };

      agent.setEventsToEmit([runStartedEvent]);

      await agent.runAgent({}, temporarySubscriber);

      // Both subscribers should have been called
      expect(permanentSubscriber.onRunStartedEvent).toHaveBeenCalled();
      expect(temporarySubscriber.onRunStartedEvent).toHaveBeenCalled();
    });
  });

  describe("mutation capabilities", () => {
    it("should allow subscribers to mutate messages", async () => {
      const newMessage: Message = {
        id: "new-msg",
        role: "assistant",
        content: "I was added by subscriber",
      };

      const mutatingSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          messages: [...agent.messages, newMessage],
        }),
        onMessagesChanged: jest.fn(),
      };

      // Emit a dummy event to avoid EmptyError
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test",
          runId: "test",
        } as RunStartedEvent,
      ]);

      await agent.runAgent({}, mutatingSubscriber);

      // Verify the subscriber was called with the initial messages
      expect(mutatingSubscriber.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          messages: [
            {
              id: "msg-1",
              role: "user",
              content: "Hello",
            },
          ],
        }),
      );

      // Verify the agent's messages were updated
      expect(agent.messages).toHaveLength(2);
      expect(agent.messages[1]).toEqual(newMessage);

      // Verify onMessagesChanged was called
      expect(mutatingSubscriber.onMessagesChanged).toHaveBeenCalledWith(
        expect.objectContaining({
          messages: agent.messages,
        }),
      );
    });

    it("should allow subscribers to mutate state", async () => {
      const mutatingSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          state: { counter: 42, newField: "added" },
        }),
        onStateChanged: jest.fn(),
      };

      // Emit a dummy event to avoid EmptyError
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test",
          runId: "test",
        } as RunStartedEvent,
      ]);

      await agent.runAgent({}, mutatingSubscriber);

      // Verify the subscriber was called with the initial state
      expect(mutatingSubscriber.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { counter: 0 },
        }),
      );

      // Verify the agent's state was updated
      expect(agent.state).toEqual({ counter: 42, newField: "added" });

      // Verify onStateChanged was called
      expect(mutatingSubscriber.onStateChanged).toHaveBeenCalledWith(
        expect.objectContaining({
          state: agent.state,
        }),
      );
    });

    it("should allow mutations in event handlers", async () => {
      const stateEvent: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: { newCounter: 100 },
      };

      const mutatingSubscriber: AgentSubscriber = {
        onStateSnapshotEvent: jest.fn().mockReturnValue({
          state: { modifiedBySubscriber: true },
          stopPropagation: true, // Prevent the event from applying its snapshot
        }),
        onStateChanged: jest.fn(),
      };

      agent.setEventsToEmit([stateEvent]);

      await agent.runAgent({}, mutatingSubscriber);

      expect(mutatingSubscriber.onStateSnapshotEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: stateEvent,
        }),
      );

      // State should be updated by the subscriber
      expect(agent.state).toEqual({ modifiedBySubscriber: true });
      expect(mutatingSubscriber.onStateChanged).toHaveBeenCalled();
    });
  });

  describe("stopPropagation functionality", () => {
    it("should stop propagation to subsequent subscribers when stopPropagation is true", async () => {
      const firstSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          stopPropagation: true,
        }),
      };

      const secondSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn(),
      };

      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      // Emit a dummy event to avoid EmptyError
      agent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          threadId: "test",
          runId: "test",
        } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // First subscriber should be called
      expect(firstSubscriber.onRunInitialized).toHaveBeenCalled();

      // Second subscriber should NOT be called due to stopPropagation
      expect(secondSubscriber.onRunInitialized).not.toHaveBeenCalled();
    });

    it("should continue to next subscriber when stopPropagation is false", async () => {
      const firstSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          stopPropagation: false,
        }),
      };

      const secondSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn(),
      };

      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // Both subscribers should be called
      expect(firstSubscriber.onRunInitialized).toHaveBeenCalled();
      expect(secondSubscriber.onRunInitialized).toHaveBeenCalled();
    });

    it("should continue to next subscriber when stopPropagation is undefined", async () => {
      const firstSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({}), // No stopPropagation field
      };

      const secondSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn(),
      };

      agent.subscribe(firstSubscriber);
      agent.subscribe(secondSubscriber);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // Both subscribers should be called
      expect(firstSubscriber.onRunInitialized).toHaveBeenCalled();
      expect(secondSubscriber.onRunInitialized).toHaveBeenCalled();
    });

    it("should stop default behavior on error when stopPropagation is true", async () => {
      const errorHandlingSubscriber: AgentSubscriber = {
        onRunFailed: jest.fn().mockReturnValue({
          stopPropagation: true,
        }),
      };

      // Create an agent that throws an error
      class ErrorAgent extends AbstractAgent {
        protected run(input: RunAgentInput): Observable<BaseEvent> {
          return from([
            {
              type: EventType.RUN_STARTED,
              threadId: input.threadId,
              runId: input.runId,
            } as RunStartedEvent,
          ]).pipe(mergeMap(() => throwError(() => new Error("Test error"))));
        }
      }

      const errorAgent = new ErrorAgent();
      errorAgent.subscribe(errorHandlingSubscriber);

      // Mock console.error to check if it's called
      const consoleErrorSpy = jest.spyOn(console, "error").mockImplementation();

      // This should not throw because the subscriber handles the error
      await expect(errorAgent.runAgent({})).resolves.toBeDefined();

      expect(errorHandlingSubscriber.onRunFailed).toHaveBeenCalledWith(
        expect.objectContaining({
          error: expect.any(Error),
        }),
      );

      // Console.error should NOT be called because subscriber handled the error
      expect(consoleErrorSpy).not.toHaveBeenCalled();

      consoleErrorSpy.mockRestore();
    });

    it("should allow default error behavior when stopPropagation is false", async () => {
      const errorHandlingSubscriber: AgentSubscriber = {
        onRunFailed: jest.fn().mockReturnValue({
          stopPropagation: false,
        }),
      };

      // Create an agent that throws an error
      class ErrorAgent extends AbstractAgent {
        protected run(input: RunAgentInput): Observable<BaseEvent> {
          return from([
            {
              type: EventType.RUN_STARTED,
              threadId: input.threadId,
              runId: input.runId,
            } as RunStartedEvent,
          ]).pipe(mergeMap(() => throwError(() => new Error("Test error"))));
        }
      }

      const errorAgent = new ErrorAgent();
      errorAgent.subscribe(errorHandlingSubscriber);

      // Mock console.error to check if it's called
      const consoleErrorSpy = jest.spyOn(console, "error").mockImplementation();

      // This should throw because the subscriber doesn't stop propagation
      await expect(errorAgent.runAgent({})).rejects.toThrow("Test error");

      expect(errorHandlingSubscriber.onRunFailed).toHaveBeenCalled();

      // Console.error should be called because error propagated
      expect(consoleErrorSpy).toHaveBeenCalledWith("Agent execution failed:", expect.any(Error));

      consoleErrorSpy.mockRestore();
    });
  });

  describe("subscriber order and chaining", () => {
    it("should call subscribers in the order they were added", async () => {
      const callOrder: string[] = [];

      const subscriber1: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("subscriber1");
        }),
      };

      const subscriber2: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("subscriber2");
        }),
      };

      const subscriber3: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("subscriber3");
        }),
      };

      agent.subscribe(subscriber1);
      agent.subscribe(subscriber2);
      agent.subscribe(subscriber3);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      expect(callOrder).toEqual(["subscriber1", "subscriber2", "subscriber3"]);
    });

    it("should pass mutations from one subscriber to the next", async () => {
      const subscriber1: AgentSubscriber = {
        onRunInitialized: jest.fn().mockReturnValue({
          state: { step: 1 },
        }),
      };

      const subscriber2: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation((params) => {
          // Should receive the state modified by subscriber1
          expect(params.state).toEqual({ step: 1 });
          return {
            state: { step: 2 },
          };
        }),
      };

      const subscriber3: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation((params) => {
          // Should receive the state modified by subscriber2
          expect(params.state).toEqual({ step: 2 });
          return {
            state: { step: 3 },
          };
        }),
      };

      agent.subscribe(subscriber1);
      agent.subscribe(subscriber2);
      agent.subscribe(subscriber3);

      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      // Final state should reflect all mutations
      expect(agent.state).toEqual({ step: 3 });

      expect(subscriber1.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { counter: 0 }, // Original state
        }),
      );

      expect(subscriber2.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { step: 1 }, // Modified by subscriber1
        }),
      );

      expect(subscriber3.onRunInitialized).toHaveBeenCalledWith(
        expect.objectContaining({
          state: { step: 2 }, // Modified by subscriber2
        }),
      );
    });
  });

  describe("event-specific callbacks", () => {
    it("should call specific event callbacks with correct parameters", async () => {
      const textStartEvent: TextMessageStartEvent = {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "test-msg",
        role: "assistant",
      };

      const textContentEvent: TextMessageContentEvent = {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "test-msg",
        delta: "Hello",
      };

      const specificSubscriber: AgentSubscriber = {
        onTextMessageStartEvent: jest.fn(),
        onTextMessageContentEvent: jest.fn(),
      };

      agent.subscribe(specificSubscriber);
      agent.setEventsToEmit([textStartEvent, textContentEvent]);

      await agent.runAgent({});

      expect(specificSubscriber.onTextMessageStartEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: textStartEvent,
          messages: [{ content: "Hello", id: "msg-1", role: "user" }], // Pre-mutation state
          state: { counter: 0 }, // Pre-mutation state
          agent,
        }),
      );

      expect(specificSubscriber.onTextMessageContentEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: textContentEvent,
          textMessageBuffer: "", // Empty - buffer before current delta is applied
          messages: expect.arrayContaining([
            expect.objectContaining({ content: "Hello", id: "msg-1", role: "user" }),
            expect.objectContaining({ content: "", id: "test-msg", role: "assistant" }), // Message before delta applied
          ]),
          state: { counter: 0 },
          agent,
        }),
      );
    });

    it("should call generic onEvent callback for all events", async () => {
      const events: BaseEvent[] = [
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "test-msg",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.STATE_SNAPSHOT,
          snapshot: { test: true },
        } as StateSnapshotEvent,
      ];

      const genericSubscriber: AgentSubscriber = {
        onEvent: jest.fn(),
      };

      agent.subscribe(genericSubscriber);
      agent.setEventsToEmit(events);

      await agent.runAgent({});

      expect(genericSubscriber.onEvent).toHaveBeenCalledTimes(2);
      expect(genericSubscriber.onEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          event: events[0],
        }),
      );
      expect(genericSubscriber.onEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          event: events[1],
        }),
      );
    });
  });

  describe("lifecycle callbacks", () => {
    it("should call lifecycle callbacks in correct order", async () => {
      const callOrder: string[] = [];

      const lifecycleSubscriber: AgentSubscriber = {
        onRunInitialized: jest.fn().mockImplementation(() => {
          callOrder.push("initialized");
        }),
        onRunFinalized: jest.fn().mockImplementation(() => {
          callOrder.push("finalized");
        }),
      };

      agent.subscribe(lifecycleSubscriber);
      agent.setEventsToEmit([
        { type: EventType.RUN_STARTED, threadId: "test", runId: "test" } as RunStartedEvent,
      ]);

      await agent.runAgent({});

      expect(callOrder).toEqual(["initialized", "finalized"]);
    });

    it("should call onRunFinalized even after errors", async () => {
      const lifecycleSubscriber: AgentSubscriber = {
        onRunFailed: jest.fn().mockReturnValue({
          stopPropagation: true, // Handle the error
        }),
        onRunFinalized: jest.fn(),
      };

      // Create an agent that throws an error
      class ErrorAgent extends AbstractAgent {
        protected run(input: RunAgentInput): Observable<BaseEvent> {
          return from([
            {
              type: EventType.RUN_STARTED,
              threadId: input.threadId,
              runId: input.runId,
            } as RunStartedEvent,
          ]).pipe(mergeMap(() => throwError(() => new Error("Test error"))));
        }
      }

      const errorAgent = new ErrorAgent();
      errorAgent.subscribe(lifecycleSubscriber);

      await errorAgent.runAgent({});

      expect(lifecycleSubscriber.onRunFailed).toHaveBeenCalled();
      expect(lifecycleSubscriber.onRunFinalized).toHaveBeenCalled();
    });
  });

  describe("Tool Call Tests", () => {
    test("should handle tool call events with proper buffer accumulation", async () => {
      // Create agent that emits tool call sequence
      const toolCallAgent = new TestAgent();
      toolCallAgent.subscribe(mockSubscriber);
      toolCallAgent.setEventsToEmit([
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-123",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-123",
          delta: '{"query": "te',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-123",
          delta: 'st"}',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_END,
          toolCallId: "call-123",
        } as ToolCallEndEvent,
      ]);

      await toolCallAgent.runAgent({});

      // Verify tool call events were called
      expect(mockSubscriber.onToolCallStartEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: expect.objectContaining({
            type: EventType.TOOL_CALL_START,
            toolCallId: "call-123",
            toolCallName: "search",
          }),
          messages: [],
          state: {},
          agent: toolCallAgent,
        }),
      );

      // Check buffer accumulation
      expect(mockSubscriber.onToolCallArgsEvent).toHaveBeenCalledTimes(2);

      // First call should have empty buffer (before first delta applied)
      expect(mockSubscriber.onToolCallArgsEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          toolCallBuffer: "",
          toolCallName: "search",
          partialToolCallArgs: "", // Empty string when buffer is empty
        }),
      );

      // Second call should have partial buffer (before second delta applied)
      expect(mockSubscriber.onToolCallArgsEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          toolCallBuffer: '{"query": "te',
          toolCallName: "search",
          partialToolCallArgs: '{"query": "te"}', // untruncateJson returns truncated JSON string
        }),
      );

      expect(mockSubscriber.onToolCallEndEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          toolCallName: "search",
          toolCallArgs: { query: "test" },
        }),
      );

      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledWith(
        expect.objectContaining({
          toolCall: {
            id: "call-123",
            type: "function",
            function: {
              name: "search",
              arguments: '{"query": "test"}',
            },
          },
        }),
      );
    });
  });

  describe("Buffer Accumulation Tests", () => {
    test("should properly accumulate text message buffer", async () => {
      const textAgent = new TestAgent();
      textAgent.subscribe(mockSubscriber);
      textAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "Hello",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: " ",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "World",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
      ]);

      await textAgent.runAgent({});

      // Verify buffer accumulation
      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenCalledTimes(3);

      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          textMessageBuffer: "", // First event: no content accumulated yet
        }),
      );

      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          textMessageBuffer: "Hello", // Second event: content from first event
        }),
      );

      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        3,
        expect.objectContaining({
          textMessageBuffer: "Hello ", // Third event: content from first + second events
        }),
      );

      expect(mockSubscriber.onTextMessageEndEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          textMessageBuffer: "Hello World",
        }),
      );
    });

    test("should reset text buffer on new message", async () => {
      const multiMessageAgent = new TestAgent();
      multiMessageAgent.subscribe(mockSubscriber);
      multiMessageAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "First",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-2",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-2",
          delta: "Second",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-2",
        } as TextMessageEndEvent,
      ]);

      await multiMessageAgent.runAgent({});

      // Check first message
      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        1,
        expect.objectContaining({
          textMessageBuffer: "", // First message, first content: no content accumulated yet
        }),
      );

      // Check second message (buffer should reset)
      expect(mockSubscriber.onTextMessageContentEvent).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          textMessageBuffer: "", // Second message, first content: buffer reset, no content accumulated yet
        }),
      );
    });
  });

  describe("Message and Tool Call Lifecycle Tests", () => {
    test("should call onNewMessage after text message completion", async () => {
      const textAgent = new TestAgent();
      textAgent.subscribe(mockSubscriber);
      textAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "Test message",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
      ]);

      await textAgent.runAgent({});

      expect(mockSubscriber.onNewMessage).toHaveBeenCalledWith(
        expect.objectContaining({
          message: expect.objectContaining({
            id: "msg-1",
            role: "assistant",
            content: "Test message",
          }),
        }),
      );
    });

    test("should call onNewToolCall after tool call completion", async () => {
      const toolCallAgent = new TestAgent();
      toolCallAgent.subscribe(mockSubscriber);
      toolCallAgent.setEventsToEmit([
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-123",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-123",
          delta: '{"query": "test"}',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_END,
          toolCallId: "call-123",
        } as ToolCallEndEvent,
      ]);

      await toolCallAgent.runAgent({});

      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledWith(
        expect.objectContaining({
          toolCall: {
            id: "call-123",
            type: "function",
            function: {
              name: "search",
              arguments: '{"query": "test"}',
            },
          },
        }),
      );
    });
  });

  describe("Custom Event Tests", () => {
    test("should handle custom events", async () => {
      const customAgent = new TestAgent();
      customAgent.subscribe(mockSubscriber);
      customAgent.setEventsToEmit([
        {
          type: EventType.CUSTOM,
          name: "user_interaction",
          data: { action: "click", target: "button" },
        } as CustomEvent,
      ]);

      await customAgent.runAgent({});

      expect(mockSubscriber.onCustomEvent).toHaveBeenCalledWith(
        expect.objectContaining({
          event: expect.objectContaining({
            type: EventType.CUSTOM,
            name: "user_interaction",
            data: { action: "click", target: "button" },
          }),
          messages: [],
          state: {},
          agent: customAgent,
        }),
      );
    });
  });

  describe("Subscriber Error Handling", () => {
    test("should handle errors in subscriber callbacks gracefully", async () => {
      const errorSubscriber = {
        onEvent: jest.fn().mockImplementation(() => {
          // Return stopPropagation to handle the error gracefully
          throw new Error("Subscriber error");
        }),
        onTextMessageStartEvent: jest.fn().mockImplementation(() => {
          throw new Error("Sync subscriber error");
        }),
      };

      // Add a working subscriber to ensure others still work
      const workingSubscriber = {
        onEvent: jest.fn(),
        onTextMessageStartEvent: jest.fn(),
      };

      const testAgent = new TestAgent();
      testAgent.subscribe(errorSubscriber);
      testAgent.subscribe(workingSubscriber);
      testAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
      ]);

      // Should not throw despite subscriber errors
      await expect(testAgent.runAgent({})).resolves.toBeDefined();

      expect(errorSubscriber.onEvent).toHaveBeenCalled();
      expect(errorSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
      expect(workingSubscriber.onEvent).toHaveBeenCalled();
      expect(workingSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
    });

    test("should continue processing other subscribers when one fails", async () => {
      const errorSubscriber = {
        onTextMessageStartEvent: jest.fn().mockImplementation(() => {
          throw new Error("First subscriber error");
        }),
      };

      const workingSubscriber = {
        onTextMessageStartEvent: jest.fn().mockResolvedValue(undefined),
      };

      const testAgent = new TestAgent();
      testAgent.subscribe(errorSubscriber);
      testAgent.subscribe(workingSubscriber);
      testAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
      ]);

      await testAgent.runAgent({});

      expect(errorSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
      expect(workingSubscriber.onTextMessageStartEvent).toHaveBeenCalled();
    });
  });

  describe("Realistic Event Sequences", () => {
    test("should handle a realistic conversation with mixed events", async () => {
      const realisticAgent = new TestAgent();
      realisticAgent.subscribe(mockSubscriber);
      realisticAgent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          runId: "run-123",
        } as RunStartedEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-1",
          delta: "Let me search for that information.",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-1",
        } as TextMessageEndEvent,
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-1",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: "call-1",
          delta: '{"query": "weather today"}',
        } as ToolCallArgsEvent,
        {
          type: EventType.TOOL_CALL_END,
          toolCallId: "call-1",
        } as ToolCallEndEvent,
        {
          type: EventType.TOOL_CALL_RESULT,
          toolCallId: "call-1",
          content: "Sunny, 75°F",
          messageId: "result-1",
        } as ToolCallResultEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-2",
          role: "assistant",
        } as TextMessageStartEvent,
        {
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: "msg-2",
          delta: "The weather today is sunny and 75°F.",
        } as TextMessageContentEvent,
        {
          type: EventType.TEXT_MESSAGE_END,
          messageId: "msg-2",
        } as TextMessageEndEvent,
        {
          type: EventType.STATE_SNAPSHOT,
          state: { weather: "sunny" },
        } as StateSnapshotEvent,
        {
          type: EventType.RUN_FINISHED,
          runId: "run-123",
          result: "success",
        } as RunFinishedEvent,
      ]);

      await realisticAgent.runAgent({});

      // Verify complete sequence was processed
      expect(mockSubscriber.onRunStartedEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onTextMessageStartEvent).toHaveBeenCalledTimes(2);
      expect(mockSubscriber.onTextMessageEndEvent).toHaveBeenCalledTimes(2);
      expect(mockSubscriber.onToolCallStartEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onToolCallEndEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onToolCallResultEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onStateSnapshotEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onRunFinishedEvent).toHaveBeenCalledTimes(1);
      expect(mockSubscriber.onNewMessage).toHaveBeenCalledTimes(3); // 2 TEXT_MESSAGE_END + 1 TOOL_CALL_RESULT
      expect(mockSubscriber.onNewToolCall).toHaveBeenCalledTimes(1);
    });
  });

  describe("Advanced Mutation Tests", () => {
    test("should handle mutations with stopPropagation in tool call events", async () => {
      const mutatingSubscriber = {
        onToolCallStartEvent: jest.fn().mockResolvedValue({
          state: { toolCallBlocked: true },
          stopPropagation: true,
        }),
      };

      const secondSubscriber = {
        onToolCallStartEvent: jest.fn(),
      };

      const toolCallAgent = new TestAgent();
      toolCallAgent.subscribe(mutatingSubscriber);
      toolCallAgent.subscribe(secondSubscriber);
      toolCallAgent.setEventsToEmit([
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-123",
          toolCallName: "search",
        } as ToolCallStartEvent,
      ]);

      await toolCallAgent.runAgent({});

      expect(mutatingSubscriber.onToolCallStartEvent).toHaveBeenCalled();
      expect(secondSubscriber.onToolCallStartEvent).not.toHaveBeenCalled();
    });

    test("should accumulate mutations across multiple event types", async () => {
      let messageCount = 0;
      let stateUpdates = 0;

      const trackingSubscriber = {
        onTextMessageStartEvent: jest.fn().mockImplementation(() => {
          messageCount++;
          return { state: { messageCount } };
        }),
        onToolCallStartEvent: jest.fn().mockImplementation(() => {
          stateUpdates++;
          return { state: { stateUpdates } };
        }),
      };

      const mixedAgent = new TestAgent();
      mixedAgent.subscribe(mockSubscriber);
      mixedAgent.subscribe(trackingSubscriber);
      mixedAgent.setEventsToEmit([
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-1",
        } as TextMessageStartEvent,
        {
          type: EventType.TOOL_CALL_START,
          toolCallId: "call-1",
          toolCallName: "search",
        } as ToolCallStartEvent,
        {
          type: EventType.TEXT_MESSAGE_START,
          messageId: "msg-2",
        } as TextMessageStartEvent,
      ]);

      await mixedAgent.runAgent({});

      expect(trackingSubscriber.onTextMessageStartEvent).toHaveBeenCalledTimes(2);
      expect(trackingSubscriber.onToolCallStartEvent).toHaveBeenCalledTimes(1);
    });
  });

  describe("EmptyError Bug Reproduction", () => {
    test("should demonstrate EmptyError with STEP_STARTED/STEP_FINISHED events that cause no mutations", async () => {
      const emptyAgent = new TestAgent();

      // No subscribers that return mutations
      emptyAgent.setEventsToEmit([
        {
          type: EventType.RUN_STARTED,
          runId: "run-123",
        } as RunStartedEvent,
        {
          type: EventType.STEP_STARTED,
          stepName: "step-1",
        } as StepStartedEvent,
        {
          type: EventType.STEP_FINISHED,
          stepName: "step-1",
        } as StepFinishedEvent,
        {
          type: EventType.RUN_FINISHED,
          runId: "run-123",
        } as RunFinishedEvent,
      ]);

      // This should throw EmptyError because:
      // 1. STEP_STARTED and STEP_FINISHED have no default behavior (don't modify messages/state)
      // 2. No subscribers return mutations
      // 3. ALL calls to emitUpdates() return EMPTY
      // 4. Observable completes without emitting anything
      await expect(emptyAgent.runAgent({}));
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/default.ts
================================================
import {
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  Message,
  DeveloperMessage,
  SystemMessage,
  AssistantMessage,
  UserMessage,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
  CustomEvent,
  BaseEvent,
  ToolCallResultEvent,
  ToolMessage,
  RunAgentInput,
  TextMessageEndEvent,
  ToolCallEndEvent,
  RawEvent,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";
import { mergeMap, mergeAll, defaultIfEmpty, concatMap } from "rxjs/operators";
import { of, EMPTY } from "rxjs";
import { structuredClone_ } from "../utils";
import { applyPatch } from "fast-json-patch";
import {
  AgentStateMutation,
  AgentSubscriber,
  runSubscribersWithMutation,
} from "@/agent/subscriber";
import { Observable } from "rxjs";
import { AbstractAgent } from "@/agent/agent";
import untruncateJson from "untruncate-json";

export const defaultApplyEvents = (
  input: RunAgentInput,
  events$: Observable<BaseEvent>,
  agent: AbstractAgent,
  subscribers: AgentSubscriber[],
): Observable<AgentStateMutation> => {
  let messages = structuredClone_(input.messages);
  let state = structuredClone_(input.state);
  let currentMutation: AgentStateMutation = {};

  const applyMutation = (mutation: AgentStateMutation) => {
    if (mutation.messages !== undefined) {
      messages = mutation.messages;
      currentMutation.messages = mutation.messages;
    }
    if (mutation.state !== undefined) {
      state = mutation.state;
      currentMutation.state = mutation.state;
    }
  };

  const emitUpdates = () => {
    const result = structuredClone_(currentMutation) as AgentStateMutation;
    currentMutation = {};
    if (result.messages !== undefined || result.state !== undefined) {
      return of(result);
    }
    return EMPTY;
  };

  return events$.pipe(
    concatMap(async (event) => {
      const mutation = await runSubscribersWithMutation(
        subscribers,
        messages,
        state,
        (subscriber, messages, state) =>
          subscriber.onEvent?.({ event, agent, input, messages, state }),
      );
      applyMutation(mutation);

      if (mutation.stopPropagation === true) {
        return emitUpdates();
      }

      switch (event.type) {
        case EventType.TEXT_MESSAGE_START: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onTextMessageStartEvent?.({
                event: event as TextMessageStartEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { messageId, role = "assistant" } = event as TextMessageStartEvent;

            // Create a new message using properties from the event
            // Text messages can be developer, system, assistant, or user (not tool)
            const newMessage: Message = {
              id: messageId,
              role: role,
              content: "",
            };

            // Add the new message to the messages array
            messages.push(newMessage);
            applyMutation({ messages });
          }
          return emitUpdates();
        }

        case EventType.TEXT_MESSAGE_CONTENT: {
          const { messageId, delta } = event as TextMessageContentEvent;

          // Find the target message by ID
          const targetMessage = messages.find((m) => m.id === messageId);
          if (!targetMessage) {
            console.warn(`TEXT_MESSAGE_CONTENT: No message found with ID '${messageId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onTextMessageContentEvent?.({
                event: event as TextMessageContentEvent,
                messages,
                state,
                agent,
                input,
                textMessageBuffer: targetMessage.content ?? "",
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            // Append content to the correct message by ID
            targetMessage.content = (targetMessage.content || "") + delta;
            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.TEXT_MESSAGE_END: {
          const { messageId } = event as TextMessageEndEvent;

          // Find the target message by ID
          const targetMessage = messages.find((m) => m.id === messageId);
          if (!targetMessage) {
            console.warn(`TEXT_MESSAGE_END: No message found with ID '${messageId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onTextMessageEndEvent?.({
                event: event as TextMessageEndEvent,
                messages,
                state,
                agent,
                input,
                textMessageBuffer: targetMessage.content ?? "",
              }),
          );
          applyMutation(mutation);

          await Promise.all(
            subscribers.map((subscriber) => {
              subscriber.onNewMessage?.({
                message: targetMessage,
                messages,
                state,
                agent,
                input,
              });
            }),
          );

          return emitUpdates();
        }

        case EventType.TOOL_CALL_START: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onToolCallStartEvent?.({
                event: event as ToolCallStartEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { toolCallId, toolCallName, parentMessageId } = event as ToolCallStartEvent;

            let targetMessage: AssistantMessage;

            // Use last message if parentMessageId exists, we have messages, and the parentMessageId matches the last message's id
            if (
              parentMessageId &&
              messages.length > 0 &&
              messages[messages.length - 1].id === parentMessageId
            ) {
              targetMessage = messages[messages.length - 1] as AssistantMessage;
            } else {
              // Create a new message otherwise
              targetMessage = {
                id: parentMessageId || toolCallId,
                role: "assistant",
                toolCalls: [],
              };
              messages.push(targetMessage);
            }

            targetMessage.toolCalls ??= [];

            // Add the new tool call
            targetMessage.toolCalls.push({
              id: toolCallId,
              type: "function",
              function: {
                name: toolCallName,
                arguments: "",
              },
            });

            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.TOOL_CALL_ARGS: {
          const { toolCallId, delta } = event as ToolCallArgsEvent;

          // Find the message containing this tool call
          const targetMessage = messages.find((m) =>
            (m as AssistantMessage).toolCalls?.some((tc) => tc.id === toolCallId),
          ) as AssistantMessage;

          if (!targetMessage) {
            console.warn(
              `TOOL_CALL_ARGS: No message found containing tool call with ID '${toolCallId}'`,
            );
            return emitUpdates();
          }

          // Find the specific tool call
          const targetToolCall = targetMessage.toolCalls!.find((tc) => tc.id === toolCallId);
          if (!targetToolCall) {
            console.warn(`TOOL_CALL_ARGS: No tool call found with ID '${toolCallId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) => {
              const toolCallBuffer = targetToolCall.function.arguments;
              const toolCallName = targetToolCall.function.name;
              let partialToolCallArgs = {};
              try {
                // Parse from toolCallBuffer only (before current delta is applied)
                partialToolCallArgs = untruncateJson(toolCallBuffer);
              } catch (error) {}

              return subscriber.onToolCallArgsEvent?.({
                event: event as ToolCallArgsEvent,
                messages,
                state,
                agent,
                input,
                toolCallBuffer,
                toolCallName,
                partialToolCallArgs,
              });
            },
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            // Append the arguments to the correct tool call by ID
            targetToolCall.function.arguments += delta;
            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.TOOL_CALL_END: {
          const { toolCallId } = event as ToolCallEndEvent;

          // Find the message containing this tool call
          const targetMessage = messages.find((m) =>
            (m as AssistantMessage).toolCalls?.some((tc) => tc.id === toolCallId),
          ) as AssistantMessage;

          if (!targetMessage) {
            console.warn(
              `TOOL_CALL_END: No message found containing tool call with ID '${toolCallId}'`,
            );
            return emitUpdates();
          }

          // Find the specific tool call
          const targetToolCall = targetMessage.toolCalls!.find((tc) => tc.id === toolCallId);
          if (!targetToolCall) {
            console.warn(`TOOL_CALL_END: No tool call found with ID '${toolCallId}'`);
            return emitUpdates();
          }

          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) => {
              const toolCallArgsString = targetToolCall.function.arguments;
              const toolCallName = targetToolCall.function.name;
              let toolCallArgs = {};
              try {
                toolCallArgs = JSON.parse(toolCallArgsString);
              } catch (error) {}
              return subscriber.onToolCallEndEvent?.({
                event: event as ToolCallEndEvent,
                messages,
                state,
                agent,
                input,
                toolCallName,
                toolCallArgs,
              });
            },
          );
          applyMutation(mutation);

          await Promise.all(
            subscribers.map((subscriber) => {
              subscriber.onNewToolCall?.({
                toolCall: targetToolCall,
                messages,
                state,
                agent,
                input,
              });
            }),
          );

          return emitUpdates();
        }

        case EventType.TOOL_CALL_RESULT: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onToolCallResultEvent?.({
                event: event as ToolCallResultEvent,
                messages,
                state,
                agent,
                input,
              }),
          );

          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { messageId, toolCallId, content, role } = event as ToolCallResultEvent;

            const toolMessage: ToolMessage = {
              id: messageId,
              toolCallId,
              role: role || "tool",
              content: content,
            };

            messages.push(toolMessage);

            await Promise.all(
              subscribers.map((subscriber) => {
                subscriber.onNewMessage?.({
                  message: toolMessage,
                  messages,
                  state,
                  agent,
                  input,
                });
              }),
            );

            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.STATE_SNAPSHOT: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStateSnapshotEvent?.({
                event: event as StateSnapshotEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { snapshot } = event as StateSnapshotEvent;

            // Replace state with the literal snapshot
            state = snapshot;

            applyMutation({ state });
          }

          return emitUpdates();
        }

        case EventType.STATE_DELTA: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStateDeltaEvent?.({
                event: event as StateDeltaEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { delta } = event as StateDeltaEvent;

            try {
              // Apply the JSON Patch operations to the current state without mutating the original
              const result = applyPatch(state, delta, true, false);
              state = result.newDocument;
              applyMutation({ state });
            } catch (error: unknown) {
              const errorMessage = error instanceof Error ? error.message : String(error);
              console.warn(
                `Failed to apply state patch:\n` +
                  `Current state: ${JSON.stringify(state, null, 2)}\n` +
                  `Patch operations: ${JSON.stringify(delta, null, 2)}\n` +
                  `Error: ${errorMessage}`,
              );
              // If patch failed, only emit updates if there were subscriber mutations
              // This prevents emitting updates when both patch fails AND no subscriber mutations
            }
          }

          return emitUpdates();
        }

        case EventType.MESSAGES_SNAPSHOT: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onMessagesSnapshotEvent?.({
                event: event as MessagesSnapshotEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          if (mutation.stopPropagation !== true) {
            const { messages: newMessages } = event as MessagesSnapshotEvent;

            // Replace messages with the snapshot
            messages = newMessages;

            applyMutation({ messages });
          }

          return emitUpdates();
        }

        case EventType.RAW: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRawEvent?.({
                event: event as RawEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.CUSTOM: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onCustomEvent?.({
                event: event as CustomEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.RUN_STARTED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRunStartedEvent?.({
                event: event as RunStartedEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.RUN_FINISHED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRunFinishedEvent?.({
                event: event as RunFinishedEvent,
                messages,
                state,
                agent,
                input,
                result: (event as RunFinishedEvent).result,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.RUN_ERROR: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onRunErrorEvent?.({
                event: event as RunErrorEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.STEP_STARTED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStepStartedEvent?.({
                event: event as StepStartedEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.STEP_FINISHED: {
          const mutation = await runSubscribersWithMutation(
            subscribers,
            messages,
            state,
            (subscriber, messages, state) =>
              subscriber.onStepFinishedEvent?.({
                event: event as StepFinishedEvent,
                messages,
                state,
                agent,
                input,
              }),
          );
          applyMutation(mutation);

          return emitUpdates();
        }

        case EventType.TEXT_MESSAGE_CHUNK: {
          throw new Error("TEXT_MESSAGE_CHUNK must be tranformed before being applied");
        }

        case EventType.TOOL_CALL_CHUNK: {
          throw new Error("TOOL_CALL_CHUNK must be tranformed before being applied");
        }

        case EventType.THINKING_START: {
          return emitUpdates();
        }

        case EventType.THINKING_END: {
          return emitUpdates();
        }

        case EventType.THINKING_TEXT_MESSAGE_START: {
          return emitUpdates();
        }

        case EventType.THINKING_TEXT_MESSAGE_CONTENT: {
          return emitUpdates();
        }

        case EventType.THINKING_TEXT_MESSAGE_END: {
          return emitUpdates();
        }
      }

      // This makes TypeScript check that the switch is exhaustive
      // If a new EventType is added, this will cause a compile error
      const _exhaustiveCheck: never = event.type;
      return emitUpdates();
    }),
    mergeAll(),
    // Only use defaultIfEmpty when there are subscribers to avoid emitting empty updates
    // when patches fail and there are no subscribers (like in state patching test)
    subscribers.length > 0 ? defaultIfEmpty({} as AgentStateMutation) : (stream: any) => stream,
  );
};



================================================
FILE: typescript-sdk/packages/client/src/apply/index.ts
================================================
export { defaultApplyEvents } from "./default";



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.concurrent.test.ts
================================================
import { Subject } from "rxjs";
import { toArray } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { defaultApplyEvents } from "../default";
import {
  BaseEvent,
  EventType,
  RunAgentInput,
  RunStartedEvent,
  RunFinishedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  Message,
  AssistantMessage,
} from "@ag-ui/core";
import { AbstractAgent } from "../../agent";

// Mock agent for testing
const FAKE_AGENT = {
  messages: [],
  state: {},
  agentId: "test-agent",
} as unknown as AbstractAgent;

describe("defaultApplyEvents concurrent operations", () => {
  // Test: Concurrent text messages should create separate messages
  it("should handle concurrent text messages correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for concurrent text messages
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start two concurrent text messages
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
      role: "assistant",
    } as TextMessageStartEvent);

    // Send content for both messages
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "First message content",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Second message content",
    } as TextMessageContentEvent);

    // End messages in reverse order
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Verify we have the expected number of state updates
    expect(stateUpdates.length).toBeGreaterThan(0);

    // Check final state has both messages
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify messages have correct IDs and content
    const msg1 = finalState.messages?.find((m) => m.id === "msg1");
    const msg2 = finalState.messages?.find((m) => m.id === "msg2");

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.content).toBe("First message content");
    expect(msg2?.content).toBe("Second message content");
    expect(msg1?.role).toBe("assistant");
    expect(msg2?.role).toBe("assistant");
  });

  // Test: Concurrent tool calls should create separate tool calls
  it("should handle concurrent tool calls correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for concurrent tool calls
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start two concurrent tool calls
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: "msg1",
    } as ToolCallStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
      parentMessageId: "msg2",
    } as ToolCallStartEvent);

    // Send args for both tool calls
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test search"}',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);

    // End tool calls in reverse order
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Verify we have the expected number of state updates
    expect(stateUpdates.length).toBeGreaterThan(0);

    // Check final state has both messages with tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify tool calls are properly attached to messages
    const msg1 = finalState.messages?.find((m) => m.id === "msg1") as AssistantMessage;
    const msg2 = finalState.messages?.find((m) => m.id === "msg2") as AssistantMessage;

    expect(msg1).toBeDefined();
    expect(msg2).toBeDefined();
    expect(msg1?.toolCalls?.length).toBe(1);
    expect(msg2?.toolCalls?.length).toBe(1);

    // Verify tool call details
    expect(msg1.toolCalls?.[0]?.id).toBe("tool1");
    expect(msg1.toolCalls?.[0]?.function.name).toBe("search");
    expect(msg1.toolCalls?.[0]?.function.arguments).toBe('{"query":"test search"}');

    expect(msg2.toolCalls?.[0]?.id).toBe("tool2");
    expect(msg2.toolCalls?.[0]?.function.name).toBe("calculate");
    expect(msg2.toolCalls?.[0]?.function.arguments).toBe('{"expression":"1+1"}');
  });

  // Test: Mixed concurrent messages and tool calls
  it("should handle mixed concurrent text messages and tool calls", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send mixed concurrent events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start a text message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "thinking_msg",
      role: "assistant",
    } as TextMessageStartEvent);

    // Start a tool call while message is active
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "search_tool",
      toolCallName: "web_search",
      parentMessageId: "tool_msg",
    } as ToolCallStartEvent);

    // Add content to text message
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "thinking_msg",
      delta: "Let me search for that information...",
    } as TextMessageContentEvent);

    // Add args to tool call
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "search_tool",
      delta: '{"query":"concurrent events"}',
    } as ToolCallArgsEvent);

    // Start another text message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "status_msg",
      role: "assistant",
    } as TextMessageStartEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "status_msg",
      delta: "Processing your request...",
    } as TextMessageContentEvent);

    // End everything in mixed order
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "thinking_msg",
    } as TextMessageEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "search_tool",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "status_msg",
    } as TextMessageEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(3);

    // Verify all messages are present
    const thinkingMsg = finalState.messages?.find((m) => m.id === "thinking_msg");
    const toolMsg = finalState.messages?.find((m) => m.id === "tool_msg") as AssistantMessage;
    const statusMsg = finalState.messages?.find((m) => m.id === "status_msg");

    expect(thinkingMsg).toBeDefined();
    expect(toolMsg).toBeDefined();
    expect(statusMsg).toBeDefined();

    expect(thinkingMsg?.content).toBe("Let me search for that information...");
    expect(statusMsg?.content).toBe("Processing your request...");
    expect(toolMsg?.toolCalls?.length).toBe(1);
    expect(toolMsg.toolCalls?.[0]?.function.name).toBe("web_search");
  });

  // Test: Multiple tool calls on the same message
  it("should handle multiple tool calls on the same parent message", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();

    // Create initial state with an existing message
    const parentMessageId = "parent_msg";
    const initialState: RunAgentInput = {
      messages: [
        {
          id: parentMessageId,
          role: "assistant",
          content: "I'll help you with multiple tools.",
          toolCalls: [],
        },
      ],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for multiple tool calls on the same message
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start multiple tool calls concurrently with the same parent message
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool3",
      toolCallName: "format",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);

    // Send args for all tool calls
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"2*3"}',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool3",
      delta: '{"format":"json"}',
    } as ToolCallArgsEvent);

    // End all tool calls
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool3",
    } as ToolCallEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state - should still have only one message with 3 tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(1);

    const parentMsg = finalState.messages?.[0] as AssistantMessage;
    expect(parentMsg.id).toBe(parentMessageId);
    expect(parentMsg.toolCalls?.length).toBe(3);

    // Verify all tool calls are present
    const toolCallIds = parentMsg.toolCalls?.map((tc) => tc.id).sort();
    expect(toolCallIds).toEqual(["tool1", "tool2", "tool3"]);

    // Verify tool call details
    const searchTool = parentMsg.toolCalls?.find((tc) => tc.id === "tool1");
    const calcTool = parentMsg.toolCalls?.find((tc) => tc.id === "tool2");
    const formatTool = parentMsg.toolCalls?.find((tc) => tc.id === "tool3");

    expect(searchTool?.function.name).toBe("search");
    expect(calcTool?.function.name).toBe("calculate");
    expect(formatTool?.function.name).toBe("format");

    expect(searchTool?.function.arguments).toBe('{"query":"test"}');
    expect(calcTool?.function.arguments).toBe('{"expression":"2*3"}');
    expect(formatTool?.function.arguments).toBe('{"format":"json"}');
  });

  // Test: High-frequency concurrent events
  it("should handle high-frequency concurrent events", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Create many concurrent messages and tool calls
    const numMessages = 10;
    const numToolCalls = 10;

    // Start all messages
    for (let i = 0; i < numMessages; i++) {
      events$.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg${i}`,
        role: "assistant",
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events$.next({
        type: EventType.TOOL_CALL_START,
        toolCallId: `tool${i}`,
        toolCallName: `tool_${i}`,
        parentMessageId: `tool_msg${i}`,
      } as ToolCallStartEvent);
    }

    // Send content for all messages
    for (let i = 0; i < numMessages; i++) {
      events$.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg${i}`,
        delta: `Content for message ${i}`,
      } as TextMessageContentEvent);
    }

    // Send args for all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      events$.next({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: `tool${i}`,
        delta: `{"param${i}":"value${i}"}`,
      } as ToolCallArgsEvent);
    }

    // End all in reverse order
    for (let i = numMessages - 1; i >= 0; i--) {
      events$.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg${i}`,
      } as TextMessageEndEvent);
    }

    for (let i = numToolCalls - 1; i >= 0; i--) {
      events$.next({
        type: EventType.TOOL_CALL_END,
        toolCallId: `tool${i}`,
      } as ToolCallEndEvent);
    }

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state
    const finalState = stateUpdates[stateUpdates.length - 1];

    // Should have numMessages + numToolCalls messages total
    expect(finalState.messages?.length).toBe(numMessages + numToolCalls);

    // Verify all text messages are present with correct content
    for (let i = 0; i < numMessages; i++) {
      const msg = finalState.messages?.find((m) => m.id === `msg${i}`);
      expect(msg).toBeDefined();
      expect(msg?.content).toBe(`Content for message ${i}`);
      expect(msg?.role).toBe("assistant");
    }

    // Verify all tool call messages are present with correct tool calls
    for (let i = 0; i < numToolCalls; i++) {
      const toolMsg = finalState.messages?.find((m) => m.id === `tool_msg${i}`) as AssistantMessage;
      expect(toolMsg).toBeDefined();
      expect(toolMsg?.toolCalls?.length).toBe(1);
      expect(toolMsg.toolCalls?.[0]?.id).toBe(`tool${i}`);
      expect(toolMsg.toolCalls?.[0]?.function.name).toBe(`tool_${i}`);
      expect(toolMsg.toolCalls?.[0]?.function.arguments).toBe(`{"param${i}":"value${i}"}`);
    }
  });

  // Test: Interleaved content and args updates
  it("should handle interleaved content and args updates correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // Start concurrent message and tool call
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);

    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: "tool_msg1",
    } as ToolCallStartEvent);

    // Interleave content and args updates
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Searching ",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"que',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "for ",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: 'ry":"',
    } as ToolCallArgsEvent);

    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "information...",
    } as TextMessageContentEvent);

    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: 'test"}',
    } as ToolCallArgsEvent);

    // End both
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check final state
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify text message content is assembled correctly
    const textMsg = finalState.messages?.find((m) => m.id === "msg1");
    expect(textMsg?.content).toBe("Searching for information...");

    // Verify tool call args are assembled correctly
    const toolMsg = finalState.messages?.find((m) => m.id === "tool_msg1") as AssistantMessage;
    expect(toolMsg?.toolCalls?.[0]?.function.arguments).toBe('{"query":"test"}');
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.state.test.ts
================================================
import { AbstractAgent } from "@/agent";
import { defaultApplyEvents } from "../default";
import { EventType, StateDeltaEvent } from "@ag-ui/core";
import { of } from "rxjs";
import { AgentStateMutation } from "@/agent/subscriber";

const FAKE_AGENT = null as unknown as AbstractAgent;

describe("defaultApplyEvents - State Patching", () => {
  it("should apply state delta patch correctly", (done) => {
    const initialState = {
      messages: [],
      state: {
        count: 0,
        text: "hello",
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [
        { op: "replace", path: "/count", value: 1 },
        { op: "replace", path: "/text", value: "world" },
      ],
    };

    const events$ = of(stateDelta);

    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    result$.subscribe((update: AgentStateMutation) => {
      expect(update.state).toEqual({
        count: 1,
        text: "world",
      });
      done();
    });
  });

  it("should handle nested state updates", (done) => {
    const initialState = {
      messages: [],
      state: {
        user: {
          name: "John",
          settings: {
            theme: "light",
          },
        },
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [{ op: "replace", path: "/user/settings/theme", value: "dark" }],
    };

    const events$ = of(stateDelta);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    result$.subscribe((update: AgentStateMutation) => {
      expect(update.state).toEqual({
        user: {
          name: "John",
          settings: {
            theme: "dark",
          },
        },
      });
      done();
    });
  });

  it("should handle array updates", (done) => {
    const initialState = {
      messages: [],
      state: {
        items: ["a", "b", "c"],
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [
        { op: "add", path: "/items/-", value: "d" },
        { op: "replace", path: "/items/0", value: "x" },
      ],
    };

    const events$ = of(stateDelta);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    result$.subscribe((update: AgentStateMutation) => {
      expect(update.state).toEqual({
        items: ["x", "b", "c", "d"],
      });
      done();
    });
  });

  it("should handle multiple patches in sequence", (done) => {
    const initialState = {
      messages: [],
      state: {
        counter: 0,
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    const stateDeltas: StateDeltaEvent[] = [
      {
        type: EventType.STATE_DELTA,
        delta: [{ op: "replace", path: "/counter", value: 1 }],
      },
      {
        type: EventType.STATE_DELTA,
        delta: [{ op: "replace", path: "/counter", value: 2 }],
      },
    ];

    const events$ = of(...stateDeltas);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    let updateCount = 0;
    result$.subscribe((update: AgentStateMutation) => {
      updateCount++;
      if (updateCount === 2) {
        expect(update.state).toEqual({
          counter: 2,
        });
        done();
      }
    });
  });

  it("should handle invalid patch operations gracefully", (done) => {
    // Suppress console.warn for this test
    const originalWarn = console.warn;
    console.warn = jest.fn();

    const initialState = {
      messages: [],
      state: {
        count: 0,
        text: "hello",
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Invalid patch: trying to replace a non-existent path
    const stateDelta: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      delta: [{ op: "replace", path: "/nonexistent", value: 1 }],
    };

    const events$ = of(stateDelta);
    // Cast to any to bypass strict type checking
    const result$ = defaultApplyEvents(initialState as any, events$, FAKE_AGENT, []);

    let updateCount = 0;
    result$.subscribe({
      next: (update: AgentStateMutation) => {
        updateCount++;
      },
      complete: () => {
        // When patch fails, no updates should be emitted
        expect(updateCount).toBe(0);
        // Restore original console.warn
        console.warn = originalWarn;
        done();
      },
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.text-message.test.ts
================================================
import { Subject } from "rxjs";
import { toArray } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import {
  BaseEvent,
  EventType,
  RunStartedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunAgentInput,
} from "@ag-ui/core";
import { defaultApplyEvents } from "../default";
import { AbstractAgent } from "@/agent";

const FAKE_AGENT = null as unknown as AbstractAgent;

describe("defaultApplyEvents with text messages", () => {
  it("should handle text message events correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Hello ",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "world!",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 3 state updates:
    // 1. After TEXT_MESSAGE_START
    // 2. After first TEXT_MESSAGE_CONTENT
    // 3. After second TEXT_MESSAGE_CONTENT
    // And NO update after TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(3);

    // First update: empty message added
    expect(stateUpdates[0]?.messages?.length).toBe(1);
    expect(stateUpdates[0]?.messages?.[0]?.id).toBe("msg1");
    expect(stateUpdates[0]?.messages?.[0]?.content).toBe("");

    // Second update: first content chunk added
    expect(stateUpdates[1]?.messages?.length).toBe(1);
    expect(stateUpdates[1]?.messages?.[0]?.content).toBe("Hello ");

    // Third update: second content chunk appended
    expect(stateUpdates[2]?.messages?.length).toBe(1);
    expect(stateUpdates[2]?.messages?.[0]?.content).toBe("Hello world!");

    // Verify the last update came from TEXT_MESSAGE_CONTENT, not TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(3);
  });

  it("should handle multiple text messages correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for two different messages
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // First message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
      role: "assistant",
    } as TextMessageStartEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "First message",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Second message
    events$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
      role: "user",
    } as unknown as TextMessageStartEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Second message",
    } as TextMessageContentEvent);
    events$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 4 state updates:
    // 1. After first TEXT_MESSAGE_START
    // 2. After first TEXT_MESSAGE_CONTENT
    // 3. After second TEXT_MESSAGE_START
    // 4. After second TEXT_MESSAGE_CONTENT
    // And NO updates after either TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(4);

    // First update: first empty message added
    expect(stateUpdates[0]?.messages?.length).toBe(1);
    expect(stateUpdates[0]?.messages?.[0]?.id).toBe("msg1");
    expect(stateUpdates[0]?.messages?.[0]?.role).toBe("assistant");
    expect(stateUpdates[0]?.messages?.[0]?.content).toBe("");

    // Second update: first message content added
    expect(stateUpdates[1]?.messages?.length).toBe(1);
    expect(stateUpdates[1]?.messages?.[0]?.content).toBe("First message");

    // Third update: second empty message added
    expect(stateUpdates[2]?.messages?.length).toBe(2);
    expect(stateUpdates[2]?.messages?.[0]?.id).toBe("msg1");
    expect(stateUpdates[2]?.messages?.[0]?.content).toBe("First message");
    expect(stateUpdates[2]?.messages?.[1]?.id).toBe("msg2");
    expect(stateUpdates[2]?.messages?.[1]?.role).toBe("user");
    expect(stateUpdates[2]?.messages?.[1]?.content).toBe("");

    // Fourth update: second message content added
    expect(stateUpdates[3]?.messages?.length).toBe(2);
    expect(stateUpdates[3]?.messages?.[0]?.content).toBe("First message");
    expect(stateUpdates[3]?.messages?.[1]?.content).toBe("Second message");

    // Verify no additional updates after either TEXT_MESSAGE_END
    expect(stateUpdates.length).toBe(4);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/apply/__tests__/default.tool-calls.test.ts
================================================
import { Subject } from "rxjs";
import { toArray } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import {
  BaseEvent,
  EventType,
  RunStartedEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  RunAgentInput,
  AssistantMessage,
} from "@ag-ui/core";
import { defaultApplyEvents } from "../default";
import { AbstractAgent } from "@/agent";

const FAKE_AGENT = null as unknown as AbstractAgent;

describe("defaultApplyEvents with tool calls", () => {
  it("should handle a single tool call correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState = {
      messages: [],
      state: {
        count: 0,
        text: "hello",
      },
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query": "',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: "test search",
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 4 state updates:
    // 1. After TOOL_CALL_START
    // 2-4. After each TOOL_CALL_ARGS
    // And NO update after TOOL_CALL_END
    expect(stateUpdates.length).toBe(4);

    // First update: tool call created
    expect(stateUpdates[0].messages?.length).toBe(1);
    expect((stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );
    expect(
      (stateUpdates[0].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe("");

    // Second update: first args chunk added
    expect(
      (stateUpdates[1].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe('{"query": "');

    // Third update: second args chunk appended
    expect(
      (stateUpdates[2].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe('{"query": "test search');

    // Fourth update: third args chunk appended
    expect(
      (stateUpdates[3].messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments,
    ).toBe('{"query": "test search"}');
  });

  it("should handle multiple tool calls correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events for two different tool calls
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // First tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Second tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 4 state updates:
    // 1. After first TOOL_CALL_START
    // 2. After first TOOL_CALL_ARGS
    // 3. After second TOOL_CALL_START
    // 4. After second TOOL_CALL_ARGS
    expect(stateUpdates.length).toBe(4);

    // Check last state update for the correct tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // First message should have first tool call
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"query":"test"}',
    );

    // Second message should have second tool call
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool2");
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "calculate",
    );
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"expression":"1+1"}',
    );
  });

  it("should handle tool calls with parent message ID correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();

    // Create initial state with an existing message
    const parentMessageId = "existing_message";
    const initialState: RunAgentInput = {
      messages: [
        {
          id: parentMessageId,
          role: "assistant",
          content: "I'll help you with that.",
          toolCalls: [],
        },
      ],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
      parentMessageId: parentMessageId,
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should have exactly 2 state updates
    expect(stateUpdates.length).toBe(2);

    // Check that the tool call was added to the existing message
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(1);
    expect(finalState.messages?.[0]?.id).toBe(parentMessageId);
    expect(finalState.messages?.[0]?.content).toBe("I'll help you with that.");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"query":"test"}',
    );
  });

  it("should handle errors and partial updates correctly", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events with errors in the tool args JSON
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query',
    } as ToolCallArgsEvent); // Incomplete JSON
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: ':"test"}',
    } as ToolCallArgsEvent); // Completes the JSON
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // We should still have updates despite the JSON syntax error
    expect(stateUpdates.length).toBe(3);

    // Check the final JSON (should be valid now)
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.arguments).toBe(
      '{"query:"test"}',
    );
  });

  it("should handle advanced scenarios with multiple tools and text messages", async () => {
    // Create a subject and state for events
    const events$ = new Subject<BaseEvent>();
    const initialState: RunAgentInput = {
      messages: [],
      state: {},
      threadId: "test-thread",
      runId: "test-run",
      tools: [],
      context: [],
    };

    // Create the observable stream
    const result$ = defaultApplyEvents(initialState, events$, FAKE_AGENT, []);

    // Collect all emitted state updates in an array
    const stateUpdatesPromise = firstValueFrom(result$.pipe(toArray()));

    // Send events with a mix of tool calls and text messages
    events$.next({ type: EventType.RUN_STARTED } as RunStartedEvent);

    // First tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    // Second tool call
    events$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);
    events$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);
    events$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    // Add a small delay to ensure any potential updates would be processed
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Complete the events stream
    events$.complete();

    // Wait for all state updates
    const stateUpdates = await stateUpdatesPromise;

    // Check for expected state updates
    expect(stateUpdates.length).toBe(4);

    // Check the final state for both tool calls
    const finalState = stateUpdates[stateUpdates.length - 1];
    expect(finalState.messages?.length).toBe(2);

    // Verify first tool call
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool1");
    expect((finalState.messages?.[0] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "search",
    );

    // Verify second tool call
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.length).toBe(1);
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.id).toBe("tool2");
    expect((finalState.messages?.[1] as AssistantMessage).toolCalls?.[0]?.function?.name).toBe(
      "calculate",
    );
  });
});



================================================
FILE: typescript-sdk/packages/client/src/chunks/index.ts
================================================
export * from "./transform";



================================================
FILE: typescript-sdk/packages/client/src/chunks/transform.ts
================================================
import { mergeMap, Observable, finalize } from "rxjs";
import {
  BaseEvent,
  TextMessageChunkEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  TextMessageStartEvent,
  ToolCallArgsEvent,
  ToolCallChunkEvent,
  ToolCallEndEvent,
  ToolCallStartEvent,
} from "@ag-ui/core";
import { EventType } from "@ag-ui/core";

interface TextMessageFields {
  messageId: string;
}

interface ToolCallFields {
  toolCallId: string;
  toolCallName: string;
  parentMessageId?: string;
}

export const transformChunks =
  (debug: boolean) =>
  (events$: Observable<BaseEvent>): Observable<BaseEvent> => {
    let textMessageFields: TextMessageFields | undefined;
    let toolCallFields: ToolCallFields | undefined;
    let mode: "text" | "tool" | undefined;

    const closeTextMessage = () => {
      if (!textMessageFields || mode !== "text") {
        throw new Error("No text message to close");
      }
      const event = {
        type: EventType.TEXT_MESSAGE_END,
        messageId: textMessageFields.messageId,
      } as TextMessageEndEvent;
      mode = undefined;
      textMessageFields = undefined;

      if (debug) {
        console.debug("[TRANSFORM]: TEXT_MESSAGE_END", JSON.stringify(event));
      }

      return event;
    };

    const closeToolCall = () => {
      if (!toolCallFields || mode !== "tool") {
        throw new Error("No tool call to close");
      }
      const event = {
        type: EventType.TOOL_CALL_END,
        toolCallId: toolCallFields.toolCallId,
      } as ToolCallEndEvent;
      mode = undefined;
      toolCallFields = undefined;

      if (debug) {
        console.debug("[TRANSFORM]: TOOL_CALL_END", JSON.stringify(event));
      }

      return event;
    };

    const closePendingEvent = () => {
      if (mode === "text") {
        return [closeTextMessage()];
      }
      if (mode === "tool") {
        return [closeToolCall()];
      }
      return [];
    };

    return events$.pipe(
      mergeMap((event) => {
        switch (event.type) {
          case EventType.TEXT_MESSAGE_START:
          case EventType.TEXT_MESSAGE_CONTENT:
          case EventType.TEXT_MESSAGE_END:
          case EventType.TOOL_CALL_START:
          case EventType.TOOL_CALL_ARGS:
          case EventType.TOOL_CALL_END:
          case EventType.TOOL_CALL_RESULT:
          case EventType.STATE_SNAPSHOT:
          case EventType.STATE_DELTA:
          case EventType.MESSAGES_SNAPSHOT:
          case EventType.CUSTOM:
          case EventType.RUN_STARTED:
          case EventType.RUN_FINISHED:
          case EventType.RUN_ERROR:
          case EventType.STEP_STARTED:
          case EventType.STEP_FINISHED:
          case EventType.THINKING_START:
          case EventType.THINKING_END:
          case EventType.THINKING_TEXT_MESSAGE_START:
          case EventType.THINKING_TEXT_MESSAGE_CONTENT:
          case EventType.THINKING_TEXT_MESSAGE_END:
            return [...closePendingEvent(), event];
          case EventType.RAW:
            return [event];
          case EventType.TEXT_MESSAGE_CHUNK:
            const messageChunkEvent = event as TextMessageChunkEvent;
            const textMessageResult = [];
            if (
              // we are not in a text message
              mode !== "text" ||
              // or the message id is different
              (messageChunkEvent.messageId !== undefined &&
                messageChunkEvent.messageId !== textMessageFields?.messageId)
            ) {
              // close the current message if any
              textMessageResult.push(...closePendingEvent());
            }

            // we are not in a text message, start a new one
            if (mode !== "text") {
              if (messageChunkEvent.messageId === undefined) {
                throw new Error("First TEXT_MESSAGE_CHUNK must have a messageId");
              }

              textMessageFields = {
                messageId: messageChunkEvent.messageId,
              };
              mode = "text";

              const textMessageStartEvent = {
                type: EventType.TEXT_MESSAGE_START,
                messageId: messageChunkEvent.messageId,
                role: messageChunkEvent.role || "assistant",
              } as TextMessageStartEvent;

              textMessageResult.push(textMessageStartEvent);

              if (debug) {
                console.debug(
                  "[TRANSFORM]: TEXT_MESSAGE_START",
                  JSON.stringify(textMessageStartEvent),
                );
              }
            }

            if (messageChunkEvent.delta !== undefined) {
              const textMessageContentEvent = {
                type: EventType.TEXT_MESSAGE_CONTENT,
                messageId: textMessageFields!.messageId,
                delta: messageChunkEvent.delta,
              } as TextMessageContentEvent;

              textMessageResult.push(textMessageContentEvent);

              if (debug) {
                console.debug(
                  "[TRANSFORM]: TEXT_MESSAGE_CONTENT",
                  JSON.stringify(textMessageContentEvent),
                );
              }
            }

            return textMessageResult;
          case EventType.TOOL_CALL_CHUNK:
            const toolCallChunkEvent = event as ToolCallChunkEvent;
            const toolMessageResult = [];
            if (
              // we are not in a text message
              mode !== "tool" ||
              // or the tool call id is different
              (toolCallChunkEvent.toolCallId !== undefined &&
                toolCallChunkEvent.toolCallId !== toolCallFields?.toolCallId)
            ) {
              // close the current message if any
              toolMessageResult.push(...closePendingEvent());
            }

            if (mode !== "tool") {
              if (toolCallChunkEvent.toolCallId === undefined) {
                throw new Error("First TOOL_CALL_CHUNK must have a toolCallId");
              }
              if (toolCallChunkEvent.toolCallName === undefined) {
                throw new Error("First TOOL_CALL_CHUNK must have a toolCallName");
              }
              toolCallFields = {
                toolCallId: toolCallChunkEvent.toolCallId,
                toolCallName: toolCallChunkEvent.toolCallName,
                parentMessageId: toolCallChunkEvent.parentMessageId,
              };
              mode = "tool";

              const toolCallStartEvent = {
                type: EventType.TOOL_CALL_START,
                toolCallId: toolCallChunkEvent.toolCallId,
                toolCallName: toolCallChunkEvent.toolCallName,
                parentMessageId: toolCallChunkEvent.parentMessageId,
              } as ToolCallStartEvent;

              toolMessageResult.push(toolCallStartEvent);

              if (debug) {
                console.debug("[TRANSFORM]: TOOL_CALL_START", JSON.stringify(toolCallStartEvent));
              }
            }

            if (toolCallChunkEvent.delta !== undefined) {
              const toolCallArgsEvent = {
                type: EventType.TOOL_CALL_ARGS,
                toolCallId: toolCallFields!.toolCallId,
                delta: toolCallChunkEvent.delta,
              } as ToolCallArgsEvent;

              toolMessageResult.push(toolCallArgsEvent);

              if (debug) {
                console.debug("[TRANSFORM]: TOOL_CALL_ARGS", JSON.stringify(toolCallArgsEvent));
              }
            }

            return toolMessageResult;
        }
        const _exhaustiveCheck: never = event.type;
      }),
      finalize(() => {
        // This ensures that we close any pending events when the source observable completes
        return closePendingEvent();
      }),
    );
  };



================================================
FILE: typescript-sdk/packages/client/src/chunks/__tests__/transform-roles.test.ts
================================================
import { from } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  EventType,
  TextMessageChunkEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunFinishedEvent,
  Role,
} from "@ag-ui/core";
import { transformChunks } from "../transform";

describe("transformChunks with roles", () => {
  const roles: Role[] = ["developer", "system", "assistant", "user", "tool"];

  it.each(roles)(
    "should preserve role '%s' when transforming text message chunks",
    (role, done) => {
      const chunk: TextMessageChunkEvent = {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: `msg-${role}`,
        role: role as unknown as any,
        delta: `Hello from ${role}`,
      };

      // Add a non-chunk event to close the sequence
      const closeEvent: RunFinishedEvent = {
        type: EventType.RUN_FINISHED,
        threadId: "thread-123",
        runId: "run-123",
      };

      from([chunk, closeEvent])
        .pipe(transformChunks(false), toArray())
        .subscribe({
          next: (events) => {
            expect(events).toHaveLength(4); // start, content, end, run_finished

            const startEvent = events[0] as TextMessageStartEvent;
            expect(startEvent.type).toBe(EventType.TEXT_MESSAGE_START);
            expect(startEvent.messageId).toBe(`msg-${role}`);
            expect(startEvent.role).toBe(role);

            const contentEvent = events[1] as TextMessageContentEvent;
            expect(contentEvent.type).toBe(EventType.TEXT_MESSAGE_CONTENT);
            expect(contentEvent.delta).toBe(`Hello from ${role}`);

            const endEvent = events[2] as TextMessageEndEvent;
            expect(endEvent.type).toBe(EventType.TEXT_MESSAGE_END);

            done();
          },
          error: done,
        });
    },
  );

  it("should default to 'assistant' role when chunk has no role", (done) => {
    const chunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-default",
      delta: "Hello default",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    from([chunk, closeEvent])
      .pipe(transformChunks(false), toArray())
      .subscribe({
        next: (events) => {
          expect(events).toHaveLength(4);

          const startEvent = events[0] as TextMessageStartEvent;
          expect(startEvent.type).toBe(EventType.TEXT_MESSAGE_START);
          expect(startEvent.messageId).toBe("msg-default");
          expect(startEvent.role).toBe("assistant"); // default role

          done();
        },
        error: done,
      });
  });

  it("should handle multiple chunks with different roles", (done) => {
    const chunk1: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-user",
      role: "user",
      delta: "User message",
    };

    const chunk2: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-system",
      role: "system",
      delta: "System message",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    from([chunk1, chunk2, closeEvent])
      .pipe(transformChunks(false), toArray())
      .subscribe({
        next: (events) => {
          // Should have: start1, content1, end1, start2, content2, end2, run_finished
          expect(events).toHaveLength(7);

          // First message
          const start1 = events[0] as TextMessageStartEvent;
          expect(start1.type).toBe(EventType.TEXT_MESSAGE_START);
          expect(start1.messageId).toBe("msg-user");
          expect(start1.role).toBe("user");

          const content1 = events[1] as TextMessageContentEvent;
          expect(content1.delta).toBe("User message");

          // Second message
          const start2 = events[3] as TextMessageStartEvent;
          expect(start2.type).toBe(EventType.TEXT_MESSAGE_START);
          expect(start2.messageId).toBe("msg-system");
          expect(start2.role).toBe("system");

          const content2 = events[4] as TextMessageContentEvent;
          expect(content2.delta).toBe("System message");

          done();
        },
        error: done,
      });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/chunks/__tests__/transform.test.ts
================================================
import { of, Observable, concat, EMPTY, throwError } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { transformChunks } from "../transform";
import {
  BaseEvent,
  EventType,
  TextMessageChunkEvent,
  ToolCallChunkEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  RunStartedEvent,
  RawEvent,
  RunFinishedEvent,
} from "@ag-ui/core";

describe("transformChunks", () => {
  it("should transform a single text message chunk into start, content, and end events", (done) => {
    const chunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello, world!",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0]).toEqual({
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-123",
        role: "assistant",
      } as TextMessageStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-123",
        delta: "Hello, world!",
      } as TextMessageContentEvent);

      expect(events[2]).toEqual({
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-123",
      } as TextMessageEndEvent);

      expect(events[3]).toEqual(closeEvent);

      done();
    });
  });

  it("should transform multiple text message chunks with the same ID", (done) => {
    const chunk1: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const chunk2: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: ", world!",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk1, chunk2), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(5);

      expect(events[0]).toEqual({
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-123",
        role: "assistant",
      } as TextMessageStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-123",
        delta: "Hello",
      } as TextMessageContentEvent);

      expect(events[2]).toEqual({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-123",
        delta: ", world!",
      } as TextMessageContentEvent);

      expect(events[3]).toEqual({
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-123",
      } as TextMessageEndEvent);

      expect(events[4]).toEqual(closeEvent);

      done();
    });
  });

  it("should transform a single tool call chunk into start, args, and end events", (done) => {
    const chunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      delta: '{"arg1": "value1"}',
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0]).toEqual({
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-123",
        toolCallName: "testTool",
      } as ToolCallStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool-123",
        delta: '{"arg1": "value1"}',
      } as ToolCallArgsEvent);

      expect(events[2]).toEqual({
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-123",
      } as ToolCallEndEvent);

      expect(events[3]).toEqual(closeEvent);

      done();
    });
  });

  it("should handle switching from text message to tool call", (done) => {
    const textChunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const toolChunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      delta: '{"arg1": "value1"}',
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(textChunk, toolChunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(7);

      // Text message events
      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_END);

      // Tool call events
      expect(events[3].type).toBe(EventType.TOOL_CALL_START);
      expect(events[4].type).toBe(EventType.TOOL_CALL_ARGS);
      expect(events[5].type).toBe(EventType.TOOL_CALL_END);

      // Run finished event
      expect(events[6].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should pass through non-chunk events", (done) => {
    const runStartEvent: RunStartedEvent = {
      type: EventType.RUN_STARTED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = of(runStartEvent);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(1);
      expect(events[0]).toEqual(runStartEvent);
      done();
    });
  });

  it("should close current message when encountering a non-chunk event", (done) => {
    const textChunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const runStartEvent: RunStartedEvent = {
      type: EventType.RUN_STARTED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = of(textChunk, runStartEvent);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_END);
      expect(events[3].type).toBe(EventType.RUN_STARTED);

      done();
    });
  });

  it("should handle text message chunks with different IDs", (done) => {
    const chunk1: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      delta: "Hello",
    };

    const chunk2: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-456",
      delta: "Different message",
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk1, chunk2), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(7);

      // First message
      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect((events[0] as TextMessageStartEvent).messageId).toBe("msg-123");

      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect((events[1] as TextMessageContentEvent).messageId).toBe("msg-123");

      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_END);
      expect((events[2] as TextMessageEndEvent).messageId).toBe("msg-123");

      // Second message
      expect(events[3].type).toBe(EventType.TEXT_MESSAGE_START);
      expect((events[3] as TextMessageStartEvent).messageId).toBe("msg-456");

      expect(events[4].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect((events[4] as TextMessageContentEvent).messageId).toBe("msg-456");

      expect(events[5].type).toBe(EventType.TEXT_MESSAGE_END);
      expect((events[5] as TextMessageEndEvent).messageId).toBe("msg-456");

      // Run finished event
      expect(events[6].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should handle errors when first text message chunk has no ID", (done) => {
    const invalidChunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      delta: "This will fail",
    };

    const events$ = of(invalidChunk);
    const transformed$ = transformChunks(false)(events$);

    transformed$
      .pipe(
        catchError((err) => {
          expect(err.message).toBe("First TEXT_MESSAGE_CHUNK must have a messageId");
          done();
          return EMPTY;
        }),
      )
      .subscribe({
        next: () => {
          fail("Should have thrown an error");
        },
        complete: () => {
          // Should not complete normally
        },
      });
  });

  it("should handle errors when first tool call chunk has no ID", (done) => {
    const invalidChunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      delta: "This will fail",
    };

    const events$ = of(invalidChunk);
    const transformed$ = transformChunks(false)(events$);

    transformed$
      .pipe(
        catchError((err) => {
          expect(err.message).toBe("First TOOL_CALL_CHUNK must have a toolCallId");
          done();
          return EMPTY;
        }),
      )
      .subscribe({
        next: () => {
          fail("Should have thrown an error");
        },
        complete: () => {
          // Should not complete normally
        },
      });
  });

  it("should handle errors when first tool call chunk has no name", (done) => {
    const invalidChunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      delta: "This will fail",
    };

    const events$ = of(invalidChunk);
    const transformed$ = transformChunks(false)(events$);

    transformed$
      .pipe(
        catchError((err) => {
          expect(err.message).toBe("First TOOL_CALL_CHUNK must have a toolCallName");
          done();
          return EMPTY;
        }),
      )
      .subscribe({
        next: () => {
          fail("Should have thrown an error");
        },
        complete: () => {
          // Should not complete normally
        },
      });
  });

  it("should handle tool call chunks with parentMessageId", (done) => {
    const chunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      parentMessageId: "parent-msg-123",
      delta: '{"arg1": "value1"}',
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(4);

      expect(events[0]).toEqual({
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-123",
        toolCallName: "testTool",
        parentMessageId: "parent-msg-123",
      } as ToolCallStartEvent);

      expect(events[1]).toEqual({
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool-123",
        delta: '{"arg1": "value1"}',
      } as ToolCallArgsEvent);

      expect(events[2]).toEqual({
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-123",
      } as ToolCallEndEvent);

      expect(events[3]).toEqual(closeEvent);

      done();
    });
  });

  it("should pass through RAW events without transformation", (done) => {
    const rawEvent: RawEvent = {
      type: EventType.RAW,
      event: { some: "data" },
      source: "test-source",
    };

    const events$ = of(rawEvent);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(1);
      expect(events[0]).toEqual(rawEvent);
      done();
    });
  });

  it("should handle a complex sequence of mixed events", (done) => {
    const events: BaseEvent[] = [
      // Text message chunk
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Hello",
      } as TextMessageChunkEvent,

      // Tool call chunk
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-123",
        toolCallName: "testTool",
        delta: '{"arg1": "value1"}',
      } as ToolCallChunkEvent,

      // Another text message chunk
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-456",
        delta: "After tool call",
      } as TextMessageChunkEvent,

      // Non-chunk event to close the sequence
      {
        type: EventType.RUN_FINISHED,
        threadId: "thread-123",
        runId: "run-123",
      } as RunFinishedEvent,
    ];

    const events$ = of(...events);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((result) => {
      expect(result.length).toBe(10);

      // First text message (3 events)
      expect(result[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(result[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(result[2].type).toBe(EventType.TEXT_MESSAGE_END);

      // Tool call (3 events)
      expect(result[3].type).toBe(EventType.TOOL_CALL_START);
      expect(result[4].type).toBe(EventType.TOOL_CALL_ARGS);
      expect(result[5].type).toBe(EventType.TOOL_CALL_END);

      // Second text message (3 events)
      expect(result[6].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(result[7].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(result[8].type).toBe(EventType.TEXT_MESSAGE_END);

      // Final event
      expect(result[9].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should handle text message chunks without delta", (done) => {
    const chunk: TextMessageChunkEvent = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "msg-123",
      // No delta property
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(3);

      expect(events[0]).toEqual({
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-123",
        role: "assistant",
      } as TextMessageStartEvent);

      // No content event because there was no delta

      expect(events[1]).toEqual({
        type: EventType.TEXT_MESSAGE_END,
        messageId: "msg-123",
      } as TextMessageEndEvent);

      expect(events[2]).toEqual(closeEvent);

      done();
    });
  });

  it("should handle tool call chunks without delta", (done) => {
    const chunk: ToolCallChunkEvent = {
      type: EventType.TOOL_CALL_CHUNK,
      toolCallId: "tool-123",
      toolCallName: "testTool",
      // No delta property
    };

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(chunk), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(3);

      expect(events[0]).toEqual({
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-123",
        toolCallName: "testTool",
      } as ToolCallStartEvent);

      // No args event because there was no delta

      expect(events[1]).toEqual({
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-123",
      } as ToolCallEndEvent);

      expect(events[2]).toEqual(closeEvent);

      done();
    });
  });

  it("should generate exactly one start and one end event for multiple chunks with same ID", (done) => {
    // Create multiple chunks with the same message ID
    const chunks: TextMessageChunkEvent[] = [
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "First part",
      },
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Second part",
      },
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Third part",
      },
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-123",
        delta: "Fourth part",
      },
    ];

    // Add a non-chunk event to close the sequence
    const closeEvent: RunFinishedEvent = {
      type: EventType.RUN_FINISHED,
      threadId: "thread-123",
      runId: "run-123",
    };

    const events$ = concat(of(...chunks), of(closeEvent));
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((events) => {
      expect(events.length).toBe(7); // 1 start + 4 content + 1 end + 1 close event

      // Count events by type
      const eventCounts = events.reduce(
        (counts, event) => {
          counts[event.type] = (counts[event.type] || 0) + 1;
          return counts;
        },
        {} as Record<EventType, number>,
      );

      // There should be exactly one start event
      expect(eventCounts[EventType.TEXT_MESSAGE_START]).toBe(1);

      // There should be exactly one end event
      expect(eventCounts[EventType.TEXT_MESSAGE_END]).toBe(1);

      // There should be exactly four content events (one for each chunk)
      expect(eventCounts[EventType.TEXT_MESSAGE_CONTENT]).toBe(4);

      // There should be exactly one run finished event
      expect(eventCounts[EventType.RUN_FINISHED]).toBe(1);

      // All content events should have the same message ID
      const contentEvents = events.filter(
        (e) => e.type === EventType.TEXT_MESSAGE_CONTENT,
      ) as TextMessageContentEvent[];

      contentEvents.forEach((e) => {
        expect(e.messageId).toBe("msg-123");
      });

      // Events should be in correct order: start, content*4, end, run_finished
      expect(events[0].type).toBe(EventType.TEXT_MESSAGE_START);
      expect(events[1].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[2].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[3].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[4].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
      expect(events[5].type).toBe(EventType.TEXT_MESSAGE_END);
      expect(events[6].type).toBe(EventType.RUN_FINISHED);

      done();
    });
  });

  it("should handle interleaved chunks with different message and tool call IDs", (done) => {
    // Create a complex sequence that alternates between different types of chunks
    const events: BaseEvent[] = [
      // First text message
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-1",
        delta: "First message part 1",
      } as TextMessageChunkEvent,

      // First tool call
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-1",
        toolCallName: "firstTool",
        delta: '{"arg1": "value1"}',
      } as ToolCallChunkEvent,

      // Back to first text message
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-1",
        delta: "First message part 2",
      } as TextMessageChunkEvent,

      // Second text message
      {
        type: EventType.TEXT_MESSAGE_CHUNK,
        messageId: "msg-2",
        delta: "Second message",
      } as TextMessageChunkEvent,

      // Second tool call
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-2",
        toolCallName: "secondTool",
        delta: '{"arg2": "value2"}',
      } as ToolCallChunkEvent,

      // Back to first tool call
      {
        type: EventType.TOOL_CALL_CHUNK,
        toolCallId: "tool-1",
        toolCallName: "firstTool",
        delta: ',"arg1_more": "more data"}',
      } as ToolCallChunkEvent,

      // Non-chunk event to close the sequence
      {
        type: EventType.RUN_FINISHED,
        threadId: "thread-123",
        runId: "run-123",
      } as RunFinishedEvent,
    ];

    const events$ = of(...events);
    const transformed$ = transformChunks(false)(events$);

    transformed$.pipe(toArray()).subscribe((results) => {
      // Count events by type
      const eventCounts = results.reduce(
        (counts, event) => {
          counts[event.type] = (counts[event.type] || 0) + 1;
          return counts;
        },
        {} as Record<EventType, number>,
      );

      // When switching between message types, the function creates new start events
      // even for previously seen message IDs
      expect(eventCounts[EventType.TEXT_MESSAGE_START]).toBe(3);
      expect(eventCounts[EventType.TOOL_CALL_START]).toBe(3);

      // There should be corresponding end events
      expect(eventCounts[EventType.TEXT_MESSAGE_END]).toBe(3);
      expect(eventCounts[EventType.TOOL_CALL_END]).toBe(3);

      // There should be 3 content events (for the text messages)
      expect(eventCounts[EventType.TEXT_MESSAGE_CONTENT]).toBe(3);

      // There should be 3 args events (for the tool calls)
      expect(eventCounts[EventType.TOOL_CALL_ARGS]).toBe(3);

      // There should be exactly one run finished event
      expect(eventCounts[EventType.RUN_FINISHED]).toBe(1);

      // Verify the total number of events
      expect(results.length).toBe(19); // 6 starts + 6 contents/args + 6 ends + 1 run finished

      // Get all messageId pairs to see start/content/end sequences
      const messageEventsById: Record<string, EventType[]> = {};

      results.forEach((event) => {
        if (
          event.type === EventType.TEXT_MESSAGE_START ||
          event.type === EventType.TEXT_MESSAGE_CONTENT ||
          event.type === EventType.TEXT_MESSAGE_END
        ) {
          const msgEvent = event as
            | TextMessageStartEvent
            | TextMessageContentEvent
            | TextMessageEndEvent;
          if (!messageEventsById[msgEvent.messageId]) {
            messageEventsById[msgEvent.messageId] = [];
          }
          messageEventsById[msgEvent.messageId].push(event.type);
        }
      });

      // Check that the first message ID appears twice
      expect(
        messageEventsById["msg-1"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_START)
          .length,
      ).toBe(2);
      expect(
        messageEventsById["msg-1"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_END)
          .length,
      ).toBe(2);

      // The second message ID appears only once
      expect(
        messageEventsById["msg-2"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_START)
          .length,
      ).toBe(1);
      expect(
        messageEventsById["msg-2"].filter((t: EventType) => t === EventType.TEXT_MESSAGE_END)
          .length,
      ).toBe(1);

      done();
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/convert.ts
================================================
import { mergeMap } from "rxjs/operators";
import { applyPatch } from "fast-json-patch";

import {
  BaseEvent,
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  ToolCallResultEvent,
  CustomEvent,
  StateSnapshotEvent,
  StepStartedEvent,
  Message,
  StateDeltaEvent,
  MessagesSnapshotEvent,
  ToolCall,
  RunErrorEvent,
} from "@ag-ui/core";
import { Observable } from "rxjs";
import {
  LegacyTextMessageStart,
  LegacyTextMessageContent,
  LegacyTextMessageEnd,
  LegacyActionExecutionStart,
  LegacyActionExecutionArgs,
  LegacyActionExecutionEnd,
  LegacyRuntimeEventTypes,
  LegacyRuntimeProtocolEvent,
  LegacyMetaEvent,
  LegacyAgentStateMessage,
  LegacyMessage,
  LegacyTextMessage,
  LegacyActionExecutionMessage,
  LegacyResultMessage,
  LegacyActionExecutionResult,
  LegacyRunError
} from "./types";
import untruncateJson from "untruncate-json";

interface PredictStateValue {
  state_key: string;
  tool: string;
  tool_argument: string;
}

export const convertToLegacyEvents =
  (threadId: string, runId: string, agentName: string) =>
  (events$: Observable<BaseEvent>): Observable<LegacyRuntimeProtocolEvent> => {
    let currentState: any = {};
    let running = true;
    let active = true;
    let nodeName = "";
    let syncedMessages: Message[] | null = null;
    let predictState: PredictStateValue[] | null = null;
    let currentToolCalls: ToolCall[] = [];
    let toolCallNames: Record<string, string> = {};

    const updateCurrentState = (newState: any) => {
      // the legacy protocol will only support object state
      if (typeof newState === "object" && newState !== null) {
        if ("messages" in newState) {
          delete newState.messages;
        }
        currentState = newState;
      }
    };

    return events$.pipe(
      mergeMap((event) => {
        switch (event.type) {
          case EventType.TEXT_MESSAGE_START: {
            const startEvent = event as TextMessageStartEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.TextMessageStart,
                messageId: startEvent.messageId,
                role: startEvent.role,
              } as LegacyTextMessageStart,
            ];
          }
          case EventType.TEXT_MESSAGE_CONTENT: {
            const contentEvent = event as TextMessageContentEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.TextMessageContent,
                messageId: contentEvent.messageId,
                content: contentEvent.delta,
              } as LegacyTextMessageContent,
            ];
          }
          case EventType.TEXT_MESSAGE_END: {
            const endEvent = event as TextMessageEndEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.TextMessageEnd,
                messageId: endEvent.messageId,
              } as LegacyTextMessageEnd,
            ];
          }
          case EventType.TOOL_CALL_START: {
            const startEvent = event as ToolCallStartEvent;

            currentToolCalls.push({
              id: startEvent.toolCallId,
              type: "function",
              function: {
                name: startEvent.toolCallName,
                arguments: "",
              },
            });

            active = true;
            toolCallNames[startEvent.toolCallId] = startEvent.toolCallName;

            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionStart,
                actionExecutionId: startEvent.toolCallId,
                actionName: startEvent.toolCallName,
                parentMessageId: startEvent.parentMessageId,
              } as LegacyActionExecutionStart,
            ];
          }
          case EventType.TOOL_CALL_ARGS: {
            const argsEvent = event as ToolCallArgsEvent;

            // Find the tool call by ID instead of using the last one
            const currentToolCall = currentToolCalls.find((tc) => tc.id === argsEvent.toolCallId);
            if (!currentToolCall) {
              console.warn(`TOOL_CALL_ARGS: No tool call found with ID '${argsEvent.toolCallId}'`);
              return [];
            }

            currentToolCall.function.arguments += argsEvent.delta;
            let didUpdateState = false;

            if (predictState) {
              let currentPredictState = predictState.find(
                (s) => s.tool == currentToolCall.function.name,
              );

              if (currentPredictState) {
                try {
                  const currentArgs = JSON.parse(
                    untruncateJson(currentToolCall.function.arguments),
                  );
                  if (
                    currentPredictState.tool_argument &&
                    currentPredictState.tool_argument in currentArgs
                  ) {
                    updateCurrentState({
                      ...currentState,
                      [currentPredictState.state_key]:
                        currentArgs[currentPredictState.tool_argument],
                    });
                    didUpdateState = true;
                  } else if (!currentPredictState.tool_argument) {
                    updateCurrentState({
                      ...currentState,
                      [currentPredictState.state_key]: currentArgs,
                    });
                    didUpdateState = true;
                  }
                } catch (e) {}
              }
            }

            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionArgs,
                actionExecutionId: argsEvent.toolCallId,
                args: argsEvent.delta,
              } as LegacyActionExecutionArgs,
              ...(didUpdateState
                ? [
                    {
                      type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                      threadId,
                      agentName,
                      nodeName,
                      runId,
                      running,
                      role: "assistant",
                      state: JSON.stringify(currentState),
                      active,
                    },
                  ]
                : []),
            ];
          }
          case EventType.TOOL_CALL_END: {
            const endEvent = event as ToolCallEndEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionEnd,
                actionExecutionId: endEvent.toolCallId,
              } as LegacyActionExecutionEnd,
            ];
          }
          case EventType.TOOL_CALL_RESULT: {
            const resultEvent = event as ToolCallResultEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.ActionExecutionResult,
                actionExecutionId: resultEvent.toolCallId,
                result: resultEvent.content,
                actionName: toolCallNames[resultEvent.toolCallId] || "unknown",
              } as LegacyActionExecutionResult,
            ];
          }
          case EventType.RAW: {
            // The legacy protocol doesn't support raw events
            return [];
          }
          case EventType.CUSTOM: {
            const customEvent = event as CustomEvent;
            switch (customEvent.name) {
              case "Exit":
                running = false;
                break;
              case "PredictState":
                predictState = customEvent.value as PredictStateValue[];
                break;
            }

            return [
              {
                type: LegacyRuntimeEventTypes.enum.MetaEvent,
                name: customEvent.name,
                value: customEvent.value,
              } as LegacyMetaEvent,
            ];
          }
          case EventType.STATE_SNAPSHOT: {
            const stateEvent = event as StateSnapshotEvent;
            updateCurrentState(stateEvent.snapshot);

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.STATE_DELTA: {
            const deltaEvent = event as StateDeltaEvent;
            const result = applyPatch(currentState, deltaEvent.delta, true, false);
            if (!result) {
              return [];
            }
            updateCurrentState(result.newDocument);

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.MESSAGES_SNAPSHOT: {
            const messagesSnapshot = event as MessagesSnapshotEvent;
            syncedMessages = messagesSnapshot.messages;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify({
                  ...currentState,
                  ...(syncedMessages ? { messages: syncedMessages } : {}),
                }),
                active: true,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.RUN_STARTED: {
            // There is nothing to do in the legacy protocol
            return [];
          }
          case EventType.RUN_FINISHED: {
            if (syncedMessages) {
              currentState.messages = syncedMessages;
            }

            // Only do an update if state is not empty
            if (Object.keys(currentState).length === 0) {
              return [];
            }

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify({
                  ...currentState,
                  ...(syncedMessages
                    ? {
                        messages: convertMessagesToLegacyFormat(syncedMessages),
                      }
                    : {}),
                }),
                active: false,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.RUN_ERROR: {
            const errorEvent = event as RunErrorEvent;
            return [
              {
                type: LegacyRuntimeEventTypes.enum.RunError,
                message: errorEvent.message,
                code: errorEvent.code,
              } as LegacyRunError,
            ];
          }
          case EventType.STEP_STARTED: {
            const stepStarted = event as StepStartedEvent;
            nodeName = stepStarted.stepName;

            currentToolCalls = [];
            predictState = null;

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active: true,
              } as LegacyAgentStateMessage,
            ];
          }
          case EventType.STEP_FINISHED: {
            currentToolCalls = [];
            predictState = null;

            return [
              {
                type: LegacyRuntimeEventTypes.enum.AgentStateMessage,
                threadId,
                agentName,
                nodeName,
                runId,
                running,
                role: "assistant",
                state: JSON.stringify(currentState),
                active: false,
              } as LegacyAgentStateMessage,
            ];
          }
          default: {
            return [];
          }
        }
      }),
    );
  };

export function convertMessagesToLegacyFormat(messages: Message[]): LegacyMessage[] {
  const result: LegacyMessage[] = [];

  for (const message of messages) {
    if (message.role === "assistant" || message.role === "user" || message.role === "system") {
      if (message.content) {
        const textMessage: LegacyTextMessage = {
          id: message.id,
          role: message.role,
          content: message.content,
        };
        result.push(textMessage);
      }
      if (message.role === "assistant" && message.toolCalls && message.toolCalls.length > 0) {
        for (const toolCall of message.toolCalls) {
          const actionExecutionMessage: LegacyActionExecutionMessage = {
            id: toolCall.id,
            name: toolCall.function.name,
            arguments: JSON.parse(toolCall.function.arguments),
            parentMessageId: message.id,
          };
          result.push(actionExecutionMessage);
        }
      }
    } else if (message.role === "tool") {
      let actionName = "unknown";
      for (const m of messages) {
        if (m.role === "assistant" && m.toolCalls?.length) {
          for (const toolCall of m.toolCalls) {
            if (toolCall.id === message.toolCallId) {
              actionName = toolCall.function.name;
              break;
            }
          }
        }
      }
      const toolMessage: LegacyResultMessage = {
        id: message.id,
        result: message.content,
        actionExecutionId: message.toolCallId,
        actionName,
      };
      result.push(toolMessage);
    }
  }

  return result;
}



================================================
FILE: typescript-sdk/packages/client/src/legacy/index.ts
================================================
export { convertToLegacyEvents } from "./convert";



================================================
FILE: typescript-sdk/packages/client/src/legacy/types.ts
================================================
import { z } from "zod";

// Protocol Events
export const LegacyRuntimeEventTypes = z.enum([
  "TextMessageStart",
  "TextMessageContent",
  "TextMessageEnd",
  "ActionExecutionStart",
  "ActionExecutionArgs",
  "ActionExecutionEnd",
  "ActionExecutionResult",
  "AgentStateMessage",
  "MetaEvent",
  "RunStarted",
  "RunFinished",
  "RunError",
  "NodeStarted",
  "NodeFinished",
]);

export const LegacyRuntimeMetaEventName = z.enum([
  "LangGraphInterruptEvent",
  "PredictState",
  "Exit",
]);

export const LegacyTextMessageStart = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.TextMessageStart),
  messageId: z.string(),
  parentMessageId: z.string().optional(),
  role: z.string().optional(),
});

export const LegacyTextMessageContent = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.TextMessageContent),
  messageId: z.string(),
  content: z.string(),
});

export const LegacyTextMessageEnd = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.TextMessageEnd),
  messageId: z.string(),
});

export const LegacyActionExecutionStart = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionStart),
  actionExecutionId: z.string(),
  actionName: z.string(),
  parentMessageId: z.string().optional(),
});

export const LegacyActionExecutionArgs = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionArgs),
  actionExecutionId: z.string(),
  args: z.string(),
});

export const LegacyActionExecutionEnd = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionEnd),
  actionExecutionId: z.string(),
});

export const LegacyActionExecutionResult = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.ActionExecutionResult),
  actionName: z.string(),
  actionExecutionId: z.string(),
  result: z.string(),
});

export const LegacyAgentStateMessage = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.AgentStateMessage),
  threadId: z.string(),
  agentName: z.string(),
  nodeName: z.string(),
  runId: z.string(),
  active: z.boolean(),
  role: z.string(),
  state: z.string(),
  running: z.boolean(),
});

export const LegacyMetaEvent = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.MetaEvent),
  name: LegacyRuntimeMetaEventName,
  value: z.any(),
});


export const LegacyRunError = z.object({
  type: z.literal(LegacyRuntimeEventTypes.enum.RunError),
  message: z.string(),
  code: z.string().optional(),
});

export const LegacyRuntimeProtocolEvent = z.discriminatedUnion("type", [
  LegacyTextMessageStart,
  LegacyTextMessageContent,
  LegacyTextMessageEnd,
  LegacyActionExecutionStart,
  LegacyActionExecutionArgs,
  LegacyActionExecutionEnd,
  LegacyActionExecutionResult,
  LegacyAgentStateMessage,
  LegacyMetaEvent,
  LegacyRunError,
]);

// Protocol Event type exports
export type RuntimeEventTypes = z.infer<typeof LegacyRuntimeEventTypes>;
export type RuntimeMetaEventName = z.infer<typeof LegacyRuntimeMetaEventName>;
export type LegacyTextMessageStart = z.infer<typeof LegacyTextMessageStart>;
export type LegacyTextMessageContent = z.infer<typeof LegacyTextMessageContent>;
export type LegacyTextMessageEnd = z.infer<typeof LegacyTextMessageEnd>;
export type LegacyActionExecutionStart = z.infer<typeof LegacyActionExecutionStart>;
export type LegacyActionExecutionArgs = z.infer<typeof LegacyActionExecutionArgs>;
export type LegacyActionExecutionEnd = z.infer<typeof LegacyActionExecutionEnd>;
export type LegacyActionExecutionResult = z.infer<typeof LegacyActionExecutionResult>;
export type LegacyAgentStateMessage = z.infer<typeof LegacyAgentStateMessage>;
export type LegacyMetaEvent = z.infer<typeof LegacyMetaEvent>;
export type LegacyRuntimeProtocolEvent = z.infer<typeof LegacyRuntimeProtocolEvent>;
export type LegacyRunError = z.infer<typeof LegacyRunError>;

// Message schemas (with kind discriminator)
export const LegacyTextMessageSchema = z.object({
  id: z.string(),
  role: z.string(),
  content: z.string(),
  parentMessageId: z.string().optional(),
});

export const LegacyActionExecutionMessageSchema = z.object({
  id: z.string(),
  name: z.string(),
  arguments: z.any(),
  parentMessageId: z.string().optional(),
});

export const LegacyResultMessageSchema = z.object({
  id: z.string(),
  result: z.any(),
  actionExecutionId: z.string(),
  actionName: z.string(),
});

// Message type exports
export type LegacyTextMessage = z.infer<typeof LegacyTextMessageSchema>;
export type LegacyActionExecutionMessage = z.infer<typeof LegacyActionExecutionMessageSchema>;
export type LegacyResultMessage = z.infer<typeof LegacyResultMessageSchema>;
export type LegacyMessage = LegacyTextMessage | LegacyActionExecutionMessage | LegacyResultMessage;



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.concurrent.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  BaseEvent,
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  CustomEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";

describe("convertToLegacyEvents - Concurrent Operations", () => {
  const defaultParams = {
    threadId: "test-thread",
    runId: "test-run",
    agentName: "test-agent",
  };

  it("should handle concurrent text messages correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start two concurrent text messages
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg2",
        role: "assistant",
      } as TextMessageStartEvent,

      // Send content for both messages
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "First message content",
      } as TextMessageContentEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg2",
        delta: "Second message content",
      } as TextMessageContentEvent,

      // End messages in reverse order
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg2",
      } as TextMessageEndEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg1",
      } as TextMessageEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(6);

    // Verify message starts
    expect(events[0].type).toBe("TextMessageStart");
    expect(events[1].type).toBe("TextMessageStart");
    if (events[0].type === "TextMessageStart" && events[1].type === "TextMessageStart") {
      expect(events[0].messageId).toBe("msg1");
      expect(events[1].messageId).toBe("msg2");
    }

    // Verify message content
    expect(events[2].type).toBe("TextMessageContent");
    expect(events[3].type).toBe("TextMessageContent");
    if (events[2].type === "TextMessageContent" && events[3].type === "TextMessageContent") {
      expect(events[2].messageId).toBe("msg1");
      expect(events[2].content).toBe("First message content");
      expect(events[3].messageId).toBe("msg2");
      expect(events[3].content).toBe("Second message content");
    }

    // Verify message ends (in reverse order)
    expect(events[4].type).toBe("TextMessageEnd");
    expect(events[5].type).toBe("TextMessageEnd");
    if (events[4].type === "TextMessageEnd" && events[5].type === "TextMessageEnd") {
      expect(events[4].messageId).toBe("msg2");
      expect(events[5].messageId).toBe("msg1");
    }
  });

  it("should handle concurrent tool calls correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start two concurrent tool calls
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "msg1",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool2",
        toolCallName: "calculate",
        parentMessageId: "msg2",
      } as ToolCallStartEvent,

      // Send args for both tool calls
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: '{"query":"test search"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool2",
        delta: '{"expression":"2+2"}',
      } as ToolCallArgsEvent,

      // End tool calls in reverse order
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool2",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(6);

    // Verify tool call starts
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionStart");
    if (events[0].type === "ActionExecutionStart" && events[1].type === "ActionExecutionStart") {
      expect(events[0].actionExecutionId).toBe("tool1");
      expect(events[0].actionName).toBe("search");
      expect(events[0].parentMessageId).toBe("msg1");
      expect(events[1].actionExecutionId).toBe("tool2");
      expect(events[1].actionName).toBe("calculate");
      expect(events[1].parentMessageId).toBe("msg2");
    }

    // Verify tool call args
    expect(events[2].type).toBe("ActionExecutionArgs");
    expect(events[3].type).toBe("ActionExecutionArgs");
    if (events[2].type === "ActionExecutionArgs" && events[3].type === "ActionExecutionArgs") {
      expect(events[2].actionExecutionId).toBe("tool1");
      expect(events[2].args).toBe('{"query":"test search"}');
      expect(events[3].actionExecutionId).toBe("tool2");
      expect(events[3].args).toBe('{"expression":"2+2"}');
    }

    // Verify tool call ends (in reverse order)
    expect(events[4].type).toBe("ActionExecutionEnd");
    expect(events[5].type).toBe("ActionExecutionEnd");
    if (events[4].type === "ActionExecutionEnd" && events[5].type === "ActionExecutionEnd") {
      expect(events[4].actionExecutionId).toBe("tool2");
      expect(events[5].actionExecutionId).toBe("tool1");
    }
  });

  it("should handle mixed concurrent text messages and tool calls", async () => {
    const mockEvents: BaseEvent[] = [
      // Start a text message
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        role: "assistant",
      } as TextMessageStartEvent,

      // Start a tool call while message is active
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        toolCallName: "web_search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,

      // Add content to text message
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        delta: "Let me search for that...",
      } as TextMessageContentEvent,

      // Add args to tool call
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        delta: '{"query":"concurrent events"}',
      } as ToolCallArgsEvent,

      // Start another text message
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "status_msg",
        role: "assistant",
      } as TextMessageStartEvent,

      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "status_msg",
        delta: "Processing...",
      } as TextMessageContentEvent,

      // End everything
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "thinking_msg",
      } as TextMessageEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search_tool",
      } as ToolCallEndEvent,
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "status_msg",
      } as TextMessageEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(9);

    // Check the sequence matches expected pattern
    const expectedTypes = [
      "TextMessageStart", // thinking_msg start
      "ActionExecutionStart", // search_tool start
      "TextMessageContent", // thinking_msg content
      "ActionExecutionArgs", // search_tool args
      "TextMessageStart", // status_msg start
      "TextMessageContent", // status_msg content
      "TextMessageEnd", // thinking_msg end
      "ActionExecutionEnd", // search_tool end
      "TextMessageEnd", // status_msg end
    ];

    for (let i = 0; i < expectedTypes.length; i++) {
      expect(events[i].type).toBe(expectedTypes[i]);
    }

    // Verify specific content
    const thinkingContent = events.find(
      (e) => e.type === "TextMessageContent" && (e as any).messageId === "thinking_msg",
    );
    expect(thinkingContent).toBeDefined();
    if (thinkingContent?.type === "TextMessageContent") {
      expect(thinkingContent.content).toBe("Let me search for that...");
    }

    const toolArgs = events.find(
      (e) => e.type === "ActionExecutionArgs" && (e as any).actionExecutionId === "search_tool",
    );
    expect(toolArgs).toBeDefined();
    if (toolArgs?.type === "ActionExecutionArgs") {
      expect(toolArgs.args).toBe('{"query":"concurrent events"}');
    }
  });

  it("should handle multiple tool calls on same parent message", async () => {
    const mockEvents: BaseEvent[] = [
      // Start multiple tool calls with same parent
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search1",
        toolCallName: "search",
        parentMessageId: "agent_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "calc1",
        toolCallName: "calculate",
        parentMessageId: "agent_msg",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "format1",
        toolCallName: "format",
        parentMessageId: "agent_msg",
      } as ToolCallStartEvent,

      // Send args for all tool calls
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search1",
        delta: '{"query":"test"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "calc1",
        delta: '{"expression":"2*3"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "format1",
        delta: '{"format":"json"}',
      } as ToolCallArgsEvent,

      // End all tool calls
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search1",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "calc1",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "format1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(9);

    // Verify all start events have same parent
    const startEvents = events.filter((e) => e.type === "ActionExecutionStart");
    expect(startEvents).toHaveLength(3);
    for (const event of startEvents) {
      if (event.type === "ActionExecutionStart") {
        expect(event.parentMessageId).toBe("agent_msg");
      }
    }

    // Verify args events match correct tool calls
    const argsEvents = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(argsEvents).toHaveLength(3);

    const searchArgs = argsEvents.find((e) => (e as any).actionExecutionId === "search1");
    expect(searchArgs).toBeDefined();
    if (searchArgs?.type === "ActionExecutionArgs") {
      expect(searchArgs.args).toBe('{"query":"test"}');
    }

    const calcArgs = argsEvents.find((e) => (e as any).actionExecutionId === "calc1");
    expect(calcArgs).toBeDefined();
    if (calcArgs?.type === "ActionExecutionArgs") {
      expect(calcArgs.args).toBe('{"expression":"2*3"}');
    }

    const formatArgs = argsEvents.find((e) => (e as any).actionExecutionId === "format1");
    expect(formatArgs).toBeDefined();
    if (formatArgs?.type === "ActionExecutionArgs") {
      expect(formatArgs.args).toBe('{"format":"json"}');
    }
  });

  it("should handle high-frequency concurrent events", async () => {
    const mockEvents: BaseEvent[] = [];

    // Create many concurrent messages and tool calls
    const numMessages = 5;
    const numToolCalls = 5;

    // Start all messages
    for (let i = 0; i < numMessages; i++) {
      mockEvents.push({
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now() + i,
        messageId: `msg${i}`,
        role: "assistant",
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      mockEvents.push({
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now() + numMessages + i,
        toolCallId: `tool${i}`,
        toolCallName: `tool_${i}`,
        parentMessageId: `tool_msg${i}`,
      } as ToolCallStartEvent);
    }

    // Send content for all messages
    for (let i = 0; i < numMessages; i++) {
      mockEvents.push({
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now() + numMessages + numToolCalls + i,
        messageId: `msg${i}`,
        delta: `Content for message ${i}`,
      } as TextMessageContentEvent);
    }

    // Send args for all tool calls
    for (let i = 0; i < numToolCalls; i++) {
      mockEvents.push({
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now() + numMessages * 2 + numToolCalls + i,
        toolCallId: `tool${i}`,
        delta: `{"param${i}":"value${i}"}`,
      } as ToolCallArgsEvent);
    }

    // End all in reverse order
    for (let i = numMessages - 1; i >= 0; i--) {
      mockEvents.push({
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now() + numMessages * 2 + numToolCalls * 2 + (numMessages - 1 - i),
        messageId: `msg${i}`,
      } as TextMessageEndEvent);
    }

    for (let i = numToolCalls - 1; i >= 0; i--) {
      mockEvents.push({
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now() + numMessages * 3 + numToolCalls * 2 + (numToolCalls - 1 - i),
        toolCallId: `tool${i}`,
      } as ToolCallEndEvent);
    }

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    // Should have: numMessages starts + numToolCalls starts + numMessages content + numToolCalls args + numMessages ends + numToolCalls ends
    const expectedLength = numMessages * 3 + numToolCalls * 3;
    expect(events).toHaveLength(expectedLength);

    // Verify all message starts are present
    const messageStarts = events.filter((e) => e.type === "TextMessageStart");
    expect(messageStarts).toHaveLength(numMessages);
    for (let i = 0; i < numMessages; i++) {
      const start = messageStarts.find((e) => (e as any).messageId === `msg${i}`);
      expect(start).toBeDefined();
    }

    // Verify all tool call starts are present
    const toolStarts = events.filter((e) => e.type === "ActionExecutionStart");
    expect(toolStarts).toHaveLength(numToolCalls);
    for (let i = 0; i < numToolCalls; i++) {
      const start = toolStarts.find((e) => (e as any).actionExecutionId === `tool${i}`);
      expect(start).toBeDefined();
      if (start?.type === "ActionExecutionStart") {
        expect(start.actionName).toBe(`tool_${i}`);
      }
    }

    // Verify all message content is present
    const messageContent = events.filter((e) => e.type === "TextMessageContent");
    expect(messageContent).toHaveLength(numMessages);
    for (let i = 0; i < numMessages; i++) {
      const content = messageContent.find((e) => (e as any).messageId === `msg${i}`);
      expect(content).toBeDefined();
      if (content?.type === "TextMessageContent") {
        expect(content.content).toBe(`Content for message ${i}`);
      }
    }

    // Verify all tool call args are present
    const toolArgs = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(toolArgs).toHaveLength(numToolCalls);
    for (let i = 0; i < numToolCalls; i++) {
      const args = toolArgs.find((e) => (e as any).actionExecutionId === `tool${i}`);
      expect(args).toBeDefined();
      if (args?.type === "ActionExecutionArgs") {
        expect(args.args).toBe(`{"param${i}":"value${i}"}`);
      }
    }
  });

  it("should handle interleaved content and args updates correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start concurrent message and tool call
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg1",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool1",
        toolCallName: "search",
        parentMessageId: "tool_msg1",
      } as ToolCallStartEvent,

      // Interleave content and args updates
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "Searching ",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: '{"que',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "for ",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: 'ry":"',
      } as ToolCallArgsEvent,
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg1",
        delta: "information...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool1",
        delta: 'test"}',
      } as ToolCallArgsEvent,

      // End both
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg1",
      } as TextMessageEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(10);

    // Verify the interleaved pattern
    expect(events[0].type).toBe("TextMessageStart");
    expect(events[1].type).toBe("ActionExecutionStart");
    expect(events[2].type).toBe("TextMessageContent");
    expect(events[3].type).toBe("ActionExecutionArgs");
    expect(events[4].type).toBe("TextMessageContent");
    expect(events[5].type).toBe("ActionExecutionArgs");
    expect(events[6].type).toBe("TextMessageContent");
    expect(events[7].type).toBe("ActionExecutionArgs");
    expect(events[8].type).toBe("TextMessageEnd");
    expect(events[9].type).toBe("ActionExecutionEnd");

    // Verify content chunks
    const contentEvents = events.filter((e) => e.type === "TextMessageContent");
    expect(contentEvents).toHaveLength(3);
    if (contentEvents[0]?.type === "TextMessageContent") {
      expect(contentEvents[0].content).toBe("Searching ");
    }
    if (contentEvents[1]?.type === "TextMessageContent") {
      expect(contentEvents[1].content).toBe("for ");
    }
    if (contentEvents[2]?.type === "TextMessageContent") {
      expect(contentEvents[2].content).toBe("information...");
    }

    // Verify args chunks
    const argsEvents = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(argsEvents).toHaveLength(3);
    if (argsEvents[0]?.type === "ActionExecutionArgs") {
      expect(argsEvents[0].args).toBe('{"que');
    }
    if (argsEvents[1]?.type === "ActionExecutionArgs") {
      expect(argsEvents[1].args).toBe('ry":"');
    }
    if (argsEvents[2]?.type === "ActionExecutionArgs") {
      expect(argsEvents[2].args).toBe('test"}');
    }
  });

  it("should handle concurrent operations with predictive state updates", async () => {
    const mockEvents: BaseEvent[] = [
      // Set up predictive state
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "search_results",
            tool: "search",
            tool_argument: "query",
          },
          {
            state_key: "calculation",
            tool: "calculate",
            tool_argument: "expression",
          },
        ],
      } as CustomEvent,

      // Start concurrent tool calls
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search1",
        toolCallName: "search",
        parentMessageId: "msg1",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "calc1",
        toolCallName: "calculate",
        parentMessageId: "msg2",
      } as ToolCallStartEvent,

      // Send args that should trigger state updates
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search1",
        delta: '{"query":"concurrent test"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "calc1",
        delta: '{"expression":"5*5"}',
      } as ToolCallArgsEvent,

      // End tool calls
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search1",
      } as ToolCallEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "calc1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    // Should have: PredictState + 2 starts + 2 args + 2 state updates + 2 ends = 9 events
    expect(events).toHaveLength(9);

    // First event should be the meta event
    expect(events[0].type).toBe("MetaEvent");

    // Should have state update events triggered by the tool call args
    const stateEvents = events.filter((e) => e.type === "AgentStateMessage");
    expect(stateEvents).toHaveLength(2);

    // Verify first state update (from search)
    if (stateEvents[0]?.type === "AgentStateMessage") {
      const state = JSON.parse(stateEvents[0].state);
      expect(state.search_results).toBe("concurrent test");
    }

    // Verify second state update (from calculation)
    if (stateEvents[1]?.type === "AgentStateMessage") {
      const state = JSON.parse(stateEvents[1].state);
      expect(state.calculation).toBe("5*5");
    }
  });

  it("should handle concurrent operations with lifecycle steps", async () => {
    const mockEvents: BaseEvent[] = [
      // Start a step
      {
        type: EventType.STEP_STARTED,
        timestamp: Date.now(),
        stepName: "processing",
      } as StepStartedEvent,

      // Start concurrent operations during the step
      {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        role: "assistant",
      } as TextMessageStartEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        toolCallName: "search",
        parentMessageId: "tool_msg",
      } as ToolCallStartEvent,

      // Add content and args
      {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "thinking_msg",
        delta: "Analyzing...",
      } as TextMessageContentEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "search_tool",
        delta: '{"query":"analysis"}',
      } as ToolCallArgsEvent,

      // End operations
      {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "thinking_msg",
      } as TextMessageEndEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "search_tool",
      } as ToolCallEndEvent,

      // End the step
      {
        type: EventType.STEP_FINISHED,
        timestamp: Date.now(),
        stepName: "processing",
      } as StepFinishedEvent,
    ];

    const events = (await convertToLegacyEvents(
      defaultParams.threadId,
      defaultParams.runId,
      defaultParams.agentName,
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(8);

    // Verify the sequence includes step lifecycle and concurrent operations
    expect(events[0].type).toBe("AgentStateMessage"); // Step start
    expect(events[1].type).toBe("TextMessageStart");
    expect(events[2].type).toBe("ActionExecutionStart");
    expect(events[3].type).toBe("TextMessageContent");
    expect(events[4].type).toBe("ActionExecutionArgs");
    expect(events[5].type).toBe("TextMessageEnd");
    expect(events[6].type).toBe("ActionExecutionEnd");
    expect(events[7].type).toBe("AgentStateMessage"); // Step end

    // Verify step states
    const stepStates = events.filter((e) => e.type === "AgentStateMessage");
    expect(stepStates).toHaveLength(2);
    if (stepStates[0]?.type === "AgentStateMessage") {
      expect(stepStates[0].active).toBe(true);
    }
    if (stepStates[1]?.type === "AgentStateMessage") {
      expect(stepStates[1].active).toBe(false);
    }
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.predictive.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import {
  BaseEvent,
  EventType,
  CustomEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  StateSnapshotEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";
import { toArray } from "rxjs/operators";

describe("convertToLegacyEvents", () => {
  it("should handle predictive state and tool call events", async () => {
    const mockEvents: BaseEvent[] = [
      // First, send a predict state event
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "greeting",
            tool: "make_greeting",
            tool_argument: "message",
          },
        ],
      } as CustomEvent,
      // Then, send the tool call start event
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
        toolCallName: "make_greeting",
      } as ToolCallStartEvent,
      // Send partial JSON arguments in multiple deltas
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
        delta: '{"message": "Hello',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
        delta: ' world!"}',
      } as ToolCallArgsEvent,
      // Finally, end the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "greeting-1",
      } as ToolCallEndEvent,
    ];

    const result = convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents));

    const events = (await result.pipe(toArray()).toPromise()) as LegacyRuntimeProtocolEvent[];
    expect(events).toHaveLength(7);

    // First event should be the predict state meta event
    expect(events[0].type).toBe("MetaEvent");
    if (events[0].type === "MetaEvent") {
      expect(events[0].name).toBe("PredictState");
      expect(events[0].value).toEqual([
        {
          state_key: "greeting",
          tool: "make_greeting",
          tool_argument: "message",
        },
      ]);
    }

    // Second event should be the tool call start
    expect(events[1].type).toBe("ActionExecutionStart");
    if (events[1].type === "ActionExecutionStart") {
      expect(events[1].actionName).toBe("make_greeting");
      expect(events[1].actionExecutionId).toBe("greeting-1");
    }

    // Third event should be the first tool call args
    expect(events[2].type).toBe("ActionExecutionArgs");
    if (events[2].type === "ActionExecutionArgs") {
      expect(events[2].actionExecutionId).toBe("greeting-1");
      expect(events[2].args).toBe('{"message": "Hello');
    }

    // Fourth event should be the agent state message (after first delta)
    expect(events[3].type).toBe("AgentStateMessage");
    if (events[3].type === "AgentStateMessage") {
      expect(events[3].threadId).toBe("test-thread");
      expect(events[3].agentName).toBe("test-agent");
      expect(events[3].runId).toBe("test-run");
      expect(events[3].active).toBe(true);
      expect(events[3].role).toBe("assistant");
      expect(JSON.parse(events[3].state)).toEqual({ greeting: "Hello" });
      expect(events[3].running).toBe(true);
    }

    // Fifth event should be the second tool call args
    expect(events[4].type).toBe("ActionExecutionArgs");
    if (events[4].type === "ActionExecutionArgs") {
      expect(events[4].actionExecutionId).toBe("greeting-1");
      expect(events[4].args).toBe(' world!"}');
    }

    // Sixth event should be the agent state message (after complete JSON)
    expect(events[5].type).toBe("AgentStateMessage");
    if (events[5].type === "AgentStateMessage") {
      expect(events[5].threadId).toBe("test-thread");
      expect(events[5].agentName).toBe("test-agent");
      expect(events[5].runId).toBe("test-run");
      expect(events[5].active).toBe(true);
      expect(events[5].role).toBe("assistant");
      expect(JSON.parse(events[5].state)).toEqual({ greeting: "Hello world!" });
      expect(events[5].running).toBe(true);
    }

    // Seventh event should be the tool call end
    expect(events[6].type).toBe("ActionExecutionEnd");
    if (events[6].type === "ActionExecutionEnd") {
      expect(events[6].actionExecutionId).toBe("greeting-1");
    }
  });

  it("should handle predictive state without tool_argument, including all args in state", async () => {
    const mockEvents: BaseEvent[] = [
      // First, send a predict state event without tool_argument
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "user_preferences",
            tool: "update_preferences",
          },
        ],
      } as CustomEvent,
      // Then, send the tool call start event
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
        toolCallName: "update_preferences",
      } as ToolCallStartEvent,
      // Send partial JSON arguments in multiple deltas
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
        delta: '{"theme": "dark", "language": "en',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
        delta: '", "notifications": true}',
      } as ToolCallArgsEvent,
      // Finally, end the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "prefs-1",
      } as ToolCallEndEvent,
    ];

    const result = convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents));

    const events = (await result.pipe(toArray()).toPromise()) as LegacyRuntimeProtocolEvent[];
    expect(events).toHaveLength(7);

    // First event should be the predict state meta event
    expect(events[0].type).toBe("MetaEvent");
    if (events[0].type === "MetaEvent") {
      expect(events[0].name).toBe("PredictState");
      expect(events[0].value).toEqual([
        {
          state_key: "user_preferences",
          tool: "update_preferences",
        },
      ]);
    }

    // Second event should be the tool call start
    expect(events[1].type).toBe("ActionExecutionStart");
    if (events[1].type === "ActionExecutionStart") {
      expect(events[1].actionName).toBe("update_preferences");
      expect(events[1].actionExecutionId).toBe("prefs-1");
    }

    // Third event should be the first tool call args
    expect(events[2].type).toBe("ActionExecutionArgs");
    if (events[2].type === "ActionExecutionArgs") {
      expect(events[2].actionExecutionId).toBe("prefs-1");
      expect(events[2].args).toBe('{"theme": "dark", "language": "en');
    }

    // Fourth event should be the agent state message (after first delta)
    expect(events[3].type).toBe("AgentStateMessage");
    if (events[3].type === "AgentStateMessage") {
      expect(events[3].threadId).toBe("test-thread");
      expect(events[3].agentName).toBe("test-agent");
      expect(events[3].runId).toBe("test-run");
      expect(events[3].active).toBe(true);
      expect(events[3].role).toBe("assistant");
      expect(JSON.parse(events[3].state)).toEqual({
        user_preferences: { theme: "dark", language: "en" },
      });
      expect(events[3].running).toBe(true);
    }

    // Fifth event should be the second tool call args
    expect(events[4].type).toBe("ActionExecutionArgs");
    if (events[4].type === "ActionExecutionArgs") {
      expect(events[4].actionExecutionId).toBe("prefs-1");
      expect(events[4].args).toBe('", "notifications": true}');
    }

    // Sixth event should be the agent state message (after complete JSON)
    expect(events[5].type).toBe("AgentStateMessage");
    if (events[5].type === "AgentStateMessage") {
      expect(events[5].threadId).toBe("test-thread");
      expect(events[5].agentName).toBe("test-agent");
      expect(events[5].runId).toBe("test-run");
      expect(events[5].active).toBe(true);
      expect(events[5].role).toBe("assistant");
      expect(JSON.parse(events[5].state)).toEqual({
        user_preferences: {
          theme: "dark",
          language: "en",
          notifications: true,
        },
      });
      expect(events[5].running).toBe(true);
    }

    // Seventh event should be the tool call end
    expect(events[6].type).toBe("ActionExecutionEnd");
    if (events[6].type === "ActionExecutionEnd") {
      expect(events[6].actionExecutionId).toBe("prefs-1");
    }
  });

  it("should handle step events and state snapshots correctly", async () => {
    const mockEvents: BaseEvent[] = [
      // Start a step
      {
        type: EventType.STEP_STARTED,
        timestamp: Date.now(),
        stepName: "process_task",
      } as StepStartedEvent,
      // Send a predict state event
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "current_task",
            tool: "update_task",
          },
        ],
      } as CustomEvent,
      // Start a tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "task-1",
        toolCallName: "update_task",
      } as ToolCallStartEvent,
      // Send tool call args
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "task-1",
        delta: '{"status": "in_progress", "progress": 50, "details": "Processing data"}',
      } as ToolCallArgsEvent,
      // End the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "task-1",
      } as ToolCallEndEvent,
      // End the step
      {
        type: EventType.STEP_FINISHED,
        timestamp: Date.now(),
        stepName: "process_task",
      } as StepFinishedEvent,
      // Send a state snapshot
      {
        type: EventType.STATE_SNAPSHOT,
        timestamp: Date.now(),
        snapshot: {
          current_task: {
            status: "completed",
            progress: 100,
            details: "Task finished",
          },
        },
      } as StateSnapshotEvent,
      // Start another tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "task-2",
        toolCallName: "update_task",
      } as ToolCallStartEvent,
      // Send tool call args
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "task-2",
        delta: '{"status": "new_task", "progress": 0}',
      } as ToolCallArgsEvent,
      // End the tool call
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "task-2",
      } as ToolCallEndEvent,
    ];

    const result = convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents));

    const events = (await result.pipe(toArray()).toPromise()) as LegacyRuntimeProtocolEvent[];
    expect(events).toHaveLength(11);

    // First event should be the agent state message (after step start)
    expect(events[0].type).toBe("AgentStateMessage");
    if (events[0].type === "AgentStateMessage") {
      expect(events[0].threadId).toBe("test-thread");
      expect(events[0].agentName).toBe("test-agent");
      expect(events[0].runId).toBe("test-run");
      expect(events[0].active).toBe(true);
      expect(events[0].role).toBe("assistant");
      expect(JSON.parse(events[0].state)).toEqual({});
      expect(events[0].running).toBe(true);
    }

    // Second event should be the predict state meta event
    expect(events[1].type).toBe("MetaEvent");
    if (events[1].type === "MetaEvent") {
      expect(events[1].name).toBe("PredictState");
      expect(events[1].value).toEqual([
        {
          state_key: "current_task",
          tool: "update_task",
        },
      ]);
    }

    // Third event should be the tool call start
    expect(events[2].type).toBe("ActionExecutionStart");
    if (events[2].type === "ActionExecutionStart") {
      expect(events[2].actionName).toBe("update_task");
      expect(events[2].actionExecutionId).toBe("task-1");
    }

    // Fourth event should be the first tool call args
    expect(events[3].type).toBe("ActionExecutionArgs");
    if (events[3].type === "ActionExecutionArgs") {
      expect(events[3].actionExecutionId).toBe("task-1");
      expect(events[3].args).toBe(
        '{"status": "in_progress", "progress": 50, "details": "Processing data"}',
      );
    }

    // Fifth event should be the agent state message (after tool call args)
    expect(events[4].type).toBe("AgentStateMessage");
    if (events[4].type === "AgentStateMessage") {
      expect(events[4].threadId).toBe("test-thread");
      expect(events[4].agentName).toBe("test-agent");
      expect(events[4].runId).toBe("test-run");
      expect(events[4].active).toBe(true);
      expect(events[4].role).toBe("assistant");
      expect(JSON.parse(events[4].state)).toEqual({
        current_task: {
          status: "in_progress",
          progress: 50,
          details: "Processing data",
        },
      });
      expect(events[4].running).toBe(true);
    }

    // Sixth event should be the tool call end
    expect(events[5].type).toBe("ActionExecutionEnd");
    if (events[5].type === "ActionExecutionEnd") {
      expect(events[5].actionExecutionId).toBe("task-1");
    }

    // Seventh event should be the agent state message (after step finished)
    expect(events[6].type).toBe("AgentStateMessage");
    if (events[6].type === "AgentStateMessage") {
      expect(events[6].threadId).toBe("test-thread");
      expect(events[6].agentName).toBe("test-agent");
      expect(events[6].runId).toBe("test-run");
      expect(events[6].active).toBe(false);
      expect(events[6].role).toBe("assistant");
      expect(JSON.parse(events[6].state)).toEqual({
        current_task: {
          status: "in_progress",
          progress: 50,
          details: "Processing data",
        },
      });
      expect(events[6].running).toBe(true);
    }

    // Eighth event should be the agent state message (after state snapshot)
    expect(events[7].type).toBe("AgentStateMessage");
    if (events[7].type === "AgentStateMessage") {
      expect(events[7].threadId).toBe("test-thread");
      expect(events[7].agentName).toBe("test-agent");
      expect(events[7].runId).toBe("test-run");
      expect(events[7].active).toBe(true);
      expect(events[7].role).toBe("assistant");
      expect(JSON.parse(events[7].state)).toEqual({
        current_task: {
          status: "completed",
          progress: 100,
          details: "Task finished",
        },
      });
      expect(events[7].running).toBe(true);
    }

    // Ninth event should be the second tool call start
    expect(events[8].type).toBe("ActionExecutionStart");
    if (events[8].type === "ActionExecutionStart") {
      expect(events[8].actionName).toBe("update_task");
      expect(events[8].actionExecutionId).toBe("task-2");
    }

    // Tenth event should be the second tool call args
    expect(events[9].type).toBe("ActionExecutionArgs");
    if (events[9].type === "ActionExecutionArgs") {
      expect(events[9].actionExecutionId).toBe("task-2");
      expect(events[9].args).toBe('{"status": "new_task", "progress": 0}');
    }

    // Eleventh event should be the second tool call end
    expect(events[10].type).toBe("ActionExecutionEnd");
    if (events[10].type === "ActionExecutionEnd") {
      expect(events[10].actionExecutionId).toBe("task-2");
    }
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.state.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  BaseEvent,
  EventType,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  CustomEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";

describe("convertToLegacyEvents - State Management", () => {
  const defaultParams = {
    threadId: "test-thread",
    runId: "test-run",
    agentName: "test-agent",
  };

  it("should handle state updates from complete tool call arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "user",
            tool: "update_user",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-1",
        toolCallName: "update_user",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-1",
        delta: '{"data": {"name": "John", "age": 30}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(5);
    expect(events[0].type).toBe("MetaEvent");
    expect(events[1].type).toBe("ActionExecutionStart");
    expect(events[2].type).toBe("ActionExecutionArgs");
    expect(events[3].type).toBe("AgentStateMessage");
    expect(events[4].type).toBe("ActionExecutionEnd");

    // Verify state update
    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        user: { name: "John", age: 30 },
      });
    }
  });

  it("should handle partial state updates from incomplete JSON", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "settings",
            tool: "update_settings",
            tool_argument: "config",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-2",
        toolCallName: "update_settings",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '{"config": {"theme": "dark", "fontSize": 14',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: ', "notifications": true}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-2",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    // Verify intermediate state update
    const stateEvents = events.filter((e) => e.type === "AgentStateMessage");
    expect(stateEvents).toHaveLength(2);
    if (stateEvents[0]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[0].state)).toEqual({
        settings: { theme: "dark", fontSize: 14 },
      });
    }
    if (stateEvents[1]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[1].state)).toEqual({
        settings: { theme: "dark", fontSize: 14, notifications: true },
      });
    }
  });

  it("should handle state updates with nested objects", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "profile",
            tool: "update_profile",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-3",
        toolCallName: "update_profile",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-3",
        delta:
          '{"data": {"personal": {"name": "Alice", "age": 25}, "preferences": {"theme": "light"}}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-3",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        profile: {
          personal: { name: "Alice", age: 25 },
          preferences: { theme: "light" },
        },
      });
    }
  });

  it("should handle state updates with arrays", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "tasks",
            tool: "update_tasks",
            tool_argument: "list",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-4",
        toolCallName: "update_tasks",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-4",
        delta: '{"list": {"items": ["task1", "task2", "task3"]}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-4",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        tasks: { items: ["task1", "task2", "task3"] },
      });
    }
  });

  it("should handle empty state updates", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "empty",
            tool: "clear_state",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-5",
        toolCallName: "clear_state",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-5",
        delta: '{"data": {}}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-5",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        empty: {},
      });
    }
  });

  it("should handle invalid state updates (malformed JSON)", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "invalid",
            tool: "update_invalid",
            tool_argument: "data",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-6",
        toolCallName: "update_invalid",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-6",
        delta: '{"data": {"invalid": "json"', // Incomplete JSON
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-6",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvent = events.find((e) => e.type === "AgentStateMessage");
    expect(stateEvent).toBeDefined();
    if (stateEvent?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvent.state)).toEqual({
        invalid: { invalid: "json" }, // The JSON is actually valid when wrapped in data object
      });
    }
  });

  it("should handle state rollback scenarios", async () => {
    const mockEvents: BaseEvent[] = [
      // First update
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "counter",
            tool: "increment",
            tool_argument: "value",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-7",
        toolCallName: "increment",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-7",
        delta: '{"value": 1}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-7",
      } as ToolCallEndEvent,
      // Second update (rollback)
      {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "PredictState",
        value: [
          {
            state_key: "counter",
            tool: "decrement",
            tool_argument: "value",
          },
        ],
      } as CustomEvent,
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-8",
        toolCallName: "decrement",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-8",
        delta: '{"value": 0}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-8",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    const stateEvents = events.filter((e) => e.type === "AgentStateMessage");
    expect(stateEvents).toHaveLength(2);
    if (stateEvents[0]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[0].state)).toEqual({
        counter: 1, // The value is directly assigned
      });
    }
    if (stateEvents[1]?.type === "AgentStateMessage") {
      expect(JSON.parse(stateEvents[1].state)).toEqual({
        counter: 0, // The value is directly assigned
      });
    }
  });
});



================================================
FILE: typescript-sdk/packages/client/src/legacy/__tests__/convert.tool-calls.test.ts
================================================
import { convertToLegacyEvents } from "../convert";
import { of } from "rxjs";
import { toArray } from "rxjs/operators";
import {
  BaseEvent,
  EventType,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
} from "@ag-ui/core";
import { LegacyRuntimeProtocolEvent } from "../types";

describe("convertToLegacyEvents - Tool Call Sequences", () => {
  const defaultParams = {
    threadId: "test-thread",
    runId: "test-run",
    agentName: "test-agent",
  };

  it("should handle basic tool call lifecycle (start → args → end)", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-1",
        toolCallName: "test_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-1",
        delta: '{"key": "value"}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-1",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(3);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    expect(events[2].type).toBe("ActionExecutionEnd");
  });

  it("should handle partial/chunked tool call arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-2",
        toolCallName: "test_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '{"complex',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '": "object",',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-2",
        delta: '"value": 123}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-2",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(5);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    expect(events[2].type).toBe("ActionExecutionArgs");
    expect(events[3].type).toBe("ActionExecutionArgs");
    expect(events[4].type).toBe("ActionExecutionEnd");

    // Verify the chunked arguments
    const argsEvents = events.filter((e) => e.type === "ActionExecutionArgs");
    expect(argsEvents[0].args).toBe('{"complex');
    expect(argsEvents[1].args).toBe('": "object",');
    expect(argsEvents[2].args).toBe('"value": 123}');
  });

  it("should handle multiple tool calls in sequence", async () => {
    const mockEvents: BaseEvent[] = [
      // First tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-3",
        toolCallName: "first_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-3",
        delta: '{"first": true}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-3",
      } as ToolCallEndEvent,
      // Second tool call
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-4",
        toolCallName: "second_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-4",
        delta: '{"second": true}',
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-4",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(6);

    // Verify first tool call
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    expect(events[2].type).toBe("ActionExecutionEnd");

    // Verify second tool call
    expect(events[3].type).toBe("ActionExecutionStart");
    expect(events[4].type).toBe("ActionExecutionArgs");
    expect(events[5].type).toBe("ActionExecutionEnd");
  });

  it("should handle tool calls without arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-5",
        toolCallName: "no_args_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-5",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(2);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionEnd");
  });

  it("should handle tool calls with invalid/malformed arguments", async () => {
    const mockEvents: BaseEvent[] = [
      {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "call-6",
        toolCallName: "invalid_args_tool",
      } as ToolCallStartEvent,
      {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "call-6",
        delta: '{"invalid": "json"', // Incomplete JSON
      } as ToolCallArgsEvent,
      {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "call-6",
      } as ToolCallEndEvent,
    ];

    const events = (await convertToLegacyEvents(
      "test-thread",
      "test-run",
      "test-agent",
    )(of(...mockEvents))
      .pipe(toArray())
      .toPromise()) as LegacyRuntimeProtocolEvent[];

    expect(events).toHaveLength(3);
    expect(events[0].type).toBe("ActionExecutionStart");
    expect(events[1].type).toBe("ActionExecutionArgs");
    if (events[1].type === "ActionExecutionArgs") {
      expect(events[1].args).toBe('{"invalid": "json"'); // Should pass through invalid JSON as-is
    }
    expect(events[2].type).toBe("ActionExecutionEnd");
  });
});



================================================
FILE: typescript-sdk/packages/client/src/run/http-request.ts
================================================
import { Observable, from, defer, throwError } from "rxjs";
import { mergeMap, switchMap } from "rxjs/operators";

export enum HttpEventType {
  HEADERS = "headers",
  DATA = "data",
}

export interface HttpDataEvent {
  type: HttpEventType.DATA;
  data?: Uint8Array;
}

export interface HttpHeadersEvent {
  type: HttpEventType.HEADERS;
  status: number;
  headers: Headers;
}

export type HttpEvent = HttpDataEvent | HttpHeadersEvent;

export const runHttpRequest = (url: string, requestInit: RequestInit): Observable<HttpEvent> => {
  // Defer the fetch so that it's executed when subscribed to
  return defer(() => from(fetch(url, requestInit))).pipe(
    switchMap((response) => {
      if (!response.ok) {
        const contentType = response.headers.get("content-type") || "";
        // Read the (small) error body once, then error the stream
        return from(response.text()).pipe(
          mergeMap((text) => {
            let payload: unknown = text;
            if (contentType.includes("application/json")) {
              try { payload = JSON.parse(text); } catch {/* keep raw text */}
            }
            const err: any = new Error(
              `HTTP ${response.status}: ${typeof payload === "string" ? payload : JSON.stringify(payload)}`
            );
            err.status = response.status;
            err.payload = payload;
            return throwError(() => err);
          })
        );
      }
      // Emit headers event first
      const headersEvent: HttpHeadersEvent = {
        type: HttpEventType.HEADERS,
        status: response.status,
        headers: response.headers,
      };

      const reader = response.body?.getReader();
      if (!reader) {
        return throwError(() => new Error("Failed to getReader() from response"));
      }

      return new Observable<HttpEvent>((subscriber) => {
        // Emit headers event first
        subscriber.next(headersEvent);

        (async () => {
          try {
            while (true) {
              const { done, value } = await reader.read();
              if (done) break;
              // Emit data event instead of raw Uint8Array
              const dataEvent: HttpDataEvent = {
                type: HttpEventType.DATA,
                data: value,
              };
              subscriber.next(dataEvent);
            }
            subscriber.complete();
          } catch (error) {
            subscriber.error(error);
          }
        })();

        return () => {
          reader.cancel().catch((error) => {
            if ((error as DOMException)?.name === "AbortError") {
              return;
            }

            throw error;
          });
        };
      });
    }),
  );
};



================================================
FILE: typescript-sdk/packages/client/src/run/index.ts
================================================
export { runHttpRequest as runHttpRequest } from "./http-request";



================================================
FILE: typescript-sdk/packages/client/src/run/__tests__/http-request.test.ts
================================================
import { runHttpRequest, HttpEventType } from "../http-request";

describe("runHttpRequest", () => {
  let originalFetch: any;
  let fetchMock: jest.Mock;

  beforeEach(() => {
    // Save original fetch
    originalFetch = global.fetch;

    // Create a mock fetch function with proper response structure
    fetchMock = jest.fn();
    global.fetch = fetchMock;
  });

  afterEach(() => {
    // Restore original fetch
    global.fetch = originalFetch;
  });

  it("should call fetch with the provided configuration", async () => {
    // Set up test configuration
    const config = {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
      },
      body: JSON.stringify({ key: "value" }),
    };

    // Mock a proper response
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "application/json");

    const mockResponse = {
      ok: true,
      status: 200,
      headers: mockHeaders,
      body: {
        getReader: jest.fn().mockReturnValue({
          read: jest.fn().mockResolvedValue({ done: true }),
          cancel: jest.fn(),
        }),
      },
    };

    fetchMock.mockResolvedValue(mockResponse);

    // Create the run agent function

    // Execute the function which should trigger a fetch call
    const observable = runHttpRequest("https://example.com/api", config);

    // Subscribe to trigger the fetch
    const subscription = observable.subscribe({
      next: () => {},
      error: () => {},
      complete: () => {},
    });

    // Give time for async operations to complete
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Verify fetch was called with the expected parameters
    expect(fetchMock).toHaveBeenCalledWith("https://example.com/api", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: "Bearer test-token",
      },
      body: JSON.stringify({ key: "value" }),
    });

    // Clean up subscription
    subscription.unsubscribe();
  });

  it("should pass an abort signal when provided", async () => {
    // Create an abort controller
    const abortController = new AbortController();

    // Set up test configuration with abort signal
    const config = {
      method: "GET",
      abortSignal: abortController.signal,
    };

    // Mock a proper response
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "application/json");

    const mockResponse = {
      ok: true,
      status: 200,
      headers: mockHeaders,
      body: {
        getReader: jest.fn().mockReturnValue({
          read: jest.fn().mockResolvedValue({ done: true }),
          cancel: jest.fn(),
        }),
      },
    };

    fetchMock.mockResolvedValue(mockResponse);

    // Create the run agent function
    const observable = runHttpRequest("https://example.com/api", config);

    // Subscribe to trigger the fetch
    const subscription = observable.subscribe();

    // Give time for async operations to complete
    await new Promise((resolve) => setTimeout(resolve, 10));

    // Verify fetch was called with the expected configuration
    // The implementation passes the config directly, including abortSignal property
    expect(fetchMock).toHaveBeenCalledWith("https://example.com/api", {
      method: "GET",
      abortSignal: abortController.signal,
    });

    // Clean up subscription
    subscription.unsubscribe();
  });

  it("should emit headers and data events from the response", async () => {
    // Create mock chunks to be returned by the reader
    const chunk1 = new Uint8Array([1, 2, 3]);
    const chunk2 = new Uint8Array([4, 5, 6]);

    // Mock reader that returns multiple chunks before completing
    const mockReader = {
      read: jest
        .fn()
        .mockResolvedValueOnce({ done: false, value: chunk1 })
        .mockResolvedValueOnce({ done: false, value: chunk2 })
        .mockResolvedValueOnce({ done: true }),
      cancel: jest.fn(),
    };

    // Mock response with our custom reader and headers
    const mockHeaders = new Headers();
    mockHeaders.append("Content-Type", "application/json");

    const mockResponse = {
      ok: true,
      status: 200,
      headers: mockHeaders,
      body: {
        getReader: jest.fn().mockReturnValue(mockReader),
      },
    };

    // Override the fetch mock for this specific test
    fetchMock.mockResolvedValue(mockResponse);

    // Set up test configuration
    const config = {
      method: "GET",
    };

    // Create and execute the run agent function
    const observable = runHttpRequest("https://example.com/api", config);

    // Collect the emitted events
    const emittedEvents: any[] = [];
    const subscription = observable.subscribe({
      next: (event) => emittedEvents.push(event),
      error: (err) => fail(`Should not have errored: ${err}`),
      complete: () => {},
    });

    // Wait for all async operations to complete
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify we received the expected events
    expect(emittedEvents.length).toBe(3);

    // First event should be headers
    expect(emittedEvents[0].type).toBe(HttpEventType.HEADERS);
    expect(emittedEvents[0].status).toBe(200);
    expect(emittedEvents[0].headers).toBe(mockHeaders);

    // Second and third events should be data
    expect(emittedEvents[1].type).toBe(HttpEventType.DATA);
    expect(emittedEvents[1].data).toBe(chunk1);

    expect(emittedEvents[2].type).toBe(HttpEventType.DATA);
    expect(emittedEvents[2].data).toBe(chunk2);

    // Verify reader.read was called the expected number of times
    expect(mockReader.read).toHaveBeenCalledTimes(3);

    // Clean up
    subscription.unsubscribe();
  });

  it("should throw HTTP error on occurs", async () => {
    // Mock a 404 error response with JSON body
    const mockHeaders = new Headers();
    mockHeaders.append("content-type", "application/json");

    const mockText = '{"message":"User not found"}';

    const mockResponse = {
      ok: false,
      status: 404,
      headers: mockHeaders,
      // our error-path reads .text() (not streaming)
      text: jest.fn().mockResolvedValue(mockText),
    } as unknown as Response;

    // Override fetch for this test
    fetchMock.mockResolvedValue(mockResponse);

    const observable = runHttpRequest("https://example.com/api", { method: "GET" });

    const nextSpy = jest.fn();

    await new Promise<void>((resolve) => {
      const sub = observable.subscribe({
        next: nextSpy,
        error: (err: any) => {
          // error should carry status + parsed payload
          expect(err).toBeInstanceOf(Error);
          expect(err.status).toBe(404);
          expect(err.payload).toEqual({ message: "User not found" });
          // readable message is okay too (optional)
          expect(err.message).toContain("HTTP 404");
          expect(err.message).toContain("User not found");
          resolve();
          sub.unsubscribe();
        },
        complete: () => {
          fail("Should not complete on HTTP error");
        },
      });
    });

    // Should not have emitted any data events on error short-circuit
    expect(nextSpy).not.toHaveBeenCalled();

    // Ensure we read the error body exactly once
    expect((mockResponse as any).text).toHaveBeenCalledTimes(1);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/transform/http.ts
================================================
import { BaseEvent, EventSchemas } from "@ag-ui/core";
import { Subject, ReplaySubject, Observable } from "rxjs";
import { HttpEvent, HttpEventType } from "../run/http-request";
import { parseSSEStream } from "./sse";
import { parseProtoStream } from "./proto";
import * as proto from "@ag-ui/proto";
import { EventType } from "@ag-ui/core";

/**
 * Transforms HTTP events into BaseEvents using the appropriate format parser based on content type.
 */
export const transformHttpEventStream = (source$: Observable<HttpEvent>): Observable<BaseEvent> => {
  const eventSubject = new Subject<BaseEvent>();

  // Use ReplaySubject to buffer events until we decide on the parser
  const bufferSubject = new ReplaySubject<HttpEvent>();

  // Flag to track whether we've set up the parser
  let parserInitialized = false;

  // Subscribe to source and buffer events while we determine the content type
  source$.subscribe({
    next: (event: HttpEvent) => {
      // Forward event to buffer
      bufferSubject.next(event);

      // If we get headers and haven't initialized a parser yet, check content type
      if (event.type === HttpEventType.HEADERS && !parserInitialized) {
        parserInitialized = true;
        const contentType = event.headers.get("content-type");

        // Choose parser based on content type
        if (contentType === proto.AGUI_MEDIA_TYPE) {
          // Use protocol buffer parser
          parseProtoStream(bufferSubject).subscribe({
            next: (event) => eventSubject.next(event),
            error: (err) => eventSubject.error(err),
            complete: () => eventSubject.complete(),
          });
        } else {
          // Use SSE JSON parser for all other cases
          parseSSEStream(bufferSubject).subscribe({
            next: (json) => {
              try {
                const parsedEvent = EventSchemas.parse(json);
                eventSubject.next(parsedEvent as BaseEvent);
              } catch (err) {
                eventSubject.error(err);
              }
            },
            error: (err) => {
              if ((err as DOMException)?.name === "AbortError") {
                eventSubject.next({
                  type: EventType.RUN_ERROR,
                  rawEvent: err,
                });
                eventSubject.complete();
                return;
              }
              return eventSubject.error(err)
            },
            complete: () => eventSubject.complete(),
          });
        }
      } else if (!parserInitialized) {
        eventSubject.error(new Error("No headers event received before data events"));
      }
    },
    error: (err) => {
      bufferSubject.error(err);
      eventSubject.error(err);
    },
    complete: () => {
      bufferSubject.complete();
    },
  });

  return eventSubject.asObservable();
};



================================================
FILE: typescript-sdk/packages/client/src/transform/index.ts
================================================
export { transformHttpEventStream } from "./http";
export { parseSSEStream } from "./sse";
export { parseProtoStream } from "./proto";



================================================
FILE: typescript-sdk/packages/client/src/transform/proto.ts
================================================
import { Observable, Subject } from "rxjs";
import { HttpEvent, HttpEventType } from "../run/http-request";
import { BaseEvent } from "@ag-ui/core";
import * as proto from "@ag-ui/proto";

/**
 * Parses a stream of HTTP events into a stream of BaseEvent objects using Protocol Buffer format.
 * Each message is prefixed with a 4-byte length header (uint32 in big-endian format)
 * followed by the protocol buffer encoded message.
 */
export const parseProtoStream = (source$: Observable<HttpEvent>): Observable<BaseEvent> => {
  const eventSubject = new Subject<BaseEvent>();
  let buffer = new Uint8Array(0);

  source$.subscribe({
    next: (event: HttpEvent) => {
      if (event.type === HttpEventType.HEADERS) {
        return;
      }

      if (event.type === HttpEventType.DATA && event.data) {
        // Append the new data to our buffer
        const newBuffer = new Uint8Array(buffer.length + event.data.length);
        newBuffer.set(buffer, 0);
        newBuffer.set(event.data, buffer.length);
        buffer = newBuffer;

        // Process as many complete messages as possible
        processBuffer();
      }
    },
    error: (err) => eventSubject.error(err),
    complete: () => {
      // Try to process any remaining data in the buffer
      if (buffer.length > 0) {
        try {
          processBuffer();
        } catch (error: unknown) {
          console.warn("Incomplete or invalid protocol buffer data at stream end");
        }
      }
      eventSubject.complete();
    },
  });

  /**
   * Process as many complete messages as possible from the buffer
   */
  function processBuffer() {
    // Keep processing while we have enough data for at least a header (4 bytes)
    while (buffer.length >= 4) {
      // Read message length from the first 4 bytes (big-endian uint32)
      const view = new DataView(buffer.buffer, buffer.byteOffset, 4);
      const messageLength = view.getUint32(0, false); // false = big-endian

      // Check if we have the complete message (header + message body)
      const totalLength = 4 + messageLength;
      if (buffer.length < totalLength) {
        // Not enough data yet, wait for more
        break;
      }

      try {
        // Extract the message (skipping the 4-byte header)
        const message = buffer.slice(4, totalLength);

        // Decode the protocol buffer message using the imported decode function
        const event = proto.decode(message);

        // Emit the parsed event
        eventSubject.next(event);

        // Remove the processed message from the buffer
        buffer = buffer.slice(totalLength);
      } catch (error: unknown) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        eventSubject.error(new Error(`Failed to decode protocol buffer message: ${errorMessage}`));
        return;
      }
    }
  }

  return eventSubject.asObservable();
};



================================================
FILE: typescript-sdk/packages/client/src/transform/sse.ts
================================================
import { Observable, Subject } from "rxjs";
import { HttpEvent, HttpEventType } from "../run/http-request";

/**
 * Parses a stream of HTTP events into a stream of JSON objects using Server-Sent Events (SSE) format.
 * Strictly follows the SSE standard where:
 * - Events are separated by double newlines ('\n\n')
 * - Only 'data:' prefixed lines are processed
 * - Multi-line data events are supported and joined
 * - Non-data fields (event, id, retry) are ignored
 */
export const parseSSEStream = (source$: Observable<HttpEvent>): Observable<any> => {
  const jsonSubject = new Subject<any>();
  // Create TextDecoder with stream option set to true to handle split UTF-8 characters
  const decoder = new TextDecoder("utf-8", { fatal: false });
  let buffer = "";

  // Subscribe to the source once and multicast to all subscribers
  source$.subscribe({
    next: (event: HttpEvent) => {
      if (event.type === HttpEventType.HEADERS) {
        return;
      }

      if (event.type === HttpEventType.DATA && event.data) {
        // Decode chunk carefully to handle UTF-8
        const text = decoder.decode(event.data, { stream: true });
        buffer += text;

        // Process complete events (separated by double newlines)
        const events = buffer.split(/\n\n/);
        // Keep the last potentially incomplete event in buffer
        buffer = events.pop() || "";

        for (const event of events) {
          processSSEEvent(event);
        }
      }
    },
    error: (err) => jsonSubject.error(err),
    complete: () => {
      // Use the final call to decoder.decode() to flush any remaining bytes
      if (buffer) {
        buffer += decoder.decode();
        // Process any remaining SSE event data
        processSSEEvent(buffer);
      }
      jsonSubject.complete();
    },
  });

  /**
   * Helper function to process an SSE event.
   * Extracts and joins data lines, then parses the result as JSON.
   * Follows the SSE spec by only processing 'data:' prefixed lines.
   * @param eventText The raw event text to process
   */
  function processSSEEvent(eventText: string) {
    const lines = eventText.split("\n");
    const dataLines: string[] = [];

    for (const line of lines) {
      if (line.startsWith("data: ")) {
        // Extract data content (remove 'data: ' prefix)
        dataLines.push(line.slice(6));
      }
    }

    // Only process if we have data lines
    if (dataLines.length > 0) {
      try {
        // Join multi-line data and parse JSON
        const jsonStr = dataLines.join("\n");
        const json = JSON.parse(jsonStr);
        jsonSubject.next(json);
      } catch (err) {
        jsonSubject.error(err);
      }
    }
  }

  return jsonSubject.asObservable();
};



================================================
FILE: typescript-sdk/packages/client/src/transform/__tests__/http.test.ts
================================================
import { transformHttpEventStream } from "../http";
import { HttpEvent, HttpEventType } from "../../run/http-request";
import { parseProtoStream } from "../proto";
import * as proto from "@ag-ui/proto";
import { BaseEvent, EventType } from "@ag-ui/core";
import { Subject, of, throwError } from "rxjs";

// Mock dependencies
jest.mock("../proto", () => ({
  parseProtoStream: jest.fn(),
}));

describe("transformHttpEventStream", () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  test("should correctly transform protocol buffer events", () => {
    // Given
    const mockHttpSource = new Subject<HttpEvent>();
    const mockBaseEvent: BaseEvent = {
      type: EventType.TEXT_MESSAGE_CONTENT,
      timestamp: Date.now(),
    };

    // Mock parseProtoStream to return our test event
    (parseProtoStream as jest.Mock).mockReturnValue(of(mockBaseEvent));

    // Create a list to collect emitted events
    const receivedEvents: BaseEvent[] = [];

    // When
    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe((event) => receivedEvents.push(event));

    // Send a HEADERS event with protocol buffer content type
    mockHttpSource.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers([["content-type", proto.AGUI_MEDIA_TYPE]]),
    });

    // Send a DATA event
    mockHttpSource.next({
      type: HttpEventType.DATA,
      data: new Uint8Array([1, 2, 3, 4]),
    });

    // Complete the stream
    mockHttpSource.complete();

    // Then
    expect(parseProtoStream).toHaveBeenCalled();
    expect(receivedEvents).toEqual([mockBaseEvent]);
  });

  test("should emit RUN_ERROR and complete on AbortError without erroring", () => {
    const mockHttpSource = new Subject<HttpEvent>();
    const receivedEvents: BaseEvent[] = [];
    let completed = false;
    let receivedError: unknown = undefined;

    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe({
      next: (event) => receivedEvents.push(event),
      error: (err) => {
        receivedError = err;
      },
      complete: () => {
        completed = true;
      },
    });

    mockHttpSource.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers([["content-type", "text/event-stream"]]),
    });

    const abortError = { name: "AbortError" } as DOMException;
    mockHttpSource.error(abortError);

    expect(receivedEvents).toHaveLength(1);
    expect(receivedEvents[0].type).toBe(EventType.RUN_ERROR);
    const runErrorEvent = receivedEvents[0] as any;
    expect(runErrorEvent.rawEvent).toBe(abortError);
    expect(completed).toBe(true);
    expect(receivedError).toBeUndefined();
  });

  test("should handle parseProtoStream errors", (done) => {
    // Given
    const mockHttpSource = new Subject<HttpEvent>();
    const testError = new Error("Test proto parsing error");

    // Mock parseProtoStream to throw an error
    (parseProtoStream as jest.Mock).mockReturnValue(throwError(() => testError));

    // When
    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe({
      next: () => {
        // Should not emit any events
        fail("Should not emit events when parseProtoStream errors");
      },
      error: (err) => {
        // Then
        expect(err).toBe(testError);
        done();
      },
    });

    // Send a HEADERS event with protocol buffer content type
    mockHttpSource.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: new Headers([["content-type", proto.AGUI_MEDIA_TYPE]]),
    });
  });

  test("should error if DATA received before HEADERS", (done) => {
    // Given
    const mockHttpSource = new Subject<HttpEvent>();

    // When
    const result$ = transformHttpEventStream(mockHttpSource);
    result$.subscribe({
      next: () => {
        // Should not emit any events
        fail("Should not emit events when DATA received before HEADERS");
      },
      error: (err) => {
        // Then
        expect(err.message).toContain("No headers event received before data events");
        done();
      },
    });

    // Send a DATA event before HEADERS
    mockHttpSource.next({
      type: HttpEventType.DATA,
      data: new Uint8Array([1, 2, 3, 4]),
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/transform/__tests__/proto.test.ts
================================================
import { HttpEvent, HttpEventType } from "../../run/http-request";
import { firstValueFrom, Subject, take } from "rxjs";
import {
  EventType,
  TextMessageStartEvent,
  TextMessageContentEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";
import * as proto from "@ag-ui/proto";
import { transformHttpEventStream } from "../http";
import * as encoder from "@ag-ui/encoder";

const eventEncoder = new encoder.EventEncoder({
  accept: proto.AGUI_MEDIA_TYPE,
});

// Don't mock the proto package so we can use real encoding/decoding
jest.unmock("@ag-ui/proto");

describe("parseProtoStream", () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  it("should correctly decode protocol buffer events", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the first event before emitting
    const firstEventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a test event
    const originalEvent = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg123",
      role: "assistant",
      timestamp: Date.now(),
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(originalEvent);

    // Send the encoded event as a DATA chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: encodedEvent,
    });

    // Await the received event
    const receivedEvent = (await firstEventPromise) as TextMessageStartEvent;

    // Verify we got back the same event
    expect(receivedEvent.type).toEqual(originalEvent.type);
    expect(receivedEvent.timestamp).toEqual(originalEvent.timestamp);
    expect(receivedEvent.messageId).toEqual(originalEvent.messageId);
    expect(receivedEvent.role).toEqual(originalEvent.role);
    // Complete the stream
    chunk$.complete();
  });

  it("should handle multiple protobuf events in a single chunk", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Create a promise that resolves after receiving 2 events
    const eventsPromise = new Promise<any[]>((resolve) => {
      const events: any[] = [];
      event$.subscribe({
        next: (event) => {
          events.push(event);
          if (events.length === 2) {
            resolve(events);
          }
        },
        error: (err) => {
          throw new Error(`Unexpected error: ${err}`);
        },
      });
    });

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create two test events
    const startEvent = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg123",
      role: "assistant",
      timestamp: Date.now(),
    };

    const contentEvent = {
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg123",
      delta: "Hello world",
      timestamp: Date.now(),
    };

    // Encode both events and concatenate them
    const encodedStart = eventEncoder.encodeBinary(startEvent);
    const encodedContent = eventEncoder.encodeBinary(contentEvent);

    // Concatenate the two encoded events
    const combinedData = new Uint8Array(encodedStart.length + encodedContent.length);
    combinedData.set(encodedStart, 0);
    combinedData.set(encodedContent, encodedStart.length);

    // Send the combined data as a single chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: combinedData,
    });

    // Wait for both events to be emitted
    const events = await eventsPromise;

    // Verify we received both events correctly
    expect(events.length).toBe(2);
    expect(events[0].type).toEqual(startEvent.type);
    expect(events[0].messageId).toEqual(startEvent.messageId);
    expect(events[0].role).toEqual(startEvent.role);
    expect(events[1].type).toEqual(contentEvent.type);
    expect(events[1].messageId).toEqual(contentEvent.messageId);
    expect(events[1].delta).toEqual(contentEvent.delta);

    // Complete the stream
    chunk$.complete();
  });

  it("should handle split protobuf event across multiple chunks", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a test event
    const originalEvent = {
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg123",
      delta: "This is a message that will be split across chunks",
      timestamp: Date.now(),
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(originalEvent);

    // Split the encoded event into three parts
    const firstPart = encodedEvent.slice(0, Math.floor(encodedEvent.length / 3));
    const secondPart = encodedEvent.slice(
      Math.floor(encodedEvent.length / 3),
      Math.floor((2 * encodedEvent.length) / 3),
    );
    const thirdPart = encodedEvent.slice(Math.floor((2 * encodedEvent.length) / 3));

    // Send the parts as separate chunks
    chunk$.next({
      type: HttpEventType.DATA,
      data: firstPart,
    });

    chunk$.next({
      type: HttpEventType.DATA,
      data: secondPart,
    });

    chunk$.next({
      type: HttpEventType.DATA,
      data: thirdPart,
    });

    // Complete the stream
    chunk$.complete();

    // Await the received event
    const receivedEvent = (await eventPromise) as TextMessageContentEvent;

    // Verify we got back the same event
    expect(receivedEvent.type).toEqual(originalEvent.type);
    expect(receivedEvent.messageId).toEqual(originalEvent.messageId);
    expect(receivedEvent.delta).toEqual(originalEvent.delta);
  });

  it("should emit error when invalid protobuf data is received", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    let receivedEvent = false;
    let receivedError = false;
    let errorReceived: any = null;

    // Set up a subscription with shorter timeout
    const subscription = event$.subscribe({
      next: () => {
        receivedEvent = true;
      },
      error: (err) => {
        receivedError = true;
        errorReceived = err;
      },
      complete: () => {
        // This is fine if it completes
      },
    });

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send invalid protobuf data (just random bytes)
    const invalidData = new Uint8Array([0x01, 0x02, 0x03, 0xff, 0xee, 0xdd]);

    chunk$.next({
      type: HttpEventType.DATA,
      data: invalidData,
    });

    // Give it a moment to process
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Force completion
    chunk$.complete();

    // Clean up subscription
    subscription.unsubscribe();

    // Here we're just verifying we didn't get an event from invalid data
    // The implementation could either emit an error or just ignore bad data
    expect(receivedEvent).toBe(false);
  }, 3000);

  it("should correctly encode and decode a STATE_DELTA event with JSON patch operations", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a state delta event with JSON patch operations
    const stateDeltaEvent: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: Date.now(),
      delta: [
        { op: "add", path: "/counter", value: 42 },
        { op: "add", path: "/items", value: ["apple", "banana", "cherry"] },
        { op: "replace", path: "/users/123/name", value: "Jane Doe" },
        { op: "remove", path: "/outdated" },
        { op: "move", from: "/oldPath", path: "/newPath" },
        { op: "copy", from: "/source", path: "/destination" },
      ],
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(stateDeltaEvent);

    // Send the encoded event as a DATA chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: encodedEvent,
    });

    // Await the received event
    const receivedEvent = (await eventPromise) as StateDeltaEvent;

    // Verify we got back the same event with all patch operations intact
    expect(receivedEvent.type).toEqual(stateDeltaEvent.type);
    expect(receivedEvent.timestamp).toEqual(stateDeltaEvent.timestamp);

    // Check the JSON patch operations were correctly preserved
    expect(receivedEvent.delta.length).toEqual(stateDeltaEvent.delta.length);

    // Verify each patch operation
    receivedEvent.delta.forEach((operation, index) => {
      expect(operation.op).toEqual(stateDeltaEvent.delta[index].op);
      expect(operation.path).toEqual(stateDeltaEvent.delta[index].path);

      if ("from" in operation) {
        expect(operation.from).toEqual(stateDeltaEvent.delta[index].from);
      }

      if ("value" in operation) {
        expect(operation.value).toEqual(stateDeltaEvent.delta[index].value);
      }
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should correctly encode and decode a MESSAGES_SNAPSHOT event", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first with protobuf content type
    const headers = new Headers();
    headers.append("Content-Type", proto.AGUI_MEDIA_TYPE);

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Create a messages snapshot event with complex message objects
    const messagesSnapshotEvent: MessagesSnapshotEvent = {
      type: EventType.MESSAGES_SNAPSHOT,
      timestamp: Date.now(),
      messages: [
        {
          id: "msg1",
          role: "user",
          content: "Hello, can you help me with something?",
        },
        {
          id: "msg2",
          role: "assistant",
          content: "Of course! How can I assist you today?",
        },
        {
          id: "msg3",
          role: "user",
          content: "I need help with coding",
        },
        {
          id: "msg4",
          role: "assistant",
          content: undefined,
          toolCalls: [
            {
              id: "tool1",
              type: "function",
              function: {
                name: "write_code",
                arguments: JSON.stringify({
                  language: "python",
                  task: "sorting algorithm",
                }),
              },
            },
          ],
        },
      ],
    };

    // Encode the event using the encoder
    const encodedEvent = eventEncoder.encodeBinary(messagesSnapshotEvent);

    // Send the encoded event as a DATA chunk
    chunk$.next({
      type: HttpEventType.DATA,
      data: encodedEvent,
    });

    // Await the received event
    const receivedEvent = (await eventPromise) as MessagesSnapshotEvent;

    // Verify we got back the same event
    expect(receivedEvent.type).toEqual(messagesSnapshotEvent.type);
    expect(receivedEvent.timestamp).toEqual(messagesSnapshotEvent.timestamp);

    // Check the messages array was correctly preserved
    expect(receivedEvent.messages.length).toEqual(messagesSnapshotEvent.messages.length);

    // Verify each message
    receivedEvent.messages.forEach((message, index) => {
      expect(message.id).toEqual(messagesSnapshotEvent.messages[index].id);
      expect(message.role).toEqual(messagesSnapshotEvent.messages[index].role);
      expect(message.content).toEqual(messagesSnapshotEvent.messages[index].content);

      // Check tool calls if present
      if ((messagesSnapshotEvent.messages[index] as any).toolCalls) {
        expect((message as any).toolCalls).toBeDefined();
        expect((message as any).toolCalls!.length).toEqual(
          (messagesSnapshotEvent.messages[index] as any).toolCalls!.length,
        );

        (message as any).toolCalls!.forEach((toolCall: any, toolIndex: number) => {
          const originalToolCall = (messagesSnapshotEvent.messages[index] as any).toolCalls![
            toolIndex
          ];
          expect(toolCall.id).toEqual(originalToolCall.id);
          expect(toolCall.type).toEqual(originalToolCall.type);
          expect(toolCall.function.name).toEqual(originalToolCall.function.name);
          expect(JSON.parse(toolCall.function.arguments)).toEqual(
            JSON.parse(originalToolCall.function.arguments),
          );
        });
      }
    });

    // Complete the stream
    chunk$.complete();
  });
});



================================================
FILE: typescript-sdk/packages/client/src/transform/__tests__/sse.test.ts
================================================
import { Subject } from "rxjs";
import { firstValueFrom } from "rxjs";
import { take } from "rxjs/operators";
import { transformHttpEventStream } from "../http";
import { EventType } from "@ag-ui/core";
import { HttpEvent, HttpEventType } from "../../run/http-request";

describe("transformHttpEventStream", () => {
  it("should emit events as soon as complete SSE events are encountered", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the first event before emitting
    const firstEventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send first chunk with a complete SSE event
    const firstChunkData = new TextEncoder().encode(
      'data: {"type": "TEXT_MESSAGE_START", "messageId": "1", "role": "assistant"}\n\n',
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: firstChunkData,
    });

    // Await the first event
    const firstEvent = await firstEventPromise;
    expect(firstEvent).toEqual({
      type: EventType.TEXT_MESSAGE_START,
      role: "assistant",
      messageId: "1",
    });

    // Set up subscription promise for the second event before emitting
    const secondEventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send second chunk with another complete SSE event
    const secondChunkData = new TextEncoder().encode(
      'data: {"type": "TEXT_MESSAGE_CONTENT", "messageId": "1", "delta": "Hello"}\n\n',
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: secondChunkData,
    });

    // Await the second event
    const secondEvent = await secondEventPromise;
    expect(secondEvent).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello",
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should handle multiple complete SSE events in a single chunk", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Create a promise that resolves after receiving 2 events
    const eventsPromise = new Promise<any[]>((resolve) => {
      const events: any[] = [];
      event$.subscribe({
        next: (event) => {
          events.push(event);
          if (events.length === 2) {
            resolve(events);
          }
        },
        error: (err) => fail(err),
      });
    });

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send a single chunk with multiple complete SSE events
    const multilineJson = new TextEncoder().encode(
      'data: {"type": "TEXT_MESSAGE_START", "messageId": "1", "role": "assistant"}\n\n' +
        'data: {"type": "TEXT_MESSAGE_CONTENT", "messageId": "1", "delta": "Hello"}\n\n',
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: multilineJson,
    });

    // Wait for both events to be emitted
    const events = await eventsPromise;

    // Verify we received both events in the correct order
    expect(events.length).toBe(2);
    expect(events[0]).toEqual({
      type: EventType.TEXT_MESSAGE_START,
      role: "assistant",
      messageId: "1",
    });
    expect(events[1]).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello",
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should handle split SSE event across multiple chunks", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send first part of an SSE event
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('data: {"type": "TEXT_MESSAGE'),
    });

    // Send middle part
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('_START", "messageId": '),
    });

    // Send final part with double newline to complete the SSE event
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('"1", "role": "assistant"}\n\n'),
    });

    // Complete the stream after sending all chunks
    chunk$.complete();

    // Await the complete event
    const event = await eventPromise;

    // Verify we correctly assembled and parsed the JSON
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_START,
      role: "assistant",
      messageId: "1",
    });
  });

  it("should emit error when invalid JSON is received in SSE format", async () => {
    const chunk$ = new Subject<HttpEvent>();
    const event$ = transformHttpEventStream(chunk$);

    // Create a promise that will resolve when an error occurs
    const errorPromise = new Promise<any>((resolve) => {
      event$.subscribe({
        next: () => {
          // This should not be called
          fail("Should not emit events for invalid JSON");
        },
        error: (err) => {
          resolve(err);
        },
        complete: () => {
          fail("Stream should not complete successfully with invalid JSON");
        },
      });
    });

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send invalid JSON (missing closing bracket) in SSE format
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('data: {"type": "TEXT_MESSAGE_START", "messageId": "1"\n\n'),
    });

    // Wait for the error to be caught
    const error = await errorPromise;

    // Verify we got a JSON parsing error
    expect(error).toBeDefined();
    expect(error instanceof SyntaxError || error.message.includes("JSON")).toBeTruthy();
  });

  it("should handle Server-Sent Events (SSE) format with multiple data lines", async () => {
    const chunk$ = new Subject<HttpEvent>();
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$.pipe(take(1)));

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send an SSE formatted event with multi-line data
    const sseData = new TextEncoder().encode(
      "event: message\n" +
        "id: 123\n" +
        "data: {\n" +
        'data: "type": "TEXT_MESSAGE_CONTENT",\n' +
        'data: "messageId": "1",\n' +
        'data: "delta": "Hello World"\n' +
        "data: }\n\n",
    );

    chunk$.next({
      type: HttpEventType.DATA,
      data: sseData,
    });

    // Await the event
    const event = await eventPromise;

    // Verify we received the correct event with the multi-line data properly joined
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello World",
    });

    // Complete the stream
    chunk$.complete();
  });

  it("should handle JSON split between HTTP chunks in a single SSE event", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send the start of the SSE event with first part of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('data: {"type": "TEXT_MESSAGE_CONTENT", "messageId": "1"'),
    });

    // Send the middle part of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode(', "delta": "Hello '),
    });

    // Send the end of the JSON with the closing SSE event markers
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('World"}\n\n'),
    });

    // Complete the stream after sending all chunks
    chunk$.complete();

    // Await the complete event
    const event = await eventPromise;

    // Verify we correctly assembled and parsed the JSON
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Hello World",
    });
  });

  it("should handle SSE with 'data:' prefix split from JSON content", async () => {
    // Create a subject to simulate the HTTP chunk stream
    const chunk$ = new Subject<HttpEvent>();

    // Create the transform stream
    const event$ = transformHttpEventStream(chunk$);

    // Set up subscription promise for the event
    const eventPromise = firstValueFrom(event$);

    // Send headers event first
    const headers = new Headers();
    headers.append("Content-Type", "text/event-stream");

    chunk$.next({
      type: HttpEventType.HEADERS,
      status: 200,
      headers: headers,
    });

    // Send the first chunk with just the SSE prefix
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode("data: "),
    });

    // Send the start of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode('{"type": "TEXT_MESSAGE_CONTENT"'),
    });

    // Send the middle part of the JSON
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode(', "messageId": "1", "delta":'),
    });

    // Send the end of the JSON with the closing SSE event markers
    chunk$.next({
      type: HttpEventType.DATA,
      data: new TextEncoder().encode(' "Split JSON Test"}\n\n'),
    });

    // Complete the stream after sending all chunks
    chunk$.complete();

    // Await the complete event
    const event = await eventPromise;

    // Verify we correctly assembled and parsed the JSON
    expect(event).toEqual({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Split JSON Test",
    });
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/index.ts
================================================
export { verifyEvents } from "./verify";



================================================
FILE: typescript-sdk/packages/client/src/verify/verify.ts
================================================
import { BaseEvent, EventType, AGUIError } from "@ag-ui/core";
import { Observable, throwError, of } from "rxjs";
import { mergeMap } from "rxjs/operators";

export const verifyEvents =
  (debug: boolean) =>
  (source$: Observable<BaseEvent>): Observable<BaseEvent> => {
    // Declare variables in closure to maintain state across events
    let activeMessages = new Map<string, boolean>(); // Map of message ID -> active status
    let activeToolCalls = new Map<string, boolean>(); // Map of tool call ID -> active status
    let runFinished = false;
    let runError = false; // New flag to track if RUN_ERROR has been sent
    // New flags to track first/last event requirements
    let firstEventReceived = false;
    // Track active steps
    let activeSteps = new Map<string, boolean>(); // Map of step name -> active status
    let activeThinkingStep = false;
    let activeThinkingStepMessage = false;
    let runStarted = false; // Track if a run has started

    // Function to reset state for a new run
    const resetRunState = () => {
      activeMessages.clear();
      activeToolCalls.clear();
      activeSteps.clear();
      activeThinkingStep = false;
      activeThinkingStepMessage = false;
      runFinished = false;
      runError = false;
      runStarted = true;
    };

    return source$.pipe(
      // Process each event through our state machine
      mergeMap((event) => {
        const eventType = event.type;

        if (debug) {
          console.debug("[VERIFY]:", JSON.stringify(event));
        }

        // Check if run has errored
        if (runError) {
          return throwError(
            () =>
              new AGUIError(
                `Cannot send event type '${eventType}': The run has already errored with 'RUN_ERROR'. No further events can be sent.`,
              ),
          );
        }

        // Check if run has already finished (but allow new RUN_STARTED to start a new run)
        if (runFinished && eventType !== EventType.RUN_ERROR && eventType !== EventType.RUN_STARTED) {
          return throwError(
            () =>
              new AGUIError(
                `Cannot send event type '${eventType}': The run has already finished with 'RUN_FINISHED'. Start a new run with 'RUN_STARTED'.`,
              ),
          );
        }

        // Handle first event requirement and sequential RUN_STARTED
        if (!firstEventReceived) {
          firstEventReceived = true;
          if (eventType !== EventType.RUN_STARTED && eventType !== EventType.RUN_ERROR) {
            return throwError(() => new AGUIError(`First event must be 'RUN_STARTED'`));
          }
        } else if (eventType === EventType.RUN_STARTED) {
          // Allow RUN_STARTED after RUN_FINISHED (new run), but not during an active run
          if (runStarted && !runFinished) {
            return throwError(
              () =>
                new AGUIError(
                  `Cannot send 'RUN_STARTED' while a run is still active. The previous run must be finished with 'RUN_FINISHED' before starting a new run.`,
                ),
            );
          }
          // If we're here, it's either the first RUN_STARTED or a new run after RUN_FINISHED
          if (runFinished) {
            // This is a new run after the previous one finished, reset state
            resetRunState();
          }
        }

        // Validate event based on type and current state
        switch (eventType) {
          // Text message flow
          case EventType.TEXT_MESSAGE_START: {
            const messageId = (event as any).messageId;

            // Check if this message is already in progress
            if (activeMessages.has(messageId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TEXT_MESSAGE_START' event: A text message with ID '${messageId}' is already in progress. Complete it with 'TEXT_MESSAGE_END' first.`,
                  ),
              );
            }

            activeMessages.set(messageId, true);
            return of(event);
          }

          case EventType.TEXT_MESSAGE_CONTENT: {
            const messageId = (event as any).messageId;

            // Must be in a message with this ID
            if (!activeMessages.has(messageId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID '${messageId}'. Start a text message with 'TEXT_MESSAGE_START' first.`,
                  ),
              );
            }

            return of(event);
          }

          case EventType.TEXT_MESSAGE_END: {
            const messageId = (event as any).messageId;

            // Must be in a message with this ID
            if (!activeMessages.has(messageId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID '${messageId}'. A 'TEXT_MESSAGE_START' event must be sent first.`,
                  ),
              );
            }

            // Remove message from active set
            activeMessages.delete(messageId);
            return of(event);
          }

          // Tool call flow
          case EventType.TOOL_CALL_START: {
            const toolCallId = (event as any).toolCallId;

            // Check if this tool call is already in progress
            if (activeToolCalls.has(toolCallId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TOOL_CALL_START' event: A tool call with ID '${toolCallId}' is already in progress. Complete it with 'TOOL_CALL_END' first.`,
                  ),
              );
            }

            activeToolCalls.set(toolCallId, true);
            return of(event);
          }

          case EventType.TOOL_CALL_ARGS: {
            const toolCallId = (event as any).toolCallId;

            // Must be in a tool call with this ID
            if (!activeToolCalls.has(toolCallId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID '${toolCallId}'. Start a tool call with 'TOOL_CALL_START' first.`,
                  ),
              );
            }

            return of(event);
          }

          case EventType.TOOL_CALL_END: {
            const toolCallId = (event as any).toolCallId;

            // Must be in a tool call with this ID
            if (!activeToolCalls.has(toolCallId)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID '${toolCallId}'. A 'TOOL_CALL_START' event must be sent first.`,
                  ),
              );
            }

            // Remove tool call from active set
            activeToolCalls.delete(toolCallId);
            return of(event);
          }

          // Step flow
          case EventType.STEP_STARTED: {
            const stepName = (event as any).stepName;
            if (activeSteps.has(stepName)) {
              return throwError(
                () => new AGUIError(`Step "${stepName}" is already active for 'STEP_STARTED'`),
              );
            }
            activeSteps.set(stepName, true);
            return of(event);
          }

          case EventType.STEP_FINISHED: {
            const stepName = (event as any).stepName;
            if (!activeSteps.has(stepName)) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'STEP_FINISHED' for step "${stepName}" that was not started`,
                  ),
              );
            }
            activeSteps.delete(stepName);
            return of(event);
          }

          // Run flow
          case EventType.RUN_STARTED: {
            // We've already validated this above
            runStarted = true;
            return of(event);
          }

          case EventType.RUN_FINISHED: {
            // Can't be the first event (already checked)
            // and can't happen after already being finished (already checked)

            // Check that all steps are finished before run ends
            if (activeSteps.size > 0) {
              const unfinishedSteps = Array.from(activeSteps.keys()).join(", ");
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'RUN_FINISHED' while steps are still active: ${unfinishedSteps}`,
                  ),
              );
            }

            // Check that all messages are finished before run ends
            if (activeMessages.size > 0) {
              const unfinishedMessages = Array.from(activeMessages.keys()).join(", ");
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'RUN_FINISHED' while text messages are still active: ${unfinishedMessages}`,
                  ),
              );
            }

            // Check that all tool calls are finished before run ends
            if (activeToolCalls.size > 0) {
              const unfinishedToolCalls = Array.from(activeToolCalls.keys()).join(", ");
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'RUN_FINISHED' while tool calls are still active: ${unfinishedToolCalls}`,
                  ),
              );
            }

            runFinished = true;
            return of(event);
          }

          case EventType.RUN_ERROR: {
            // RUN_ERROR can happen at any time
            runError = true; // Set flag to prevent any further events
            return of(event);
          }

          case EventType.CUSTOM: {
            return of(event);
          }

          // Text message flow
          case EventType.THINKING_TEXT_MESSAGE_START: {
            if (!activeThinkingStep) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_START' event: A thinking step is not in progress. Create one with 'THINKING_START' first.`,
                  ),
              );
            }
            // Can't start a message if one is already in progress
            if (activeThinkingStepMessage) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_START' event: A thinking message is already in progress. Complete it with 'THINKING_TEXT_MESSAGE_END' first.`,
                  ),
              );
            }

            activeThinkingStepMessage = true;
            return of(event);
          }

          case EventType.THINKING_TEXT_MESSAGE_CONTENT: {
            // Must be in a message and IDs must match
            if (!activeThinkingStepMessage) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_CONTENT' event: No active thinking message found. Start a message with 'THINKING_TEXT_MESSAGE_START' first.`,
                  ),
              );
            }

            return of(event);
          }

          case EventType.THINKING_TEXT_MESSAGE_END: {
            // Must be in a message and IDs must match
            if (!activeThinkingStepMessage) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_TEXT_MESSAGE_END' event: No active thinking message found. A 'THINKING_TEXT_MESSAGE_START' event must be sent first.`,
                  ),
              );
            }

            // Reset message state
            activeThinkingStepMessage = false;
            return of(event);
          }

          case EventType.THINKING_START: {
            if (activeThinkingStep) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_START' event: A thinking step is already in progress. End it with 'THINKING_END' first.`,
                  ),
              );
            }

            activeThinkingStep = true;
            return of(event);
          }

          case EventType.THINKING_END: {
            // Must be in a message and IDs must match
            if (!activeThinkingStep) {
              return throwError(
                () =>
                  new AGUIError(
                    `Cannot send 'THINKING_END' event: No active thinking step found. A 'THINKING_START' event must be sent first.`,
                  ),
              );
            }

            // Reset message state
            activeThinkingStep = false;
            return of(event);
          }

          default: {
            return of(event);
          }
        }
      }),
    );
  };



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.concurrent.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents concurrent operations", () => {
  // Test: Concurrent text messages with different IDs should be allowed
  it("should allow concurrent text messages with different IDs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send concurrent text messages
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start first message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Start second message before first one ends
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);

    // Content for both messages
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Content for message 1",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Content for message 2",
    } as TextMessageContentEvent);

    // End messages in different order
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[2].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[7].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Concurrent tool calls with different IDs should be allowed
  it("should allow concurrent tool calls with different IDs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send concurrent tool calls
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start first tool call
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Start second tool call before first one ends
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);

    // Args for both tool calls
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);

    // End tool calls in different order
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool2",
    } as ToolCallEndEvent);

    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[2].type).toBe(EventType.TOOL_CALL_START);
    expect(result[7].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Overlapping text messages and tool calls should be allowed
  it("should allow overlapping text messages and tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send overlapping text messages and tool calls
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start a text message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Start a tool call while message is active
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Send content for both
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Thinking...",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    // Start another message while tool call is active
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);

    // End in various orders
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "Based on the search...",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(11);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[10].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Steps and other lifecycle events should be allowed during concurrent messages/tool calls
  it("should allow lifecycle events during concurrent messages and tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start a step
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "search_step",
    } as StepStartedEvent);

    // Start messages and tool calls within the step
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Lifecycle events should be allowed
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "analysis_step",
    } as StepStartedEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Searching...",
    } as TextMessageContentEvent);

    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);

    // End everything
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);

    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "analysis_step",
    } as StepFinishedEvent);

    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "search_step",
    } as StepFinishedEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(12);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[11].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Should reject duplicate message ID starts
  it("should reject starting a text message with an ID already in progress", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_START' event: A text message with ID 'msg1' is already in progress`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Try to start the same message ID again
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
  });

  // Test: Should reject duplicate tool call ID starts
  it("should reject starting a tool call with an ID already in progress", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_START' event: A tool call with ID 'tool1' is already in progress`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    // Try to start the same tool call ID again
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "calculate",
    } as ToolCallStartEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
  });

  // Test: Should reject content for non-existent message ID
  it("should reject content for non-existent message ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID 'nonexistent'`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send content for a message that was never started
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "nonexistent",
      delta: "test content",
    } as TextMessageContentEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
  });

  // Test: Should reject args for non-existent tool call ID
  it("should reject args for non-existent tool call ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 'nonexistent'`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send args for a tool call that was never started
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "nonexistent",
      delta: '{"test":"value"}',
    } as ToolCallArgsEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
  });

  // Test: Should reject RUN_FINISHED while messages are still active
  it("should reject RUN_FINISHED while text messages are still active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'RUN_FINISHED' while text messages are still active: msg1, msg2`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);

    // Try to finish run while messages are still active
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(3);
  });

  // Test: Should reject RUN_FINISHED while tool calls are still active
  it("should reject RUN_FINISHED while tool calls are still active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'RUN_FINISHED' while tool calls are still active: tool1, tool2`,
        );
        subscription.unsubscribe();
      },
    });

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);

    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);

    // Try to finish run while tool calls are still active
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(3);
  });

  // Test: Complex concurrent scenario with high frequency events
  it("should handle complex concurrent scenario with many overlapping events", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Start multiple concurrent messages and tool calls
    const messageIds = ["msg1", "msg2", "msg3", "msg4", "msg5"];
    const toolCallIds = ["tool1", "tool2", "tool3", "tool4", "tool5"];

    // Start all messages
    for (const msgId of messageIds) {
      source$.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId: msgId,
      } as TextMessageStartEvent);
    }

    // Start all tool calls
    for (const toolId of toolCallIds) {
      source$.next({
        type: EventType.TOOL_CALL_START,
        toolCallId: toolId,
        toolCallName: "test_tool",
      } as ToolCallStartEvent);
    }

    // Send content/args in random order
    for (let i = 0; i < 3; i++) {
      for (const msgId of messageIds) {
        source$.next({
          type: EventType.TEXT_MESSAGE_CONTENT,
          messageId: msgId,
          delta: `Content ${i} for ${msgId}`,
        } as TextMessageContentEvent);
      }

      for (const toolId of toolCallIds) {
        source$.next({
          type: EventType.TOOL_CALL_ARGS,
          toolCallId: toolId,
          delta: `{"step":${i}}`,
        } as ToolCallArgsEvent);
      }
    }

    // End all in reverse order
    for (const msgId of [...messageIds].reverse()) {
      source$.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId: msgId,
      } as TextMessageEndEvent);
    }

    for (const toolId of [...toolCallIds].reverse()) {
      source$.next({
        type: EventType.TOOL_CALL_END,
        toolCallId: toolId,
      } as ToolCallEndEvent);
    }

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify we have the expected number of events:
    // 1 RUN_STARTED + 5 MSG_START + 5 TOOL_START + 15 MSG_CONTENT + 15 TOOL_ARGS + 5 MSG_END + 5 TOOL_END + 1 RUN_FINISHED = 52
    expect(result.length).toBe(52);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[51].type).toBe(EventType.RUN_FINISHED);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.events.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";

describe("verifyEvents general validation", () => {
  // Test: Event IDs must match their parent events (e.g. TEXT_MESSAGE_CONTENT must have same ID as TEXT_MESSAGE_START)
  it("should ensure message content has the same ID as message start", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID 'different-id'. Start a text message with 'TEXT_MESSAGE_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a message start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Send message content with different ID
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "different-id",
      delta: "test content",
    } as TextMessageContentEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TEXT_MESSAGE_START);
  });

  // Test: Cannot end a message that wasn't started
  it("should not allow ending a message that wasn't started", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID 'msg1'. A 'TEXT_MESSAGE_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence without a message start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send message end without a start
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: TOOL_CALL_ARGS must have matching ID with TOOL_CALL_START
  it("should ensure tool call args has the same ID as tool call start", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 'different-id'. Start a tool call with 'TOOL_CALL_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a tool call start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);

    // Send tool call args with different ID
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "different-id",
      delta: "test args",
    } as ToolCallArgsEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TOOL_CALL_START);
  });

  // Test: Cannot end a tool call that wasn't started
  it("should not allow ending a tool call that wasn't started", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID 't1'. A 'TOOL_CALL_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence without a tool call start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send tool call end without a start
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Properly handle CUSTOM and RAW in any context
  it("should allow CUSTOM and RAW in any context", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a sequence with meta and raw events at different places
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.CUSTOM,
      name: "Exit",
      value: undefined,
    } as CustomEvent);
    source$.next({
      type: EventType.RAW,
      event: {
        type: "test_rawEvent",
        content: "test",
      },
    } as RawEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.CUSTOM);
    expect(result[2].type).toBe(EventType.RAW);
  });

  // Test: Properly handle STATE_SNAPSHOT, STATE_DELTA, and MESSAGES_SNAPSHOT
  it("should allow state-related events in appropriate contexts", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a sequence with state events at different places
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "initial",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);
    source$.next({
      type: EventType.MESSAGES_SNAPSHOT,
      messages: [{ role: "user", content: "test" }],
    } as MessagesSnapshotEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.STATE_DELTA,
      delta: [{ op: "add", path: "/result", value: "success" }],
    } as StateDeltaEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(7);
    expect(result[1].type).toBe(EventType.STATE_SNAPSHOT);
    expect(result[3].type).toBe(EventType.MESSAGES_SNAPSHOT);
    expect(result[5].type).toBe(EventType.STATE_DELTA);
  });

  // Test: Complex valid sequence with multiple message types
  it("should allow complex valid sequences with multiple message types", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a complex but valid sequence
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "msg1 content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "t1 args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg2",
      delta: "msg2 content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg2",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(13);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[12].type).toBe(EventType.RUN_FINISHED);
  });
});

describe("verifyEvents events", () => {
  // Test: TEXT_MESSAGE_CONTENT requires TEXT_MESSAGE_START with matching ID
  it("should require TEXT_MESSAGE_START before TEXT_MESSAGE_CONTENT with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID 'different-id'. Start a text message with 'TEXT_MESSAGE_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run and open a message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);

    // Try to send a message content event with a different message ID
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "different-id",
      delta: "test content",
    } as TextMessageContentEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TEXT_MESSAGE_START);
  });

  // Test: TEXT_MESSAGE_END requires TEXT_MESSAGE_START with matching ID
  it("should require TEXT_MESSAGE_START before TEXT_MESSAGE_END with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID 'msg1'. A 'TEXT_MESSAGE_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run without starting a message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send a message end event without a matching start
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: TOOL_CALL_ARGS requires TOOL_CALL_START with matching ID
  it("should require TOOL_CALL_START before TOOL_CALL_ARGS with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 'different-id'. Start a tool call with 'TOOL_CALL_START' first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run and open a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);

    // Try to send a tool args event with a different tool ID
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "different-id",
      delta: "test args",
    } as ToolCallArgsEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.TOOL_CALL_START);
  });

  // Test: TOOL_CALL_END requires TOOL_CALL_START with matching ID
  it("should require TOOL_CALL_START before TOOL_CALL_END with the same ID", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID 't1'. A 'TOOL_CALL_START' event must be sent first.`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run without starting a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to end a tool call without a matching start
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Special events (RAW, CUSTOM, etc.) are allowed outside of tool calls
  it("should allow special events outside of tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with special events
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Meta event
    source$.next({
      type: EventType.CUSTOM,
      name: "Exit",
      value: undefined,
    } as CustomEvent);

    // Raw event
    source$.next({
      type: EventType.RAW,
      event: {
        type: "raw_data",
        content: "test",
      },
    } as RawEvent);

    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.CUSTOM);
    expect(result[2].type).toBe(EventType.RAW);
  });

  // Test: STATE_SNAPSHOT is allowed
  it("should allow STATE_SNAPSHOT events", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state snapshot
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "test_state",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify both events were processed
    expect(result.length).toBe(2);
    expect(result[1].type).toBe(EventType.STATE_SNAPSHOT);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.lifecycle.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents lifecycle", () => {
  // Test: RUN_STARTED must be the first event
  it("should require RUN_STARTED as the first event", async () => {
    const source$ = new Subject<BaseEvent>();
    const result$ = verifyEvents(false)(source$).pipe(
      catchError((err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("First event must be 'RUN_STARTED'");
        throw err;
      }),
    );

    // Set up subscription
    const promise = firstValueFrom(result$).catch((e) => e);

    // Send an event that is not RUN_STARTED
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect it to be an error
    const result = await promise;
    expect(result).toBeInstanceOf(AGUIError);
  });

  // Test: Multiple RUN_STARTED events are not allowed
  it("should not allow multiple RUN_STARTED events", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("Cannot send 'RUN_STARTED' while a run is still active");
        subscription.unsubscribe();
      },
    });

    // Send first RUN_STARTED (should be accepted)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send second RUN_STARTED (should be rejected)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify one event was processed before the error
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: No events should be allowed after RUN_FINISHED (except RUN_ERROR)
  it("should not allow events after RUN_FINISHED (except RUN_ERROR)", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "Cannot send event type 'TEXT_MESSAGE_START': The run has already finished with 'RUN_FINISHED'",
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence then RUN_FINISHED
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Send another event after RUN_FINISHED (should be rejected)
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "2",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify the events before RUN_FINISHED were processed
    expect(events.length).toBe(4);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[3].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: RUN_ERROR is allowed after RUN_FINISHED
  it("should allow RUN_ERROR after RUN_FINISHED", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send valid sequence ending with RUN_FINISHED followed by RUN_ERROR
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed including the RUN_ERROR after RUN_FINISHED
    expect(result.length).toBe(5);
    expect(result[4].type).toBe(EventType.RUN_ERROR);
  });

  // Test: RUN_ERROR can happen at any time (even as the first event)
  it("should allow RUN_ERROR at any time (even as first event)", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send RUN_ERROR as the first event
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify the RUN_ERROR was accepted as first event
    expect(result.length).toBe(1);
    expect(result[0].type).toBe(EventType.RUN_ERROR);
  });

  // Test: No events should be allowed after RUN_ERROR
  it("should not allow any events after RUN_ERROR", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "Cannot send event type 'TEXT_MESSAGE_START': The run has already errored with 'RUN_ERROR'. No further events can be sent.",
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence then RUN_ERROR
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Send another event after RUN_ERROR (should be rejected)
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify the events before RUN_ERROR were processed
    expect(events.length).toBe(2);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[1].type).toBe(EventType.RUN_ERROR);
  });

  // Test: Valid sequence of events is allowed
  it("should allow a valid sequence of events", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[7].type).toBe(EventType.RUN_FINISHED);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.multiple-runs.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents multiple runs", () => {
  // Test: Basic multiple sequential runs
  it("should allow multiple sequential runs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg-1",
      delta: "Hello from run 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg-2",
      delta: "Hello from run 2",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-2",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(10);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect((result[0] as RunStartedEvent).runId).toBe("test-run-1");
    expect(result[4].type).toBe(EventType.RUN_FINISHED);
    expect(result[5].type).toBe(EventType.RUN_STARTED);
    expect((result[5] as RunStartedEvent).runId).toBe("test-run-2");
    expect(result[9].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Multiple runs with different message IDs
  it("should allow reusing message IDs across different runs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run with message ID "msg-1"
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run reusing message ID "msg-1" (should be allowed)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
  });

  // Test: Multiple runs with tool calls
  it("should allow multiple runs with tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run with tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool-1",
      toolCallName: "calculator",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool-1",
      delta: '{"a": 1, "b": 2}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool-1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run with tool call (reusing toolCallId should be allowed)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool-1",
      toolCallName: "weather",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool-1",
      delta: '{"city": "NYC"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool-1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(10);
  });

  // Test: Multiple runs with steps
  it("should allow multiple runs with steps", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run with steps
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "planning",
    } as StepStartedEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "planning",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run reusing step name (should be allowed)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "planning",
    } as StepStartedEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "planning",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
  });

  // Test: Cannot start new run while current run is active
  it("should not allow new RUN_STARTED while run is active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "Cannot send 'RUN_STARTED' while a run is still active",
        );
        subscription.unsubscribe();
      },
    });

    // Start first run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);

    // Try to start second run without finishing first (should fail)
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only first RUN_STARTED was processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Three sequential runs
  it("should allow three sequential runs", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Three sequential runs
    for (let i = 1; i <= 3; i++) {
      source$.next({
        type: EventType.RUN_STARTED,
        threadId: "test-thread-1",
        runId: `test-run-${i}`,
      } as RunStartedEvent);
      source$.next({
        type: EventType.TEXT_MESSAGE_START,
        messageId: `msg-${i}`,
      } as TextMessageStartEvent);
      source$.next({
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: `msg-${i}`,
        delta: `Message from run ${i}`,
      } as TextMessageContentEvent);
      source$.next({
        type: EventType.TEXT_MESSAGE_END,
        messageId: `msg-${i}`,
      } as TextMessageEndEvent);
      source$.next({
        type: EventType.RUN_FINISHED,
      } as RunFinishedEvent);
    }

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed (5 events per run * 3 runs = 15 events)
    expect(result.length).toBe(15);

    // Verify run IDs are correct
    expect((result[0] as RunStartedEvent).runId).toBe("test-run-1");
    expect((result[5] as RunStartedEvent).runId).toBe("test-run-2");
    expect((result[10] as RunStartedEvent).runId).toBe("test-run-3");
  });

  // Test: RUN_ERROR still blocks subsequent events in the same run
  it("should still block events after RUN_ERROR within the same run", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          "The run has already errored with 'RUN_ERROR'",
        );
        subscription.unsubscribe();
      },
    });

    // Start run and send error
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.RUN_ERROR,
      message: "Test error",
    } as RunErrorEvent);

    // Try to send another event (should fail)
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify events before error were processed
    expect(events.length).toBe(2);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[1].type).toBe(EventType.RUN_ERROR);
  });

  // Test: Complex scenario with mixed events across runs
  it("should handle complex scenario with multiple runs and various event types", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // First run: message + tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-1",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool-1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool-1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Second run: step + message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-1",
      runId: "test-run-2",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "analysis",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg-2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg-2",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "analysis",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.RUN_FINISHED,
    } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(12);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[5].type).toBe(EventType.RUN_FINISHED);
    expect(result[6].type).toBe(EventType.RUN_STARTED);
    expect(result[11].type).toBe(EventType.RUN_FINISHED);
  });
});


================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.steps.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  StepStartedEvent,
  StepFinishedEvent,
} from "@ag-ui/core";

describe("verifyEvents steps", () => {
  // Test: STEP_FINISHED must have matching name with STEP_STARTED
  it("should ensure step end has the same name as step start", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'STEP_FINISHED' for step "different-name" that was not started`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a step start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);

    // Send step end with different name
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "different-name",
    } as StepFinishedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.STEP_STARTED);
  });

  // Test: Cannot end a step that wasn't started
  it("should not allow ending a step that wasn't started", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'STEP_FINISHED' for step "test-step" that was not started`,
        );
        subscription.unsubscribe();
      },
    });

    // Send valid sequence without a step start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Send step end without a start
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "test-step",
    } as StepFinishedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Cannot start a step with a name that's already active
  it("should not allow starting a step with a name that's already active", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(`Step "test-step" is already active for 'STEP_STARTED'`);
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with a step start
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);

    // Send another step start with the same name
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(2);
    expect(events[1].type).toBe(EventType.STEP_STARTED);
  });

  // Test: All steps must be ended before RUN_FINISHED
  it("should require all steps to be ended before run ends", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(`Cannot send 'RUN_FINISHED' while steps are still active`);
        subscription.unsubscribe();
      },
    });

    // Send valid sequence with multiple steps
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step2",
    } as StepStartedEvent);
    // Intentionally not finishing step2

    // Try to end the run with active steps
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(4);
    expect(events[3].type).toBe(EventType.STEP_STARTED);
  });

  // Test: Valid sequence with properly nested steps
  it("should allow properly nested steps", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const events: BaseEvent[] = [];
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        fail(`Should not have errored: ${err.message}`);
      },
    });

    // Send a valid sequence with nested steps
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "step1",
    } as StepStartedEvent);

    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "step1",
    } as StepFinishedEvent);

    source$.next({
      type: EventType.RUN_FINISHED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunFinishedEvent);

    // Complete the source and wait for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));
    subscription.unsubscribe();

    // Verify events were processed correctly
    expect(events.length).toBe(4);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
    expect(events[1].type).toBe(EventType.STEP_STARTED);
    expect(events[2].type).toBe(EventType.STEP_FINISHED);
    expect(events[3].type).toBe(EventType.RUN_FINISHED);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.text-messages.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";

describe("verifyEvents text messages", () => {
  // Test: Cannot send TEXT_MESSAGE_CONTENT before TEXT_MESSAGE_START
  it("should not allow TEXT_MESSAGE_CONTENT before TEXT_MESSAGE_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_CONTENT' event: No active text message found with ID '1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send content without starting a text message
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Cannot send TEXT_MESSAGE_END before TEXT_MESSAGE_START
  it("should not allow TEXT_MESSAGE_END before TEXT_MESSAGE_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TEXT_MESSAGE_END' event: No active text message found with ID '1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to end a text message without starting it
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Should allow TEXT_MESSAGE_CONTENT inside a text message
  it("should allow TEXT_MESSAGE_CONTENT inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with text message content
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 2",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[2].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[4].type).toBe(EventType.TEXT_MESSAGE_END);
  });

  // Test: Should allow RAW inside a text message
  it("should allow RAW inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a raw event inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.RAW,
      event: {
        type: "raw_data",
        content: "test",
      },
    } as RawEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.RAW);
  });

  // Test: Should allow CUSTOM inside a text message
  it("should allow CUSTOM inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a custom event inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.CUSTOM,
      name: "test_event",
      value: "test_value",
    } as CustomEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.CUSTOM);
  });

  // Test: Should allow STATE_SNAPSHOT inside a text message
  it("should allow STATE_SNAPSHOT inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state snapshot inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "test_state",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_SNAPSHOT);
  });

  // Test: Should allow STATE_DELTA inside a text message
  it("should allow STATE_DELTA inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state delta inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.STATE_DELTA,
      delta: [{ op: "add", path: "/result", value: "success" }],
    } as StateDeltaEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_DELTA);
  });

  // Test: Should allow MESSAGES_SNAPSHOT inside a text message
  it("should allow MESSAGES_SNAPSHOT inside a text message", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a messages snapshot inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.MESSAGES_SNAPSHOT,
      messages: [{ role: "user", content: "test", id: "test-id" }],
    } as MessagesSnapshotEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.MESSAGES_SNAPSHOT);
  });

  // Test: Should allow lifecycle events (STEP_STARTED/STEP_FINISHED) during text messages
  it("should allow lifecycle events during text messages", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with lifecycle events inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "test content",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "test-step",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(7);
    expect(result[2].type).toBe(EventType.STEP_STARTED);
    expect(result[4].type).toBe(EventType.STEP_FINISHED);
  });

  // Test: Should allow tool calls to start during text messages
  it("should allow tool calls to start during text messages", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with tool calls inside a text message
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Starting search...",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "tool1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "tool1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "tool1",
    } as ToolCallEndEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "Search completed.",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(9);
    expect(result[3].type).toBe(EventType.TOOL_CALL_START);
    expect(result[4].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[5].type).toBe(EventType.TOOL_CALL_END);
  });

  // Test: Sequential text messages
  it("should allow multiple sequential text messages", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with multiple text messages
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // First text message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);

    // Second text message
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "2",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "2",
      delta: "content 2",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "2",
    } as TextMessageEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[2].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_END);
    expect(result[4].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[5].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[6].type).toBe(EventType.TEXT_MESSAGE_END);
  });

  // Test: Text message at run boundaries
  it("should allow text messages immediately after RUN_STARTED and before RUN_FINISHED", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send text message immediately after run start and before run end
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "1",
      delta: "content 1",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "1",
    } as TextMessageEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(5);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_END);
    expect(result[4].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Starting text message before RUN_STARTED
  it("should not allow starting a text message before RUN_STARTED", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("First event must be 'RUN_STARTED'");
        subscription.unsubscribe();
      },
    });

    // Try to start a text message before RUN_STARTED
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "1",
    } as TextMessageStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify no events were processed
    expect(events.length).toBe(0);
  });
});



================================================
FILE: typescript-sdk/packages/client/src/verify/__tests__/verify.tool-calls.test.ts
================================================
import { Subject } from "rxjs";
import { toArray, catchError } from "rxjs/operators";
import { firstValueFrom } from "rxjs";
import { verifyEvents } from "../verify";
import {
  BaseEvent,
  EventType,
  AGUIError,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
  ToolCallStartEvent,
  ToolCallArgsEvent,
  ToolCallEndEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
  StateSnapshotEvent,
  StateDeltaEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";

describe("verifyEvents tool calls", () => {
  // Test: Cannot send TOOL_CALL_ARGS before TOOL_CALL_START
  it("should not allow TOOL_CALL_ARGS before TOOL_CALL_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_ARGS' event: No active tool call found with ID 't1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to send args without starting a tool call
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Cannot send TOOL_CALL_END before TOOL_CALL_START
  it("should not allow TOOL_CALL_END before TOOL_CALL_START", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain(
          `Cannot send 'TOOL_CALL_END' event: No active tool call found with ID 't1'`,
        );
        subscription.unsubscribe();
      },
    });

    // Start a valid run
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // Try to end a tool call without starting it
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify only events before the error were processed
    expect(events.length).toBe(1);
    expect(events[0].type).toBe(EventType.RUN_STARTED);
  });

  // Test: Should allow TOOL_CALL_ARGS and TOOL_CALL_END inside a tool call
  it("should allow TOOL_CALL_ARGS and TOOL_CALL_END inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with tool call events
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args 1",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args 2",
    } as ToolCallArgsEvent); // Multiple args allowed
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[2].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[3].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[4].type).toBe(EventType.TOOL_CALL_END);
  });

  // Test: Should allow RAW inside a tool call
  it("should allow RAW inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a raw event inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.RAW,
      event: {
        type: "raw_data",
        content: "test",
      },
    } as RawEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.RAW);
  });

  // Test: Should allow CUSTOM inside a tool call
  it("should allow CUSTOM inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a custom event inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.CUSTOM,
      name: "test_event",
      value: "test_value",
    } as CustomEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.CUSTOM);
  });

  // Test: Should allow STATE_SNAPSHOT inside a tool call
  it("should allow STATE_SNAPSHOT inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state snapshot inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.STATE_SNAPSHOT,
      snapshot: {
        state: "test_state",
        data: { foo: "bar" },
      },
    } as StateSnapshotEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_SNAPSHOT);
  });

  // Test: Should allow STATE_DELTA inside a tool call
  it("should allow STATE_DELTA inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a state delta inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.STATE_DELTA,
      delta: [{ op: "add", path: "/result", value: "success" }],
    } as StateDeltaEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.STATE_DELTA);
  });

  // Test: Should allow MESSAGES_SNAPSHOT inside a tool call
  it("should allow MESSAGES_SNAPSHOT inside a tool call", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with a messages snapshot inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.MESSAGES_SNAPSHOT,
      messages: [{ role: "user", content: "test", id: "test-id" }],
    } as MessagesSnapshotEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(6);
    expect(result[3].type).toBe(EventType.MESSAGES_SNAPSHOT);
  });

  // Test: Should allow lifecycle events (STEP_STARTED/STEP_FINISHED) during tool calls
  it("should allow lifecycle events during tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with lifecycle events inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.STEP_STARTED,
      stepName: "test-step",
    } as StepStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.STEP_FINISHED,
      stepName: "test-step",
    } as StepFinishedEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(7);
    expect(result[2].type).toBe(EventType.STEP_STARTED);
    expect(result[4].type).toBe(EventType.STEP_FINISHED);
  });

  // Test: Should allow text messages to start during tool calls
  it("should allow text messages to start during tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with text messages inside a tool call
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "Preparing...",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_START,
      messageId: "msg1",
    } as TextMessageStartEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_CONTENT,
      messageId: "msg1",
      delta: "Tool is processing...",
    } as TextMessageContentEvent);
    source$.next({
      type: EventType.TEXT_MESSAGE_END,
      messageId: "msg1",
    } as TextMessageEndEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "Completed.",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(9);
    expect(result[3].type).toBe(EventType.TEXT_MESSAGE_START);
    expect(result[4].type).toBe(EventType.TEXT_MESSAGE_CONTENT);
    expect(result[5].type).toBe(EventType.TEXT_MESSAGE_END);
  });

  // Test: Sequential tool calls
  it("should allow multiple sequential tool calls", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send a valid sequence with multiple tool calls
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);

    // First tool call
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "search",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: '{"query":"test"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);

    // Second tool call
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t2",
      toolCallName: "calculate",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t2",
      delta: '{"expression":"1+1"}',
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t2",
    } as ToolCallEndEvent);

    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(8);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[2].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[3].type).toBe(EventType.TOOL_CALL_END);
    expect(result[4].type).toBe(EventType.TOOL_CALL_START);
    expect(result[5].type).toBe(EventType.TOOL_CALL_ARGS);
    expect(result[6].type).toBe(EventType.TOOL_CALL_END);
  });

  // Test: Tool call at run boundaries
  it("should allow tool calls immediately after RUN_STARTED and before RUN_FINISHED", async () => {
    const source$ = new Subject<BaseEvent>();

    // Set up subscription and collect events
    const promise = firstValueFrom(
      verifyEvents(false)(source$).pipe(
        toArray(),
        catchError((err) => {
          throw err;
        }),
      ),
    );

    // Send tool call immediately after run start and before run end
    source$.next({
      type: EventType.RUN_STARTED,
      threadId: "test-thread-id",
      runId: "test-run-id",
    } as RunStartedEvent);
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);
    source$.next({
      type: EventType.TOOL_CALL_ARGS,
      toolCallId: "t1",
      delta: "test args",
    } as ToolCallArgsEvent);
    source$.next({
      type: EventType.TOOL_CALL_END,
      toolCallId: "t1",
    } as ToolCallEndEvent);
    source$.next({ type: EventType.RUN_FINISHED } as RunFinishedEvent);

    // Complete the source
    source$.complete();

    // Await the promise and expect no errors
    const result = await promise;

    // Verify all events were processed
    expect(result.length).toBe(5);
    expect(result[0].type).toBe(EventType.RUN_STARTED);
    expect(result[1].type).toBe(EventType.TOOL_CALL_START);
    expect(result[3].type).toBe(EventType.TOOL_CALL_END);
    expect(result[4].type).toBe(EventType.RUN_FINISHED);
  });

  // Test: Starting tool call before RUN_STARTED
  it("should not allow starting a tool call before RUN_STARTED", async () => {
    const source$ = new Subject<BaseEvent>();
    const events: BaseEvent[] = [];

    // Create a subscription that will complete only after an error
    const subscription = verifyEvents(false)(source$).subscribe({
      next: (event) => events.push(event),
      error: (err) => {
        expect(err).toBeInstanceOf(AGUIError);
        expect(err.message).toContain("First event must be 'RUN_STARTED'");
        subscription.unsubscribe();
      },
    });

    // Try to start a tool call before RUN_STARTED
    source$.next({
      type: EventType.TOOL_CALL_START,
      toolCallId: "t1",
      toolCallName: "test-tool",
    } as ToolCallStartEvent);

    // Complete the source and wait a bit for processing
    source$.complete();
    await new Promise((resolve) => setTimeout(resolve, 100));

    // Verify no events were processed
    expect(events.length).toBe(0);
  });
});



================================================
FILE: typescript-sdk/packages/core/README.md
================================================
# @ag-ui/core

TypeScript definitions & runtime schemas for the **Agent-User Interaction (AG-UI) Protocol**.

`@ag-ui/core` delivers the strongly-typed building blocks that every other AG-UI package is built on: message & state models, run inputs and the full set of streaming event types.

## Installation

```bash
npm install @ag-ui/core
pnpm add @ag-ui/core
yarn add @ag-ui/core
```

## Features

- 🧩 **Typed data models** – `Message`, `Tool`, `Context`, `RunAgentInput`, `State` …
- 🔄 **Streaming events** – 16 core event kinds covering assistant messages, tool calls, state updates and run lifecycle.
- ✅ **Runtime validation** – schemas catch malformed payloads early.
- 🚀 **Framework-agnostic** – works in Node.js, browsers and any agent framework that can emit JSON.

## Quick example

```ts
import { EventSchemas, EventType } from "@ag-ui/core";

// Validate an incoming event
EventSchemas.parse({
  type: EventType.TEXT_MESSAGE_CONTENT,
  messageId: "msg_123",
  delta: "Hello, world!",
});
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/core`](https://docs.ag-ui.com/sdk/js/core/overview)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/core/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
};



================================================
FILE: typescript-sdk/packages/core/package.json
================================================
{
  "name": "@ag-ui/core",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.39",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "eslint \"src/**/*.ts*\"",
    "clean": "rm -rf dist .turbo node_modules",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "rxjs": "7.8.1",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@types/jest": "^29.5.12",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.8.2"
  }
}



================================================
FILE: typescript-sdk/packages/core/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/core/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
}));



================================================
FILE: typescript-sdk/packages/core/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/core/src/events.ts
================================================
import { z } from "zod";
import { MessageSchema, StateSchema } from "./types";

// Text messages can have any role except "tool"
const TextMessageRoleSchema = z.union([
  z.literal("developer"),
  z.literal("system"),
  z.literal("assistant"),
  z.literal("user"),
]);

export enum EventType {
  TEXT_MESSAGE_START = "TEXT_MESSAGE_START",
  TEXT_MESSAGE_CONTENT = "TEXT_MESSAGE_CONTENT",
  TEXT_MESSAGE_END = "TEXT_MESSAGE_END",
  TEXT_MESSAGE_CHUNK = "TEXT_MESSAGE_CHUNK",
  THINKING_TEXT_MESSAGE_START = "THINKING_TEXT_MESSAGE_START",
  THINKING_TEXT_MESSAGE_CONTENT = "THINKING_TEXT_MESSAGE_CONTENT",
  THINKING_TEXT_MESSAGE_END = "THINKING_TEXT_MESSAGE_END",
  TOOL_CALL_START = "TOOL_CALL_START",
  TOOL_CALL_ARGS = "TOOL_CALL_ARGS",
  TOOL_CALL_END = "TOOL_CALL_END",
  TOOL_CALL_CHUNK = "TOOL_CALL_CHUNK",
  TOOL_CALL_RESULT = "TOOL_CALL_RESULT",
  THINKING_START = "THINKING_START",
  THINKING_END = "THINKING_END",
  STATE_SNAPSHOT = "STATE_SNAPSHOT",
  STATE_DELTA = "STATE_DELTA",
  MESSAGES_SNAPSHOT = "MESSAGES_SNAPSHOT",
  RAW = "RAW",
  CUSTOM = "CUSTOM",
  RUN_STARTED = "RUN_STARTED",
  RUN_FINISHED = "RUN_FINISHED",
  RUN_ERROR = "RUN_ERROR",
  STEP_STARTED = "STEP_STARTED",
  STEP_FINISHED = "STEP_FINISHED",
}

export const BaseEventSchema = z.object({
  type: z.nativeEnum(EventType),
  timestamp: z.number().optional(),
  rawEvent: z.any().optional(),
});

export const TextMessageStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_START),
  messageId: z.string(),
  role: TextMessageRoleSchema.default("assistant"),
});

export const TextMessageContentEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_CONTENT),
  messageId: z.string(),
  delta: z.string().refine((s) => s.length > 0, "Delta must not be an empty string"),
});

export const TextMessageEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_END),
  messageId: z.string(),
});

export const TextMessageChunkEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TEXT_MESSAGE_CHUNK),
  messageId: z.string().optional(),
  role: TextMessageRoleSchema.optional(),
  delta: z.string().optional(),
});

export const ThinkingTextMessageStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_TEXT_MESSAGE_START),
});

export const ThinkingTextMessageContentEventSchema = TextMessageContentEventSchema.omit({
  messageId: true,
  type: true,
}).extend({
  type: z.literal(EventType.THINKING_TEXT_MESSAGE_CONTENT),
});

export const ThinkingTextMessageEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_TEXT_MESSAGE_END),
});

export const ToolCallStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_START),
  toolCallId: z.string(),
  toolCallName: z.string(),
  parentMessageId: z.string().optional(),
});

export const ToolCallArgsEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_ARGS),
  toolCallId: z.string(),
  delta: z.string(),
});

export const ToolCallEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_END),
  toolCallId: z.string(),
});

export const ToolCallResultEventSchema = BaseEventSchema.extend({
  messageId: z.string(),
  type: z.literal(EventType.TOOL_CALL_RESULT),
  toolCallId: z.string(),
  content: z.string(),
  role: z.literal("tool").optional(),
});

export const ToolCallChunkEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.TOOL_CALL_CHUNK),
  toolCallId: z.string().optional(),
  toolCallName: z.string().optional(),
  parentMessageId: z.string().optional(),
  delta: z.string().optional(),
});

export const ThinkingStartEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_START),
  title: z.string().optional(),
});

export const ThinkingEndEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.THINKING_END),
});

export const StateSnapshotEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STATE_SNAPSHOT),
  snapshot: StateSchema,
});

export const StateDeltaEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STATE_DELTA),
  delta: z.array(z.any()), // JSON Patch (RFC 6902)
});

export const MessagesSnapshotEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.MESSAGES_SNAPSHOT),
  messages: z.array(MessageSchema),
});

export const RawEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RAW),
  event: z.any(),
  source: z.string().optional(),
});

export const CustomEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.CUSTOM),
  name: z.string(),
  value: z.any(),
});

export const RunStartedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RUN_STARTED),
  threadId: z.string(),
  runId: z.string(),
});

export const RunFinishedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RUN_FINISHED),
  threadId: z.string(),
  runId: z.string(),
  result: z.any().optional(),
});

export const RunErrorEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.RUN_ERROR),
  message: z.string(),
  code: z.string().optional(),
});

export const StepStartedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STEP_STARTED),
  stepName: z.string(),
});

export const StepFinishedEventSchema = BaseEventSchema.extend({
  type: z.literal(EventType.STEP_FINISHED),
  stepName: z.string(),
});

export const EventSchemas = z.discriminatedUnion("type", [
  TextMessageStartEventSchema,
  TextMessageContentEventSchema,
  TextMessageEndEventSchema,
  TextMessageChunkEventSchema,
  ThinkingStartEventSchema,
  ThinkingEndEventSchema,
  ThinkingTextMessageStartEventSchema,
  ThinkingTextMessageContentEventSchema,
  ThinkingTextMessageEndEventSchema,
  ToolCallStartEventSchema,
  ToolCallArgsEventSchema,
  ToolCallEndEventSchema,
  ToolCallChunkEventSchema,
  ToolCallResultEventSchema,
  StateSnapshotEventSchema,
  StateDeltaEventSchema,
  MessagesSnapshotEventSchema,
  RawEventSchema,
  CustomEventSchema,
  RunStartedEventSchema,
  RunFinishedEventSchema,
  RunErrorEventSchema,
  StepStartedEventSchema,
  StepFinishedEventSchema,
]);

export type BaseEvent = z.infer<typeof BaseEventSchema>;
export type TextMessageStartEvent = z.infer<typeof TextMessageStartEventSchema>;
export type TextMessageContentEvent = z.infer<typeof TextMessageContentEventSchema>;
export type TextMessageEndEvent = z.infer<typeof TextMessageEndEventSchema>;
export type TextMessageChunkEvent = z.infer<typeof TextMessageChunkEventSchema>;
export type ThinkingTextMessageStartEvent = z.infer<typeof ThinkingTextMessageStartEventSchema>;
export type ThinkingTextMessageContentEvent = z.infer<typeof ThinkingTextMessageContentEventSchema>;
export type ThinkingTextMessageEndEvent = z.infer<typeof ThinkingTextMessageEndEventSchema>;
export type ToolCallStartEvent = z.infer<typeof ToolCallStartEventSchema>;
export type ToolCallArgsEvent = z.infer<typeof ToolCallArgsEventSchema>;
export type ToolCallEndEvent = z.infer<typeof ToolCallEndEventSchema>;
export type ToolCallChunkEvent = z.infer<typeof ToolCallChunkEventSchema>;
export type ToolCallResultEvent = z.infer<typeof ToolCallResultEventSchema>;
export type ThinkingStartEvent = z.infer<typeof ThinkingStartEventSchema>;
export type ThinkingEndEvent = z.infer<typeof ThinkingEndEventSchema>;
export type StateSnapshotEvent = z.infer<typeof StateSnapshotEventSchema>;
export type StateDeltaEvent = z.infer<typeof StateDeltaEventSchema>;
export type MessagesSnapshotEvent = z.infer<typeof MessagesSnapshotEventSchema>;
export type RawEvent = z.infer<typeof RawEventSchema>;
export type CustomEvent = z.infer<typeof CustomEventSchema>;
export type RunStartedEvent = z.infer<typeof RunStartedEventSchema>;
export type RunFinishedEvent = z.infer<typeof RunFinishedEventSchema>;
export type RunErrorEvent = z.infer<typeof RunErrorEventSchema>;
export type StepStartedEvent = z.infer<typeof StepStartedEventSchema>;
export type StepFinishedEvent = z.infer<typeof StepFinishedEventSchema>;



================================================
FILE: typescript-sdk/packages/core/src/index.ts
================================================
// Export all base types and schemas
export * from "./types";

// Export all event-related types and schemas
export * from "./events";



================================================
FILE: typescript-sdk/packages/core/src/types.ts
================================================
import { z } from "zod";

export const FunctionCallSchema = z.object({
  name: z.string(),
  arguments: z.string(),
});

export const ToolCallSchema = z.object({
  id: z.string(),
  type: z.literal("function"),
  function: FunctionCallSchema,
});

export const BaseMessageSchema = z.object({
  id: z.string(),
  role: z.string(),
  content: z.string().optional(),
  name: z.string().optional(),
});

export const DeveloperMessageSchema = BaseMessageSchema.extend({
  role: z.literal("developer"),
  content: z.string(),
});

export const SystemMessageSchema = BaseMessageSchema.extend({
  role: z.literal("system"),
  content: z.string(),
});

export const AssistantMessageSchema = BaseMessageSchema.extend({
  role: z.literal("assistant"),
  content: z.string().optional(),
  toolCalls: z.array(ToolCallSchema).optional(),
});

export const UserMessageSchema = BaseMessageSchema.extend({
  role: z.literal("user"),
  content: z.string(),
});

export const ToolMessageSchema = z.object({
  id: z.string(),
  content: z.string(),
  role: z.literal("tool"),
  toolCallId: z.string(),
  error: z.string().optional(),
});

export const MessageSchema = z.discriminatedUnion("role", [
  DeveloperMessageSchema,
  SystemMessageSchema,
  AssistantMessageSchema,
  UserMessageSchema,
  ToolMessageSchema,
]);

export const RoleSchema = z.union([
  z.literal("developer"),
  z.literal("system"),
  z.literal("assistant"),
  z.literal("user"),
  z.literal("tool"),
]);

export const ContextSchema = z.object({
  description: z.string(),
  value: z.string(),
});

export const ToolSchema = z.object({
  name: z.string(),
  description: z.string(),
  parameters: z.any(), // JSON Schema for the tool parameters
});

export const RunAgentInputSchema = z.object({
  threadId: z.string(),
  runId: z.string(),
  state: z.any(),
  messages: z.array(MessageSchema),
  tools: z.array(ToolSchema),
  context: z.array(ContextSchema),
  forwardedProps: z.any(),
});

export const StateSchema = z.any();

export type ToolCall = z.infer<typeof ToolCallSchema>;
export type FunctionCall = z.infer<typeof FunctionCallSchema>;
export type DeveloperMessage = z.infer<typeof DeveloperMessageSchema>;
export type SystemMessage = z.infer<typeof SystemMessageSchema>;
export type AssistantMessage = z.infer<typeof AssistantMessageSchema>;
export type UserMessage = z.infer<typeof UserMessageSchema>;
export type ToolMessage = z.infer<typeof ToolMessageSchema>;
export type Message = z.infer<typeof MessageSchema>;
export type Context = z.infer<typeof ContextSchema>;
export type Tool = z.infer<typeof ToolSchema>;
export type RunAgentInput = z.infer<typeof RunAgentInputSchema>;
export type State = z.infer<typeof StateSchema>;
export type Role = z.infer<typeof RoleSchema>;

export class AGUIError extends Error {
  constructor(message: string) {
    super(message);
  }
}



================================================
FILE: typescript-sdk/packages/core/src/__tests__/events-role-defaults.test.ts
================================================
import { TextMessageStartEventSchema, TextMessageChunkEventSchema, EventType } from "../events";

describe("Event role defaults", () => {
  it("should default TextMessageStartEvent role to 'assistant' when not provided", () => {
    const eventData = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      // role not provided
    };

    const parsed = TextMessageStartEventSchema.parse(eventData);
    
    expect(parsed.type).toBe(EventType.TEXT_MESSAGE_START);
    expect(parsed.messageId).toBe("test-msg");
    expect(parsed.role).toBe("assistant"); // Should default to assistant
  });

  it("should allow overriding the default role in TextMessageStartEvent", () => {
    const eventData = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      role: "user",
    };

    const parsed = TextMessageStartEventSchema.parse(eventData);
    
    expect(parsed.type).toBe(EventType.TEXT_MESSAGE_START);
    expect(parsed.messageId).toBe("test-msg");
    expect(parsed.role).toBe("user"); // Should use provided role
  });

  it("should accept all valid text message roles in TextMessageStartEvent", () => {
    const textMessageRoles = ["developer", "system", "assistant", "user"];
    
    textMessageRoles.forEach(role => {
      const eventData = {
        type: EventType.TEXT_MESSAGE_START,
        messageId: `test-msg-${role}`,
        role,
      };

      const parsed = TextMessageStartEventSchema.parse(eventData);
      expect(parsed.role).toBe(role);
    });
  });

  it("should keep role optional in TextMessageChunkEvent", () => {
    const eventDataWithoutRole = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "test-msg",
      delta: "test content",
      // role not provided
    };

    const parsed1 = TextMessageChunkEventSchema.parse(eventDataWithoutRole);
    expect(parsed1.role).toBeUndefined(); // Should be undefined when not provided

    const eventDataWithRole = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "test-msg",
      role: "user",
      delta: "test content",
    };

    const parsed2 = TextMessageChunkEventSchema.parse(eventDataWithRole);
    expect(parsed2.role).toBe("user"); // Should use provided role
  });

  it("should reject invalid roles", () => {
    const invalidEventData = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      role: "invalid_role",
    };

    expect(() => {
      TextMessageStartEventSchema.parse(invalidEventData);
    }).toThrow();
  });

  it("should reject 'tool' role for text messages", () => {
    // Test TextMessageStartEvent with tool role
    const startEventWithToolRole = {
      type: EventType.TEXT_MESSAGE_START,
      messageId: "test-msg",
      role: "tool",
    };

    expect(() => {
      TextMessageStartEventSchema.parse(startEventWithToolRole);
    }).toThrow();

    // Test TextMessageChunkEvent with tool role
    const chunkEventWithToolRole = {
      type: EventType.TEXT_MESSAGE_CHUNK,
      messageId: "test-msg",
      role: "tool",
      delta: "content",
    };

    expect(() => {
      TextMessageChunkEventSchema.parse(chunkEventWithToolRole);
    }).toThrow();
  });
});


================================================
FILE: typescript-sdk/packages/core/src/__tests__/index.test.ts
================================================
describe("Core package", () => {
  it("should pass a simple test", () => {
    expect(true).toBe(true);
  });
});



================================================
FILE: typescript-sdk/packages/encoder/README.md
================================================
# @ag-ui/encoder

Event encoding utilities for the **Agent-User Interaction (AG-UI) Protocol**.

`@ag-ui/encoder` handles content negotiation and format encoding for AG-UI events. It automatically chooses between Server-Sent Events (JSON) and Protocol Buffers based on client `Accept` headers, ensuring optimal transport efficiency.

## Installation

```bash
npm install @ag-ui/encoder
pnpm add @ag-ui/encoder
yarn add @ag-ui/encoder
```

## Features

- 🎯 **Content negotiation** – Automatic format selection based on `Accept` headers
- 📦 **Dual encoding** – SSE (JSON) and Protocol Buffer support
- ⚡ **Efficient binary** – Length-prefixed protobuf encoding for high-throughput scenarios
- 🔄 **Seamless fallback** – Graceful degradation to SSE when protobuf isn't supported

## Quick example

```ts
import { EventEncoder } from "@ag-ui/encoder";
import { EventType } from "@ag-ui/core";

const encoder = new EventEncoder({
  accept: "application/vnd.ag-ui.event+proto, text/event-stream",
});

const event = {
  type: EventType.TEXT_MESSAGE_CONTENT,
  messageId: "msg_123",
  delta: "Hello, world!",
};

// Returns protobuf-encoded binary data
const encoded = encoder.encodeBinary(event);
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/encoder`](https://docs.ag-ui.com/sdk/js/encoder)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/encoder/jest.config.js
================================================
/** @type {import('ts-jest').JestConfigWithTsJest} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  testMatch: ["**/*.test.ts"],
  passWithNoTests: true,
};



================================================
FILE: typescript-sdk/packages/encoder/package.json
================================================
{
  "name": "@ag-ui/encoder",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.39",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "eslint \"src/**/*.ts*\"",
    "clean": "rm -rf dist .turbo node_modules",
    "test": "jest",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/core": "workspace:*",
    "@ag-ui/proto": "workspace:*"
  },
  "devDependencies": {
    "@types/jest": "^29.5.12",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "tsup": "^8.0.2",
    "typescript": "^5.8.2"
  }
}



================================================
FILE: typescript-sdk/packages/encoder/tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "es2017",
    "module": "esnext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node",
    "skipLibCheck": true,
    "strict": true,
    "jsx": "react-jsx",
    "esModuleInterop": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["src"],
  "exclude": ["node_modules", "dist"]
}



================================================
FILE: typescript-sdk/packages/encoder/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["cjs", "esm"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
}));



================================================
FILE: typescript-sdk/packages/encoder/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/encoder/src/encoder.ts
================================================
import { BaseEvent } from "@ag-ui/core";
import * as proto from "@ag-ui/proto";
import { preferredMediaTypes } from "./media-type";

export interface EventEncoderParams {
  accept?: string;
}

export class EventEncoder {
  private acceptsProtobuf: boolean;

  constructor(params?: EventEncoderParams) {
    this.acceptsProtobuf = params?.accept ? this.isProtobufAccepted(params.accept) : false;
  }

  getContentType(): string {
    if (this.acceptsProtobuf) {
      return proto.AGUI_MEDIA_TYPE;
    } else {
      return "text/event-stream";
    }
  }

  encode(event: BaseEvent): string {
    return this.encodeSSE(event);
  }

  encodeSSE(event: BaseEvent): string {
    return `data: ${JSON.stringify(event)}\n\n`;
  }

  encodeBinary(event: BaseEvent): Uint8Array {
    if (this.acceptsProtobuf) {
      return this.encodeProtobuf(event);
    } else {
      const sseString = this.encodeSSE(event);
      // Convert string to Uint8Array using TextEncoder
      const encoder = new TextEncoder();
      return encoder.encode(sseString);
    }
  }

  encodeProtobuf(event: BaseEvent): Uint8Array {
    const messageBytes = proto.encode(event);
    const length = messageBytes.length;

    // Create a buffer for 4 bytes (for the uint32 length) plus the message bytes
    const buffer = new ArrayBuffer(4 + length);
    const dataView = new DataView(buffer);

    // Write the length as a uint32
    // Set the third parameter to `false` for big-endian or `true` for little-endian
    dataView.setUint32(0, length, false);

    // Create a Uint8Array view and copy in the message bytes after the 4-byte header
    const result = new Uint8Array(buffer);
    result.set(messageBytes, 4);

    return result;
  }

  private isProtobufAccepted(acceptHeader: string): boolean {
    // Pass the Accept header and an array with your media type
    const preferred = preferredMediaTypes(acceptHeader, [proto.AGUI_MEDIA_TYPE]);

    // If the returned array includes your media type, it's acceptable
    return preferred.includes(proto.AGUI_MEDIA_TYPE);
  }
}



================================================
FILE: typescript-sdk/packages/encoder/src/index.ts
================================================
export * from "./encoder";
export { AGUI_MEDIA_TYPE } from "@ag-ui/proto";



================================================
FILE: typescript-sdk/packages/encoder/src/media-type.ts
================================================
/**
 * negotiator
 * Copyright(c) 2012 Isaac Z. Schlueter
 * Copyright(c) 2014 Federico Romero
 * Copyright(c) 2014-2015 Douglas Christopher Wilson
 * MIT Licensed
 */

// modified from https://github.com/jshttp/negotiator/blob/master/lib/mediaType.js

/**
 * Module exports.
 * @public
 */

export function preferredMediaTypes(accept?: string, provided?: string[]): string[] {
  // RFC 2616 sec 14.2: no header = */*
  const accepts = parseAccept(accept === undefined ? "*/*" : accept || "");

  if (!provided) {
    // sorted list of all types
    return accepts
      .filter((spec): spec is MediaType => spec.q > 0)
      .sort((a, b) => {
        return b.q - a.q || b.i - a.i || 0;
      })
      .map(getFullType);
  }

  const priorities = provided.map(function getPriority(type: string, index: number) {
    return getMediaTypePriority(type, accepts, index);
  });

  // sorted list of accepted types
  return priorities
    .filter((spec): spec is Priority => spec.q > 0)
    .sort(compareSpecs)
    .map(function getType(priority: Priority) {
      return provided[priorities.indexOf(priority)];
    });
}

/**
 * Module variables.
 * @private
 */

const simpleMediaTypeRegExp = /^\s*([^\s\/;]+)\/([^;\s]+)\s*(?:;(.*))?$/;

/**
 * Media type interface
 * @private
 */
interface MediaType {
  type: string;
  subtype: string;
  params: Record<string, string>;
  q: number;
  i: number;
}

/**
 * Priority interface
 * @private
 */
interface Priority {
  o: number;
  q: number;
  s: number;
  i?: number;
}

/**
 * Parse the Accept header.
 * @private
 */
function parseAccept(accept: string): MediaType[] {
  const accepts = splitMediaTypes(accept);
  const result: MediaType[] = [];

  for (let i = 0, j = 0; i < accepts.length; i++) {
    const mediaType = parseMediaType(accepts[i].trim(), i);

    if (mediaType) {
      result[j++] = mediaType;
    }
  }

  return result;
}

/**
 * Parse a media type from the Accept header.
 * @private
 */
function parseMediaType(str: string, i: number): MediaType | null {
  const match = simpleMediaTypeRegExp.exec(str);
  if (!match) return null;

  const params: Record<string, string> = Object.create(null);
  let q = 1;
  const subtype = match[2];
  const type = match[1];

  if (match[3]) {
    const kvps = splitParameters(match[3]).map(splitKeyValuePair);

    for (let j = 0; j < kvps.length; j++) {
      const pair = kvps[j];
      const key = pair[0].toLowerCase();
      const val = pair[1];

      // get the value, unwrapping quotes
      const value = val && val[0] === '"' && val[val.length - 1] === '"' ? val.slice(1, -1) : val;

      if (key === "q") {
        q = parseFloat(value);
        break;
      }

      // store parameter
      params[key] = value;
    }
  }

  return {
    type: type,
    subtype: subtype,
    params: params,
    q: q,
    i: i,
  };
}

/**
 * Get the priority of a media type.
 * @private
 */
function getMediaTypePriority(type: string, accepted: MediaType[], index: number): Priority {
  const priority: Priority = { o: -1, q: 0, s: 0 };

  for (let i = 0; i < accepted.length; i++) {
    const spec = specify(type, accepted[i], index);

    if (spec && (priority.s - spec.s || priority.q - spec.q || priority.o - spec.o) < 0) {
      priority.o = spec.o;
      priority.q = spec.q;
      priority.s = spec.s;
      priority.i = spec.i;
    }
  }

  return priority;
}

/**
 * Get the specificity of the media type.
 * @private
 */
function specify(type: string, spec: MediaType, index: number): Priority | null {
  const p = parseMediaType(type, 0);
  let s = 0;

  if (!p) {
    return null;
  }

  if (spec.type.toLowerCase() == p.type.toLowerCase()) {
    s |= 4;
  } else if (spec.type != "*") {
    return null;
  }

  if (spec.subtype.toLowerCase() == p.subtype.toLowerCase()) {
    s |= 2;
  } else if (spec.subtype != "*") {
    return null;
  }

  const keys = Object.keys(spec.params);
  if (keys.length > 0) {
    if (
      keys.every(function (k) {
        return (
          spec.params[k] == "*" ||
          (spec.params[k] || "").toLowerCase() == (p.params[k] || "").toLowerCase()
        );
      })
    ) {
      s |= 1;
    } else {
      return null;
    }
  }

  return {
    i: index,
    o: spec.i,
    q: spec.q,
    s: s,
  };
}

/**
 * Compare two specs.
 * @private
 */
function compareSpecs(a: Priority, b: Priority): number {
  return b.q - a.q || b.s - a.s || (a.o || 0) - (b.o || 0) || (a.i || 0) - (b.i || 0) || 0;
}

/**
 * Get full type string.
 * @private
 */
function getFullType(spec: MediaType): string {
  return spec.type + "/" + spec.subtype;
}

/**
 * Check if a spec has any quality.
 * @private
 */
function isQuality(spec: Priority | MediaType): boolean {
  return spec.q > 0;
}

/**
 * Count the number of quotes in a string.
 * @private
 */
function quoteCount(string: string): number {
  let count = 0;
  let index = 0;

  while ((index = string.indexOf('"', index)) !== -1) {
    count++;
    index++;
  }

  return count;
}

/**
 * Split a key value pair.
 * @private
 */
function splitKeyValuePair(str: string): [string, string] {
  const index = str.indexOf("=");
  let key: string;
  let val: string = "";

  if (index === -1) {
    key = str;
  } else {
    key = str.slice(0, index);
    val = str.slice(index + 1);
  }

  return [key, val];
}

/**
 * Split an Accept header into media types.
 * @private
 */
function splitMediaTypes(accept: string): string[] {
  const accepts = accept.split(",");
  const result: string[] = [accepts[0]];

  for (let i = 1, j = 0; i < accepts.length; i++) {
    if (quoteCount(result[j]) % 2 == 0) {
      result[++j] = accepts[i];
    } else {
      result[j] += "," + accepts[i];
    }
  }

  // trim result
  return result;
}

/**
 * Split a string of parameters.
 * @private
 */
function splitParameters(str: string): string[] {
  const parameters = str.split(";");
  const result: string[] = [parameters[0]];

  for (let i = 1, j = 0; i < parameters.length; i++) {
    if (quoteCount(result[j]) % 2 == 0) {
      result[++j] = parameters[i];
    } else {
      result[j] += ";" + parameters[i];
    }
  }

  // trim parameters
  for (let i = 0; i < result.length; i++) {
    result[i] = result[i].trim();
  }

  return result;
}



================================================
FILE: typescript-sdk/packages/encoder/src/__tests__/encoder.test.ts
================================================
import { EventEncoder } from "../encoder";
import { BaseEvent, EventType, TextMessageStartEvent } from "@ag-ui/core";
import * as proto from "@ag-ui/proto";

describe("Encoder Tests", () => {
  // Create a valid TextMessageStartEvent event
  const testEvent: TextMessageStartEvent = {
    type: EventType.TEXT_MESSAGE_START,
    timestamp: 123456789,
    messageId: "msg123",
    role: "assistant",
  };

  describe("encodeBinary method", () => {
    it("should return protobuf encoded data when accept header includes protobuf media type", () => {
      // Setup an encoder with protobuf accepted
      const encoder = new EventEncoder({
        accept: `text/event-stream, ${proto.AGUI_MEDIA_TYPE}`,
      });

      // Get the binary encoding
      const result = encoder.encodeBinary(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // A protobuf message should start with 4 bytes for length followed by the message
      // So the length should be greater than 4 at minimum
      expect(result.length).toBeGreaterThan(4);

      // The first 4 bytes should be a uint32 representing the message length
      const dataView = new DataView(result.buffer);
      const messageLength = dataView.getUint32(0, false); // false for big-endian

      // The actual message should match the length specified in the header
      expect(result.length - 4).toBe(messageLength);
    });

    it("should return SSE encoded data when accept header doesn't include protobuf media type", () => {
      // Setup an encoder without protobuf accepted
      const encoder = new EventEncoder({
        accept: "text/event-stream",
      });

      // Get the binary encoding
      const result = encoder.encodeBinary(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // Convert back to string to verify it's SSE format
      const decoder = new TextDecoder();
      const resultString = decoder.decode(result);

      // Should match the SSE format with the expected JSON
      expect(resultString).toBe(`data: ${JSON.stringify(testEvent)}\n\n`);
    });

    it("should return SSE encoded data when no accept header is provided", () => {
      // Setup an encoder without any accept header
      const encoder = new EventEncoder();

      // Get the binary encoding
      const result = encoder.encodeBinary(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // Convert back to string to verify it's SSE format
      const decoder = new TextDecoder();
      const resultString = decoder.decode(result);

      // Should match the SSE format with the expected JSON
      expect(resultString).toBe(`data: ${JSON.stringify(testEvent)}\n\n`);
    });
  });

  describe("encodeProtobuf method", () => {
    it("should encode event as protobuf with length prefix", () => {
      const encoder = new EventEncoder();

      const result = encoder.encodeProtobuf(testEvent);

      // Verify it's a Uint8Array
      expect(result).toBeInstanceOf(Uint8Array);

      // A protobuf message should start with 4 bytes for length followed by the message
      expect(result.length).toBeGreaterThan(4);

      // The first 4 bytes should be a uint32 representing the message length
      const dataView = new DataView(result.buffer);
      const messageLength = dataView.getUint32(0, false); // false for big-endian

      // The actual message should match the length specified in the header
      expect(result.length - 4).toBe(messageLength);

      // The message length should be greater than zero
      expect(messageLength).toBeGreaterThan(0);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/README.md
================================================
# @ag-ui/proto

Protocol Buffer encoding/decoding for **Agent-User Interaction (AG-UI) Protocol** events.

`@ag-ui/proto` provides high-performance binary serialization of AG-UI events using Protocol Buffers. It includes generated TypeScript definitions and utilities for converting between AG-UI's JSON event format and compact binary representation.

## Installation

```bash
npm install @ag-ui/proto
pnpm add @ag-ui/proto
yarn add @ag-ui/proto
```

## Features

- ⚡ **High performance** – Binary protobuf encoding for minimal bandwidth usage
- 🔄 **Round-trip safety** – Lossless conversion between JSON and binary formats
- 📋 **Generated types** – Auto-generated TypeScript definitions from `.proto` schemas
- 🔧 **Length-prefixed** – Standard 4-byte length headers for streaming protocols

## Quick example

```ts
import { encode, decode, AGUI_MEDIA_TYPE } from "@ag-ui/proto";
import { EventType } from "@ag-ui/core";

const event = {
  type: EventType.TEXT_MESSAGE_START,
  messageId: "msg_123",
  role: "assistant",
};

// Encode to binary protobuf format
const encoded = encode(event);

// Decode back to AG-UI event
const decoded = decode(encoded);
console.log(decoded); // Original event object
```

## Documentation

- Concepts & architecture: [`docs/concepts`](https://docs.ag-ui.com/concepts/architecture)
- Full API reference: [`docs/sdk/js/proto`](https://docs.ag-ui.com/sdk/js/proto)

## Contributing

Bug reports and pull requests are welcome! Please read our [contributing guide](https://docs.ag-ui.com/development/contributing) first.

## License

MIT © 2025 AG-UI Protocol Contributors



================================================
FILE: typescript-sdk/packages/proto/jest.config.js
================================================
/** @type {import('jest').Config} */
module.exports = {
  preset: "ts-jest",
  testEnvironment: "node",
  passWithNoTests: true,
};



================================================
FILE: typescript-sdk/packages/proto/package.json
================================================
{
  "name": "@ag-ui/proto",
  "author": "Markus Ecker <markus.ecker@gmail.com>",
  "version": "0.0.39",
  "private": false,
  "publishConfig": {
    "access": "public"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "scripts": {
    "build": "tsup",
    "dev": "tsup --watch",
    "lint": "eslint \"src/**/*.ts*\"",
    "clean": "rm -rf dist .turbo node_modules",
    "test": "jest",
    "generate": "mkdir -p ./src/generated && npx protoc --plugin=./node_modules/.bin/protoc-gen-ts_proto --ts_proto_out=./src/generated --ts_proto_opt=esModuleInterop=true,outputJsonMethods=false,outputClientImpl=false -I ./src/proto ./src/proto/*.proto",
    "link:global": "pnpm link --global",
    "unlink:global": "pnpm unlink --global"
  },
  "dependencies": {
    "@ag-ui/core": "workspace:*",
    "@bufbuild/protobuf": "^2.2.5",
    "@protobuf-ts/protoc": "^2.11.1"
  },
  "devDependencies": {
    "@jest/globals": "^29.7.0",
    "@types/jest": "^29.5.14",
    "jest": "^29.7.0",
    "ts-jest": "^29.1.2",
    "ts-proto": "^2.7.0",
    "tsup": "^8.0.2",
    "typescript": "^5.8.2"
  }
}



================================================
FILE: typescript-sdk/packages/proto/tsconfig.json
================================================
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": "./src",
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "**/__tests__/**"]
}



================================================
FILE: typescript-sdk/packages/proto/tsup.config.ts
================================================
import { defineConfig } from "tsup";

export default defineConfig((options) => ({
  entry: ["src/index.ts"],
  format: ["esm", "cjs"],
  dts: true,
  splitting: false,
  sourcemap: true,
  clean: !options.watch, // Don't clean in watch mode to prevent race conditions
}));



================================================
FILE: typescript-sdk/packages/proto/.npmignore
================================================
.turbo
.DS_Store
.git
.gitignore
.idea
.vscode
.env
__tests__
src
tsup.config.ts
tsconfig.json
jest.config.js



================================================
FILE: typescript-sdk/packages/proto/__tests__/message-events.test.ts
================================================
import {
  BaseEvent,
  EventType,
  MessagesSnapshotEvent,
  TextMessageStartEvent,
  TextMessageContentEvent,
  TextMessageEndEvent,
} from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("Message Events", () => {
  describe("TextMessageStartEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: TextMessageStartEvent = {
        type: EventType.TEXT_MESSAGE_START,
        timestamp: Date.now(),
        messageId: "msg-1",
        role: "assistant",
      };

      expectRoundTripEquality(event);
    });

    it("should handle missing optional fields", () => {
      const event: TextMessageStartEvent = {
        type: EventType.TEXT_MESSAGE_START,
        messageId: "msg-1",
        role: "assistant",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("TextMessageContentEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: TextMessageContentEvent = {
        type: EventType.TEXT_MESSAGE_CONTENT,
        timestamp: Date.now(),
        messageId: "msg-1",
        delta: "Hello, how can I help you today?",
      };

      expectRoundTripEquality(event);
    });

    it("should handle special characters in content delta", () => {
      const event: TextMessageContentEvent = {
        type: EventType.TEXT_MESSAGE_CONTENT,
        messageId: "msg-1",
        delta: "Special chars: 🚀 ñ € 😊 \n\t\"'\\`",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("TextMessageEndEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: TextMessageEndEvent = {
        type: EventType.TEXT_MESSAGE_END,
        timestamp: Date.now(),
        messageId: "msg-1",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("MessagesSnapshotEvent", () => {
    it("should round-trip encode/decode with multiple messages", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        timestamp: Date.now(),
        messages: [
          {
            id: "msg-1",
            role: "user",
            content: "Can you help me with my task?",
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "I'd be happy to help! What task do you need assistance with?",
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle messages with tool calls", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "user",
            content: "What's the weather in San Francisco?",
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "Let me check the weather for you.",
            toolCalls: [
              {
                id: "tool-1",
                type: "function",
                function: {
                  name: "get_weather",
                  arguments: JSON.stringify({ location: "San Francisco" }),
                },
              },
            ],
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle messages with multiple tool calls and complex arguments", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "assistant",
            content: undefined, // Changed from null to undefined
            toolCalls: [
              {
                id: "tool-1",
                type: "function",
                function: {
                  name: "analyze_data",
                  arguments: JSON.stringify({
                    dataset: "sales_2023",
                    metrics: ["revenue", "growth", "conversion"],
                    filters: {
                      region: "North America",
                      timeframe: { start: "2023-01-01", end: "2023-12-31" },
                    },
                  }),
                },
              },
              {
                id: "tool-2",
                type: "function",
                function: {
                  name: "generate_report",
                  arguments: JSON.stringify({
                    title: "Annual Sales Report",
                    format: "pdf",
                    sections: ["summary", "detailed_analysis", "recommendations"],
                  }),
                },
              },
            ],
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle messages with undefined toolCalls", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "user",
            content: "Hello",
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "Hi there!",
            // No toolCalls field
          },
        ],
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as MessagesSnapshotEvent;

      // Check messages length
      expect(decoded.messages).toHaveLength(event.messages.length);

      // Check first message
      expect(decoded.messages[0].id).toBe(event.messages[0].id);
      expect(decoded.messages[0].role).toBe(event.messages[0].role);
      expect(decoded.messages[0].content).toBe(event.messages[0].content);
      expect((decoded.messages[0] as any).toolCalls).toBeUndefined();

      // Check second message
      expect(decoded.messages[1].id).toBe(event.messages[1].id);
      expect(decoded.messages[1].role).toBe(event.messages[1].role);
      expect(decoded.messages[1].content).toBe(event.messages[1].content);
      expect((decoded.messages[1] as any).toolCalls).toBeUndefined();
    });

    it("should handle messages with empty toolCalls array", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "assistant",
            content: "I processed your request.",
            toolCalls: [], // Explicitly empty array
          },
        ],
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as MessagesSnapshotEvent;

      // Check that empty toolCalls array is converted to undefined
      expect(decoded.messages[0].id).toBe(event.messages[0].id);
      expect(decoded.messages[0].role).toBe(event.messages[0].role);
      expect(decoded.messages[0].content).toBe(event.messages[0].content);
      expect((decoded.messages[0] as any).toolCalls).toBeUndefined();
    });

    // Test for mixed messages (one with empty toolCalls, one with non-empty)
    it("should correctly handle a mix of messages with empty and non-empty toolCalls", () => {
      const event: MessagesSnapshotEvent = {
        type: EventType.MESSAGES_SNAPSHOT,
        messages: [
          {
            id: "msg-1",
            role: "assistant",
            content: "First message",
            toolCalls: [], // Empty array that should be converted to undefined
          },
          {
            id: "msg-2",
            role: "assistant",
            content: "Second message",
            toolCalls: [
              {
                id: "tool-1",
                type: "function",
                function: {
                  name: "test_function",
                  arguments: "{}",
                },
              },
            ],
          },
        ],
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as MessagesSnapshotEvent;

      // Check first message (empty toolCalls should be undefined)
      expect((decoded.messages[0] as any).toolCalls).toBeUndefined();

      // Check second message (non-empty toolCalls should be preserved)
      expect((decoded.messages[1] as any).toolCalls).toBeDefined();
      expect((decoded.messages[1] as any).toolCalls?.length).toBe(1);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/proto.test.ts
================================================
import { encode, decode } from "../src/proto";
import {
  BaseEvent,
  EventType,
  StateDeltaEvent,
  ToolCallStartEvent,
  MessagesSnapshotEvent,
} from "@ag-ui/core";
import { describe, it, expect } from "@jest/globals";
import * as protoEvents from "../src/generated/events";

describe("Proto", () => {
  it("should encode events", () => {
    const event: BaseEvent = {
      type: EventType.TOOL_CALL_START,
      timestamp: Date.now(),
    };
    const encoded = encode(event);
    expect(encoded).toBeInstanceOf(Uint8Array);
  });
  it("should handle state delta events encoding", () => {
    const event: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: Date.now(),
      delta: [{ op: "add", path: "/foo", value: "bar" }],
    };
    const encoded = encode(event);
    expect(encoded).toBeInstanceOf(Uint8Array);
  });
  // Test for round-trip encoding/decoding
  it("should correctly round-trip encode/decode an event", () => {
    const originalEvent: ToolCallStartEvent = {
      type: EventType.TOOL_CALL_START,
      toolCallId: "123",
      toolCallName: "test",
    };
    const encoded = encode(originalEvent);
    const decoded = decode(encoded);
    expect(decoded.type).toBe(originalEvent.type);
    expect(decoded.timestamp).toBe(originalEvent.timestamp);
  });
  // Test for StateDeltaEvent round-trip
  it("should correctly round-trip encode/decode a StateDeltaEvent event", () => {
    const originalEvent: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: 1698765432123,
      delta: [
        { op: "add", path: "/foo", value: "bar" },
        { op: "remove", path: "/baz" },
      ],
    };
    const encoded = encode(originalEvent);
    const decoded = decode(encoded) as StateDeltaEvent;

    expect(decoded.type).toBe(originalEvent.type);
    expect(decoded.timestamp).toBe(originalEvent.timestamp);
    expect(decoded.delta).toHaveLength(originalEvent.delta.length);
    // Check delta operations
    expect(decoded.delta[0].op).toBe(originalEvent.delta[0].op);
    expect(decoded.delta[0].path).toBe(originalEvent.delta[0].path);
    expect(decoded.delta[0].value).toBe(originalEvent.delta[0].value);
    expect(decoded.delta[1].op).toBe(originalEvent.delta[1].op);
    expect(decoded.delta[1].path).toBe(originalEvent.delta[1].path);
  });
  // Test for complex values
  it("should correctly handle complex values in StateDeltaEvent events", () => {
    const complexValue = {
      nested: {
        array: [1, 2, 3],
        object: { key: "value" },
      },
      boolean: true,
      number: 42,
    };
    const originalEvent: StateDeltaEvent = {
      type: EventType.STATE_DELTA,
      timestamp: 1698765432123,
      delta: [{ op: "add", path: "/complex", value: complexValue }],
    };
    const encoded = encode(originalEvent);
    const decoded = decode(encoded) as StateDeltaEvent;
    expect(decoded.delta[0].value).toEqual(complexValue);
  });
  it("should correctly encode/decode a MessagesSnapshotEvent event with tool calls", () => {
    const originalEvent: MessagesSnapshotEvent = {
      type: EventType.MESSAGES_SNAPSHOT,
      timestamp: 1698765432123,
      messages: [
        {
          id: "msg-1",
          role: "user",
          content: "Hello, can you help me with something?",
        },
        {
          id: "msg-2",
          role: "assistant",
          content: "I'll help you analyze that data.",
          toolCalls: [
            {
              id: "tool-call-1",
              type: "function",
              function: {
                name: "analyze_data",
                arguments: JSON.stringify({
                  dataset: "sales_q2",
                  metrics: ["revenue", "growth"],
                }),
              },
            },
            {
              id: "tool-call-2",
              type: "function",
              function: {
                name: "generate_chart",
                arguments: JSON.stringify({
                  chartType: "bar",
                  data: "processed_data",
                }),
              },
            },
          ],
        },
      ],
    };

    const encoded = encode(originalEvent);
    const decoded = decode(encoded) as MessagesSnapshotEvent;

    // Verify basic event properties
    expect(decoded.type).toBe(originalEvent.type);
    expect(decoded.timestamp).toBe(originalEvent.timestamp);

    // Verify messages array
    expect(decoded.messages).toHaveLength(originalEvent.messages.length);

    // Verify first message (user)
    expect(decoded.messages[0].id).toBe(originalEvent.messages[0].id);
    expect(decoded.messages[0].role).toBe(originalEvent.messages[0].role);
    expect(decoded.messages[0].content).toBe(originalEvent.messages[0].content);

    // Verify second message (assistant with tool calls)
    expect(decoded.messages[1].id).toBe(originalEvent.messages[1].id);
    expect(decoded.messages[1].role).toBe(originalEvent.messages[1].role);
    expect(decoded.messages[1].content).toBe(originalEvent.messages[1].content);

    // Verify tool calls
    expect((decoded.messages[1] as any).toolCalls).toBeDefined();
    expect((decoded.messages[1] as any).toolCalls).toHaveLength(
      (originalEvent.messages[1] as any).toolCalls!.length,
    );

    // Verify first tool call
    expect((decoded.messages[1] as any).toolCalls![0].id).toBe(
      (originalEvent.messages[1] as any).toolCalls![0].id,
    );
    expect((decoded.messages[1] as any).toolCalls![0].type).toBe(
      (originalEvent.messages[1] as any).toolCalls![0].type,
    );
    expect((decoded.messages[1] as any).toolCalls![0].function.name).toBe(
      (originalEvent.messages[1] as any).toolCalls![0].function.name,
    );

    // Parse and compare JSON arguments
    const decodedArgs1 = JSON.parse((decoded.messages[1] as any).toolCalls![0].function.arguments);
    const originalArgs1 = JSON.parse(
      (originalEvent.messages[1] as any).toolCalls![0].function.arguments,
    );
    expect(decodedArgs1).toEqual(originalArgs1);

    // Verify second tool call
    expect((decoded.messages[1] as any).toolCalls![1].id).toBe(
      (originalEvent.messages[1] as any).toolCalls![1].id,
    );
    expect((decoded.messages[1] as any).toolCalls![1].function.name).toBe(
      (originalEvent.messages[1] as any).toolCalls![1].function.name,
    );

    const decodedArgs2 = JSON.parse((decoded.messages[1] as any).toolCalls![1].function.arguments);
    const originalArgs2 = JSON.parse(
      (originalEvent.messages[1] as any).toolCalls![1].function.arguments,
    );
    expect(decodedArgs2).toEqual(originalArgs2);
  });

  // Test for the "Invalid event" error case
  it("should throw an error when decoding an invalid event", () => {
    // Create an empty Event message without any oneof field set
    const emptyEvent = protoEvents.Event.create({});
    const encodedEmpty = protoEvents.Event.encode(emptyEvent).finish();

    // Attempt to decode the empty event should throw an error
    expect(() => decode(encodedEmpty)).toThrow("Invalid event");
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/run-events.test.ts
================================================
import {
  EventType,
  RunStartedEvent,
  RunFinishedEvent,
  RunErrorEvent,
  StepStartedEvent,
  StepFinishedEvent,
  RawEvent,
  CustomEvent,
} from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("Run Events and Misc Events", () => {
  describe("Run Events", () => {
    it("should round-trip encode/decode RunStartedEvent event", () => {
      const event: RunStartedEvent = {
        type: EventType.RUN_STARTED,
        timestamp: Date.now(),
        threadId: "thread-1234",
        runId: "run-5678",
      };

      expectRoundTripEquality(event);
    });

    it("should round-trip encode/decode RunFinishedEvent event", () => {
      const event: RunFinishedEvent = {
        type: EventType.RUN_FINISHED,
        timestamp: Date.now(),
        threadId: "thread-1234",
        runId: "run-5678",
      };

      expectRoundTripEquality(event);
    });

    it("should round-trip encode/decode RunErrorEvent event", () => {
      const event: RunErrorEvent = {
        type: EventType.RUN_ERROR,
        timestamp: Date.now(),
        message: "Failed to execute tool call",
      };

      expectRoundTripEquality(event);
    });

    it("should handle RunErrorEvent with detailed error info", () => {
      const event: RunErrorEvent = {
        type: EventType.RUN_ERROR,
        message: "API request failed",
        code: "API_ERROR",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("Step Events", () => {
    it("should round-trip encode/decode StepStartedEvent event", () => {
      const event: StepStartedEvent = {
        type: EventType.STEP_STARTED,
        timestamp: Date.now(),
        stepName: "data_analysis",
      };

      expectRoundTripEquality(event);
    });

    it("should round-trip encode/decode StepFinishedEvent event", () => {
      const event: StepFinishedEvent = {
        type: EventType.STEP_FINISHED,
        timestamp: Date.now(),
        stepName: "data_analysis",
      };

      expectRoundTripEquality(event);
    });

    it("should handle StepStartedEvent with minimal fields", () => {
      const event: StepStartedEvent = {
        type: EventType.STEP_STARTED,
        stepName: "process_payment",
      };

      expectRoundTripEquality(event);
    });

    it("should handle StepFinishedEvent with minimal fields", () => {
      const event: StepFinishedEvent = {
        type: EventType.STEP_FINISHED,
        stepName: "process_payment",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("RawEvent", () => {
    it("should round-trip encode/decode RawEvent", () => {
      const event: RawEvent = {
        type: EventType.RAW,
        timestamp: Date.now(),
        event: {
          type: "user_action",
          action: "button_click",
          elementId: "submit-btn",
          timestamp: Date.now(),
        },
        source: "frontend",
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex nested data in RawEvent", () => {
      const event: RawEvent = {
        type: EventType.RAW,
        event: {
          type: "analytics_event",
          session: {
            id: "sess-12345",
            user: {
              id: "user-456",
              attributes: {
                plan: "premium",
                signupDate: "2023-01-15",
                preferences: ["feature1", "feature2"],
              },
            },
            actions: [
              { type: "page_view", path: "/home", timestamp: 1676480210000 },
              {
                type: "button_click",
                elementId: "cta-1",
                timestamp: 1676480215000,
              },
              {
                type: "form_submit",
                formId: "signup",
                timestamp: 1676480230000,
                data: { email: "user@example.com" },
              },
            ],
          },
          metadata: {
            source: "web",
            version: "1.2.3",
            environment: "production",
          },
        },
      };

      expectRoundTripEquality(event);
    });
  });

  describe("CustomEvent", () => {
    it("should round-trip encode/decode CustomEvent", () => {
      const event: CustomEvent = {
        type: EventType.CUSTOM,
        timestamp: Date.now(),
        name: "user_preference_updated",
        value: {
          theme: "dark",
          fontSize: "medium",
          notifications: true,
        },
      };

      expectRoundTripEquality(event);
    });

    it("should handle CustomEvent without a value", () => {
      const event: CustomEvent = {
        type: EventType.CUSTOM,
        name: "heartbeat",
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex values in CustomEvent", () => {
      const event: CustomEvent = {
        type: EventType.CUSTOM,
        name: "analytics_update",
        value: {
          metrics: {
            active_users: 12345,
            conversion_rate: 0.0354,
            revenue: 98765.43,
          },
          segments: [
            { name: "new_users", count: 543, growth: 0.12 },
            { name: "returning_users", count: 876, growth: -0.05 },
            { name: "power_users", count: 234, growth: 0.08 },
          ],
          period: {
            start: "2023-01-01",
            end: "2023-01-31",
            duration_days: 31,
          },
          trends: {
            daily: [10, 12, 15, 14, 18, 20, 22],
            weekly: [70, 85, 92, 105],
            monthly: [320, 370],
          },
        },
      };

      expectRoundTripEquality(event);
    });
  });

  describe("Edge Cases", () => {
    it("should handle basic fields for each event type", () => {
      const events = [
        {
          type: EventType.RUN_STARTED,
          threadId: "thread-basic",
          runId: "run-basic",
        },
        {
          type: EventType.RUN_FINISHED,
          threadId: "thread-basic",
          runId: "run-basic",
        },
        { type: EventType.CUSTOM, name: "empty" },
      ];

      for (const event of events) {
        const encoded = encode(event);
        const decoded = decode(encoded);
        expect(decoded.type).toBe(event.type);
      }
    });

    it("should handle events with all base fields", () => {
      const runEvents = [
        {
          type: EventType.RUN_STARTED,
          timestamp: Date.now(),
          threadId: "thread-full",
          runId: "run-full",
          rawEvent: { original: "data", from: "external_system" },
        },
        {
          type: EventType.RUN_FINISHED,
          timestamp: Date.now(),
          threadId: "thread-full",
          runId: "run-full",
          rawEvent: { original: "data", from: "external_system" },
        },
      ];

      const nonRunEvents = [
        {
          type: EventType.RUN_ERROR,
          message: "Test error",
          timestamp: Date.now(),
          rawEvent: { original: "data", from: "external_system" },
        },
        {
          type: EventType.CUSTOM,
          name: "full_event",
          timestamp: Date.now(),
          rawEvent: { original: "data", from: "external_system" },
        },
      ];

      for (const event of [...runEvents, ...nonRunEvents]) {
        expectRoundTripEquality(event);
      }
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/state-events.test.ts
================================================
import { EventType, StateSnapshotEvent, StateDeltaEvent } from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("State Events", () => {
  describe("StateSnapshotEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        timestamp: Date.now(),
        snapshot: {
          counter: 42,
          items: ["apple", "banana", "cherry"],
          config: {
            enabled: true,
            maxRetries: 3,
          },
        },
      };

      expectRoundTripEquality(event);
    });

    it("should handle empty snapshot object", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: {},
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex nested objects", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: {
          userProfile: {
            name: "John Doe",
            age: 30,
            contact: {
              email: "john@example.com",
              phone: "+1234567890",
              address: {
                street: "123 Main St",
                city: "Anytown",
                country: "USA",
                coordinates: {
                  lat: 37.7749,
                  lng: -122.4194,
                },
              },
            },
            preferences: {
              theme: "dark",
              notifications: true,
              privateProfile: false,
            },
          },
          serviceConfig: {
            endpoints: [
              {
                name: "api1",
                url: "https://api1.example.com",
                methods: ["GET", "POST"],
              },
              {
                name: "api2",
                url: "https://api2.example.com",
                methods: ["GET"],
              },
            ],
            retryPolicy: {
              maxRetries: 3,
              backoff: "exponential",
              timeouts: [1000, 2000, 4000],
            },
          },
          stats: {
            visits: 1042,
            conversions: 123,
            bounceRate: 0.25,
            dataPoints: [
              { date: "2023-01-01", value: 10 },
              { date: "2023-01-02", value: 15 },
              { date: "2023-01-03", value: 8 },
            ],
          },
        },
      };

      expectRoundTripEquality(event);
    });

    it("should handle special values in snapshot", () => {
      const event: StateSnapshotEvent = {
        type: EventType.STATE_SNAPSHOT,
        snapshot: {
          nullValue: null,
          emptyString: "",
          zero: 0,
          negativeNumber: -123,
          floatNumber: 3.14159,
          emptyArray: [],
          emptyObject: {},
          boolValues: { true: true, false: false },
          infinityValue: Infinity,
          nanValue: NaN,
          dateString: new Date().toISOString(),
        },
      };

      const encoded = encode(event);
      const decoded = decode(encoded) as StateSnapshotEvent;

      // Check specific values that might need special handling
      expect(decoded.snapshot.nullValue).toBe(event.snapshot.nullValue);
      expect(decoded.snapshot.emptyString).toBe(event.snapshot.emptyString);
      expect(decoded.snapshot.zero).toBe(event.snapshot.zero);
      expect(decoded.snapshot.negativeNumber).toBe(event.snapshot.negativeNumber);
      expect(decoded.snapshot.floatNumber).toBe(event.snapshot.floatNumber);
      expect(decoded.snapshot.emptyArray).toEqual(event.snapshot.emptyArray);
      expect(decoded.snapshot.emptyObject).toEqual(event.snapshot.emptyObject);
      expect(decoded.snapshot.boolValues).toEqual(event.snapshot.boolValues);
      expect(decoded.snapshot.dateString).toBe(event.snapshot.dateString);

      // Infinity/NaN don't survive JSON.stringify, so they may not be exactly equal
      if (Number.isNaN(decoded.snapshot.nanValue)) {
        expect(Number.isNaN(event.snapshot.nanValue)).toBe(true);
      }
    });
  });

  describe("StateDeltaEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        timestamp: Date.now(),
        delta: [
          { op: "add", path: "/counter", value: 42 },
          { op: "add", path: "/items", value: ["apple", "banana", "cherry"] },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle all JSON Patch operation types", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          { op: "add", path: "/users/123", value: { name: "John", age: 30 } },
          { op: "remove", path: "/users/456" },
          { op: "replace", path: "/users/789/name", value: "Jane Doe" },
          { op: "move", from: "/users/old", path: "/users/new" },
          {
            op: "copy",
            from: "/templates/default",
            path: "/users/123/template",
          },
          { op: "test", path: "/users/123/active", value: true },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex values in add operations", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          {
            op: "add",
            path: "/data",
            value: {
              nested: {
                array: [1, 2, 3],
                object: { key: "value" },
              },
              boolean: true,
              number: 42,
            },
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle array operations", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          { op: "add", path: "/items", value: [] },
          { op: "add", path: "/items/0", value: "first" },
          { op: "add", path: "/items/-", value: "last" },
          { op: "replace", path: "/items/0", value: "updated first" },
          { op: "remove", path: "/items/1" },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle special characters in paths", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [
          { op: "add", path: "/special~0field", value: "value with tilde" },
          { op: "add", path: "/special~1field", value: "value with slash" },
          {
            op: "add",
            path: "/special/field",
            value: "value with actual slash",
          },
          { op: "add", path: '/special"field', value: "value with quote" },
          {
            op: "add",
            path: "/emoji\u{1F680}field",
            value: "value with emoji",
          },
        ],
      };

      expectRoundTripEquality(event);
    });

    it("should handle empty delta array", () => {
      const event: StateDeltaEvent = {
        type: EventType.STATE_DELTA,
        delta: [],
      };

      expectRoundTripEquality(event);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/test-utils.ts
================================================
import { BaseEvent } from "@ag-ui/core";
import { encode, decode } from "../src/proto";
import { expect, describe, it } from "@jest/globals";

/**
 * Performs a round-trip encode-decode on an event and returns the decoded result
 */
export function roundTrip<T extends BaseEvent>(event: T): T {
  const encoded = encode(event);
  return decode(encoded) as T;
}

/**
 * Verifies that an event is the same after round-trip encoding and decoding
 */
export function expectRoundTripEquality<T extends BaseEvent>(event: T): void {
  const decoded = roundTrip(event);

  // Verify all properties match
  for (const key in event) {
    if (Object.prototype.hasOwnProperty.call(event, key)) {
      expect(decoded[key]).toEqual(event[key]);
    }
  }
}

// Add a simple test to prevent "Your test suite must contain at least one test" error
describe("Test Utilities", () => {
  it("should exist as a module for other tests to import from", () => {
    expect(typeof roundTrip).toBe("function");
    expect(typeof expectRoundTripEquality).toBe("function");
  });
});



================================================
FILE: typescript-sdk/packages/proto/__tests__/tool-call-events.test.ts
================================================
import { EventType, ToolCallStartEvent, ToolCallArgsEvent, ToolCallEndEvent } from "@ag-ui/core";
import { expect, describe, it } from "@jest/globals";
import { encode, decode } from "../src/proto";
import { expectRoundTripEquality } from "./test-utils";

describe("Tool Call Events", () => {
  describe("ToolCallStartEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        timestamp: Date.now(),
        toolCallId: "tool-1",
        toolCallName: "get_weather",
      };

      expectRoundTripEquality(event);
    });

    it("should handle event with parent message id", () => {
      const event: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        toolCallId: "tool-1",
        toolCallName: "search_database",
        parentMessageId: "msg-123",
      };

      expectRoundTripEquality(event);
    });

    it("should preserve all optional fields", () => {
      const event: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        timestamp: 1698765432123,
        toolCallId: "tool-call-id-123",
        toolCallName: "very_long_tool_name_with_underscores",
        parentMessageId: "parent-message-id-456",
        rawEvent: { original: "event data", from: "source system" },
      };

      expectRoundTripEquality(event);
    });
  });

  describe("ToolCallArgsEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: Date.now(),
        toolCallId: "tool-1",
        delta: '{"location":"San Francisco"}',
      };

      expectRoundTripEquality(event);
    });

    it("should handle complex JSON in delta", () => {
      const complexJson = JSON.stringify({
        query: "SELECT * FROM users",
        filters: {
          age: { min: 18, max: 65 },
          status: ["active", "pending"],
          location: {
            country: "US",
            states: ["CA", "NY", "TX"],
          },
        },
        options: {
          limit: 100,
          offset: 0,
          sort: { field: "created_at", order: "desc" },
        },
      });

      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "db-query-tool-123",
        delta: complexJson,
      };

      expectRoundTripEquality(event);
    });

    it("should handle special characters in delta", () => {
      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "tool-1",
        delta: '{"text":"Special chars: 🚀 ñ € 😊 \\n\\t\\"\'\\\\"}',
      };

      expectRoundTripEquality(event);
    });

    it("should handle partial JSON in delta (streaming case)", () => {
      // Test case for when JSON might be sent in chunks
      const event: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        toolCallId: "streaming-tool",
        delta: '{"location":"San Fran',
      };

      expectRoundTripEquality(event);
    });
  });

  describe("ToolCallEndEvent", () => {
    it("should round-trip encode/decode correctly", () => {
      const event: ToolCallEndEvent = {
        type: EventType.TOOL_CALL_END,
        timestamp: Date.now(),
        toolCallId: "tool-1",
      };

      expectRoundTripEquality(event);
    });

    it("should handle minimal required fields", () => {
      const event: ToolCallEndEvent = {
        type: EventType.TOOL_CALL_END,
        toolCallId: "tool-1",
      };

      expectRoundTripEquality(event);
    });
  });

  describe("Complex Tool Call Sequence", () => {
    it("should correctly encode/decode a sequence of related tool call events", () => {
      // Create a sequence of related tool call events
      const startEvent: ToolCallStartEvent = {
        type: EventType.TOOL_CALL_START,
        timestamp: 1000,
        toolCallId: "complex-tool-1",
        toolCallName: "query_database",
      };

      const argsEvent1: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: 1001,
        toolCallId: "complex-tool-1",
        delta: '{"query":"SELECT * FROM',
      };

      const argsEvent2: ToolCallArgsEvent = {
        type: EventType.TOOL_CALL_ARGS,
        timestamp: 1002,
        toolCallId: "complex-tool-1",
        delta: ' users WHERE age > 18"}',
      };

      const endEvent: ToolCallEndEvent = {
        type: EventType.TOOL_CALL_END,
        timestamp: 1003,
        toolCallId: "complex-tool-1",
      };

      // Test each event in the sequence
      expectRoundTripEquality(startEvent);
      expectRoundTripEquality(argsEvent1);
      expectRoundTripEquality(argsEvent2);
      expectRoundTripEquality(endEvent);

      // Ensure toolCallId is preserved across events
      const decodedStart = decode(encode(startEvent)) as ToolCallStartEvent;
      const decodedArgs1 = decode(encode(argsEvent1)) as ToolCallArgsEvent;
      const decodedArgs2 = decode(encode(argsEvent2)) as ToolCallArgsEvent;
      const decodedEnd = decode(encode(endEvent)) as ToolCallEndEvent;

      // Check consistent fields across events
      expect(decodedStart.toolCallId).toBe(startEvent.toolCallId);

      expect(decodedArgs1.toolCallId).toBe(argsEvent1.toolCallId);

      expect(decodedArgs2.toolCallId).toBe(argsEvent2.toolCallId);

      expect(decodedEnd.toolCallId).toBe(endEvent.toolCallId);
    });
  });
});



================================================
FILE: typescript-sdk/packages/proto/src/index.ts
================================================
export { encode, decode } from "./proto";

export const AGUI_MEDIA_TYPE = "application/vnd.ag-ui.event+proto";



================================================
FILE: typescript-sdk/packages/proto/src/proto.ts
================================================
import { BaseEvent, EventSchemas, EventType, Message } from "@ag-ui/core";
import * as protoEvents from "./generated/events";
import * as protoPatch from "./generated/patch";

function toCamelCase(str: string): string {
  return str.toLowerCase().replace(/_([a-z])/g, (_, letter) => letter.toUpperCase());
}

/**
 * Encodes an event message to a protocol buffer binary format.
 */
export function encode(event: BaseEvent): Uint8Array {
  const oneofField = toCamelCase(event.type);
  const { type, timestamp, rawEvent, ...rest } = event as any;

  // since protobuf does not support optional arrays, we need to ensure that the toolCalls array is always present
  if (type === EventType.MESSAGES_SNAPSHOT) {
    rest.messages = rest.messages.map((message: Message) => {
      const untypedMessage = message as any;
      if (untypedMessage.toolCalls === undefined) {
        return { ...message, toolCalls: [] };
      }
      return message;
    });
  }

  // custom mapping for json patch operations
  if (type === EventType.STATE_DELTA) {
    rest.delta = rest.delta.map((operation: any) => ({
      ...operation,
      op: protoPatch.JsonPatchOperationType[operation.op.toUpperCase()],
    }));
  }

  const eventMessage = {
    [oneofField]: {
      baseEvent: {
        type: protoEvents.EventType[event.type as keyof typeof protoEvents.EventType],
        timestamp,
        rawEvent,
      },
      ...rest,
    },
  };
  return protoEvents.Event.encode(eventMessage).finish();
}

/**
 * Decodes a protocol buffer binary format to an event message.
 * The format includes a 4-byte length prefix followed by the message.
 */
export function decode(data: Uint8Array): BaseEvent {
  const event = protoEvents.Event.decode(data);
  const decoded = Object.values(event).find((value) => value !== undefined);
  if (!decoded) {
    throw new Error("Invalid event");
  }
  decoded.type = protoEvents.EventType[decoded.baseEvent.type];
  decoded.timestamp = decoded.baseEvent.timestamp;
  decoded.rawEvent = decoded.baseEvent.rawEvent;

  // we want tool calls to be optional, so we need to remove them if they are empty
  if (decoded.type === EventType.MESSAGES_SNAPSHOT) {
    for (const message of (decoded as any).messages as Message[]) {
      const untypedMessage = message as any;
      if (untypedMessage.toolCalls?.length === 0) {
        untypedMessage.toolCalls = undefined;
      }
    }
  }

  // custom mapping for json patch operations
  if (decoded.type === EventType.STATE_DELTA) {
    for (const operation of (decoded as any).delta) {
      operation.op = protoPatch.JsonPatchOperationType[operation.op].toLowerCase();
      Object.keys(operation).forEach((key) => {
        if (operation[key] === undefined) {
          delete operation[key];
        }
      });
    }
  }

  Object.keys(decoded).forEach((key) => {
    if (decoded[key] === undefined) {
      delete decoded[key];
    }
  });

  return EventSchemas.parse(decoded);
}



================================================
FILE: typescript-sdk/packages/proto/src/proto/events.proto
================================================
syntax = "proto3";

package ag_ui;

import "google/protobuf/struct.proto";
import "patch.proto";
import "types.proto";

enum EventType {
  TEXT_MESSAGE_START = 0;
  TEXT_MESSAGE_CONTENT = 1;
  TEXT_MESSAGE_END = 2;
  TOOL_CALL_START = 3;
  TOOL_CALL_ARGS = 4;
  TOOL_CALL_END = 5;
  STATE_SNAPSHOT = 6;
  STATE_DELTA = 7;
  MESSAGES_SNAPSHOT = 8;
  RAW = 9;
  CUSTOM = 10;
  RUN_STARTED = 11;
  RUN_FINISHED = 12;
  RUN_ERROR = 13;
  STEP_STARTED = 14;
  STEP_FINISHED = 15;
}

message BaseEvent {
  EventType type = 1;
  optional int64 timestamp = 2;
  optional google.protobuf.Value raw_event = 3;
}

message TextMessageStartEvent {
  BaseEvent base_event = 1;
  string message_id = 2;
  optional string role = 3;
}

message TextMessageContentEvent {
  BaseEvent base_event = 1;
  string message_id = 2;
  string delta = 3;
}

message TextMessageEndEvent {
  BaseEvent base_event = 1;
  string message_id = 2;
}

message ToolCallStartEvent {
  BaseEvent base_event = 1;
  string tool_call_id = 2;
  string tool_call_name = 3;
  optional string parent_message_id = 4;
}

message ToolCallArgsEvent {
  BaseEvent base_event = 1;
  string tool_call_id = 2;
  string delta = 3;
}

message ToolCallEndEvent {
  BaseEvent base_event = 1;
  string tool_call_id = 2;
}

message StateSnapshotEvent {
  BaseEvent base_event = 1;
  google.protobuf.Value snapshot = 2;
}

message StateDeltaEvent {
  BaseEvent base_event = 1;
  repeated JsonPatchOperation delta = 2;
}

message MessagesSnapshotEvent {
  BaseEvent base_event = 1;
  repeated Message messages = 2;
}

message RawEvent {
  BaseEvent base_event = 1;
  google.protobuf.Value event = 2;
  optional string source = 3;
}

message CustomEvent {
  BaseEvent base_event = 1;
  string name = 2;
  optional google.protobuf.Value value = 3;
}

message RunStartedEvent {
  BaseEvent base_event = 1;
  string thread_id = 2;
  string run_id = 3;
}

message RunFinishedEvent {
  BaseEvent base_event = 1;
  string thread_id = 2;
  string run_id = 3;
  optional google.protobuf.Value result = 4;
}

message RunErrorEvent {
  BaseEvent base_event = 1;
  optional string code = 2;
  string message = 3;
}

message StepStartedEvent {
  BaseEvent base_event = 1;
  string step_name = 2;
}

message StepFinishedEvent {
  BaseEvent base_event = 1;
  string step_name = 2;
}

message TextMessageChunkEvent {
  BaseEvent base_event = 1;
  optional string message_id = 2;
  optional string role = 3;
  optional string delta = 4;
}

message ToolCallChunkEvent {
  BaseEvent base_event = 1;
  optional string tool_call_id = 2;
  optional string tool_call_name = 3;
  optional string parent_message_id = 4;
  optional string delta = 5;
}

message Event {
  oneof event {
    TextMessageStartEvent text_message_start = 1;
    TextMessageContentEvent text_message_content = 2;
    TextMessageEndEvent text_message_end = 3;
    ToolCallStartEvent tool_call_start = 4;
    ToolCallArgsEvent tool_call_args = 5;
    ToolCallEndEvent tool_call_end = 6;
    StateSnapshotEvent state_snapshot = 7;
    StateDeltaEvent state_delta = 8;
    MessagesSnapshotEvent messages_snapshot = 9;
    RawEvent raw = 10;
    CustomEvent custom = 11;
    RunStartedEvent run_started = 12;
    RunFinishedEvent run_finished = 13;
    RunErrorEvent run_error = 14;
    StepStartedEvent step_started = 15;
    StepFinishedEvent step_finished = 16;
    TextMessageChunkEvent text_message_chunk = 17;
    ToolCallChunkEvent tool_call_chunk = 18;
  }
}


================================================
FILE: typescript-sdk/packages/proto/src/proto/patch.proto
================================================
syntax = "proto3";

import "google/protobuf/struct.proto";

package ag_ui;

enum JsonPatchOperationType {
  ADD = 0;
  REMOVE = 1;
  REPLACE = 2;
  MOVE = 3;
  COPY = 4;
  TEST = 5;
}

message JsonPatchOperation {
  JsonPatchOperationType op = 1;
  string path = 2;
  optional string from = 3;
  optional google.protobuf.Value value = 4;
}



================================================
FILE: typescript-sdk/packages/proto/src/proto/types.proto
================================================
syntax = "proto3";

package ag_ui;

message ToolCall {
  string id = 1;
  string type = 2; 
  message Function {
    string name = 1;
    string arguments = 2; 
  }  
  Function function = 3;
}

message Message {
  string id = 1;
  string role = 2;
  optional string content = 3;
  optional string name = 4;
  repeated ToolCall tool_calls = 5;
  optional string tool_call_id = 6;
  optional string error = 7;
}



================================================
FILE: typescript-sdk/.cursor/rules/project-rules.mdc
================================================
---
description: 
globs: 
alwaysApply: true
---
# Project Overview

This monorepo project utilizes:
- Turborepo for build system orchestration
- PNPM for package management
- Jest for unit testing

Test files are located in `__tests__` directories alongside their corresponding implementation files.

Note: To run tests, navigate to the specific package directory and execute `pnpm run test`


================================================
FILE: .github/CODEOWNERS
================================================
* @mme @ranst91 @ataibarkai @maxkorp @tylerslaton @NathanTarbert



================================================
FILE: .github/workflows/check-generated-files.yml
================================================
name: Check Generated Files

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  check-files-json:
    name: Check files.json
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Regenerate files.json
        working-directory: typescript-sdk/apps/dojo
        run: npm run generate-content-json

      - name: Check files.json
        working-directory: typescript-sdk/apps/dojo
        run: |
          if git diff --exit-code src/files.json > /dev/null; then
            echo "✅ No changes detected in dojo/src/files.json. Everything is up to date."
          else
            echo "❌ Detected changes in dojo/src/files.json."
            echo ""
            echo "Please run \`(p)npm run generate-content-json\` in the typescript-sdk/apps/dojo folder and commit the changes."
            echo ""
            echo "The detected diff was as follows:"
            echo "::group::Diff for dojo/src/files.json"
            git diff src/files.json
            echo "::endgroup::"
            exit 1
          fi





================================================
FILE: .github/workflows/dojo-e2e.yml
================================================
name: e2e

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  e2e:
    name: ${{ matrix.suite }}
    runs-on: depot-ubuntu-24.04
    strategy:
      fail-fast: false
      matrix:
        include:
          - suite: adk-middleware
            test_path: tests/adkMiddlewareTests
            services: ["dojo","adk-middleware"]
            wait_on: http://localhost:9999,tcp:localhost:8010
          - suite: agno
            test_path: tests/agnoTests
            services: ["dojo","agno"]
            wait_on: http://localhost:9999,tcp:localhost:8002
          - suite: crew-ai
            test_path: tests/crewAITests
            services: ["dojo","crew-ai"]
            wait_on: http://localhost:9999,tcp:localhost:8003
          - suite: langgraph-python
            test_path: tests/langgraphPythonTests
            services: ["dojo","langgraph-platform-python"]
            wait_on: http://localhost:9999,tcp:localhost:8005
          - suite: langgraph-typescript
            test_path: tests/langgraphTypescriptTests
            services: ["dojo","langgraph-platform-typescript"]
            wait_on: http://localhost:9999,tcp:localhost:8006
          - suite: langgraph-fastapi
            test_path: tests/langgraphFastAPITests
            services: ["dojo","langgraph-fastapi"]
            wait_on: http://localhost:9999,tcp:localhost:8004
          - suite: llama-index
            test_path: tests/llamaIndexTests
            services: ["dojo","llama-index"]
            wait_on: http://localhost:9999,tcp:localhost:8007
          - suite: mastra
            test_path: tests/mastraTests
            services: ["dojo","mastra"]
            wait_on: http://localhost:9999,tcp:localhost:8008
          - suite: mastra-agent-local
            test_path: tests/mastraAgentLocalTests
            services: ["dojo"]
            wait_on: http://localhost:9999
          - suite: middleware-starter
            test_path: tests/middlewareStarterTests
            services: ["dojo"]
            wait_on: http://localhost:9999
          - suite: pydantic-ai
            test_path: tests/pydanticAITests
            services: ["dojo","pydantic-ai"]
            wait_on: http://localhost:9999,tcp:localhost:8009
          - suite: server-starter
            test_path: tests/serverStarterTests
            services: ["dojo","server-starter"]
            wait_on: http://localhost:9999,tcp:localhost:8000
          - suite: server-starter-all
            test_path: tests/serverStarterAllFeaturesTests
            services: ["dojo","server-starter-all"]
            wait_on: http://localhost:9999,tcp:localhost:8001
          - suite: vercel-ai-sdk
            test_path: tests/vercelAISdkTests
            services: ["dojo"]
            wait_on: http://localhost:9999

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'

    - name: Install pnpm
      uses: pnpm/action-setup@v4
      with:
        version: 10.13.1

    # Now that pnpm is available, cache its store to speed installs
    - name: Resolve pnpm store path
      id: pnpm-store
      run: echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

    - name: Cache pnpm store
      uses: actions/cache@v4
      with:
        path: ${{ env.STORE_PATH }}
        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
        restore-keys: |
          ${{ runner.os }}-pnpm-store-

    # Cache Python tool caches and virtualenvs; restore only to avoid long saves
    - name: Cache Python dependencies (restore-only)
      id: cache-python
      uses: actions/cache/restore@v4
      with:
        path: |
          ~/.cache/pip
          ~/.cache/pypoetry
          ~/.cache/uv
          **/.venv
        key: ${{ runner.os }}-pydeps-${{ hashFiles('**/poetry.lock', '**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pydeps-

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install uv
      uses: astral-sh/setup-uv@v6

    - name: Install dependencies
      working-directory: typescript-sdk
      run: pnpm install --frozen-lockfile

    - name: Prepare dojo for e2e
      working-directory: typescript-sdk/apps/dojo
      if: ${{ join(matrix.services, ',') != '' }}
      run: node ./scripts/prep-dojo-everything.js --only ${{ join(matrix.services, ',') }}

    - name: Install e2e dependencies
      working-directory: typescript-sdk/apps/dojo/e2e
      run: |
        pnpm install

    - name: write langgraph env files
      working-directory: typescript-sdk/integrations/langgraph
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
      if: ${{ contains(join(matrix.services, ','), 'langgraph-fastapi') || contains(join(matrix.services, ','), 'langgraph-platform-python') || contains(join(matrix.services, ','), 'langgraph-platform-typescript') }}
      run: |
        echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > examples/python/.env
        echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> examples/python/.env
        echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > examples/typescript/.env
        echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> examples/typescript/.env
        echo "OPENAI_API_KEY=${OPENAI_API_KEY}" > python/ag_ui_langgraph/.env
        echo "LANGSMITH_API_KEY=${LANGSMITH_API_KEY}" >> python/ag_ui_langgraph/.env

    - name: Run dojo+agents
      uses: JarvusInnovations/background-action@v1
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      if: ${{ join(matrix.services, ',') != '' && contains(join(matrix.services, ','), 'dojo') }}
      with:
        run: |
          node ../scripts/run-dojo-everything.js --only ${{ join(matrix.services, ',') }}
        working-directory: typescript-sdk/apps/dojo/e2e
        wait-on: ${{ matrix.wait_on }}
        wait-for: 300000

    - name: Run tests – ${{ matrix.suite }}
      working-directory: typescript-sdk/apps/dojo/e2e
      env:
        BASE_URL: http://localhost:9999
        PLAYWRIGHT_SUITE: ${{ matrix.suite }}
      run: |
        pnpm test -- ${{ matrix.test_path }}

    - name: Upload traces – ${{ matrix.suite }}
      if: always() # Uploads artifacts even if tests fail
      uses: actions/upload-artifact@v4
      with:
        name: ${{ matrix.suite }}-playwright-traces
        path: |
          typescript-sdk/apps/dojo/e2e/test-results/${{ matrix.suite }}/**/*
          typescript-sdk/apps/dojo/e2e/playwright-report/**/*
        retention-days: 7



================================================
FILE: .github/workflows/test.yml
================================================
name: test

on:
  push:
    branches: main
  pull_request:
    branches: main

jobs:
  python:
    name: Python SDK Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v4
      with:
        path: python-sdk/.venv
        key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      working-directory: python-sdk
      run: poetry install --no-interaction --no-root

    - name: Install project
      working-directory: python-sdk
      run: poetry install --no-interaction

    - name: Run tests
      working-directory: python-sdk
      run: poetry run python -m unittest discover tests -v

  typescript:
    name: TypeScript SDK Tests
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install protoc
      uses: arduino/setup-protoc@v3
      with:
        version: "25.x"
        repo-token: ${{ secrets.GITHUB_TOKEN }}

    - name: Install pnpm
      uses: pnpm/action-setup@v4
      with:
        version: 10.13.1

    - name: Setup pnpm cache
      uses: actions/cache@v4
      with:
        path: ~/.local/share/pnpm/store
        key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
        restore-keys: |
          ${{ runner.os }}-pnpm-store-

    - name: Install dependencies
      working-directory: typescript-sdk
      run: pnpm install --frozen-lockfile

    - name: Test Build
      working-directory: typescript-sdk
      run: pnpm run build

    - name: Run tests
      working-directory: typescript-sdk
      run: pnpm run test

