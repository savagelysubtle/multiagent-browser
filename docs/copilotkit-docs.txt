Directory structure:
└── docs/
    ├── README.md
    ├── components.json
    ├── next-env.d.ts
    ├── next.config.mjs
    ├── package.json
    ├── pnpm-lock.yaml
    ├── postcss.config.js
    ├── props.ts
    ├── script.mjs
    ├── source.config.ts
    ├── tailwind.config.js
    ├── tsconfig.json
    ├── vercel.json
    ├── .env
    ├── .gitignore
    ├── .prettierignore
    ├── app/
    │   ├── global.css
    │   ├── layout.config.tsx
    │   ├── layout.tsx
    │   ├── logo.tsx
    │   ├── not-found.tsx
    │   ├── sitemap.ts
    │   ├── source.ts
    │   ├── (home)/
    │   │   ├── layout.tsx
    │   │   └── [[...slug]]/
    │   │       └── page.tsx
    │   ├── api/
    │   │   └── search/
    │   │       └── route.ts
    │   └── og/
    │       └── [...slug]/
    │           └── route.tsx
    ├── components/
    │   ├── layout/
    │   │   ├── banners.tsx
    │   │   └── top-bar.tsx
    │   ├── markdown/
    │   │   └── test-markdown-component.mdx
    │   ├── react/
    │   │   ├── copilotkit-css.tsx
    │   │   ├── cta-cards.tsx
    │   │   ├── dynamic-content-wrapper.tsx
    │   │   ├── examples-carousel.tsx
    │   │   ├── frame.tsx
    │   │   ├── image-and-code.tsx
    │   │   ├── insecure-password-protected.tsx
    │   │   ├── link-to-copilot-cloud.tsx
    │   │   ├── property-reference.tsx
    │   │   ├── select-llm-provider.tsx
    │   │   ├── socials.tsx
    │   │   ├── subdocs-menu.tsx
    │   │   ├── tabs.tsx
    │   │   ├── tailored-content.tsx
    │   │   ├── test-react-component.tsx
    │   │   ├── youtube-video.tsx
    │   │   ├── coagents/
    │   │   │   ├── coagents-diagram.tsx
    │   │   │   ├── coagents-enterprise-cta.tsx
    │   │   │   └── coagents-features.tsx
    │   │   ├── component-previews/
    │   │   │   └── new-look-and-feel.tsx
    │   │   └── multi-provider-content/
    │   │       ├── multi-provider-content.tsx
    │   │       └── utils.ts
    │   └── ui/
    │       ├── badge.tsx
    │       ├── button.tsx
    │       ├── card.tsx
    │       ├── input.tsx
    │       ├── scroll-area.tsx
    │       └── select.tsx
    ├── content/
    │   └── docs/
    │       ├── (root)/
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── quickstart.mdx
    │       │   ├── (other)/
    │       │   │   ├── contributing/
    │       │   │   │   ├── docs-contributions.mdx
    │       │   │   │   ├── meta.json
    │       │   │   │   └── code-contributions/
    │       │   │   │       ├── index.mdx
    │       │   │   │       └── package-linking.mdx
    │       │   │   ├── observability/
    │       │   │   │   └── langsmith.mdx
    │       │   │   └── telemetry/
    │       │   │       └── index.mdx
    │       │   ├── cookbook/
    │       │   │   └── state-machine.mdx
    │       │   ├── guides/
    │       │   │   ├── authenticated-actions.mdx
    │       │   │   ├── backend-actions_old.mdx
    │       │   │   ├── bring-your-own-llm.mdx
    │       │   │   ├── copilot-suggestions.mdx
    │       │   │   ├── copilot-textarea.mdx
    │       │   │   ├── custom-ai-assistant-behavior.mdx
    │       │   │   ├── front-backend-action-pairing.mdx
    │       │   │   ├── frontend-actions.mdx
    │       │   │   ├── generative-ui.mdx
    │       │   │   ├── guardrails.mdx
    │       │   │   ├── messages-localstorage.mdx
    │       │   │   ├── meta.json
    │       │   │   ├── model-context-protocol.mdx
    │       │   │   ├── self-hosting.mdx
    │       │   │   ├── backend-actions/
    │       │   │   │   ├── index.mdx
    │       │   │   │   ├── langchain-js-backend-actions.mdx
    │       │   │   │   ├── langgraph-platform-endpoint.mdx
    │       │   │   │   ├── langserve-backend-actions.mdx
    │       │   │   │   ├── meta.json
    │       │   │   │   ├── remote-backend-endpoint.mdx
    │       │   │   │   └── typescript-backend-actions.mdx
    │       │   │   ├── connect-your-data/
    │       │   │   │   ├── backend.mdx
    │       │   │   │   ├── frontend.mdx
    │       │   │   │   ├── index.mdx
    │       │   │   │   └── meta.json
    │       │   │   └── custom-look-and-feel/
    │       │   │       ├── bring-your-own-components.mdx
    │       │   │       ├── built-in-ui-components.mdx
    │       │   │       ├── customize-built-in-ui-components.mdx
    │       │   │       ├── headless-ui.mdx
    │       │   │       ├── index.mdx
    │       │   │       ├── markdown-rendering.mdx
    │       │   │       └── meta.json
    │       │   ├── troubleshooting/
    │       │   │   ├── common-issues.mdx
    │       │   │   ├── meta.json
    │       │   │   └── migrate-to-1.8.2.mdx
    │       │   └── tutorials/
    │       │       ├── meta.json
    │       │       ├── ai-powered-textarea/
    │       │       │   ├── meta.json
    │       │       │   ├── next-steps.mdx
    │       │       │   ├── overview.mdx
    │       │       │   ├── step-1-checkout-repo.mdx
    │       │       │   ├── step-2-setup-copilotkit.mdx
    │       │       │   ├── step-3-copilot-textarea.mdx
    │       │       │   └── step-4-copilot-readable-state.mdx
    │       │       └── ai-todo-app/
    │       │           ├── meta.json
    │       │           ├── next-steps.mdx
    │       │           ├── overview.mdx
    │       │           ├── step-1-checkout-repo.mdx
    │       │           ├── step-2-setup-copilotkit.mdx
    │       │           ├── step-3-copilot-readable-state.mdx
    │       │           └── step-4-copilot-actions.mdx
    │       ├── ag2/
    │       │   ├── agentic-chat-ui.mdx
    │       │   ├── frontend-actions.mdx
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── quickstart.mdx
    │       │   ├── concepts/
    │       │   │   ├── ag2.mdx
    │       │   │   ├── agentic-copilots.mdx
    │       │   │   ├── meta.json
    │       │   │   └── terminology.mdx
    │       │   └── human-in-the-loop/
    │       │       ├── hitl.mdx
    │       │       ├── index.mdx
    │       │       └── meta.json
    │       ├── coagents/
    │       │   ├── agentic-chat-ui.mdx
    │       │   ├── frontend-actions.mdx
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── multi-agent-flows.mdx
    │       │   ├── quickstart.mdx
    │       │   ├── advanced/
    │       │   │   ├── adding-runtime-configuration.mdx
    │       │   │   ├── disabling-state-streaming.mdx
    │       │   │   ├── emit-messages.mdx
    │       │   │   ├── exit-agent.mdx
    │       │   │   └── meta.json
    │       │   ├── concepts/
    │       │   │   ├── agentic-copilots.mdx
    │       │   │   ├── copilotkit-config.mdx
    │       │   │   ├── langgraph.mdx
    │       │   │   ├── message-management.mdx
    │       │   │   ├── meta.json
    │       │   │   ├── state.mdx
    │       │   │   └── terminology.mdx
    │       │   ├── custom-look-and-feel/
    │       │   │   ├── bring-your-own-components.mdx
    │       │   │   ├── built-in-ui-components.mdx
    │       │   │   ├── customize-built-in-ui-components.mdx
    │       │   │   ├── headless-ui.mdx
    │       │   │   ├── index.mdx
    │       │   │   └── meta.json
    │       │   ├── generative-ui/
    │       │   │   ├── agentic.mdx
    │       │   │   ├── index.mdx
    │       │   │   └── tool-based.mdx
    │       │   ├── human-in-the-loop/
    │       │   │   ├── index.mdx
    │       │   │   ├── interrupt-flow.mdx
    │       │   │   ├── meta.json
    │       │   │   └── node-flow.mdx
    │       │   ├── persistence/
    │       │   │   ├── loading-agent-state.mdx
    │       │   │   ├── loading-message-history.mdx
    │       │   │   ├── message-persistence.mdx
    │       │   │   └── meta.json
    │       │   ├── shared-state/
    │       │   │   ├── in-app-agent-read.mdx
    │       │   │   ├── in-app-agent-write.mdx
    │       │   │   ├── index.mdx
    │       │   │   ├── meta.json
    │       │   │   ├── predictive-state-updates.mdx
    │       │   │   └── state-inputs-outputs.mdx
    │       │   ├── troubleshooting/
    │       │   │   ├── common-issues.mdx
    │       │   │   └── migrate-from-v0.2-to-v0.3.mdx
    │       │   ├── tutorials/
    │       │   │   ├── meta.json
    │       │   │   ├── agent-native-app/
    │       │   │   │   ├── index.mdx
    │       │   │   │   ├── meta.json
    │       │   │   │   ├── next-steps.mdx
    │       │   │   │   ├── step-1-checkout-repo.mdx
    │       │   │   │   ├── step-2-start-the-agent.mdx
    │       │   │   │   ├── step-3-setup-copilotkit.mdx
    │       │   │   │   ├── step-4-agentic-chat-ui.mdx
    │       │   │   │   ├── step-5-human-in-the-loop.mdx
    │       │   │   │   ├── step-6-shared-state.mdx
    │       │   │   │   ├── step-7-generative-ui.mdx
    │       │   │   │   └── step-8-progressive-state-updates.mdx
    │       │   │   └── ai-travel-app/
    │       │   │       ├── index.mdx
    │       │   │       ├── meta.json
    │       │   │       ├── next-steps.mdx
    │       │   │       ├── step-1-checkout-repo.mdx
    │       │   │       ├── step-2-langgraph-agent.mdx
    │       │   │       ├── step-3-setup-copilotkit.mdx
    │       │   │       ├── step-4-integrate-the-agent.mdx
    │       │   │       ├── step-5-stream-progress.mdx
    │       │   │       └── step-6-human-in-the-loop.mdx
    │       │   └── videos/
    │       │       ├── meta.json
    │       │       ├── perplexity-clone.mdx
    │       │       └── research-canvas.mdx
    │       ├── crewai-crews/
    │       │   ├── agentic-chat-ui.mdx
    │       │   ├── frontend-actions.mdx
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── multi-agent-flows.mdx
    │       │   ├── quickstart.mdx
    │       │   ├── advanced/
    │       │   │   ├── exit-agent.mdx
    │       │   │   └── meta.json
    │       │   ├── concepts/
    │       │   │   ├── agentic-copilots.mdx
    │       │   │   ├── copilotkit-stream.mdx
    │       │   │   ├── crewai.mdx
    │       │   │   ├── message-management.mdx
    │       │   │   ├── meta.json
    │       │   │   ├── state.mdx
    │       │   │   └── terminology.mdx
    │       │   ├── generative-ui/
    │       │   │   ├── agentic.mdx
    │       │   │   ├── index.mdx
    │       │   │   └── tool-based.mdx
    │       │   ├── human-in-the-loop/
    │       │   │   ├── flow.mdx
    │       │   │   ├── index.mdx
    │       │   │   └── meta.json
    │       │   └── shared-state/
    │       │       ├── in-app-agent-read.mdx
    │       │       ├── in-app-agent-write.mdx
    │       │       ├── index.mdx
    │       │       └── meta.json
    │       ├── crewai-flows/
    │       │   ├── agentic-chat-ui.mdx
    │       │   ├── frontend-actions.mdx
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── multi-agent-flows.mdx
    │       │   ├── quickstart.mdx
    │       │   ├── advanced/
    │       │   │   ├── disabling-state-streaming.mdx
    │       │   │   ├── emit-messages.mdx
    │       │   │   ├── exit-agent.mdx
    │       │   │   └── meta.json
    │       │   ├── concepts/
    │       │   │   ├── agentic-copilots.mdx
    │       │   │   ├── copilotkit-stream.mdx
    │       │   │   ├── crewai.mdx
    │       │   │   ├── message-management.mdx
    │       │   │   ├── meta.json
    │       │   │   ├── state.mdx
    │       │   │   └── terminology.mdx
    │       │   ├── generative-ui/
    │       │   │   ├── agentic.mdx
    │       │   │   ├── index.mdx
    │       │   │   └── tool-based.mdx
    │       │   ├── human-in-the-loop/
    │       │   │   ├── flow.mdx
    │       │   │   ├── index.mdx
    │       │   │   └── meta.json
    │       │   ├── persistence/
    │       │   │   ├── loading-agent-state.mdx
    │       │   │   ├── loading-message-history.mdx
    │       │   │   ├── message-persistence.mdx
    │       │   │   └── meta.json
    │       │   ├── shared-state/
    │       │   │   ├── in-app-agent-read.mdx
    │       │   │   ├── in-app-agent-write.mdx
    │       │   │   ├── index.mdx
    │       │   │   ├── meta.json
    │       │   │   └── predictive-state-updates.mdx
    │       │   └── troubleshooting/
    │       │       ├── common-issues.mdx
    │       │       └── migrate-from-v0.2-to-v0.3.mdx
    │       ├── mastra/
    │       │   ├── agentic-chat-ui.mdx
    │       │   ├── frontend-actions.mdx
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── multi-agent-flows.mdx
    │       │   ├── quickstart.mdx
    │       │   ├── concepts/
    │       │   │   ├── agentic-copilots.mdx
    │       │   │   ├── mastra.mdx
    │       │   │   ├── meta.json
    │       │   │   └── terminology.mdx
    │       │   ├── generative-ui/
    │       │   │   ├── index.mdx
    │       │   │   └── tool-based.mdx
    │       │   └── human-in-the-loop/
    │       │       ├── index.mdx
    │       │       ├── meta.json
    │       │       └── tool-based.mdx
    │       ├── reference/
    │       │   ├── index.mdx
    │       │   ├── meta.json
    │       │   ├── classes/
    │       │   │   ├── CopilotRuntime.mdx
    │       │   │   ├── CopilotTask.mdx
    │       │   │   ├── meta.json
    │       │   │   └── llm-adapters/
    │       │   │       ├── AnthropicAdapter.mdx
    │       │   │       ├── GoogleGenerativeAIAdapter.mdx
    │       │   │       ├── GroqAdapter.mdx
    │       │   │       ├── LangChainAdapter.mdx
    │       │   │       ├── meta.json
    │       │   │       ├── OpenAIAdapter.mdx
    │       │   │       └── OpenAIAssistantAdapter.mdx
    │       │   ├── components/
    │       │   │   ├── CopilotKit.mdx
    │       │   │   ├── CopilotTextarea.mdx
    │       │   │   ├── meta.json
    │       │   │   └── chat/
    │       │   │       ├── CopilotChat.mdx
    │       │   │       ├── CopilotPopup.mdx
    │       │   │       ├── CopilotSidebar.mdx
    │       │   │       ├── index.mdx
    │       │   │       └── meta.json
    │       │   ├── hooks/
    │       │   │   ├── meta.json
    │       │   │   ├── useCoAgent.mdx
    │       │   │   ├── useCoAgentStateRender.mdx
    │       │   │   ├── useCopilotAction.mdx
    │       │   │   ├── useCopilotAdditionalInstructions.mdx
    │       │   │   ├── useCopilotChat.mdx
    │       │   │   ├── useCopilotChatSuggestions.mdx
    │       │   │   ├── useCopilotReadable.mdx
    │       │   │   └── useLangGraphInterrupt.mdx
    │       │   └── sdk/
    │       │       ├── meta.json
    │       │       ├── js/
    │       │       │   ├── LangGraph.mdx
    │       │       │   └── meta.json
    │       │       └── python/
    │       │           ├── CrewAI.mdx
    │       │           ├── CrewAIAgent.mdx
    │       │           ├── LangGraph.mdx
    │       │           ├── LangGraphAgent.mdx
    │       │           ├── meta.json
    │       │           └── RemoteEndpoints.mdx
    │       └── .coagents-template/
    │           ├── agentic-chat-ui.mdx
    │           ├── frontend-actions.mdx
    │           ├── index.mdx
    │           ├── meta.json
    │           ├── multi-agent-flows.mdx
    │           ├── advanced/
    │           │   ├── disabling-state-streaming.mdx
    │           │   ├── emit-messages.mdx
    │           │   ├── exit-agent.mdx
    │           │   └── meta.json
    │           ├── concepts/
    │           │   ├── agentic-copilots.mdx
    │           │   ├── copilotkit-stream.mdx
    │           │   ├── message-management.mdx
    │           │   ├── meta.json
    │           │   ├── state.mdx
    │           │   ├── terminology.mdx
    │           │   └── your-framework.mdx
    │           ├── generative-ui/
    │           │   ├── agentic.mdx
    │           │   ├── index.mdx
    │           │   └── tool-based.mdx
    │           ├── human-in-the-loop/
    │           │   ├── flow.mdx
    │           │   ├── index.mdx
    │           │   └── meta.json
    │           ├── persistence/
    │           │   ├── loading-agent-state.mdx
    │           │   ├── loading-message-history.mdx
    │           │   ├── message-persistence.mdx
    │           │   └── meta.json
    │           ├── quickstart/
    │           │   ├── meta.json
    │           │   └── your-framework.mdx
    │           └── shared-state/
    │               ├── in-app-agent-read.mdx
    │               ├── in-app-agent-write.mdx
    │               ├── index.mdx
    │               ├── meta.json
    │               └── predictive-state-updates.mdx
    ├── lib/
    │   ├── utils.ts
    │   ├── hooks/
    │   │   ├── use-google-analytics.tsx
    │   │   ├── use-rb2b.tsx
    │   │   └── use-tailored-content.tsx
    │   ├── icons/
    │   │   ├── custom-icons.tsx
    │   │   └── index.tsx
    │   └── providers/
    │       ├── posthog-provider.tsx
    │       ├── providers-wrapper.tsx
    │       └── scarf-pixel.tsx
    ├── public/
    │   ├── llms-full.txt
    │   ├── llms.txt
    │   ├── robots.txt
    │   ├── icons/
    │   └── images/
    │       ├── logo-light.webp
    │       ├── coagents/
    │       │   ├── ag2/
    │       │   ├── crew-ai/
    │       │   │   └── flows/
    │       │   └── tutorials/
    │       │       ├── ai-travel-app/
    │       │       └── research-ana/
    │       ├── concepts/
    │       │   ├── customize-look-and-feel/
    │       │   └── generative-ui/
    │       ├── contributing/
    │       ├── cookbook/
    │       │   └── state-machine/
    │       ├── copilot-cloud/
    │       ├── examples/
    │       ├── use-copilot-action/
    │       └── use-copilot-chat-suggestions/
    ├── snippets/
    │   ├── component-examples.mdx
    │   ├── copilot-cloud-configure-copilotkit-provider.mdx
    │   ├── copilot-cloud-configure-remote-endpoint-langgraph.mdx
    │   ├── copilot-cloud-configure-remote-endpoint.mdx
    │   ├── copilot-ui.mdx
    │   ├── crew-quickstart.mdx
    │   ├── find-your-copilot-runtime.mdx
    │   ├── headless-ui.mdx
    │   ├── install-python-sdk-crew.mdx
    │   ├── install-python-sdk.mdx
    │   ├── install-sdk.mdx
    │   ├── langgraph-platform-deployment-tabs.mdx
    │   ├── llm-adapters.mdx
    │   ├── self-hosting-copilot-runtime-configure-copilotkit-provider.mdx
    │   ├── self-hosting-copilot-runtime-create-endpoint.mdx
    │   ├── self-hosting-copilot-runtime-langgraph-endpoint.mdx
    │   ├── self-hosting-copilot-runtime-starter.mdx
    │   ├── self-hosting-remote-endpoints.mdx
    │   ├── use-client-callout.mdx
    │   ├── cloud/
    │   │   └── cloud-copilotkit-provider.mdx
    │   └── coagents/
    │       ├── cloud-configure-copilotkit-provider.mdx
    │       ├── run-and-connect-agent.mdx
    │       └── self-host-configure-copilotkit-provider.mdx
    └── .husky/
        └── pre-commit

================================================
FILE: docs/README.md
================================================
# fumadocs-test

This is a Next.js application generated with
[Create Fumadocs](https://github.com/fuma-nama/fumadocs).

Run development server:

```bash
npm run dev
# or
pnpm dev
# or
yarn dev
```

Open http://localhost:3000 with your browser to see the result.

## Learn More

To learn more about Next.js and Fumadocs, take a look at the following
resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js
  features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.
- [Fumadocs](https://fumadocs.vercel.app) - learn about Fumadocs



================================================
FILE: docs/components.json
================================================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.js",
    "css": "app/global.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  }
}


================================================
FILE: docs/next-env.d.ts
================================================
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/app/building-your-application/configuring/typescript for more information.



================================================
FILE: docs/next.config.mjs
================================================
import { createMDX } from "fumadocs-mdx/next";

const withMDX = createMDX();

/** @type {import('next').NextConfig} */
const config = {
  reactStrictMode: true,
  env: {
    RB2B_ID: process.env.RB2B_ID,
    POSTHOG_KEY: process.env.POSTHOG_KEY,
    POSTHOG_HOST: process.env.POSTHOG_HOST,
    SCARF_PIXEL_ID: process.env.SCARF_PIXEL_ID,
  },

  images: {
    domains: [
      "github-production-user-asset-6210df.s3.amazonaws.com",
      "fonts.gstatic.com",
      "docs.copilotkit.ai",
    ],
    remotePatterns: [
      {
        protocol: "https",
        hostname: "**",
      },
    ],
  },

  skipTrailingSlashRedirect: true,
  skipMiddlewareUrlNormalize: true,

  optimizeFonts: false,

  experimental: {
    turbo: true,
  },

  async redirects() {
    return [
      {
        source: "/coagents/tutorials/ai-travel-app/overview",
        destination: "/coagents/tutorials/ai-travel-app",
        permanent: true,
      },
      {
        source: "/coagents/chat-ui/hitl/json-hitl",
        destination: "/coagents/chat-ui/hitl",
        permanent: true,
      },
      {
        source: "/coagents/react-ui/frontend-functions",
        destination: "/coagents/react-ui/hitl",
        permanent: true,
      },
      {
        source: "/coagents/chat-ui/render-agent-state",
        destination: "/coagents/generative-ui/agentic",
        permanent: true,
      },
      {
        source: "/coagents/chat-ui/hitl",
        destination: "/coagents/human-in-the-loop/node-flow",
        permanent: true,
      },
      {
        source: "/coagents/chat-ui/hitl/interrupt-flow",
        destination: "/coagents/human-in-the-loop/interrupt-flow",
        permanent: true,
      },
      {
        source: "/coagents/chat-ui/loading-message-history",
        destination: "/coagents/persistence/loading-message-history",
        permanent: true,
      },
      {
        source: "/coagents/react-ui/in-app-agent-read",
        destination: "/coagents/shared-state/in-app-agent-read",
        permanent: true,
      },
      {
        source: "/coagents/react-ui/in-app-agent-write",
        destination: "/coagents/shared-state/in-app-agent-write",
        permanent: true,
      },
      {
        source: "/coagents/react-ui/hitl",
        destination: "/coagents/human-in-the-loop/node-flow",
        permanent: true,
      },
      {
        source: "/coagents/advanced/router-mode-agent-lock",
        destination: "/coagents/multi-agent-flows",
        permanent: true,
      },
      {
        source: "/coagents/advanced/intermediate-state-streaming",
        destination: "/coagents/shared-state/predictive-state-updates",
        permanent: true,
      },
      {
        source: "/coagents/advanced/manually-emitting-messages",
        destination: "/coagents/advanced/emit-messages",
        permanent: true,
      },
      {
        source: "/coagents/advanced/state-streaming",
        destination: "/coagents/shared-state",
        permanent: true,
      },
      {
        source: "/coagents/advanced/copilotkit-state",
        destination: "/coagents/frontend-actions",
        permanent: true,
      },
      {
        source: "/coagents/advanced/message-persistence",
        destination: "/coagents/persistence/message-persistence",
        permanent: true,
      },
      {
        source: "/coagents/advanced/loading-message-history",
        destination: "/coagents/persistence/loading-message-history",
        permanent: true,
      },
      {
        source: "/coagents/advanced/loading-agent-state",
        destination: "/coagents/persistence/loading-agent-state",
        permanent: true,
      },
      {
        source: "/coagents/concepts/state",
        destination: "/coagents/shared-state",
        permanent: true,
      },
      {
        source: "/coagents/concepts/human-in-the-loop",
        destination: "/coagents/human-in-the-loop",
        permanent: true,
      },
      {
        source: "/coagents/concepts/multi-agent-flows",
        destination: "/coagents/multi-agent-flows",
        permanent: true,
      },
      {
        source: "/coagents/quickstart/langgraph",
        destination: "/coagents/quickstart",
        permanent: true,
      },
      {
        source: "/crewai-crews/quickstart/crewai",
        destination: "/crewai-crews/quickstart",
        permanent: true,
      },
      {
        source: "/crewai-flows/quickstart/crewai",
        destination: "/crewai-flows/quickstart",
        permanent: true,
      },
      {
        source: "/mastra/quickstart/mastra",
        destination: "/mastra/quickstart",
        permanent: true,
      },
      {
        source: "/ag2/quickstart/ag2",
        destination: "/ag2/quickstart",
        permanent: true,
      },
    ];
  },
};

export default withMDX(config);



================================================
FILE: docs/package.json
================================================
{
  "name": "docs",
  "version": "0.0.0",
  "private": true,
  "scripts": {
    "build": "next build",
    "dev": "next dev",
    "start": "next start",
    "postinstall": "fumadocs-mdx",
    "prepare": "husky"
  },
  "dependencies": {
    "@clerk/clerk-react": "^5.18.2",
    "@clerk/nextjs": "^6.7.1",
    "@copilotkit/react-core": "1.8.2",
    "@copilotkit/react-ui": "1.8.2",
    "@icons-pack/react-simple-icons": "^11.2.0",
    "@radix-ui/react-dialog": "^1.1.2",
    "@radix-ui/react-icons": "^1.3.0",
    "@radix-ui/react-scroll-area": "^1.2.2",
    "@radix-ui/react-select": "^2.1.2",
    "@radix-ui/react-slot": "^1.1.0",
    "@radix-ui/react-tabs": "^1.1.2",
    "@shikijs/transformers": "^1.20.0",
    "@theguild/remark-mermaid": "^0.1.3",
    "@theguild/remark-npm2yarn": "^0.3.2",
    "class-variance-authority": "^0.7.0",
    "classnames": "^2.5.1",
    "clsx": "^2.1.1",
    "fumadocs-core": "13.4.10",
    "fumadocs-docgen": "^1.2.0",
    "fumadocs-mdx": "10.0.2",
    "fumadocs-typescript": "^2.1.0",
    "fumadocs-ui": "13.4.10",
    "hast-util-to-jsx-runtime": "^2.3.0",
    "lucide-react": "^0.446.0",
    "mdast": "^3.0.0",
    "next": "^14.2.8",
    "next-themes": "^0.3.0",
    "npm-to-yarn": "^3.0.0",
    "posthog-js": "^1.175.0",
    "react": "^18.3.1",
    "react-dom": "^18.3.1",
    "react-ga4": "^2.1.0",
    "react-icons": "^5.3.0",
    "react-youtube": "^10.1.0",
    "rehype-highlight-code-lines": "^1.0.4",
    "shiki": "^1.20.0",
    "swr": "^2.2.5",
    "tailwind-merge": "^2.5.2",
    "tailwindcss-animate": "^1.0.7",
    "usehooks-ts": "^3.1.0"
  },
  "devDependencies": {
    "@types/mdx": "^2.0.13",
    "@types/node": "22.5.4",
    "@types/react": "^18.3.5",
    "@types/react-dom": "^18.3.0",
    "autoprefixer": "^10.4.20",
    "husky": "^9.1.6",
    "postcss": "^8.4.45",
    "tailwindcss": "^3.4.10",
    "typescript": "^5.5.4"
  }
}



================================================
FILE: docs/pnpm-lock.yaml
================================================
lockfileVersion: '9.0'

settings:
  autoInstallPeers: true
  excludeLinksFromLockfile: false

importers:

  .:
    dependencies:
      '@clerk/clerk-react':
        specifier: ^5.18.2
        version: 5.18.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@clerk/nextjs':
        specifier: ^6.7.1
        version: 6.7.1(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@copilotkit/react-core':
        specifier: 1.8.2
        version: 1.8.2(@types/react@18.3.9)(graphql@16.10.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@copilotkit/react-ui':
        specifier: 1.8.2
        version: 1.8.2(@types/react@18.3.9)(graphql@16.10.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@icons-pack/react-simple-icons':
        specifier: ^11.2.0
        version: 11.2.0(react@18.3.1)
      '@radix-ui/react-dialog':
        specifier: ^1.1.2
        version: 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-icons':
        specifier: ^1.3.0
        version: 1.3.0(react@18.3.1)
      '@radix-ui/react-scroll-area':
        specifier: ^1.2.2
        version: 1.2.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-select':
        specifier: ^2.1.2
        version: 2.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot':
        specifier: ^1.1.0
        version: 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-tabs':
        specifier: ^1.1.2
        version: 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@shikijs/transformers':
        specifier: ^1.20.0
        version: 1.20.0
      '@theguild/remark-mermaid':
        specifier: ^0.1.3
        version: 0.1.3(react@18.3.1)
      '@theguild/remark-npm2yarn':
        specifier: ^0.3.2
        version: 0.3.2
      class-variance-authority:
        specifier: ^0.7.0
        version: 0.7.0
      classnames:
        specifier: ^2.5.1
        version: 2.5.1
      clsx:
        specifier: ^2.1.1
        version: 2.1.1
      fumadocs-core:
        specifier: 13.4.10
        version: 13.4.10(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      fumadocs-docgen:
        specifier: ^1.2.0
        version: 1.2.0(typescript@5.6.2)
      fumadocs-mdx:
        specifier: 10.0.2
        version: 10.0.2(fumadocs-core@13.4.10(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))
      fumadocs-typescript:
        specifier: ^2.1.0
        version: 2.1.0(typescript@5.6.2)
      fumadocs-ui:
        specifier: 13.4.10
        version: 13.4.10(@types/react-dom@18.3.0)(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(tailwindcss@3.4.13)
      hast-util-to-jsx-runtime:
        specifier: ^2.3.0
        version: 2.3.0
      lucide-react:
        specifier: ^0.446.0
        version: 0.446.0(react@18.3.1)
      mdast:
        specifier: ^3.0.0
        version: 3.0.0
      next:
        specifier: ^14.2.8
        version: 14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      next-themes:
        specifier: ^0.3.0
        version: 0.3.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      npm-to-yarn:
        specifier: ^3.0.0
        version: 3.0.0
      posthog-js:
        specifier: ^1.175.0
        version: 1.175.0
      react:
        specifier: ^18.3.1
        version: 18.3.1
      react-dom:
        specifier: ^18.3.1
        version: 18.3.1(react@18.3.1)
      react-ga4:
        specifier: ^2.1.0
        version: 2.1.0
      react-icons:
        specifier: ^5.3.0
        version: 5.3.0(react@18.3.1)
      react-youtube:
        specifier: ^10.1.0
        version: 10.1.0(react@18.3.1)
      rehype-highlight-code-lines:
        specifier: ^1.0.4
        version: 1.0.4
      shiki:
        specifier: ^1.20.0
        version: 1.20.0
      swr:
        specifier: ^2.2.5
        version: 2.2.5(react@18.3.1)
      tailwind-merge:
        specifier: ^2.5.2
        version: 2.5.2
      tailwindcss-animate:
        specifier: ^1.0.7
        version: 1.0.7(tailwindcss@3.4.13)
      usehooks-ts:
        specifier: ^3.1.0
        version: 3.1.0(react@18.3.1)
    devDependencies:
      '@types/mdx':
        specifier: ^2.0.13
        version: 2.0.13
      '@types/node':
        specifier: 22.5.4
        version: 22.5.4
      '@types/react':
        specifier: ^18.3.5
        version: 18.3.9
      '@types/react-dom':
        specifier: ^18.3.0
        version: 18.3.0
      autoprefixer:
        specifier: ^10.4.20
        version: 10.4.20(postcss@8.4.47)
      husky:
        specifier: ^9.1.6
        version: 9.1.6
      postcss:
        specifier: ^8.4.45
        version: 8.4.47
      tailwindcss:
        specifier: ^3.4.10
        version: 3.4.13
      typescript:
        specifier: ^5.5.4
        version: 5.6.2

packages:

  '@0no-co/graphql.web@1.1.2':
    resolution: {integrity: sha512-N2NGsU5FLBhT8NZ+3l2YrzZSHITjNXNuDhC4iDiikv0IujaJ0Xc6xIxQZ/Ek3Cb+rgPjnLHYyJm11tInuJn+cw==}
    peerDependencies:
      graphql: ^14.0.0 || ^15.0.0 || ^16.0.0
    peerDependenciesMeta:
      graphql:
        optional: true

  '@alloc/quick-lru@5.2.0':
    resolution: {integrity: sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==}
    engines: {node: '>=10'}

  '@antfu/install-pkg@0.4.1':
    resolution: {integrity: sha512-T7yB5QNG29afhWVkVq7XeIMBa5U/vs9mX69YqayXypPRmYzUmzwnYltplHmPtZ4HPCn+sQKeXW8I47wCbuBOjw==}

  '@antfu/utils@0.7.10':
    resolution: {integrity: sha512-+562v9k4aI80m1+VuMHehNJWLOFjBnXn3tdOitzD0il5b7smkSBal4+a3oKiQTbrwMmN/TBUMDvbdoWDehgOww==}

  '@babel/runtime@7.25.6':
    resolution: {integrity: sha512-VBj9MYyDb9tuLq7yzqjgzt6Q+IBQLrGZfdjOekyEirZPHxXWoTSGUTMrpsfi58Up73d13NfYLv8HT9vmznjzhQ==}
    engines: {node: '>=6.9.0'}

  '@braintree/sanitize-url@7.1.0':
    resolution: {integrity: sha512-o+UlMLt49RvtCASlOMW0AkHnabN9wR9rwCCherxO0yG4Npy34GkvrAqdXQvrhNs+jh+gkK8gB8Lf05qL/O7KWg==}

  '@chevrotain/cst-dts-gen@11.0.3':
    resolution: {integrity: sha512-BvIKpRLeS/8UbfxXxgC33xOumsacaeCKAjAeLyOn7Pcp95HiRbrpl14S+9vaZLolnbssPIUuiUd8IvgkRyt6NQ==}

  '@chevrotain/gast@11.0.3':
    resolution: {integrity: sha512-+qNfcoNk70PyS/uxmj3li5NiECO+2YKZZQMbmjTqRI3Qchu8Hig/Q9vgkHpI3alNjr7M+a2St5pw5w5F6NL5/Q==}

  '@chevrotain/regexp-to-ast@11.0.3':
    resolution: {integrity: sha512-1fMHaBZxLFvWI067AVbGJav1eRY7N8DDvYCTwGBiE/ytKBgP8azTdgyrKyWZ9Mfh09eHWb5PgTSO8wi7U824RA==}

  '@chevrotain/types@11.0.3':
    resolution: {integrity: sha512-gsiM3G8b58kZC2HaWR50gu6Y1440cHiJ+i3JUvcp/35JchYejb2+5MVeJK0iKThYpAa/P2PYFV4hoi44HD+aHQ==}

  '@chevrotain/utils@11.0.3':
    resolution: {integrity: sha512-YslZMgtJUyuMbZ+aKvfF3x1f5liK4mWNxghFRv7jqRR9C3R3fAOGTTKvxXDa2Y1s9zSbcpuO0cAxDYsc9SrXoQ==}

  '@clerk/backend@1.19.2':
    resolution: {integrity: sha512-oajOw3vzvU0vLBcbdk4fuRApGz9eRxrRlNlUkMsX+ErxsWq6SXtsa/ZZrWdCgidkkDIAO3oAOrxRgSoxW0kK6g==}
    engines: {node: '>=18.17.0'}

  '@clerk/clerk-react@5.18.2':
    resolution: {integrity: sha512-BMn1BsludrpvM9CgAl5pAeTgtIrUCuKmI7LDwZJKW5XNFoy6Fd9hKXJ+7YNWglfkboTu3kL569H1de8lA4iUvA==}
    engines: {node: '>=18.17.0'}
    peerDependencies:
      react: ^18 || ^19.0.0-0
      react-dom: ^18 || ^19.0.0-0

  '@clerk/nextjs@6.7.1':
    resolution: {integrity: sha512-SiOrau0GRqAd+drImfMtJuKFTyLSXhXf7UYG1E48giSoyFnu7EhBIass6ovJ9C/aRYUwqn2QCKY6xAxrwjAANQ==}
    engines: {node: '>=18.17.0'}
    peerDependencies:
      next: ^13.5.4 || ^14.0.3 || ^15.0.0
      react: ^18 || ^19.0.0-0
      react-dom: ^18 || ^19.0.0-0

  '@clerk/shared@2.19.0':
    resolution: {integrity: sha512-CKe526lx3KdI/J+gDVUiB5Mx9/7fRqbUeLiXG3kTy4QeULzbroCvmkQdVjHJhWAq2+Nolwh6eCDjN9IZ6Tshfg==}
    engines: {node: '>=18.17.0'}
    peerDependencies:
      react: ^18 || ^19.0.0-0
      react-dom: ^18 || ^19.0.0-0
    peerDependenciesMeta:
      react:
        optional: true
      react-dom:
        optional: true

  '@clerk/types@4.38.0':
    resolution: {integrity: sha512-806lLBal6MVChTVWnzCWZAQdZ2miLJHkVJ+JUX2XX8D1DDPonw2y5tVk9BGWZfKq/rtUP2Jg6HdZOnA5ZbU0Ow==}
    engines: {node: '>=18.17.0'}

  '@copilotkit/react-core@1.8.2':
    resolution: {integrity: sha512-lQj6PovM7sTYbDPzo9hyzBEB7VCFxWz0NFFAFzzzBMFMh8gPBRiOamsOv/jZTDV3k1z9uQgBxfME6AYe+yVeNw==}
    peerDependencies:
      react: ^18 || ^19 || ^19.0.0-rc
      react-dom: ^18 || ^19 || ^19.0.0-rc

  '@copilotkit/react-ui@1.8.2':
    resolution: {integrity: sha512-1KMy7y61ApgVyDZy9TpUR764moKqmP8tv/7TLAA3M7MsIJF8EC5qv304U2d+0sIEqqFiNF2z6qjTBbNp/20IhA==}
    peerDependencies:
      react: ^18 || ^19 || ^19.0.0-rc

  '@copilotkit/runtime-client-gql@1.8.2':
    resolution: {integrity: sha512-myREgwz86UkluSqkZ8f2IL2/+/BNi0v0Utp5WLkpReXaTCx+ryFmcytyZCS9hclC2RnMQvSW89kaO/7o7+XeEw==}
    peerDependencies:
      react: ^18 || ^19 || ^19.0.0-rc

  '@copilotkit/shared@1.8.2':
    resolution: {integrity: sha512-1Ak3RX+jiC57gaBfVC4Db1D+5DURkPFEzkauVRcMPWMkJUidaMLvbzuI2lasxBrXhM5WQ4gtuDgQ5QYTsLFD4w==}

  '@esbuild/aix-ppc64@0.23.1':
    resolution: {integrity: sha512-6VhYk1diRqrhBAqpJEdjASR/+WVRtfjpqKuNw11cLiaWpAT/Uu+nokB+UJnevzy/P9C/ty6AOe0dwueMrGh/iQ==}
    engines: {node: '>=18'}
    cpu: [ppc64]
    os: [aix]

  '@esbuild/android-arm64@0.23.1':
    resolution: {integrity: sha512-xw50ipykXcLstLeWH7WRdQuysJqejuAGPd30vd1i5zSyKK3WE+ijzHmLKxdiCMtH1pHz78rOg0BKSYOSB/2Khw==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [android]

  '@esbuild/android-arm@0.23.1':
    resolution: {integrity: sha512-uz6/tEy2IFm9RYOyvKl88zdzZfwEfKZmnX9Cj1BHjeSGNuGLuMD1kR8y5bteYmwqKm1tj8m4cb/aKEorr6fHWQ==}
    engines: {node: '>=18'}
    cpu: [arm]
    os: [android]

  '@esbuild/android-x64@0.23.1':
    resolution: {integrity: sha512-nlN9B69St9BwUoB+jkyU090bru8L0NA3yFvAd7k8dNsVH8bi9a8cUAUSEcEEgTp2z3dbEDGJGfP6VUnkQnlReg==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [android]

  '@esbuild/darwin-arm64@0.23.1':
    resolution: {integrity: sha512-YsS2e3Wtgnw7Wq53XXBLcV6JhRsEq8hkfg91ESVadIrzr9wO6jJDMZnCQbHm1Guc5t/CdDiFSSfWP58FNuvT3Q==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [darwin]

  '@esbuild/darwin-x64@0.23.1':
    resolution: {integrity: sha512-aClqdgTDVPSEGgoCS8QDG37Gu8yc9lTHNAQlsztQ6ENetKEO//b8y31MMu2ZaPbn4kVsIABzVLXYLhCGekGDqw==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [darwin]

  '@esbuild/freebsd-arm64@0.23.1':
    resolution: {integrity: sha512-h1k6yS8/pN/NHlMl5+v4XPfikhJulk4G+tKGFIOwURBSFzE8bixw1ebjluLOjfwtLqY0kewfjLSrO6tN2MgIhA==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [freebsd]

  '@esbuild/freebsd-x64@0.23.1':
    resolution: {integrity: sha512-lK1eJeyk1ZX8UklqFd/3A60UuZ/6UVfGT2LuGo3Wp4/z7eRTRYY+0xOu2kpClP+vMTi9wKOfXi2vjUpO1Ro76g==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [freebsd]

  '@esbuild/linux-arm64@0.23.1':
    resolution: {integrity: sha512-/93bf2yxencYDnItMYV/v116zff6UyTjo4EtEQjUBeGiVpMmffDNUyD9UN2zV+V3LRV3/on4xdZ26NKzn6754g==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [linux]

  '@esbuild/linux-arm@0.23.1':
    resolution: {integrity: sha512-CXXkzgn+dXAPs3WBwE+Kvnrf4WECwBdfjfeYHpMeVxWE0EceB6vhWGShs6wi0IYEqMSIzdOF1XjQ/Mkm5d7ZdQ==}
    engines: {node: '>=18'}
    cpu: [arm]
    os: [linux]

  '@esbuild/linux-ia32@0.23.1':
    resolution: {integrity: sha512-VTN4EuOHwXEkXzX5nTvVY4s7E/Krz7COC8xkftbbKRYAl96vPiUssGkeMELQMOnLOJ8k3BY1+ZY52tttZnHcXQ==}
    engines: {node: '>=18'}
    cpu: [ia32]
    os: [linux]

  '@esbuild/linux-loong64@0.23.1':
    resolution: {integrity: sha512-Vx09LzEoBa5zDnieH8LSMRToj7ir/Jeq0Gu6qJ/1GcBq9GkfoEAoXvLiW1U9J1qE/Y/Oyaq33w5p2ZWrNNHNEw==}
    engines: {node: '>=18'}
    cpu: [loong64]
    os: [linux]

  '@esbuild/linux-mips64el@0.23.1':
    resolution: {integrity: sha512-nrFzzMQ7W4WRLNUOU5dlWAqa6yVeI0P78WKGUo7lg2HShq/yx+UYkeNSE0SSfSure0SqgnsxPvmAUu/vu0E+3Q==}
    engines: {node: '>=18'}
    cpu: [mips64el]
    os: [linux]

  '@esbuild/linux-ppc64@0.23.1':
    resolution: {integrity: sha512-dKN8fgVqd0vUIjxuJI6P/9SSSe/mB9rvA98CSH2sJnlZ/OCZWO1DJvxj8jvKTfYUdGfcq2dDxoKaC6bHuTlgcw==}
    engines: {node: '>=18'}
    cpu: [ppc64]
    os: [linux]

  '@esbuild/linux-riscv64@0.23.1':
    resolution: {integrity: sha512-5AV4Pzp80fhHL83JM6LoA6pTQVWgB1HovMBsLQ9OZWLDqVY8MVobBXNSmAJi//Csh6tcY7e7Lny2Hg1tElMjIA==}
    engines: {node: '>=18'}
    cpu: [riscv64]
    os: [linux]

  '@esbuild/linux-s390x@0.23.1':
    resolution: {integrity: sha512-9ygs73tuFCe6f6m/Tb+9LtYxWR4c9yg7zjt2cYkjDbDpV/xVn+68cQxMXCjUpYwEkze2RcU/rMnfIXNRFmSoDw==}
    engines: {node: '>=18'}
    cpu: [s390x]
    os: [linux]

  '@esbuild/linux-x64@0.23.1':
    resolution: {integrity: sha512-EV6+ovTsEXCPAp58g2dD68LxoP/wK5pRvgy0J/HxPGB009omFPv3Yet0HiaqvrIrgPTBuC6wCH1LTOY91EO5hQ==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [linux]

  '@esbuild/netbsd-x64@0.23.1':
    resolution: {integrity: sha512-aevEkCNu7KlPRpYLjwmdcuNz6bDFiE7Z8XC4CPqExjTvrHugh28QzUXVOZtiYghciKUacNktqxdpymplil1beA==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [netbsd]

  '@esbuild/openbsd-arm64@0.23.1':
    resolution: {integrity: sha512-3x37szhLexNA4bXhLrCC/LImN/YtWis6WXr1VESlfVtVeoFJBRINPJ3f0a/6LV8zpikqoUg4hyXw0sFBt5Cr+Q==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [openbsd]

  '@esbuild/openbsd-x64@0.23.1':
    resolution: {integrity: sha512-aY2gMmKmPhxfU+0EdnN+XNtGbjfQgwZj43k8G3fyrDM/UdZww6xrWxmDkuz2eCZchqVeABjV5BpildOrUbBTqA==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [openbsd]

  '@esbuild/sunos-x64@0.23.1':
    resolution: {integrity: sha512-RBRT2gqEl0IKQABT4XTj78tpk9v7ehp+mazn2HbUeZl1YMdaGAQqhapjGTCe7uw7y0frDi4gS0uHzhvpFuI1sA==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [sunos]

  '@esbuild/win32-arm64@0.23.1':
    resolution: {integrity: sha512-4O+gPR5rEBe2FpKOVyiJ7wNDPA8nGzDuJ6gN4okSA1gEOYZ67N8JPk58tkWtdtPeLz7lBnY6I5L3jdsr3S+A6A==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [win32]

  '@esbuild/win32-ia32@0.23.1':
    resolution: {integrity: sha512-BcaL0Vn6QwCwre3Y717nVHZbAa4UBEigzFm6VdsVdT/MbZ38xoj1X9HPkZhbmaBGUD1W8vxAfffbDe8bA6AKnQ==}
    engines: {node: '>=18'}
    cpu: [ia32]
    os: [win32]

  '@esbuild/win32-x64@0.23.1':
    resolution: {integrity: sha512-BHpFFeslkWrXWyUPnbKm+xYYVYruCinGcftSBaa8zoF9hZO4BcSCFUvHVTtzpIY6YzUnYtuEhZ+C9iEXjxnasg==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [win32]

  '@floating-ui/core@1.6.8':
    resolution: {integrity: sha512-7XJ9cPU+yI2QeLS+FCSlqNFZJq8arvswefkZrYI1yQBbftw6FyrZOxYSh+9S7z7TpeWlRt9zJ5IhM1WIL334jA==}

  '@floating-ui/dom@1.6.11':
    resolution: {integrity: sha512-qkMCxSR24v2vGkhYDo/UzxfJN3D4syqSjyuTFz6C7XcpU1pASPRieNI0Kj5VP3/503mOfYiGY891ugBX1GlABQ==}

  '@floating-ui/react-dom@2.1.2':
    resolution: {integrity: sha512-06okr5cgPzMNBy+Ycse2A6udMi4bqwW/zgBF/rwjcNqWkyr82Mcg8b0vjX8OJpZFy/FKjJmw6wV7t44kK6kW7A==}
    peerDependencies:
      react: '>=16.8.0'
      react-dom: '>=16.8.0'

  '@floating-ui/react@0.26.28':
    resolution: {integrity: sha512-yORQuuAtVpiRjpMhdc0wJj06b9JFjrYF4qp96j++v2NBpbi6SEGF7donUJ3TMieerQ6qVkAv1tgr7L4r5roTqw==}
    peerDependencies:
      react: '>=16.8.0'
      react-dom: '>=16.8.0'

  '@floating-ui/utils@0.2.8':
    resolution: {integrity: sha512-kym7SodPp8/wloecOpcmSnWJsK7M0E5Wg8UcFA+uO4B9s5d0ywXOEro/8HM9x0rW+TljRzul/14UYz3TleT3ig==}

  '@formatjs/intl-localematcher@0.5.4':
    resolution: {integrity: sha512-zTwEpWOzZ2CiKcB93BLngUX59hQkuZjT2+SAQEscSm52peDW/getsawMcWF1rGRpMCX6D7nSJA3CzJ8gn13N/g==}

  '@headlessui/react@2.2.0':
    resolution: {integrity: sha512-RzCEg+LXsuI7mHiSomsu/gBJSjpupm6A1qIZ5sWjd7JhARNlMiSA4kKfJpCKwU9tE+zMRterhhrP74PvfJrpXQ==}
    engines: {node: '>=10'}
    peerDependencies:
      react: ^18 || ^19 || ^19.0.0-rc
      react-dom: ^18 || ^19 || ^19.0.0-rc

  '@iconify/types@2.0.0':
    resolution: {integrity: sha512-+wluvCrRhXrhyOmRDJ3q8mux9JkKy5SJ/v8ol2tu4FVjyYvtEzkc/3pK15ET6RKg4b4w4BmTk1+gsCUhf21Ykg==}

  '@iconify/utils@2.1.33':
    resolution: {integrity: sha512-jP9h6v/g0BIZx0p7XGJJVtkVnydtbgTgt9mVNcGDYwaa7UhdHdI9dvoq+gKj9sijMSJKxUPEG2JyjsgXjxL7Kw==}

  '@icons-pack/react-simple-icons@11.2.0':
    resolution: {integrity: sha512-jCJ+1Fe0yiBQGYSfhx8QGU/9o27t8J4Hw3mxHEI9vohRltLSi5CaPzO2fCQcMNeTrAUAm4j+yaDuAutskiKRjA==}
    peerDependencies:
      react: ^16.13 || ^17 || ^18 || ^19

  '@isaacs/cliui@8.0.2':
    resolution: {integrity: sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==}
    engines: {node: '>=12'}

  '@jridgewell/gen-mapping@0.3.5':
    resolution: {integrity: sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg==}
    engines: {node: '>=6.0.0'}

  '@jridgewell/resolve-uri@3.1.2':
    resolution: {integrity: sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==}
    engines: {node: '>=6.0.0'}

  '@jridgewell/set-array@1.2.1':
    resolution: {integrity: sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==}
    engines: {node: '>=6.0.0'}

  '@jridgewell/sourcemap-codec@1.5.0':
    resolution: {integrity: sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==}

  '@jridgewell/trace-mapping@0.3.25':
    resolution: {integrity: sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==}

  '@lukeed/csprng@1.1.0':
    resolution: {integrity: sha512-Z7C/xXCiGWsg0KuKsHTKJxbWhpI3Vs5GwLfOean7MGyVFGqdRgBbAjOCh6u4bbjPc/8MJ2pZmK/0DLdCbivLDA==}
    engines: {node: '>=8'}

  '@lukeed/uuid@2.0.1':
    resolution: {integrity: sha512-qC72D4+CDdjGqJvkFMMEAtancHUQ7/d/tAiHf64z8MopFDmcrtbcJuerDtFceuAfQJ2pDSfCKCtbqoGBNnwg0w==}
    engines: {node: '>=8'}

  '@mdx-js/mdx@3.0.1':
    resolution: {integrity: sha512-eIQ4QTrOWyL3LWEe/bu6Taqzq2HQvHcyTMaOrI95P2/LmJE7AsfPfgJGuFLPVqBUE1BC1rik3VIhU+s9u72arA==}

  '@mermaid-js/parser@0.3.0':
    resolution: {integrity: sha512-HsvL6zgE5sUPGgkIDlmAWR1HTNHz2Iy11BAWPTa4Jjabkpguy4Ze2gzfLrg6pdRuBvFwgUYyxiaNqZwrEEXepA==}

  '@next/env@14.2.13':
    resolution: {integrity: sha512-s3lh6K8cbW1h5Nga7NNeXrbe0+2jIIYK9YaA9T7IufDWnZpozdFUp6Hf0d5rNWUKu4fEuSX2rCKlGjCrtylfDw==}

  '@next/swc-darwin-arm64@14.2.13':
    resolution: {integrity: sha512-IkAmQEa2Htq+wHACBxOsslt+jMoV3msvxCn0WFSfJSkv/scy+i/EukBKNad36grRxywaXUYJc9mxEGkeIs8Bzg==}
    engines: {node: '>= 10'}
    cpu: [arm64]
    os: [darwin]

  '@next/swc-darwin-x64@14.2.13':
    resolution: {integrity: sha512-Dv1RBGs2TTjkwEnFMVL5XIfJEavnLqqwYSD6LXgTPdEy/u6FlSrLBSSfe1pcfqhFEXRAgVL3Wpjibe5wXJzWog==}
    engines: {node: '>= 10'}
    cpu: [x64]
    os: [darwin]

  '@next/swc-linux-arm64-gnu@14.2.13':
    resolution: {integrity: sha512-yB1tYEFFqo4ZNWkwrJultbsw7NPAAxlPXURXioRl9SdW6aIefOLS+0TEsKrWBtbJ9moTDgU3HRILL6QBQnMevg==}
    engines: {node: '>= 10'}
    cpu: [arm64]
    os: [linux]

  '@next/swc-linux-arm64-musl@14.2.13':
    resolution: {integrity: sha512-v5jZ/FV/eHGoWhMKYrsAweQ7CWb8xsWGM/8m1mwwZQ/sutJjoFaXchwK4pX8NqwImILEvQmZWyb8pPTcP7htWg==}
    engines: {node: '>= 10'}
    cpu: [arm64]
    os: [linux]

  '@next/swc-linux-x64-gnu@14.2.13':
    resolution: {integrity: sha512-aVc7m4YL7ViiRv7SOXK3RplXzOEe/qQzRA5R2vpXboHABs3w8vtFslGTz+5tKiQzWUmTmBNVW0UQdhkKRORmGA==}
    engines: {node: '>= 10'}
    cpu: [x64]
    os: [linux]

  '@next/swc-linux-x64-musl@14.2.13':
    resolution: {integrity: sha512-4wWY7/OsSaJOOKvMsu1Teylku7vKyTuocvDLTZQq0TYv9OjiYYWt63PiE1nTuZnqQ4RPvME7Xai+9enoiN0Wrg==}
    engines: {node: '>= 10'}
    cpu: [x64]
    os: [linux]

  '@next/swc-win32-arm64-msvc@14.2.13':
    resolution: {integrity: sha512-uP1XkqCqV2NVH9+g2sC7qIw+w2tRbcMiXFEbMihkQ8B1+V6m28sshBwAB0SDmOe0u44ne1vFU66+gx/28RsBVQ==}
    engines: {node: '>= 10'}
    cpu: [arm64]
    os: [win32]

  '@next/swc-win32-ia32-msvc@14.2.13':
    resolution: {integrity: sha512-V26ezyjPqQpDBV4lcWIh8B/QICQ4v+M5Bo9ykLN+sqeKKBxJVDpEc6biDVyluTXTC40f5IqCU0ttth7Es2ZuMw==}
    engines: {node: '>= 10'}
    cpu: [ia32]
    os: [win32]

  '@next/swc-win32-x64-msvc@14.2.13':
    resolution: {integrity: sha512-WwzOEAFBGhlDHE5Z73mNU8CO8mqMNLqaG+AO9ETmzdCQlJhVtWZnOl2+rqgVQS+YHunjOWptdFmNfbpwcUuEsw==}
    engines: {node: '>= 10'}
    cpu: [x64]
    os: [win32]

  '@nodelib/fs.scandir@2.1.5':
    resolution: {integrity: sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==}
    engines: {node: '>= 8'}

  '@nodelib/fs.stat@2.0.5':
    resolution: {integrity: sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==}
    engines: {node: '>= 8'}

  '@nodelib/fs.walk@1.2.8':
    resolution: {integrity: sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==}
    engines: {node: '>= 8'}

  '@pkgjs/parseargs@0.11.0':
    resolution: {integrity: sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==}
    engines: {node: '>=14'}

  '@radix-ui/number@1.1.0':
    resolution: {integrity: sha512-V3gRzhVNU1ldS5XhAPTom1fOIo4ccrjjJgmE+LI2h/WaFpHmx0MQApT+KZHnx8abG6Avtfcz4WoEciMnpFT3HQ==}

  '@radix-ui/primitive@1.0.1':
    resolution: {integrity: sha512-yQ8oGX2GVsEYMWGxcovu1uGWPCxV5BFfeeYxqPmuAzUyLT9qmaMXSAhXpb0WrspIeqYzdJpkh2vHModJPgRIaw==}

  '@radix-ui/primitive@1.1.0':
    resolution: {integrity: sha512-4Z8dn6Upk0qk4P74xBhZ6Hd/w0mPEzOOLxy4xiPXOXqjF7jZS0VAKk7/x/H6FyY2zCkYJqePf1G5KmkmNJ4RBA==}

  '@radix-ui/primitive@1.1.1':
    resolution: {integrity: sha512-SJ31y+Q/zAyShtXJc8x83i9TYdbAfHZ++tUZnvjJJqFjzsdUnKsxPL6IEtBlxKkU7yzer//GQtZSV4GbldL3YA==}

  '@radix-ui/react-accordion@1.2.1':
    resolution: {integrity: sha512-bg/l7l5QzUjgsh8kjwDFommzAshnUsuVMV5NM56QVCm+7ZckYdd9P/ExR8xG/Oup0OajVxNLaHJ1tb8mXk+nzQ==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-arrow@1.1.0':
    resolution: {integrity: sha512-FmlW1rCg7hBpEBwFbjHwCW6AmWLQM6g/v0Sn8XbP9NvmSZ2San1FpQeyPtufzOMSIx7Y4dzjlHoifhp+7NkZhw==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-collapsible@1.1.0':
    resolution: {integrity: sha512-zQY7Epa8sTL0mq4ajSJpjgn2YmCgyrG7RsQgLp3C0LQVkG7+Tf6Pv1CeNWZLyqMjhdPkBa5Lx7wYBeSu7uCSTA==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-collapsible@1.1.1':
    resolution: {integrity: sha512-1///SnrfQHJEofLokyczERxQbWfCGQlQ2XsCZMucVs6it+lq9iw4vXy+uDn1edlb58cOZOWSldnfPAYcT4O/Yg==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-collection@1.1.0':
    resolution: {integrity: sha512-GZsZslMJEyo1VKm5L1ZJY8tGDxZNPAoUeQUIbKeJfoi7Q4kmig5AsgLMYYuyYbfjd8fBmFORAIwYAkXMnXZgZw==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-collection@1.1.1':
    resolution: {integrity: sha512-LwT3pSho9Dljg+wY2KN2mrrh6y3qELfftINERIzBUO9e0N+t0oMTyn3k9iv+ZqgrwGkRnLpNJrsMv9BZlt2yuA==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-compose-refs@1.0.1':
    resolution: {integrity: sha512-fDSBgd44FKHa1FRMU59qBMPFcl2PZE+2nmqunj+BWFyYYjnhIDWL2ItDs3rrbJDQOtzt5nIebLCQc4QRfz6LJw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-compose-refs@1.1.0':
    resolution: {integrity: sha512-b4inOtiaOnYf9KWyO3jAeeCG6FeyfY6ldiEPanbUjWd+xIk5wZeHa8yVwmrJ2vderhu/BQvzCrJI0lHd+wIiqw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-compose-refs@1.1.1':
    resolution: {integrity: sha512-Y9VzoRDSJtgFMUCoiZBDVo084VQ5hfpXxVE+NgkdNsjiDBByiImMZKKhxMwCbdHvhlENG6a833CbFkOQvTricw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-context@1.0.1':
    resolution: {integrity: sha512-ebbrdFoYTcuZ0v4wG5tedGnp9tzcV8awzsxYph7gXUyvnNLuTIcCk1q17JEbnVhXAKG9oX3KtchwiMIAYp9NLg==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-context@1.1.0':
    resolution: {integrity: sha512-OKrckBy+sMEgYM/sMmqmErVn0kZqrHPJze+Ql3DzYsDDp0hl0L62nx/2122/Bvps1qz645jlcu2tD9lrRSdf8A==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-context@1.1.1':
    resolution: {integrity: sha512-UASk9zi+crv9WteK/NU4PLvOoL3OuE6BWVKNF6hPRBtYBDXQ2u5iu3O59zUlJiTVvkyuycnqrztsHVJwcK9K+Q==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-dialog@1.0.5':
    resolution: {integrity: sha512-GjWJX/AUpB703eEBanuBnIWdIXg6NvJFCXcNlSZk4xdszCdhrJgBoUd1cGk67vFO+WdA2pfI/plOpqz/5GUP6Q==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0
      react-dom: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-dialog@1.1.2':
    resolution: {integrity: sha512-Yj4dZtqa2o+kG61fzB0H2qUvmwBA2oyQroGLyNtBj1beo1khoQ3q1a2AO8rrQYjd8256CO9+N8L9tvsS+bnIyA==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-direction@1.1.0':
    resolution: {integrity: sha512-BUuBvgThEiAXh2DWu93XsT+a3aWrGqolGlqqw5VU1kG7p/ZH2cuDlM1sRLNnY3QcBS69UIz2mcKhMxDsdewhjg==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-dismissable-layer@1.0.5':
    resolution: {integrity: sha512-aJeDjQhywg9LBu2t/At58hCvr7pEm0o2Ke1x33B+MhjNmmZ17sy4KImo0KPLgsnc/zN7GPdce8Cnn0SWvwZO7g==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0
      react-dom: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-dismissable-layer@1.1.0':
    resolution: {integrity: sha512-/UovfmmXGptwGcBQawLzvn2jOfM0t4z3/uKffoBlj724+n3FvBbZ7M0aaBOmkp6pqFYpO4yx8tSVJjx3Fl2jig==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-dismissable-layer@1.1.1':
    resolution: {integrity: sha512-QSxg29lfr/xcev6kSz7MAlmDnzbP1eI/Dwn3Tp1ip0KT5CUELsxkekFEMVBEoykI3oV39hKT4TKZzBNMbcTZYQ==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-focus-guards@1.0.1':
    resolution: {integrity: sha512-Rect2dWbQ8waGzhMavsIbmSVCgYxkXLxxR3ZvCX79JOglzdEy4JXMb98lq4hPxUbLr77nP0UOGf4rcMU+s1pUA==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-focus-guards@1.1.0':
    resolution: {integrity: sha512-w6XZNUPVv6xCpZUqb/yN9DL6auvpGX3C/ee6Hdi16v2UUy25HV2Q5bcflsiDyT/g5RwbPQ/GIT1vLkeRb+ITBw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-focus-guards@1.1.1':
    resolution: {integrity: sha512-pSIwfrT1a6sIoDASCSpFwOasEwKTZWDw/iBdtnqKO7v6FeOzYJ7U53cPzYFVR3geGGXgVHaH+CdngrrAzqUGxg==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-focus-scope@1.0.4':
    resolution: {integrity: sha512-sL04Mgvf+FmyvZeYfNu1EPAaaxD+aw7cYeIB9L9Fvq8+urhltTRaEo5ysKOpHuKPclsZcSUMKlN05x4u+CINpA==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0
      react-dom: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-focus-scope@1.1.0':
    resolution: {integrity: sha512-200UD8zylvEyL8Bx+z76RJnASR2gRMuxlgFCPAe/Q/679a/r0eK3MBVYMb7vZODZcffZBdob1EGnky78xmVvcA==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-icons@1.3.0':
    resolution: {integrity: sha512-jQxj/0LKgp+j9BiTXz3O3sgs26RNet2iLWmsPyRz2SIcR4q/4SbazXfnYwbAr+vLYKSfc7qxzyGQA1HLlYiuNw==}
    peerDependencies:
      react: ^16.x || ^17.x || ^18.x

  '@radix-ui/react-id@1.0.1':
    resolution: {integrity: sha512-tI7sT/kqYp8p96yGWY1OAnLHrqDgzHefRBKQ2YAkBS5ja7QLcZ9Z/uY7bEjPUatf8RomoXM8/1sMj1IJaE5UzQ==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-id@1.1.0':
    resolution: {integrity: sha512-EJUrI8yYh7WOjNOqpoJaf1jlFIH2LvtgAl+YcFqNCa+4hj64ZXmPkAKOFs/ukjz3byN6bdb/AVUqHkI8/uWWMA==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-popover@1.1.1':
    resolution: {integrity: sha512-3y1A3isulwnWhvTTwmIreiB8CF4L+qRjZnK1wYLO7pplddzXKby/GnZ2M7OZY3qgnl6p9AodUIHRYGXNah8Y7g==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-popper@1.2.0':
    resolution: {integrity: sha512-ZnRMshKF43aBxVWPWvbj21+7TQCvhuULWJ4gNIKYpRlQt5xGRhLx66tMp8pya2UkGHTSlhpXwmjqltDYHhw7Vg==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-portal@1.0.4':
    resolution: {integrity: sha512-Qki+C/EuGUVCQTOTD5vzJzJuMUlewbzuKyUy+/iHM2uwGiru9gZeBJtHAPKAEkB5KWGi9mP/CHKcY0wt1aW45Q==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0
      react-dom: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-portal@1.1.1':
    resolution: {integrity: sha512-A3UtLk85UtqhzFqtoC8Q0KvR2GbXF3mtPgACSazajqq6A41mEQgo53iPzY4i6BwDxlIFqWIhiQ2G729n+2aw/g==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-portal@1.1.2':
    resolution: {integrity: sha512-WeDYLGPxJb/5EGBoedyJbT0MpoULmwnIPMJMSldkuiMsBAv7N1cRdsTWZWht9vpPOiN3qyiGAtbK2is47/uMFg==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-presence@1.0.1':
    resolution: {integrity: sha512-UXLW4UAbIY5ZjcvzjfRFo5gxva8QirC9hF7wRE4U5gz+TP0DbRk+//qyuAQ1McDxBt1xNMBTaciFGvEmJvAZCg==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0
      react-dom: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-presence@1.1.0':
    resolution: {integrity: sha512-Gq6wuRN/asf9H/E/VzdKoUtT8GC9PQc9z40/vEr0VCJ4u5XvvhWIrSsCB6vD2/cH7ugTdSfYq9fLJCcM00acrQ==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-presence@1.1.1':
    resolution: {integrity: sha512-IeFXVi4YS1K0wVZzXNrbaaUvIJ3qdY+/Ih4eHFhWA9SwGR9UDX7Ck8abvL57C4cv3wwMvUE0OG69Qc3NCcTe/A==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-presence@1.1.2':
    resolution: {integrity: sha512-18TFr80t5EVgL9x1SwF/YGtfG+l0BS0PRAlCWBDoBEiDQjeKgnNZRVJp/oVBl24sr3Gbfwc/Qpj4OcWTQMsAEg==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-primitive@1.0.3':
    resolution: {integrity: sha512-yi58uVyoAcK/Nq1inRY56ZSjKypBNKTa/1mcL8qdl6oJeEaDbOldlzrGn7P6Q3Id5d+SYNGc5AJgc4vGhjs5+g==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0
      react-dom: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-primitive@2.0.0':
    resolution: {integrity: sha512-ZSpFm0/uHa8zTvKBDjLFWLo8dkr4MBsiDLz0g3gMUwqgLHz9rTaRRGYDgvZPtBJgYCBKXkS9fzmoySgr8CO6Cw==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-primitive@2.0.1':
    resolution: {integrity: sha512-sHCWTtxwNn3L3fH8qAfnF3WbUZycW93SM1j3NFDzXBiz8D6F5UTTy8G1+WFEaiCdvCVRJWj6N2R4Xq6HdiHmDg==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-roving-focus@1.1.1':
    resolution: {integrity: sha512-QE1RoxPGJ/Nm8Qmk0PxP8ojmoaS67i0s7hVssS7KuI2FQoc/uzVlZsqKfQvxPE6D8hICCPHJ4D88zNhT3OOmkw==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-scroll-area@1.2.2':
    resolution: {integrity: sha512-EFI1N/S3YxZEW/lJ/H1jY3njlvTd8tBmgKEn4GHi51+aMm94i6NmAJstsm5cu3yJwYqYc93gpCPm21FeAbFk6g==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-select@2.1.2':
    resolution: {integrity: sha512-rZJtWmorC7dFRi0owDmoijm6nSJH1tVw64QGiNIZ9PNLyBDtG+iAq+XGsya052At4BfarzY/Dhv9wrrUr6IMZA==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-slot@1.0.2':
    resolution: {integrity: sha512-YeTpuq4deV+6DusvVUW4ivBgnkHwECUu0BiN43L5UCDFgdhsRUWAghhTF5MbvNTPzmiFOx90asDSUjWuCNapwg==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-slot@1.1.0':
    resolution: {integrity: sha512-FUCf5XMfmW4dtYl69pdS4DbxKy8nj4M7SafBgPllysxmdachynNflAdp/gCsnYWNDnge6tI9onzMp5ARYc1KNw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-slot@1.1.1':
    resolution: {integrity: sha512-RApLLOcINYJA+dMVbOju7MYv1Mb2EBp2nH4HdDzXTSyaR5optlm6Otrz1euW3HbdOR8UmmFK06TD+A9frYWv+g==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-tabs@1.1.2':
    resolution: {integrity: sha512-9u/tQJMcC2aGq7KXpGivMm1mgq7oRJKXphDwdypPd/j21j/2znamPU8WkXgnhUaTrSFNIt8XhOyCAupg8/GbwQ==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/react-use-callback-ref@1.0.1':
    resolution: {integrity: sha512-D94LjX4Sp0xJFVaoQOd3OO9k7tpBYNOXdVhkltUbGv2Qb9OXdrg/CpsjlZv7ia14Sylv398LswWBVVu5nqKzAQ==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-callback-ref@1.1.0':
    resolution: {integrity: sha512-CasTfvsy+frcFkbXtSJ2Zu9JHpN8TYKxkgJGWbjiZhFivxaeW7rMeZt7QELGVLaYVfFMsKHjb7Ak0nMEe+2Vfw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-controllable-state@1.0.1':
    resolution: {integrity: sha512-Svl5GY5FQeN758fWKrjM6Qb7asvXeiZltlT4U2gVfl8Gx5UAv2sMR0LWo8yhsIZh2oQ0eFdZ59aoOOMV7b47VA==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-controllable-state@1.1.0':
    resolution: {integrity: sha512-MtfMVJiSr2NjzS0Aa90NPTnvTSg6C/JLCV7ma0W6+OMV78vd8OyRpID+Ng9LxzsPbLeuBnWBA1Nq30AtBIDChw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-escape-keydown@1.0.3':
    resolution: {integrity: sha512-vyL82j40hcFicA+M4Ex7hVkB9vHgSse1ZWomAqV2Je3RleKGO5iM8KMOEtfoSB0PnIelMd2lATjTGMYqN5ylTg==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-escape-keydown@1.1.0':
    resolution: {integrity: sha512-L7vwWlR1kTTQ3oh7g1O0CBF3YCyyTj8NmhLR+phShpyA50HCfBFKVJTpshm9PzLiKmehsrQzTYTpX9HvmC9rhw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-layout-effect@1.0.1':
    resolution: {integrity: sha512-v/5RegiJWYdoCvMnITBkNNx6bCj20fiaJnWtRkU18yITptraXjffz5Qbn05uOiQnOvi+dbkznkoaMltz1GnszQ==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-layout-effect@1.1.0':
    resolution: {integrity: sha512-+FPE0rOdziWSrH9athwI1R0HDVbWlEhd+FR+aSDk4uWGmSJ9Z54sdZVDQPZAinJhJXwfT+qnj969mCsT2gfm5w==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-previous@1.1.0':
    resolution: {integrity: sha512-Z/e78qg2YFnnXcW88A4JmTtm4ADckLno6F7OXotmkQfeuCVaKuYzqAATPhVzl3delXE7CxIV8shofPn3jPc5Og==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-rect@1.1.0':
    resolution: {integrity: sha512-0Fmkebhr6PiseyZlYAOtLS+nb7jLmpqTrJyv61Pe68MKYW6OWdRE2kI70TaYY27u7H0lajqM3hSMMLFq18Z7nQ==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-use-size@1.1.0':
    resolution: {integrity: sha512-XW3/vWuIXHa+2Uwcc2ABSfcCledmXhhQPlGbfcRXbiUQI5Icjcg19BGCZVKKInYbvUCut/ufbbLLPFC5cbb1hw==}
    peerDependencies:
      '@types/react': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true

  '@radix-ui/react-visually-hidden@1.1.0':
    resolution: {integrity: sha512-N8MDZqtgCgG5S3aV60INAB475osJousYpZ4cTJ2cFbMpdHS5Y6loLTH8LPtkj2QN0x93J30HT/M3qJXM0+lyeQ==}
    peerDependencies:
      '@types/react': '*'
      '@types/react-dom': '*'
      react: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
      react-dom: ^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc
    peerDependenciesMeta:
      '@types/react':
        optional: true
      '@types/react-dom':
        optional: true

  '@radix-ui/rect@1.1.0':
    resolution: {integrity: sha512-A9+lCBZoaMJlVKcRBz2YByCG+Cp2t6nAnMnNba+XiWxnj6r4JUFqfsgwocMBZU9LPtdxC6wB56ySYpc7LQIoJg==}

  '@react-aria/focus@3.20.1':
    resolution: {integrity: sha512-lgYs+sQ1TtBrAXnAdRBQrBo0/7o5H6IrfDxec1j+VRpcXL0xyk0xPq+m3lZp8typzIghqDgpnKkJ5Jf4OrzPIw==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1
      react-dom: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1

  '@react-aria/interactions@3.24.1':
    resolution: {integrity: sha512-OWEcIC6UQfWq4Td5Ptuh4PZQ4LHLJr/JL2jGYvuNL6EgL3bWvzPrRYIF/R64YbfVxIC7FeZpPSkS07sZ93/NoA==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1
      react-dom: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1

  '@react-aria/ssr@3.9.7':
    resolution: {integrity: sha512-GQygZaGlmYjmYM+tiNBA5C6acmiDWF52Nqd40bBp0Znk4M4hP+LTmI0lpI1BuKMw45T8RIhrAsICIfKwZvi2Gg==}
    engines: {node: '>= 12'}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1

  '@react-aria/utils@3.28.1':
    resolution: {integrity: sha512-mnHFF4YOVu9BRFQ1SZSKfPhg3z+lBRYoW5mLcYTQihbKhz48+I1sqRkP7ahMITr8ANH3nb34YaMME4XWmK2Mgg==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1
      react-dom: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1

  '@react-stately/flags@3.1.0':
    resolution: {integrity: sha512-KSHOCxTFpBtxhIRcKwsD1YDTaNxFtCYuAUb0KEihc16QwqZViq4hasgPBs2gYm7fHRbw7WYzWKf6ZSo/+YsFlg==}

  '@react-stately/utils@3.10.5':
    resolution: {integrity: sha512-iMQSGcpaecghDIh3mZEpZfoFH3ExBwTtuBEcvZ2XnGzCgQjeYXcMdIUwAfVQLXFTdHUHGF6Gu6/dFrYsCzySBQ==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1

  '@react-types/shared@3.28.0':
    resolution: {integrity: sha512-9oMEYIDc3sk0G5rysnYvdNrkSg7B04yTKl50HHSZVbokeHpnU0yRmsDaWb9B/5RprcKj8XszEk5guBO8Sa/Q+Q==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0-rc.1 || ^18.0.0 || ^19.0.0-rc.1

  '@scarf/scarf@1.4.0':
    resolution: {integrity: sha512-xxeapPiUXdZAE3che6f3xogoJPeZgig6omHEy1rIY5WVsB3H2BHNnZH+gHG6x91SCWyQCzWGsuL2Hh3ClO5/qQ==}

  '@segment/analytics-core@1.8.1':
    resolution: {integrity: sha512-EYcdBdhfi1pOYRX+Sf5orpzzYYFmDHTEu6+w0hjXpW5bWkWct+Nv6UJg1hF4sGDKEQjpZIinLTpQ4eioFM4KeQ==}

  '@segment/analytics-generic-utils@1.2.0':
    resolution: {integrity: sha512-DfnW6mW3YQOLlDQQdR89k4EqfHb0g/3XvBXkovH1FstUN93eL1kfW9CsDcVQyH3bAC5ZsFyjA/o/1Q2j0QeoWw==}

  '@segment/analytics-node@2.2.1':
    resolution: {integrity: sha512-J+p5r2BewzowI6YsnSH6U+W9IAvRbEyheqDOSUEwh6QDbxjwcBXwzuPwtz5DtEjbEGMu2QwrwoJvZlZ/n5fugw==}
    engines: {node: '>=18'}

  '@shikijs/core@1.18.0':
    resolution: {integrity: sha512-VK4BNVCd2leY62Nm2JjyxtRLkyrZT/tv104O81eyaCjHq4Adceq2uJVFJJAIof6lT1mBwZrEo2qT/T+grv3MQQ==}

  '@shikijs/core@1.20.0':
    resolution: {integrity: sha512-KlO3iE0THzSdYkzDFugt8SHe6FR3qNYTkmpbdW1d6xo8juQkMjybxAw/cBi2npL2eb2F4PbbnSs5Z9tDusfvyg==}

  '@shikijs/engine-javascript@1.18.0':
    resolution: {integrity: sha512-qoP/aO/ATNwYAUw1YMdaip/YVEstMZEgrwhePm83Ll9OeQPuxDZd48szZR8oSQNQBT8m8UlWxZv8EA3lFuyI5A==}

  '@shikijs/engine-javascript@1.20.0':
    resolution: {integrity: sha512-ZUMo758uduM0Tfgzi/kd+0IKMbNdumCxxWjY36uf1DIs2Qyg9HIq3vA1Wfa/vc6HE7tHWFpANRi3mv7UzJ68MQ==}

  '@shikijs/engine-oniguruma@1.18.0':
    resolution: {integrity: sha512-B9u0ZKI/cud+TcmF8Chyh+R4V5qQVvyDOqXC2l2a4x73PBSBc6sZ0JRAX3eqyJswqir6ktwApUUGBYePdKnMJg==}

  '@shikijs/engine-oniguruma@1.20.0':
    resolution: {integrity: sha512-MQ40WkVTZk7by33ces4PGK6XNFSo6PYvKTSAr2kTWdRNhFmOcnaX+1XzvFwB26eySXR7U74t91czZ1qJkEgxTA==}

  '@shikijs/rehype@1.18.0':
    resolution: {integrity: sha512-6E+X1pI8lrzABlJcnxUIAw/ReaNkzBFlgDAG/t9n7xX97DV2VT9VC5cbR5ztydbHoYEhVaUT0O9sZ8wW13fQlQ==}

  '@shikijs/transformers@1.20.0':
    resolution: {integrity: sha512-TNS5KAErbNIOm1QqabuVaU77NOs5xWfpjpnqME059SA8yddr3mN5ZNAeCI+4QAAnNqZd8RKXjp+9hw66f5ak/A==}

  '@shikijs/types@1.18.0':
    resolution: {integrity: sha512-O9N36UEaGGrxv1yUrN2nye7gDLG5Uq0/c1LyfmxsvzNPqlHzWo9DI0A4+fhW2y3bGKuQu/fwS7EPdKJJCowcVA==}

  '@shikijs/types@1.20.0':
    resolution: {integrity: sha512-y+EaDvU2K6/GaXOKXxJaGnr1XtmZMF7MfS0pSEDdxEq66gCtKsLwQvVwoQFdp7R7dLlNAro3ijEE19sMZ0pzqg==}

  '@shikijs/vscode-textmate@9.2.2':
    resolution: {integrity: sha512-TMp15K+GGYrWlZM8+Lnj9EaHEFmOen0WJBrfa17hF7taDOYthuPPV0GWzfd/9iMij0akS/8Yw2ikquH7uVi/fg==}

  '@swc/counter@0.1.3':
    resolution: {integrity: sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ==}

  '@swc/helpers@0.5.5':
    resolution: {integrity: sha512-KGYxvIOXcceOAbEk4bi/dVLEK9z8sZ0uBB3Il5b1rhfClSpcX0yfRO0KmTkqR2cnQDymwLB+25ZyMzICg/cm/A==}

  '@tailwindcss/typography@0.5.15':
    resolution: {integrity: sha512-AqhlCXl+8grUz8uqExv5OTtgpjuVIwFTSXTrh8y9/pw6q2ek7fJ+Y8ZEVw7EB2DCcuCOtEjf9w3+J3rzts01uA==}
    peerDependencies:
      tailwindcss: '>=3.0.0 || insiders || >=4.0.0-alpha.20'

  '@tanstack/react-virtual@3.13.5':
    resolution: {integrity: sha512-MzSSMGkFWCDSb2xXqmdbfQqBG4wcRI3JKVjpYGZG0CccnViLpfRW4tGU97ImfBbSYzvEWJ/2SK/OiIoSmcUBAA==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0
      react-dom: ^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0

  '@tanstack/virtual-core@3.13.5':
    resolution: {integrity: sha512-gMLNylxhJdUlfRR1G3U9rtuwUh2IjdrrniJIDcekVJN3/3i+bluvdMi3+eodnxzJq5nKnxnigo9h0lIpaqV6HQ==}

  '@theguild/remark-mermaid@0.1.3':
    resolution: {integrity: sha512-2FjVlaaKXK7Zj7UJAgOVTyaahn/3/EAfqYhyXg0BfDBVUl+lXcoIWRaxzqfnDr2rv8ax6GsC5mNh6hAaT86PDw==}
    peerDependencies:
      react: ^18.2.0

  '@theguild/remark-npm2yarn@0.3.2':
    resolution: {integrity: sha512-H9T/GOuS/+4H7AY1cfD5DJIIIcGIIw1zMCB8OeTgXk7azJULsnuOurZ/CR54rvuTD+Krx0MVQccaUCvCWfP+vw==}

  '@types/acorn@4.0.6':
    resolution: {integrity: sha512-veQTnWP+1D/xbxVrPC3zHnCZRjSrKfhbMUlEA43iMZLu7EsnTtkJklIuwrCPbOi8YkvDQAiW05VQQFvvz9oieQ==}

  '@types/debug@4.1.12':
    resolution: {integrity: sha512-vIChWdVG3LG1SMxEvI/AK+FWJthlrqlTu7fbrlywTkkaONwk/UAGaULXRlf8vkzFBLVm0zkMdCquhL5aOjhXPQ==}

  '@types/estree-jsx@1.0.5':
    resolution: {integrity: sha512-52CcUVNFyfb1A2ALocQw/Dd1BQFNmSdkuC3BkZ6iqhdMfQz7JWOFRuJFloOzjk+6WijU56m9oKXFAXc7o3Towg==}

  '@types/estree@1.0.6':
    resolution: {integrity: sha512-AYnb1nQyY49te+VRAVgmzfcgjYS91mY5P0TKUDCLEM+gNnA+3T6rWITXRLYCpahpqSQbN5cE+gHpnPyXjHWxcw==}

  '@types/hast@2.3.10':
    resolution: {integrity: sha512-McWspRw8xx8J9HurkVBfYj0xKoE25tOFlHGdx4MJ5xORQrMGZNqJhVQWaIbm6Oyla5kYOXtDiopzKRJzEOkwJw==}

  '@types/hast@3.0.4':
    resolution: {integrity: sha512-WPs+bbQw5aCj+x6laNGWLH3wviHtoCv/P3+otBhbOhJgG8qtpdAMlTCxLtsTWA7LH1Oh/bFCHsBn0TPS5m30EQ==}

  '@types/katex@0.16.7':
    resolution: {integrity: sha512-HMwFiRujE5PjrgwHQ25+bsLJgowjGjm5Z8FVSf0N6PwgJrwxH0QxzHYDcKsTfV3wva0vzrpqMTJS2jXPr5BMEQ==}

  '@types/mdast@3.0.15':
    resolution: {integrity: sha512-LnwD+mUEfxWMa1QpDraczIn6k0Ee3SMicuYSSzS6ZYl2gKS09EClnJYGd8Du6rfc5r/GZEk5o1mRb8TaTj03sQ==}

  '@types/mdast@4.0.4':
    resolution: {integrity: sha512-kGaNbPh1k7AFzgpud/gMdvIm5xuECykRR+JnWKQno9TAXVa6WIVCGTPvYGekIDL4uwCZQSYbUxNBSb1aUo79oA==}

  '@types/mdx@2.0.13':
    resolution: {integrity: sha512-+OWZQfAYyio6YkJb3HLxDrvnx6SWWDbC0zVPfBRzUk0/nqoDyf6dNxQi3eArPe8rJ473nobTMQ/8Zk+LxJ+Yuw==}

  '@types/ms@0.7.34':
    resolution: {integrity: sha512-nG96G3Wp6acyAgJqGasjODb+acrI7KltPiRxzHPXnP3NgI28bpQDRv53olbqGXbfcgF5aiiHmO3xpwEpS5Ld9g==}

  '@types/node@22.5.4':
    resolution: {integrity: sha512-FDuKUJQm/ju9fT/SeX/6+gBzoPzlVCzfzmGkwKvRHQVxi4BntVbyIwf6a4Xn62mrvndLiml6z/UBXIdEVjQLXg==}

  '@types/prop-types@15.7.13':
    resolution: {integrity: sha512-hCZTSvwbzWGvhqxp/RqVqwU999pBf2vp7hzIjiYOsl8wqOmUxkQ6ddw1cV3l8811+kdUFus/q4d1Y3E3SyEifA==}

  '@types/react-dom@18.3.0':
    resolution: {integrity: sha512-EhwApuTmMBmXuFOikhQLIBUn6uFg81SwLMOAUgodJF14SOBOCMdU04gDoYi0WOJJHD144TL32z4yDqCW3dnkQg==}

  '@types/react@18.3.9':
    resolution: {integrity: sha512-+BpAVyTpJkNWWSSnaLBk6ePpHLOGJKnEQNbINNovPWzvEUyAe3e+/d494QdEh71RekM/qV7lw6jzf1HGrJyAtQ==}

  '@types/unist@2.0.11':
    resolution: {integrity: sha512-CmBKiL6NNo/OqgmMn95Fk9Whlp2mtvIv+KNpQKN2F4SjvrEesubTRWGYSg+BnWZOnlCaSTU1sMpsBOzgbYhnsA==}

  '@types/unist@3.0.3':
    resolution: {integrity: sha512-ko/gIFJRv177XgZsZcBwnqJN5x/Gien8qNOn0D5bQU/zAzVf9Zt3BlcUiLqhV9y4ARk0GbT3tnUiPNgnTXzc/Q==}

  '@ungap/structured-clone@1.2.0':
    resolution: {integrity: sha512-zuVdFrMJiuCDQUMCzQaD6KL28MjnqqN8XnAqiEq9PNm/hCPTSGfrXCOfwj1ow4LFb/tNymJPwsNbVePc1xFqrQ==}

  '@urql/core@5.1.1':
    resolution: {integrity: sha512-aGh024z5v2oINGD/In6rAtVKTm4VmQ2TxKQBAtk2ZSME5dunZFcjltw4p5ENQg+5CBhZ3FHMzl0Oa+rwqiWqlg==}

  acorn-jsx@5.3.2:
    resolution: {integrity: sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==}
    peerDependencies:
      acorn: ^6.0.0 || ^7.0.0 || ^8.0.0

  acorn@8.12.1:
    resolution: {integrity: sha512-tcpGyI9zbizT9JbV6oYE477V6mTlXvvi0T0G3SNIYE2apm/G5huBa1+K89VGeovbg+jycCrfhl3ADxErOuO6Jg==}
    engines: {node: '>=0.4.0'}
    hasBin: true

  ansi-regex@5.0.1:
    resolution: {integrity: sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==}
    engines: {node: '>=8'}

  ansi-regex@6.1.0:
    resolution: {integrity: sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==}
    engines: {node: '>=12'}

  ansi-styles@4.3.0:
    resolution: {integrity: sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==}
    engines: {node: '>=8'}

  ansi-styles@6.2.1:
    resolution: {integrity: sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==}
    engines: {node: '>=12'}

  any-promise@1.3.0:
    resolution: {integrity: sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==}

  anymatch@3.1.3:
    resolution: {integrity: sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==}
    engines: {node: '>= 8'}

  arg@5.0.2:
    resolution: {integrity: sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==}

  argparse@1.0.10:
    resolution: {integrity: sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==}

  aria-hidden@1.2.4:
    resolution: {integrity: sha512-y+CcFFwelSXpLZk/7fMB2mUbGtX9lKycf1MWJ7CaTIERyitVlyQx6C+sxcROU2BAJ24OiZyK+8wj2i8AlBoS3A==}
    engines: {node: '>=10'}

  astring@1.9.0:
    resolution: {integrity: sha512-LElXdjswlqjWrPpJFg1Fx4wpkOCxj1TDHlSV4PlaRxHGWko024xICaa97ZkMfs6DRKlCguiAI+rbXv5GWwXIkg==}
    hasBin: true

  autoprefixer@10.4.20:
    resolution: {integrity: sha512-XY25y5xSv/wEoqzDyXXME4AFfkZI0P23z6Fs3YgymDnKJkCGOnkL0iTxCa85UTqaSgfcqyf3UA6+c7wUvx/16g==}
    engines: {node: ^10 || ^12 || >=14}
    hasBin: true
    peerDependencies:
      postcss: ^8.1.0

  bail@2.0.2:
    resolution: {integrity: sha512-0xO6mYd7JB2YesxDKplafRpsiOzPt9V02ddPCLbY1xYGPOX24NTyN50qnUxgCPcSoYMhKpAuBTjQoRZCAkUDRw==}

  balanced-match@1.0.2:
    resolution: {integrity: sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==}

  base64-js@1.5.1:
    resolution: {integrity: sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==}

  binary-extensions@2.3.0:
    resolution: {integrity: sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==}
    engines: {node: '>=8'}

  brace-expansion@2.0.1:
    resolution: {integrity: sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==}

  braces@3.0.3:
    resolution: {integrity: sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==}
    engines: {node: '>=8'}

  browserslist@4.24.0:
    resolution: {integrity: sha512-Rmb62sR1Zpjql25eSanFGEhAxcFwfA1K0GuQcLoaJBAcENegrQut3hYdhXFF1obQfiDyqIW/cLM5HSJ/9k884A==}
    engines: {node: ^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7}
    hasBin: true

  buffer@6.0.3:
    resolution: {integrity: sha512-FTiCpNxtwiZZHEZbcbTIcZjERVICn9yq/pDFkTl95/AxzD1naBctN7YO68riM/gLSDY7sdrMby8hofADYuuqOA==}

  busboy@1.6.0:
    resolution: {integrity: sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==}
    engines: {node: '>=10.16.0'}

  camelcase-css@2.0.1:
    resolution: {integrity: sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==}
    engines: {node: '>= 6'}

  caniuse-lite@1.0.30001663:
    resolution: {integrity: sha512-o9C3X27GLKbLeTYZ6HBOLU1tsAcBZsLis28wrVzddShCS16RujjHp9GDHKZqrB3meE0YjhawvMFsGb/igqiPzA==}

  ccount@2.0.1:
    resolution: {integrity: sha512-eyrF0jiFpY+3drT6383f1qhkbGsLSifNAjA61IUjZjmLCWjItY6LB9ft9YhoDgwfmclB2zhu51Lc7+95b8NRAg==}

  chalk@4.1.2:
    resolution: {integrity: sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==}
    engines: {node: '>=10'}

  character-entities-html4@2.1.0:
    resolution: {integrity: sha512-1v7fgQRj6hnSwFpq1Eu0ynr/CDEw0rXo2B61qXrLNdHZmPKgb7fqS1a2JwF0rISo9q77jDI8VMEHoApn8qDoZA==}

  character-entities-legacy@1.1.4:
    resolution: {integrity: sha512-3Xnr+7ZFS1uxeiUDvV02wQ+QDbc55o97tIV5zHScSPJpcLm/r0DFPcoY3tYRp+VZukxuMeKgXYmsXQHO05zQeA==}

  character-entities-legacy@3.0.0:
    resolution: {integrity: sha512-RpPp0asT/6ufRm//AJVwpViZbGM/MkjQFxJccQRHmISF/22NBtsHqAWmL+/pmkPWoIUJdWyeVleTl1wydHATVQ==}

  character-entities@1.2.4:
    resolution: {integrity: sha512-iBMyeEHxfVnIakwOuDXpVkc54HijNgCyQB2w0VfGQThle6NXn50zU6V/u+LDhxHcDUPojn6Kpga3PTAD8W1bQw==}

  character-entities@2.0.2:
    resolution: {integrity: sha512-shx7oQ0Awen/BRIdkjkvz54PnEEI/EjwXDSIZp86/KKdbafHh1Df/RYGBhn4hbe2+uKC9FnT5UCEdyPz3ai9hQ==}

  character-reference-invalid@1.1.4:
    resolution: {integrity: sha512-mKKUkUbhPpQlCOfIuZkvSEgktjPFIsZKRRbC6KWVEMvlzblj3i3asQv5ODsrwt0N3pHAEvjP8KTQPHkp0+6jOg==}

  character-reference-invalid@2.0.1:
    resolution: {integrity: sha512-iBZ4F4wRbyORVsu0jPV7gXkOsGYjGHPmAyv+HiHG8gi5PtC9KI2j1+v8/tlibRvjoWX027ypmG/n0HtO5t7unw==}

  chevrotain-allstar@0.3.1:
    resolution: {integrity: sha512-b7g+y9A0v4mxCW1qUhf3BSVPg+/NvGErk/dOkrDaHA0nQIQGAtrOjlX//9OQtRlSCy+x9rfB5N8yC71lH1nvMw==}
    peerDependencies:
      chevrotain: ^11.0.0

  chevrotain@11.0.3:
    resolution: {integrity: sha512-ci2iJH6LeIkvP9eJW6gpueU8cnZhv85ELY8w8WiFtNjMHA5ad6pQLaJo9mEly/9qUyCpvqX8/POVUTf18/HFdw==}

  chokidar@3.6.0:
    resolution: {integrity: sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==}
    engines: {node: '>= 8.10.0'}

  class-variance-authority@0.7.0:
    resolution: {integrity: sha512-jFI8IQw4hczaL4ALINxqLEXQbWcNjoSkloa4IaufXCJr6QawJyw7tuRysRsrE8w2p/4gGaxKIt/hX3qz/IbD1A==}

  classnames@2.5.1:
    resolution: {integrity: sha512-saHYOzhIQs6wy2sVxTM6bUDsQO4F50V9RQ22qBpEdCW+I+/Wmke2HOl6lS6dTpdxVhb88/I6+Hs+438c3lfUow==}

  client-only@0.0.1:
    resolution: {integrity: sha512-IV3Ou0jSMzZrd3pZ48nLkT9DA7Ag1pnPzaiQhpW7c3RbcqqzvzzVu+L8gfqMp/8IM2MQtSiqaCxrrcfu8I8rMA==}

  clsx@2.0.0:
    resolution: {integrity: sha512-rQ1+kcj+ttHG0MKVGBUXwayCCF1oh39BF5COIpRzuCEv8Mwjv0XucrI2ExNTOn9IlLifGClWQcU9BrZORvtw6Q==}
    engines: {node: '>=6'}

  clsx@2.1.1:
    resolution: {integrity: sha512-eYm0QWBtUrBWZWG0d386OGAw16Z995PiOVo2B7bjWSbHedGl5e0ZWaq65kOGgUSNesEIDkB9ISbTg/JK9dhCZA==}
    engines: {node: '>=6'}

  cmdk@1.0.0:
    resolution: {integrity: sha512-gDzVf0a09TvoJ5jnuPvygTB77+XdOSwEmJ88L6XPFPlv7T3RxbP9jgenfylrAMD0+Le1aO0nVjQUzl2g+vjz5Q==}
    peerDependencies:
      react: ^18.0.0
      react-dom: ^18.0.0

  collapse-white-space@2.1.0:
    resolution: {integrity: sha512-loKTxY1zCOuG4j9f6EPnuyyYkf58RnhhWTvRoZEokgB+WbdXehfjFviyOVYkqzEWz1Q5kRiZdBYS5SwxbQYwzw==}

  color-convert@2.0.1:
    resolution: {integrity: sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==}
    engines: {node: '>=7.0.0'}

  color-name@1.1.4:
    resolution: {integrity: sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==}

  comma-separated-tokens@1.0.8:
    resolution: {integrity: sha512-GHuDRO12Sypu2cV70d1dkA2EUmXHgntrzbpvOB+Qy+49ypNfGgFQIC2fhhXbnyrJRynDCAARsT7Ou0M6hirpfw==}

  comma-separated-tokens@2.0.3:
    resolution: {integrity: sha512-Fu4hJdvzeylCfQPp9SGWidpzrMs7tTrlu6Vb8XGaRGck8QSNZJJp538Wrb60Lax4fPwR64ViY468OIUTbRlGZg==}

  commander@4.1.1:
    resolution: {integrity: sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==}
    engines: {node: '>= 6'}

  commander@7.2.0:
    resolution: {integrity: sha512-QrWXB+ZQSVPmIWIhtEO9H+gwHaMGYiF5ChvoJ+K9ZGHG/sVsa6yiesAD1GC/x46sET00Xlwo1u49RVVVzvcSkw==}
    engines: {node: '>= 10'}

  commander@8.3.0:
    resolution: {integrity: sha512-OkTL9umf+He2DZkUq8f8J9of7yL6RJKI24dVITBmNfZBmri9zYZQrKkuXiKhyfPSu8tUhnVBB1iKXevvnlR4Ww==}
    engines: {node: '>= 12'}

  compute-scroll-into-view@3.1.0:
    resolution: {integrity: sha512-rj8l8pD4bJ1nx+dAkMhV1xB5RuZEyVysfxJqB1pRchh1KVvwOv9b7CGB8ZfjTImVv2oF+sYMUkMZq6Na5Ftmbg==}

  confbox@0.1.7:
    resolution: {integrity: sha512-uJcB/FKZtBMCJpK8MQji6bJHgu1tixKPxRLeGkNzBoOZzpnZUJm0jm2/sBDWcuBx1dYgxV4JU+g5hmNxCyAmdA==}

  cookie@0.7.0:
    resolution: {integrity: sha512-qCf+V4dtlNhSRXGAZatc1TasyFO6GjohcOul807YOb5ik3+kQSnb4d7iajeCL8QHaJ4uZEjCgiCJerKXwdRVlQ==}
    engines: {node: '>= 0.6'}

  core-js@3.38.1:
    resolution: {integrity: sha512-OP35aUorbU3Zvlx7pjsFdu1rGNnD4pgw/CWoYzRY3t2EzoVT7shKHY1dlAy3f41cGIO7ZDPQimhGFTlEYkG/Hw==}

  cose-base@1.0.3:
    resolution: {integrity: sha512-s9whTXInMSgAp/NVXVNuVxVKzGH2qck3aQlVHxDCdAEPgtMKwc4Wq6/QKhgdEdgbLSi9rBTAcPoRa6JpiG4ksg==}

  cose-base@2.2.0:
    resolution: {integrity: sha512-AzlgcsCbUMymkADOJtQm3wO9S3ltPfYOFD5033keQn9NJzIbtnZj+UdBJe7DYml/8TdbtHJW3j58SOnKhWY/5g==}

  cross-spawn@7.0.3:
    resolution: {integrity: sha512-iRDPJKUPVEND7dHPO8rkbOnPpyDygcDFtWjpeWNCgy8WP2rXcxXL8TskReQl6OrB2G7+UJrags1q15Fudc7G6w==}
    engines: {node: '>= 8'}

  crypto-js@4.2.0:
    resolution: {integrity: sha512-KALDyEYgpY+Rlob/iriUtjV6d5Eq+Y191A5g4UqLAi8CyGP9N1+FdVbkc1SxKc2r4YAYqG8JzO2KGL+AizD70Q==}

  cssesc@3.0.0:
    resolution: {integrity: sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==}
    engines: {node: '>=4'}
    hasBin: true

  csstype@3.1.1:
    resolution: {integrity: sha512-DJR/VvkAvSZW9bTouZue2sSxDwdTN92uHjqeKVm+0dAqdfNykRzQ95tay8aXMBAAPpUiq4Qcug2L7neoRh2Egw==}

  csstype@3.1.3:
    resolution: {integrity: sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==}

  cytoscape-cose-bilkent@4.1.0:
    resolution: {integrity: sha512-wgQlVIUJF13Quxiv5e1gstZ08rnZj2XaLHGoFMYXz7SkNfCDOOteKBE6SYRfA9WxxI/iBc3ajfDoc6hb/MRAHQ==}
    peerDependencies:
      cytoscape: ^3.2.0

  cytoscape-fcose@2.2.0:
    resolution: {integrity: sha512-ki1/VuRIHFCzxWNrsshHYPs6L7TvLu3DL+TyIGEsRcvVERmxokbf5Gdk7mFxZnTdiGtnA4cfSmjZJMviqSuZrQ==}
    peerDependencies:
      cytoscape: ^3.2.0

  cytoscape@3.30.2:
    resolution: {integrity: sha512-oICxQsjW8uSaRmn4UK/jkczKOqTrVqt5/1WL0POiJUT2EKNc9STM4hYFHv917yu55aTBMFNRzymlJhVAiWPCxw==}
    engines: {node: '>=0.10'}

  d3-array@2.12.1:
    resolution: {integrity: sha512-B0ErZK/66mHtEsR1TkPEEkwdy+WDesimkM5gpZr5Dsg54BiTA5RXtYW5qTLIAcekaS9xfZrzBLF/OAkB3Qn1YQ==}

  d3-array@3.2.4:
    resolution: {integrity: sha512-tdQAmyA18i4J7wprpYq8ClcxZy3SC31QMeByyCFyRt7BVHdREQZ5lpzoe5mFEYZUWe+oq8HBvk9JjpibyEV4Jg==}
    engines: {node: '>=12'}

  d3-axis@3.0.0:
    resolution: {integrity: sha512-IH5tgjV4jE/GhHkRV0HiVYPDtvfjHQlQfJHs0usq7M30XcSBvOotpmH1IgkcXsO/5gEQZD43B//fc7SRT5S+xw==}
    engines: {node: '>=12'}

  d3-brush@3.0.0:
    resolution: {integrity: sha512-ALnjWlVYkXsVIGlOsuWH1+3udkYFI48Ljihfnh8FZPF2QS9o+PzGLBslO0PjzVoHLZ2KCVgAM8NVkXPJB2aNnQ==}
    engines: {node: '>=12'}

  d3-chord@3.0.1:
    resolution: {integrity: sha512-VE5S6TNa+j8msksl7HwjxMHDM2yNK3XCkusIlpX5kwauBfXuyLAtNg9jCp/iHH61tgI4sb6R/EIMWCqEIdjT/g==}
    engines: {node: '>=12'}

  d3-color@3.1.0:
    resolution: {integrity: sha512-zg/chbXyeBtMQ1LbD/WSoW2DpC3I0mpmPdW+ynRTj/x2DAWYrIY7qeZIHidozwV24m4iavr15lNwIwLxRmOxhA==}
    engines: {node: '>=12'}

  d3-contour@4.0.2:
    resolution: {integrity: sha512-4EzFTRIikzs47RGmdxbeUvLWtGedDUNkTcmzoeyg4sP/dvCexO47AaQL7VKy/gul85TOxw+IBgA8US2xwbToNA==}
    engines: {node: '>=12'}

  d3-delaunay@6.0.4:
    resolution: {integrity: sha512-mdjtIZ1XLAM8bm/hx3WwjfHt6Sggek7qH043O8KEjDXN40xi3vx/6pYSVTwLjEgiXQTbvaouWKynLBiUZ6SK6A==}
    engines: {node: '>=12'}

  d3-dispatch@3.0.1:
    resolution: {integrity: sha512-rzUyPU/S7rwUflMyLc1ETDeBj0NRuHKKAcvukozwhshr6g6c5d8zh4c2gQjY2bZ0dXeGLWc1PF174P2tVvKhfg==}
    engines: {node: '>=12'}

  d3-drag@3.0.0:
    resolution: {integrity: sha512-pWbUJLdETVA8lQNJecMxoXfH6x+mO2UQo8rSmZ+QqxcbyA3hfeprFgIT//HW2nlHChWeIIMwS2Fq+gEARkhTkg==}
    engines: {node: '>=12'}

  d3-dsv@3.0.1:
    resolution: {integrity: sha512-UG6OvdI5afDIFP9w4G0mNq50dSOsXHJaRE8arAS5o9ApWnIElp8GZw1Dun8vP8OyHOZ/QJUKUJwxiiCCnUwm+Q==}
    engines: {node: '>=12'}
    hasBin: true

  d3-ease@3.0.1:
    resolution: {integrity: sha512-wR/XK3D3XcLIZwpbvQwQ5fK+8Ykds1ip7A2Txe0yxncXSdq1L9skcG7blcedkOX+ZcgxGAmLX1FrRGbADwzi0w==}
    engines: {node: '>=12'}

  d3-fetch@3.0.1:
    resolution: {integrity: sha512-kpkQIM20n3oLVBKGg6oHrUchHM3xODkTzjMoj7aWQFq5QEM+R6E4WkzT5+tojDY7yjez8KgCBRoj4aEr99Fdqw==}
    engines: {node: '>=12'}

  d3-force@3.0.0:
    resolution: {integrity: sha512-zxV/SsA+U4yte8051P4ECydjD/S+qeYtnaIyAs9tgHCqfguma/aAQDjo85A9Z6EKhBirHRJHXIgJUlffT4wdLg==}
    engines: {node: '>=12'}

  d3-format@3.1.0:
    resolution: {integrity: sha512-YyUI6AEuY/Wpt8KWLgZHsIU86atmikuoOmCfommt0LYHiQSPjvX2AcFc38PX0CBpr2RCyZhjex+NS/LPOv6YqA==}
    engines: {node: '>=12'}

  d3-geo@3.1.1:
    resolution: {integrity: sha512-637ln3gXKXOwhalDzinUgY83KzNWZRKbYubaG+fGVuc/dxO64RRljtCTnf5ecMyE1RIdtqpkVcq0IbtU2S8j2Q==}
    engines: {node: '>=12'}

  d3-hierarchy@3.1.2:
    resolution: {integrity: sha512-FX/9frcub54beBdugHjDCdikxThEqjnR93Qt7PvQTOHxyiNCAlvMrHhclk3cD5VeAaq9fxmfRp+CnWw9rEMBuA==}
    engines: {node: '>=12'}

  d3-interpolate@3.0.1:
    resolution: {integrity: sha512-3bYs1rOD33uo8aqJfKP3JWPAibgw8Zm2+L9vBKEHJ2Rg+viTR7o5Mmv5mZcieN+FRYaAOWX5SJATX6k1PWz72g==}
    engines: {node: '>=12'}

  d3-path@1.0.9:
    resolution: {integrity: sha512-VLaYcn81dtHVTjEHd8B+pbe9yHWpXKZUC87PzoFmsFrJqgFwDe/qxfp5MlfsfM1V5E/iVt0MmEbWQ7FVIXh/bg==}

  d3-path@3.1.0:
    resolution: {integrity: sha512-p3KP5HCf/bvjBSSKuXid6Zqijx7wIfNW+J/maPs+iwR35at5JCbLUT0LzF1cnjbCHWhqzQTIN2Jpe8pRebIEFQ==}
    engines: {node: '>=12'}

  d3-polygon@3.0.1:
    resolution: {integrity: sha512-3vbA7vXYwfe1SYhED++fPUQlWSYTTGmFmQiany/gdbiWgU/iEyQzyymwL9SkJjFFuCS4902BSzewVGsHHmHtXg==}
    engines: {node: '>=12'}

  d3-quadtree@3.0.1:
    resolution: {integrity: sha512-04xDrxQTDTCFwP5H6hRhsRcb9xxv2RzkcsygFzmkSIOJy3PeRJP7sNk3VRIbKXcog561P9oU0/rVH6vDROAgUw==}
    engines: {node: '>=12'}

  d3-random@3.0.1:
    resolution: {integrity: sha512-FXMe9GfxTxqd5D6jFsQ+DJ8BJS4E/fT5mqqdjovykEB2oFbTMDVdg1MGFxfQW+FBOGoB++k8swBrgwSHT1cUXQ==}
    engines: {node: '>=12'}

  d3-sankey@0.12.3:
    resolution: {integrity: sha512-nQhsBRmM19Ax5xEIPLMY9ZmJ/cDvd1BG3UVvt5h3WRxKg5zGRbvnteTyWAbzeSvlh3tW7ZEmq4VwR5mB3tutmQ==}

  d3-scale-chromatic@3.1.0:
    resolution: {integrity: sha512-A3s5PWiZ9YCXFye1o246KoscMWqf8BsD9eRiJ3He7C9OBaxKhAd5TFCdEx/7VbKtxxTsu//1mMJFrEt572cEyQ==}
    engines: {node: '>=12'}

  d3-scale@4.0.2:
    resolution: {integrity: sha512-GZW464g1SH7ag3Y7hXjf8RoUuAFIqklOAq3MRl4OaWabTFJY9PN/E1YklhXLh+OQ3fM9yS2nOkCoS+WLZ6kvxQ==}
    engines: {node: '>=12'}

  d3-selection@3.0.0:
    resolution: {integrity: sha512-fmTRWbNMmsmWq6xJV8D19U/gw/bwrHfNXxrIN+HfZgnzqTHp9jOmKMhsTUjXOJnZOdZY9Q28y4yebKzqDKlxlQ==}
    engines: {node: '>=12'}

  d3-shape@1.3.7:
    resolution: {integrity: sha512-EUkvKjqPFUAZyOlhY5gzCxCeI0Aep04LwIRpsZ/mLFelJiUfnK56jo5JMDSE7yyP2kLSb6LtF+S5chMk7uqPqw==}

  d3-shape@3.2.0:
    resolution: {integrity: sha512-SaLBuwGm3MOViRq2ABk3eLoxwZELpH6zhl3FbAoJ7Vm1gofKx6El1Ib5z23NUEhF9AsGl7y+dzLe5Cw2AArGTA==}
    engines: {node: '>=12'}

  d3-time-format@4.1.0:
    resolution: {integrity: sha512-dJxPBlzC7NugB2PDLwo9Q8JiTR3M3e4/XANkreKSUxF8vvXKqm1Yfq4Q5dl8budlunRVlUUaDUgFt7eA8D6NLg==}
    engines: {node: '>=12'}

  d3-time@3.1.0:
    resolution: {integrity: sha512-VqKjzBLejbSMT4IgbmVgDjpkYrNWUYJnbCGo874u7MMKIWsILRX+OpX/gTk8MqjpT1A/c6HY2dCA77ZN0lkQ2Q==}
    engines: {node: '>=12'}

  d3-timer@3.0.1:
    resolution: {integrity: sha512-ndfJ/JxxMd3nw31uyKoY2naivF+r29V+Lc0svZxe1JvvIRmi8hUsrMvdOwgS1o6uBHmiz91geQ0ylPP0aj1VUA==}
    engines: {node: '>=12'}

  d3-transition@3.0.1:
    resolution: {integrity: sha512-ApKvfjsSR6tg06xrL434C0WydLr7JewBB3V+/39RMHsaXTOG0zmt/OAXeng5M5LBm0ojmxJrpomQVZ1aPvBL4w==}
    engines: {node: '>=12'}
    peerDependencies:
      d3-selection: 2 - 3

  d3-zoom@3.0.0:
    resolution: {integrity: sha512-b8AmV3kfQaqWAuacbPuNbL6vahnOJflOhexLzMMNLga62+/nh0JzvJ0aO/5a5MVgUFGS7Hu1P9P03o3fJkDCyw==}
    engines: {node: '>=12'}

  d3@7.9.0:
    resolution: {integrity: sha512-e1U46jVP+w7Iut8Jt8ri1YsPOvFpg46k+K8TpCb0P+zjCkjkPnV7WzfDJzMHy1LnA+wj5pLT1wjO901gLXeEhA==}
    engines: {node: '>=12'}

  dagre-d3-es@7.0.10:
    resolution: {integrity: sha512-qTCQmEhcynucuaZgY5/+ti3X/rnszKZhEQH/ZdWdtP1tA/y3VoHJzcVrO9pjjJCNpigfscAtoUB5ONcd2wNn0A==}

  dayjs@1.11.13:
    resolution: {integrity: sha512-oaMBel6gjolK862uaPQOVTA7q3TZhuSvuMQAAglQDOWYO9A91IrAOUJEyKVlqJlHE0vq5p5UXxzdPfMH/x6xNg==}

  debug@2.6.9:
    resolution: {integrity: sha512-bC7ElrdJaJnPbAP+1EotYvqZsb3ecl5wi6Bfi6BJTUcNowp6cvspg0jXznRTKDjm/E7AdgFBVeAPVMNcKGsHMA==}
    peerDependencies:
      supports-color: '*'
    peerDependenciesMeta:
      supports-color:
        optional: true

  debug@4.3.7:
    resolution: {integrity: sha512-Er2nc/H7RrMXZBFCEim6TCmMk02Z8vLC2Rbi1KEBggpo0fS6l0S1nnapwmIi3yW/+GOJap1Krg4w0Hg80oCqgQ==}
    engines: {node: '>=6.0'}
    peerDependencies:
      supports-color: '*'
    peerDependenciesMeta:
      supports-color:
        optional: true

  decode-named-character-reference@1.0.2:
    resolution: {integrity: sha512-O8x12RzrUF8xyVcY0KJowWsmaJxQbmy0/EtnNtHRpsOcT7dFk5W598coHqBVpmWo1oQQfsCqfCmkZN5DJrZVdg==}

  delaunator@5.0.1:
    resolution: {integrity: sha512-8nvh+XBe96aCESrGOqMp/84b13H9cdKbG5P2ejQCh4d4sK9RL4371qou9drQjMhvnPmhWl5hnmqbEE0fXr9Xnw==}

  dequal@2.0.3:
    resolution: {integrity: sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==}
    engines: {node: '>=6'}

  detect-node-es@1.1.0:
    resolution: {integrity: sha512-ypdmJU/TbBby2Dxibuv7ZLW3Bs1QEmM7nHjEANfohJLvE0XVujisn1qPJcZxg+qDucsr+bP6fLD1rPS3AhJ7EQ==}

  devlop@1.1.0:
    resolution: {integrity: sha512-RWmIqhcFf1lRYBvNmr7qTNuyCt/7/ns2jbpp1+PalgE/rDQcBT0fioSMUpJ93irlUhC5hrg4cYqe6U+0ImW0rA==}

  didyoumean@1.2.2:
    resolution: {integrity: sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==}

  diff@5.2.0:
    resolution: {integrity: sha512-uIFDxqpRZGZ6ThOk84hEfqWoHx2devRFvpTZcTHur85vImfaxUbTW9Ryh4CpCuDnToOP1CEtXKIgytHBPVff5A==}
    engines: {node: '>=0.3.1'}

  dlv@1.1.3:
    resolution: {integrity: sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==}

  dompurify@3.1.6:
    resolution: {integrity: sha512-cTOAhc36AalkjtBpfG6O8JimdTMWNXjiePT2xQH/ppBGi/4uIpmj8eKyIkMJErXWARyINV/sB38yf8JCLF5pbQ==}

  dot-case@3.0.4:
    resolution: {integrity: sha512-Kv5nKlh6yRrdrGvxeJ2e5y2eRUpkUosIW4A2AS38zwSz27zu7ufDwQPi5Jhs3XAlGNetl3bmnGhQsMtkKJnj3w==}

  dset@3.1.4:
    resolution: {integrity: sha512-2QF/g9/zTaPDc3BjNcVTGoBbXBgYfMTTceLaYcFJ/W9kggFUkhxD/hMEeuLKbugyef9SqAx8cpgwlIP/jinUTA==}
    engines: {node: '>=4'}

  eastasianwidth@0.2.0:
    resolution: {integrity: sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==}

  electron-to-chromium@1.5.28:
    resolution: {integrity: sha512-VufdJl+rzaKZoYVUijN13QcXVF5dWPZANeFTLNy+OSpHdDL5ynXTF35+60RSBbaQYB1ae723lQXHCrf4pyLsMw==}

  emoji-regex@8.0.0:
    resolution: {integrity: sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==}

  emoji-regex@9.2.2:
    resolution: {integrity: sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==}

  esbuild@0.23.1:
    resolution: {integrity: sha512-VVNz/9Sa0bs5SELtn3f7qhJCDPCF5oMEl5cO9/SSinpE9hbPVvxbd572HH5AKiP7WD8INO53GgfDDhRjkylHEg==}
    engines: {node: '>=18'}
    hasBin: true

  escalade@3.2.0:
    resolution: {integrity: sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==}
    engines: {node: '>=6'}

  escape-string-regexp@5.0.0:
    resolution: {integrity: sha512-/veY75JbMK4j1yjvuUxuVsiS/hr/4iHs9FTT6cgTexxdE0Ly/glccBAkloH/DofkjRbZU3bnoj38mOmhkZ0lHw==}
    engines: {node: '>=12'}

  esprima@4.0.1:
    resolution: {integrity: sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==}
    engines: {node: '>=4'}
    hasBin: true

  estree-util-attach-comments@3.0.0:
    resolution: {integrity: sha512-cKUwm/HUcTDsYh/9FgnuFqpfquUbwIqwKM26BVCGDPVgvaCl/nDCCjUfiLlx6lsEZ3Z4RFxNbOQ60pkaEwFxGw==}

  estree-util-build-jsx@3.0.1:
    resolution: {integrity: sha512-8U5eiL6BTrPxp/CHbs2yMgP8ftMhR5ww1eIKoWRMlqvltHF8fZn5LRDvTKuxD3DUn+shRbLGqXemcP51oFCsGQ==}

  estree-util-is-identifier-name@3.0.0:
    resolution: {integrity: sha512-hFtqIDZTIUZ9BXLb8y4pYGyk6+wekIivNVTcmvk8NoOh+VeRn5y6cEHzbURrWbfp1fIqdVipilzj+lfaadNZmg==}

  estree-util-to-js@2.0.0:
    resolution: {integrity: sha512-WDF+xj5rRWmD5tj6bIqRi6CkLIXbbNQUcxQHzGysQzvHmdYG2G7p/Tf0J0gpxGgkeMZNTIjT/AoSvC9Xehcgdg==}

  estree-util-value-to-estree@3.1.2:
    resolution: {integrity: sha512-S0gW2+XZkmsx00tU2uJ4L9hUT7IFabbml9pHh2WQqFmAbxit++YGZne0sKJbNwkj9Wvg9E4uqWl4nCIFQMmfag==}

  estree-util-visit@2.0.0:
    resolution: {integrity: sha512-m5KgiH85xAhhW8Wta0vShLcUvOsh3LLPI2YVwcbio1l7E09NTLL1EyMZFM1OyWowoH0skScNbhOPl4kcBgzTww==}

  estree-walker@3.0.3:
    resolution: {integrity: sha512-7RUKfXgSMMkzt6ZuXmqapOurLGPPfgj6l9uRZ7lRGolvk0y2yocc35LdcxKC5PQZdn2DMqioAQ2NoWcrTKmm6g==}

  extend-shallow@2.0.1:
    resolution: {integrity: sha512-zCnTtlxNoAiDc3gqY2aYAWFx7XWWiasuF2K8Me5WbN8otHKTUKBwjPtNpRs/rbUZm7KxWAaNj7P1a/p52GbVug==}
    engines: {node: '>=0.10.0'}

  extend@3.0.2:
    resolution: {integrity: sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==}

  fast-deep-equal@3.1.3:
    resolution: {integrity: sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==}

  fast-glob@3.3.2:
    resolution: {integrity: sha512-oX2ruAFQwf/Orj8m737Y5adxDQO0LAB7/S5MnxCdTNDd4p6BsyIVsv9JQsATbTSq8KHRpLwIHbVlUNatxd+1Ow==}
    engines: {node: '>=8.6.0'}

  fastq@1.17.1:
    resolution: {integrity: sha512-sRVD3lWVIXWg6By68ZN7vho9a1pQcN/WBFaAAsDDFzlJjvoGx0P8z7V1t72grFJfJhu3YPZBuu25f7Kaw2jN1w==}

  fault@1.0.4:
    resolution: {integrity: sha512-CJ0HCB5tL5fYTEA7ToAq5+kTwd++Borf1/bifxd9iT70QcXr4MRrO3Llf8Ifs70q+SJcGHFtnIE/Nw6giCtECA==}

  fflate@0.4.8:
    resolution: {integrity: sha512-FJqqoDBR00Mdj9ppamLa/Y7vxm+PRmNWA67N846RvsoYVMKB4q3y/de5PA7gUmRMYK/8CMz2GDZQmCRN1wBcWA==}

  fill-range@7.1.1:
    resolution: {integrity: sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==}
    engines: {node: '>=8'}

  flexsearch@0.7.21:
    resolution: {integrity: sha512-W7cHV7Hrwjid6lWmy0IhsWDFQboWSng25U3VVywpHOTJnnAZNPScog67G+cVpeX9f7yDD21ih0WDrMMT+JoaYg==}

  foreground-child@3.3.0:
    resolution: {integrity: sha512-Ld2g8rrAyMYFXBhEqMz8ZAHBi4J4uS1i/CxGMDnjyFWddMXLVcDp051DZfu+t7+ab7Wv6SMqpWmyFIj5UbfFvg==}
    engines: {node: '>=14'}

  format@0.2.2:
    resolution: {integrity: sha512-wzsgA6WOq+09wrU1tsJ09udeR/YZRaeArL9e1wPbFg3GG2yDnC2ldKpxs4xunpFF9DgqCqOIra3bc1HWrJ37Ww==}
    engines: {node: '>=0.4.x'}

  fraction.js@4.3.7:
    resolution: {integrity: sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==}

  fsevents@2.3.3:
    resolution: {integrity: sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==}
    engines: {node: ^8.16.0 || ^10.6.0 || >=11.0.0}
    os: [darwin]

  fumadocs-core@13.4.10:
    resolution: {integrity: sha512-ygLVuWyeD2xTm//wPy5mAEDq+eiLc2mCyOSY7kwRYh2+ZfLruI8Sb7Hy7HfdYuzSaVYpAZ0mD+NGQSBunUiS7Q==}
    peerDependencies:
      next: '>= 14.1.0'
      react: '>= 18'
      react-dom: '>= 18'

  fumadocs-docgen@1.2.0:
    resolution: {integrity: sha512-w3V3h33hc4+GGTCaGcihDYwClvpr6eHWjdf59SifRY9i2VnpGnkTZu0A+G08JipnLTFhGFf/8t7UigDVglQm0w==}

  fumadocs-mdx@10.0.2:
    resolution: {integrity: sha512-kpM4QfLXF3CjqBCLsYySZNvXvKpDrqDCK7wobhoAbTTmzql2cGXBk+bkAogwjgW3sidGw9d/HIGOcB61R07QLA==}
    hasBin: true
    peerDependencies:
      fumadocs-core: ^13.2.1
      next: '>= 14.1.0'

  fumadocs-typescript@2.1.0:
    resolution: {integrity: sha512-fxxC8F+bQQxlVQA03vWaoztJFeKkevW3WgT7ECPCmdOB2UFsRB61cgzlRvwKqtFWJuJYASX55+2wEMxXAjzBjQ==}
    peerDependencies:
      typescript: '*'

  fumadocs-ui@13.4.10:
    resolution: {integrity: sha512-aHN9sUHwKTSu+37bxx8KDbMNGolG5iNsKdvK40VKiTbNz5p495uzui8aLPGKTV96TS53oPQzPdk6YoCqWZTE+A==}
    peerDependencies:
      next: '>= 14.1.0'
      react: '>= 18'
      react-dom: '>= 18'

  function-bind@1.1.2:
    resolution: {integrity: sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==}

  get-nonce@1.0.1:
    resolution: {integrity: sha512-FJhYRoDaiatfEkUK8HKlicmu/3SGFD51q3itKDGoSTysQJBnfOcxU5GxnhE1E6soB76MbT0MBtnKJuXyAx+96Q==}
    engines: {node: '>=6'}

  github-slugger@2.0.0:
    resolution: {integrity: sha512-IaOQ9puYtjrkq7Y0Ygl9KDZnrf/aiUJYUpVf89y8kyaxbRG7Y1SrX/jaumrv81vc61+kiMempujsM3Yw7w5qcw==}

  glob-parent@5.1.2:
    resolution: {integrity: sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==}
    engines: {node: '>= 6'}

  glob-parent@6.0.2:
    resolution: {integrity: sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==}
    engines: {node: '>=10.13.0'}

  glob-to-regexp@0.4.1:
    resolution: {integrity: sha512-lkX1HJXwyMcprw/5YUZc2s7DrpAiHB21/V+E1rHUrVNokkvB6bqMzT0VfV6/86ZNabt1k14YOIaT7nDvOX3Iiw==}

  glob@10.4.5:
    resolution: {integrity: sha512-7Bv8RF0k6xjo7d4A/PxYLbUCfb6c+Vpd2/mB2yRDlew7Jb5hEXiCD9ibfO7wpk8i4sevK6DFny9h7EYbM3/sHg==}
    hasBin: true

  graceful-fs@4.2.11:
    resolution: {integrity: sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==}

  graphql@16.10.0:
    resolution: {integrity: sha512-AjqGKbDGUFRKIRCP9tCKiIGHyriz2oHEbPIbEtcSLSs4YjReZOIPQQWek4+6hjw62H9QShXHyaGivGiYVLeYFQ==}
    engines: {node: ^12.22.0 || ^14.16.0 || ^16.0.0 || >=17.0.0}

  gray-matter@4.0.3:
    resolution: {integrity: sha512-5v6yZd4JK3eMI3FqqCouswVqwugaA9r4dNZB1wwcmrD02QkV5H0y7XBQW8QwQqEaZY1pM9aqORSORhJRdNK44Q==}
    engines: {node: '>=6.0'}

  hachure-fill@0.5.2:
    resolution: {integrity: sha512-3GKBOn+m2LX9iq+JC1064cSFprJY4jL1jCXTcpnfER5HYE2l/4EfWSGzkPa/ZDBmYI0ZOEj5VHV/eKnPGkHuOg==}

  has-flag@4.0.0:
    resolution: {integrity: sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==}
    engines: {node: '>=8'}

  hasown@2.0.2:
    resolution: {integrity: sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==}
    engines: {node: '>= 0.4'}

  hast-util-parse-selector@2.2.5:
    resolution: {integrity: sha512-7j6mrk/qqkSehsM92wQjdIgWM2/BW61u/53G6xmC8i1OmEdKLHbk419QKQUjz6LglWsfqoiHmyMRkP1BGjecNQ==}

  hast-util-to-estree@3.1.0:
    resolution: {integrity: sha512-lfX5g6hqVh9kjS/B9E2gSkvHH4SZNiQFiqWS0x9fENzEl+8W12RqdRxX6d/Cwxi30tPQs3bIO+aolQJNp1bIyw==}

  hast-util-to-html@9.0.3:
    resolution: {integrity: sha512-M17uBDzMJ9RPCqLMO92gNNUDuBSq10a25SDBI08iCCxmorf4Yy6sYHK57n9WAbRAAaU+DuR4W6GN9K4DFZesYg==}

  hast-util-to-jsx-runtime@2.3.0:
    resolution: {integrity: sha512-H/y0+IWPdsLLS738P8tDnrQ8Z+dj12zQQ6WC11TIM21C8WFVoIxcqWXf2H3hiTVZjF1AWqoimGwrTWecWrnmRQ==}

  hast-util-to-string@3.0.0:
    resolution: {integrity: sha512-OGkAxX1Ua3cbcW6EJ5pT/tslVb90uViVkcJ4ZZIMW/R33DX/AkcJcRrPebPwJkHYwlDHXz4aIwvAAaAdtrACFA==}

  hast-util-whitespace@2.0.1:
    resolution: {integrity: sha512-nAxA0v8+vXSBDt3AnRUNjyRIQ0rD+ntpbAp4LnPkumc5M9yUbSMa4XDU9Q6etY4f1Wp4bNgvc1yjiZtsTTrSng==}

  hast-util-whitespace@3.0.0:
    resolution: {integrity: sha512-88JUN06ipLwsnv+dVn+OIYOvAuvBMy/Qoi6O7mQHxdPXpjy+Cd6xRkWwux7DKO+4sYILtLBRIKgsdpS2gQc7qw==}

  hastscript@6.0.0:
    resolution: {integrity: sha512-nDM6bvd7lIqDUiYEiu5Sl/+6ReP0BMk/2f4U/Rooccxkj0P5nm+acM5PrGJ/t5I8qPGiqZSE6hVAwZEdZIvP4w==}

  highlight.js@10.7.3:
    resolution: {integrity: sha512-tzcUFauisWKNHaRkN4Wjl/ZA07gENAjFl3J/c480dprkGTg5EQstgaNFqBfUqCq54kZRIEcreTsAgF/m2quD7A==}

  highlightjs-vue@1.0.0:
    resolution: {integrity: sha512-PDEfEF102G23vHmPhLyPboFCD+BkMGu+GuJe2d9/eH4FsCwvgBpnc9n0pGE+ffKdph38s6foEZiEjdgHdzp+IA==}

  html-void-elements@3.0.0:
    resolution: {integrity: sha512-bEqo66MRXsUGxWHV5IP0PUiAWwoEjba4VCzg0LjFJBpchPaTfyfCKTG6bc5F8ucKec3q5y6qOdGyYTSBEvhCrg==}

  husky@9.1.6:
    resolution: {integrity: sha512-sqbjZKK7kf44hfdE94EoX8MZNk0n7HeW37O4YrVGCF4wzgQjp+akPAkfUK5LZ6KuR/6sqeAVuXHji+RzQgOn5A==}
    engines: {node: '>=18'}
    hasBin: true

  iconv-lite@0.6.3:
    resolution: {integrity: sha512-4fCk79wshMdzMp2rH06qWrJE4iolqLhCUH+OiuIgU++RB0+94NlDL81atO7GX55uUKueo0txHNtvEyI6D7WdMw==}
    engines: {node: '>=0.10.0'}

  ieee754@1.2.1:
    resolution: {integrity: sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA==}

  image-size@1.1.1:
    resolution: {integrity: sha512-541xKlUw6jr/6gGuk92F+mYM5zaFAc5ahphvkqvNe2bQ6gVBkd6bfrmVJ2t4KDAfikAYZyIqTnktX3i6/aQDrQ==}
    engines: {node: '>=16.x'}
    hasBin: true

  inherits@2.0.4:
    resolution: {integrity: sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==}

  inline-style-parser@0.1.1:
    resolution: {integrity: sha512-7NXolsK4CAS5+xvdj5OMMbI962hU/wvwoxk+LWR9Ek9bVtyuuYScDN6eS0rUm6TxApFpw7CX1o4uJzcd4AyD3Q==}

  inline-style-parser@0.2.4:
    resolution: {integrity: sha512-0aO8FkhNZlj/ZIbNi7Lxxr12obT7cL1moPfE4tg1LkX7LlLfC6DeX4l2ZEud1ukP9jNQyNnfzQVqwbwmAATY4Q==}

  internmap@1.0.1:
    resolution: {integrity: sha512-lDB5YccMydFBtasVtxnZ3MRBHuaoE8GKsppq+EchKL2U4nK/DmEpPHNH8MZe5HkMtpSiTSOZwfN0tzYjO/lJEw==}

  internmap@2.0.3:
    resolution: {integrity: sha512-5Hh7Y1wQbvY5ooGgPbDaL5iYLAPzMTUrjMulskHLH6wnv/A+1q5rgEaiuqEjB+oxGXIVZs1FF+R/KPN3ZSQYYg==}
    engines: {node: '>=12'}

  invariant@2.2.4:
    resolution: {integrity: sha512-phJfQVBuaJM5raOpJjSfkiD6BpbCE4Ns//LaXl6wGYtUBY83nWS6Rf9tXm2e8VaK60JEjYldbPif/A2B1C2gNA==}

  is-alphabetical@1.0.4:
    resolution: {integrity: sha512-DwzsA04LQ10FHTZuL0/grVDk4rFoVH1pjAToYwBrHSxcrBIGQuXrQMtD5U1b0U2XVgKZCTLLP8u2Qxqhy3l2Vg==}

  is-alphabetical@2.0.1:
    resolution: {integrity: sha512-FWyyY60MeTNyeSRpkM2Iry0G9hpr7/9kD40mD/cGQEuilcZYS4okz8SN2Q6rLCJ8gbCt6fN+rC+6tMGS99LaxQ==}

  is-alphanumerical@1.0.4:
    resolution: {integrity: sha512-UzoZUr+XfVz3t3v4KyGEniVL9BDRoQtY7tOyrRybkVNjDFWyo1yhXNGrrBTQxp3ib9BLAWs7k2YKBQsFRkZG9A==}

  is-alphanumerical@2.0.1:
    resolution: {integrity: sha512-hmbYhX/9MUMF5uh7tOXyK/n0ZvWpad5caBA17GsC6vyuCqaWliRG5K1qS9inmUhEMaOBIW7/whAnSwveW/LtZw==}

  is-binary-path@2.1.0:
    resolution: {integrity: sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==}
    engines: {node: '>=8'}

  is-buffer@2.0.5:
    resolution: {integrity: sha512-i2R6zNFDwgEHJyQUtJEk0XFi1i0dPFn/oqjK3/vPCcDeJvW5NQ83V8QbicfF1SupOaB0h8ntgBC2YiE7dfyctQ==}
    engines: {node: '>=4'}

  is-core-module@2.15.1:
    resolution: {integrity: sha512-z0vtXSwucUJtANQWldhbtbt7BnL0vxiFjIdDLAatwhDYty2bad6s+rijD6Ri4YuYJubLzIJLUidCh09e1djEVQ==}
    engines: {node: '>= 0.4'}

  is-decimal@1.0.4:
    resolution: {integrity: sha512-RGdriMmQQvZ2aqaQq3awNA6dCGtKpiDFcOzrTWrDAT2MiWrKQVPmxLGHl7Y2nNu6led0kEyoX0enY0qXYsv9zw==}

  is-decimal@2.0.1:
    resolution: {integrity: sha512-AAB9hiomQs5DXWcRB1rqsxGUstbRroFOPPVAomNk/3XHR5JyEZChOyTWe2oayKnsSsr/kcGqF+z6yuH6HHpN0A==}

  is-extendable@0.1.1:
    resolution: {integrity: sha512-5BMULNob1vgFX6EjQw5izWDxrecWK9AM72rugNr0TFldMOi0fj6Jk+zeKIt0xGj4cEfQIJth4w3OKWOJ4f+AFw==}
    engines: {node: '>=0.10.0'}

  is-extglob@2.1.1:
    resolution: {integrity: sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==}
    engines: {node: '>=0.10.0'}

  is-fullwidth-code-point@3.0.0:
    resolution: {integrity: sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==}
    engines: {node: '>=8'}

  is-glob@4.0.3:
    resolution: {integrity: sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==}
    engines: {node: '>=0.10.0'}

  is-hexadecimal@1.0.4:
    resolution: {integrity: sha512-gyPJuv83bHMpocVYoqof5VDiZveEoGoFL8m3BXNb2VW8Xs+rz9kqO8LOQ5DH6EsuvilT1ApazU0pyl+ytbPtlw==}

  is-hexadecimal@2.0.1:
    resolution: {integrity: sha512-DgZQp241c8oO6cA1SbTEWiXeoxV42vlcJxgH+B3hi1AiqqKruZR3ZGF8In3fj4+/y/7rHvlOZLZtgJ/4ttYGZg==}

  is-number@7.0.0:
    resolution: {integrity: sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==}
    engines: {node: '>=0.12.0'}

  is-plain-obj@4.1.0:
    resolution: {integrity: sha512-+Pgi+vMuUNkJyExiMBt5IlFoMyKnr5zhJ4Uspz58WOhBF5QoIZkFyNHIbBAtHwzVAgk5RtndVNsDRN61/mmDqg==}
    engines: {node: '>=12'}

  is-reference@3.0.2:
    resolution: {integrity: sha512-v3rht/LgVcsdZa3O2Nqs+NMowLOxeOm7Ay9+/ARQ2F+qEoANRcqrjAZKGN0v8ymUetZGgkp26LTnGT7H0Qo9Pg==}

  isexe@2.0.0:
    resolution: {integrity: sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==}

  jackspeak@3.4.3:
    resolution: {integrity: sha512-OGlZQpz2yfahA/Rd1Y8Cd9SIEsqvXkLVoSw/cgwhnhFMDbsQFeZYoJJ7bIZBS9BcamUW96asq/npPWugM+RQBw==}

  jiti@1.21.6:
    resolution: {integrity: sha512-2yTgeWTWzMWkHu6Jp9NKgePDaYHbntiwvYuuJLbbN9vl7DC9DvXKOB2BC3ZZ92D3cvV/aflH0osDfwpHepQ53w==}
    hasBin: true

  jose@5.10.0:
    resolution: {integrity: sha512-s+3Al/p9g32Iq+oqXxkW//7jk2Vig6FF1CFqzVXoTUXt2qz89YWbL+OwS17NFYEvxC35n0FKeGO2LGYSxeM2Gg==}

  js-cookie@3.0.5:
    resolution: {integrity: sha512-cEiJEAEoIbWfCZYKWhVwFuvPX1gETRYPw6LlaTKoxD3s2AkXzkCjnp6h0V77ozyqj0jakteJ4YqDJT830+lVGw==}
    engines: {node: '>=14'}

  js-tokens@4.0.0:
    resolution: {integrity: sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==}

  js-yaml@3.14.1:
    resolution: {integrity: sha512-okMH7OXXJ7YrN9Ok3/SXrnu4iX9yOk+25nqX4imS2npuvTYDmo/QEZoqwZkYaIDk3jVvBOTOIEgEhaLOynBS9g==}
    hasBin: true

  katex@0.16.11:
    resolution: {integrity: sha512-RQrI8rlHY92OLf3rho/Ts8i/XvjgguEjOkO1BEXcU3N8BqPpSzBNwV/G0Ukr+P/l3ivvJUE/Fa/CwbS6HesGNQ==}
    hasBin: true

  khroma@2.1.0:
    resolution: {integrity: sha512-Ls993zuzfayK269Svk9hzpeGUKob/sIgZzyHYdjQoAdQetRKpOLj+k/QQQ/6Qi0Yz65mlROrfd+Ev+1+7dz9Kw==}

  kind-of@6.0.3:
    resolution: {integrity: sha512-dcS1ul+9tmeD95T+x28/ehLgd9mENa3LsvDTtzm3vyBEO7RPptvAD+t44WVXaUjTBRcrpFeFlC8WCruUR456hw==}
    engines: {node: '>=0.10.0'}

  kleur@4.1.5:
    resolution: {integrity: sha512-o+NO+8WrRiQEE4/7nwRJhN1HWpVmJm511pBHUxPLtp0BUISzlBplORYSmTclCnJvQq2tKu/sgl3xVpkc7ZWuQQ==}
    engines: {node: '>=6'}

  kolorist@1.8.0:
    resolution: {integrity: sha512-Y+60/zizpJ3HRH8DCss+q95yr6145JXZo46OTpFvDZWLfRCE4qChOyk1b26nMaNpfHHgxagk9dXT5OP0Tfe+dQ==}

  langium@3.0.0:
    resolution: {integrity: sha512-+Ez9EoiByeoTu/2BXmEaZ06iPNXM6thWJp02KfBO/raSMyCJ4jw7AkWWa+zBCTm0+Tw1Fj9FOxdqSskyN5nAwg==}
    engines: {node: '>=16.0.0'}

  layout-base@1.0.2:
    resolution: {integrity: sha512-8h2oVEZNktL4BH2JCOI90iD1yXwL6iNW7KcCKT2QZgQJR2vbqDsldCTPRU9NifTCqHZci57XvQQ15YTu+sTYPg==}

  layout-base@2.0.1:
    resolution: {integrity: sha512-dp3s92+uNI1hWIpPGH3jK2kxE2lMjdXdr+DH8ynZHpd6PUlH6x6cbuXnoMmiNumznqaNO31xu9e79F0uuZ0JFg==}

  lilconfig@2.1.0:
    resolution: {integrity: sha512-utWOt/GHzuUxnLKxB6dk81RoOeoNeHgbrXiuGk4yyF5qlRz+iIVWu56E2fqGHFrXz0QNUhLB/8nKqvRH66JKGQ==}
    engines: {node: '>=10'}

  lilconfig@3.1.2:
    resolution: {integrity: sha512-eop+wDAvpItUys0FWkHIKeC9ybYrTGbU41U5K7+bttZZeohvnY7M9dZ5kB21GNWiFT2q1OoPTvncPCgSOVO5ow==}
    engines: {node: '>=14'}

  lines-and-columns@1.2.4:
    resolution: {integrity: sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==}

  load-script@1.0.0:
    resolution: {integrity: sha512-kPEjMFtZvwL9TaZo0uZ2ml+Ye9HUMmPwbYRJ324qF9tqMejwykJ5ggTyvzmrbBeapCAbk98BSbTeovHEEP1uCA==}

  local-pkg@0.5.0:
    resolution: {integrity: sha512-ok6z3qlYyCDS4ZEU27HaU6x/xZa9Whf8jD4ptH5UZTQYZVYeb9bnZ3ojVhiJNLiXK1Hfc0GNbLXcmZ5plLDDBg==}
    engines: {node: '>=14'}

  lodash-es@4.17.21:
    resolution: {integrity: sha512-mKnC+QJ9pWVzv+C4/U3rRsHapFfHvQFoFB92e52xeyGMcX6/OlIl78je1u8vePzYZSkkogMPJ2yjxxsb89cxyw==}

  lodash.castarray@4.4.0:
    resolution: {integrity: sha512-aVx8ztPv7/2ULbArGJ2Y42bG1mEQ5mGjpdvrbJcJFU3TbYybe+QlLS4pst9zV52ymy2in1KpFPiZnAOATxD4+Q==}

  lodash.debounce@4.0.8:
    resolution: {integrity: sha512-FT1yDzDYEoYWhnSGnpE/4Kj1fLZkDFyqRb7fNt6FdYOSxlUWAtp42Eh6Wb0rGIv/m9Bgo7x4GhQbm5Ys4SG5ow==}

  lodash.isplainobject@4.0.6:
    resolution: {integrity: sha512-oSXzaWypCMHkPC3NvBEaPHf0KsA5mvPrOPgQWDsbg8n7orZ290M0BmC/jgRZ4vcJ6DTAhjrsSYgdsW/F+MFOBA==}

  lodash.merge@4.6.2:
    resolution: {integrity: sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==}

  longest-streak@3.1.0:
    resolution: {integrity: sha512-9Ri+o0JYgehTaVBBDoMqIl8GXtbWg711O3srftcHhZ0dqnETqLaoIK0x17fUw9rFSlK/0NlsKe0Ahhyl5pXE2g==}

  loose-envify@1.4.0:
    resolution: {integrity: sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==}
    hasBin: true

  lower-case@2.0.2:
    resolution: {integrity: sha512-7fm3l3NAF9WfN6W3JOmf5drwpVqX78JtoGJ3A6W0a6ZnldM41w2fV5D490psKFTpMds8TJse/eHLFFsNHHjHgg==}

  lowlight@1.20.0:
    resolution: {integrity: sha512-8Ktj+prEb1RoCPkEOrPMYUN/nCggB7qAWe3a7OpMjWQkh3l2RD5wKRQ+o8Q8YuI9RG/xs95waaI/E6ym/7NsTw==}

  lru-cache@10.4.3:
    resolution: {integrity: sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==}

  lucide-react@0.438.0:
    resolution: {integrity: sha512-uq6yCB+IzVfgIPMK8ibkecXSWTTSOMs9UjUgZigfrDCVqgdwkpIgYg1fSYnf0XXF2AoSyCJZhoZXQwzoai7VGw==}
    peerDependencies:
      react: ^16.5.1 || ^17.0.0 || ^18.0.0 || ^19.0.0-rc

  lucide-react@0.446.0:
    resolution: {integrity: sha512-BU7gy8MfBMqvEdDPH79VhOXSEgyG8TSPOKWaExWGCQVqnGH7wGgDngPbofu+KdtVjPQBWbEmnfMTq90CTiiDRg==}
    peerDependencies:
      react: ^16.5.1 || ^17.0.0 || ^18.0.0 || ^19.0.0-rc

  map-obj@4.3.0:
    resolution: {integrity: sha512-hdN1wVrZbb29eBGiGjJbeP8JbKjq1urkHJ/LIP/NY48MZ1QVXUsQBV1G1zvYFHn1XE06cwjBsOI2K3Ulnj1YXQ==}
    engines: {node: '>=8'}

  markdown-extensions@2.0.0:
    resolution: {integrity: sha512-o5vL7aDWatOTX8LzaS1WMoaoxIiLRQJuIKKe2wAw6IeULDHaqbiqiggmx+pKvZDb1Sj+pE46Sn1T7lCqfFtg1Q==}
    engines: {node: '>=16'}

  markdown-table@3.0.3:
    resolution: {integrity: sha512-Z1NL3Tb1M9wH4XESsCDEksWoKTdlUafKc4pt0GRwjUyXaCFZ+dc3g2erqB6zm3szA2IUSi7VnPI+o/9jnxh9hw==}

  marked@13.0.3:
    resolution: {integrity: sha512-rqRix3/TWzE9rIoFGIn8JmsVfhiuC8VIQ8IdX5TfzmeBucdY05/0UlzKaw0eVtpcN/OdVFpBk7CjKGo9iHJ/zA==}
    engines: {node: '>= 18'}
    hasBin: true

  mdast-util-definitions@5.1.2:
    resolution: {integrity: sha512-8SVPMuHqlPME/z3gqVwWY4zVXn8lqKv/pAhC57FuJ40ImXyBpmO5ukh98zB2v7Blql2FiHjHv9LVztSIqjY+MA==}

  mdast-util-find-and-replace@2.2.2:
    resolution: {integrity: sha512-MTtdFRz/eMDHXzeK6W3dO7mXUlF82Gom4y0oOgvHhh/HXZAGvIQDUvQ0SuUx+j2tv44b8xTHOm8K/9OoRFnXKw==}

  mdast-util-find-and-replace@3.0.1:
    resolution: {integrity: sha512-SG21kZHGC3XRTSUhtofZkBzZTJNM5ecCi0SK2IMKmSXR8vO3peL+kb1O0z7Zl83jKtutG4k5Wv/W7V3/YHvzPA==}

  mdast-util-from-markdown@1.3.1:
    resolution: {integrity: sha512-4xTO/M8c82qBcnQc1tgpNtubGUW/Y1tBQ1B0i5CtSoelOLKFYlElIr3bvgREYYO5iRqbMY1YuqZng0GVOI8Qww==}

  mdast-util-from-markdown@2.0.1:
    resolution: {integrity: sha512-aJEUyzZ6TzlsX2s5B4Of7lN7EQtAxvtradMMglCQDyaTFgse6CmtmdJ15ElnVRlCg1vpNyVtbem0PWzlNieZsA==}

  mdast-util-gfm-autolink-literal@1.0.3:
    resolution: {integrity: sha512-My8KJ57FYEy2W2LyNom4n3E7hKTuQk/0SES0u16tjA9Z3oFkF4RrC/hPAPgjlSpezsOvI8ObcXcElo92wn5IGA==}

  mdast-util-gfm-autolink-literal@2.0.1:
    resolution: {integrity: sha512-5HVP2MKaP6L+G6YaxPNjuL0BPrq9orG3TsrZ9YXbA3vDw/ACI4MEsnoDpn6ZNm7GnZgtAcONJyPhOP8tNJQavQ==}

  mdast-util-gfm-footnote@1.0.2:
    resolution: {integrity: sha512-56D19KOGbE00uKVj3sgIykpwKL179QsVFwx/DCW0u/0+URsryacI4MAdNJl0dh+u2PSsD9FtxPFbHCzJ78qJFQ==}

  mdast-util-gfm-footnote@2.0.0:
    resolution: {integrity: sha512-5jOT2boTSVkMnQ7LTrd6n/18kqwjmuYqo7JUPe+tRCY6O7dAuTFMtTPauYYrMPpox9hlN0uOx/FL8XvEfG9/mQ==}

  mdast-util-gfm-strikethrough@1.0.3:
    resolution: {integrity: sha512-DAPhYzTYrRcXdMjUtUjKvW9z/FNAMTdU0ORyMcbmkwYNbKocDpdk+PX1L1dQgOID/+vVs1uBQ7ElrBQfZ0cuiQ==}

  mdast-util-gfm-strikethrough@2.0.0:
    resolution: {integrity: sha512-mKKb915TF+OC5ptj5bJ7WFRPdYtuHv0yTRxK2tJvi+BDqbkiG7h7u/9SI89nRAYcmap2xHQL9D+QG/6wSrTtXg==}

  mdast-util-gfm-table@1.0.7:
    resolution: {integrity: sha512-jjcpmNnQvrmN5Vx7y7lEc2iIOEytYv7rTvu+MeyAsSHTASGCCRA79Igg2uKssgOs1i1po8s3plW0sTu1wkkLGg==}

  mdast-util-gfm-table@2.0.0:
    resolution: {integrity: sha512-78UEvebzz/rJIxLvE7ZtDd/vIQ0RHv+3Mh5DR96p7cS7HsBhYIICDBCu8csTNWNO6tBWfqXPWekRuj2FNOGOZg==}

  mdast-util-gfm-task-list-item@1.0.2:
    resolution: {integrity: sha512-PFTA1gzfp1B1UaiJVyhJZA1rm0+Tzn690frc/L8vNX1Jop4STZgOE6bxUhnzdVSB+vm2GU1tIsuQcA9bxTQpMQ==}

  mdast-util-gfm-task-list-item@2.0.0:
    resolution: {integrity: sha512-IrtvNvjxC1o06taBAVJznEnkiHxLFTzgonUdy8hzFVeDun0uTjxxrRGVaNFqkU1wJR3RBPEfsxmU6jDWPofrTQ==}

  mdast-util-gfm@2.0.2:
    resolution: {integrity: sha512-qvZ608nBppZ4icQlhQQIAdc6S3Ffj9RGmzwUKUWuEICFnd1LVkN3EktF7ZHAgfcEdvZB5owU9tQgt99e2TlLjg==}

  mdast-util-gfm@3.0.0:
    resolution: {integrity: sha512-dgQEX5Amaq+DuUqf26jJqSK9qgixgd6rYDHAv4aTBuA92cTknZlKpPfa86Z/s8Dj8xsAQpFfBmPUHWJBWqS4Bw==}

  mdast-util-math@2.0.2:
    resolution: {integrity: sha512-8gmkKVp9v6+Tgjtq6SYx9kGPpTf6FVYRa53/DLh479aldR9AyP48qeVOgNZ5X7QUK7nOy4yw7vg6mbiGcs9jWQ==}

  mdast-util-mdx-expression@2.0.1:
    resolution: {integrity: sha512-J6f+9hUp+ldTZqKRSg7Vw5V6MqjATc+3E4gf3CFNcuZNWD8XdyI6zQ8GqH7f8169MM6P7hMBRDVGnn7oHB9kXQ==}

  mdast-util-mdx-jsx@3.1.3:
    resolution: {integrity: sha512-bfOjvNt+1AcbPLTFMFWY149nJz0OjmewJs3LQQ5pIyVGxP4CdOqNVJL6kTaM5c68p8q82Xv3nCyFfUnuEcH3UQ==}

  mdast-util-mdx@3.0.0:
    resolution: {integrity: sha512-JfbYLAW7XnYTTbUsmpu0kdBUVe+yKVJZBItEjwyYJiDJuZ9w4eeaqks4HQO+R7objWgS2ymV60GYpI14Ug554w==}

  mdast-util-mdxjs-esm@2.0.1:
    resolution: {integrity: sha512-EcmOpxsZ96CvlP03NghtH1EsLtr0n9Tm4lPUJUBccV9RwUOneqSycg19n5HGzCf+10LozMRSObtVr3ee1WoHtg==}

  mdast-util-phrasing@3.0.1:
    resolution: {integrity: sha512-WmI1gTXUBJo4/ZmSk79Wcb2HcjPJBzM1nlI/OUWA8yk2X9ik3ffNbBGsU+09BFmXaL1IBb9fiuvq6/KMiNycSg==}

  mdast-util-phrasing@4.1.0:
    resolution: {integrity: sha512-TqICwyvJJpBwvGAMZjj4J2n0X8QWp21b9l0o7eXyVJ25YNWYbJDVIyD1bZXE6WtV6RmKJVYmQAKWa0zWOABz2w==}

  mdast-util-to-hast@12.3.0:
    resolution: {integrity: sha512-pits93r8PhnIoU4Vy9bjW39M2jJ6/tdHyja9rrot9uujkN7UTU9SDnE6WNJz/IGyQk3XHX6yNNtrBH6cQzm8Hw==}

  mdast-util-to-hast@13.2.0:
    resolution: {integrity: sha512-QGYKEuUsYT9ykKBCMOEDLsU5JRObWQusAolFMeko/tYPufNkRffBAQjIE+99jbA87xv6FgmjLtwjh9wBWajwAA==}

  mdast-util-to-markdown@1.5.0:
    resolution: {integrity: sha512-bbv7TPv/WC49thZPg3jXuqzuvI45IL2EVAr/KxF0BSdHsU0ceFHOmwQn6evxAh1GaoK/6GQ1wp4R4oW2+LFL/A==}

  mdast-util-to-markdown@2.1.0:
    resolution: {integrity: sha512-SR2VnIEdVNCJbP6y7kVTJgPLifdr8WEU440fQec7qHoHOUz/oJ2jmNRqdDQ3rbiStOXb2mCDGTuwsK5OPUgYlQ==}

  mdast-util-to-string@3.2.0:
    resolution: {integrity: sha512-V4Zn/ncyN1QNSqSBxTrMOLpjr+IKdHl2v3KVLoWmDPscP4r9GcCi71gjgvUV1SFSKh92AjAG4peFuBl2/YgCJg==}

  mdast-util-to-string@4.0.0:
    resolution: {integrity: sha512-0H44vDimn51F0YwvxSJSm0eCDOJTRlmN0R1yBh4HLj9wiV1Dn0QoXGbvFAWj2hSItVTlCmBF1hqKlIyUBVFLPg==}

  mdast@3.0.0:
    resolution: {integrity: sha512-xySmf8g4fPKMeC07jXGz971EkLbWAJ83s4US2Tj9lEdnZ142UP5grN73H1Xd3HzrdbU5o9GYYP/y8F9ZSwLE9g==}
    deprecated: '`mdast` was renamed to `remark`'

  merge2@1.4.1:
    resolution: {integrity: sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==}
    engines: {node: '>= 8'}

  mermaid@11.2.1:
    resolution: {integrity: sha512-F8TEaLVVyxTUmvKswVFyOkjPrlJA5h5vNR1f7ZnSWSpqxgEZG1hggtn/QCa7znC28bhlcrNh10qYaIiill7q4A==}

  micromark-core-commonmark@1.1.0:
    resolution: {integrity: sha512-BgHO1aRbolh2hcrzL2d1La37V0Aoz73ymF8rAcKnohLy93titmv62E0gP8Hrx9PKcKrqCZ1BbLGbP3bEhoXYlw==}

  micromark-core-commonmark@2.0.1:
    resolution: {integrity: sha512-CUQyKr1e///ZODyD1U3xit6zXwy1a8q2a1S1HKtIlmgvurrEpaw/Y9y6KSIbF8P59cn/NjzHyO+Q2fAyYLQrAA==}

  micromark-extension-gfm-autolink-literal@1.0.5:
    resolution: {integrity: sha512-z3wJSLrDf8kRDOh2qBtoTRD53vJ+CWIyo7uyZuxf/JAbNJjiHsOpG1y5wxk8drtv3ETAHutCu6N3thkOOgueWg==}

  micromark-extension-gfm-autolink-literal@2.1.0:
    resolution: {integrity: sha512-oOg7knzhicgQ3t4QCjCWgTmfNhvQbDDnJeVu9v81r7NltNCVmhPy1fJRX27pISafdjL+SVc4d3l48Gb6pbRypw==}

  micromark-extension-gfm-footnote@1.1.2:
    resolution: {integrity: sha512-Yxn7z7SxgyGWRNa4wzf8AhYYWNrwl5q1Z8ii+CSTTIqVkmGZF1CElX2JI8g5yGoM3GAman9/PVCUFUSJ0kB/8Q==}

  micromark-extension-gfm-footnote@2.1.0:
    resolution: {integrity: sha512-/yPhxI1ntnDNsiHtzLKYnE3vf9JZ6cAisqVDauhp4CEHxlb4uoOTxOCJ+9s51bIB8U1N1FJ1RXOKTIlD5B/gqw==}

  micromark-extension-gfm-strikethrough@1.0.7:
    resolution: {integrity: sha512-sX0FawVE1o3abGk3vRjOH50L5TTLr3b5XMqnP9YDRb34M0v5OoZhG+OHFz1OffZ9dlwgpTBKaT4XW/AsUVnSDw==}

  micromark-extension-gfm-strikethrough@2.1.0:
    resolution: {integrity: sha512-ADVjpOOkjz1hhkZLlBiYA9cR2Anf8F4HqZUO6e5eDcPQd0Txw5fxLzzxnEkSkfnD0wziSGiv7sYhk/ktvbf1uw==}

  micromark-extension-gfm-table@1.0.7:
    resolution: {integrity: sha512-3ZORTHtcSnMQEKtAOsBQ9/oHp9096pI/UvdPtN7ehKvrmZZ2+bbWhi0ln+I9drmwXMt5boocn6OlwQzNXeVeqw==}

  micromark-extension-gfm-table@2.1.0:
    resolution: {integrity: sha512-Ub2ncQv+fwD70/l4ou27b4YzfNaCJOvyX4HxXU15m7mpYY+rjuWzsLIPZHJL253Z643RpbcP1oeIJlQ/SKW67g==}

  micromark-extension-gfm-tagfilter@1.0.2:
    resolution: {integrity: sha512-5XWB9GbAUSHTn8VPU8/1DBXMuKYT5uOgEjJb8gN3mW0PNW5OPHpSdojoqf+iq1xo7vWzw/P8bAHY0n6ijpXF7g==}

  micromark-extension-gfm-tagfilter@2.0.0:
    resolution: {integrity: sha512-xHlTOmuCSotIA8TW1mDIM6X2O1SiX5P9IuDtqGonFhEK0qgRI4yeC6vMxEV2dgyr2TiD+2PQ10o+cOhdVAcwfg==}

  micromark-extension-gfm-task-list-item@1.0.5:
    resolution: {integrity: sha512-RMFXl2uQ0pNQy6Lun2YBYT9g9INXtWJULgbt01D/x8/6yJ2qpKyzdZD3pi6UIkzF++Da49xAelVKUeUMqd5eIQ==}

  micromark-extension-gfm-task-list-item@2.1.0:
    resolution: {integrity: sha512-qIBZhqxqI6fjLDYFTBIa4eivDMnP+OZqsNwmQ3xNLE4Cxwc+zfQEfbs6tzAo2Hjq+bh6q5F+Z8/cksrLFYWQQw==}

  micromark-extension-gfm@2.0.3:
    resolution: {integrity: sha512-vb9OoHqrhCmbRidQv/2+Bc6pkP0FrtlhurxZofvOEy5o8RtuuvTq+RQ1Vw5ZDNrVraQZu3HixESqbG+0iKk/MQ==}

  micromark-extension-gfm@3.0.0:
    resolution: {integrity: sha512-vsKArQsicm7t0z2GugkCKtZehqUm31oeGBV/KVSorWSy8ZlNAv7ytjFhvaryUiCUJYqs+NoE6AFhpQvBTM6Q4w==}

  micromark-extension-math@2.1.2:
    resolution: {integrity: sha512-es0CcOV89VNS9wFmyn+wyFTKweXGW4CEvdaAca6SWRWPyYCbBisnjaHLjWO4Nszuiud84jCpkHsqAJoa768Pvg==}

  micromark-extension-mdx-expression@3.0.0:
    resolution: {integrity: sha512-sI0nwhUDz97xyzqJAbHQhp5TfaxEvZZZ2JDqUo+7NvyIYG6BZ5CPPqj2ogUoPJlmXHBnyZUzISg9+oUmU6tUjQ==}

  micromark-extension-mdx-jsx@3.0.1:
    resolution: {integrity: sha512-vNuFb9czP8QCtAQcEJn0UJQJZA8Dk6DXKBqx+bg/w0WGuSxDxNr7hErW89tHUY31dUW4NqEOWwmEUNhjTFmHkg==}

  micromark-extension-mdx-md@2.0.0:
    resolution: {integrity: sha512-EpAiszsB3blw4Rpba7xTOUptcFeBFi+6PY8VnJ2hhimH+vCQDirWgsMpz7w1XcZE7LVrSAUGb9VJpG9ghlYvYQ==}

  micromark-extension-mdxjs-esm@3.0.0:
    resolution: {integrity: sha512-DJFl4ZqkErRpq/dAPyeWp15tGrcrrJho1hKK5uBS70BCtfrIFg81sqcTVu3Ta+KD1Tk5vAtBNElWxtAa+m8K9A==}

  micromark-extension-mdxjs@3.0.0:
    resolution: {integrity: sha512-A873fJfhnJ2siZyUrJ31l34Uqwy4xIFmvPY1oj+Ean5PHcPBYzEsvqvWGaWcfEIr11O5Dlw3p2y0tZWpKHDejQ==}

  micromark-factory-destination@1.1.0:
    resolution: {integrity: sha512-XaNDROBgx9SgSChd69pjiGKbV+nfHGDPVYFs5dOoDd7ZnMAE+Cuu91BCpsY8RT2NP9vo/B8pds2VQNCLiu0zhg==}

  micromark-factory-destination@2.0.0:
    resolution: {integrity: sha512-j9DGrQLm/Uhl2tCzcbLhy5kXsgkHUrjJHg4fFAeoMRwJmJerT9aw4FEhIbZStWN8A3qMwOp1uzHr4UL8AInxtA==}

  micromark-factory-label@1.1.0:
    resolution: {integrity: sha512-OLtyez4vZo/1NjxGhcpDSbHQ+m0IIGnT8BoPamh+7jVlzLJBH98zzuCoUeMxvM6WsNeh8wx8cKvqLiPHEACn0w==}

  micromark-factory-label@2.0.0:
    resolution: {integrity: sha512-RR3i96ohZGde//4WSe/dJsxOX6vxIg9TimLAS3i4EhBAFx8Sm5SmqVfR8E87DPSR31nEAjZfbt91OMZWcNgdZw==}

  micromark-factory-mdx-expression@2.0.2:
    resolution: {integrity: sha512-5E5I2pFzJyg2CtemqAbcyCktpHXuJbABnsb32wX2U8IQKhhVFBqkcZR5LRm1WVoFqa4kTueZK4abep7wdo9nrw==}

  micromark-factory-space@1.1.0:
    resolution: {integrity: sha512-cRzEj7c0OL4Mw2v6nwzttyOZe8XY/Z8G0rzmWQZTBi/jjwyw/U4uqKtUORXQrR5bAZZnbTI/feRV/R7hc4jQYQ==}

  micromark-factory-space@2.0.0:
    resolution: {integrity: sha512-TKr+LIDX2pkBJXFLzpyPyljzYK3MtmllMUMODTQJIUfDGncESaqB90db9IAUcz4AZAJFdd8U9zOp9ty1458rxg==}

  micromark-factory-title@1.1.0:
    resolution: {integrity: sha512-J7n9R3vMmgjDOCY8NPw55jiyaQnH5kBdV2/UXCtZIpnHH3P6nHUKaH7XXEYuWwx/xUJcawa8plLBEjMPU24HzQ==}

  micromark-factory-title@2.0.0:
    resolution: {integrity: sha512-jY8CSxmpWLOxS+t8W+FG3Xigc0RDQA9bKMY/EwILvsesiRniiVMejYTE4wumNc2f4UbAa4WsHqe3J1QS1sli+A==}

  micromark-factory-whitespace@1.1.0:
    resolution: {integrity: sha512-v2WlmiymVSp5oMg+1Q0N1Lxmt6pMhIHD457whWM7/GUlEks1hI9xj5w3zbc4uuMKXGisksZk8DzP2UyGbGqNsQ==}

  micromark-factory-whitespace@2.0.0:
    resolution: {integrity: sha512-28kbwaBjc5yAI1XadbdPYHX/eDnqaUFVikLwrO7FDnKG7lpgxnvk/XGRhX/PN0mOZ+dBSZ+LgunHS+6tYQAzhA==}

  micromark-util-character@1.2.0:
    resolution: {integrity: sha512-lXraTwcX3yH/vMDaFWCQJP1uIszLVebzUa3ZHdrgxr7KEU/9mL4mVgCpGbyhvNLNlauROiNUq7WN5u7ndbY6xg==}

  micromark-util-character@2.1.0:
    resolution: {integrity: sha512-KvOVV+X1yLBfs9dCBSopq/+G1PcgT3lAK07mC4BzXi5E7ahzMAF8oIupDDJ6mievI6F+lAATkbQQlQixJfT3aQ==}

  micromark-util-chunked@1.1.0:
    resolution: {integrity: sha512-Ye01HXpkZPNcV6FiyoW2fGZDUw4Yc7vT0E9Sad83+bEDiCJ1uXu0S3mr8WLpsz3HaG3x2q0HM6CTuPdcZcluFQ==}

  micromark-util-chunked@2.0.0:
    resolution: {integrity: sha512-anK8SWmNphkXdaKgz5hJvGa7l00qmcaUQoMYsBwDlSKFKjc6gjGXPDw3FNL3Nbwq5L8gE+RCbGqTw49FK5Qyvg==}

  micromark-util-classify-character@1.1.0:
    resolution: {integrity: sha512-SL0wLxtKSnklKSUplok1WQFoGhUdWYKggKUiqhX+Swala+BtptGCu5iPRc+xvzJ4PXE/hwM3FNXsfEVgoZsWbw==}

  micromark-util-classify-character@2.0.0:
    resolution: {integrity: sha512-S0ze2R9GH+fu41FA7pbSqNWObo/kzwf8rN/+IGlW/4tC6oACOs8B++bh+i9bVyNnwCcuksbFwsBme5OCKXCwIw==}

  micromark-util-combine-extensions@1.1.0:
    resolution: {integrity: sha512-Q20sp4mfNf9yEqDL50WwuWZHUrCO4fEyeDCnMGmG5Pr0Cz15Uo7KBs6jq+dq0EgX4DPwwrh9m0X+zPV1ypFvUA==}

  micromark-util-combine-extensions@2.0.0:
    resolution: {integrity: sha512-vZZio48k7ON0fVS3CUgFatWHoKbbLTK/rT7pzpJ4Bjp5JjkZeasRfrS9wsBdDJK2cJLHMckXZdzPSSr1B8a4oQ==}

  micromark-util-decode-numeric-character-reference@1.1.0:
    resolution: {integrity: sha512-m9V0ExGv0jB1OT21mrWcuf4QhP46pH1KkfWy9ZEezqHKAxkj4mPCy3nIH1rkbdMlChLHX531eOrymlwyZIf2iw==}

  micromark-util-decode-numeric-character-reference@2.0.1:
    resolution: {integrity: sha512-bmkNc7z8Wn6kgjZmVHOX3SowGmVdhYS7yBpMnuMnPzDq/6xwVA604DuOXMZTO1lvq01g+Adfa0pE2UKGlxL1XQ==}

  micromark-util-decode-string@1.1.0:
    resolution: {integrity: sha512-YphLGCK8gM1tG1bd54azwyrQRjCFcmgj2S2GoJDNnh4vYtnL38JS8M4gpxzOPNyHdNEpheyWXCTnnTDY3N+NVQ==}

  micromark-util-decode-string@2.0.0:
    resolution: {integrity: sha512-r4Sc6leeUTn3P6gk20aFMj2ntPwn6qpDZqWvYmAG6NgvFTIlj4WtrAudLi65qYoaGdXYViXYw2pkmn7QnIFasA==}

  micromark-util-encode@1.1.0:
    resolution: {integrity: sha512-EuEzTWSTAj9PA5GOAs992GzNh2dGQO52UvAbtSOMvXTxv3Criqb6IOzJUBCmEqrrXSblJIJBbFFv6zPxpreiJw==}

  micromark-util-encode@2.0.0:
    resolution: {integrity: sha512-pS+ROfCXAGLWCOc8egcBvT0kf27GoWMqtdarNfDcjb6YLuV5cM3ioG45Ys2qOVqeqSbjaKg72vU+Wby3eddPsA==}

  micromark-util-events-to-acorn@2.0.2:
    resolution: {integrity: sha512-Fk+xmBrOv9QZnEDguL9OI9/NQQp6Hz4FuQ4YmCb/5V7+9eAh1s6AYSvL20kHkD67YIg7EpE54TiSlcsf3vyZgA==}

  micromark-util-html-tag-name@1.2.0:
    resolution: {integrity: sha512-VTQzcuQgFUD7yYztuQFKXT49KghjtETQ+Wv/zUjGSGBioZnkA4P1XXZPT1FHeJA6RwRXSF47yvJ1tsJdoxwO+Q==}

  micromark-util-html-tag-name@2.0.0:
    resolution: {integrity: sha512-xNn4Pqkj2puRhKdKTm8t1YHC/BAjx6CEwRFXntTaRf/x16aqka6ouVoutm+QdkISTlT7e2zU7U4ZdlDLJd2Mcw==}

  micromark-util-normalize-identifier@1.1.0:
    resolution: {integrity: sha512-N+w5vhqrBihhjdpM8+5Xsxy71QWqGn7HYNUvch71iV2PM7+E3uWGox1Qp90loa1ephtCxG2ftRV/Conitc6P2Q==}

  micromark-util-normalize-identifier@2.0.0:
    resolution: {integrity: sha512-2xhYT0sfo85FMrUPtHcPo2rrp1lwbDEEzpx7jiH2xXJLqBuy4H0GgXk5ToU8IEwoROtXuL8ND0ttVa4rNqYK3w==}

  micromark-util-resolve-all@1.1.0:
    resolution: {integrity: sha512-b/G6BTMSg+bX+xVCshPTPyAu2tmA0E4X98NSR7eIbeC6ycCqCeE7wjfDIgzEbkzdEVJXRtOG4FbEm/uGbCRouA==}

  micromark-util-resolve-all@2.0.0:
    resolution: {integrity: sha512-6KU6qO7DZ7GJkaCgwBNtplXCvGkJToU86ybBAUdavvgsCiG8lSSvYxr9MhwmQ+udpzywHsl4RpGJsYWG1pDOcA==}

  micromark-util-sanitize-uri@1.2.0:
    resolution: {integrity: sha512-QO4GXv0XZfWey4pYFndLUKEAktKkG5kZTdUNaTAkzbuJxn2tNBOr+QtxR2XpWaMhbImT2dPzyLrPXLlPhph34A==}

  micromark-util-sanitize-uri@2.0.0:
    resolution: {integrity: sha512-WhYv5UEcZrbAtlsnPuChHUAsu/iBPOVaEVsntLBIdpibO0ddy8OzavZz3iL2xVvBZOpolujSliP65Kq0/7KIYw==}

  micromark-util-subtokenize@1.1.0:
    resolution: {integrity: sha512-kUQHyzRoxvZO2PuLzMt2P/dwVsTiivCK8icYTeR+3WgbuPqfHgPPy7nFKbeqRivBvn/3N3GBiNC+JRTMSxEC7A==}

  micromark-util-subtokenize@2.0.1:
    resolution: {integrity: sha512-jZNtiFl/1aY73yS3UGQkutD0UbhTt68qnRpw2Pifmz5wV9h8gOVsN70v+Lq/f1rKaU/W8pxRe8y8Q9FX1AOe1Q==}

  micromark-util-symbol@1.1.0:
    resolution: {integrity: sha512-uEjpEYY6KMs1g7QfJ2eX1SQEV+ZT4rUD3UcF6l57acZvLNK7PBZL+ty82Z1qhK1/yXIY4bdx04FKMgR0g4IAag==}

  micromark-util-symbol@2.0.0:
    resolution: {integrity: sha512-8JZt9ElZ5kyTnO94muPxIGS8oyElRJaiJO8EzV6ZSyGQ1Is8xwl4Q45qU5UOg+bGH4AikWziz0iN4sFLWs8PGw==}

  micromark-util-types@1.1.0:
    resolution: {integrity: sha512-ukRBgie8TIAcacscVHSiddHjO4k/q3pnedmzMQ4iwDcK0FtFCohKOlFbaOL/mPgfnPsL3C1ZyxJa4sbWrBl3jg==}

  micromark-util-types@2.0.0:
    resolution: {integrity: sha512-oNh6S2WMHWRZrmutsRmDDfkzKtxF+bc2VxLC9dvtrDIRFln627VsFP6fLMgTryGDljgLPjkrzQSDcPrjPyDJ5w==}

  micromark@3.2.0:
    resolution: {integrity: sha512-uD66tJj54JLYq0De10AhWycZWGQNUvDI55xPgk2sQM5kn1JYlhbCMTtEeT27+vAhW2FBQxLlOmS3pmA7/2z4aA==}

  micromark@4.0.0:
    resolution: {integrity: sha512-o/sd0nMof8kYff+TqcDx3VSrgBTcZpSvYcAHIfHhv5VAuNmisCxjhx6YmxS8PFEpb9z5WKWKPdzf0jM23ro3RQ==}

  micromatch@4.0.8:
    resolution: {integrity: sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==}
    engines: {node: '>=8.6'}

  minimatch@9.0.5:
    resolution: {integrity: sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==}
    engines: {node: '>=16 || 14 >=14.17'}

  minipass@7.1.2:
    resolution: {integrity: sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==}
    engines: {node: '>=16 || 14 >=14.17'}

  mlly@1.7.1:
    resolution: {integrity: sha512-rrVRZRELyQzrIUAVMHxP97kv+G786pHmOKzuFII8zDYahFBS7qnHh2AlYSl1GAHhaMPCz6/oHjVMcfFYgFYHgA==}

  mri@1.2.0:
    resolution: {integrity: sha512-tzzskb3bG8LvYGFF/mDTpq3jpI6Q9wc3LEmBaghu+DdCssd1FakN7Bc0hVNmEyGq1bq3RgfkCb3cmQLpNPOroA==}
    engines: {node: '>=4'}

  ms@2.0.0:
    resolution: {integrity: sha512-Tpp60P6IUJDTuOq/5Z8cdskzJujfwqfOTkrwIwj7IRISpnkJnT6SyJ4PCPnGMoFjC9ddhal5KVIYtAt97ix05A==}

  ms@2.1.3:
    resolution: {integrity: sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==}

  mz@2.7.0:
    resolution: {integrity: sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==}

  nanoid@3.3.7:
    resolution: {integrity: sha512-eSRppjcPIatRIMC1U6UngP8XFcz8MQWGQdt1MTBQ7NaAmvXDfvNxbvWV3x2y6CdEUciCSsDHDQZbhYaB8QEo2g==}
    engines: {node: ^10 || ^12 || ^13.7 || ^14 || >=15.0.1}
    hasBin: true

  negotiator@0.6.3:
    resolution: {integrity: sha512-+EUsqGPLsM+j/zdChZjsnX51g4XrHFOIXwfnCVPGlQk/k5giakcKsuxCObBRu6DSm9opw/O6slWbJdghQM4bBg==}
    engines: {node: '>= 0.6'}

  next-themes@0.3.0:
    resolution: {integrity: sha512-/QHIrsYpd6Kfk7xakK4svpDI5mmXP0gfvCoJdGpZQ2TOrQZmsW0QxjaiLn8wbIKjtm4BTSqLoix4lxYYOnLJ/w==}
    peerDependencies:
      react: ^16.8 || ^17 || ^18
      react-dom: ^16.8 || ^17 || ^18

  next@14.2.13:
    resolution: {integrity: sha512-BseY9YNw8QJSwLYD7hlZzl6QVDoSFHL/URN5K64kVEVpCsSOWeyjbIGK+dZUaRViHTaMQX8aqmnn0PHBbGZezg==}
    engines: {node: '>=18.17.0'}
    hasBin: true
    peerDependencies:
      '@opentelemetry/api': ^1.1.0
      '@playwright/test': ^1.41.2
      react: ^18.2.0
      react-dom: ^18.2.0
      sass: ^1.3.0
    peerDependenciesMeta:
      '@opentelemetry/api':
        optional: true
      '@playwright/test':
        optional: true
      sass:
        optional: true

  no-case@3.0.4:
    resolution: {integrity: sha512-fgAN3jGAh+RoxUGZHTSOLJIqUc2wmoBwGR4tbpNAKmmovFoWq0OdRkb0VkldReO2a2iBT/OEulG9XSUc10r3zg==}

  node-fetch@2.7.0:
    resolution: {integrity: sha512-c4FRfUm/dbcWZ7U+1Wq0AwCyFL+3nt2bEw05wfxSz+DWpWsitgmSgYmy2dQdWyKC1694ELPqMs/YzUSNozLt8A==}
    engines: {node: 4.x || >=6.0.0}
    peerDependencies:
      encoding: ^0.1.0
    peerDependenciesMeta:
      encoding:
        optional: true

  node-releases@2.0.18:
    resolution: {integrity: sha512-d9VeXT4SJ7ZeOqGX6R5EM022wpL+eWPooLI+5UpWn2jCT1aosUQEhQP214x33Wkwx3JQMvIm+tIoVOdodFS40g==}

  normalize-path@3.0.0:
    resolution: {integrity: sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==}
    engines: {node: '>=0.10.0'}

  normalize-range@0.1.2:
    resolution: {integrity: sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==}
    engines: {node: '>=0.10.0'}

  npm-to-yarn@3.0.0:
    resolution: {integrity: sha512-76YnmsbfrYp0tMsWxM0RNX0Vs+x8JxpJGu6B/jDn4lW8+laiTcKmKi9MeMh4UikO4RkJ1oqURoDy9bXJmMXS6A==}
    engines: {node: ^12.22.0 || ^14.17.0 || >=16.0.0}

  object-assign@4.1.1:
    resolution: {integrity: sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==}
    engines: {node: '>=0.10.0'}

  object-hash@3.0.0:
    resolution: {integrity: sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==}
    engines: {node: '>= 6'}

  oniguruma-to-js@0.4.3:
    resolution: {integrity: sha512-X0jWUcAlxORhOqqBREgPMgnshB7ZGYszBNspP+tS9hPD3l13CdaXcHbgImoHUHlrvGx/7AvFEkTRhAGYh+jzjQ==}

  package-json-from-dist@1.0.0:
    resolution: {integrity: sha512-dATvCeZN/8wQsGywez1mzHtTlP22H8OEfPrVMLNr4/eGa+ijtLn/6M5f0dY8UKNrC2O9UCU6SSoG3qRKnt7STw==}

  package-manager-detector@0.2.0:
    resolution: {integrity: sha512-E385OSk9qDcXhcM9LNSe4sdhx8a9mAPrZ4sMLW+tmxl5ZuGtPUcdFu+MPP2jbgiWAZ6Pfe5soGFMd+0Db5Vrog==}

  parse-entities@2.0.0:
    resolution: {integrity: sha512-kkywGpCcRYhqQIchaWqZ875wzpS/bMKhz5HnN3p7wveJTkTtyAB/AlnS0f8DFSqYW1T82t6yEAkEcB+A1I3MbQ==}

  parse-entities@4.0.1:
    resolution: {integrity: sha512-SWzvYcSJh4d/SGLIOQfZ/CoNv6BTlI6YEQ7Nj82oDVnRpwe/Z/F1EMx42x3JAOwGBlCjeCH0BRJQbQ/opHL17w==}

  parse-numeric-range@1.3.0:
    resolution: {integrity: sha512-twN+njEipszzlMJd4ONUYgSfZPDxgHhT9Ahed5uTigpQn90FggW4SA/AIPq/6a149fTbE9qBEcSwE3FAEp6wQQ==}

  path-data-parser@0.1.0:
    resolution: {integrity: sha512-NOnmBpt5Y2RWbuv0LMzsayp3lVylAHLPUTut412ZA3l+C4uw4ZVkQbjShYCQ8TCpUMdPapr4YjUqLYD6v68j+w==}

  path-key@3.1.1:
    resolution: {integrity: sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==}
    engines: {node: '>=8'}

  path-parse@1.0.7:
    resolution: {integrity: sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==}

  path-scurry@1.11.1:
    resolution: {integrity: sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==}
    engines: {node: '>=16 || 14 >=14.18'}

  pathe@1.1.2:
    resolution: {integrity: sha512-whLdWMYL2TwI08hn8/ZqAbrVemu0LNaNNJZX73O6qaIdCTfXutsLhMkjdENX0qhsQ9uIimo4/aQOmXkoon2nDQ==}

  periscopic@3.1.0:
    resolution: {integrity: sha512-vKiQ8RRtkl9P+r/+oefh25C3fhybptkHKCZSPlcXiJux2tJF55GnEj3BVn4A5gKfq9NWWXXrxkHBwVPUfH0opw==}

  picocolors@1.1.0:
    resolution: {integrity: sha512-TQ92mBOW0l3LeMeyLV6mzy/kWr8lkd/hp3mTg7wYK7zJhuBStmGMBG0BdeDZS/dZx1IukaX6Bk11zcln25o1Aw==}

  picomatch@2.3.1:
    resolution: {integrity: sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==}
    engines: {node: '>=8.6'}

  pify@2.3.0:
    resolution: {integrity: sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==}
    engines: {node: '>=0.10.0'}

  pirates@4.0.6:
    resolution: {integrity: sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==}
    engines: {node: '>= 6'}

  pkg-types@1.2.0:
    resolution: {integrity: sha512-+ifYuSSqOQ8CqP4MbZA5hDpb97n3E8SVWdJe+Wms9kj745lmd3b7EZJiqvmLwAlmRfjrI7Hi5z3kdBJ93lFNPA==}

  points-on-curve@0.2.0:
    resolution: {integrity: sha512-0mYKnYYe9ZcqMCWhUjItv/oHjvgEsfKvnUTg8sAtnHr3GVy7rGkXCb6d5cSyqrWqL4k81b9CPg3urd+T7aop3A==}

  points-on-path@0.2.1:
    resolution: {integrity: sha512-25ClnWWuw7JbWZcgqY/gJ4FQWadKxGWk+3kR/7kD0tCaDtPPMj7oHu2ToLaVhfpnHrZzYby2w6tUA0eOIuUg8g==}

  postcss-import@15.1.0:
    resolution: {integrity: sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==}
    engines: {node: '>=14.0.0'}
    peerDependencies:
      postcss: ^8.0.0

  postcss-js@4.0.1:
    resolution: {integrity: sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==}
    engines: {node: ^12 || ^14 || >= 16}
    peerDependencies:
      postcss: ^8.4.21

  postcss-load-config@4.0.2:
    resolution: {integrity: sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==}
    engines: {node: '>= 14'}
    peerDependencies:
      postcss: '>=8.0.9'
      ts-node: '>=9.0.0'
    peerDependenciesMeta:
      postcss:
        optional: true
      ts-node:
        optional: true

  postcss-nested@6.2.0:
    resolution: {integrity: sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==}
    engines: {node: '>=12.0'}
    peerDependencies:
      postcss: ^8.2.14

  postcss-selector-parser@6.0.10:
    resolution: {integrity: sha512-IQ7TZdoaqbT+LCpShg46jnZVlhWD2w6iQYAcYXfHARZ7X1t/UGhhceQDs5X0cGqKvYlHNOuv7Oa1xmb0oQuA3w==}
    engines: {node: '>=4'}

  postcss-selector-parser@6.1.2:
    resolution: {integrity: sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==}
    engines: {node: '>=4'}

  postcss-value-parser@4.2.0:
    resolution: {integrity: sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==}

  postcss@8.4.31:
    resolution: {integrity: sha512-PS08Iboia9mts/2ygV3eLpY5ghnUcfLV/EXTOW1E2qYxJKGGBUtNjN76FYHnMs36RmARn41bC0AZmn+rR0OVpQ==}
    engines: {node: ^10 || ^12 || >=14}

  postcss@8.4.47:
    resolution: {integrity: sha512-56rxCq7G/XfB4EkXq9Egn5GCqugWvDFjafDOThIdMBsI15iqPqR5r15TfSr1YPYeEI19YeaXMCbY6u88Y76GLQ==}
    engines: {node: ^10 || ^12 || >=14}

  posthog-js@1.175.0:
    resolution: {integrity: sha512-ZPdM7/azh90gqqlYSJ3RIBJVViER8JDR7LtHWatVt2UCsIRvV+FSRQd85n770TFLDQSKAekFVcwCC9t+syTJJA==}

  preact@10.24.2:
    resolution: {integrity: sha512-1cSoF0aCC8uaARATfrlz4VCBqE8LwZwRfLgkxJOQwAlQt6ayTmi0D9OF7nXid1POI5SZidFuG9CnlXbDfLqY/Q==}

  prismjs@1.27.0:
    resolution: {integrity: sha512-t13BGPUlFDR7wRB5kQDG4jjl7XeuH6jbJGt11JHPL96qwsEHNX2+68tFXqc1/k+/jALsbSWJKUOT/hcYAZ5LkA==}
    engines: {node: '>=6'}

  prismjs@1.30.0:
    resolution: {integrity: sha512-DEvV2ZF2r2/63V+tK8hQvrR2ZGn10srHbXviTlcv7Kpzw8jWiNTqbVgjO3IY8RxrrOUF8VPMQQFysYYYv0YZxw==}
    engines: {node: '>=6'}

  prop-types@15.8.1:
    resolution: {integrity: sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==}

  property-information@5.6.0:
    resolution: {integrity: sha512-YUHSPk+A30YPv+0Qf8i9Mbfe/C0hdPXk1s1jPVToV8pk8BQtpw10ct89Eo7OWkutrwqvT0eicAxlOg3dOAu8JA==}

  property-information@6.5.0:
    resolution: {integrity: sha512-PgTgs/BlvHxOu8QuEN7wi5A0OmXaBcHpmCSTehcs6Uuu9IkDIEo13Hy7n898RHfrQ49vKCoGeWZSaAK01nwVig==}

  queue-microtask@1.2.3:
    resolution: {integrity: sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==}

  queue@6.0.2:
    resolution: {integrity: sha512-iHZWu+q3IdFZFX36ro/lKBkSvfkztY5Y7HMiPlOUjhupPcG2JMfst2KKEpu5XndviX/3UhFbRngUPNKtgvtZiA==}

  react-dom@18.3.1:
    resolution: {integrity: sha512-5m4nQKp+rZRb09LNH59GM4BxTh9251/ylbKIbpe7TpGxfJ+9kv6BLkLBXIjjspbgbnIBNqlI23tRnTWT0snUIw==}
    peerDependencies:
      react: ^18.3.1

  react-ga4@2.1.0:
    resolution: {integrity: sha512-ZKS7PGNFqqMd3PJ6+C2Jtz/o1iU9ggiy8Y8nUeksgVuvNISbmrQtJiZNvC/TjDsqD0QlU5Wkgs7i+w9+OjHhhQ==}

  react-icons@5.3.0:
    resolution: {integrity: sha512-DnUk8aFbTyQPSkCfF8dbX6kQjXA9DktMeJqfjrg6cK9vwQVMxmcA3BfP4QoiztVmEHtwlTgLFsPuH2NskKT6eg==}
    peerDependencies:
      react: '*'

  react-is@16.13.1:
    resolution: {integrity: sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==}

  react-is@18.3.1:
    resolution: {integrity: sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==}

  react-markdown@8.0.7:
    resolution: {integrity: sha512-bvWbzG4MtOU62XqBx3Xx+zB2raaFFsq4mYiAzfjXJMEz2sixgeAfraA3tvzULF02ZdOMUOKTBFFaZJDDrq+BJQ==}
    peerDependencies:
      '@types/react': '>=16'
      react: '>=16'

  react-medium-image-zoom@5.2.10:
    resolution: {integrity: sha512-JBYf4u0zsocezIDtrjwStD+8sX+c8XuLsdz+HxPbojRj0sCicua0XOQKysuPetoFyX+YgStfj+vEtZ+699O/pg==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
      react-dom: ^16.8.0 || ^17.0.0 || ^18.0.0

  react-remove-scroll-bar@2.3.6:
    resolution: {integrity: sha512-DtSYaao4mBmX+HDo5YWYdBWQwYIQQshUV/dVxFxK+KM26Wjwp1gZ6rv6OC3oujI6Bfu6Xyg3TwK533AQutsn/g==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.8.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  react-remove-scroll@2.5.5:
    resolution: {integrity: sha512-ImKhrzJJsyXJfBZ4bzu8Bwpka14c/fQt0k+cyFp/PBhTfyDnU5hjOtM4AG/0AMyy8oKzOTR0lDgJIM7pYXI0kw==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.8.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  react-remove-scroll@2.5.7:
    resolution: {integrity: sha512-FnrTWO4L7/Bhhf3CYBNArEG/yROV0tKmTv7/3h9QCFvH6sndeFf1wPqOcbFVu5VAulS5dV1wGT3GZZ/1GawqiA==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.8.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  react-remove-scroll@2.6.0:
    resolution: {integrity: sha512-I2U4JVEsQenxDAKaVa3VZ/JeJZe0/2DxPWL8Tj8yLKctQJQiZM52pn/GWFpSp8dftjM3pSAHVJZscAnC/y+ySQ==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.8.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  react-style-singleton@2.2.1:
    resolution: {integrity: sha512-ZWj0fHEMyWkHzKYUr2Bs/4zU6XLmq9HsgBURm7g5pAVfyn49DgUiNgY2d4lXRlYSiCif9YBGpQleewkcqddc7g==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.8.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  react-syntax-highlighter@15.6.1:
    resolution: {integrity: sha512-OqJ2/vL7lEeV5zTJyG7kmARppUjiB9h9udl4qHQjjgEos66z00Ia0OckwYfRxCSFrW8RJIBnsBwQsHZbVPspqg==}
    peerDependencies:
      react: '>= 0.14.0'

  react-youtube@10.1.0:
    resolution: {integrity: sha512-ZfGtcVpk0SSZtWCSTYOQKhfx5/1cfyEW1JN/mugGNfAxT3rmVJeMbGpA9+e78yG21ls5nc/5uZJETE3cm3knBg==}
    engines: {node: '>= 14.x'}
    peerDependencies:
      react: '>=0.14.1'

  react@18.3.1:
    resolution: {integrity: sha512-wS+hAgJShR0KhEvPJArfuPVN1+Hz1t0Y6n5jLrGQbkb4urgPE/0Rve+1kMB1v/oWgHgm4WIcV+i7F2pTVj+2iQ==}
    engines: {node: '>=0.10.0'}

  read-cache@1.0.0:
    resolution: {integrity: sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==}

  readdirp@3.6.0:
    resolution: {integrity: sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==}
    engines: {node: '>=8.10.0'}

  refractor@3.6.0:
    resolution: {integrity: sha512-MY9W41IOWxxk31o+YvFCNyNzdkc9M20NoZK5vq6jkv4I/uh2zkWcfudj0Q1fovjUQJrNewS9NMzeTtqPf+n5EA==}

  regenerator-runtime@0.14.1:
    resolution: {integrity: sha512-dYnhHh0nJoMfnkZs6GmmhFknAGRrLznOu5nc9ML+EJxGvrx6H7teuevqVqCuPcPK//3eDrrjQhehXVx9cnkGdw==}

  regex@4.3.2:
    resolution: {integrity: sha512-kK/AA3A9K6q2js89+VMymcboLOlF5lZRCYJv3gzszXFHBr6kO6qLGzbm+UIugBEV8SMMKCTR59txoY6ctRHYVw==}

  rehype-highlight-code-lines@1.0.4:
    resolution: {integrity: sha512-sDX8HZLfx+uFXGYP56XWR1pwt2tiQA6C/evATfLZPFD88EePKk+uzhwprLSxv/QHYWkAW6tLAgkTd23bd+BUaQ==}

  remark-gfm@3.0.1:
    resolution: {integrity: sha512-lEFDoi2PICJyNrACFOfDD3JlLkuSbOa5Wd8EPt06HUdptv8Gn0bxYTdbU/XXQ3swAPkEaGxxPN9cbnMHvVu1Ig==}

  remark-gfm@4.0.0:
    resolution: {integrity: sha512-U92vJgBPkbw4Zfu/IiW2oTZLSL3Zpv+uI7My2eq8JxKgqraFdU8YUGicEJCEgSbeaG+QDFqIcwwfMTOEelPxuA==}

  remark-math@5.1.1:
    resolution: {integrity: sha512-cE5T2R/xLVtfFI4cCePtiRn+e6jKMtFDR3P8V3qpv8wpKjwvHoBA4eJzvX+nVrnlNy0911bdGmuspCSwetfYHw==}

  remark-mdx@3.0.1:
    resolution: {integrity: sha512-3Pz3yPQ5Rht2pM5R+0J2MrGoBSrzf+tJG94N+t/ilfdh8YLyyKYtidAYwTveB20BoHAcwIopOUqhcmh2F7hGYA==}

  remark-parse@10.0.2:
    resolution: {integrity: sha512-3ydxgHa/ZQzG8LvC7jTXccARYDcRld3VfcgIIFs7bI6vbRSxJJmzgLEIIoYKyrfhaY+ujuWaf/PJiMZXoiCXgw==}

  remark-parse@11.0.0:
    resolution: {integrity: sha512-FCxlKLNGknS5ba/1lmpYijMUzX2esxW5xQqjWxw2eHFfS2MSdaHVINFmhjo+qN1WhZhNimq0dZATN9pH0IDrpA==}

  remark-rehype@10.1.0:
    resolution: {integrity: sha512-EFmR5zppdBp0WQeDVZ/b66CWJipB2q2VLNFMabzDSGR66Z2fQii83G5gTBbgGEnEEA0QRussvrFHxk1HWGJskw==}

  remark-rehype@11.1.1:
    resolution: {integrity: sha512-g/osARvjkBXb6Wo0XvAeXQohVta8i84ACbenPpoSsxTOQH/Ae0/RGP4WZgnMH5pMLpsj4FG7OHmcIcXxpza8eQ==}

  remark-stringify@11.0.0:
    resolution: {integrity: sha512-1OSmLd3awB/t8qdoEOMazZkNsfVTeY4fTsgzcQFdXNq8ToTN4ZGwrMnlda4K6smTFKD+GRV6O48i6Z4iKgPPpw==}

  remark@15.0.1:
    resolution: {integrity: sha512-Eht5w30ruCXgFmxVUSlNWQ9iiimq07URKeFS3hNc8cUWy1llX4KDWfyEDZRycMc+znsN9Ux5/tJ/BFdgdOwA3A==}

  resolve@1.22.8:
    resolution: {integrity: sha512-oKWePCxqpd6FlLvGV1VU0x7bkPmmCNolxzjMf4NczoDnQcIWrAF+cPtZn5i6n+RfD2d9i0tzpKnG6Yk168yIyw==}
    hasBin: true

  reusify@1.0.4:
    resolution: {integrity: sha512-U9nH88a3fc/ekCF1l0/UP1IosiuIjyTh7hBvXVMHYgVcfGvt897Xguj2UOLDeI5BG2m7/uwyaLVT6fbtCwTyzw==}
    engines: {iojs: '>=1.0.0', node: '>=0.10.0'}

  robust-predicates@3.0.2:
    resolution: {integrity: sha512-IXgzBWvWQwE6PrDI05OvmXUIruQTcoMDzRsOd5CDvHCVLcLHMTSYvOK5Cm46kWqlV3yAbuSpBZdJ5oP5OUoStg==}

  roughjs@4.6.6:
    resolution: {integrity: sha512-ZUz/69+SYpFN/g/lUlo2FXcIjRkSu3nDarreVdGGndHEBJ6cXPdKguS8JGxwj5HA5xIbVKSmLgr5b3AWxtRfvQ==}

  run-parallel@1.2.0:
    resolution: {integrity: sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==}

  rw@1.3.3:
    resolution: {integrity: sha512-PdhdWy89SiZogBLaw42zdeqtRJ//zFd2PgQavcICDUgJT5oW10QCRKbJ6bg4r0/UY2M6BWd5tkxuGFRvCkgfHQ==}

  sade@1.8.1:
    resolution: {integrity: sha512-xal3CZX1Xlo/k4ApwCFrHVACi9fBqJ7V+mwhBsuf/1IOKbBy098Fex+Wa/5QMubw09pSZ/u8EY8PWgevJsXp1A==}
    engines: {node: '>=6'}

  safer-buffer@2.1.2:
    resolution: {integrity: sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==}

  scheduler@0.23.2:
    resolution: {integrity: sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==}

  scroll-into-view-if-needed@3.1.0:
    resolution: {integrity: sha512-49oNpRjWRvnU8NyGVmUaYG4jtTkNonFZI86MmGRDqBphEK2EXT9gdEUoQPZhuBM8yWHxCWbobltqYO5M4XrUvQ==}

  section-matter@1.0.0:
    resolution: {integrity: sha512-vfD3pmTzGpufjScBh50YHKzEu2lxBWhVEHsNGoEXmCmn2hKGfeNLYMzCJpe8cD7gqX7TJluOVpBkAequ6dgMmA==}
    engines: {node: '>=4'}

  server-only@0.0.1:
    resolution: {integrity: sha512-qepMx2JxAa5jjfzxG79yPPq+8BuFToHd1hm7kI+Z4zAq1ftQiP7HcxMhDDItrbtwVeLg/cY2JnKnrcFkmiswNA==}

  shebang-command@2.0.0:
    resolution: {integrity: sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==}
    engines: {node: '>=8'}

  shebang-regex@3.0.0:
    resolution: {integrity: sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==}
    engines: {node: '>=8'}

  shiki@1.18.0:
    resolution: {integrity: sha512-8jo7tOXr96h9PBQmOHVrltnETn1honZZY76YA79MHheGQg55jBvbm9dtU+MI5pjC5NJCFuA6rvVTLVeSW5cE4A==}

  shiki@1.20.0:
    resolution: {integrity: sha512-MZJJ1PCFsQB1Piq+25wiz0a75yUv8Q3/fzy7SzRx5ONdjdtGdyiKwYn8vb/FnK5kjS0voWGnPpjG16POauUR+g==}

  signal-exit@4.1.0:
    resolution: {integrity: sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==}
    engines: {node: '>=14'}

  sister@3.0.2:
    resolution: {integrity: sha512-p19rtTs+NksBRKW9qn0UhZ8/TUI9BPw9lmtHny+Y3TinWlOa9jWh9xB0AtPSdmOy49NJJJSSe0Ey4C7h0TrcYA==}

  snake-case@3.0.4:
    resolution: {integrity: sha512-LAOh4z89bGQvl9pFfNF8V146i7o7/CqFPbqzYgP+yYzDIDeS9HaNFtXABamRW+AQzEVODcvE79ljJ+8a9YSdMg==}

  snakecase-keys@5.4.4:
    resolution: {integrity: sha512-YTywJG93yxwHLgrYLZjlC75moVEX04LZM4FHfihjHe1FCXm+QaLOFfSf535aXOAd0ArVQMWUAe8ZPm4VtWyXaA==}
    engines: {node: '>=12'}

  source-map-js@1.2.1:
    resolution: {integrity: sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==}
    engines: {node: '>=0.10.0'}

  source-map@0.7.4:
    resolution: {integrity: sha512-l3BikUxvPOcn5E74dZiq5BGsTb5yEwhaTSzccU6t4sDOH8NWJCstKO5QT2CvtFoK6F0saL7p9xHAqHOlCPJygA==}
    engines: {node: '>= 8'}

  space-separated-tokens@1.1.5:
    resolution: {integrity: sha512-q/JSVd1Lptzhf5bkYm4ob4iWPjx0KiRe3sRFBNrVqbJkFaBm5vbbowy1mymoPNLRa52+oadOhJ+K49wsSeSjTA==}

  space-separated-tokens@2.0.2:
    resolution: {integrity: sha512-PEGlAwrG8yXGXRjW32fGbg66JAlOAwbObuqVoJpv/mRgoWDQfgH1wDPvtzWyUSNAXBGSk8h755YDbbcEy3SH2Q==}

  sprintf-js@1.0.3:
    resolution: {integrity: sha512-D9cPgkvLlV3t3IzL0D0YLvGA9Ahk4PcvVwUbN0dSGr1aP0Nrt4AEnTUbuGvquEC0mA64Gqt1fzirlRs5ibXx8g==}

  std-env@3.7.0:
    resolution: {integrity: sha512-JPbdCEQLj1w5GilpiHAx3qJvFndqybBysA3qUOnznweH4QbNYUsW/ea8QzSrnh0vNsezMMw5bcVool8lM0gwzg==}

  streamsearch@1.1.0:
    resolution: {integrity: sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==}
    engines: {node: '>=10.0.0'}

  string-width@4.2.3:
    resolution: {integrity: sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==}
    engines: {node: '>=8'}

  string-width@5.1.2:
    resolution: {integrity: sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==}
    engines: {node: '>=12'}

  stringify-entities@4.0.4:
    resolution: {integrity: sha512-IwfBptatlO+QCJUo19AqvrPNqlVMpW9YEL2LIVY+Rpv2qsjCGxaDLNRgeGsQWJhfItebuJhsGSLjaBbNSQ+ieg==}

  strip-ansi@6.0.1:
    resolution: {integrity: sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==}
    engines: {node: '>=8'}

  strip-ansi@7.1.0:
    resolution: {integrity: sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==}
    engines: {node: '>=12'}

  strip-bom-string@1.0.0:
    resolution: {integrity: sha512-uCC2VHvQRYu+lMh4My/sFNmF2klFymLX1wHJeXnbEJERpV/ZsVuonzerjfrGpIGF7LBVa1O7i9kjiWvJiFck8g==}
    engines: {node: '>=0.10.0'}

  style-to-object@0.4.4:
    resolution: {integrity: sha512-HYNoHZa2GorYNyqiCaBgsxvcJIn7OHq6inEga+E6Ke3m5JkoqpQbnFssk4jwe+K7AhGa2fcha4wSOf1Kn01dMg==}

  style-to-object@1.0.8:
    resolution: {integrity: sha512-xT47I/Eo0rwJmaXC4oilDGDWLohVhR6o/xAQcPQN8q6QBuZVL8qMYL85kLmST5cPjAorwvqIA4qXTRQoYHaL6g==}

  styled-jsx@5.1.1:
    resolution: {integrity: sha512-pW7uC1l4mBZ8ugbiZrcIsiIvVx1UmTfw7UkC3Um2tmfUq9Bhk8IiyEIPl6F8agHgjzku6j0xQEZbfA5uSgSaCw==}
    engines: {node: '>= 12.0.0'}
    peerDependencies:
      '@babel/core': '*'
      babel-plugin-macros: '*'
      react: '>= 16.8.0 || 17.x.x || ^18.0.0-0'
    peerDependenciesMeta:
      '@babel/core':
        optional: true
      babel-plugin-macros:
        optional: true

  stylis@4.3.4:
    resolution: {integrity: sha512-osIBl6BGUmSfDkyH2mB7EFvCJntXDrLhKjHTRj/rK6xLH0yuPrHULDRQzKokSOD4VoorhtKpfcfW1GAntu8now==}

  sucrase@3.35.0:
    resolution: {integrity: sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==}
    engines: {node: '>=16 || 14 >=14.17'}
    hasBin: true

  supports-color@7.2.0:
    resolution: {integrity: sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==}
    engines: {node: '>=8'}

  supports-preserve-symlinks-flag@1.0.0:
    resolution: {integrity: sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==}
    engines: {node: '>= 0.4'}

  swr@2.2.5:
    resolution: {integrity: sha512-QtxqyclFeAsxEUeZIYmsaQ0UjimSq1RZ9Un7I68/0ClKK/U3LoyQunwkQfJZr2fc22DfIXLNDc2wFyTEikCUpg==}
    peerDependencies:
      react: ^16.11.0 || ^17.0.0 || ^18.0.0

  tabbable@6.2.0:
    resolution: {integrity: sha512-Cat63mxsVJlzYvN51JmVXIgNoUokrIaT2zLclCXjRd8boZ0004U4KCs/sToJ75C6sdlByWxpYnb5Boif1VSFew==}

  tailwind-merge@2.5.2:
    resolution: {integrity: sha512-kjEBm+pvD+6eAwzJL2Bi+02/9LFLal1Gs61+QB7HvTfQQ0aXwC5LGT8PEt1gS0CWKktKe6ysPTAy3cBC5MeiIg==}

  tailwindcss-animate@1.0.7:
    resolution: {integrity: sha512-bl6mpH3T7I3UFxuvDEXLxy/VuFxBk5bbzplh7tXI68mwMokNYd1t9qPBHlnyTwfa4JGC4zP516I1hYYtQ/vspA==}
    peerDependencies:
      tailwindcss: '>=3.0.0 || insiders'

  tailwindcss@3.4.13:
    resolution: {integrity: sha512-KqjHOJKogOUt5Bs752ykCeiwvi0fKVkr5oqsFNt/8px/tA8scFPIlkygsf6jXrfCqGHz7VflA6+yytWuM+XhFw==}
    engines: {node: '>=14.0.0'}
    hasBin: true

  thenify-all@1.6.0:
    resolution: {integrity: sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==}
    engines: {node: '>=0.8'}

  thenify@3.3.1:
    resolution: {integrity: sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==}

  tinyexec@0.3.0:
    resolution: {integrity: sha512-tVGE0mVJPGb0chKhqmsoosjsS+qUnJVGJpZgsHYQcGoPlG3B51R3PouqTgEGH2Dc9jjFyOqOpix6ZHNMXp1FZg==}

  to-regex-range@5.0.1:
    resolution: {integrity: sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==}
    engines: {node: '>=8.0'}

  tr46@0.0.3:
    resolution: {integrity: sha512-N3WMsuqV66lT30CrXNbEjx4GEwlow3v6rr4mCcv6prnfwhS01rkgyFdjPNBYd9br7LpXV1+Emh01fHnq2Gdgrw==}

  trim-lines@3.0.1:
    resolution: {integrity: sha512-kRj8B+YHZCc9kQYdWfJB2/oUl9rA99qbowYYBtr4ui4mZyAQ2JpvVBd/6U2YloATfqBhBTSMhTpgBHtU0Mf3Rg==}

  trough@2.2.0:
    resolution: {integrity: sha512-tmMpK00BjZiUyVyvrBK7knerNgmgvcV/KLVyuma/SC+TQN167GrMRciANTz09+k3zW8L8t60jWO1GpfkZdjTaw==}

  ts-dedent@2.2.0:
    resolution: {integrity: sha512-q5W7tVM71e2xjHZTlgfTDoPF/SmqKG5hddq9SzR49CH2hayqRKJtQ4mtRlSxKaJlR/+9rEM+mnBHf7I2/BQcpQ==}
    engines: {node: '>=6.10'}

  ts-interface-checker@0.1.13:
    resolution: {integrity: sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==}

  tslib@2.4.1:
    resolution: {integrity: sha512-tGyy4dAjRIEwI7BzsB0lynWgOpfqjUdq91XXAlIWD2OwKBH7oCl/GZG/HT4BOHrTlPMOASlMQ7veyTqpmRcrNA==}

  tslib@2.7.0:
    resolution: {integrity: sha512-gLXCKdN1/j47AiHiOkJN69hJmcbGTHI0ImLmbYLHykhgeN0jVGola9yVjFgzCUklsZQMW55o+dW7IXv3RCXDzA==}

  type-fest@2.19.0:
    resolution: {integrity: sha512-RAH822pAdBgcNMAfWnCBU3CFZcfZ/i1eZjwFU/dsLKumyuuP3niueg2UAukXYF0E2AAoc82ZSSf9J0WQBinzHA==}
    engines: {node: '>=12.20'}

  typescript@5.6.2:
    resolution: {integrity: sha512-NW8ByodCSNCwZeghjN3o+JX5OFH0Ojg6sadjEKY4huZ52TqbJTJnDo5+Tw98lSy63NZvi4n+ez5m2u5d4PkZyw==}
    engines: {node: '>=14.17'}
    hasBin: true

  ufo@1.5.4:
    resolution: {integrity: sha512-UsUk3byDzKd04EyoZ7U4DOlxQaD14JUKQl6/P7wiX4FNvUfm3XL246n9W5AmqwW5RSFJ27NAuM0iLscAOYUiGQ==}

  undici-types@6.19.8:
    resolution: {integrity: sha512-ve2KP6f/JnbPBFyobGHuerC9g1FYGn/F8n1LWTwNxCEzd6IfqTwUQcNXgEtmmQ6DlRrC1hrSrBnCZPokRrDHjw==}

  unified@10.1.2:
    resolution: {integrity: sha512-pUSWAi/RAnVy1Pif2kAoeWNBa3JVrx0MId2LASj8G+7AiHWoKZNTomq6LG326T68U7/e263X6fTdcXIy7XnF7Q==}

  unified@11.0.5:
    resolution: {integrity: sha512-xKvGhPWw3k84Qjh8bI3ZeJjqnyadK+GEFtazSfZv/rKeTkTjOJho6mFqh2SM96iIcZokxiOpg78GazTSg8+KHA==}

  unist-util-generated@2.0.1:
    resolution: {integrity: sha512-qF72kLmPxAw0oN2fwpWIqbXAVyEqUzDHMsbtPvOudIlUzXYFIeQIuxXQCRCFh22B7cixvU0MG7m3MW8FTq/S+A==}

  unist-util-is@5.2.1:
    resolution: {integrity: sha512-u9njyyfEh43npf1M+yGKDGVPbY/JWEemg5nH05ncKPfi+kBbKBJoTdsogMu33uhytuLlv9y0O7GH7fEdwLdLQw==}

  unist-util-is@6.0.0:
    resolution: {integrity: sha512-2qCTHimwdxLfz+YzdGfkqNlH0tLi9xjTnHddPmJwtIG9MGsdbutfTc4P+haPD7l7Cjxf/WZj+we5qfVPvvxfYw==}

  unist-util-position-from-estree@2.0.0:
    resolution: {integrity: sha512-KaFVRjoqLyF6YXCbVLNad/eS4+OfPQQn2yOd7zF/h5T/CSL2v8NpN6a5TPvtbXthAGw5nG+PuTtq+DdIZr+cRQ==}

  unist-util-position@4.0.4:
    resolution: {integrity: sha512-kUBE91efOWfIVBo8xzh/uZQ7p9ffYRtUbMRZBNFYwf0RK8koUMx6dGUfwylLOKmaT2cs4wSW96QoYUSXAyEtpg==}

  unist-util-position@5.0.0:
    resolution: {integrity: sha512-fucsC7HjXvkB5R3kTCO7kUjRdrS0BJt3M/FPxmHMBOm8JQi2BsHAHFsy27E0EolP8rp0NzXsJ+jNPyDWvOJZPA==}

  unist-util-stringify-position@3.0.3:
    resolution: {integrity: sha512-k5GzIBZ/QatR8N5X2y+drfpWG8IDBzdnVj6OInRNWm1oXrzydiaAT2OQiA8DPRRZyAKb9b6I2a6PxYklZD0gKg==}

  unist-util-stringify-position@4.0.0:
    resolution: {integrity: sha512-0ASV06AAoKCDkS2+xw5RXJywruurpbC4JZSm7nr7MOt1ojAzvyyaO+UxZf18j8FCF6kmzCZKcAgN/yu2gm2XgQ==}

  unist-util-visit-parents@5.1.3:
    resolution: {integrity: sha512-x6+y8g7wWMyQhL1iZfhIPhDAs7Xwbn9nRosDXl7qoPTSCy0yNxnKc+hWokFifWQIDGi154rdUqKvbCa4+1kLhg==}

  unist-util-visit-parents@6.0.1:
    resolution: {integrity: sha512-L/PqWzfTP9lzzEa6CKs0k2nARxTdZduw3zyh8d2NVBnsyvHjSX4TWse388YrrQKbvI8w20fGjGlhgT96WwKykw==}

  unist-util-visit@4.1.2:
    resolution: {integrity: sha512-MSd8OUGISqHdVvfY9TPhyK2VdUrPgxkUtWSuMHF6XAAFuL4LokseigBnZtPnJMu+FbynTkFNnFlyjxpVKujMRg==}

  unist-util-visit@5.0.0:
    resolution: {integrity: sha512-MR04uvD+07cwl/yhVuVWAtw+3GOR/knlL55Nd/wAdblk27GCVt3lqpTivy/tkJcZoNPzTwS1Y+KMojlLDhoTzg==}

  untruncate-json@0.0.1:
    resolution: {integrity: sha512-4W9enDK4X1y1s2S/Rz7ysw6kDuMS3VmRjMFg7GZrNO+98OSe+x5Lh7PKYoVjy3lW/1wmhs6HW0lusnQRHgMarA==}

  update-browserslist-db@1.1.0:
    resolution: {integrity: sha512-EdRAaAyk2cUE1wOf2DkEhzxqOQvFOoRJFNS6NeyJ01Gp2beMRpBAINjM2iDXE3KCuKhwnvHIQCJm6ThL2Z+HzQ==}
    hasBin: true
    peerDependencies:
      browserslist: '>= 4.21.0'

  urql@4.2.2:
    resolution: {integrity: sha512-3GgqNa6iF7bC4hY/ImJKN4REQILcSU9VKcKL8gfELZM8mM5BnLH1BsCc8kBdnVGD1LIFOs4W3O2idNHhON1r0w==}
    peerDependencies:
      '@urql/core': ^5.0.0
      react: '>= 16.8.0'

  use-callback-ref@1.3.2:
    resolution: {integrity: sha512-elOQwe6Q8gqZgDA8mrh44qRTQqpIHDcZ3hXTLjBe1i4ph8XpNJnO+aQf3NaG+lriLopI4HMx9VjQLfPQ6vhnoA==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.8.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  use-sidecar@1.1.2:
    resolution: {integrity: sha512-epTbsLuzZ7lPClpz2TyryBfztm7m+28DlEv2ZCQ3MDr5ssiwyOwGH/e5F9CkfWjJ1t4clvI58yF822/GUkjjhw==}
    engines: {node: '>=10'}
    peerDependencies:
      '@types/react': ^16.9.0 || ^17.0.0 || ^18.0.0
      react: ^16.8.0 || ^17.0.0 || ^18.0.0
    peerDependenciesMeta:
      '@types/react':
        optional: true

  use-sync-external-store@1.2.2:
    resolution: {integrity: sha512-PElTlVMwpblvbNqQ82d2n6RjStvdSoNe9FG28kNfz3WiXilJm4DdNkEzRhCZuIDwY8U08WVihhGR5iRqAwfDiw==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0 || ^18.0.0

  usehooks-ts@3.1.0:
    resolution: {integrity: sha512-bBIa7yUyPhE1BCc0GmR96VU/15l/9gP1Ch5mYdLcFBaFGQsdmXkvjV0TtOqW1yUd6VjIwDunm+flSciCQXujiw==}
    engines: {node: '>=16.15.0'}
    peerDependencies:
      react: ^16.8.0  || ^17 || ^18

  util-deprecate@1.0.2:
    resolution: {integrity: sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==}

  uuid@10.0.0:
    resolution: {integrity: sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==}
    hasBin: true

  uuid@9.0.1:
    resolution: {integrity: sha512-b+1eJOlsR9K8HJpow9Ok3fiWOWSIcIzXodvv0rQjVoOVNpWMpxf1wZNpt4y9h10odCNrqnYp1OBzRktckBe3sA==}
    hasBin: true

  uvu@0.5.6:
    resolution: {integrity: sha512-+g8ENReyr8YsOc6fv/NVJs2vFdHBnBNdfE49rshrTzDWOlUx4Gq7KOS2GD8eqhy2j+Ejq29+SbKH8yjkAqXqoA==}
    engines: {node: '>=8'}
    hasBin: true

  vfile-message@3.1.4:
    resolution: {integrity: sha512-fa0Z6P8HUrQN4BZaX05SIVXic+7kE3b05PWAtPuYP9QLHsLKYR7/AlLW3NtOrpXRLeawpDLMsVkmk5DG0NXgWw==}

  vfile-message@4.0.2:
    resolution: {integrity: sha512-jRDZ1IMLttGj41KcZvlrYAaI3CfqpLpfpf+Mfig13viT6NKvRzWZ+lXz0Y5D60w6uJIBAOGq9mSHf0gktF0duw==}

  vfile@5.3.7:
    resolution: {integrity: sha512-r7qlzkgErKjobAmyNIkkSpizsFPYiUPuJb5pNW1RB4JcYVZhs4lIbVqk8XPk033CV/1z8ss5pkax8SuhGpcG8g==}

  vfile@6.0.3:
    resolution: {integrity: sha512-KzIbH/9tXat2u30jf+smMwFCsno4wHVdNmzFyL+T/L3UGqqk6JKfVqOFOZEpZSHADH1k40ab6NUIXZq422ov3Q==}

  vscode-jsonrpc@8.2.0:
    resolution: {integrity: sha512-C+r0eKJUIfiDIfwJhria30+TYWPtuHJXHtI7J0YlOmKAo7ogxP20T0zxB7HZQIFhIyvoBPwWskjxrvAtfjyZfA==}
    engines: {node: '>=14.0.0'}

  vscode-languageserver-protocol@3.17.5:
    resolution: {integrity: sha512-mb1bvRJN8SVznADSGWM9u/b07H7Ecg0I3OgXDuLdn307rl/J3A9YD6/eYOssqhecL27hK1IPZAsaqh00i/Jljg==}

  vscode-languageserver-textdocument@1.0.12:
    resolution: {integrity: sha512-cxWNPesCnQCcMPeenjKKsOCKQZ/L6Tv19DTRIGuLWe32lyzWhihGVJ/rcckZXJxfdKCFvRLS3fpBIsV/ZGX4zA==}

  vscode-languageserver-types@3.17.5:
    resolution: {integrity: sha512-Ld1VelNuX9pdF39h2Hgaeb5hEZM2Z3jUrrMgWQAu82jMtZp7p3vJT3BzToKtZI7NgQssZje5o0zryOrhQvzQAg==}

  vscode-languageserver@9.0.1:
    resolution: {integrity: sha512-woByF3PDpkHFUreUa7Hos7+pUWdeWMXRd26+ZX2A8cFx6v/JPTtd4/uN0/jB6XQHYaOlHbio03NTHCqrgG5n7g==}
    hasBin: true

  vscode-uri@3.0.8:
    resolution: {integrity: sha512-AyFQ0EVmsOZOlAnxoFOGOq1SQDWAB7C6aqMGS23svWAllfOaxbuFvcT8D1i8z3Gyn8fraVeZNNmN6e9bxxXkKw==}

  web-vitals@4.2.3:
    resolution: {integrity: sha512-/CFAm1mNxSmOj6i0Co+iGFJ58OS4NRGVP+AWS/l509uIK5a1bSoIVaHz/ZumpHTfHSZBpgrJ+wjfpAOrTHok5Q==}

  webidl-conversions@3.0.1:
    resolution: {integrity: sha512-2JAn3z8AR6rjK8Sm8orRC0h/bcl/DqL7tRPdGZ4I1CjdF+EaMLmYxBHyXuKL849eucPFhvBoxMsflfOb8kxaeQ==}

  whatwg-url@5.0.0:
    resolution: {integrity: sha512-saE57nupxk6v3HY35+jzBwYa0rKSy0XR8JSxZPwgLr7ys0IBzhGviA1/TUGJLmSVqs8pb9AnvICXEuOHLprYTw==}

  which@2.0.2:
    resolution: {integrity: sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==}
    engines: {node: '>= 8'}
    hasBin: true

  wonka@6.3.5:
    resolution: {integrity: sha512-SSil+ecw6B4/Dm7Pf2sAshKQ5hWFvfyGlfPbEd6A14dOH6VDjrmbY86u6nZvy9omGwwIPFR8V41+of1EezgoUw==}

  wrap-ansi@7.0.0:
    resolution: {integrity: sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==}
    engines: {node: '>=10'}

  wrap-ansi@8.1.0:
    resolution: {integrity: sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==}
    engines: {node: '>=12'}

  xtend@4.0.2:
    resolution: {integrity: sha512-LKYU1iAXJXUgAXn9URjiu+MWhyUXHsvfp7mcuYm9dSUKK0/CjtrUwFAxD82/mCWbtLsGjFIad0wIsod4zrTAEQ==}
    engines: {node: '>=0.4'}

  yaml@2.5.1:
    resolution: {integrity: sha512-bLQOjaX/ADgQ20isPJRvF0iRUHIxVhYvr53Of7wGcWlO2jvtUlH5m87DsmulFVxRpNLOnI4tB6p/oh8D7kpn9Q==}
    engines: {node: '>= 14'}
    hasBin: true

  youtube-player@5.5.2:
    resolution: {integrity: sha512-ZGtsemSpXnDky2AUYWgxjaopgB+shFHgXVpiJFeNB5nWEugpW1KWYDaHKuLqh2b67r24GtP6HoSW5swvf0fFIQ==}

  zod-to-json-schema@3.24.5:
    resolution: {integrity: sha512-/AuWwMP+YqiPbsJx5D6TfgRTc4kTLjsh5SOcd4bLsfUg2RcEXrFMJl1DGgdHy2aCfsIA/cr/1JM0xcB2GZji8g==}
    peerDependencies:
      zod: ^3.24.1

  zod@3.23.8:
    resolution: {integrity: sha512-XBx9AXhXktjUqnepgTiE5flcKIYWi/rme0Eaj+5Y0lftuGBq+jyRu/md4WnuxqgP1ubdpNCsYEYPxrzVHD8d6g==}

  zwitch@2.0.4:
    resolution: {integrity: sha512-bXE4cR/kVZhKZX/RjPEflHaKVhUVl85noU3v6b8apfQEc1x4A+zBxjZ4lN8LqGd6WZ3dl98pY4o717VFmoPp+A==}

snapshots:

  '@0no-co/graphql.web@1.1.2(graphql@16.10.0)':
    optionalDependencies:
      graphql: 16.10.0

  '@alloc/quick-lru@5.2.0': {}

  '@antfu/install-pkg@0.4.1':
    dependencies:
      package-manager-detector: 0.2.0
      tinyexec: 0.3.0

  '@antfu/utils@0.7.10': {}

  '@babel/runtime@7.25.6':
    dependencies:
      regenerator-runtime: 0.14.1

  '@braintree/sanitize-url@7.1.0': {}

  '@chevrotain/cst-dts-gen@11.0.3':
    dependencies:
      '@chevrotain/gast': 11.0.3
      '@chevrotain/types': 11.0.3
      lodash-es: 4.17.21

  '@chevrotain/gast@11.0.3':
    dependencies:
      '@chevrotain/types': 11.0.3
      lodash-es: 4.17.21

  '@chevrotain/regexp-to-ast@11.0.3': {}

  '@chevrotain/types@11.0.3': {}

  '@chevrotain/utils@11.0.3': {}

  '@clerk/backend@1.19.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@clerk/shared': 2.19.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@clerk/types': 4.38.0
      cookie: 0.7.0
      snakecase-keys: 5.4.4
      tslib: 2.4.1
    transitivePeerDependencies:
      - react
      - react-dom

  '@clerk/clerk-react@5.18.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@clerk/shared': 2.19.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@clerk/types': 4.38.0
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      tslib: 2.4.1

  '@clerk/nextjs@6.7.1(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@clerk/backend': 1.19.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@clerk/clerk-react': 5.18.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@clerk/shared': 2.19.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@clerk/types': 4.38.0
      crypto-js: 4.2.0
      next: 14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      server-only: 0.0.1
      tslib: 2.4.1

  '@clerk/shared@2.19.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@clerk/types': 4.38.0
      dequal: 2.0.3
      glob-to-regexp: 0.4.1
      js-cookie: 3.0.5
      std-env: 3.7.0
      swr: 2.2.5(react@18.3.1)
    optionalDependencies:
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@clerk/types@4.38.0':
    dependencies:
      csstype: 3.1.1

  '@copilotkit/react-core@1.8.2(@types/react@18.3.9)(graphql@16.10.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@copilotkit/runtime-client-gql': 1.8.2(graphql@16.10.0)(react@18.3.1)
      '@copilotkit/shared': 1.8.2
      '@scarf/scarf': 1.4.0
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-markdown: 8.0.7(@types/react@18.3.9)(react@18.3.1)
      untruncate-json: 0.0.1
    transitivePeerDependencies:
      - '@types/react'
      - encoding
      - graphql
      - supports-color

  '@copilotkit/react-ui@1.8.2(@types/react@18.3.9)(graphql@16.10.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@copilotkit/react-core': 1.8.2(@types/react@18.3.9)(graphql@16.10.0)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@copilotkit/runtime-client-gql': 1.8.2(graphql@16.10.0)(react@18.3.1)
      '@copilotkit/shared': 1.8.2
      '@headlessui/react': 2.2.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-markdown: 8.0.7(@types/react@18.3.9)(react@18.3.1)
      react-syntax-highlighter: 15.6.1(react@18.3.1)
      remark-gfm: 3.0.1
      remark-math: 5.1.1
    transitivePeerDependencies:
      - '@types/react'
      - encoding
      - graphql
      - react-dom
      - supports-color

  '@copilotkit/runtime-client-gql@1.8.2(graphql@16.10.0)(react@18.3.1)':
    dependencies:
      '@copilotkit/shared': 1.8.2
      '@urql/core': 5.1.1(graphql@16.10.0)
      react: 18.3.1
      untruncate-json: 0.0.1
      urql: 4.2.2(@urql/core@5.1.1(graphql@16.10.0))(react@18.3.1)
    transitivePeerDependencies:
      - encoding
      - graphql

  '@copilotkit/shared@1.8.2':
    dependencies:
      '@segment/analytics-node': 2.2.1
      chalk: 4.1.2
      graphql: 16.10.0
      uuid: 10.0.0
      zod: 3.23.8
      zod-to-json-schema: 3.24.5(zod@3.23.8)
    transitivePeerDependencies:
      - encoding

  '@esbuild/aix-ppc64@0.23.1':
    optional: true

  '@esbuild/android-arm64@0.23.1':
    optional: true

  '@esbuild/android-arm@0.23.1':
    optional: true

  '@esbuild/android-x64@0.23.1':
    optional: true

  '@esbuild/darwin-arm64@0.23.1':
    optional: true

  '@esbuild/darwin-x64@0.23.1':
    optional: true

  '@esbuild/freebsd-arm64@0.23.1':
    optional: true

  '@esbuild/freebsd-x64@0.23.1':
    optional: true

  '@esbuild/linux-arm64@0.23.1':
    optional: true

  '@esbuild/linux-arm@0.23.1':
    optional: true

  '@esbuild/linux-ia32@0.23.1':
    optional: true

  '@esbuild/linux-loong64@0.23.1':
    optional: true

  '@esbuild/linux-mips64el@0.23.1':
    optional: true

  '@esbuild/linux-ppc64@0.23.1':
    optional: true

  '@esbuild/linux-riscv64@0.23.1':
    optional: true

  '@esbuild/linux-s390x@0.23.1':
    optional: true

  '@esbuild/linux-x64@0.23.1':
    optional: true

  '@esbuild/netbsd-x64@0.23.1':
    optional: true

  '@esbuild/openbsd-arm64@0.23.1':
    optional: true

  '@esbuild/openbsd-x64@0.23.1':
    optional: true

  '@esbuild/sunos-x64@0.23.1':
    optional: true

  '@esbuild/win32-arm64@0.23.1':
    optional: true

  '@esbuild/win32-ia32@0.23.1':
    optional: true

  '@esbuild/win32-x64@0.23.1':
    optional: true

  '@floating-ui/core@1.6.8':
    dependencies:
      '@floating-ui/utils': 0.2.8

  '@floating-ui/dom@1.6.11':
    dependencies:
      '@floating-ui/core': 1.6.8
      '@floating-ui/utils': 0.2.8

  '@floating-ui/react-dom@2.1.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@floating-ui/dom': 1.6.11
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@floating-ui/react@0.26.28(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@floating-ui/react-dom': 2.1.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@floating-ui/utils': 0.2.8
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      tabbable: 6.2.0

  '@floating-ui/utils@0.2.8': {}

  '@formatjs/intl-localematcher@0.5.4':
    dependencies:
      tslib: 2.7.0

  '@headlessui/react@2.2.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@floating-ui/react': 0.26.28(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@react-aria/focus': 3.20.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@react-aria/interactions': 3.24.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@tanstack/react-virtual': 3.13.5(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@iconify/types@2.0.0': {}

  '@iconify/utils@2.1.33':
    dependencies:
      '@antfu/install-pkg': 0.4.1
      '@antfu/utils': 0.7.10
      '@iconify/types': 2.0.0
      debug: 4.3.7
      kolorist: 1.8.0
      local-pkg: 0.5.0
      mlly: 1.7.1
    transitivePeerDependencies:
      - supports-color

  '@icons-pack/react-simple-icons@11.2.0(react@18.3.1)':
    dependencies:
      react: 18.3.1

  '@isaacs/cliui@8.0.2':
    dependencies:
      string-width: 5.1.2
      string-width-cjs: string-width@4.2.3
      strip-ansi: 7.1.0
      strip-ansi-cjs: strip-ansi@6.0.1
      wrap-ansi: 8.1.0
      wrap-ansi-cjs: wrap-ansi@7.0.0

  '@jridgewell/gen-mapping@0.3.5':
    dependencies:
      '@jridgewell/set-array': 1.2.1
      '@jridgewell/sourcemap-codec': 1.5.0
      '@jridgewell/trace-mapping': 0.3.25

  '@jridgewell/resolve-uri@3.1.2': {}

  '@jridgewell/set-array@1.2.1': {}

  '@jridgewell/sourcemap-codec@1.5.0': {}

  '@jridgewell/trace-mapping@0.3.25':
    dependencies:
      '@jridgewell/resolve-uri': 3.1.2
      '@jridgewell/sourcemap-codec': 1.5.0

  '@lukeed/csprng@1.1.0': {}

  '@lukeed/uuid@2.0.1':
    dependencies:
      '@lukeed/csprng': 1.1.0

  '@mdx-js/mdx@3.0.1':
    dependencies:
      '@types/estree': 1.0.6
      '@types/estree-jsx': 1.0.5
      '@types/hast': 3.0.4
      '@types/mdx': 2.0.13
      collapse-white-space: 2.1.0
      devlop: 1.1.0
      estree-util-build-jsx: 3.0.1
      estree-util-is-identifier-name: 3.0.0
      estree-util-to-js: 2.0.0
      estree-walker: 3.0.3
      hast-util-to-estree: 3.1.0
      hast-util-to-jsx-runtime: 2.3.0
      markdown-extensions: 2.0.0
      periscopic: 3.1.0
      remark-mdx: 3.0.1
      remark-parse: 11.0.0
      remark-rehype: 11.1.1
      source-map: 0.7.4
      unified: 11.0.5
      unist-util-position-from-estree: 2.0.0
      unist-util-stringify-position: 4.0.0
      unist-util-visit: 5.0.0
      vfile: 6.0.3
    transitivePeerDependencies:
      - supports-color

  '@mermaid-js/parser@0.3.0':
    dependencies:
      langium: 3.0.0

  '@next/env@14.2.13': {}

  '@next/swc-darwin-arm64@14.2.13':
    optional: true

  '@next/swc-darwin-x64@14.2.13':
    optional: true

  '@next/swc-linux-arm64-gnu@14.2.13':
    optional: true

  '@next/swc-linux-arm64-musl@14.2.13':
    optional: true

  '@next/swc-linux-x64-gnu@14.2.13':
    optional: true

  '@next/swc-linux-x64-musl@14.2.13':
    optional: true

  '@next/swc-win32-arm64-msvc@14.2.13':
    optional: true

  '@next/swc-win32-ia32-msvc@14.2.13':
    optional: true

  '@next/swc-win32-x64-msvc@14.2.13':
    optional: true

  '@nodelib/fs.scandir@2.1.5':
    dependencies:
      '@nodelib/fs.stat': 2.0.5
      run-parallel: 1.2.0

  '@nodelib/fs.stat@2.0.5': {}

  '@nodelib/fs.walk@1.2.8':
    dependencies:
      '@nodelib/fs.scandir': 2.1.5
      fastq: 1.17.1

  '@pkgjs/parseargs@0.11.0':
    optional: true

  '@radix-ui/number@1.1.0': {}

  '@radix-ui/primitive@1.0.1':
    dependencies:
      '@babel/runtime': 7.25.6

  '@radix-ui/primitive@1.1.0': {}

  '@radix-ui/primitive@1.1.1': {}

  '@radix-ui/react-accordion@1.2.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-collapsible': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-collection': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-direction': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-arrow@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-collapsible@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-presence': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-collapsible@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-presence': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-collection@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-collection@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-compose-refs@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-compose-refs@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-compose-refs@1.1.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-context@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-context@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-context@1.1.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-dialog@1.0.5(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/primitive': 1.0.1
      '@radix-ui/react-compose-refs': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-dismissable-layer': 1.0.5(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-focus-guards': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-focus-scope': 1.0.4(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-id': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-portal': 1.0.4(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-presence': 1.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 1.0.3(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot': 1.0.2(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      aria-hidden: 1.2.4
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-remove-scroll: 2.5.5(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-dialog@1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-dismissable-layer': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-focus-guards': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-focus-scope': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-portal': 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-presence': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      aria-hidden: 1.2.4
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-remove-scroll: 2.6.0(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-direction@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-dismissable-layer@1.0.5(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/primitive': 1.0.1
      '@radix-ui/react-compose-refs': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 1.0.3(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-escape-keydown': 1.0.3(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-dismissable-layer@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-escape-keydown': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-dismissable-layer@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-escape-keydown': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-focus-guards@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-focus-guards@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-focus-guards@1.1.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-focus-scope@1.0.4(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-compose-refs': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 1.0.3(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-focus-scope@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-icons@1.3.0(react@18.3.1)':
    dependencies:
      react: 18.3.1

  '@radix-ui/react-id@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-use-layout-effect': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-id@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-popover@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-dismissable-layer': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-focus-guards': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-focus-scope': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-popper': 1.2.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-portal': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-presence': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      aria-hidden: 1.2.4
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-remove-scroll: 2.5.7(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-popper@1.2.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@floating-ui/react-dom': 2.1.2(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-arrow': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-rect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-size': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/rect': 1.1.0
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-portal@1.0.4(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-primitive': 1.0.3(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-portal@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-portal@1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-presence@1.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-compose-refs': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-presence@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-presence@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-presence@1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-primitive@1.0.3(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-slot': 1.0.2(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-primitive@2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-slot': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-primitive@2.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-slot': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-roving-focus@1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.1
      '@radix-ui/react-collection': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-compose-refs': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-direction': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-scroll-area@1.2.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/number': 1.1.0
      '@radix-ui/primitive': 1.1.1
      '@radix-ui/react-compose-refs': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-direction': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-presence': 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-select@2.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/number': 1.1.0
      '@radix-ui/primitive': 1.1.0
      '@radix-ui/react-collection': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-direction': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-dismissable-layer': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-focus-guards': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-focus-scope': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-popper': 1.2.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-portal': 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-slot': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-use-previous': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-visually-hidden': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      aria-hidden: 1.2.4
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-remove-scroll: 2.6.0(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-slot@1.0.2(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-compose-refs': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-slot@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-slot@1.1.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/react-compose-refs': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-tabs@1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/primitive': 1.1.1
      '@radix-ui/react-context': 1.1.1(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-direction': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-id': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-presence': 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 2.0.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-roving-focus': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-use-controllable-state': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/react-use-callback-ref@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-callback-ref@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-controllable-state@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-use-callback-ref': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-controllable-state@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-escape-keydown@1.0.3(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      '@radix-ui/react-use-callback-ref': 1.0.1(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-escape-keydown@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/react-use-callback-ref': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-layout-effect@1.0.1(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@babel/runtime': 7.25.6
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-layout-effect@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-previous@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-rect@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/rect': 1.1.0
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-use-size@1.1.0(@types/react@18.3.9)(react@18.3.1)':
    dependencies:
      '@radix-ui/react-use-layout-effect': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      react: 18.3.1
    optionalDependencies:
      '@types/react': 18.3.9

  '@radix-ui/react-visually-hidden@1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@radix-ui/react-primitive': 2.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9
      '@types/react-dom': 18.3.0

  '@radix-ui/rect@1.1.0': {}

  '@react-aria/focus@3.20.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@react-aria/interactions': 3.24.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@react-aria/utils': 3.28.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@react-types/shared': 3.28.0(react@18.3.1)
      '@swc/helpers': 0.5.5
      clsx: 2.1.1
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@react-aria/interactions@3.24.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@react-aria/ssr': 3.9.7(react@18.3.1)
      '@react-aria/utils': 3.28.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@react-stately/flags': 3.1.0
      '@react-types/shared': 3.28.0(react@18.3.1)
      '@swc/helpers': 0.5.5
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@react-aria/ssr@3.9.7(react@18.3.1)':
    dependencies:
      '@swc/helpers': 0.5.5
      react: 18.3.1

  '@react-aria/utils@3.28.1(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@react-aria/ssr': 3.9.7(react@18.3.1)
      '@react-stately/flags': 3.1.0
      '@react-stately/utils': 3.10.5(react@18.3.1)
      '@react-types/shared': 3.28.0(react@18.3.1)
      '@swc/helpers': 0.5.5
      clsx: 2.1.1
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@react-stately/flags@3.1.0':
    dependencies:
      '@swc/helpers': 0.5.5

  '@react-stately/utils@3.10.5(react@18.3.1)':
    dependencies:
      '@swc/helpers': 0.5.5
      react: 18.3.1

  '@react-types/shared@3.28.0(react@18.3.1)':
    dependencies:
      react: 18.3.1

  '@scarf/scarf@1.4.0': {}

  '@segment/analytics-core@1.8.1':
    dependencies:
      '@lukeed/uuid': 2.0.1
      '@segment/analytics-generic-utils': 1.2.0
      dset: 3.1.4
      tslib: 2.7.0

  '@segment/analytics-generic-utils@1.2.0':
    dependencies:
      tslib: 2.7.0

  '@segment/analytics-node@2.2.1':
    dependencies:
      '@lukeed/uuid': 2.0.1
      '@segment/analytics-core': 1.8.1
      '@segment/analytics-generic-utils': 1.2.0
      buffer: 6.0.3
      jose: 5.10.0
      node-fetch: 2.7.0
      tslib: 2.7.0
    transitivePeerDependencies:
      - encoding

  '@shikijs/core@1.18.0':
    dependencies:
      '@shikijs/engine-javascript': 1.18.0
      '@shikijs/engine-oniguruma': 1.18.0
      '@shikijs/types': 1.18.0
      '@shikijs/vscode-textmate': 9.2.2
      '@types/hast': 3.0.4
      hast-util-to-html: 9.0.3

  '@shikijs/core@1.20.0':
    dependencies:
      '@shikijs/engine-javascript': 1.20.0
      '@shikijs/engine-oniguruma': 1.20.0
      '@shikijs/types': 1.20.0
      '@shikijs/vscode-textmate': 9.2.2
      '@types/hast': 3.0.4
      hast-util-to-html: 9.0.3

  '@shikijs/engine-javascript@1.18.0':
    dependencies:
      '@shikijs/types': 1.18.0
      '@shikijs/vscode-textmate': 9.2.2
      oniguruma-to-js: 0.4.3

  '@shikijs/engine-javascript@1.20.0':
    dependencies:
      '@shikijs/types': 1.20.0
      '@shikijs/vscode-textmate': 9.2.2
      oniguruma-to-js: 0.4.3

  '@shikijs/engine-oniguruma@1.18.0':
    dependencies:
      '@shikijs/types': 1.18.0
      '@shikijs/vscode-textmate': 9.2.2

  '@shikijs/engine-oniguruma@1.20.0':
    dependencies:
      '@shikijs/types': 1.20.0
      '@shikijs/vscode-textmate': 9.2.2

  '@shikijs/rehype@1.18.0':
    dependencies:
      '@shikijs/types': 1.18.0
      '@types/hast': 3.0.4
      hast-util-to-string: 3.0.0
      shiki: 1.18.0
      unified: 11.0.5
      unist-util-visit: 5.0.0

  '@shikijs/transformers@1.20.0':
    dependencies:
      shiki: 1.20.0

  '@shikijs/types@1.18.0':
    dependencies:
      '@shikijs/vscode-textmate': 9.2.2
      '@types/hast': 3.0.4

  '@shikijs/types@1.20.0':
    dependencies:
      '@shikijs/vscode-textmate': 9.2.2
      '@types/hast': 3.0.4

  '@shikijs/vscode-textmate@9.2.2': {}

  '@swc/counter@0.1.3': {}

  '@swc/helpers@0.5.5':
    dependencies:
      '@swc/counter': 0.1.3
      tslib: 2.7.0

  '@tailwindcss/typography@0.5.15(tailwindcss@3.4.13)':
    dependencies:
      lodash.castarray: 4.4.0
      lodash.isplainobject: 4.0.6
      lodash.merge: 4.6.2
      postcss-selector-parser: 6.0.10
      tailwindcss: 3.4.13

  '@tanstack/react-virtual@3.13.5(react-dom@18.3.1(react@18.3.1))(react@18.3.1)':
    dependencies:
      '@tanstack/virtual-core': 3.13.5
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  '@tanstack/virtual-core@3.13.5': {}

  '@theguild/remark-mermaid@0.1.3(react@18.3.1)':
    dependencies:
      mermaid: 11.2.1
      react: 18.3.1
      unist-util-visit: 5.0.0
    transitivePeerDependencies:
      - supports-color

  '@theguild/remark-npm2yarn@0.3.2':
    dependencies:
      npm-to-yarn: 3.0.0
      unist-util-visit: 5.0.0

  '@types/acorn@4.0.6':
    dependencies:
      '@types/estree': 1.0.6

  '@types/debug@4.1.12':
    dependencies:
      '@types/ms': 0.7.34

  '@types/estree-jsx@1.0.5':
    dependencies:
      '@types/estree': 1.0.6

  '@types/estree@1.0.6': {}

  '@types/hast@2.3.10':
    dependencies:
      '@types/unist': 2.0.11

  '@types/hast@3.0.4':
    dependencies:
      '@types/unist': 3.0.3

  '@types/katex@0.16.7': {}

  '@types/mdast@3.0.15':
    dependencies:
      '@types/unist': 2.0.11

  '@types/mdast@4.0.4':
    dependencies:
      '@types/unist': 3.0.3

  '@types/mdx@2.0.13': {}

  '@types/ms@0.7.34': {}

  '@types/node@22.5.4':
    dependencies:
      undici-types: 6.19.8

  '@types/prop-types@15.7.13': {}

  '@types/react-dom@18.3.0':
    dependencies:
      '@types/react': 18.3.9

  '@types/react@18.3.9':
    dependencies:
      '@types/prop-types': 15.7.13
      csstype: 3.1.3

  '@types/unist@2.0.11': {}

  '@types/unist@3.0.3': {}

  '@ungap/structured-clone@1.2.0': {}

  '@urql/core@5.1.1(graphql@16.10.0)':
    dependencies:
      '@0no-co/graphql.web': 1.1.2(graphql@16.10.0)
      wonka: 6.3.5
    transitivePeerDependencies:
      - graphql

  acorn-jsx@5.3.2(acorn@8.12.1):
    dependencies:
      acorn: 8.12.1

  acorn@8.12.1: {}

  ansi-regex@5.0.1: {}

  ansi-regex@6.1.0: {}

  ansi-styles@4.3.0:
    dependencies:
      color-convert: 2.0.1

  ansi-styles@6.2.1: {}

  any-promise@1.3.0: {}

  anymatch@3.1.3:
    dependencies:
      normalize-path: 3.0.0
      picomatch: 2.3.1

  arg@5.0.2: {}

  argparse@1.0.10:
    dependencies:
      sprintf-js: 1.0.3

  aria-hidden@1.2.4:
    dependencies:
      tslib: 2.7.0

  astring@1.9.0: {}

  autoprefixer@10.4.20(postcss@8.4.47):
    dependencies:
      browserslist: 4.24.0
      caniuse-lite: 1.0.30001663
      fraction.js: 4.3.7
      normalize-range: 0.1.2
      picocolors: 1.1.0
      postcss: 8.4.47
      postcss-value-parser: 4.2.0

  bail@2.0.2: {}

  balanced-match@1.0.2: {}

  base64-js@1.5.1: {}

  binary-extensions@2.3.0: {}

  brace-expansion@2.0.1:
    dependencies:
      balanced-match: 1.0.2

  braces@3.0.3:
    dependencies:
      fill-range: 7.1.1

  browserslist@4.24.0:
    dependencies:
      caniuse-lite: 1.0.30001663
      electron-to-chromium: 1.5.28
      node-releases: 2.0.18
      update-browserslist-db: 1.1.0(browserslist@4.24.0)

  buffer@6.0.3:
    dependencies:
      base64-js: 1.5.1
      ieee754: 1.2.1

  busboy@1.6.0:
    dependencies:
      streamsearch: 1.1.0

  camelcase-css@2.0.1: {}

  caniuse-lite@1.0.30001663: {}

  ccount@2.0.1: {}

  chalk@4.1.2:
    dependencies:
      ansi-styles: 4.3.0
      supports-color: 7.2.0

  character-entities-html4@2.1.0: {}

  character-entities-legacy@1.1.4: {}

  character-entities-legacy@3.0.0: {}

  character-entities@1.2.4: {}

  character-entities@2.0.2: {}

  character-reference-invalid@1.1.4: {}

  character-reference-invalid@2.0.1: {}

  chevrotain-allstar@0.3.1(chevrotain@11.0.3):
    dependencies:
      chevrotain: 11.0.3
      lodash-es: 4.17.21

  chevrotain@11.0.3:
    dependencies:
      '@chevrotain/cst-dts-gen': 11.0.3
      '@chevrotain/gast': 11.0.3
      '@chevrotain/regexp-to-ast': 11.0.3
      '@chevrotain/types': 11.0.3
      '@chevrotain/utils': 11.0.3
      lodash-es: 4.17.21

  chokidar@3.6.0:
    dependencies:
      anymatch: 3.1.3
      braces: 3.0.3
      glob-parent: 5.1.2
      is-binary-path: 2.1.0
      is-glob: 4.0.3
      normalize-path: 3.0.0
      readdirp: 3.6.0
    optionalDependencies:
      fsevents: 2.3.3

  class-variance-authority@0.7.0:
    dependencies:
      clsx: 2.0.0

  classnames@2.5.1: {}

  client-only@0.0.1: {}

  clsx@2.0.0: {}

  clsx@2.1.1: {}

  cmdk@1.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1):
    dependencies:
      '@radix-ui/react-dialog': 1.0.5(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-primitive': 1.0.3(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
    transitivePeerDependencies:
      - '@types/react'
      - '@types/react-dom'

  collapse-white-space@2.1.0: {}

  color-convert@2.0.1:
    dependencies:
      color-name: 1.1.4

  color-name@1.1.4: {}

  comma-separated-tokens@1.0.8: {}

  comma-separated-tokens@2.0.3: {}

  commander@4.1.1: {}

  commander@7.2.0: {}

  commander@8.3.0: {}

  compute-scroll-into-view@3.1.0: {}

  confbox@0.1.7: {}

  cookie@0.7.0: {}

  core-js@3.38.1: {}

  cose-base@1.0.3:
    dependencies:
      layout-base: 1.0.2

  cose-base@2.2.0:
    dependencies:
      layout-base: 2.0.1

  cross-spawn@7.0.3:
    dependencies:
      path-key: 3.1.1
      shebang-command: 2.0.0
      which: 2.0.2

  crypto-js@4.2.0: {}

  cssesc@3.0.0: {}

  csstype@3.1.1: {}

  csstype@3.1.3: {}

  cytoscape-cose-bilkent@4.1.0(cytoscape@3.30.2):
    dependencies:
      cose-base: 1.0.3
      cytoscape: 3.30.2

  cytoscape-fcose@2.2.0(cytoscape@3.30.2):
    dependencies:
      cose-base: 2.2.0
      cytoscape: 3.30.2

  cytoscape@3.30.2: {}

  d3-array@2.12.1:
    dependencies:
      internmap: 1.0.1

  d3-array@3.2.4:
    dependencies:
      internmap: 2.0.3

  d3-axis@3.0.0: {}

  d3-brush@3.0.0:
    dependencies:
      d3-dispatch: 3.0.1
      d3-drag: 3.0.0
      d3-interpolate: 3.0.1
      d3-selection: 3.0.0
      d3-transition: 3.0.1(d3-selection@3.0.0)

  d3-chord@3.0.1:
    dependencies:
      d3-path: 3.1.0

  d3-color@3.1.0: {}

  d3-contour@4.0.2:
    dependencies:
      d3-array: 3.2.4

  d3-delaunay@6.0.4:
    dependencies:
      delaunator: 5.0.1

  d3-dispatch@3.0.1: {}

  d3-drag@3.0.0:
    dependencies:
      d3-dispatch: 3.0.1
      d3-selection: 3.0.0

  d3-dsv@3.0.1:
    dependencies:
      commander: 7.2.0
      iconv-lite: 0.6.3
      rw: 1.3.3

  d3-ease@3.0.1: {}

  d3-fetch@3.0.1:
    dependencies:
      d3-dsv: 3.0.1

  d3-force@3.0.0:
    dependencies:
      d3-dispatch: 3.0.1
      d3-quadtree: 3.0.1
      d3-timer: 3.0.1

  d3-format@3.1.0: {}

  d3-geo@3.1.1:
    dependencies:
      d3-array: 3.2.4

  d3-hierarchy@3.1.2: {}

  d3-interpolate@3.0.1:
    dependencies:
      d3-color: 3.1.0

  d3-path@1.0.9: {}

  d3-path@3.1.0: {}

  d3-polygon@3.0.1: {}

  d3-quadtree@3.0.1: {}

  d3-random@3.0.1: {}

  d3-sankey@0.12.3:
    dependencies:
      d3-array: 2.12.1
      d3-shape: 1.3.7

  d3-scale-chromatic@3.1.0:
    dependencies:
      d3-color: 3.1.0
      d3-interpolate: 3.0.1

  d3-scale@4.0.2:
    dependencies:
      d3-array: 3.2.4
      d3-format: 3.1.0
      d3-interpolate: 3.0.1
      d3-time: 3.1.0
      d3-time-format: 4.1.0

  d3-selection@3.0.0: {}

  d3-shape@1.3.7:
    dependencies:
      d3-path: 1.0.9

  d3-shape@3.2.0:
    dependencies:
      d3-path: 3.1.0

  d3-time-format@4.1.0:
    dependencies:
      d3-time: 3.1.0

  d3-time@3.1.0:
    dependencies:
      d3-array: 3.2.4

  d3-timer@3.0.1: {}

  d3-transition@3.0.1(d3-selection@3.0.0):
    dependencies:
      d3-color: 3.1.0
      d3-dispatch: 3.0.1
      d3-ease: 3.0.1
      d3-interpolate: 3.0.1
      d3-selection: 3.0.0
      d3-timer: 3.0.1

  d3-zoom@3.0.0:
    dependencies:
      d3-dispatch: 3.0.1
      d3-drag: 3.0.0
      d3-interpolate: 3.0.1
      d3-selection: 3.0.0
      d3-transition: 3.0.1(d3-selection@3.0.0)

  d3@7.9.0:
    dependencies:
      d3-array: 3.2.4
      d3-axis: 3.0.0
      d3-brush: 3.0.0
      d3-chord: 3.0.1
      d3-color: 3.1.0
      d3-contour: 4.0.2
      d3-delaunay: 6.0.4
      d3-dispatch: 3.0.1
      d3-drag: 3.0.0
      d3-dsv: 3.0.1
      d3-ease: 3.0.1
      d3-fetch: 3.0.1
      d3-force: 3.0.0
      d3-format: 3.1.0
      d3-geo: 3.1.1
      d3-hierarchy: 3.1.2
      d3-interpolate: 3.0.1
      d3-path: 3.1.0
      d3-polygon: 3.0.1
      d3-quadtree: 3.0.1
      d3-random: 3.0.1
      d3-scale: 4.0.2
      d3-scale-chromatic: 3.1.0
      d3-selection: 3.0.0
      d3-shape: 3.2.0
      d3-time: 3.1.0
      d3-time-format: 4.1.0
      d3-timer: 3.0.1
      d3-transition: 3.0.1(d3-selection@3.0.0)
      d3-zoom: 3.0.0

  dagre-d3-es@7.0.10:
    dependencies:
      d3: 7.9.0
      lodash-es: 4.17.21

  dayjs@1.11.13: {}

  debug@2.6.9:
    dependencies:
      ms: 2.0.0

  debug@4.3.7:
    dependencies:
      ms: 2.1.3

  decode-named-character-reference@1.0.2:
    dependencies:
      character-entities: 2.0.2

  delaunator@5.0.1:
    dependencies:
      robust-predicates: 3.0.2

  dequal@2.0.3: {}

  detect-node-es@1.1.0: {}

  devlop@1.1.0:
    dependencies:
      dequal: 2.0.3

  didyoumean@1.2.2: {}

  diff@5.2.0: {}

  dlv@1.1.3: {}

  dompurify@3.1.6: {}

  dot-case@3.0.4:
    dependencies:
      no-case: 3.0.4
      tslib: 2.7.0

  dset@3.1.4: {}

  eastasianwidth@0.2.0: {}

  electron-to-chromium@1.5.28: {}

  emoji-regex@8.0.0: {}

  emoji-regex@9.2.2: {}

  esbuild@0.23.1:
    optionalDependencies:
      '@esbuild/aix-ppc64': 0.23.1
      '@esbuild/android-arm': 0.23.1
      '@esbuild/android-arm64': 0.23.1
      '@esbuild/android-x64': 0.23.1
      '@esbuild/darwin-arm64': 0.23.1
      '@esbuild/darwin-x64': 0.23.1
      '@esbuild/freebsd-arm64': 0.23.1
      '@esbuild/freebsd-x64': 0.23.1
      '@esbuild/linux-arm': 0.23.1
      '@esbuild/linux-arm64': 0.23.1
      '@esbuild/linux-ia32': 0.23.1
      '@esbuild/linux-loong64': 0.23.1
      '@esbuild/linux-mips64el': 0.23.1
      '@esbuild/linux-ppc64': 0.23.1
      '@esbuild/linux-riscv64': 0.23.1
      '@esbuild/linux-s390x': 0.23.1
      '@esbuild/linux-x64': 0.23.1
      '@esbuild/netbsd-x64': 0.23.1
      '@esbuild/openbsd-arm64': 0.23.1
      '@esbuild/openbsd-x64': 0.23.1
      '@esbuild/sunos-x64': 0.23.1
      '@esbuild/win32-arm64': 0.23.1
      '@esbuild/win32-ia32': 0.23.1
      '@esbuild/win32-x64': 0.23.1

  escalade@3.2.0: {}

  escape-string-regexp@5.0.0: {}

  esprima@4.0.1: {}

  estree-util-attach-comments@3.0.0:
    dependencies:
      '@types/estree': 1.0.6

  estree-util-build-jsx@3.0.1:
    dependencies:
      '@types/estree-jsx': 1.0.5
      devlop: 1.1.0
      estree-util-is-identifier-name: 3.0.0
      estree-walker: 3.0.3

  estree-util-is-identifier-name@3.0.0: {}

  estree-util-to-js@2.0.0:
    dependencies:
      '@types/estree-jsx': 1.0.5
      astring: 1.9.0
      source-map: 0.7.4

  estree-util-value-to-estree@3.1.2:
    dependencies:
      '@types/estree': 1.0.6

  estree-util-visit@2.0.0:
    dependencies:
      '@types/estree-jsx': 1.0.5
      '@types/unist': 3.0.3

  estree-walker@3.0.3:
    dependencies:
      '@types/estree': 1.0.6

  extend-shallow@2.0.1:
    dependencies:
      is-extendable: 0.1.1

  extend@3.0.2: {}

  fast-deep-equal@3.1.3: {}

  fast-glob@3.3.2:
    dependencies:
      '@nodelib/fs.stat': 2.0.5
      '@nodelib/fs.walk': 1.2.8
      glob-parent: 5.1.2
      merge2: 1.4.1
      micromatch: 4.0.8

  fastq@1.17.1:
    dependencies:
      reusify: 1.0.4

  fault@1.0.4:
    dependencies:
      format: 0.2.2

  fflate@0.4.8: {}

  fill-range@7.1.1:
    dependencies:
      to-regex-range: 5.0.1

  flexsearch@0.7.21: {}

  foreground-child@3.3.0:
    dependencies:
      cross-spawn: 7.0.3
      signal-exit: 4.1.0

  format@0.2.2: {}

  fraction.js@4.3.7: {}

  fsevents@2.3.3:
    optional: true

  fumadocs-core@13.4.10(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1):
    dependencies:
      '@formatjs/intl-localematcher': 0.5.4
      '@shikijs/rehype': 1.18.0
      '@shikijs/transformers': 1.20.0
      flexsearch: 0.7.21
      github-slugger: 2.0.0
      image-size: 1.1.1
      negotiator: 0.6.3
      next: 14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      npm-to-yarn: 3.0.0
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-remove-scroll: 2.6.0(@types/react@18.3.9)(react@18.3.1)
      remark: 15.0.1
      remark-gfm: 4.0.0
      remark-mdx: 3.0.1
      scroll-into-view-if-needed: 3.1.0
      shiki: 1.20.0
      swr: 2.2.5(react@18.3.1)
      unist-util-visit: 5.0.0
    transitivePeerDependencies:
      - '@types/react'
      - supports-color

  fumadocs-docgen@1.2.0(typescript@5.6.2):
    dependencies:
      estree-util-value-to-estree: 3.1.2
      fumadocs-typescript: 2.1.0(typescript@5.6.2)
      hast-util-to-estree: 3.1.0
      npm-to-yarn: 3.0.0
      unist-util-visit: 5.0.0
      zod: 3.23.8
    transitivePeerDependencies:
      - supports-color
      - typescript

  fumadocs-mdx@10.0.2(fumadocs-core@13.4.10(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1)):
    dependencies:
      '@mdx-js/mdx': 3.0.1
      chokidar: 3.6.0
      cross-spawn: 7.0.3
      esbuild: 0.23.1
      estree-util-value-to-estree: 3.1.2
      fast-glob: 3.3.2
      fumadocs-core: 13.4.10(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      gray-matter: 4.0.3
      micromatch: 4.0.8
      next: 14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      zod: 3.23.8
    transitivePeerDependencies:
      - supports-color

  fumadocs-typescript@2.1.0(typescript@5.6.2):
    dependencies:
      fast-glob: 3.3.2
      hast-util-to-jsx-runtime: 2.3.0
      mdast-util-from-markdown: 2.0.1
      mdast-util-gfm: 3.0.0
      mdast-util-to-hast: 13.2.0
      typescript: 5.6.2
    transitivePeerDependencies:
      - supports-color

  fumadocs-ui@13.4.10(@types/react-dom@18.3.0)(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)(tailwindcss@3.4.13):
    dependencies:
      '@radix-ui/react-accordion': 1.2.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-collapsible': 1.1.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-dialog': 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-direction': 1.1.0(@types/react@18.3.9)(react@18.3.1)
      '@radix-ui/react-popover': 1.1.1(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-scroll-area': 1.2.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@radix-ui/react-tabs': 1.1.2(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      '@tailwindcss/typography': 0.5.15(tailwindcss@3.4.13)
      class-variance-authority: 0.7.0
      cmdk: 1.0.0(@types/react-dom@18.3.0)(@types/react@18.3.9)(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      fumadocs-core: 13.4.10(@types/react@18.3.9)(next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1))(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      lucide-react: 0.438.0(react@18.3.1)
      next: 14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      next-themes: 0.3.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      react-medium-image-zoom: 5.2.10(react-dom@18.3.1(react@18.3.1))(react@18.3.1)
      swr: 2.2.5(react@18.3.1)
      tailwind-merge: 2.5.2
    transitivePeerDependencies:
      - '@types/react'
      - '@types/react-dom'
      - supports-color
      - tailwindcss

  function-bind@1.1.2: {}

  get-nonce@1.0.1: {}

  github-slugger@2.0.0: {}

  glob-parent@5.1.2:
    dependencies:
      is-glob: 4.0.3

  glob-parent@6.0.2:
    dependencies:
      is-glob: 4.0.3

  glob-to-regexp@0.4.1: {}

  glob@10.4.5:
    dependencies:
      foreground-child: 3.3.0
      jackspeak: 3.4.3
      minimatch: 9.0.5
      minipass: 7.1.2
      package-json-from-dist: 1.0.0
      path-scurry: 1.11.1

  graceful-fs@4.2.11: {}

  graphql@16.10.0: {}

  gray-matter@4.0.3:
    dependencies:
      js-yaml: 3.14.1
      kind-of: 6.0.3
      section-matter: 1.0.0
      strip-bom-string: 1.0.0

  hachure-fill@0.5.2: {}

  has-flag@4.0.0: {}

  hasown@2.0.2:
    dependencies:
      function-bind: 1.1.2

  hast-util-parse-selector@2.2.5: {}

  hast-util-to-estree@3.1.0:
    dependencies:
      '@types/estree': 1.0.6
      '@types/estree-jsx': 1.0.5
      '@types/hast': 3.0.4
      comma-separated-tokens: 2.0.3
      devlop: 1.1.0
      estree-util-attach-comments: 3.0.0
      estree-util-is-identifier-name: 3.0.0
      hast-util-whitespace: 3.0.0
      mdast-util-mdx-expression: 2.0.1
      mdast-util-mdx-jsx: 3.1.3
      mdast-util-mdxjs-esm: 2.0.1
      property-information: 6.5.0
      space-separated-tokens: 2.0.2
      style-to-object: 0.4.4
      unist-util-position: 5.0.0
      zwitch: 2.0.4
    transitivePeerDependencies:
      - supports-color

  hast-util-to-html@9.0.3:
    dependencies:
      '@types/hast': 3.0.4
      '@types/unist': 3.0.3
      ccount: 2.0.1
      comma-separated-tokens: 2.0.3
      hast-util-whitespace: 3.0.0
      html-void-elements: 3.0.0
      mdast-util-to-hast: 13.2.0
      property-information: 6.5.0
      space-separated-tokens: 2.0.2
      stringify-entities: 4.0.4
      zwitch: 2.0.4

  hast-util-to-jsx-runtime@2.3.0:
    dependencies:
      '@types/estree': 1.0.6
      '@types/hast': 3.0.4
      '@types/unist': 3.0.3
      comma-separated-tokens: 2.0.3
      devlop: 1.1.0
      estree-util-is-identifier-name: 3.0.0
      hast-util-whitespace: 3.0.0
      mdast-util-mdx-expression: 2.0.1
      mdast-util-mdx-jsx: 3.1.3
      mdast-util-mdxjs-esm: 2.0.1
      property-information: 6.5.0
      space-separated-tokens: 2.0.2
      style-to-object: 1.0.8
      unist-util-position: 5.0.0
      vfile-message: 4.0.2
    transitivePeerDependencies:
      - supports-color

  hast-util-to-string@3.0.0:
    dependencies:
      '@types/hast': 3.0.4

  hast-util-whitespace@2.0.1: {}

  hast-util-whitespace@3.0.0:
    dependencies:
      '@types/hast': 3.0.4

  hastscript@6.0.0:
    dependencies:
      '@types/hast': 2.3.10
      comma-separated-tokens: 1.0.8
      hast-util-parse-selector: 2.2.5
      property-information: 5.6.0
      space-separated-tokens: 1.1.5

  highlight.js@10.7.3: {}

  highlightjs-vue@1.0.0: {}

  html-void-elements@3.0.0: {}

  husky@9.1.6: {}

  iconv-lite@0.6.3:
    dependencies:
      safer-buffer: 2.1.2

  ieee754@1.2.1: {}

  image-size@1.1.1:
    dependencies:
      queue: 6.0.2

  inherits@2.0.4: {}

  inline-style-parser@0.1.1: {}

  inline-style-parser@0.2.4: {}

  internmap@1.0.1: {}

  internmap@2.0.3: {}

  invariant@2.2.4:
    dependencies:
      loose-envify: 1.4.0

  is-alphabetical@1.0.4: {}

  is-alphabetical@2.0.1: {}

  is-alphanumerical@1.0.4:
    dependencies:
      is-alphabetical: 1.0.4
      is-decimal: 1.0.4

  is-alphanumerical@2.0.1:
    dependencies:
      is-alphabetical: 2.0.1
      is-decimal: 2.0.1

  is-binary-path@2.1.0:
    dependencies:
      binary-extensions: 2.3.0

  is-buffer@2.0.5: {}

  is-core-module@2.15.1:
    dependencies:
      hasown: 2.0.2

  is-decimal@1.0.4: {}

  is-decimal@2.0.1: {}

  is-extendable@0.1.1: {}

  is-extglob@2.1.1: {}

  is-fullwidth-code-point@3.0.0: {}

  is-glob@4.0.3:
    dependencies:
      is-extglob: 2.1.1

  is-hexadecimal@1.0.4: {}

  is-hexadecimal@2.0.1: {}

  is-number@7.0.0: {}

  is-plain-obj@4.1.0: {}

  is-reference@3.0.2:
    dependencies:
      '@types/estree': 1.0.6

  isexe@2.0.0: {}

  jackspeak@3.4.3:
    dependencies:
      '@isaacs/cliui': 8.0.2
    optionalDependencies:
      '@pkgjs/parseargs': 0.11.0

  jiti@1.21.6: {}

  jose@5.10.0: {}

  js-cookie@3.0.5: {}

  js-tokens@4.0.0: {}

  js-yaml@3.14.1:
    dependencies:
      argparse: 1.0.10
      esprima: 4.0.1

  katex@0.16.11:
    dependencies:
      commander: 8.3.0

  khroma@2.1.0: {}

  kind-of@6.0.3: {}

  kleur@4.1.5: {}

  kolorist@1.8.0: {}

  langium@3.0.0:
    dependencies:
      chevrotain: 11.0.3
      chevrotain-allstar: 0.3.1(chevrotain@11.0.3)
      vscode-languageserver: 9.0.1
      vscode-languageserver-textdocument: 1.0.12
      vscode-uri: 3.0.8

  layout-base@1.0.2: {}

  layout-base@2.0.1: {}

  lilconfig@2.1.0: {}

  lilconfig@3.1.2: {}

  lines-and-columns@1.2.4: {}

  load-script@1.0.0: {}

  local-pkg@0.5.0:
    dependencies:
      mlly: 1.7.1
      pkg-types: 1.2.0

  lodash-es@4.17.21: {}

  lodash.castarray@4.4.0: {}

  lodash.debounce@4.0.8: {}

  lodash.isplainobject@4.0.6: {}

  lodash.merge@4.6.2: {}

  longest-streak@3.1.0: {}

  loose-envify@1.4.0:
    dependencies:
      js-tokens: 4.0.0

  lower-case@2.0.2:
    dependencies:
      tslib: 2.7.0

  lowlight@1.20.0:
    dependencies:
      fault: 1.0.4
      highlight.js: 10.7.3

  lru-cache@10.4.3: {}

  lucide-react@0.438.0(react@18.3.1):
    dependencies:
      react: 18.3.1

  lucide-react@0.446.0(react@18.3.1):
    dependencies:
      react: 18.3.1

  map-obj@4.3.0: {}

  markdown-extensions@2.0.0: {}

  markdown-table@3.0.3: {}

  marked@13.0.3: {}

  mdast-util-definitions@5.1.2:
    dependencies:
      '@types/mdast': 3.0.15
      '@types/unist': 2.0.11
      unist-util-visit: 4.1.2

  mdast-util-find-and-replace@2.2.2:
    dependencies:
      '@types/mdast': 3.0.15
      escape-string-regexp: 5.0.0
      unist-util-is: 5.2.1
      unist-util-visit-parents: 5.1.3

  mdast-util-find-and-replace@3.0.1:
    dependencies:
      '@types/mdast': 4.0.4
      escape-string-regexp: 5.0.0
      unist-util-is: 6.0.0
      unist-util-visit-parents: 6.0.1

  mdast-util-from-markdown@1.3.1:
    dependencies:
      '@types/mdast': 3.0.15
      '@types/unist': 2.0.11
      decode-named-character-reference: 1.0.2
      mdast-util-to-string: 3.2.0
      micromark: 3.2.0
      micromark-util-decode-numeric-character-reference: 1.1.0
      micromark-util-decode-string: 1.1.0
      micromark-util-normalize-identifier: 1.1.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      unist-util-stringify-position: 3.0.3
      uvu: 0.5.6
    transitivePeerDependencies:
      - supports-color

  mdast-util-from-markdown@2.0.1:
    dependencies:
      '@types/mdast': 4.0.4
      '@types/unist': 3.0.3
      decode-named-character-reference: 1.0.2
      devlop: 1.1.0
      mdast-util-to-string: 4.0.0
      micromark: 4.0.0
      micromark-util-decode-numeric-character-reference: 2.0.1
      micromark-util-decode-string: 2.0.0
      micromark-util-normalize-identifier: 2.0.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0
      unist-util-stringify-position: 4.0.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm-autolink-literal@1.0.3:
    dependencies:
      '@types/mdast': 3.0.15
      ccount: 2.0.1
      mdast-util-find-and-replace: 2.2.2
      micromark-util-character: 1.2.0

  mdast-util-gfm-autolink-literal@2.0.1:
    dependencies:
      '@types/mdast': 4.0.4
      ccount: 2.0.1
      devlop: 1.1.0
      mdast-util-find-and-replace: 3.0.1
      micromark-util-character: 2.1.0

  mdast-util-gfm-footnote@1.0.2:
    dependencies:
      '@types/mdast': 3.0.15
      mdast-util-to-markdown: 1.5.0
      micromark-util-normalize-identifier: 1.1.0

  mdast-util-gfm-footnote@2.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      devlop: 1.1.0
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
      micromark-util-normalize-identifier: 2.0.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm-strikethrough@1.0.3:
    dependencies:
      '@types/mdast': 3.0.15
      mdast-util-to-markdown: 1.5.0

  mdast-util-gfm-strikethrough@2.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm-table@1.0.7:
    dependencies:
      '@types/mdast': 3.0.15
      markdown-table: 3.0.3
      mdast-util-from-markdown: 1.3.1
      mdast-util-to-markdown: 1.5.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm-table@2.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      devlop: 1.1.0
      markdown-table: 3.0.3
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm-task-list-item@1.0.2:
    dependencies:
      '@types/mdast': 3.0.15
      mdast-util-to-markdown: 1.5.0

  mdast-util-gfm-task-list-item@2.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      devlop: 1.1.0
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm@2.0.2:
    dependencies:
      mdast-util-from-markdown: 1.3.1
      mdast-util-gfm-autolink-literal: 1.0.3
      mdast-util-gfm-footnote: 1.0.2
      mdast-util-gfm-strikethrough: 1.0.3
      mdast-util-gfm-table: 1.0.7
      mdast-util-gfm-task-list-item: 1.0.2
      mdast-util-to-markdown: 1.5.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-gfm@3.0.0:
    dependencies:
      mdast-util-from-markdown: 2.0.1
      mdast-util-gfm-autolink-literal: 2.0.1
      mdast-util-gfm-footnote: 2.0.0
      mdast-util-gfm-strikethrough: 2.0.0
      mdast-util-gfm-table: 2.0.0
      mdast-util-gfm-task-list-item: 2.0.0
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-math@2.0.2:
    dependencies:
      '@types/mdast': 3.0.15
      longest-streak: 3.1.0
      mdast-util-to-markdown: 1.5.0

  mdast-util-mdx-expression@2.0.1:
    dependencies:
      '@types/estree-jsx': 1.0.5
      '@types/hast': 3.0.4
      '@types/mdast': 4.0.4
      devlop: 1.1.0
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-mdx-jsx@3.1.3:
    dependencies:
      '@types/estree-jsx': 1.0.5
      '@types/hast': 3.0.4
      '@types/mdast': 4.0.4
      '@types/unist': 3.0.3
      ccount: 2.0.1
      devlop: 1.1.0
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
      parse-entities: 4.0.1
      stringify-entities: 4.0.4
      unist-util-stringify-position: 4.0.0
      vfile-message: 4.0.2
    transitivePeerDependencies:
      - supports-color

  mdast-util-mdx@3.0.0:
    dependencies:
      mdast-util-from-markdown: 2.0.1
      mdast-util-mdx-expression: 2.0.1
      mdast-util-mdx-jsx: 3.1.3
      mdast-util-mdxjs-esm: 2.0.1
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-mdxjs-esm@2.0.1:
    dependencies:
      '@types/estree-jsx': 1.0.5
      '@types/hast': 3.0.4
      '@types/mdast': 4.0.4
      devlop: 1.1.0
      mdast-util-from-markdown: 2.0.1
      mdast-util-to-markdown: 2.1.0
    transitivePeerDependencies:
      - supports-color

  mdast-util-phrasing@3.0.1:
    dependencies:
      '@types/mdast': 3.0.15
      unist-util-is: 5.2.1

  mdast-util-phrasing@4.1.0:
    dependencies:
      '@types/mdast': 4.0.4
      unist-util-is: 6.0.0

  mdast-util-to-hast@12.3.0:
    dependencies:
      '@types/hast': 2.3.10
      '@types/mdast': 3.0.15
      mdast-util-definitions: 5.1.2
      micromark-util-sanitize-uri: 1.2.0
      trim-lines: 3.0.1
      unist-util-generated: 2.0.1
      unist-util-position: 4.0.4
      unist-util-visit: 4.1.2

  mdast-util-to-hast@13.2.0:
    dependencies:
      '@types/hast': 3.0.4
      '@types/mdast': 4.0.4
      '@ungap/structured-clone': 1.2.0
      devlop: 1.1.0
      micromark-util-sanitize-uri: 2.0.0
      trim-lines: 3.0.1
      unist-util-position: 5.0.0
      unist-util-visit: 5.0.0
      vfile: 6.0.3

  mdast-util-to-markdown@1.5.0:
    dependencies:
      '@types/mdast': 3.0.15
      '@types/unist': 2.0.11
      longest-streak: 3.1.0
      mdast-util-phrasing: 3.0.1
      mdast-util-to-string: 3.2.0
      micromark-util-decode-string: 1.1.0
      unist-util-visit: 4.1.2
      zwitch: 2.0.4

  mdast-util-to-markdown@2.1.0:
    dependencies:
      '@types/mdast': 4.0.4
      '@types/unist': 3.0.3
      longest-streak: 3.1.0
      mdast-util-phrasing: 4.1.0
      mdast-util-to-string: 4.0.0
      micromark-util-decode-string: 2.0.0
      unist-util-visit: 5.0.0
      zwitch: 2.0.4

  mdast-util-to-string@3.2.0:
    dependencies:
      '@types/mdast': 3.0.15

  mdast-util-to-string@4.0.0:
    dependencies:
      '@types/mdast': 4.0.4

  mdast@3.0.0: {}

  merge2@1.4.1: {}

  mermaid@11.2.1:
    dependencies:
      '@braintree/sanitize-url': 7.1.0
      '@iconify/utils': 2.1.33
      '@mermaid-js/parser': 0.3.0
      cytoscape: 3.30.2
      cytoscape-cose-bilkent: 4.1.0(cytoscape@3.30.2)
      cytoscape-fcose: 2.2.0(cytoscape@3.30.2)
      d3: 7.9.0
      d3-sankey: 0.12.3
      dagre-d3-es: 7.0.10
      dayjs: 1.11.13
      dompurify: 3.1.6
      katex: 0.16.11
      khroma: 2.1.0
      lodash-es: 4.17.21
      marked: 13.0.3
      roughjs: 4.6.6
      stylis: 4.3.4
      ts-dedent: 2.2.0
      uuid: 9.0.1
    transitivePeerDependencies:
      - supports-color

  micromark-core-commonmark@1.1.0:
    dependencies:
      decode-named-character-reference: 1.0.2
      micromark-factory-destination: 1.1.0
      micromark-factory-label: 1.1.0
      micromark-factory-space: 1.1.0
      micromark-factory-title: 1.1.0
      micromark-factory-whitespace: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-chunked: 1.1.0
      micromark-util-classify-character: 1.1.0
      micromark-util-html-tag-name: 1.2.0
      micromark-util-normalize-identifier: 1.1.0
      micromark-util-resolve-all: 1.1.0
      micromark-util-subtokenize: 1.1.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-core-commonmark@2.0.1:
    dependencies:
      decode-named-character-reference: 1.0.2
      devlop: 1.1.0
      micromark-factory-destination: 2.0.0
      micromark-factory-label: 2.0.0
      micromark-factory-space: 2.0.0
      micromark-factory-title: 2.0.0
      micromark-factory-whitespace: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-chunked: 2.0.0
      micromark-util-classify-character: 2.0.0
      micromark-util-html-tag-name: 2.0.0
      micromark-util-normalize-identifier: 2.0.0
      micromark-util-resolve-all: 2.0.0
      micromark-util-subtokenize: 2.0.1
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-gfm-autolink-literal@1.0.5:
    dependencies:
      micromark-util-character: 1.2.0
      micromark-util-sanitize-uri: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0

  micromark-extension-gfm-autolink-literal@2.1.0:
    dependencies:
      micromark-util-character: 2.1.0
      micromark-util-sanitize-uri: 2.0.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-gfm-footnote@1.1.2:
    dependencies:
      micromark-core-commonmark: 1.1.0
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-normalize-identifier: 1.1.0
      micromark-util-sanitize-uri: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-extension-gfm-footnote@2.1.0:
    dependencies:
      devlop: 1.1.0
      micromark-core-commonmark: 2.0.1
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-normalize-identifier: 2.0.0
      micromark-util-sanitize-uri: 2.0.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-gfm-strikethrough@1.0.7:
    dependencies:
      micromark-util-chunked: 1.1.0
      micromark-util-classify-character: 1.1.0
      micromark-util-resolve-all: 1.1.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-extension-gfm-strikethrough@2.1.0:
    dependencies:
      devlop: 1.1.0
      micromark-util-chunked: 2.0.0
      micromark-util-classify-character: 2.0.0
      micromark-util-resolve-all: 2.0.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-gfm-table@1.0.7:
    dependencies:
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-extension-gfm-table@2.1.0:
    dependencies:
      devlop: 1.1.0
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-gfm-tagfilter@1.0.2:
    dependencies:
      micromark-util-types: 1.1.0

  micromark-extension-gfm-tagfilter@2.0.0:
    dependencies:
      micromark-util-types: 2.0.0

  micromark-extension-gfm-task-list-item@1.0.5:
    dependencies:
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-extension-gfm-task-list-item@2.1.0:
    dependencies:
      devlop: 1.1.0
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-gfm@2.0.3:
    dependencies:
      micromark-extension-gfm-autolink-literal: 1.0.5
      micromark-extension-gfm-footnote: 1.1.2
      micromark-extension-gfm-strikethrough: 1.0.7
      micromark-extension-gfm-table: 1.0.7
      micromark-extension-gfm-tagfilter: 1.0.2
      micromark-extension-gfm-task-list-item: 1.0.5
      micromark-util-combine-extensions: 1.1.0
      micromark-util-types: 1.1.0

  micromark-extension-gfm@3.0.0:
    dependencies:
      micromark-extension-gfm-autolink-literal: 2.1.0
      micromark-extension-gfm-footnote: 2.1.0
      micromark-extension-gfm-strikethrough: 2.1.0
      micromark-extension-gfm-table: 2.1.0
      micromark-extension-gfm-tagfilter: 2.0.0
      micromark-extension-gfm-task-list-item: 2.1.0
      micromark-util-combine-extensions: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-math@2.1.2:
    dependencies:
      '@types/katex': 0.16.7
      katex: 0.16.11
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-extension-mdx-expression@3.0.0:
    dependencies:
      '@types/estree': 1.0.6
      devlop: 1.1.0
      micromark-factory-mdx-expression: 2.0.2
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-events-to-acorn: 2.0.2
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-extension-mdx-jsx@3.0.1:
    dependencies:
      '@types/acorn': 4.0.6
      '@types/estree': 1.0.6
      devlop: 1.1.0
      estree-util-is-identifier-name: 3.0.0
      micromark-factory-mdx-expression: 2.0.2
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-events-to-acorn: 2.0.2
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0
      vfile-message: 4.0.2

  micromark-extension-mdx-md@2.0.0:
    dependencies:
      micromark-util-types: 2.0.0

  micromark-extension-mdxjs-esm@3.0.0:
    dependencies:
      '@types/estree': 1.0.6
      devlop: 1.1.0
      micromark-core-commonmark: 2.0.1
      micromark-util-character: 2.1.0
      micromark-util-events-to-acorn: 2.0.2
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0
      unist-util-position-from-estree: 2.0.0
      vfile-message: 4.0.2

  micromark-extension-mdxjs@3.0.0:
    dependencies:
      acorn: 8.12.1
      acorn-jsx: 5.3.2(acorn@8.12.1)
      micromark-extension-mdx-expression: 3.0.0
      micromark-extension-mdx-jsx: 3.0.1
      micromark-extension-mdx-md: 2.0.0
      micromark-extension-mdxjs-esm: 3.0.0
      micromark-util-combine-extensions: 2.0.0
      micromark-util-types: 2.0.0

  micromark-factory-destination@1.1.0:
    dependencies:
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0

  micromark-factory-destination@2.0.0:
    dependencies:
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-factory-label@1.1.0:
    dependencies:
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-factory-label@2.0.0:
    dependencies:
      devlop: 1.1.0
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-factory-mdx-expression@2.0.2:
    dependencies:
      '@types/estree': 1.0.6
      devlop: 1.1.0
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-events-to-acorn: 2.0.2
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0
      unist-util-position-from-estree: 2.0.0
      vfile-message: 4.0.2

  micromark-factory-space@1.1.0:
    dependencies:
      micromark-util-character: 1.2.0
      micromark-util-types: 1.1.0

  micromark-factory-space@2.0.0:
    dependencies:
      micromark-util-character: 2.1.0
      micromark-util-types: 2.0.0

  micromark-factory-title@1.1.0:
    dependencies:
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0

  micromark-factory-title@2.0.0:
    dependencies:
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-factory-whitespace@1.1.0:
    dependencies:
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0

  micromark-factory-whitespace@2.0.0:
    dependencies:
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-util-character@1.2.0:
    dependencies:
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0

  micromark-util-character@2.1.0:
    dependencies:
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-util-chunked@1.1.0:
    dependencies:
      micromark-util-symbol: 1.1.0

  micromark-util-chunked@2.0.0:
    dependencies:
      micromark-util-symbol: 2.0.0

  micromark-util-classify-character@1.1.0:
    dependencies:
      micromark-util-character: 1.2.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0

  micromark-util-classify-character@2.0.0:
    dependencies:
      micromark-util-character: 2.1.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-util-combine-extensions@1.1.0:
    dependencies:
      micromark-util-chunked: 1.1.0
      micromark-util-types: 1.1.0

  micromark-util-combine-extensions@2.0.0:
    dependencies:
      micromark-util-chunked: 2.0.0
      micromark-util-types: 2.0.0

  micromark-util-decode-numeric-character-reference@1.1.0:
    dependencies:
      micromark-util-symbol: 1.1.0

  micromark-util-decode-numeric-character-reference@2.0.1:
    dependencies:
      micromark-util-symbol: 2.0.0

  micromark-util-decode-string@1.1.0:
    dependencies:
      decode-named-character-reference: 1.0.2
      micromark-util-character: 1.2.0
      micromark-util-decode-numeric-character-reference: 1.1.0
      micromark-util-symbol: 1.1.0

  micromark-util-decode-string@2.0.0:
    dependencies:
      decode-named-character-reference: 1.0.2
      micromark-util-character: 2.1.0
      micromark-util-decode-numeric-character-reference: 2.0.1
      micromark-util-symbol: 2.0.0

  micromark-util-encode@1.1.0: {}

  micromark-util-encode@2.0.0: {}

  micromark-util-events-to-acorn@2.0.2:
    dependencies:
      '@types/acorn': 4.0.6
      '@types/estree': 1.0.6
      '@types/unist': 3.0.3
      devlop: 1.1.0
      estree-util-visit: 2.0.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0
      vfile-message: 4.0.2

  micromark-util-html-tag-name@1.2.0: {}

  micromark-util-html-tag-name@2.0.0: {}

  micromark-util-normalize-identifier@1.1.0:
    dependencies:
      micromark-util-symbol: 1.1.0

  micromark-util-normalize-identifier@2.0.0:
    dependencies:
      micromark-util-symbol: 2.0.0

  micromark-util-resolve-all@1.1.0:
    dependencies:
      micromark-util-types: 1.1.0

  micromark-util-resolve-all@2.0.0:
    dependencies:
      micromark-util-types: 2.0.0

  micromark-util-sanitize-uri@1.2.0:
    dependencies:
      micromark-util-character: 1.2.0
      micromark-util-encode: 1.1.0
      micromark-util-symbol: 1.1.0

  micromark-util-sanitize-uri@2.0.0:
    dependencies:
      micromark-util-character: 2.1.0
      micromark-util-encode: 2.0.0
      micromark-util-symbol: 2.0.0

  micromark-util-subtokenize@1.1.0:
    dependencies:
      micromark-util-chunked: 1.1.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6

  micromark-util-subtokenize@2.0.1:
    dependencies:
      devlop: 1.1.0
      micromark-util-chunked: 2.0.0
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0

  micromark-util-symbol@1.1.0: {}

  micromark-util-symbol@2.0.0: {}

  micromark-util-types@1.1.0: {}

  micromark-util-types@2.0.0: {}

  micromark@3.2.0:
    dependencies:
      '@types/debug': 4.1.12
      debug: 4.3.7
      decode-named-character-reference: 1.0.2
      micromark-core-commonmark: 1.1.0
      micromark-factory-space: 1.1.0
      micromark-util-character: 1.2.0
      micromark-util-chunked: 1.1.0
      micromark-util-combine-extensions: 1.1.0
      micromark-util-decode-numeric-character-reference: 1.1.0
      micromark-util-encode: 1.1.0
      micromark-util-normalize-identifier: 1.1.0
      micromark-util-resolve-all: 1.1.0
      micromark-util-sanitize-uri: 1.2.0
      micromark-util-subtokenize: 1.1.0
      micromark-util-symbol: 1.1.0
      micromark-util-types: 1.1.0
      uvu: 0.5.6
    transitivePeerDependencies:
      - supports-color

  micromark@4.0.0:
    dependencies:
      '@types/debug': 4.1.12
      debug: 4.3.7
      decode-named-character-reference: 1.0.2
      devlop: 1.1.0
      micromark-core-commonmark: 2.0.1
      micromark-factory-space: 2.0.0
      micromark-util-character: 2.1.0
      micromark-util-chunked: 2.0.0
      micromark-util-combine-extensions: 2.0.0
      micromark-util-decode-numeric-character-reference: 2.0.1
      micromark-util-encode: 2.0.0
      micromark-util-normalize-identifier: 2.0.0
      micromark-util-resolve-all: 2.0.0
      micromark-util-sanitize-uri: 2.0.0
      micromark-util-subtokenize: 2.0.1
      micromark-util-symbol: 2.0.0
      micromark-util-types: 2.0.0
    transitivePeerDependencies:
      - supports-color

  micromatch@4.0.8:
    dependencies:
      braces: 3.0.3
      picomatch: 2.3.1

  minimatch@9.0.5:
    dependencies:
      brace-expansion: 2.0.1

  minipass@7.1.2: {}

  mlly@1.7.1:
    dependencies:
      acorn: 8.12.1
      pathe: 1.1.2
      pkg-types: 1.2.0
      ufo: 1.5.4

  mri@1.2.0: {}

  ms@2.0.0: {}

  ms@2.1.3: {}

  mz@2.7.0:
    dependencies:
      any-promise: 1.3.0
      object-assign: 4.1.1
      thenify-all: 1.6.0

  nanoid@3.3.7: {}

  negotiator@0.6.3: {}

  next-themes@0.3.0(react-dom@18.3.1(react@18.3.1))(react@18.3.1):
    dependencies:
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  next@14.2.13(react-dom@18.3.1(react@18.3.1))(react@18.3.1):
    dependencies:
      '@next/env': 14.2.13
      '@swc/helpers': 0.5.5
      busboy: 1.6.0
      caniuse-lite: 1.0.30001663
      graceful-fs: 4.2.11
      postcss: 8.4.31
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)
      styled-jsx: 5.1.1(react@18.3.1)
    optionalDependencies:
      '@next/swc-darwin-arm64': 14.2.13
      '@next/swc-darwin-x64': 14.2.13
      '@next/swc-linux-arm64-gnu': 14.2.13
      '@next/swc-linux-arm64-musl': 14.2.13
      '@next/swc-linux-x64-gnu': 14.2.13
      '@next/swc-linux-x64-musl': 14.2.13
      '@next/swc-win32-arm64-msvc': 14.2.13
      '@next/swc-win32-ia32-msvc': 14.2.13
      '@next/swc-win32-x64-msvc': 14.2.13
    transitivePeerDependencies:
      - '@babel/core'
      - babel-plugin-macros

  no-case@3.0.4:
    dependencies:
      lower-case: 2.0.2
      tslib: 2.7.0

  node-fetch@2.7.0:
    dependencies:
      whatwg-url: 5.0.0

  node-releases@2.0.18: {}

  normalize-path@3.0.0: {}

  normalize-range@0.1.2: {}

  npm-to-yarn@3.0.0: {}

  object-assign@4.1.1: {}

  object-hash@3.0.0: {}

  oniguruma-to-js@0.4.3:
    dependencies:
      regex: 4.3.2

  package-json-from-dist@1.0.0: {}

  package-manager-detector@0.2.0: {}

  parse-entities@2.0.0:
    dependencies:
      character-entities: 1.2.4
      character-entities-legacy: 1.1.4
      character-reference-invalid: 1.1.4
      is-alphanumerical: 1.0.4
      is-decimal: 1.0.4
      is-hexadecimal: 1.0.4

  parse-entities@4.0.1:
    dependencies:
      '@types/unist': 2.0.11
      character-entities: 2.0.2
      character-entities-legacy: 3.0.0
      character-reference-invalid: 2.0.1
      decode-named-character-reference: 1.0.2
      is-alphanumerical: 2.0.1
      is-decimal: 2.0.1
      is-hexadecimal: 2.0.1

  parse-numeric-range@1.3.0: {}

  path-data-parser@0.1.0: {}

  path-key@3.1.1: {}

  path-parse@1.0.7: {}

  path-scurry@1.11.1:
    dependencies:
      lru-cache: 10.4.3
      minipass: 7.1.2

  pathe@1.1.2: {}

  periscopic@3.1.0:
    dependencies:
      '@types/estree': 1.0.6
      estree-walker: 3.0.3
      is-reference: 3.0.2

  picocolors@1.1.0: {}

  picomatch@2.3.1: {}

  pify@2.3.0: {}

  pirates@4.0.6: {}

  pkg-types@1.2.0:
    dependencies:
      confbox: 0.1.7
      mlly: 1.7.1
      pathe: 1.1.2

  points-on-curve@0.2.0: {}

  points-on-path@0.2.1:
    dependencies:
      path-data-parser: 0.1.0
      points-on-curve: 0.2.0

  postcss-import@15.1.0(postcss@8.4.47):
    dependencies:
      postcss: 8.4.47
      postcss-value-parser: 4.2.0
      read-cache: 1.0.0
      resolve: 1.22.8

  postcss-js@4.0.1(postcss@8.4.47):
    dependencies:
      camelcase-css: 2.0.1
      postcss: 8.4.47

  postcss-load-config@4.0.2(postcss@8.4.47):
    dependencies:
      lilconfig: 3.1.2
      yaml: 2.5.1
    optionalDependencies:
      postcss: 8.4.47

  postcss-nested@6.2.0(postcss@8.4.47):
    dependencies:
      postcss: 8.4.47
      postcss-selector-parser: 6.1.2

  postcss-selector-parser@6.0.10:
    dependencies:
      cssesc: 3.0.0
      util-deprecate: 1.0.2

  postcss-selector-parser@6.1.2:
    dependencies:
      cssesc: 3.0.0
      util-deprecate: 1.0.2

  postcss-value-parser@4.2.0: {}

  postcss@8.4.31:
    dependencies:
      nanoid: 3.3.7
      picocolors: 1.1.0
      source-map-js: 1.2.1

  postcss@8.4.47:
    dependencies:
      nanoid: 3.3.7
      picocolors: 1.1.0
      source-map-js: 1.2.1

  posthog-js@1.175.0:
    dependencies:
      core-js: 3.38.1
      fflate: 0.4.8
      preact: 10.24.2
      web-vitals: 4.2.3

  preact@10.24.2: {}

  prismjs@1.27.0: {}

  prismjs@1.30.0: {}

  prop-types@15.8.1:
    dependencies:
      loose-envify: 1.4.0
      object-assign: 4.1.1
      react-is: 16.13.1

  property-information@5.6.0:
    dependencies:
      xtend: 4.0.2

  property-information@6.5.0: {}

  queue-microtask@1.2.3: {}

  queue@6.0.2:
    dependencies:
      inherits: 2.0.4

  react-dom@18.3.1(react@18.3.1):
    dependencies:
      loose-envify: 1.4.0
      react: 18.3.1
      scheduler: 0.23.2

  react-ga4@2.1.0: {}

  react-icons@5.3.0(react@18.3.1):
    dependencies:
      react: 18.3.1

  react-is@16.13.1: {}

  react-is@18.3.1: {}

  react-markdown@8.0.7(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      '@types/hast': 2.3.10
      '@types/prop-types': 15.7.13
      '@types/react': 18.3.9
      '@types/unist': 2.0.11
      comma-separated-tokens: 2.0.3
      hast-util-whitespace: 2.0.1
      prop-types: 15.8.1
      property-information: 6.5.0
      react: 18.3.1
      react-is: 18.3.1
      remark-parse: 10.0.2
      remark-rehype: 10.1.0
      space-separated-tokens: 2.0.2
      style-to-object: 0.4.4
      unified: 10.1.2
      unist-util-visit: 4.1.2
      vfile: 5.3.7
    transitivePeerDependencies:
      - supports-color

  react-medium-image-zoom@5.2.10(react-dom@18.3.1(react@18.3.1))(react@18.3.1):
    dependencies:
      react: 18.3.1
      react-dom: 18.3.1(react@18.3.1)

  react-remove-scroll-bar@2.3.6(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      react: 18.3.1
      react-style-singleton: 2.2.1(@types/react@18.3.9)(react@18.3.1)
      tslib: 2.7.0
    optionalDependencies:
      '@types/react': 18.3.9

  react-remove-scroll@2.5.5(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      react: 18.3.1
      react-remove-scroll-bar: 2.3.6(@types/react@18.3.9)(react@18.3.1)
      react-style-singleton: 2.2.1(@types/react@18.3.9)(react@18.3.1)
      tslib: 2.7.0
      use-callback-ref: 1.3.2(@types/react@18.3.9)(react@18.3.1)
      use-sidecar: 1.1.2(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9

  react-remove-scroll@2.5.7(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      react: 18.3.1
      react-remove-scroll-bar: 2.3.6(@types/react@18.3.9)(react@18.3.1)
      react-style-singleton: 2.2.1(@types/react@18.3.9)(react@18.3.1)
      tslib: 2.7.0
      use-callback-ref: 1.3.2(@types/react@18.3.9)(react@18.3.1)
      use-sidecar: 1.1.2(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9

  react-remove-scroll@2.6.0(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      react: 18.3.1
      react-remove-scroll-bar: 2.3.6(@types/react@18.3.9)(react@18.3.1)
      react-style-singleton: 2.2.1(@types/react@18.3.9)(react@18.3.1)
      tslib: 2.7.0
      use-callback-ref: 1.3.2(@types/react@18.3.9)(react@18.3.1)
      use-sidecar: 1.1.2(@types/react@18.3.9)(react@18.3.1)
    optionalDependencies:
      '@types/react': 18.3.9

  react-style-singleton@2.2.1(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      get-nonce: 1.0.1
      invariant: 2.2.4
      react: 18.3.1
      tslib: 2.7.0
    optionalDependencies:
      '@types/react': 18.3.9

  react-syntax-highlighter@15.6.1(react@18.3.1):
    dependencies:
      '@babel/runtime': 7.25.6
      highlight.js: 10.7.3
      highlightjs-vue: 1.0.0
      lowlight: 1.20.0
      prismjs: 1.30.0
      react: 18.3.1
      refractor: 3.6.0

  react-youtube@10.1.0(react@18.3.1):
    dependencies:
      fast-deep-equal: 3.1.3
      prop-types: 15.8.1
      react: 18.3.1
      youtube-player: 5.5.2
    transitivePeerDependencies:
      - supports-color

  react@18.3.1:
    dependencies:
      loose-envify: 1.4.0

  read-cache@1.0.0:
    dependencies:
      pify: 2.3.0

  readdirp@3.6.0:
    dependencies:
      picomatch: 2.3.1

  refractor@3.6.0:
    dependencies:
      hastscript: 6.0.0
      parse-entities: 2.0.0
      prismjs: 1.27.0

  regenerator-runtime@0.14.1: {}

  regex@4.3.2: {}

  rehype-highlight-code-lines@1.0.4:
    dependencies:
      '@types/hast': 3.0.4
      parse-numeric-range: 1.3.0
      unified: 11.0.5
      unist-util-visit: 5.0.0

  remark-gfm@3.0.1:
    dependencies:
      '@types/mdast': 3.0.15
      mdast-util-gfm: 2.0.2
      micromark-extension-gfm: 2.0.3
      unified: 10.1.2
    transitivePeerDependencies:
      - supports-color

  remark-gfm@4.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      mdast-util-gfm: 3.0.0
      micromark-extension-gfm: 3.0.0
      remark-parse: 11.0.0
      remark-stringify: 11.0.0
      unified: 11.0.5
    transitivePeerDependencies:
      - supports-color

  remark-math@5.1.1:
    dependencies:
      '@types/mdast': 3.0.15
      mdast-util-math: 2.0.2
      micromark-extension-math: 2.1.2
      unified: 10.1.2

  remark-mdx@3.0.1:
    dependencies:
      mdast-util-mdx: 3.0.0
      micromark-extension-mdxjs: 3.0.0
    transitivePeerDependencies:
      - supports-color

  remark-parse@10.0.2:
    dependencies:
      '@types/mdast': 3.0.15
      mdast-util-from-markdown: 1.3.1
      unified: 10.1.2
    transitivePeerDependencies:
      - supports-color

  remark-parse@11.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      mdast-util-from-markdown: 2.0.1
      micromark-util-types: 2.0.0
      unified: 11.0.5
    transitivePeerDependencies:
      - supports-color

  remark-rehype@10.1.0:
    dependencies:
      '@types/hast': 2.3.10
      '@types/mdast': 3.0.15
      mdast-util-to-hast: 12.3.0
      unified: 10.1.2

  remark-rehype@11.1.1:
    dependencies:
      '@types/hast': 3.0.4
      '@types/mdast': 4.0.4
      mdast-util-to-hast: 13.2.0
      unified: 11.0.5
      vfile: 6.0.3

  remark-stringify@11.0.0:
    dependencies:
      '@types/mdast': 4.0.4
      mdast-util-to-markdown: 2.1.0
      unified: 11.0.5

  remark@15.0.1:
    dependencies:
      '@types/mdast': 4.0.4
      remark-parse: 11.0.0
      remark-stringify: 11.0.0
      unified: 11.0.5
    transitivePeerDependencies:
      - supports-color

  resolve@1.22.8:
    dependencies:
      is-core-module: 2.15.1
      path-parse: 1.0.7
      supports-preserve-symlinks-flag: 1.0.0

  reusify@1.0.4: {}

  robust-predicates@3.0.2: {}

  roughjs@4.6.6:
    dependencies:
      hachure-fill: 0.5.2
      path-data-parser: 0.1.0
      points-on-curve: 0.2.0
      points-on-path: 0.2.1

  run-parallel@1.2.0:
    dependencies:
      queue-microtask: 1.2.3

  rw@1.3.3: {}

  sade@1.8.1:
    dependencies:
      mri: 1.2.0

  safer-buffer@2.1.2: {}

  scheduler@0.23.2:
    dependencies:
      loose-envify: 1.4.0

  scroll-into-view-if-needed@3.1.0:
    dependencies:
      compute-scroll-into-view: 3.1.0

  section-matter@1.0.0:
    dependencies:
      extend-shallow: 2.0.1
      kind-of: 6.0.3

  server-only@0.0.1: {}

  shebang-command@2.0.0:
    dependencies:
      shebang-regex: 3.0.0

  shebang-regex@3.0.0: {}

  shiki@1.18.0:
    dependencies:
      '@shikijs/core': 1.18.0
      '@shikijs/engine-javascript': 1.18.0
      '@shikijs/engine-oniguruma': 1.18.0
      '@shikijs/types': 1.18.0
      '@shikijs/vscode-textmate': 9.2.2
      '@types/hast': 3.0.4

  shiki@1.20.0:
    dependencies:
      '@shikijs/core': 1.20.0
      '@shikijs/engine-javascript': 1.20.0
      '@shikijs/engine-oniguruma': 1.20.0
      '@shikijs/types': 1.20.0
      '@shikijs/vscode-textmate': 9.2.2
      '@types/hast': 3.0.4

  signal-exit@4.1.0: {}

  sister@3.0.2: {}

  snake-case@3.0.4:
    dependencies:
      dot-case: 3.0.4
      tslib: 2.7.0

  snakecase-keys@5.4.4:
    dependencies:
      map-obj: 4.3.0
      snake-case: 3.0.4
      type-fest: 2.19.0

  source-map-js@1.2.1: {}

  source-map@0.7.4: {}

  space-separated-tokens@1.1.5: {}

  space-separated-tokens@2.0.2: {}

  sprintf-js@1.0.3: {}

  std-env@3.7.0: {}

  streamsearch@1.1.0: {}

  string-width@4.2.3:
    dependencies:
      emoji-regex: 8.0.0
      is-fullwidth-code-point: 3.0.0
      strip-ansi: 6.0.1

  string-width@5.1.2:
    dependencies:
      eastasianwidth: 0.2.0
      emoji-regex: 9.2.2
      strip-ansi: 7.1.0

  stringify-entities@4.0.4:
    dependencies:
      character-entities-html4: 2.1.0
      character-entities-legacy: 3.0.0

  strip-ansi@6.0.1:
    dependencies:
      ansi-regex: 5.0.1

  strip-ansi@7.1.0:
    dependencies:
      ansi-regex: 6.1.0

  strip-bom-string@1.0.0: {}

  style-to-object@0.4.4:
    dependencies:
      inline-style-parser: 0.1.1

  style-to-object@1.0.8:
    dependencies:
      inline-style-parser: 0.2.4

  styled-jsx@5.1.1(react@18.3.1):
    dependencies:
      client-only: 0.0.1
      react: 18.3.1

  stylis@4.3.4: {}

  sucrase@3.35.0:
    dependencies:
      '@jridgewell/gen-mapping': 0.3.5
      commander: 4.1.1
      glob: 10.4.5
      lines-and-columns: 1.2.4
      mz: 2.7.0
      pirates: 4.0.6
      ts-interface-checker: 0.1.13

  supports-color@7.2.0:
    dependencies:
      has-flag: 4.0.0

  supports-preserve-symlinks-flag@1.0.0: {}

  swr@2.2.5(react@18.3.1):
    dependencies:
      client-only: 0.0.1
      react: 18.3.1
      use-sync-external-store: 1.2.2(react@18.3.1)

  tabbable@6.2.0: {}

  tailwind-merge@2.5.2: {}

  tailwindcss-animate@1.0.7(tailwindcss@3.4.13):
    dependencies:
      tailwindcss: 3.4.13

  tailwindcss@3.4.13:
    dependencies:
      '@alloc/quick-lru': 5.2.0
      arg: 5.0.2
      chokidar: 3.6.0
      didyoumean: 1.2.2
      dlv: 1.1.3
      fast-glob: 3.3.2
      glob-parent: 6.0.2
      is-glob: 4.0.3
      jiti: 1.21.6
      lilconfig: 2.1.0
      micromatch: 4.0.8
      normalize-path: 3.0.0
      object-hash: 3.0.0
      picocolors: 1.1.0
      postcss: 8.4.47
      postcss-import: 15.1.0(postcss@8.4.47)
      postcss-js: 4.0.1(postcss@8.4.47)
      postcss-load-config: 4.0.2(postcss@8.4.47)
      postcss-nested: 6.2.0(postcss@8.4.47)
      postcss-selector-parser: 6.1.2
      resolve: 1.22.8
      sucrase: 3.35.0
    transitivePeerDependencies:
      - ts-node

  thenify-all@1.6.0:
    dependencies:
      thenify: 3.3.1

  thenify@3.3.1:
    dependencies:
      any-promise: 1.3.0

  tinyexec@0.3.0: {}

  to-regex-range@5.0.1:
    dependencies:
      is-number: 7.0.0

  tr46@0.0.3: {}

  trim-lines@3.0.1: {}

  trough@2.2.0: {}

  ts-dedent@2.2.0: {}

  ts-interface-checker@0.1.13: {}

  tslib@2.4.1: {}

  tslib@2.7.0: {}

  type-fest@2.19.0: {}

  typescript@5.6.2: {}

  ufo@1.5.4: {}

  undici-types@6.19.8: {}

  unified@10.1.2:
    dependencies:
      '@types/unist': 2.0.11
      bail: 2.0.2
      extend: 3.0.2
      is-buffer: 2.0.5
      is-plain-obj: 4.1.0
      trough: 2.2.0
      vfile: 5.3.7

  unified@11.0.5:
    dependencies:
      '@types/unist': 3.0.3
      bail: 2.0.2
      devlop: 1.1.0
      extend: 3.0.2
      is-plain-obj: 4.1.0
      trough: 2.2.0
      vfile: 6.0.3

  unist-util-generated@2.0.1: {}

  unist-util-is@5.2.1:
    dependencies:
      '@types/unist': 2.0.11

  unist-util-is@6.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-position-from-estree@2.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-position@4.0.4:
    dependencies:
      '@types/unist': 2.0.11

  unist-util-position@5.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-stringify-position@3.0.3:
    dependencies:
      '@types/unist': 2.0.11

  unist-util-stringify-position@4.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-visit-parents@5.1.3:
    dependencies:
      '@types/unist': 2.0.11
      unist-util-is: 5.2.1

  unist-util-visit-parents@6.0.1:
    dependencies:
      '@types/unist': 3.0.3
      unist-util-is: 6.0.0

  unist-util-visit@4.1.2:
    dependencies:
      '@types/unist': 2.0.11
      unist-util-is: 5.2.1
      unist-util-visit-parents: 5.1.3

  unist-util-visit@5.0.0:
    dependencies:
      '@types/unist': 3.0.3
      unist-util-is: 6.0.0
      unist-util-visit-parents: 6.0.1

  untruncate-json@0.0.1: {}

  update-browserslist-db@1.1.0(browserslist@4.24.0):
    dependencies:
      browserslist: 4.24.0
      escalade: 3.2.0
      picocolors: 1.1.0

  urql@4.2.2(@urql/core@5.1.1(graphql@16.10.0))(react@18.3.1):
    dependencies:
      '@urql/core': 5.1.1(graphql@16.10.0)
      react: 18.3.1
      wonka: 6.3.5

  use-callback-ref@1.3.2(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      react: 18.3.1
      tslib: 2.7.0
    optionalDependencies:
      '@types/react': 18.3.9

  use-sidecar@1.1.2(@types/react@18.3.9)(react@18.3.1):
    dependencies:
      detect-node-es: 1.1.0
      react: 18.3.1
      tslib: 2.7.0
    optionalDependencies:
      '@types/react': 18.3.9

  use-sync-external-store@1.2.2(react@18.3.1):
    dependencies:
      react: 18.3.1

  usehooks-ts@3.1.0(react@18.3.1):
    dependencies:
      lodash.debounce: 4.0.8
      react: 18.3.1

  util-deprecate@1.0.2: {}

  uuid@10.0.0: {}

  uuid@9.0.1: {}

  uvu@0.5.6:
    dependencies:
      dequal: 2.0.3
      diff: 5.2.0
      kleur: 4.1.5
      sade: 1.8.1

  vfile-message@3.1.4:
    dependencies:
      '@types/unist': 2.0.11
      unist-util-stringify-position: 3.0.3

  vfile-message@4.0.2:
    dependencies:
      '@types/unist': 3.0.3
      unist-util-stringify-position: 4.0.0

  vfile@5.3.7:
    dependencies:
      '@types/unist': 2.0.11
      is-buffer: 2.0.5
      unist-util-stringify-position: 3.0.3
      vfile-message: 3.1.4

  vfile@6.0.3:
    dependencies:
      '@types/unist': 3.0.3
      vfile-message: 4.0.2

  vscode-jsonrpc@8.2.0: {}

  vscode-languageserver-protocol@3.17.5:
    dependencies:
      vscode-jsonrpc: 8.2.0
      vscode-languageserver-types: 3.17.5

  vscode-languageserver-textdocument@1.0.12: {}

  vscode-languageserver-types@3.17.5: {}

  vscode-languageserver@9.0.1:
    dependencies:
      vscode-languageserver-protocol: 3.17.5

  vscode-uri@3.0.8: {}

  web-vitals@4.2.3: {}

  webidl-conversions@3.0.1: {}

  whatwg-url@5.0.0:
    dependencies:
      tr46: 0.0.3
      webidl-conversions: 3.0.1

  which@2.0.2:
    dependencies:
      isexe: 2.0.0

  wonka@6.3.5: {}

  wrap-ansi@7.0.0:
    dependencies:
      ansi-styles: 4.3.0
      string-width: 4.2.3
      strip-ansi: 6.0.1

  wrap-ansi@8.1.0:
    dependencies:
      ansi-styles: 6.2.1
      string-width: 5.1.2
      strip-ansi: 7.1.0

  xtend@4.0.2: {}

  yaml@2.5.1: {}

  youtube-player@5.5.2:
    dependencies:
      debug: 2.6.9
      load-script: 1.0.0
      sister: 3.0.2
    transitivePeerDependencies:
      - supports-color

  zod-to-json-schema@3.24.5(zod@3.23.8):
    dependencies:
      zod: 3.23.8

  zod@3.23.8: {}

  zwitch@2.0.4: {}



================================================
FILE: docs/postcss.config.js
================================================
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};



================================================
FILE: docs/props.ts
================================================
export type SomeProps = {
  some: string;
}


================================================
FILE: docs/script.mjs
================================================
import { generateFiles, generateMDX } from 'fumadocs-typescript';
import * as path from 'node:path';
import * as fs from 'node:fs/promises';

console.log("Generating files...");

void generateFiles({
  input: ['./content/docs/**/*.model.mdx'],
  // Rename x.model.mdx to x.mdx
  output: (file) =>
    path.resolve(
      path.dirname(file),
      `${path.basename(file).split('.')[0]}.mdx`,
    ),
});


================================================
FILE: docs/source.config.ts
================================================
import { defineDocs, defineConfig } from "fumadocs-mdx/config";

import {
  fileGenerator,
  remarkDocGen,
  remarkInstall,
  typescriptGenerator,
} from "fumadocs-docgen";
import { rehypeCode } from "fumadocs-core/mdx-plugins";
import {
  transformerNotationDiff,
  transformerNotationHighlight,
  transformerNotationWordHighlight,
  // ...
} from "@shikijs/transformers";
import { remarkMermaid } from '@theguild/remark-mermaid'

export const { docs, meta } = defineDocs();

export default defineConfig({
  mdxOptions: {
    rehypePlugins: [
      [
        rehypeCode,
        {
          transformers: [
            transformerNotationDiff(),
            transformerNotationHighlight(),
            transformerNotationWordHighlight(),
          ],
        },
      ],
    ],
    remarkPlugins: [
      remarkMermaid,
      [remarkInstall, { persist: { id: "package-manager" } }],
      [remarkDocGen, { generators: [typescriptGenerator(), fileGenerator()] }],
    ],
  },
});



================================================
FILE: docs/tailwind.config.js
================================================
import { createPreset } from 'fumadocs-ui/tailwind-plugin';

/** @type {import('tailwindcss').Config} */
export default {
    darkMode: ['class'],
    content: [
		'./lib/icons/**/*.{ts,tsx}',
    './components/**/*.{ts,tsx}',
    './app/**/*.{ts,tsx}',
    './content/**/*.{md,mdx}',
    './mdx-components.{ts,tsx}',
    './node_modules/fumadocs-ui/dist/**/*.js',
  ],
  safelist: [
    'xl:grid-cols-1',
    'xl:grid-cols-2',
    'xl:grid-cols-3',
    'xl:grid-cols-4',
    'xl:col-span-2',
    'xl:col-span-3',
    'xl:col-span-4',
    'prose',
    'prose-headings',
    'prose-lead',
    'prose-p',
    'prose-blockquote',
    'prose-figure',
    'prose-figcaption',
    'prose-strong',
    'prose-em',
    'prose-code',
    'prose-pre',
    'prose-ol',
    'prose-ul',
    'prose-li',
    'prose-table',
    'prose-thead',
    'prose-tr',
    'prose-th',
    'prose-td',
    'prose-img',
    'prose-video',
    'prose-hr',
    'prose-a',
    'dark:prose-invert'
  ],
  presets: [createPreset()],
    plugins: [
      require("tailwindcss-animate"),
      require("@tailwindcss/typography"),
    ],
    theme: {
    	extend: {
    		borderRadius: {
    			lg: 'var(--radius)',
    			md: 'calc(var(--radius) - 2px)',
    			sm: 'calc(var(--radius) - 4px)'
    		},
    		colors: {
    			background: 'hsl(var(--background))',
    			foreground: 'hsl(var(--foreground))',
    			card: {
    				DEFAULT: 'hsl(var(--card))',
    				foreground: 'hsl(var(--card-foreground))'
    			},
    			popover: {
    				DEFAULT: 'hsl(var(--popover))',
    				foreground: 'hsl(var(--popover-foreground))'
    			},
    			primary: {
    				DEFAULT: 'hsl(var(--primary))',
    				foreground: 'hsl(var(--primary-foreground))'
    			},
    			secondary: {
    				DEFAULT: 'hsl(var(--secondary))',
    				foreground: 'hsl(var(--secondary-foreground))'
    			},
    			muted: {
    				DEFAULT: 'hsl(var(--muted))',
    				foreground: 'hsl(var(--muted-foreground))'
    			},
    			accent: {
    				DEFAULT: 'hsl(var(--accent))',
    				foreground: 'hsl(var(--accent-foreground))'
    			},
    			destructive: {
    				DEFAULT: 'hsl(var(--destructive))',
    				foreground: 'hsl(var(--destructive-foreground))',
    				muted: 'hsl(var(--destructive-muted))',
    				'muted-foreground': 'hsl(var(--destructive-muted-foreground))'
    			},
    			success: {
    				DEFAULT: 'hsl(var(--success))',
    				foreground: 'hsl(var(--success-foreground))',
    				muted: 'hsl(var(--success-muted))',
    				'muted-foreground': 'hsl(var(--success-muted-foreground))'
    			},
    			warning: {
    				DEFAULT: 'hsl(var(--warning))',
    				foreground: 'hsl(var(--warning-foreground))',
    				muted: 'hsl(var(--warning-muted))',
    				'muted-foreground': 'hsl(var(--warning-muted-foreground))'
    			},
    			error: {
    				DEFAULT: 'hsl(var(--error))',
    				foreground: 'hsl(var(--error-foreground))',
    				muted: 'hsl(var(--error-muted))',
    				'muted-foreground': 'hsl(var(--error-muted-foreground))'
    			},
    			info: {
    				DEFAULT: 'hsl(var(--info))',
    				foreground: 'hsl(var(--info-foreground))',
    				muted: 'hsl(var(--info-muted))',
    				'muted-foreground': 'hsl(var(--info-muted-foreground))'
    			},
    			border: 'hsl(var(--border))',
    			input: 'hsl(var(--input))',
    			ring: 'hsl(var(--ring))',
    			chart: {
    				'1': 'hsl(var(--chart-1))',
    				'2': 'hsl(var(--chart-2))',
    				'3': 'hsl(var(--chart-3))',
    				'4': 'hsl(var(--chart-4))',
    				'5': 'hsl(var(--chart-5))'
    			}
    		},
    		keyframes: {
    			'accordion-down': {
    				from: {
    					height: '0'
    				},
    				to: {
    					height: 'var(--radix-accordion-content-height)'
    				}
    			},
    			'accordion-up': {
    				from: {
    					height: 'var(--radix-accordion-content-height)'
    				},
    				to: {
    					height: '0'
    				}
    			}
    		},
    		animation: {
    			'accordion-down': 'accordion-down 0.2s ease-out',
    			'accordion-up': 'accordion-up 0.2s ease-out'
    		},
        typography: {
          DEFAULT: {
            css: {
              maxWidth: 'none',
            },
          },
        },
    	}
    }
};



================================================
FILE: docs/tsconfig.json
================================================
{
  "compilerOptions": {
    "baseUrl": ".",
    "target": "ESNext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "allowImportingTsExtensions": true,
    "paths": {
      "@/*": ["./*"],
    },
    "plugins": [
      {
        "name": "next"
      }
    ]
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
FILE: docs/vercel.json
================================================
{
  "functions": {
    "app/og/**": {
      "maxDuration": 60
    }
  },
  "buildCommand": "next build",
  "images": {
    "sizes": [640, 750, 828, 1080, 1200, 1920, 2048, 3840],
    "domains": [
      "github-production-user-asset-6210df.s3.amazonaws.com",
      "fonts.gstatic.com",
      "docs.copilotkit.ai"
    ],
    "remotePatterns": [
      {
        "protocol": "https",
        "hostname": "**"
      }
    ]
  }
}



================================================
FILE: docs/.env
================================================
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY="pk_test_Zmxvd2luZy1ld2UtMzEuY2xlcmsuYWNjb3VudHMuZGV2JA"
# NEXT_PUBLIC_COPILOT_CLOUD_PUBLIC_API_KEY="..."
# NEXT_PUBLIC_POSTHOG_KEY="phc_XZdymVYjrph9Mi0xZYGNyCKexxgblXRR1jMENCtdz5Q"
# NEXT_PUBLIC_POSTHOG_HOST="https://eu.i.posthog.com"
# NEXT_PUBLIC_SCARF_PIXEL_ID="ffc9f65d-0186-4575-b065-61d62ea9d7d3"
# NEXT_PUBLIC_RB2B_ID="1N5W0HMJG4O5"


================================================
FILE: docs/.gitignore
================================================
# deps
/node_modules

# generated content
.contentlayer
.content-collections
.source

# test & build
/coverage
/.next/
/out/
/build
*.tsbuildinfo

# misc
.DS_Store
*.pem
/.pnp
.pnp.js
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# others
.env*.local
.vercel
next-env.d.ts


================================================
FILE: docs/.prettierignore
================================================
**/*.mdx



================================================
FILE: docs/app/global.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

.line.diff.remove {
  @apply px-0 mx-0;
  background-color: rgb(255, 220, 220);
  @apply dark:bg-red-950/70;
}

.line.diff.add {
  @apply px-0 mx-0;
  background-color: rgb(220, 255, 220);
  @apply dark:bg-green-950/70;
}

@layer base {
  #nd-sidebar > div.overflow-hidden.flex-1 > div{
    @apply px-4;
  }
  #model-context-protocol-banner > button {
    @apply text-white hover:text-black dark:text-white dark:hover:bg-white dark:hover:text-black;
  }

  :root {
    --fd-sidebar-width: 330px !important;
    --background: 0 0% 100%;
    --foreground: 0 0% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 0 0% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 0 0% 3.9%;
    --primary: 0 0% 9%;
    --primary-foreground: 0 0% 98%;
    --secondary: 0 0% 96.1%;
    --secondary-foreground: 0 0% 9%;
    --muted: 0 0% 96.1%;
    --muted-foreground: 0 0% 45.1%;
    --accent: 0 0% 96.1%;
    --accent-foreground: 0 0% 9%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 89.8%;
    --input: 0 0% 89.8%;
    --ring: 0 0% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;
    --success: 142 72% 29%;
    --success-foreground: 0 0% 98%;
    --success-muted: 142 76% 90%;
    --success-muted-foreground: 142 72% 29%;
    --warning: 38 92% 50%;
    --warning-foreground: 0 0% 98%;
    --warning-muted: 38 92% 90%;
    --warning-muted-foreground: 38 92% 30%;
    --error: 0 84.2% 60.2%;
    --error-foreground: 0 0% 98%;
    --error-muted: 0 84.2% 90%;
    --error-muted-foreground: 0 84.2% 40%;
    --info: 214 95% 48%;
    --info-foreground: 0 0% 98%;
    --info-muted: 214 95% 90%;
    --info-muted-foreground: 214 95% 30%;
  }
  @media (max-width: 1200px) {
    :root {
      --fd-sidebar-width: 280px !important;
    }
  }
  @media (max-width: 640px) {
    :root {
      --fd-sidebar-width: 260px !important;
    }
  }
  .dark {
    --background: 0 0% 3.9%;
    --foreground: 0 0% 98%;
    --card: 0 0% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 0 0% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 0 0% 9%;
    --secondary: 0 0% 14.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 0 0% 14.9%;
    --muted-foreground: 0 0% 63.9%;
    --accent: 0 0% 14.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 14.9%;
    --input: 0 0% 14.9%;
    --ring: 0 0% 83.1%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;
    --success: 142 72% 46%;
    --success-foreground: 0 0% 98%;
    --success-muted: 142 76% 20%;
    --success-muted-foreground: 142 72% 80%;
    --warning: 38 92% 50%;
    --warning-foreground: 0 0% 98%;
    --warning-muted: 38 92% 20%;
    --warning-muted-foreground: 38 92% 80%;
    --error: 0 62.8% 30.6%;
    --error-foreground: 0 0% 98%;
    --error-muted: 0 62.8% 20%;
    --error-muted-foreground: 0 62.8% 80%;
    --info: 214 95% 60%;
    --info-foreground: 0 0% 98%;
    --info-muted: 214 95% 20%;
    --info-muted-foreground: 214 95% 80%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }

  .fd-codeblock pre {
    @apply max-h-none;
  }

  div[data-toc] {
    @apply lg:mt-10;
  }

  article {
    @apply lg:mt-10;
  }
} 


================================================
FILE: docs/app/layout.config.tsx
================================================
import { type HomeLayoutProps } from 'fumadocs-ui/home-layout';
import { Logo } from "./logo";
import { FaDiscord, FaEdit } from 'react-icons/fa';
import { FaXTwitter } from 'react-icons/fa6';

/**
 * Shared layout configurations
 *
 * you can configure layouts individually from:
 * Home Layout: app/(home)/layout.tsx
 * Docs Layout: app/docs/layout.tsx
 */
export const baseOptions: HomeLayoutProps = {
  githubUrl: "https://github.com/copilotkit/copilotkit",
  nav: {
    title: <Logo />,
  },
  links: [
    {
      text: "Feedback",
      url: "https://github.com/CopilotKit/CopilotKit/issues/new/choose",
      icon: <FaEdit />,
    },
    {
      text: "Discord",
      url: "https://discord.com/invite/6dffbvGU3D",
      icon: <FaDiscord />,
    },
    {
      text: "Twitter",
      url: "https://x.com/copilotkit",
      icon: <FaXTwitter />,
    },
  ],
};




================================================
FILE: docs/app/layout.tsx
================================================
import "./global.css";
import { RootProvider } from "fumadocs-ui/provider";
import { Inter } from "next/font/google";
import type { ReactNode } from "react";
import { ProvidersWrapper } from "@/lib/providers/providers-wrapper";
import { Banners } from "@/components/layout/banners";
import Script from "next/script";

const inter = Inter({
  subsets: ["latin"],
});

export default async function Layout({ children }: { children: ReactNode }) {
  return (
    <html lang="en" className={inter.className} suppressHydrationWarning>
      <head>
        <Script
          id="hubspot-script"
          type="text/javascript"
          src="https://js.hs-scripts.com/45532593.js"
          async
          defer
        />
      </head>
      <body>
        <ProvidersWrapper>
          <Banners />
          <RootProvider theme={{ enabled: true, defaultTheme: "dark" }}>
            {children}
          </RootProvider>
        </ProvidersWrapper>
      </body>
    </html>
  );
}



================================================
FILE: docs/app/logo.tsx
================================================
import Image from "next/image";

export function Logo() {

  return (
    // <div className="w-[--fd-sidebar-width] flex items-center justify-center gap-1 ml-[-12px]">
    <div className="flex items-center justify-center gap-1 md:px-6 py-2">
      <Image src={"/copilotkit-logo-light.png"} width={150} height={40} alt="Logo" className="block dark:hidden" />
      <Image src={"/copilotkit-logo-dark.png"} width={150} height={40} alt="Logo" className="hidden dark:block" />
    </div>
  )
  
}


================================================
FILE: docs/app/not-found.tsx
================================================
'use client';

import Image from 'next/image';
import Link from 'next/link';

export default function NotFound() {
  return (
    <div className="flex flex-col items-center justify-center min-h-screen">
      <div className="text-center">
        <div className="relative w-32 h-32 mx-auto mb-8 animate-bounce">
          <Image
            src="/images/copilotkit-logo.svg"
            alt="CopilotKit Logo"
            fill
            priority
            className="object-contain"
          />
        </div>
        <h1 className="text-4xl font-bold mb-4 bg-gradient-to-r from-blue-600 to-purple-600 text-transparent bg-clip-text">
          Page Not Found
        </h1>
        <p className="text-gray-600 dark:text-gray-300 mb-6 max-w-sm">
          Oops! The page you're looking for doesn't exist.
        </p>
        <Link 
          href="/" 
          className="inline-flex items-center px-6 py-3 text-base font-medium text-white bg-gradient-to-r from-blue-600 to-purple-600 rounded-lg hover:opacity-90 transition-opacity"
        >
          Go to Documentation
        </Link>
      </div>
    </div>
  );
}



================================================
FILE: docs/app/sitemap.ts
================================================
import type { MetadataRoute } from 'next';
import { source } from "./source";

export const revalidate = false;

const baseUrl =
  process.env.NODE_ENV === 'development' || !process.env.VERCEL_URL
    ? new URL('http://localhost:3000')
    : new URL(`https://${process.env.VERCEL_URL}`);

export default function sitemap(): MetadataRoute.Sitemap {
  const url = (path: string): string => new URL(path, baseUrl).toString();

  return [
    {
      url: url('/'),
      changeFrequency: 'monthly',
      priority: 1,
    },
    ...source.getPages().map<MetadataRoute.Sitemap[number]>((page) => ({
      url: url(page.url),
      lastModified: page.data.lastModified
        ? new Date(page.data.lastModified)
        : undefined,
      changeFrequency: 'weekly',
      priority: 0.5,
    })),
  ];
}



================================================
FILE: docs/app/source.ts
================================================
import { docs, meta } from '@/.source';
import { createMDXSource } from 'fumadocs-mdx';
import { loader } from 'fumadocs-core/source';
import { icon } from "@/lib/icons";

export const source = loader({
  baseUrl: '/',
  source: createMDXSource(docs, meta),
  icon,
});



================================================
FILE: docs/app/(home)/layout.tsx
================================================
import { DocsLayout } from "fumadocs-ui/layout";
import type { ReactNode } from "react";
import { baseOptions } from "../layout.config";
import { source } from "@/app/source";
import { SubdocsMenu } from "@/components/react/subdocs-menu";
import { TerminalIcon, RocketIcon } from "lucide-react";
import { SiCrewai } from "@icons-pack/react-simple-icons";
import { TopBar } from "@/components/layout/top-bar";
import { SiLangchain } from "react-icons/si";
import { AG2Icon, MastraIcon } from "@/lib/icons/custom-icons";

export default function Layout({ children }: { children: ReactNode }) {
  return (
    <>
      <TopBar />
      <DocsLayout
        tree={source.pageTree}
        {...baseOptions}
        sidebar={{
          hideSearch: true,
          banner: (
            <SubdocsMenu
              options={[
                {
                  title: "Standard",
                  description: "Documentation for building Copilots",
                  url: "/",
                  icon: <RocketIcon className="w-4 h-4" />,
                  bgGradient:
                    "bg-gradient-to-b from-indigo-700 to-indigo-400 text-indigo-100",
                  selectedStyle: "ring-indigo-500/70 ring-2 rounded-sm",
                },

                {
                  title: "CoAgents",
                  options: [
                    {
                      title: "CoAgents (LangGraph)",
                      description: "Documentation for CoAgents with LangGraph",
                      url: "/coagents",
                      icon: <SiLangchain className="w-4 h-4 text-bold" />,
                      bgGradient:
                        "bg-gradient-to-b from-purple-700 to-purple-400 text-purple-100",
                      selectedStyle: "ring-purple-500/70 ring-2 rounded-sm",
                    },
                    {
                      title: "CoAgents (CrewAI Flows)",
                      description:
                        "Documentation for CoAgents with CrewAI Flows",
                      url: "/crewai-flows",
                      icon: <SiCrewai className="w-4 h-4 text-bold" />,
                      bgGradient:
                        "bg-gradient-to-b from-[#FA694C] to-[#FE8A71] text-white",
                      selectedStyle: "ring-[#FA694C]/70 ring-2 rounded-sm",
                    },
                    {
                      title: "CoAgents (CrewAI Crews)",
                      description:
                        "Documentation for CoAgents with CrewAI Crews",
                      url: "/crewai-crews",
                      icon: <SiCrewai className="w-4 h-4 text-bold" />,
                      bgGradient:
                        "bg-gradient-to-b from-[#FA694C] to-[#FE8A71] text-white",
                      selectedStyle: "ring-[#FA694C]/70 ring-2 rounded-sm",
                    },
                    {
                      title: "CoAgents (Mastra)",
                      description: "Documentation for CoAgents with Mastra",
                      url: "/mastra",
                      icon: <MastraIcon className="w-4 h-4 text-bold" />,
                      bgGradient:
                        "bg-gradient-to-b from-black to-zinc-800 text-white",
                      selectedStyle: "ring-zinc-800 dark:ring-white ring-2 rounded-sm",
                    },
                    {
                      title: "CoAgents (AG2)",
                      description: "Documentation for CoAgents with AG2",
                      url: "/ag2",
                      icon: <AG2Icon className="w-4 h-4 text-bold" />,
                      bgGradient:
                        "bg-gradient-to-b from-indigo-700 to-indigo-400 text-indigo-100",
                      selectedStyle: "ring-indigo-500/70 ring-2 rounded-sm",
                    },
                  ],
                },
                {
                  title: "API Reference",
                  description: "API Reference",
                  url: "/reference",
                  icon: <TerminalIcon className="w-4 h-4" />,
                  bgGradient:
                    "bg-gradient-to-b from-teal-700 to-teal-400 text-teal-100",
                  selectedStyle: "ring-teal-500/70 ring-2 rounded-sm",
                },

                // {
                //   title: "Chat with our docs",
                //   description: "Chat with our docs",
                //   url: "https://entelligence.ai/CopilotKit&CopilotKit",
                //   icon: <CircleArrowOutUpRight className="w-4 h-4" />,
                //   bgGradient:
                //     "bg-gradient-to-b from-purple-700 to-purple-400 text-purple-100",
                //   selectedBorder: "ring-teal-500/70",
                // },
              ]}
            />
          ),
        }}
      >
        {children}
      </DocsLayout>
    </>
  );
}



================================================
FILE: docs/app/(home)/[[...slug]]/page.tsx
================================================
import { source } from "@/app/source";
import type { Metadata } from "next";
import {
  DocsPage,
  DocsBody,
  DocsDescription,
  DocsTitle,
} from "fumadocs-ui/page";
import { notFound } from "next/navigation";
import defaultMdxComponents from "fumadocs-ui/mdx";
import { Badge } from "@/components/ui/badge";
import { CloudIcon } from "lucide-react";

import { Tabs, Tab } from "@/components/react/tabs";
import { Steps, Step } from "fumadocs-ui/components/steps";
import { TypeTable } from "fumadocs-ui/components/type-table";
import { Pre, CodeBlock } from "fumadocs-ui/components/codeblock";
import { Callout } from "fumadocs-ui/components/callout";
import { Frame } from "@/components/react/frame";
import { Mermaid } from "@theguild/remark-mermaid/mermaid";
import { Cards, Card } from "fumadocs-ui/components/card";
import { PropertyReference } from "@/components/react/property-reference";
import { getImageMeta } from "fumadocs-ui/og";
import { InsecurePasswordProtected } from "@/components/react/insecure-password-protected";
import { LinkToCopilotCloud } from "@/components/react/link-to-copilot-cloud";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

/**
 * TODO: This should be dynamic, but it's not working.
 */
const cloudOnlyFeatures = ["Authenticated Actions", "Guardrails"];

const mdxComponents = {
  ...defaultMdxComponents,
  InsecurePasswordProtected: InsecurePasswordProtected,
  LinkToCopilotCloud: LinkToCopilotCloud,
  Accordions: Accordions,
  Accordion: Accordion,
  Tabs: Tabs,
  Tab: Tab,
  Steps: Steps,
  Step: Step,
  TypeTable: TypeTable,
  Callout: Callout,
  Frame: Frame,
  Mermaid: Mermaid,
  Cards: Cards,
  Card: Card,
  PropertyReference: PropertyReference,
  // HTML `ref` attribute conflicts with `forwardRef`
  pre: ({ ref: _ref, ...props }: any) => (
    <CodeBlock {...props}>
      <Pre>{props.children}</Pre>
    </CodeBlock>
  ),
};

export default async function Page({
  params,
}: {
  params: { slug?: string[] };
}) {
  const page = source.getPage(params.slug);
  if (!page) notFound();
  const MDX = page.data.body;
  const cloudOnly = cloudOnlyFeatures.includes(page.data.title);
  return (
    <DocsPage
      toc={page.data.toc}
      full={page.data.full}
      editOnGithub={{
        owner: "CopilotKit",
        repo: "CopilotKit",
        sha: "main",
        path: `/docs/content/docs/${page.file.path}`,
      }}
    >
      <div className="flex items-center gap-3">
        <DocsTitle className="flex items-center">
          {page.data.title}
          {cloudOnly && (
            <Badge
              variant="secondary"
              className="ml-3 mt-1 inline-flex items-center gap-1.5 py-1.5 px-3 bg-indigo-600/90 text-white hover:bg-indigo-600 border-0 rounded-md transition-colors"
            >
              <CloudIcon className="w-3 h-3" />
              <span className="text-xs">Cloud Only</span>
            </Badge>
          )}
        </DocsTitle>
      </div>
      <DocsDescription>{page.data.description}</DocsDescription>
      <DocsBody>
        <MDX components={mdxComponents} renderSmth={() => <div>test</div>} />
      </DocsBody>
    </DocsPage>
  );
}

export async function generateStaticParams() {
  return source.generateParams();
}

export function generateMetadata({ params }: { params: { slug?: string[] } }) {
  const page = source.getPage(params.slug);
  if (!page) notFound();

  const image = getImageMeta("og", page.slugs);

  return {
    title: page.data.title,
    description: page.data.description,
    openGraph: {
      images: image,
    },
    twitter: {
      images: image,
      card: "summary_large_image",
    },
  } satisfies Metadata;
}



================================================
FILE: docs/app/api/search/route.ts
================================================
import { source } from '@/app/source';
import { createSearchAPI } from 'fumadocs-core/search/server';

export const { GET } = createSearchAPI('advanced', {
  indexes: source.getPages().map((page) => ({
    title: page.data.title,
    description: page.data.description,
    structuredData: page.data.structuredData,
    id: page.url,
    url: page.url,
  })),
});



================================================
FILE: docs/app/og/[...slug]/route.tsx
================================================
import React from "react";
import { type NextRequest } from "next/server";
import { notFound } from "next/navigation";
import { source } from "../../source";
import { ImageResponse } from "next/og";

const getInter = async () => {
  try {
    const response = await fetch(
      `https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZg.ttf`,
      { cache: "force-cache" }
    );
    if (!response.ok) {
      throw new Error(`Failed to fetch Inter font: ${response.status}`);
    }
    const res = await response.arrayBuffer();
    return res;
  } catch (error) {
    console.error("Error fetching Inter font:", error);
    // Return null to handle the error case in the ImageResponse
    return null;
  }
};

const getInterSemibold = async () => {
  try {
    const response = await fetch(
      `https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuGKYMZg.ttf`,
      { cache: "force-cache" }
    );
    if (!response.ok) {
      throw new Error(
        `Failed to fetch Inter Semibold font: ${response.status}`
      );
    }
    const res = await response.arrayBuffer();
    return res;
  } catch (error) {
    console.error("Error fetching Inter Semibold font:", error);
    // Return null to handle the error case in the ImageResponse
    return null;
  }
};

export async function GET(
  _: NextRequest,
  { params }: { params: { slug: string[] } }
) {
  // Skip OG image generation during build phase to avoid fetch errors
  if (process.env.NEXT_PHASE === "phase-production-build") {
    return new Response("OG image skipped during build", { status: 200 });
  }

  try {
    const page = source.getPage(params.slug.slice(0, -1));
    if (!page) notFound();

    const interFont = await getInter();
    const interSemiboldFont = await getInterSemibold();

    // Define fonts array without type errors by dropping strong typing
    const fontOptions = [];

    if (interFont) {
      fontOptions.push({
        name: "Inter",
        weight: 500,
        data: interFont,
        style: "normal",
      });
    }

    if (interSemiboldFont) {
      fontOptions.push({
        name: "Inter",
        weight: 700,
        data: interSemiboldFont,
        style: "normal",
      });
    }

    return new ImageResponse(
      (
        <section
          style={{
            backgroundColor: "#000000",
            background: "#FAEEDC",
            backgroundImage:
              "url('https://docs.copilotkit.ai/images/opengraph-background.png')",
            backgroundSize: "cover",
            backgroundPosition: "0% 0%",
            width: "100%",
            height: "100%",
            padding: "5%",
            display: "block",
            position: "relative",
            fontFamily: "Satori",
          }}
        >
          <section style={{ display: "flex", flexDirection: "column" }}>
            <div style={{ display: "flex" }}>
              <img
                style={{
                  width: "14rem",
                }}
                src="https://github-production-user-asset-6210df.s3.amazonaws.com/746397/288400836-bd5c9079-929b-4d55-bdc9-16d1c8181b71.png"
              />
            </div>

            <section
              style={{
                flexGrow: 1,
                display: "flex",
                flexDirection: "column",
                justifyContent: "flex-end",
              }}
            >
              {page.data.title && (
                <p
                  style={{
                    color: "#4f46e5",
                    fontFamily: fontOptions.length ? "Inter" : "sans-serif",
                    fontWeight: 700,
                    margin: 0,
                    fontSize: 48,
                  }}
                >
                  {page.data.title}
                </p>
              )}
              {(page.data as any).description && (
                <p
                  style={{
                    color: "#000000",
                    fontSize: 34,
                    marginBottom: 12,
                    fontWeight: 500,
                    fontFamily: fontOptions.length ? "Inter" : "sans-serif",
                  }}
                >
                  {(page.data as any).description}
                </p>
              )}
            </section>
          </section>
        </section>
      ),
      {
        // width: width,
        // height: height,
        fonts: fontOptions.length ? (fontOptions as any) : undefined,
      }
    );
  } catch (error) {
    console.error("Error generating OG image:", error);
    // Return a simple fallback image
    return new Response("OG image generation failed - using fallback", {
      status: 307,
      headers: {
        Location: "/images/og-fallback.png",
      },
    });
  }
}

export function generateStaticParams() {
  return source.generateParams().map((params) => ({
    ...params,
    slug: [...params.slug, "og.png"],
  }));
}



================================================
FILE: docs/components/layout/banners.tsx
================================================
import { Banner } from "fumadocs-ui/components/banner";
import Link from "next/link";
import { PaintbrushIcon } from "lucide-react";
import { PiGraph } from "react-icons/pi";
import { SiCrewai } from "@icons-pack/react-simple-icons";

export function Banners() {
  return (
    <>
      <AGUIBanner />
    </>
  )
}

export function NewLookAndFeelBanner() {
  return (
    <Banner className="w-full text-white gap-2 bg-indigo-500 dark:bg-indigo-900 h-2!" variant="rainbow" id="new-look-and-feel-banner">
      <PaintbrushIcon className="w-5 h-5" />
      <p>
        We are launching a new default look and feel!
        Checkout the <span className="underline"><Link href="/troubleshooting/migrate-to-1.8.2"> migration guide </Link></span> to learn more.
      </p>
    </Banner>
  )
}

export function CoagentsCrewAnnouncementBanner() {
  return (
    <Banner className="w-full text-white gap-2 bg-indigo-500 dark:bg-indigo-900" variant="rainbow" id="coagents-crew-announcement-banner">
      <SiCrewai className="w-5 h-5 inline mb-1" /> CrewAI support is here! Checkout the <Link href="/crewai-crews" className="underline">Crew</Link> and <Link href="/crewai-flows" className="underline">Flow</Link> documentation.
    </Banner>
  )
}

export function ModelContextProtocolBanner() {
  return (
    <Banner className="w-full text-white bg-indigo-500 dark:bg-indigo-900 h-24 sm:h-14 !important" variant="rainbow" id="model-context-protocol-banner">
      <p className="w-3/4">
        <PiGraph className="w-5 h-5 inline mr-2" /> Model Context Protocol (MCP) support is here! Try it out <Link href="/guides/model-context-protocol" className="underline">here</Link>. Register to our<Link href="https://go.copilotkit.ai/webinarMastra" target="_blank" className="underline ml-1">webinar</Link> for a walkthrough.
      </p>
    </Banner>
  )
}

export function AGUIBanner() {
  return (
    <Banner className="w-full text-white bg-indigo-500 dark:bg-indigo-900 h-24 sm:h-14 !important" variant="rainbow" id="agui-banner">
      <p className="w-3/4">
        We're officially launching AG-UI, the protocol for agent and user interactivity! <Link href="https://ag-ui.com" target="_blank" className="underline">Learn more</Link>.
      </p>
    </Banner>
  )
}


================================================
FILE: docs/components/layout/top-bar.tsx
================================================
"use client";
import { SearchIcon } from "lucide-react";
import { LinkToCopilotCloud } from "@/components/react/link-to-copilot-cloud";

export function TopBar() {
  return (
    <>
      <div className="p-2 h-[70px] hidden lg:block absolute w-[calc(100vw-var(--fd-sidebar-width)-20px)] ml-[var(--fd-sidebar-width)]">
          <div className="flex justify-end items-center gap-2">
            <LinkToCopilotCloud />
            <SearchToggle />
        </div>
      </div>
    </>
  );
}

export function SearchToggle() {
  const toggleSearch = () => {
    const isMac = navigator.platform.toUpperCase().indexOf("MAC") >= 0;
    document.dispatchEvent(
      new KeyboardEvent("keydown", {
        key: "k",
        metaKey: isMac,
        ctrlKey: !isMac,
        bubbles: true,
      })
    );
  };
  
  return (
    <div onClick={toggleSearch} className="cursor-pointer h-12 px-4 w-[240px] xl:w-[275px] inline-flex items-center gap-2 border bg-fd-secondary/50 p-1.5 text-sm text-fd-muted-foreground transition-colors hover:bg-fd-accent hover:text-fd-accent-foreground rounded-md max-md:hidden">
      <SearchIcon className="w-4 h-4 text-foreground" />
      Search docs
      <div className="ms-auto inline-flex gap-0.5">
        <kbd className="rounded-md border bg-fd-background px-1.5">⌘</kbd>
        <kbd className="rounded-md border bg-fd-background px-1.5">K</kbd>
      </div>
    </div>
  );
}



================================================
FILE: docs/components/markdown/test-markdown-component.mdx
================================================
```ts
const this = "is a test markdown component";
```


================================================
FILE: docs/components/react/copilotkit-css.tsx
================================================
"use client";

import React from "react";
import { Frame } from "./frame";

export function CopilotKitCSS() {
  return (
    <style suppressHydrationWarning>
      {`
/* src/css/colors.css */
html {
  --copilot-kit-primary-color: rgb(28, 28, 28);
  --copilot-kit-contrast-color: rgb(255, 255, 255);
  --copilot-kit-background-color: rgb(255 255 255);
  --copilot-kit-secondary-color: rgb(255 255 255);
  --copilot-kit-secondary-contrast-color: rgb(28, 28, 28);
  --copilot-kit-separator-color: rgb(200 200 200);
  --copilot-kit-muted-color: rgb(200 200 200);
  --copilot-kit-shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
  --copilot-kit-shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
  --copilot-kit-shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
}

/* src/css/popup.css */
.copilotKitPopup {
  position: fixed;
  bottom: 1rem;
  right: 1rem;
  z-index: 30;
  line-height: 1.5;
  -webkit-text-size-adjust: 100%;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
  font-family: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
    "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  font-feature-settings: normal;
  font-variation-settings: normal;
  touch-action: manipulation;
}
.copilotKitPopup svg {
  display: inline-block;
  vertical-align: middle;
}

/* src/css/sidebar.css */
.copilotKitSidebar {
  position: fixed;
  bottom: 1rem;
  right: 1rem;
  z-index: 30;
  line-height: 1.5;
  -webkit-text-size-adjust: 100%;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
  font-family: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
    "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  font-feature-settings: normal;
  font-variation-settings: normal;
  touch-action: manipulation;
}
.copilotKitSidebar svg {
  display: inline-block;
  vertical-align: middle;
}
.copilotKitSidebarContentWrapper {
  overflow: visible;
  margin-right: 0px;
  transition: margin-right 0.3s ease;
}
@media (min-width: 640px) {
  .copilotKitSidebarContentWrapper.sidebarExpanded {
    margin-right: 28rem;
  }
}

/* src/css/button.css */
.copilotKitButton {
  width: 3.5rem;
  height: 3.5rem;
  display: flex;
  align-items: center;
  justify-content: center;
  border-radius: 50%;
  border: 1px solid var(--copilot-kit-primary-color);
  outline: none;
  position: relative;
  transform: scale(1);
  transition: all 0.2s ease;
  background-color: var(--copilot-kit-primary-color);
  color: var(--copilot-kit-contrast-color);
  cursor: pointer;
  box-shadow: var(--copilot-kit-shadow-sm);
}
.copilotKitButton:hover {
  transform: scale(1.05);
  box-shadow: var(--copilot-kit-shadow-md);
}
.copilotKitButton:active {
  transform: scale(0.95);
  box-shadow: var(--copilot-kit-shadow-sm);
}
.copilotKitButtonIcon {
  transition: opacity 100ms, transform 300ms;
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  display: flex;
  align-items: center;
  justify-content: center;
}
.copilotKitButtonIcon svg {
  width: 1.5rem;
  height: 1.5rem;
}
.copilotKitButton.open .copilotKitButtonIconOpen {
  transform: translate(-50%, -50%) scale(0) rotate(90deg);
  opacity: 0;
}
.copilotKitButton.open .copilotKitButtonIconClose {
  transform: translate(-50%, -50%) scale(1) rotate(0deg);
  opacity: 1;
}
.copilotKitButton:not(.open) .copilotKitButtonIconOpen {
  transform: translate(-50%, -50%) scale(1) rotate(0deg);
  opacity: 1;
}
.copilotKitButton:not(.open) .copilotKitButtonIconClose {
  transform: translate(-50%, -50%) scale(0) rotate(-90deg);
  opacity: 0;
}

/* src/css/header.css */
.copilotKitHeader {
  height: 56px;
  font-weight: 500;
  display: flex;
  align-items: center;
  position: relative;
  color: var(--copilot-kit-primary-color);
  border-top-left-radius: 0;
  border-top-right-radius: 0;
  border-bottom: 1px solid var(--copilot-kit-separator-color);
  padding-left: 1.5rem;
  background-color: var(--copilot-kit-contrast-color);
  justify-content: space-between;
  z-index: 2;
}
.copilotKitSidebar .copilotKitHeader {
  border-radius: 0;
}
.copilotKitHeaderControls {
  display: flex;
}
@media (min-width: 640px) {
  .copilotKitHeader {
    padding-left: 1.5rem;
    padding-right: 24px;
    border-top-left-radius: 8px;
    border-top-right-radius: 8px;
  }
}
.copilotKitHeader > button {
  border: 0;
  padding: 8px;
  position: absolute;
  top: 50%;
  right: 16px;
  transform: translateY(-50%);
  outline: none;
  color: var(--copilot-kit-muted-color);
  background-color: transparent;
  cursor: pointer;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: background-color 0.2s ease;
  width: 35px;
  height: 35px;
}
.copilotKitHeader > button:hover {
  color: color-mix(in srgb, var(--copilot-kit-muted-color) 80%, black);
}
.copilotKitHeader > button:focus {
  outline: none;
}

/* src/css/input.css */
.copilotKitInput {
  display: flex;
  flex-direction: column;
  cursor: text;
  position: relative;
  background-color: var(--copilot-kit-background-color);
  border-radius: 20px;
  border: 1px solid var(--copilot-kit-separator-color);
  padding: 12px 14px;
  height: 75px;
  margin: 0 auto;
  width: 95%;
}
.copilotKitInputContainer {
  width: 100%;
  padding: 0;
  background: var(--copilot-kit-background-color);
  border-bottom-left-radius: 0.75rem;
  border-bottom-right-radius: 0.75rem;
}
.copilotKitInputControlButton {
  padding: 0;
  cursor: pointer;
  transition-property: transform;
  transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);
  transition-duration: 200ms;
  transform: scale(1);
  color: rgba(0, 0, 0, 0.25);
  -webkit-appearance: button;
  appearance: button;
  background-color: transparent;
  background-image: none;
  text-transform: none;
  font-family: inherit;
  font-size: 100%;
  font-weight: inherit;
  line-height: inherit;
  border: 0;
  margin: 0;
  text-indent: 0px;
  text-shadow: none;
  display: inline-block;
  text-align: center;
  width: 24px;
  height: 24px;
}
.copilotKitInputControlButton:not([disabled]) {
  color: var(--copilot-kit-primary-color);
}
.copilotKitInputControlButton:not([disabled]):hover {
  color: color-mix(in srgb, var(--copilot-kit-primary-color) 80%, black);
  transform: scale(1.05);
}
.copilotKitInputControlButton[disabled] {
  color: var(--copilot-kit-muted-color);
  cursor: default;
}
.copilotKitInputControls {
  display: flex;
  gap: 3px;
}
.copilotKitInput > input {
  flex: 1;
  outline: 2px solid transparent;
  outline-offset: 2px;
  resize: none;
  white-space: pre-wrap;
  overflow-wrap: break-word;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  cursor: text;
  font-size: 0.875rem;
  line-height: 1.5rem;
  margin: 0;
  padding: 0;
  font-family: inherit;
  font-weight: inherit;
  color: var(--copilot-kit-secondary-contrast-color);
  border: 0px;
  background-color: var(--copilot-kit-background-color);
}
.copilotKitInput > textarea::placeholder {
  color: var(--copilot-kit-muted-color);
  opacity: 1;
}
.copilotKitInputControlButton.copilotKitPushToTalkRecording {
  background-color: #ec0000;
  color: white;
  border-radius: 50%;
  animation: copilotKitPulseAnimation 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

/* src/css/messages.css */
.copilotKitMessages {
  overflow-y: scroll;
  flex: 1;
  display: flex;
  flex-direction: column;
  background-color: var(--copilot-kit-background-color);
  justify-content: space-between;
  z-index: 1;
}
.copilotKitMessagesContainer {
  padding: 1rem 24px;
  display: flex;
  flex-direction: column;
}
.copilotKitMessagesFooter {
  display: flex;
  padding: 0;
  margin: 0 auto 8px auto;
  justify-content: flex-start;
  flex-direction: column;
  width: 90%;
}
.copilotKitMessages::-webkit-scrollbar {
  width: 6px;
}
.copilotKitMessages::-webkit-scrollbar-thumb {
  background-color: var(--copilot-kit-separator-color);
  border-radius: 10rem;
  border: 2px solid var(--copilot-kit-background-color);
}
.copilotKitMessages::-webkit-scrollbar-track-piece:start {
  background: transparent;
}
.copilotKitMessages::-webkit-scrollbar-track-piece:end {
  background: transparent;
}
.copilotKitMessage {
  border-radius: 15px;
  padding: 8px 12px;
  font-size: 1rem;
  line-height: 1.5;
  overflow-wrap: break-word;
  max-width: 80%;
  margin-bottom: 0.5rem;
  color: var(--copilot-kit-secondary-contrast-color);
}
.copilotKitMessage.copilotKitUserMessage {
  background: var(--copilot-kit-primary-color);
  color: var(--copilot-kit-contrast-color);
  margin-left: auto;
  white-space: pre-wrap;
  line-height: 1.75;
  font-size: 1rem;
}
.copilotKitMessage.copilotKitAssistantMessage {
  background: transparent;
  margin-right: auto;
  padding-left: 0;
  position: relative;
  max-width: 100%;
}
.copilotKitMessage.copilotKitAssistantMessage + .copilotKitMessage.copilotKitUserMessage {
  margin-top: 1.5rem;
}
.copilotKitCustomAssistantMessage {
  margin-top: 1.5rem;
  margin-bottom: 1.5rem;
}
.copilotKitMessage .inProgressLabel {
  margin-left: 10px;
  opacity: 0.7;
}

/* src/css/suggestions.css */
.copilotKitMessages footer .suggestions {
  display: flex;
  flex-wrap: wrap;
  gap: 6px;
}
.copilotKitMessages footer h6 {
  font-weight: 500;
  font-size: 0.7rem;
  margin-bottom: 8px;
}
.copilotKitMessages footer .suggestions .suggestion {
  padding: 6px 10px;
  font-size: 0.7rem;
  border-radius: 15px;
  border: 1px solid var(--copilot-kit-muted-color);
  color: var(--copilot-kit-secondary-contrast-color);
  box-shadow: 0 5px 5px 0px rgba(0,0,0,.01),0 2px 3px 0px rgba(0,0,0,.02);
}
.copilotKitMessages footer .suggestions .suggestion.loading {
  padding: 0;
  font-size: 0.7rem;
  border: none;
  color: var(--copilot-kit-secondary-contrast-color);
}
.copilotKitMessages footer .suggestions button {
  transition: transform 0.3s ease;
}
.copilotKitMessages footer .suggestions button:not(:disabled):hover {
  transform: scale(1.03);
}
.copilotKitMessages footer .suggestions button:disabled {
  cursor: wait;
}
.copilotKitMessages footer .suggestions button svg {
  margin-right: 6px;
}

/* src/css/markdown.css */
.copilotKitMarkdown h1,
.copilotKitMarkdown h2,
.copilotKitMarkdown h3,
.copilotKitMarkdown h4,
.copilotKitMarkdown h5,
.copilotKitMarkdown h6 {
  font-weight: bold;
  line-height: 1.2;
}
.copilotKitMarkdown h1:not(:last-child),
.copilotKitMarkdown h2:not(:last-child),
.copilotKitMarkdown h3:not(:last-child),
.copilotKitMarkdown h4:not(:last-child),
.copilotKitMarkdown h5:not(:last-child),
.copilotKitMarkdown h6:not(:last-child) {
  margin-bottom: 1rem;
}
.copilotKitMarkdown h1 {
  font-size: 1.5em;
}
.copilotKitMarkdown h2 {
  font-size: 1.25em;
  font-weight: 600;
}
.copilotKitMarkdown h3 {
  font-size: 1.1em;
}
.copilotKitMarkdown h4 {
  font-size: 1em;
}
.copilotKitMarkdown h5 {
  font-size: 0.9em;
}
.copilotKitMarkdown h6 {
  font-size: 0.8em;
}
.copilotKitMarkdown p:not(:last-child) {
  margin-bottom: 1.25em;
}
.copilotKitMarkdown pre:not(:last-child) {
  margin-bottom: 1.25em;
}
.copilotKitMarkdown blockquote {
  border-color: rgb(142, 142, 160);
  border-left-width: 2px;
  border-left-style: solid;
  line-height: 1.2;
  padding-left: 10px;
}
.copilotKitMarkdown blockquote p {
  padding: 0.7em 0;
}
.copilotKitMarkdown ul {
  list-style-type: disc;
  padding-left: 20px;
  overflow: visible;
}
.copilotKitMarkdown li {
  list-style-type: inherit;
  list-style-position: outside;
  margin-left: 0;
  padding-left: 0;
  position: relative;
  overflow: visible;
}
.copilotKitCodeBlock {
  position: relative;
  width: 100%;
  background-color: rgb(9 9 11);
  border-radius: 0.375rem;
}
.copilotKitCodeBlockToolbar {
  display: flex;
  width: 100%;
  align-items: center;
  justify-content: space-between;
  background-color: rgb(39 39 42);
  padding-left: 1rem;
  padding-top: 0.09rem;
  padding-bottom: 0.09rem;
  color: rgb(228, 228, 228);
  border-top-left-radius: 0.375rem;
  border-top-right-radius: 0.375rem;
  font-family: sans-serif;
}
.copilotKitCodeBlockToolbarLanguage {
  font-size: 0.75rem;
  line-height: 1rem;
  text-transform: lowercase;
}
.copilotKitCodeBlockToolbarButtons {
  display: flex;
  align-items: center;
  margin-right: 0.25rem;
  margin-left: 0.25rem;
}
.copilotKitCodeBlockToolbarButton {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  border-radius: 0.375rem;
  font-size: 0.875rem;
  line-height: 1.25rem;
  font-weight: 500;
  height: 2.5rem;
  width: 2.5rem;
  padding: 3px;
  margin: 2px;
}
.copilotKitCodeBlockToolbarButton:hover {
  background-color: rgb(55, 55, 58);
}

/* src/css/window.css */
.copilotKitWindow {
  position: fixed;
  inset: 0px;
  transform-origin: bottom;
  border-color: rgb(229 231 235);
  background-color: rgb(255 255 255);
  border-radius: 0.75rem;
  box-shadow: rgba(0, 0, 0, 0.16) 0px 5px 40px;
  flex-direction: column;
  transition: opacity 100ms ease-out, transform 200ms ease-out;
  opacity: 0;
  transform: scale(0.95) translateY(20px);
  display: flex;
  pointer-events: none;
}
.copilotKitSidebar .copilotKitWindow {
  border-radius: 0;
  opacity: 1;
  transform: translateX(100%);
}
.copilotKitWindow.open {
  opacity: 1;
  transform: scale(1) translateY(0);
  pointer-events: auto;
}
.copilotKitSidebar .copilotKitWindow.open {
  transform: translateX(0);
}
@media (min-width: 640px) {
  .copilotKitWindow {
    transform-origin: bottom right;
    bottom: 5rem;
    right: 1rem;
    top: auto;
    left: auto;
    border-width: 0px;
    margin-bottom: 1rem;
    width: 24rem;
    height: 600px;
    min-height: 200px;
    max-height: calc(100% - 6rem);
  }
  .copilotKitSidebar .copilotKitWindow {
    bottom: 0;
    right: 0;
    top: auto;
    left: auto;
    width: 28rem;
    min-height: 100%;
    margin-bottom: 0;
    max-height: none;
  }
}

/* src/css/animations.css */
.copilotKitActivityDot1 {
  animation: copilotKitActivityDotsAnimation 1.05s infinite;
}
.copilotKitActivityDot2 {
  animation-delay: 0.1s;
}
.copilotKitActivityDot3 {
  animation-delay: 0.2s;
}
@keyframes copilotKitActivityDotsAnimation {
  0%,
  57.14% {
    animation-timing-function: cubic-bezier(0.33, 0.66, 0.66, 1);
    transform: translate(0);
  }
  28.57% {
    animation-timing-function: cubic-bezier(0.33, 0, 0.66, 0.33);
    transform: translateY(-6px);
  }
  100% {
    transform: translate(0);
  }
}
@keyframes copilotKitSpinAnimation {
  to {
    transform: rotate(360deg);
  }
}
@keyframes copilotKitPulseAnimation {
  50% {
    opacity: 0.5;
  }
}

/* src/css/panel.css */
.copilotKitChat {
  z-index: 30;
  line-height: 1.5;
  -webkit-text-size-adjust: 100%;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
  background: var(--copilot-kit-background-color);
  font-family: ui-sans-serif, system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
    "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  font-feature-settings: normal;
  font-variation-settings: normal;
  touch-action: manipulation;
  display: flex;
  flex-direction: column;
}
.copilotKitChat svg {
  display: inline-block;
  vertical-align: middle;
}
.copilotKitChat .copilotKitMessages {
  flex-grow: 1;
}
.tooltip {
  display: none;
  position: absolute;
  background-color: var(--copilot-kit-background-color);
  border: 1px solid var(--copilot-kit-separator-color);
  color: var(--copilot-kit-secondary-contrast-color);
  padding: 15px;
  border-radius: 5px;
  z-index: 1000;
  font-size: 13px;
  width: 350px;
  box-shadow: var(--copilot-kit-shadow-md);
}
.tooltip b {
  color: var(--copilot-kit-primary-color);
  font-family: monospace;
}

.copilotKitInput {
  cursor: pointer;
}

.copilotKitInput input {
  flex: 1;
  outline: 2px solid transparent;
  outline-offset: 2px;
  resize: none;
  white-space: pre-wrap;
  overflow-wrap: break-word;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  cursor: pointer;
  font-size: 0.875rem;
  line-height: 1.25rem;
  margin: 0;
  padding: 0;
  font-family: inherit;
  font-weight: inherit;
  color: var(--copilot-kit-secondary-contrast-color);
  border: 0px;
  background-color: var(--copilot-kit-background-color);
}

.micButton:hover {
  border-radius: 5px;
}

.sendButton:hover {
  border-radius: 5px;
}

.poweredBy {
  visibility: visible !important;
  display: block !important;
  position: static !important;
  text-align: center !important;
  font-size: 12px !important;
  padding: 3px 0 !important;
  color: rgb(214, 214, 214) !important;
  margin: 0 !important;
}

.dark,
html.dark,
body.dark,
[data-theme="dark"],
html[style*="color-scheme: dark"],
body[style*="color-scheme: dark"] .poweredBy {
  color: rgb(69, 69, 69) !important;
}
    `}
    </style>
  );
}

export const handleMouseMove = (e: any) => {
  const tooltip: any = document.querySelector(".tooltip");
  tooltip.style.display = "block";
  const rect = tooltip.parentElement.getBoundingClientRect();
  tooltip.style.left = `${e.clientX - rect.left + 15}px`;
  tooltip.style.top = `${e.clientY - rect.top + 15}px`;

  let element = e.target;

  while (element && element !== document.body) {
    if (element.classList.contains("copilotKitHeader")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-contrast-color</b>: Header background color.<br/><br/><b>--copilot-kit-primary-color</b>: Header text color.";
      return;
    } else if (element.classList.contains("copilotKitAssistantMessage")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-secondary-contrast-color</b>: Assistant message text color.<br/><br/><b>--copilot-kit-primary-color</b>: Assistant message action buttons color.";
      return;
    } else if (element.classList.contains("copilotKitUserMessage")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-primary-color</b>: User message background color.<br/><br/><b>--copilot-kit-contrast-color</b>: User message text color.";
      return;
    } else if (element.classList.contains("copilotKitMessages")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-background-color</b>: Chat window background color.<br/><br/><b>--copilot-kit-separator-color</b>: Chat window scrollbar color.";
      return;
    } else if (element.classList.contains("sendButton")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-primary-color</b>: Active button color";
      return;
    } else if (element.classList.contains("micButton")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-muted-color</b>: Muted button color";
      return;
    } else if (element.classList.contains("copilotKitInput")) {
      tooltip.innerHTML =
        "<b>--copilot-kit-separator-color</b>: Input box border color.<br/><br/><b>--copilot-kit-muted-color</b>: Placeholder color.";
      return;
    } else if (element.classList.contains("poweredBy")) {
      tooltip.innerHTML =
          `The "Powered by CopilotKit" watermark is removed automatically for Copilot Cloud users`;
      return;
    }
    element = element.parentElement;
  }

  tooltip.style.display = "none";
};

export const handleMouseLeave = (e: any) => {
  const tooltip: any = document.querySelector(".tooltip");
  tooltip.style.display = "none";
};

export const InteractiveCSSInspector = () => {
  return (
    <>
      <div className="tooltip">Close CopilotKit</div>
      <Frame className="">
        <div
          className=""
          onMouseMove={handleMouseMove}
          onMouseLeave={handleMouseLeave}
          style={{
            width: "384px",
            cursor: "pointer",
          }}
        >
          <div className="open">
            <div className="copilotKitHeader">
              <div>CopilotKit</div>
              <button aria-label="Close">
                <svg
                  xmlns="http://www.w3.org/2000/svg"
                  fill="none"
                  viewBox="0 0 24 24"
                  strokeWidth="1.5"
                  stroke="currentColor"
                  width={24}
                  height={24}
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    d="M6 18L18 6M6 6l12 12"
                  />
                </svg>
              </button>
            </div>
            <div className="copilotKitMessages">
              <div className="copilotKitMessagesContainer">
                <div className="copilotKitMessage copilotKitAssistantMessage">
                  Hi you! 👋 I can help you create a presentation on any topic.
                </div>
                <div className="copilotKitMessage copilotKitUserMessage">
                  Hello CopilotKit!
                </div>
              </div>
            </div>
            <div className="copilotKitInputContainer">
              <div className="copilotKitInput">
                <input
                    placeholder="Type a message..."
                    // style={{
                    //   overflow: "auto",
                    //   resize: "none",
                    //   maxHeight: 100,
                    //   height: 20,
                    // }}
                    defaultValue={""}
                    disabled={false}
                />
                <div className="copilotKitInputControls">
                  <div style={{ flexGrow: 1 }} />
                  <button className="micButton copilotKitInputControlButton" disabled>
                    <svg
                        xmlns="http://www.w3.org/2000/svg"
                        fill="none"
                        viewBox="0 0 24 24"
                        strokeWidth="1.5"
                        stroke="currentColor"
                        className="w-6 h-6"
                    >
                      <path
                          strokeLinecap="round"
                          strokeLinejoin="round"
                          d="M12 18.75a6 6 0 0 0 6-6v-1.5m-6 7.5a6 6 0 0 1-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 15.75a3 3 0 0 1-3-3V4.5a3 3 0 1 1 6 0v8.25a3 3 0 0 1-3 3Z"
                      />
                    </svg>
                  </button>
                  <button className="sendButton copilotKitInputControlButton" disabled={false}>
                    <svg
                        xmlns="http://www.w3.org/2000/svg"
                        fill="none"
                        viewBox="0 0 24 24"
                        strokeWidth="1.5"
                        stroke="currentColor"
                        width="24"
                        height="24"
                    >
                      <path strokeLinecap="round" strokeLinejoin="round" d="M12 19V5m0 0l-7 7m7-7l7 7" />
                    </svg>
                  </button>
                </div>
              </div>
              <p className="poweredBy">
                Powered by CopilotKit
              </p>
            </div>
          </div>
        </div>
      </Frame>
    </>
  );
};



================================================
FILE: docs/components/react/cta-cards.tsx
================================================
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import Link from "next/link";
import { IconType } from "react-icons";

interface CTACardProps {
  icon: IconType;
  title: string;
  description: string;
  href: string;
  iconBgColor?: string;
}

interface CTACardsProps {
  cards: CTACardProps[];
  columns?: 1 | 2 | 3 | 4;
}

export function CTACard({ icon: Icon, title, description, href, iconBgColor = "bg-indigo-500" }: CTACardProps) {
  return (
    <Link href={href} className="no-underline">
      <Card className="transition-transform hover:scale-105 cursor-pointer shadow-xl shadow-indigo-500/20 h-full">
        <CardHeader>
          <div className="flex items-center gap-3">
            <div className={`flex items-center justify-center ${iconBgColor} rounded-full w-10 h-10`}>
              <Icon className="h-6 w-6 text-white"/>
            </div>
            <CardTitle className="text-md">{title}</CardTitle>
          </div>
          <CardDescription className="text-md pt-4">{description}</CardDescription>
        </CardHeader>
      </Card>
    </Link>
  );
}

export function CTACards({ cards, columns = 3 }: CTACardsProps) {
  const lastItemClass = cards.length % columns !== 0 ? `xl:col-span-${columns - (cards.length % columns) + 1}` : '';

  return (
    <div className={`grid grid-cols-1 gap-y-8 gap-x-10 xl:grid-cols-${columns} py-6`}>
      {cards.map((card, index) => (
        <div
          key={index}
          className={index === cards.length - 1 ? lastItemClass : ''}
        >
          <CTACard {...card} />
        </div>
      ))}
    </div>
  );
}


================================================
FILE: docs/components/react/dynamic-content-wrapper.tsx
================================================
"use client"
import React from "react";
import { TailoredContentProvider } from "@/lib/hooks/use-tailored-content";

export function DynamicContentWrapper({ children }: { children: React.ReactNode }) {
  return (
    <TailoredContentProvider>
      {children}
    </TailoredContentProvider>
  );
}


================================================
FILE: docs/components/react/examples-carousel.tsx
================================================
"use client"

import { Card, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";
import { Frame } from "@/components/react/frame";
import { LuBookOpen, LuBanknote, LuPlane, LuFileSpreadsheet, LuCode, LuExternalLink, LuLightbulb } from "react-icons/lu";
import { badgeVariants } from "@/components/ui/badge";
import Link from "next/link";
import { cn } from "@/lib/utils";
import { Tabs, Tab } from "@/components/react/tabs";
import { YouTubeVideo } from "./youtube-video";

interface CarouselExample {
  icon: React.ElementType;
  title: string;
  description: string;
  media: {
    type: 'video' | 'image' | 'youtube';
    src: string;
  };
  links: {
    source?: string;
    demo?: string;
    tutorial?: string;
  };
}

interface ExamplesCarouselProps {
  id: string
  examples?: CarouselExample[];
}

const badgeStyles = cn(badgeVariants({ variant: "outline" }), "bg-indigo-500 hover:bg-indigo-600 text-white no-underline focus:ring-1 focus:ring-indigo-500");

export function ExamplesCarousel({ id, examples = LandingExamples }: ExamplesCarouselProps) {
  return (
    <Tabs groupId={id} items={
      examples.map((example) => {
        const Icon = example.icon;
        return {
          value: example.title,
          icon: <Icon className="w-4 h-4" />
        }
      })
    }>
      {examples.map((example, index) => {
        const Icon = example.icon;
        return (
          <Tab key={index} value={example.title}>
            <Card className="border-none shadow-none">
              <CardHeader>
                <CardTitle className="flex items-center text-xl">
                  <Icon className="mr-2" />
                  {example.title}
                </CardTitle>
                <div className="flex flex-wrap gap-2 my-2 pt-2">
                  {example.links.source && (
                    <Link 
                      href={example.links.source}
                      target="_blank"
                      rel="noopener noreferrer"
                      className={badgeStyles}
                    >
                      <LuCode className="mr-2 h-3.5 w-3.5" />
                      Source
                    </Link>
                  )}
                  {example.links.demo && (
                    <Link 
                      href={example.links.demo}
                      target="_blank"
                      rel="noopener noreferrer"
                      className={badgeStyles}
                    >
                      <LuExternalLink className="mr-2 h-3.5 w-3.5" />
                      Demo
                    </Link>
                  )}
                  {example.links.tutorial && (
                    <Link 
                      href={example.links.tutorial}
                      target="_blank"
                      rel="noopener noreferrer"
                      className={badgeStyles}
                    >
                      <LuBookOpen className="mr-2 h-3.5 w-3.5" />
                      Tutorial
                    </Link>
                  )}
                </div>
                <CardDescription className="text-base pt-6 text-primary">
                  {example.description}
                </CardDescription>
                <div className="w-full">
                  {example.media.type === 'video' && (
                    <video 
                      autoPlay 
                      loop 
                      muted 
                      controls 
                      playsInline
                      src={example.media.src}
                      className="rounded-2xl shadow-xl border w-full h-auto"
                    />
                  )}
                  {example.media.type === 'image' && (
                    <Frame className="rounded-2xl shadow-xl">
                      <img src={example.media.src} className="w-full h-auto" />
                    </Frame>
                  )}
                  {example.media.type === 'youtube' && (
                    <div className="flex justify-center mt-6">
                      <YouTubeVideo videoId={example.media.src} />
                    </div>
                  )}
                </div>
              </CardHeader>
            </Card>
          </Tab>
        );
      })}
    </Tabs>
  );
}

export const LandingExamples: CarouselExample[] = [
  {
    icon: LuFileSpreadsheet,
    title: "Spreadsheet Copilot",
    description: "A powerful spreadsheet assistant that helps users analyze data, create formulas, and generate insights through natural language interaction.",
    media: {
      type: "video",
      src: "/images/examples/spreadsheets.mp4"
    },
    links: {
      source: "https://github.com/CopilotKit/demo-spreadsheet",
      demo: "https://spreadsheet-demo-tau.vercel.app/",
    }
  },
  {
    icon: LuBanknote,
    title: "Banking Assistant (SaaS Copilot)",
    description: "An AI-powered banking interface that helps users manage transactions, analyze spending patterns, and get personalized financial advice.",
    media: {
      type: "video",
      src: "/images/examples/banking.mp4"
    },
    links: {
      source: "https://github.com/CopilotKit/demo-banking",
      demo: "https://brex-demo-temp.vercel.app/",
    }
  },
  {
    icon: LuPlane,
    title: "Agent-Native Travel Planner (ANA)",
    description: "Interactive travel planning assistant that helps users discover destinations, create itineraries, and manage trip details with natural language.",
    media: {
      type: "video",
      src: "/images/coagents/tutorials/ai-travel-app/demo.mp4"
    },
    links: {
      source: "https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-travel?ref=travel-tutorial",
      demo: "https://examples-coagents-ai-travel-app.vercel.app/",
      tutorial: "/coagents/tutorials/ai-travel-app"
    }
  },
  {
    icon: LuBookOpen,
    title: "Agent-Native Research Canvas (ANA)",
    description: "An intelligent research assistant that helps users analyze academic papers, synthesize information across multiple sources, and generate comprehensive research summaries.",
    media: {
      type: "video",
      src: "/images/examples/research.mp4"
    },
    links: {
      source: "https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-research-canvas/readme.md",
      demo: "https://examples-coagents-research-canvas-ui.vercel.app/",
      tutorial: "/coagents/videos/research-canvas"
    }
  }
];

export const CoAgentsExamples: CarouselExample[] = [
  {
    icon: LuLightbulb,
    title: "Introduction",
    description: "Hear from the CEO of CopilotKit, Atai Barkai, and learn how CoAgents are paving the way for the next generation of AI-native apps.",
    media: {
      type: "youtube",
      src: "tVjVYJE-Nic"
    },
    links: {
      demo: "https://examples-coagents-research-canvas-ui.vercel.app/",
    }
  },
  {
    icon: LuPlane,
    title: "Agent-Native Travel Planner (ANA)",
    description: "Interactive travel planning assistant that helps users discover destinations, create itineraries, and manage trip details with natural language.",
    media: {
      type: "video",
      src: "/images/coagents/tutorials/ai-travel-app/demo.mp4"
    },
    links: {
      source: "https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-travel?ref=travel-tutorial",
      demo: "https://examples-coagents-ai-travel-app.vercel.app/",
      tutorial: "/coagents/tutorials/ai-travel-app"
    }
  },
  {
    icon: LuBookOpen,
    title: "Agent-Native Research Canvas (ANA)",
    description: "An intelligent research assistant that helps users analyze academic papers, synthesize information across multiple sources, and generate comprehensive research summaries.",
    media: {
      type: "video",
      src: "/images/examples/research.mp4"
    },
    links: {
      source: "https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-research-canvas/readme.md",
      demo: "https://examples-coagents-research-canvas-ui.vercel.app/",
      tutorial: "/coagents/videos/research-canvas"
    }
  }
]


================================================
FILE: docs/components/react/frame.tsx
================================================
import React from "react";

export function Frame({
  children,
  className,
  description,
}: {
  children: React.ReactNode;
  className?: string;
  description?: string;
}) {
  return (
    <>
      <div
        className={`flex space-x-4 w-full mx-auto justify-center ${className}`}
      >
        {React.Children.map(children, (child) =>
          React.isValidElement(child)
            ? React.cloneElement(child as React.ReactElement<any>, {
                className: `border border-foreground-muted rounded-md shadow-lg ${
                  child.props.className || ""
                }`,
              })
            : child
        )}
      </div>
      {description && <p className="text-sm text-neutral-500 text-center">{description}</p>}
    </>
  );
}



================================================
FILE: docs/components/react/image-and-code.tsx
================================================
import {Tabs, Tab} from "@/components/react/tabs"
import { Frame } from "@/components/react/frame"

export function ImageAndCode({ preview, children, id }: { preview: string | React.ReactNode; children: React.ReactNode, id: string }) {
    return (
        <Tabs groupId={id} items={["Preview", "Code"]}>
            <Tab value="Preview">
                {typeof preview === "string" ? 
                    <Frame>
                        <img className="rounded-lg w-full" src={preview} />
                    </Frame>
                    : 
                    preview
                }
            </Tab>
            <Tab value="Code">
                {children}
            </Tab>
        </Tabs>
    )
}


================================================
FILE: docs/components/react/insecure-password-protected.tsx
================================================
'use client';

import { useState } from 'react';
import { Button } from '@/components/ui/button';
import { Input } from '@/components/ui/input';
interface InsecurePasswordProtectedProps {
  password?: string;
  unauthenticatedComponent?: React.ReactNode;
  children: React.ReactNode;
}

const defaultUnauthenticatedComponent = (
  <div className="space-y-4 text-center">
    <h3 className="text-xl font-bold">This content is protected by a password.</h3>
    <div className="text-base mx-auto">
      <p>
        This content is for an upcoming release and not yet publicly available. If you’d like to apply for early access, please
        <a target="_blank" rel="noreferrer" href="https://go.copilotkit.ai/earlyaccess" className="ml-1 underline">click here.</a>
      </p>
      <p>If you’re already apart of the early adopter group, please enter your password!</p>
    </div>
  </div>
)

/**
 * This component is used to "protect" content that is not intended for public consumption yet, i.e. early access content.
 * 
 * For the moment this is completely insecure, as it relies on a single shared password for all users that is publicly
 * viewable. Additionally, the password can be easily bypassed.
 * 
 * However, this is fine for us as the content is not a secret or sensitive. We just want to prevent dissuade users from
 * using the content outside of the early adopter group, not completely prevent it.
 */
export function InsecurePasswordProtected({ 
  password = process.env.NEXT_PUBLIC_LGC_DOCS_PASSWORD, 
  unauthenticatedComponent = defaultUnauthenticatedComponent, 
  children 
}: InsecurePasswordProtectedProps) {
  const [input, setInput] = useState('');
  const [error, setError] = useState('');
  const [storedPassword, setStoredPassword] = useState(() => {
    // Initialize state from localStorage if available
    if (typeof window !== 'undefined') {
      return localStorage.getItem('storedPassword') || '';
    }
    return '';
  });

  if (!password) {
    return <>{children}</>;
  }

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (input === password) {
      setStoredPassword(input);
      setError('');
      localStorage.setItem('storedPassword', input);
    } else {
      setError('Incorrect password');
      setInput('');
    }
  };

  if (storedPassword === password) {
    return <>{children}</>;
  }

  return (
    <div className="w-full">
      <div className="hidden">
        If you're looking at this code, you'll probably notice that this is a very shallow layer of security. This 
        is very intentional, we don't want to make it impossible for users to access this content just 
        difficult until we're ready to make it readily available.
      </div>
      <div className="flex flex-col gap-6 p-8 border rounded-lg shadow-lg">
        {unauthenticatedComponent}
        <hr className="my-0" />
        <div className="flex gap-4">
          <Input
            type="password"
            autoComplete="off"
            className='w-full'
            placeholder="Enter password..."
            onKeyDown={(e) => {
              if (e.key === 'Enter') {
                handleSubmit(e);
              }
            }}
            value={input}
            onChange={(e) => {
              setInput(e.target.value);
              setError('');
            }}
            aria-invalid={!!error}
            aria-describedby={error ? "password-error" : undefined}
          />
          <Button onClick={handleSubmit}>Submit</Button>
        </div>
        {error && (
          <p id="password-error" className="text-sm text-red-500 mt-1">
            {error}
          </p>
        )}
      </div>
    </div>
  );
}



================================================
FILE: docs/components/react/link-to-copilot-cloud.tsx
================================================
"use client";

import { useEffect, useState } from "react";
import Link from "next/link";
import { useAuth } from "@clerk/nextjs";
import posthog from "posthog-js";
import { CloudIcon } from "lucide-react";

export function LinkToCopilotCloud({
  className,
  subPath,
  asButton = true,
  children
}: {
  className?: string;
  subPath?: string;
  asButton?: boolean;
  children?: React.ReactNode;
}) {
  const [isClient, setIsClient] = useState(false);
  const { userId } = useAuth();

  useEffect(() => {
    setIsClient(true);
  }, []);

  if (!isClient) {
    return null;
  }
  const url = new URL(`https://go.copilotkit.ai/copilot-cloud-button-docs`);
  url.searchParams.set("ref", "docs");

  const sessionId = posthog.get_session_id();

  if (sessionId) {
    url.searchParams.set("session_id", sessionId);
  }

  if (subPath) {
    url.pathname += subPath;
  }

  let cn = `${className}`;

  if (asButton) {
    cn = "text-indigo-800 dark:text-indigo-300 ring-1 ring-indigo-200 dark:ring-indigo-900 text-sm items-center bg-gradient-to-r from-indigo-200/50 to-purple-200/80 dark:from-indigo-900/40 dark:to-purple-900/50 flex p-3 px-4";
    cn += "transition-all duration-100 hover:ring-2 hover:ring-indigo-400 hover:dark:text-indigo-200 rounded-lg";
  } else {
    cn = "_text-primary-600 decoration-from-font underline [text-underline-position:from-font]";
  }

  return (
    <Link
      href={url.toString()}
      target="_blank"
      className={cn}
    >
      {asButton ? <CloudIcon className="w-5 h-5 mr-2" /> : null}
      {
        children ? children : userId ? "Go to Copilot Platform" : "Sign up for Copilot Platform"
      }
    </Link>
  );
}


================================================
FILE: docs/components/react/property-reference.tsx
================================================
"use client"

import React from "react";
import { IoSparklesSharp } from "react-icons/io5";
import { FaCaretRight, FaCaretDown } from "react-icons/fa";

type Props = {
  name: string;
  type: string;
  required?: boolean;
  deprecated?: boolean;
  children?: React.ReactNode;
  cloudOnly?: boolean;
  default?: string;
  collapsable?: boolean;
};

export function PropertyReference({
  children,
  name,
  type,
  required = false,
  deprecated = false,
  cloudOnly = false,
  default: defaultValue,
  collapsable = false,
}: Props) {
  const [isCollapsed, setIsCollapsed] = React.useState(
    collapsable ? true : false
  );

  const enhancedChildren = React.Children.map(children, (child) => {
    if (
      React.isValidElement(child) &&
      (child.type as any).name === "PropertyReference"
    ) {
      return React.cloneElement(child, { collapsable: true } as Props);
    }
    return child;
  });

  const collapseClassName = `${isCollapsed ? "hidden" : ""}`;

  const renderChips = () => {
    return (
      <>
        <span className="font-mono text-info-muted-foreground bg-info-muted py-1 px-2 rounded-md text-xs font-semibold">
          {type}
        </span>
        {required && (
          <span className="font-mono text-error-muted-foreground bg-error-muted py-1 px-2 rounded-md text-xs font-semibold">
            required
          </span>
        )}
        {deprecated && (
          <span className="font-mono text-warning-muted-foreground bg-warning-muted py-1 px-2 rounded-md text-xs font-semibold">
            deprecated
          </span>
        )}
      </>
    );
  };

  return (
    <div className="ck-property-reference py-4 space-y-3 text-sm">
      <div className="flex justify-betweem items-center">
        <div className="flex-1 space-x-3">
          {collapsable ? (
            <button
              onClick={() => setIsCollapsed(!isCollapsed)}
              className="flex gap-x-2 items-center font-mono font-semibold text-indigo-600"
            >
              {isCollapsed ? <FaCaretRight /> : <FaCaretDown />}
              {name}
              {renderChips()}
            </button>
          ) : (
            <span className="flex gap-x-2 items-center font-mono font-semibold text-indigo-600">
              {name}
              {renderChips()}
            </span>
          )}
        </div>

        <div>
          {cloudOnly && (
            <span className="flex space-x-1 items-center justify-center bg-indigo-500 text-white py-1 px-2 rounded-md text-xs font-semibold">
              <IoSparklesSharp className="w-3 h-3" />
              <span>COPILOT CLOUD</span>
            </span>
          )}
        </div>
      </div>
      <div className={`space-y-1 ${collapseClassName}`}>
        {defaultValue !== undefined && (
          <div>
            <span className="font-semibold">Default:</span>{" "}
            <span className="font-mono text-neutral-500">
              {typeof defaultValue === "string"
                ? `"${defaultValue}"`
                : `${defaultValue}`}
            </span>
          </div>
        )}
        <div>{enhancedChildren}</div>
      </div>
    </div>
  );
}



================================================
FILE: docs/components/react/select-llm-provider.tsx
================================================
"use client";

import { useState } from "react";
import { useLocalStorage } from "usehooks-ts";

export function SelectLLMProvider() {
  const [llmProvider, setLLMProvider] = useLocalStorage<string | null>("llmProvider", "openai");
  // const [llmProvider, setLLMProvider] = useState<string | null>("openai");

  return (
    <div className="flex gap-2">
      <button onClick={() => setLLMProvider("openai")} className={`${llmProvider === "openai" ? "bg-blue-500" : "bg-gray-200"}`}>OpenAI</button>
      <button onClick={() => setLLMProvider("anthropic")} className={`${llmProvider === "anthropic" ? "bg-blue-500" : "bg-gray-200"}`}>Anthropic</button>
    </div>
  )
}


================================================
FILE: docs/components/react/socials.tsx
================================================
import Link from "next/link";
import { FaDiscord, FaGithub, FaEdit } from "react-icons/fa";
import { FaXTwitter } from "react-icons/fa6";
import { Button } from "@/components/ui/button";
import { cn } from "@/lib/utils";

const socials = [
    {
        icon: FaDiscord,
        href: "https://discord.com/invite/6dffbvGU3D"
    },
    {
        icon: FaGithub,
        href: "https://github.com/CopilotKit/CopilotKit"
    },
    {
        icon: FaXTwitter,
        href: "https://x.com/copilotkit"
    }
]

export type SocialProps = {
    className?: string;
}

export function Socials({ className }: SocialProps) {
    return (
        <div className={cn("flex gap-1 justify-end", className)}>
            {socials.map((social, index) => (
                <Button 
                    key={index}
                    variant="ghost" 
                    size="icon" 
                    asChild 
                    className="h-10 w-10 text-indigo-500/80 hover:bg-indigo-500 hover:text-white"
                >
                    <Link href={social.href} target="_blank" rel="noopener noreferrer">
                        <social.icon className="w-4 h-4" />
                    </Link>
                </Button>
            ))}
        </div>
    )
}


================================================
FILE: docs/components/react/subdocs-menu.tsx
================================================
"use client";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import { cn } from "@/lib/utils";
import { useSidebar } from "fumadocs-ui/provider";
import Link from "next/link";
import { usePathname, useRouter } from "next/navigation";
import {
  type HTMLAttributes,
  type ReactNode,
  useCallback,
  useMemo,
  useRef,
} from "react";
import { PiGraph } from "react-icons/pi";

export function isActive(
  url: string,
  pathname: string,
  nested = true,
  root = false
): boolean {
  const isActive =
    url === pathname || (nested && pathname.startsWith(root ? url : `${url}/`));
  return isActive;
}

export interface Option {
  /**
   * Redirect URL of the folder, usually the index page
   */
  url: string;

  icon?: ReactNode;
  title: ReactNode;
  description?: ReactNode;
  bgGradient: string;
  selectedStyle?: string;
  props?: HTMLAttributes<HTMLElement>;
}

export interface OptionDropdown {
  title: ReactNode;
  options: Option[];
}

function isOptionDropdown(
  item: Option | OptionDropdown
): item is OptionDropdown {
  return "options" in item;
}

function isOption(item: Option | OptionDropdown): item is Option {
  return !isOptionDropdown(item);
}

export function SubdocsMenu({
  options,
  ...props
}: {
  options: (Option | OptionDropdown)[];
} & HTMLAttributes<HTMLButtonElement>): React.ReactElement {
  const { closeOnRedirect } = useSidebar();
  const pathname = usePathname();
  const selected: Option | undefined = useMemo(() => {
    // First, try all non-root options
    let nonRootOptions = options.filter(
      (item) => isOption(item) && item.url !== "/"
    );

    const dropDowns = options.filter((item) => isOptionDropdown(item));

    if (dropDowns.length > 0) {
      const dropDown = dropDowns[0];
      nonRootOptions = nonRootOptions.concat(dropDown.options);
    }

    const activeNonRootOption = nonRootOptions.find(
      (item) => isOption(item) && isActive(item.url, pathname, true)
    );

    if (activeNonRootOption) {
      return activeNonRootOption as Option;
    }

    // If no non-root options are active, try the root options ("/*")
    return options.find(
      (item) => isOption(item) && isActive(item.url, pathname, true, true)
    ) as Option | undefined;
  }, [options, pathname]);

  const onClick = useCallback(() => {
    closeOnRedirect.current = false;
  }, [closeOnRedirect]);

  return (
    <div className="flex flex-col gap-2 border-b p-4">
      {options.map((item) => (
        <SubdocsMenuItem
          key={isOption(item) ? item.url : "dropdown"}
          item={item}
          selected={selected}
          onClick={onClick}
        />
      ))}
    </div>
  );
}

function SubdocsMenuItem({
  item,
  selected,
  onClick,
}: {
  item: Option | OptionDropdown;
  selected?: Option;
  onClick?: () => void;
}) {
  if (isOption(item)) {
    return (
      <Link
        key={item.url}
        href={item.url}
        onClick={onClick}
        {...item.props}
        className={cn(
          "p-2 flex flex-row gap-3 items-center cursor-pointer group opacity-60 hover:opacity-100",
          item.props?.className,
          selected === item && `${item.selectedStyle} opacity-100`
        )}
      >
        <div
          className={cn(
            "rounded-sm p-1.5",
            item.bgGradient,
            selected !== item && ""
          )}
        >
          {item.icon}
        </div>
        <div className="font-medium">{item.title}</div>
      </Link>
    );
  } else if (isOptionDropdown(item)) {
    return (
      <SubdocsMenuItemDropdown
        item={item}
        selected={selected}
        onClick={onClick}
      />
    );
  }
}

function SubdocsMenuItemAgentFramework({
  item,
  selected,
  onClick,
}: {
  item: OptionDropdown;
  selected?: Option;
  onClick?: () => void;
}) {
  const defaultOption = item.options.find(
    (option) => option.url === "/coagents"
  )!;

  const isSelected = item.options.find(
    (option) => option.url === selected?.url
  );

  const showOption =
    item.options.find((option) => option.url === selected?.url) ||
    defaultOption;

  return (
    <Link
      key={showOption.url}
      href={showOption.url}
      onClick={onClick}
      {...showOption.props}
      className={cn(
        "p-2 flex flex-row gap-3 items-center cursor-pointer group opacity-60 hover:opacity-100",
        showOption.props?.className,
        isSelected && `${showOption.selectedStyle} opacity-100`
      )}
    >
      <div
        className={cn(
          "rounded-sm p-1.5",
          showOption.bgGradient,
          isSelected && ""
        )}
      >
        {showOption.icon}
      </div>
      <div className="font-medium">{showOption.title}</div>
    </Link>
  );
}

function SubdocsMenuItemDropdown({
  item,
  selected,
  onClick,
}: {
  item: OptionDropdown;
  selected?: Option;
  onClick?: () => void;
}) {
  const router = useRouter();
  const selectRef = useRef(null);

  const selectedOption = item.options.find(
    (option) => option.url === selected?.url
  );

  const isSelected = selectedOption !== undefined;

  return (
    <div className="w-full">
      <Select
        onValueChange={(url) => {
          router.push(url);
          onClick?.();
          if (selectRef.current) {
            setTimeout(() => {
              (selectRef.current as any).blur();
            }, 10);
          }
        }}
        value={selectedOption?.url}
      >
        <SelectTrigger
          className={cn(
            "pl-2 py-2 border-0 h-auto flex gap-3 items-center w-full",
            isSelected
              ? `${
                  selectedOption?.selectedStyle ||
                  "ring-purple-500/70 ring-2 rounded-sm"
                } opacity-100`
              : "ring-0 opacity-60 hover:opacity-100"
          )}
          ref={selectRef}
        >
          <SelectValue
            placeholder={
              <div className="flex items-center">
                <div className={cn("rounded-sm p-1.5 mr-2")}>
                  {selectedOption?.icon || (
                    <PiGraph
                      className={cn(
                        "w-5 h-5 text-bold bg-gradient-to-b rounded-sm",
                        "from-purple-700 to-purple-400 text-purple-100 inline-block"
                      )}
                    />
                  )}
                </div>
                <div className="font-medium">{item.title}</div>
              </div>
            }
          />
        </SelectTrigger>
        <SelectContent className="p-1">
          {item.options.map((option) => (
            <SelectItem
              key={option.url}
              value={option.url}
              className="py-2 px-2 cursor-pointer focus:bg-accent focus:text-accent-foreground"
            >
              <div className="flex items-center">
                <div className={cn("rounded-sm p-1.5 mr-2", option.bgGradient)}>
                  {option.icon}
                </div>
                <span className="font-medium">{option.title}</span>
              </div>
            </SelectItem>
          ))}
        </SelectContent>
      </Select>
    </div>
  );
}



================================================
FILE: docs/components/react/tabs.tsx
================================================
"use client";

import * as React from 'react';
import * as TabsPrimitive from '@radix-ui/react-tabs';
import { ScrollArea, ScrollBar } from "@/components/ui/scroll-area";
import { useRouter, useSearchParams } from 'next/navigation';

interface TabProps {
  value: string;
  children: React.ReactNode;
}

interface TabItem {
  value: string;
  icon?: React.ReactNode;
}

interface TabsProps {
  items: (TabItem | string)[];
  children: React.ReactNode;
  defaultValue?: string;
  groupId: string;
  persist?: boolean;
}

// Global state to sync tabs with the same groupId
const tabGroups: Record<string, Set<(value: string) => void>> = {};

const getStorageKey = (groupId: string) => `copilotkit-tabs-${groupId}`;

export function Tabs({ items, children, defaultValue, groupId, persist, ...props }: TabsProps) {
  const router = useRouter();
  const searchParams = useSearchParams();
  
  const normalizedItems = items.map(item => 
    typeof item === 'string' ? { value: item } : item
  );

  // Initialize value from URL or default
  const [value, setValue] = React.useState(() => {
    // First try URL
    const urlValue = searchParams.get(groupId);
    if (urlValue && normalizedItems.some(item => item.value === urlValue)) {
      return urlValue;
    }

    // Then try localStorage if persist is enabled
    if (persist && typeof window !== 'undefined') {
      try {
        const stored = localStorage.getItem(getStorageKey(groupId));
        if (stored && normalizedItems.some(item => item.value === stored)) {
          return stored;
        }
      } catch (e) {
        console.warn('Failed to read from localStorage:', e);
      }
    }

    return defaultValue || normalizedItems[0].value;
  });

  // Subscribe to group updates
  React.useEffect(() => {
    if (!groupId) return;

    // Create a Set for this group if it doesn't exist
    if (!tabGroups[groupId]) {
      tabGroups[groupId] = new Set();
    }

    // Create a setter function that updates this instance
    const setter = (newValue: string) => {
      setValue(newValue);
    };

    // Add this instance's setter to the group
    tabGroups[groupId].add(setter);

    return () => {
      // Cleanup: remove this instance's setter from the group
      tabGroups[groupId]?.delete(setter);
      if (tabGroups[groupId]?.size === 0) {
        delete tabGroups[groupId];
      }
    };
  }, [groupId]);

  const handleValueChange = (newValue: string) => {
    // Update URL
    const newParams = new URLSearchParams(searchParams.toString());
    newParams.set(groupId, newValue);
    router.replace(`?${newParams.toString()}`, { scroll: false });

    // Update state
    setValue(newValue);

    // Update all other tabs in the same group
    if (groupId && tabGroups[groupId]) {
      tabGroups[groupId].forEach(setter => setter(newValue));
    }

    // Persist if enabled
    if (persist && typeof window !== 'undefined') {
      try {
        localStorage.setItem(getStorageKey(groupId), newValue);
      } catch (e) {
        console.warn('Failed to write to localStorage:', e);
      }
    }
  };

  return (
    <TabsPrimitive.Root 
      className="border rounded-md" 
      value={value} 
      onValueChange={handleValueChange}
      {...props}
    >
      <ScrollArea className="w-full rounded-md rounded-b-none relative bg-secondary dark:bg-secondary/40 border-b">
        <TabsPrimitive.List className="px-4 py-3 flex" role="tablist">
          {normalizedItems.map((item) => (
            <TabsPrimitive.Trigger
              key={item.value}
              value={item.value}
              className="relative px-3 mr-2 py-1 text-sm font-medium rounded-md whitespace-nowrap flex gap-2 items-center border text-primary
                hover:bg-indigo-200/80 dark:hover:bg-indigo-900/80
                bg-indigo-200/30 dark:bg-indigo-800/20
                border-black/20 dark:border-gray-500/50
                data-[state=active]:bg-indigo-200/80 dark:data-[state=active]:bg-indigo-800/50
                data-[state=active]:border-indigo-400 dark:data-[state=active]:border-indigo-400"
              role="tab"
              aria-selected={value === item.value}
            >
              {item.icon && (
                <span className="w-4 h-4 flex items-center justify-center">
                  {item.icon}
                </span>
              )}
              {item.value}
            </TabsPrimitive.Trigger>
          ))}
          <ScrollBar orientation="horizontal" className=""/>
        </TabsPrimitive.List>
      </ScrollArea>
      {React.Children.map(children, (child) => {
        if (!React.isValidElement(child)) return null;
        return React.cloneElement(child as React.ReactElement<TabProps>);
      })}
    </TabsPrimitive.Root>
  );
}

export function Tab({ value, children }: TabProps) {
  return (
    <TabsPrimitive.Content value={value} className="px-4" role="tabpanel">
      {children}
    </TabsPrimitive.Content>
  );
}


================================================
FILE: docs/components/react/tailored-content.tsx
================================================
"use client";

import cn from "classnames";
import React, { useState, ReactNode, useEffect } from "react";
import { useRouter, useSearchParams } from "next/navigation";

type TailoredContentOptionProps = {
  title: string;
  description: string;
  icon: ReactNode;
  children: ReactNode;
  id: string;
};

export function TailoredContentOption({ title, description, icon, children }: TailoredContentOptionProps) {
  // This is just a type definition component - it won't render anything
  return <div>{children}</div>;
}

type TailoredContentProps = {
  children: ReactNode;
  header?: ReactNode;
  className?: string;
  defaultOptionIndex?: number;
  id: string;
};

export function TailoredContent({ children, className, defaultOptionIndex = 0, id, header }: TailoredContentProps) {
  const router = useRouter();
  const searchParams = useSearchParams();
  
  // Get options from children
  const options = React.Children.toArray(children).filter(
    (child) => React.isValidElement(child)
  ) as React.ReactElement<TailoredContentOptionProps>[];

  if (options.length === 0) {
    throw new Error("TailoredContent must have at least one TailoredContentOption child");
  }

  // Get the option IDs for URL handling
  const optionIds = options.map((option) => option.props.id);

  // Initialize selected index from URL or default
  const [selectedIndex, setSelectedIndex] = useState(() => {
    const urlParam = searchParams.get(id);
    const indexFromUrl = optionIds.indexOf(urlParam || "");
    return indexFromUrl >= 0 ? indexFromUrl : defaultOptionIndex;
  });

  // Update URL when selection changes
  const updateSelection = (index: number) => {
    const newParams = new URLSearchParams(searchParams.toString());
    newParams.set(id, optionIds[index]);
    
    // Update URL without reload
    router.replace(`?${newParams.toString()}`, { scroll: false });
    setSelectedIndex(index);
  };

  const itemCn =
    "border p-4 rounded-md flex-1 flex md:block md:space-y-1 items-center md:items-start gap-4 cursor-pointer bg-white dark:bg-secondary relative overflow-hidden group transition-all";
  const selectedCn =
    "shadow-lg ring-1 ring-indigo-400 selected bg-gradient-to-r from-indigo-100/80 to-purple-200 dark:from-indigo-900/20 dark:to-purple-900/30";
  const iconCn =
    "w-10 h-10 mb-4 top-0 transition-all opacity-20 group-[.selected]:text-indigo-500 group-[.selected]:opacity-60 dark:group-[.selected]:text-indigo-400 dark:group-[.selected]:opacity-60 dark:text-gray-400";

  return (
    <div>
      <div className={cn("tailored-content-wrapper mt-4", className)}>
        {header}
        <div className="flex flex-col md:flex-row gap-3 my-2 w-full">
          {options.map((option, index) => (
            <div
              key={option.props.id}
              className={cn(itemCn, selectedIndex === index && selectedCn)}
              onClick={() => updateSelection(index)}
              role="tab"
              aria-selected={selectedIndex === index}
              tabIndex={0}
            >
              <div className="my-0">
                {React.cloneElement(option.props.icon as React.ReactElement, {
                  className: cn(iconCn, selectedIndex === index, "my-0"),
                })}
              </div>
              <div>
                <p className="font-semibold text-lg">{option.props.title}</p>
                <p className="text-xs md:text-sm">{option.props.description}</p>
              </div>
            </div>
          ))}
        </div>
      </div>
      {options[selectedIndex]?.props.children}
    </div>
  );
}



================================================
FILE: docs/components/react/test-react-component.tsx
================================================
import React from "react";

export function TestReactComponent() {
  return <div>Test Componentzzz</div>
}


================================================
FILE: docs/components/react/youtube-video.tsx
================================================
"use client"

import YouTube from "react-youtube";

export function YouTubeVideo({
  videoId,
  defaultPlaybackRate = 1.0,
}: {
  videoId: string;
  defaultPlaybackRate?: number;
}) {
  const onPlayerReady: YouTube["props"]["onReady"] = (event) => {
    const player = event.target;

    if (defaultPlaybackRate) {
      player.setPlaybackRate(defaultPlaybackRate);
    }
  };

  const opts: YouTube["props"]["opts"] = {
    playerVars: {},
  };

  return (
    <YouTube
      videoId={videoId}
      className="w-full h-[425px] rounded-lg"
      iframeClassName="rounded-2xl w-full h-full shadow-xl border"
      opts={opts}
      onReady={onPlayerReady}
    />
  );
}


================================================
FILE: docs/components/react/coagents/coagents-diagram.tsx
================================================
import React from "react";

export const CoAgentsDiagram: React.FC = (): JSX.Element => {
  return (
    <div className="flex flex-col items-center">
      <div className="flex items-center">
        <DiagramNode title="Frontend (via CopilotKit provider)" />
        <DiagramArrow />
        <DiagramNode title="Copilot Runtime" variant="colored" />
        <DiagramArrow />
        <DiagramNode title="Remote Endpoint" variant="colored" />
        <DiagramArrow />
        <DiagramNode title="LangGraph Agent" />
      </div>
    </div>
  );
};

interface DiagramNodeProps {
  title: string;
  variant?: 'default' | 'colored';
}

const DiagramNode: React.FC<DiagramNodeProps> = ({ title, variant = 'default' }): JSX.Element => {
  const bgColor = variant === 'colored' 
    ? "bg-blue-100 dark:bg-blue-900" 
    : "bg-gray-50 dark:bg-neutral-900";
    
  return (
    <div className={`${bgColor} shadow-lg rounded-lg p-4 m-2 text-center`}>
      <span className="text-gray-800 dark:text-gray-200 font-medium">{title}</span>
    </div>
  );
};

const DiagramArrow: React.FC = (): JSX.Element => {
  return (
    <div className="mx-2">
      <svg
        className="w-6 h-6 text-gray-400 dark:text-gray-500"
        fill="none"
        stroke="currentColor"
        viewBox="0 0 24 24"
      >
        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 5l7 7-7 7" />
      </svg>
    </div>
  );
};


================================================
FILE: docs/components/react/coagents/coagents-enterprise-cta.tsx
================================================
import React from "react";
import Link from "next/link";

export function CoAgentsEnterpriseCTA() {
  return (
    <div className="mt-4 mb-4 ring-1 ring-indigo-200 dark:ring-indigo-500/30 selected bg-gradient-to-r from-indigo-100/80 to-purple-100 dark:from-indigo-950/50 dark:to-purple-950/50 shadow-lg rounded-lg p-5 space-y-2 relative overflow-hidden">
      <p className="text-lg mt-0 font-medium dark:text-white">
        Learn to build Agent-Native Applications / with LangGraph and CoAgents.
      </p>
      <p>
        <Link
          href="https://www.youtube.com/watch?v=0b6BVqPwqA0"
          target="_blank"
          className="block mt-3 no-underline">
          <button className="bg-indigo-600 hover:bg-indigo-700 dark:bg-indigo-500 dark:hover:bg-indigo-600 text-white px-4 py-2 rounded-lg flex items-center gap-2 mt-2 font-medium">
            <span>Watch the demo</span>
          </button>
        </Link>
      </p>
      <p className="absolute bottom-[-40px] right-[10px] text-[150px] z-0 opacity-15">
        🪁
      </p>
    </div>
  );
}



================================================
FILE: docs/components/react/coagents/coagents-features.tsx
================================================
"use client"

import { useTailoredContent } from "@/lib/hooks/use-tailored-content";
import cn from "classnames";
import { useEffect, useState } from "react";
import { AiOutlineRobot as GenerativeUiIcon } from "react-icons/ai";
import { TbActivityHeartbeat as StreamAgentStateIcon } from "react-icons/tb";
import { IoShareSocialOutline as ShareAgentStateIcon } from "react-icons/io5";
import { FaQuestionCircle as AgentQAndAIcon } from "react-icons/fa";

type FeatureMode = "generative-ui" | "stream-agent-state" | "share-agent-state" | "agent-q-and-a";

export const CoAgentsFeatureToggle: React.FC<{ className?: string }> = ({ className }) => {
  const { mode, setMode } = useTailoredContent<FeatureMode>(
    ["generative-ui", "stream-agent-state", "share-agent-state", "agent-q-and-a"],
    "generative-ui"
  );
  const [isClient, setIsClient] = useState(false);

  useEffect(() => {
    setIsClient(true);
  }, []);

  if (!isClient) {
    return null;
  }

  const itemCn =
    "border dark:text-white dark:bg-neutral-800 p-4 rounded-md flex-1 flex flex-col items-center justify-center cursor-pointer bg-white relative overflow-hidden group transition-all";
  const selectedCn =
    "ring-1 dark:text-black ring-indigo-400 selected bg-gradient-to-r from-indigo-100/80 to-purple-200 dark:from-indigo-500 dark:to-purple-500 shadow-lg";
  const iconCn =
    "w-7 h-7 mb-2 opacity-20 group-[.selected]:text-indigo-500 group-[.selected]:opacity-60  dark:group-[.selected]:text-indigo-100 transition-all";

  const features: { id: FeatureMode; title: string; description: string; Icon: React.FC<React.SVGProps<SVGSVGElement>> }[] = [
    {
      id: "generative-ui",
      title: "Generative UI",
      description: "Create dynamic user interfaces with AI-generated components.",
      Icon: GenerativeUiIcon,
    },
    {
      id: "stream-agent-state",
      title: "Stream Agent State",
      description: "Real-time updates on agent activities and decision-making processes.",
      Icon: StreamAgentStateIcon,
    },
    {
      id: "share-agent-state",
      title: "Share Agent State",
      description: "Collaborate and share agent states across different sessions or users.",
      Icon: ShareAgentStateIcon,
    },
    {
      id: "agent-q-and-a",
      title: "Agent Q&A",
      description: "Interactive question and answer sessions with AI agents.",
      Icon: AgentQAndAIcon,
    },
  ];

  return (
    <div className={cn("coagents-features-wrapper mt-4", className)}>
      <div className="grid grid-cols-2 md:grid-cols-4 gap-3 my-2 w-full">
        {features.map((feature) => (
          <div
            key={feature.id}
            className={cn(itemCn, mode === feature.id && selectedCn)}
            onClick={() => setMode(feature.id)}
          >
            <feature.Icon className={cn(iconCn, mode === feature.id && "text-indigo-500")} />
            <p className="font-semibold text-sm md:text-base text-center">{feature.title}</p>
            <p className="text-xs text-center hidden md:block">{feature.description}</p>
          </div>
        ))}
      </div>
    </div>
  );
};

const FeatureContent: React.FC<{
  children: React.ReactNode;
  className?: string;
  mode: FeatureMode;
}> = ({ children, className, mode }) => {
  const { mode: currentMode } = useTailoredContent<FeatureMode>(
    ["generative-ui", "stream-agent-state", "share-agent-state", "agent-q-and-a"],
    "generative-ui"
  );
  
  const [isClient, setIsClient] = useState(false);

  useEffect(() => {
    setIsClient(true);
  }, []);

  if (!isClient) {
    return null;
  }

  return (
    <div
      className={cn(
        "feature-content mt-6",
        currentMode !== mode && "hidden",
        className
      )}
    >
      {children}
    </div>
  );
};

export const CoAgentsFeatureRender: React.FC<{ children: React.ReactNode; className?: string, feature: "generative-ui" | "stream-agent-state" | "share-agent-state" | "agent-q-and-a" }> = (props) => (
  <FeatureContent {...props} mode={props.feature} />
);



================================================
FILE: docs/components/react/component-previews/new-look-and-feel.tsx
================================================
"use client"

import { CopilotSidebar, useCopilotChatSuggestions } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";


export const NewLookAndFeelPreview = () => {
  return (
    <CopilotKit publicApiKey={process.env.NEXT_PUBLIC_COPILOT_CLOUD_PUBLIC_API_KEY}>
      <Chat />
    </CopilotKit>
  )
}

const Chat = () => {
  useCopilotChatSuggestions({
    instructions: "Give suggestions for a fun conversation to have with the user.",
    minSuggestions: 0,
    maxSuggestions: 3,
  })

  return (
    <CopilotSidebar
      onThumbsUp={(message) => alert(message)} 
      onThumbsDown={(message) => alert(message)}
      labels={{
        initial: "Hey there Let's have a fun conversation!"
      }}
    />
  )
}



================================================
FILE: docs/components/react/multi-provider-content/multi-provider-content.tsx
================================================
'use client';

import React, { useMemo, useState, isValidElement, useContext } from "react";
import { ProviderDefinition, ProvidersConfig } from "./utils.ts";
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select.tsx";

type Props = {
    children: React.ReactNode;
    providersConfig: ProvidersConfig
    defaultProvider?: string;
}

// @ts-expect-error -- initiating this with null is fine
const ProviderContext = React.createContext<{ provider: ProviderDefinition; providerName: string }>(null)

const LOCALSTORAGE_KEY = 'preferredProvider'

export function MultiProviderContent({ children, defaultProvider = 'openai', providersConfig }: Props) {
    const [selectedProvider, internalSetSelectedProvider] = useState(() => {
        // Initialize state from localStorage if available
        if (typeof window !== 'undefined') {
            return localStorage.getItem(LOCALSTORAGE_KEY) || defaultProvider;
        }
        return defaultProvider;
    });
    const setSelectedProvider = (selection: string) => {
        internalSetSelectedProvider(selection)
        localStorage.setItem(LOCALSTORAGE_KEY, selection);
    }

    const handleSelectChange = (value: string) => {
        setSelectedProvider(value);
    }

    return (
        <div>
            <Select defaultValue={selectedProvider as string} onValueChange={handleSelectChange}>
                <div className="flex items-center w-full flex-col sm:flex-row">
                    <h5 className="mb-2 sm:mb-0 sm:mr-2">Choose your provider:</h5>
                    <SelectTrigger className="w-full sm:w-[280px]">
                        <SelectValue placeholder="Theme" />
                    </SelectTrigger>
                </div>
                <SelectContent>
                    {
                        Object.entries(providersConfig).map(([key, provider]) => (
                            <SelectItem key={provider.id} value={provider.id}>
                                <div className="flex items-center justify-center">
                                    <img
                                        className="my-0 mr-2 rounded-sm"
                                        src={provider.icon}
                                        alt={`${provider.title} logo`}
                                        width={20}
                                        height={20}
                                    />
                                    {provider.title}
                                </div>
                            </SelectItem>
                        ))
                    }
                </SelectContent>
            </Select>
            <ProviderContext.Provider value={{ provider: providersConfig[selectedProvider], providerName: selectedProvider }}>
                <Interpolate>
                    {children}
                </Interpolate>
            </ProviderContext.Provider>
        </div>
    );
}

export function Interpolate({ children }: { children: React.ReactNode; }) {
    const { provider, providerName } = useContext(ProviderContext)

    return useMemo(() => {
        if (!provider) return children;

        const processElement = (element: React.ReactNode): React.ReactNode => {
            if (!element) return element;

            // Handle string elements
            if (typeof element === 'string') {
                const tokenRegex = /{{[^}]+}}/g;
                const lines = element.split('\n');
                const filteredLines = lines.filter(line => {
                    const matches = line.match(tokenRegex);
                    if (!matches) return true;
                    
                    // Check if any token in the line has no value
                    return !matches.some(match => {
                        const propName = match.slice(2, -2).trim();
                        return provider[propName] === undefined;
                    });
                });

                return filteredLines.join('\n').replace(tokenRegex, (match) => {
                    const propName = match.slice(2, -2).trim();
                    const value = provider[propName];
                    return Array.isArray(value) ? value.join('\n').trim() : value.toString().trim();
                });
            }

            // Handle React elements
            if (isValidElement(element)) {
                const processedChildren = React.Children.map(element.props.children, processElement);
                return React.cloneElement(element, { ...element.props, children: processedChildren });
            }

            // Handle arrays
            if (Array.isArray(element)) {
                return element.map(child => processElement(child));
            }

            return element;
        };

        return React.Children.map(children, processElement);
    }, [children, providerName])
}

interface Condition { key: keyof ProviderDefinition, value: unknown }
export function If({ conditions, children }: { children: React.ReactNode; conditions: Condition[] }) {
    const { provider } = useContext(ProviderContext)

    const runCondition = ({ key, value }: Condition) => {
        switch(typeof value) {
            case "boolean":
                return Boolean(provider[key]) === value;
            default:
                return provider[key] === value;
        }
    }

    const passed = useMemo(() => conditions.some(runCondition), [conditions, provider])

    if (!passed) {
        return null
    }

    return children
}



================================================
FILE: docs/components/react/multi-provider-content/utils.ts
================================================
export type ProviderDefinition = {
    id: string;
    title: string;
} & { [key: string]: any };
export type ProvidersConfig = {
    [key: string]: ProviderDefinition;
}

export const quickStartProviders: ProvidersConfig = {
    "openai": {
        id: "openai",
        title: "OpenAI",
        icon: '/icons/openai.png',
        envVarName: "OPENAI_API_KEY",
        adapterImport: "OpenAIAdapter",
        adapterSetup: 'const serviceAdapter = new OpenAIAdapter();'
    },
    "azure": {
        id: "azure",
        title: "Azure OpenAI",
        icon: '/icons/azure.png',
        packageName: "openai",
        envVarName: "AZURE_OPENAI_API_KEY",
        adapterImport: "OpenAIAdapter",
        extraImports: `
            import OpenAI from 'openai';
        `,
        clientSetup: `
const apiKey = process.env["AZURE_OPENAI_API_KEY"];
if (!apiKey) {
  throw new Error("The AZURE_OPENAI_API_KEY environment variable is missing or empty.");
}
const openai = new OpenAI({
  apiKey: process.env.AZURE_OPENAI_API_KEY,
  baseURL: 'https://<your instance name>.openai.azure.com/openai/deployments/<your model>',
  defaultQuery: { "api-version": "2024-04-01-preview" },
  defaultHeaders: { "api-key": apiKey },
});`,
        adapterSetup: 'const serviceAdapter = new OpenAIAdapter({ openai });'
    },
    "anthropic": {
        id: "anthropic",
        title: "Anthropic (Claude)",
        icon: '/icons/anthropic.png',
        envVarName: "ANTHROPIC_API_KEY",
        adapterImport: "AnthropicAdapter",
        adapterSetup: 'const serviceAdapter = new AnthropicAdapter();'
    },
    "groq": {
        id: "groq",
        title: "Groq",
        icon: '/icons/groq.png',
        envVarName: "GROQ_API_KEY",
        adapterImport: "GroqAdapter",
        adapterSetup: 'const serviceAdapter = new GroqAdapter({ model: "<model-name>" });'
    },
    "google": {
        id: "google",
        title: "Google Generative AI (Gemini)",
        icon: '/icons/google.png',
        envVarName: "GOOGLE_API_KEY",
        adapterImport: "GoogleGenerativeAIAdapter",
        adapterSetup: 'const serviceAdapter = new GoogleGenerativeAIAdapter({ model: <optional model choice> });'
    },
    "langchain": {
        id: 'langchain',
        title: 'LangChain (any model)',
        icon: '/icons/langchain.png',
        packageName: "@langchain/openai",
        envVarName: "OPENAI_API_KEY",
        adapterImport: "LangChainAdapter",
        extraImports: `
            import { ChatOpenAI } from "@langchain/openai";
        `,
        clientSetup: 'const model = new ChatOpenAI({ model: "gpt-4o", apiKey: process.env.OPENAI_API_KEY });',
        adapterSetup: `
        const serviceAdapter = new LangChainAdapter({
    chainFn: async ({ messages, tools }) => {
    return model.bindTools(tools).stream(messages);
    // or optionally enable strict mode
    // return model.bindTools(tools, { strict: true }).stream(messages);
  }
});`
    },
    "openai-assistants": {
        id: "openai-assistants",
        title: "OpenAI Assistants API",
        icon: '/icons/openai.png',
        packageName: "openai",
        envVarName: "OPENAI_API_KEY",
        adapterImport: "OpenAIAssistantAdapter",
        extraImports: [
            'import OpenAI from \'openai\';'
        ],
        clientSetup: `
        const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  organization: "<your-organization-id>"
});
        `,
        adapterSetup: `
        const serviceAdapter = new OpenAIAssistantAdapter({
  openai,
  assistantId: "<your-assistant-id>",
  codeInterpreterEnabled: true,
  fileSearchEnabled: true,
});
        `
    },
    "empty": {
        id: "empty",
        title: "Empty Adapter (CoAgents Only)",
        icon: '/icons/empty.svg',
        adapterImport: "EmptyAdapter",
        adapterSetup: 'const serviceAdapter = new EmptyAdapter();'
    },
};



================================================
FILE: docs/components/ui/badge.tsx
================================================
import * as React from "react"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const badgeVariants = cva(
  "inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",
  {
    variants: {
      variant: {
        default:
          "border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",
        destructive:
          "border-transparent bg-destructive text-destructive-foreground shadow hover:bg-destructive/80",
        outline: "text-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

export interface BadgeProps
  extends React.HTMLAttributes<HTMLDivElement>,
    VariantProps<typeof badgeVariants> {}

function Badge({ className, variant, ...props }: BadgeProps) {
  return (
    <div className={cn(badgeVariants({ variant }), className)} {...props} />
  )
}

export { Badge, badgeVariants }



================================================
FILE: docs/components/ui/button.tsx
================================================
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90",
        outline:
          "border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground shadow-sm hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-9 w-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }



================================================
FILE: docs/components/ui/card.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-md border bg-card text-card-foreground shadow",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("font-semibold leading-none tracking-tight", className)}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardDescription = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
CardDescription.displayName = "CardDescription"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

const CardFooter = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex items-center p-6 pt-0", className)}
    {...props}
  />
))
CardFooter.displayName = "CardFooter"

export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }



================================================
FILE: docs/components/ui/input.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Input = React.forwardRef<HTMLInputElement, React.ComponentProps<"input">>(
  ({ className, type, ...props }, ref) => {
    return (
      <input
        type={type}
        className={cn(
          "flex h-9 w-full rounded-md border border-input bg-transparent px-3 py-1 text-base shadow-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Input.displayName = "Input"

export { Input }



================================================
FILE: docs/components/ui/scroll-area.tsx
================================================
"use client"

import * as React from "react"
import * as ScrollAreaPrimitive from "@radix-ui/react-scroll-area"

import { cn } from "@/lib/utils"

const ScrollArea = React.forwardRef<
  React.ElementRef<typeof ScrollAreaPrimitive.Root>,
  React.ComponentPropsWithoutRef<typeof ScrollAreaPrimitive.Root>
>(({ className, children, ...props }, ref) => (
  <ScrollAreaPrimitive.Root
    ref={ref}
    className={cn("relative overflow-hidden", className)}
    {...props}
  >
    <ScrollAreaPrimitive.Viewport className="h-full w-full rounded-[inherit]">
      {children}
    </ScrollAreaPrimitive.Viewport>
    <ScrollBar />
    <ScrollAreaPrimitive.Corner />
  </ScrollAreaPrimitive.Root>
))
ScrollArea.displayName = ScrollAreaPrimitive.Root.displayName

const ScrollBar = React.forwardRef<
  React.ElementRef<typeof ScrollAreaPrimitive.ScrollAreaScrollbar>,
  React.ComponentPropsWithoutRef<typeof ScrollAreaPrimitive.ScrollAreaScrollbar>
>(({ className, orientation = "vertical", ...props }, ref) => (
  <ScrollAreaPrimitive.ScrollAreaScrollbar
    ref={ref}
    orientation={orientation}
    className={cn(
      "flex touch-none select-none transition-colors",
      orientation === "vertical" &&
        "h-full w-2.5 border-l border-l-transparent p-[1px]",
      orientation === "horizontal" &&
        "h-2.5 flex-col border-t border-t-transparent p-[1px]",
      className
    )}
    {...props}
  >
    <ScrollAreaPrimitive.ScrollAreaThumb className="relative flex-1 rounded-full bg-border" />
  </ScrollAreaPrimitive.ScrollAreaScrollbar>
))
ScrollBar.displayName = ScrollAreaPrimitive.ScrollAreaScrollbar.displayName

export { ScrollArea, ScrollBar }



================================================
FILE: docs/components/ui/select.tsx
================================================
"use client";

import * as React from "react";
import * as SelectPrimitive from "@radix-ui/react-select";
import { cn } from "@/lib/utils";
import {
  CheckIcon,
  ChevronDownIcon,
  ChevronUpIcon,
} from "@radix-ui/react-icons";

const Select = SelectPrimitive.Root;

const SelectGroup = SelectPrimitive.Group;

const SelectValue = SelectPrimitive.Value;

const SelectTrigger = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Trigger>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Trigger
    ref={ref}
    className={cn(
      "flex h-9 w-full items-center justify-between whitespace-nowrap rounded-md border border-input bg-transparent px-3 py-2 text-sm shadow-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-1 focus:ring-ring disabled:cursor-not-allowed disabled:opacity-50 [&>span]:line-clamp-1",
      className
    )}
    {...props}
  >
    {children}
    <SelectPrimitive.Icon asChild>
      <ChevronDownIcon className="h-4 w-4 opacity-50" />
    </SelectPrimitive.Icon>
  </SelectPrimitive.Trigger>
));
SelectTrigger.displayName = SelectPrimitive.Trigger.displayName;

const SelectScrollUpButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollUpButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollUpButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollUpButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronUpIcon className="h-4 w-4" />
  </SelectPrimitive.ScrollUpButton>
));
SelectScrollUpButton.displayName = SelectPrimitive.ScrollUpButton.displayName;

const SelectScrollDownButton = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.ScrollDownButton>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.ScrollDownButton>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.ScrollDownButton
    ref={ref}
    className={cn(
      "flex cursor-default items-center justify-center py-1",
      className
    )}
    {...props}
  >
    <ChevronDownIcon className="h-4 w-4" />
  </SelectPrimitive.ScrollDownButton>
));
SelectScrollDownButton.displayName =
  SelectPrimitive.ScrollDownButton.displayName;

const SelectContent = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Content>
>(({ className, children, position = "popper", ...props }, ref) => (
  <SelectPrimitive.Portal>
    <SelectPrimitive.Content
      ref={ref}
      className={cn(
        "relative z-50 max-h-96 min-w-[8rem] overflow-hidden rounded-md border bg-popover text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2",
        position === "popper" &&
          "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
        className
      )}
      position={position}
      {...props}
    >
      <SelectScrollUpButton />
      <SelectPrimitive.Viewport
        className={cn(
          "p-1",
          position === "popper" &&
            "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)]"
        )}
      >
        {children}
      </SelectPrimitive.Viewport>
      <SelectScrollDownButton />
    </SelectPrimitive.Content>
  </SelectPrimitive.Portal>
));
SelectContent.displayName = SelectPrimitive.Content.displayName;

const SelectLabel = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Label>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Label>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Label
    ref={ref}
    className={cn("px-2 py-1.5 text-sm font-semibold", className)}
    {...props}
  />
));
SelectLabel.displayName = SelectPrimitive.Label.displayName;

const SelectItem = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Item>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Item>
>(({ className, children, ...props }, ref) => (
  <SelectPrimitive.Item
    ref={ref}
    className={cn(
      "relative flex w-full cursor-default select-none items-center rounded-sm py-1.5 pl-2 pr-8 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50",
      className
    )}
    {...props}
  >
    <span className="absolute right-2 flex h-3.5 w-3.5 items-center justify-center">
      <SelectPrimitive.ItemIndicator>
        <CheckIcon className="h-4 w-4" />
      </SelectPrimitive.ItemIndicator>
    </span>
    <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
  </SelectPrimitive.Item>
));
SelectItem.displayName = SelectPrimitive.Item.displayName;

const SelectSeparator = React.forwardRef<
  React.ElementRef<typeof SelectPrimitive.Separator>,
  React.ComponentPropsWithoutRef<typeof SelectPrimitive.Separator>
>(({ className, ...props }, ref) => (
  <SelectPrimitive.Separator
    ref={ref}
    className={cn("-mx-1 my-1 h-px bg-muted", className)}
    {...props}
  />
));
SelectSeparator.displayName = SelectPrimitive.Separator.displayName;

export {
  Select,
  SelectGroup,
  SelectValue,
  SelectTrigger,
  SelectContent,
  SelectLabel,
  SelectItem,
  SelectSeparator,
  SelectScrollUpButton,
  SelectScrollDownButton,
};



================================================
FILE: docs/content/docs/(root)/index.mdx
================================================
---
title: Introduction
description: "Build production-ready Copilots and Agents effortlessly."
icon: "lucide/Sparkles"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { YouTubeVideo } from "@/components/react/youtube-video";

import { MdMessage } from "react-icons/md";
import { TbSparkles } from "react-icons/tb";
import { SiLangchain } from "react-icons/si";
import { AG2Icon } from "@/lib/icons/custom-icons";
import { SiCrewai } from "@icons-pack/react-simple-icons";
import { FileSpreadsheet, Banknote, Plane, BookOpen, Telescope, Play } from "lucide-react";

# What is CopilotKit?

At its core, CopilotKit is a set of tools that make it easy to **let your users work
alongside Large Language Models (LLMs) to accomplish generative tasks** directly in
your application. Instead of just using the LLM to generate content, you can let it
take direct action alongside your users.

Interacting with these models can be done directly (**Standard**) or through agents (**CoAgents**).

## Standard
Utilize CopilotKit's standard agentic runloop to get started quickly.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    title="Quickstart"
    description="Get started with CopilotKit directly in your application."
    href="/quickstart"
    icon={<Play className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="Tutorial"
    description="Build an AI todo app with CopilotKit in minutes."
    href="/tutorials/ai-todo-app/overview"
    icon={<BookOpen className="text-indigo-500 dark:text-indigo-300" />}
  />
</Cards>

## CoAgents
When you need **complete control** over the agentic runloop, you can use **CoAgents**. Bridge the remaining gap between demos and production-ready experiences.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    title="LangGraph"
    description="User-interactive agents with LangGraph."
    href="/coagents"
    icon={<SiLangchain className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="CrewAI Crews"
    description="Build multi-agent workflows with CrewAI."
    href="/crewai-crews"
    icon={<SiCrewai className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="CrewAI Flows"
    description="User-interactive agents with CrewAI."
    href="/crewai-flows"
    icon={<SiCrewai className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="AG2"
    description="Autonomous, collaborative AI agents with AG2."
    href="/ag2"
    icon={<AG2Icon className="text-indigo-500 dark:text-indigo-300 h-6 w-6" />}
  />
</Cards>

## CopilotKit in Action
Need some inspiration? Check out somethings we've built with CopilotKit.

<Cards className="gap-6">
  <Card
    className="md:col-span-2 p-6 py-10 rounded-xl text-base" 
    title="Feature Viewer"
    description="Learn about all of the best features CopilotKit has to offer with an interactive experience."
    href="https://feature-viewer-langgraph.vercel.app/"
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="Spreadsheet Copilot"
    description="A powerful spreadsheet assistant that helps users analyze data, create formulas, and generate insights."
    href="https://spreadsheet-demo-tau.vercel.app/"
    icon={<FileSpreadsheet className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="SaaS Copilot"
    description="An AI-powered banking interface that helps users understand and interact with their finances."
    href="https://brex-demo-temp.vercel.app/"
    icon={<Banknote className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="Agent-Native Travel Planner"
    description="Interactive travel planning assistant that helps users generate and build travel itineraries."
    href="https://examples-coagents-ai-travel-app.vercel.app/"
    icon={<Plane className="text-indigo-500 dark:text-indigo-300" />}
  />
  <Card 
    className="p-6 rounded-xl text-base"
    title="Agent-Native Research Canvas"
    description="An intelligent research assistant that helps users synthesize information across multiple sources."
    href="https://examples-coagents-research-canvas-ui.vercel.app/"
    icon={<BookOpen className="text-indigo-500 dark:text-indigo-300" />}
  />
</Cards>

## How does CopilotKit work?
CopilotKit is thoughtfully architected to scale with you, your teams, and your product.
<ImageZoom src="/images/architecture-diagram.png" className="rounded-2xl" width={1000} height={1000}/>

## Common Questions
We've got answers to some common questions!

<Accordions>
  <Accordion title="What is a Copilot?">
    A Copilot is a trusted partner that lives in your application to help your users get things done.
    There are two main types, the **Concierge** and the **Worker**.

    ### Concierge

    The Concierge Copilot understands your application's capabilities and full user context. It translates 
    high-level user intent into actions by serving as an intelligent intermediary.

    For example, our [Banking Assistant](https://github.com/CopilotKit/demo-banking) implements Concierge Copilots 
    to help users manage their (_fake_) banking needs.
    

    ### Worker

    The Worker Copilot is a domain-specific agent that can help users perform their core work tasks.
    It serves as a partner to the user that is better at performing some tasks and worse at others. 
    Ultimately, it amplifies your users to produce better work than they thought possible. This pattern
    is often used in backoffice copilots.

    Think of the Worker Copilot as Cursor, Replit Agent, or Windsurf, but for any domain. For example, 
    see our [Open Researcher ANA](https://github.com/CopilotKit/open-research-ana).
  </Accordion>
  <Accordion title="What are the main features of CopilotKit?">
    ### Batteries included chat components
    Beautiful, powerful and customizable chat components just an import away.
    | | |
    |---------|-------------|
    | [**Chat**](/reference/components/chat/CopilotChat) | Simple and powerful chat interface |
    | [**Pop-up**](/reference/components/chat/CopilotPopup) | The Chat component in a pop-up format |
    | [**Sidebar**](/reference/components/chat/CopilotSidebar) | The Chat component in a sidebar format |
    | [**Copilot Textarea**](/reference/components/CopilotTextarea) | Powerful AI autocompletion as a drop-in replacement for any textarea |
    | [**Headless**](/guides/custom-look-and-feel/customize-built-in-ui-components) | Full customization of the chat interfaces |

    ### Deeply integrated Copilots
    Give Copilots the ability to take actions directly in your application.
    |  |  |
    |---------|-------------|
    | [**Copilot Readable State**](/reference/hooks/useCopilotReadable) | Enables Copilots to read and understand the application state |
    | [**Copilot Actions**](/reference/hooks/useCopilotAction) | Copilots can perform actions in the application |
    | [**Generative UI**](/guides/generative-ui) | Render any component in the copilot chat interface |
    | [**AI Autosuggestions**](/reference/hooks/useCopilotChatSuggestions) | AI-powered autosuggestions in your AI chat interface |
    | [**Copilot Tasks**](/reference/classes/CopilotTask) | Let your copilots take actions proactively based on application state |

    ### Rich agentic experiences
    Integrate your LangGraph agents into your product with ease.
    | |  |
    |---------|-------------|
    | [**Deep support for LangGraph**](/coagents/quickstart/langgraph) | Bring your LangGraph agents directly into your product |
    | [**Human-in-the-loop**](/coagents/human-in-the-loop) | Allow your users to work with your agents to solve complex problems |
    | [**Shared state**](/coagents/shared-state) | Render the state of your LangGraph agents with less than 10 lines of code |
    | [**Multi-agent**](/coagents/multi-agent-flows) | Build multi-agent experiences with ease |
  </Accordion>
  <Accordion title="How does it all work?">
    Great question! CopilotKit has three main components:
    1. **CopilotKit UI**: The UI components that you use to build your Copilots and Agents.
    2. **CopilotKit Runtime**: The runtime that you use to build your Copilots and Agents. This serves as the backend for your Copilots and Agents.
    3. **CopilotKit SDK**: In more complex applications, you'll use the SDK to deeply integrate CopilotKit into your agents.
  </Accordion>

  <Accordion title="Can I use any LLM with CopilotKit?">
    Yes! CopilotKit supports most LLMs, including OpenAI, Anthropic, Google, and more. In addition, you can use any LLM that is supported by LangGraph or
    LangChain.

    For more information, checkout our documentation on [bringing your own LLM](/guides/bring-your-own-llm).
  </Accordion>
</Accordions>



================================================
FILE: docs/content/docs/(root)/meta.json
================================================
{
  "title": "copilotkit",
  "root": true,
  "pages": [
    "index",
    "quickstart",
    "---Guides---",
    "...guides",
    "---Tutorials---",
    "...tutorials",
    "---Cookbook---",
    "...cookbook",
    "---Troubleshooting---",
    "...troubleshooting",
    "---Other---",
    "(other)/contributing",
    "(other)/telemetry",
    "(other)/observability"
  ]
}



================================================
FILE: docs/content/docs/(root)/quickstart.mdx
================================================
---
title: "Quickstart"
description: "Get started with CopilotKit in under 5 minutes."
icon: "lucide/Play"
---

import { LinkIcon } from "lucide-react";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import CloudCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { FaCloud, FaServer } from "react-icons/fa";

## Using the CLI
If you have a **NextJS** application, you can use our CLI to automatically bootstrap your application for use with CopilotKit.

```bash
npx copilotkit@latest init
```

<Accordions>
  <Accordion title="Starting from scratch?">
    No problem! Just use `create-next-app` to make a new NextJS application quickly.
    ```bash
    npx create-next-app@latest
    ```
  </Accordion>
</Accordions>

## Code-along
If you don't have a NextJS application or just want to code-along, you can follow the steps below.

<TailoredContent id="copilot-hosting">
<TailoredContentOption
  id="copilot-cloud"
  title="Copilot Cloud (Recommended)"
  description="Use our hosted backend endpoint to get started quickly (OpenAI only)."
  icon={<FaCloud />}
>

<Steps>
<Step>
### Install CopilotKit

First, install the latest packages for CopilotKit.

```package-install
npm install @copilotkit/react-ui @copilotkit/react-core
```

</Step>
<Step>
### Get a Copilot Cloud Public API Key
Navigate to [Copilot Cloud](https://cloud.copilotkit.ai) and follow the instructions to get a public API key - it's free!
</Step>
<Step>
### Setup the CopilotKit Provider

The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases, 
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

<CloudCopilotKitProvider components={props.components} />

</Step>
<Step>
### Choose a Copilot UI

You are almost there! Now it's time to setup your Copilot UI.

<ConnectCopilotUI components={props.components} />

</Step>
</Steps>
</TailoredContentOption>
<TailoredContentOption
  id="self-hosted"
  title="Self-hosting"
  description="Learn to host CopilotKit's runtime yourself with your own backend."
  icon={<FaServer />}
>

<Steps>
<Step>
### Install CopilotKit
First, install the latest packages for CopilotKit.

```package-install
npm install @copilotkit/react-ui @copilotkit/react-core @copilotkit/runtime
```
</Step>
<Step>
### Set up a Copilot Runtime Endpoint

<SelfHostingCopilotRuntimeCreateEndpoint components={props.components} />
</Step>
<Step>
### Configure the CopilotKit Provider

<SelfHostingCopilotRuntimeConfigureCopilotKitProvider
  components={props.components}
/>

</Step>
<Step>
### Choose a Copilot UI

You are almost there! Now it's time to setup your Copilot UI.

<ConnectCopilotUI components={props.components} />

</Step>
</Steps>
</TailoredContentOption>
</TailoredContent>

---

## Next Steps

🎉 Congrats! You've successfully integrated a fully functional chatbot in your application! Give it a try now and see it in action. Want to
take it further? Learn more about what CopilotKit has to offer!

<Cards>
  <Card
    title="Connecting Your Data"
    description="Learn how to connect CopilotKit to your data, application state and user state."
    href="/guides/connect-your-data"
    icon={<LinkIcon />}
  />
  <Card
    title="Generative UI"
    description="Learn how to render custom UI components directly in the CopilotKit chat window."
    href="/guides/generative-ui"
    icon={<LinkIcon />}
  />
  <Card
    title="Frontend Actions"
    description="Learn how to allow your copilot to take applications on frontend."
    href="/guides/frontend-actions"
    icon={<LinkIcon />}
  />
  <Card
    title="CoAgents (LangGraph)"
    description="Check out our section about CoAgents, our approach to building agentic copilots and experiences."
    href="/coagents"
    icon={<LinkIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/(root)/(other)/contributing/docs-contributions.mdx
================================================
---
title: Documentation Contributions
---

We understand that as we move quickly, sometimes our documentation website can be a bit outdated. Therefore, we highly value contributions to our documentation.

## Prerequisites

- [Node.js](https://nodejs.org/en/) 20.x or later
- [pnpm](https://pnpm.io/) v9.x installed globally (`npm i -g pnpm@^9`)

## How To Contribute

<Steps>
  <Step>
  ### Fork The Repository

  First, head over to the [CopilotKit GitHub repository](https://github.com/CopilotKit/CopilotKit) and create a fork.

  Then, clone the forked repository to your local machine:

  ```shell
  git clone https://github.com/<your-username>/CopilotKit
  cd CopilotKit/docs
  ```
  </Step>
  <Step>
  ### Run the Documentation Site Locally

  To run the documentation site locally, install the dependencies and then start the docs in development mode:

  ```shell
  pnpm install
  pnpm run dev
  ```

  The documentation site should be available at [http://localhost:3000](http://localhost:3000).
  </Step>
  <Step>
  ### Make Your Changes

  Now, you can make your changes to the documentation website.

  - All documentation-related files are located in the docs repository
  - You may want to familiarize yourself with [Nextra](https://nextra.site/) to understand how the documentation website is structured.

  <Callout type="info">
    Please ensure you review your changes for grammar, spelling and formatting errors. Also, ensure that links and images are working.
  </Callout>
  </Step>
  <Step>
  ### Review Changes & Submit Pull Request

  Once you are happy with your changes, you can commit and push them. Then, head over to the [Pull Requests page](https://github.com/CopilotKit/CopilotKit/pulls) and create a pull request. Thank you for your contribution!
  </Step>
</Steps>

## Need help?

If you need help with anything, please don't hesitate to reach out to us on [Discord](https://discord.gg/6dffbvGU3D). We have a dedicated [#contributing](https://discord.com/channels/1122926057641742418/1183863183149117561) channel.



================================================
FILE: docs/content/docs/(root)/(other)/contributing/meta.json
================================================
{
  "title": "Contributing",
  "pages": [
    "code-contributions",
    "docs-contributions"
  ]
}


================================================
FILE: docs/content/docs/(root)/(other)/contributing/code-contributions/index.mdx
================================================
---
title: Code Contributions
---

We are grateful for your interest in contributing to CopilotKit. We welcome new contributors and appreciate your help in making CopilotKit better.

This guide will help you get started as smoothly as possible.

## Step 1: Install Prerequisites

- [Node.js](https://nodejs.org/en/) 20.x or later
- [pnpm](https://pnpm.io/) v9.x installed globally (`npm i -g pnpm@^9`)
- [Turborepo v2.x](https://turborepo.org/) installed globally (`npm i -g turbo@2`)

## Step 2: Repository Setup

<Steps>
  <Step>
  ### Fork The Repository
  First, head over to the [CopilotKit repository](https://github.com/CopilotKit/CopilotKit) and create a fork.

  Then, clone your fork to your local machine:
  ```bash
  git clone https://github.com/<your-username>/CopilotKit
  cd CopilotKit/CopilotKit
  ```
  </Step>
  <Step>
  ### Install Dependencies
  <Callout type="info">
    The CopilotKit repository is a monorepo based on [Turborepo](https://turborepo.org/).
    We use [pnpm](https://pnpm.io/) as our package manager.
  </Callout>

  Install the dependencies using pnpm:
  ```bash
  pnpm install
  ```
  </Step>
  <Step>
  ### Build Packages
  To make sure everything works, let's build all packages once:
  ```bash
  turbo run build
  ```
  </Step>
</Steps>

## Step 3: Development Mode
Now that everything is set up and works as expected, you can get start developing:

```bash
# Start all packages in development mode
turbo run dev

# Start a specific package in development mode
turbo run dev --filter="@copilotkit/package-name"
```

Now you can start making changes to the code.

<Callout type="info">
You can find all `@copilotkit/*` packages under the `packages` folder of the monorepo.
</Callout>

## Step 4: Test Changes in Real-Time

In most cases, you want to seamlessly be able to test your changes in real-time as you develop.

We have an `examples` folder in the monorepo with a few different examples using CopilotKit. You can run these examples to test your changes, as they are linked to the `@copilotkit/*` packages in the monorepo.

For this tutorial, we'll use the `next-openai` example, specifically the Presentation Demo (`/presentation`).

In a separate terminal, run the following command to start the example:

```bash
cd examples/next-openai
export OPENAI_API_KEY=<your-openai-api-key>
pnpm run example-dev
```

<Callout type="info">
We use the `pnpm run example-dev` command to run examples, which is different from the `turbo run dev` command we use to work on the individual packages.
</Callout>

Now navigate to http://localhost:3000/presentation and you should see the example running. Any changes you make to the CopilotKit packages will immediately be reflected here.

## Step 5: Formatting and Linting

Before committing your changes, ensure your files are formatted properly by running the following at the root of the monorepo:
```bash
turbo run format
```

Additionally, ensure you have no linting errors:
```bash
turbo run lint
```

## Step 6: Submit a Pull Request

Now that you've made your changes, commit and push them. Then, simply head over to the [Pull Requests page](https://github.com/CopilotKit/CopilotKit/pulls) and create a pull request. Well done!

## Starting a dev environment with hot reload

CopilotKit contains a ready made script for starting a development environment based on one of the CoAgent examples. It lets you work on CopilotKit internals in the core Typescript and Python code while seeing your changes applied to the chosen example.

As a prerequisite, make sure you have GNU parallel and langgraph CLI installed.

Next, go to the `CopilotKit/` directory and run the `example.sh` script for the example you want to work on:

```bash
./scripts/develop/example.sh coagents-starter
```

This will start a development environment with hot reload.

You can optionally run the same example on LangGraph platform by running:

```bash
./scripts/develop/example.sh coagents-starter langgraph-platform
```

## Debugging

Every time you run CopilotKit on localhost, you will be able to see the **CopilotKit Dev Console** in the chat window. The Dev Console provides you with useful functionality to debug your copilot (e.g. see what state the copilot is aware of, actions it can perform, etc).

<Frame description="CopilotKit Dev Console">
  <img
    src="/images/contributing/copilotkit-dev-console.png"
    className="w-auto max-w-[420px]"
  />
</Frame>

If you'd like to disable the Dev Console locally, simply set `showDevConsole` to `false` in your `<CopilotKit />` provider.

## (Advanced) Package Linking

 In some cases, you want to test your CopilotKit changes in your own project. For example, you tried to integrate CopilotKit into your own codebase and encountered a bug you want to fix.

 Conveniently, you can link your local CopilotKit packages to your own project to test your changes.

 Check out the [Advanced: Package Linking](/contributing/code-contributions/package-linking) guide to learn how to do that.

## Need help?

If you need help with anything, please don't hesitate to reach out to us on [Discord](https://discord.gg/6dffbvGU3D). We have a dedicated [#contributing](https://discord.com/channels/1122926057641742418/1183863183149117561) channel.



================================================
FILE: docs/content/docs/(root)/(other)/contributing/code-contributions/package-linking.mdx
================================================
---
title: "Advanced: Package Linking"
---

In this guide, we'll teach you how to link the CopilotKit packages to your own project to test your changes. This way, you can run `turbo run dev` in the CopilotKit monorepo, and see changes in your own project immediately.

## Global Package Linking With `pnpm`

We will use pnpm's [global linking feature](https://pnpm.io/cli/link#pnpm-link---global) to link the CopilotKit packages to your own project.

<Steps>
  <Step>
  ### In The CopilotKit Monorepo
  Assuming you followed all steps in the contribution guide guide, you should have everything set up properly and ready to go.

  Navigate to the CopilotKit monorepo and run the following command to link the packages globally:

  ```bash
  turbo run link:global
  ```
  </Step>
  <Step>
  ### In Your Project
  In your project, ensure you have pnpm configured. This will not prevent you from using npm or yarn as well. But for the purpose of global linking, you must use pnpm.

  ```bash
  cd your-project
  pnpm i
  ```

  Next, link the desired package in your project:
  ```bash
  # For example, to link the @copilotkit/react-core package:
  pnpm link --global @copilotkit/react-core
  ```

  You can run this for all packages, or just the ones you need. Your changes will now be synced.
  </Step>
  <Step>
  ### Unlinking
  Once you are done, you can undo the global linking by running the following command in the CopilotKit monorepo:

  ```bash
  turbo run unlink:global
  ```

  And then in your project:
  ```bash
  pnpm install
  ```

  That's it, everything is now back to normal!
  </Step>
</Steps>

## Need help?

If you need help with anything, please don't hesitate to reach out to us on [Discord](https://discord.gg/6dffbvGU3D). We have a dedicated [#contributing](https://discord.com/channels/1122926057641742418/1183863183149117561) channel.



================================================
FILE: docs/content/docs/(root)/(other)/observability/langsmith.mdx
================================================
---
title: LangSmith
---

To trace your LLM runs with LangSmith, make sure to set up your environment variables:

```bash title=".env"
LANGCHAIN_API_KEY="<your-api-key>"
LANGCHAIN_PROJECT="<your-project-name>"
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com""
```

Next, use the `LangChainAdapter` to trace your CopilotKit runs:

```tsx filename="route.ts" showLineNumbers {6-8}
const { LangChainAdapter } = await import("@copilotkit/runtime");
const { ChatOpenAI } = await import("@langchain/openai");

async function getLangChainOpenAIAdapter() {
  return new LangChainAdapter({
    chainFn: async ({ messages, tools, threadId }) => {
      const model = new ChatOpenAI({
        modelName: "gpt-4-1106-preview",
      }).bindTools(tools, {
        strict: true,
      });
      return model.stream(messages, {
        tools,
        metadata: { conversation_id: threadId },
      });
    },
  });
}
```

Note that `threadId` is passed to the model as `conversation_id` in the metadata.



================================================
FILE: docs/content/docs/(root)/(other)/telemetry/index.mdx
================================================
---
title: Anonymous Telemetry
---

We use anonymous telemetry (metadata-only) to learn how to improve CopilotKit.

* Open-source telemetry is **completely anonymous** 
* We **do not collect any data** about end-users (the users interacting with your copilot)
* We **do not collect any application data** flowing through your system, only CopilotKit metadata
* We do not sell or share any data with third parties
* We do not use cookies or trackers in open-source telemetry
* To minimize the frequency of data sent, we apply batching and sampling to telemetry

## How to opt out of anonymous telemetry

You can opt out of open-source telemetry in multiple ways.

In CopilotRuntime, simply set `COPILOTKIT_TELEMETRY_DISABLED=true`. We also respect [Do Not Track (DNT)](https://consoledonottrack.com/).

Alternatively, you can directly set the `telemetryDisabled` flag to `true` when configuring your Copilot Runtime endpoint.

## How to adjust telemetry sample rate

The default sample rate is `0.05` (5%). You can adjust it by setting the `COPILOTKIT_TELEMETRY_SAMPLE_RATE` to any value between 0 and 1.

## Get in touch

If you have any questions or concerns, please reach out at [hello@copilotkit.ai](mailto:hello@copilotkit.ai).


================================================
FILE: docs/content/docs/(root)/cookbook/state-machine.mdx
================================================
---
title: "State Machines"
description: "Learn how to guide users through multi-step conversations using a state machine pattern."
icon: "lucide/Workflow"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';
import { Accordion } from 'fumadocs-ui/components/accordion';

## Overview

When building chat-based applications, you often need to guide users through a series of steps or **stages**. This recipe shows how to implement a state machine pattern to keep your assistant focused and on-track.

- Live Example: https://state-machine-copilot.vercel.app/
- Example Source Code: https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine

<video src="/images/cookbook/state-machine/demo.mp4" controls autoPlay loop muted playsInline className="rounded-xl shadow-lg border" />

<Callout>
This recipe assumes you have completed the [quickstart guide](/quickstart) and have a basic CopilotKit application running.
</Callout>

### What is a State Machine?

A state machine is a model where your application can be in exactly one state at a time, with clear rules about how to move between states. For chat applications, this means:

- The assistant knows exactly what stage of the conversation it's in
- Only certain actions are available in each stage
- There are clear rules for moving to the next stage

### State Machines in CopilotKit

When implementing a state machine in CopilotKit, the main piece that enables this pattern is the `available` prop present in
most of our hooks. This prop will allow you conditionally control what instructions, context, and actions are available to 
the assistant.

In this recipe, we combine the `available` prop with React state to control when each stage is active, sometimes through
standard deterministic update (button clicks), and sometimes through LLM-driven actions.

<ImageZoom src="/images/state-machine-arch.png" alt="State Machine Architecture" width="1000" height="500"/>

## Basic Implementation

<Steps>
  <Step>
    ### Create a stage

    Each stage is composed of stage-specific instructions, context, and actions. These are enabled or disabled
    as the stage changes via the `available` prop. In this example of a stage, we are extracting a user's name
    and ensuring it is not in a list of other names.

    ```tsx
    import { 
      useCopilotAdditionalInstructions, 
      useCopilotAction, 
      useCopilotReadable 
    } from "@copilotkit/react-core";

    // ...

    /*
     * Not required, but it is convenient to use a dedicated hook to define each 
     * stage of the state machine
     */
    function useStageOne(
      stage: string, 
      setStage: (stage: string) => void, 
      setName: (name: string) => void
    ) {

      /*
       * Each stage can define its own instructions, context, and transitions
       * (implemented via copilotActions). We transition between stages by simply
       * setting the `stage` variable from the handler of the transition:
       */

      // Add additional instructions to the system prompt if this stage is active
      useCopilotAdditionalInstructions({
        instructions: "Ask for the user's name politely.",
        // Use "available" argument to enable this only when the stage is correct! // [!code highlight:2]
        available: stage === "one" ? "available" : "disabled"
      })

      // Add context to the system prompt if this stage is active
      useCopilotReadable({
        description: "Other names",
        value: ["John", "Jane", "Jim"],
        available: stage === "one" ? "available" : "disabled" // [!code highlight]
      })

      // Add an action to the assistant that transitions to the next stage if this stage is active
      useCopilotAction({
        name: "transitionToNextStage",
        description: "Moves to the next stage, only called when the user's name is not in the list of other names",
        available: stage === "one" ? "available" : "disabled", // [!code highlight]
        parameters: [
          { name: "name", type: "string", description: "The name of the user", required: true },
        ],
        handler: ({ name }) => {
          // Perform any state updates given the user's input
          setName(name);

          // Transition to the next stage // [!code highlight:2]
          setStage("two"); 
        }
      });
    }
    ```
  </Step>

  <Step>
    ### Create another stage

    Now, let's create a second stage that's simple and just greets the user by name as a pirate. This is mainly just to
    demonstrate how to add any additional stages. The name will be made available to this stage in the next step.

    ```tsx
    import { useCopilotAdditionalInstructions } from "@copilotkit/react-core";

    // ...

    function useStageTwo(stage: string): void {
      // Add stage-specific instructions - only available in stage "two"
      useCopilotAdditionalInstructions({
        instructions: "Talk to the user about their name and refer to them like a pirate would.",
        available: stage === "two" ? "available" : "disabled"
      })

      // ...
    }

    // Any additional stages you want to add...
    ```
  </Step>

  <Step>
    ### Put it all together

    Finally, bring everything together into a chat component:

    ```tsx
    import { useState } from "react";
    import { CopilotKit, useCopilotReadable } from "@copilotkit/react-core";
    import { CopilotChat } from "@copilotkit/react-ui";

    // ...

    function StateMachineChat() {
      // Track the current stage and user's name
      const [stage, setStage] = useState<string>("one");
      const [name, setName] = useState<string>("");

      // Readable context available across all stages
      useCopilotReadable({
        description: "User's name",
        value: name,
      }, [name])

      // Initialize all stages with their required props
      useStageOne(stage, setStage, setName);
      useStageTwo(stage);
      // any additional stages...

      return (
        <CopilotKit>
          <CopilotChat/>
        </CopilotKit>
      )
    }
    ```

    <Accordions>
      <Accordion title="Full example code">
        ```tsx
        import { useState } from "react";
        import { CopilotChat } from "@copilotkit/react-ui";
        import { 
          CopilotKit, 
          useCopilotAction, 
          useCopilotAdditionalInstructions, 
          useCopilotReadable 
        } from "@copilotkit/react-core";

        /*
        * Not required, but it is convenient to use a dedicated hook to define each 
        * stage of the state machine
        */
        function useStageOne(
          stage: string, 
          setStage: (stage: string) => void, 
          setName: (name: string) => void
        ) {
        
          /*
          * Each stage can define its own instructions, context, and transitions
          * (implemented via copilotActions). We transition between stages by simply
          * setting the `stage` variable from the handler of the transition:
          */
        
          // Add additional instructions to the system prompt if this stage is active
          useCopilotAdditionalInstructions({
            instructions: "Ask for the user's name politely.",
            // Use "available" argument to enable this only when the stage is correct!
            available: stage === "one" ? "available" : "disabled"
          })
        
          // Add context to the system prompt if this stage is active
          useCopilotReadable({
            description: "Other names",
            value: ["John", "Jane", "Jim"],
            available: stage === "one" ? "available" : "disabled"
          })
        
          // Add an action to the assistant that transitions to the next stage if this stage is active
          useCopilotAction({
            name: "transitionToNextStage",
            description: "Moves to the next stage, only call is the user's name is not in the list of other names",
            available: stage === "one" ? "available" : "disabled",
            parameters: [
              { name: "name", type: "string", description: "The name of the user", required: true },
            ],
            handler: ({ name }) => {
              // Perform any state updates given the user's input
              setName(name);
        
              // Transition to the next stage
              setStage("two"); 
            }
          });
        }
        
        function useStageTwo(stage: string) => void) {
          // Add stage-specific instructions - only available in stage "two"
          useCopilotAdditionalInstructions({
            instructions: "Talk to the user about their name and refer to them like a pirate would.",
            available: stage === "two" ? "available" : "disabled"
          })
        
          // ...
        }
        
        // Any additional stages you want to add...

        function StateMachineChat() {
          const [stage, setStage] = useState<string>("one");
          const [ name, setName ] = useState<string>("");

          // Context available across all stages
          useCopilotReadable({
            description: "User's name",
            value: name,
            available: stage === "one" ? "available" : "disabled"
          }, [name])

          useStageOne(stage, setName);
          useStageTwo(stage);
          // any other stages you want to add ...

          return (
            <CopilotKit>
              <CopilotChat/>
            </CopilotKit>
          )
        }
        ```
      </Accordion>
    </Accordions>
  </Step>
  <Step>
    ### 🎉 You've implemented a state machine!
    To recap, each stage hook uses the `available` prop to control when its instructions, context, and actions are accessible to the assistant. This ensures that the assistant only uses the correct tools and context for the current stage.

    Next, let's see some advanced patterns you can implement with these fundamentals.
  </Step>
</Steps>

## Advanced Patterns

This state machine pattern can be extended for complex interactions. Below are some advanced patterns you can implement with code sourced in our 
[car sales example](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine) which you already saw a demo of in the [overview](#overview).

### Stage Transition Approaches

#### Code-driven Stage Transitions
When you want to transition between stages, you can do so by setting the `stage` deterministically, at any point in code.


```tsx
const [stage, setStage] = useState<string>("one");

// ...

<button onClick={() => setStage("two")}>
  Transition to next stage
</button>
```

The car sales demo uses this approach in generative UI (for more on generative UI, see the [section below](#generative-ui)) to transition between stages 
when a user submits their contact information.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-get-contact-info.tsx)

```tsx title="src/lib/stages/use-stage-get-contact-info.tsx"
// imports ...

export function useStageGetContactInfo() {
  const { setContactInfo, stage, setStage } = useGlobalState();

  // ...

  // Render the ContactInfo component and wait for the user's response.
  useCopilotAction(
    {
      name: "getContactInformation",
      description: "Get the contact information of the user",
      available: stage === "getContactInfo" ? "enabled" : "disabled",
      renderAndWaitForResponse: ({ status, respond }) => {
        return (
          <ContactInfo
            status={status}
            // [!code highlight:11]
            onSubmit={(name, email, phone) => {
              // Commit the contact information to the global state.
              setContactInfo({ name, email, phone });

              // Let the agent know that the user has submitted their contact information.
              respond?.("User has submitted their contact information.");

              // This move the state machine to the next stage, buildCar deterministically.
              setStage("buildCar");
            }}
          />
        );
      },
    },
    [stage],
  );
}

```

#### LLM-Driven Stage Transitions

Sometimes you need stages that can transition to different next stages based on user input or LLM-driven actions.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-sell-financing.tsx)

```tsx title="src/lib/stages/use-stage-sell-financing.tsx"
function useStageSellFinancing() {
  const { stage, setStage } = useGlobalState();
  const isActive = stage === "sellFinancing";

  // Provide context to the AI
  useCopilotReadable({
    description: "Financing Information",
    value: "Current promotion: 0% financing for 60 months...",
    available: isActive ? "enabled" : "disabled"
  });

  // Different paths based on financing choice by user, LLM will decide which path to take
  // [!code highlight:14]
  useCopilotAction({
    name: "selectFinancing",
    description: "Select the financing option",
    available: stage === "sellFinancing" ? "enabled" : "disabled",
    handler: () => setStage("getFinancingInfo"),
  }, [stage]);
 
  useCopilotAction({
    name: "selectNoFinancing",
    description: "Select the no financing option",
    available: stage === "sellFinancing" ? "enabled" : "disabled",
    handler: () => setStage("getPaymentInfo"),
  }, [stage]);

}
```

### Generative UI
[Generative UI](/guides/generative-ui) is a pattern where tool calls are streamed and rendered for the user to visualize the progress an agent is making. It can also be combined with the **Human-in-the-loop pattern** to allow checkpoints where the user can intervene and help guide the agent.

When combined with the state machine pattern, you can build deep and interactive conversations with the user. For example, the `buildCar` stage in the car sales demo 
uses generative UI to show the user available cars that they can choose from.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-build-car.tsx)

<video src="/images/cookbook/state-machine/gen-ui.mp4" controls autoPlay loop muted playsInline className="rounded-xl shadow-lg border" />

<Tabs items={["Build Car Stage", "Show Car Component"]}>
  <Tab value="Build Car Stage">
    ```tsx title="src/lib/stages/use-stage-build-car.tsx"
    export function useStageBuildCar() {
      const { setSelectedCar, stage, setStage } = useGlobalState();

      // ...

      useCopilotAction({
        name: "showCar",
        description: "Show a single car that you have in mind. Do not call this more than once, call `showMultipleCars` if you have multiple cars to show.",
        available: stage === "buildCar" ? "enabled" : "disabled", // [!code highlight]
        parameters: [
          // excluded for brevity, see source code link above for more detail
        ],
        renderAndWaitForResponse: ({ args, status, respond }) => {
          const { car } = args;
          return (
            // [!code highlight:11]
            <ShowCar
              car={(car as Car) || ({} as Car)}
              status={status}
              onSelect={() => {
                setSelectedCar((car as Car) || ({} as Car));
                respond?.("User has selected a car you can see it in your readables, the system will now move to the next state, do not call call nextState.");
                setStage("sellFinancing");
              }}
              onReject={() => respond?.("User wants to select a different car, please stay in this state and help them select a different car")}
            />
          );
        },
      }, [stage]);
      // ...
    }
    ```
  </Tab>
  <Tab value="Show Car Component">
    ```tsx title="src/components/generative-ui/show-car.tsx"
    export function ShowCar({ car, onSelect, onReject, status, className }: ShowCarProps) {
      const carDetails = [
        { label: "Make", value: car.make },
        { label: "Model", value: car.model },
        { label: "Year", value: car.year },
        { label: "Color", value: <ColorDisplay color={car.color} /> },
        { label: "Price", value: `$${car.price?.toLocaleString()}`, bold: true },
      ];

      const cardStyles = cn("min-w-[300px] max-w-sm bg-white rounded-xl overflow-hidden p-0 gap-0", className);
      const informationWrapperStyles = "space-y-6 pt-4 pb-4";
      const acceptButtonStyles = "flex-1 bg-blue-600 text-white px-6 py-3 rounded-lg font-medium hover:bg-blue-700 transition-all duration-200 shadow-sm hover:shadow-md";
      const rejectButtonStyles = "flex-1 bg-gray-50 text-gray-700 px-6 py-3 rounded-lg font-medium hover:bg-gray-100 transition-all duration-200";

      return (
        <AnimatedCard status={status} className={cardStyles}>
          <CarImage car={car} />

          <div className={informationWrapperStyles}>
            <div className="space-y-2 px-6">
              <div className="text-2xl font-semibold text-gray-900">
                {car.year} {car.make} {car.model}
              </div>
              {carDetails.map(({ label, value, bold }) => (
                <div key={label} className="flex justify-between items-center py-1">
                  <span className="text-gray-500 text-sm">{label}</span>
                  <span className={cn("text-gray-900", bold ? "font-semibold text-lg" : "text-sm")}>
                    {value}
                  </span>
                </div>
              ))}
            </div>

            <div className={cn("px-6 pt-2", status === "complete" ? "hidden" : "animate-fade-in")}>
              <hr className="mb-4 border-gray-100" />
              <div className="flex gap-3">
                {onReject && (
                  <button className={rejectButtonStyles} onClick={onReject}>
                    Other options
                  </button>
                )}
                <button className={acceptButtonStyles} onClick={onSelect}>
                  Select
                </button>
              </div>
            </div>
          </div>
        </AnimatedCard>
      );
    }
    ```
  </Tab>
</Tabs>

### Initial message loading
To add an initial message to the chat, we can use the `appendMessage` function provided by the `useCopilotChat` hook.

<Callout title="Improved experience coming soon">
  This is a temporary solution and we will be improving this in the near future.
</Callout>

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/components/car-sales-chat.tsx)

```tsx title="src/components/car-sales-chat.tsx"
import { useCopilotChat } from "@copilotkit/react-core";

// ...

const { appendMessage, isLoading } = useCopilotChat();

// Render an initial message when the chat is first loaded
useEffect(() => {
  if (initialMessageSent || isLoading) return;

  setTimeout(() => {
    appendMessage(
      new TextMessage({
        content:
          "Hi, I'm Fio, your AI car salesman. First, let's get your contact information before we get started.",
        role: MessageRole.Assistant,
      }),
    );
    setInitialMessageSent(true);
  }, 500);
}, [initialMessageSent, appendMessage, isLoading]);

// ...

```

### Tools When Entering a Stage

Sometimes you'll want to guide the AI to call a specific tool when entering a stage. 

The payment info stage demonstrates how to guide the AI to make specific tool calls by 
adding additional instructions to call the `getPaymentInformation` tool explicitly.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-get-payment-info.tsx)

```tsx title="src/lib/stages/use-stage-get-payment-info.tsx"
export function useStageGetPaymentInfo() {
  const { setCardInfo, stage, setStage } = useGlobalState();

  // Conditionally add additional instructions for the agent's prompt.
  useCopilotAdditionalInstructions({
    available: stage === "getPaymentInfo" ? "enabled" : "disabled",
    // [!code highlight:6]
    instructions: `
        CURRENT STATE: You are now getting the payment information of the user. 
        Say, 'Great! Now I need to get your payment information.' and MAKE SURE 
        to then call the 'getPaymentInformation' action.
    `,
  }, [stage]);

  // ...

}
```

## Recap

This recipe introduced a powerful pattern for building conversational AI applications using state machines. By breaking down complex interactions into discrete stages, each with
focused instructions and actions, we can create more maintainable and user-friendly experiences. 

With this pattern, you can start building your own multi-stage conversations. 

## Need Help?

Need help or want to share what you've built? Join our [Discord community](https://discord.gg/6dffbvGU3D) or open an issue on [GitHub](https://github.com/CopilotKit/CopilotKit/issues/new/choose).



================================================
FILE: docs/content/docs/(root)/guides/authenticated-actions.mdx
================================================
---
title: "Authenticated Actions"
icon: "lucide/Lock"
---

## Introduction

CopilotKit Cloud enables secure propagation of authentication state within AI conversations, allowing your copilot to interact with authenticated backend services and tools on behalf of the user.

This feature is only available with [CopilotKit Cloud](https://cloud.copilotkit.ai/).

## Overview

When building AI copilots that interact with user-specific data or services (like calendars, emails, or custom APIs), you need to ensure that:

1. The user is properly authenticated
2. The authentication state is securely propagated to backend tools
3. The copilot maintains proper authorization context

## How It Works

### Authentication Flow

1. Your frontend app configures authentication state using `authConfig_c`
2. When a user authenticates, their auth state (headers, metadata) is securely captured
3. CopilotKit Cloud Runtime maintains this auth context throughout the conversation
4. When the LLM or runloop needs to call your registered endpoints/tools:
   - All auth headers are automatically propagated
   - Your endpoints receive the same auth context
   - Tools can verify user identity and permissions

### Example Scenario

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant CloudRuntime
    participant YourAPI

    User->>Frontend: Authenticates
    Frontend->>CloudRuntime: Auth state captured
    Note over CloudRuntime: Maintains auth context
    CloudRuntime->>YourAPI: Calls with propagated headers
    YourAPI->>YourAPI: Verifies auth
    YourAPI->>CloudRuntime: Authenticated response
```

This means your backend tools and APIs:

- Receive the same authentication headers as your frontend
- Can verify user identity and permissions
- Maintain security context throughout the AI interaction
- Don't need additional auth handling specific to CopilotKit

## Frontend Implementation

### Configure Authentication State

```tsx
import { CopilotKit } from "@copilotkit/react-core";

interface AuthState {
  status: "authenticated" | "unauthenticated";
  authHeaders: Record<string, string>;
  userId?: string;
  metadata?: Record<string, any>;
}

// Your SignInComponent component
function SignInComponent({
  onSignInComplete,
}: {
  onSignInComplete: (authState: AuthState) => void;
}) {
  const handleAuth = async () => {
    // Your auth logic (e.g., OAuth, custom auth)
    const authState = {
      status: "authenticated",
      authHeaders: {
        Authorization: "Bearer your_token",
        // Add any other headers needed by your backend
      },
      userId: "user_123",
      metadata: {
        email: "user@example.com",
        // Any other user context needed by tools
      },
    };

    onAuthComplete(authState);
  };

  return <button onClick={handleAuth}>Authenticate</button>;
}

// Root configuration
export default function App() {
  return (
    <CopilotKit
      publicApiKey={process.env.COPILOTKIT_PUBLIC_API_KEY}
      authConfig_c={{
        SignInComponent,
      }}
    >
      {/* Your app */}
    </CopilotKit>
  );
}
```

## Backend Integration

Your backend endpoints will receive the authentication context automatically. Example of a tool endpoint:

```typescript
// Example backend endpoint
async function handleCalendarRequest(req, res) {
  // Auth headers from the frontend are automatically available
  const authHeader = req.headers.authorization;
  const userId = req.headers["x-user-id"];

  // Verify authentication as you normally would
  if (!isValidAuth(authHeader)) {
    return res.status(401).json({ error: "Unauthorized" });
  }

  // Proceed with authenticated operation
  const calendar = await getCalendarForUser(userId);
  return res.json(calendar);
}
```

## Best Practices

1. **Authentication Headers**

   - Include all necessary auth tokens
   - Add relevant user context
   - Consider token expiration
   - Handle refresh tokens if needed

2. **Backend Security**

   - Always verify auth headers
   - Implement proper validation
   - Use secure token verification
   - Handle expired tokens gracefully

3. **Error Handling**
   - Provide clear auth errors
   - Handle token refresh scenarios
   - Implement proper fallbacks
   - Give helpful user feedback



================================================
FILE: docs/content/docs/(root)/guides/backend-actions_old.mdx
================================================
---
title: "Backend Actions & Agents"
description: "Learn how to enable your Copilot to take actions in the backend."
---

<Steps>
<Step>
### Find your CopilotRuntime

The starting point for backend actions is the `CopilotRuntime` you setup during quickstart (the CopilotKit backend endpoint).
For a refresher, see [Self-Hosting](/guides/self-hosting) (or alternatively, revisit the [quickstart](/quickstart)).

Backend actions can return (and stream) values -- which will be piped back to the Copilot system and which may result in additional agentic action.
</Step>

<Step>
### Integrate your backend actions

Choose any of the methods below to integrate backend actions into your Copilot system.<br/>
**They can be mixed-and-matched as desired.**

<Tabs items={['TypeScript / Node.js', 'LangChain JS', 'LangServe', 'Python + Remote Actions']}>


  {/* Native Backend Action tab */}
  <Tab value="TypeScript / Node.js">

  When you initialize the `CopilotRuntime`, you can provide backend actions in the same format as frontend Copilot actions.

  **Note that `actions` is not merely an array of actions, but rather a _generator_ of actions.**
  This generator takes `properties` and `url` as input -- which means you can customize which backend actions are made available according to the current frontend URL,
  as well as custom properties you can pass from the frontend.

    ```tsx title="/api/copilotkit/route.ts"
    const runtime = new CopilotRuntime({
      actions: ({properties, url}) => {
        // You can use the input parameters to the actions generator to expose different backend actions to the Copilot at different times: 
        // `url` is the current URL on the frontend application.
        // `properties` contains custom properties you can pass from the frontend application.
        
        return [
          {
            name: "fetchNameForUserId",
            description: "Fetches user name from the database for a given ID.",
            parameters: [
              {
                name: "userId",
                type: "string",
                description: "The ID of the user to fetch data for.",
                required: true,
              },
            ],
            handler: async ({userId}: {userId: string}) => {
              // do something with the userId
              // return the user data
              return {
                name: "Darth Doe",
              };
            },
          },
        ]
      }
    });

    // ... define the route using the CopilotRuntime.
    ```
  </Tab>

  {/* LangChain JS Backend Action tab */}
  <Tab value="LangChain JS">
  The backend action interface also supports LangChain JS natively.
  Simply return chain.stream and the results will be piped back to the Copilot.

    ```tsx title="/api/copilotkit/route.ts"
    import { ChatOpenAI } from "@langchain/openai";
    import { ChatPromptTemplate } from "@langchain/core/prompts";

    const runtime = new CopilotRuntime({
      actions: ({properties, url}) => {
        return [
          {
            name: "generateJokeForTopic",
            description: "Generates a joke for a given topic.",
            parameters: [
              {
                name: "topic",
                type: "string",
                description: "The topic to generate a joke about.",
                required: true,
              },
            ],
            handler: async ({topic}: {topic: string}) => {
              const prompt = ChatPromptTemplate.fromMessages([
                [
                  "system",
                  "You are a witty comedian. Generate a short, funny joke about the given topic. But make it sound like a pirate joke!",
                ],
                ["user", "Topic: {topic}"],
              ]);
              const chain = prompt.pipe(new ChatOpenAI());
              return chain.stream({
                topic: topic,
              });
            },
          },
        ]
      }
    });
    ```
  </Tab>

    {/* LangServe tab */}
  <Tab value="LangServe">
    LangServe allows you to integrate LangChain chains hosted as separate services into your CopilotKit application.
    You can easily connect to existing chains, whether they're written in Python or JavaScript.

    ```tsx title="/api/copilotkit/route.ts"
    const runtime = new CopilotRuntime({
      langserve: [
        {
          chainUrl: "http://my-langserve.chain",
          name: "performResearch",
          description: "Performs research on a given topic.",
        },
      ],
    });

    // ... define the route using the CopilotRuntime.
    ```

  </Tab>


  {/* Remote Actions tab */}
  <Tab value="Python + Remote Actions">
    Remote actions allow you to integrate external services or APIs into your CopilotKit application.
    Any service that conforms to the Open-Source CopilotKit backend protocol can be served here.

    We provide a Python backend SDK which includes support for [LangGraph-powered CoAgents!](/coagents).
    For instructions how to set it up, see [here]().

    ```tsx title="/api/copilotkit/route.ts"
    const runtime = new CopilotRuntime({
      remoteEndpoints: [
        {
          url: `${BASE_URL}/copilotkit`,
        },
      ],
    });

    // ... define the route using the CopilotRuntime.
    ```

  </Tab>

</Tabs>

</Step>

<Step>
### Test it out!
After defining the action, ask the copilot to perform the task. Watch it select the correct task, execute it, and stream back relevant responses.
</Step>
</Steps>



================================================
FILE: docs/content/docs/(root)/guides/bring-your-own-llm.mdx
================================================
---
title: "Bring Your Own LLM"
description: "Learn how to use any LLM with CopilotKit."
icon: "lucide/Plug"
---

import LLMAdapters from "@/snippets/llm-adapters.mdx";

<LLMAdapters components={props.components} />


================================================
FILE: docs/content/docs/(root)/guides/copilot-suggestions.mdx
================================================
---
title: "Copilot Suggestions"
description: "Learn how to auto-generate suggestions in the chat window based on real time application state."
icon: "lucide/CopyCheck"
---

import UseClientCalloutSnippet from "@/snippets/use-client-callout.mdx";

<Callout type="warn">
  useCopilotChatSuggestions is experimental. The interface is not final and can
  change without notice.
</Callout>

[`useCopilotChatSuggestions`](/reference/hooks/useCopilotChatSuggestions) is a React hook that generates suggestions in the chat window based on real time application state.

<Frame>
  <img
    src="/images/use-copilot-chat-suggestions/use-copilot-chat-suggestions.gif"
    width="500"
  />
</Frame>


<Steps>

<Step>
### Simple Usage
 
```tsx
import { useCopilotChatSuggestions } from "@copilotkit/react-ui"; // [!code highlight]
 
export function MyComponent() {
  // [!code highlight:9]
  useCopilotChatSuggestions(
    {
      instructions: "Suggest the most relevant next actions.",
      minSuggestions: 1,
      maxSuggestions: 2,
    },
    [relevantState],
  );
}
```
</Step>

<Step>
### Dependency Management
 
```tsx
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";
 
export function MyComponent() {
  useCopilotChatSuggestions(
    {
      instructions: "Suggest the most relevant next actions.",
      minSuggestions: 1,
      maxSuggestions: 2,
    },
    [relevantState], // [!code highlight]
  );
}
```
 
In the example above, the suggestions are generated based on the given instructions.
The hook monitors `relevantState`, and updates suggestions accordingly whenever it changes.

</Step>


<Step>
  <UseClientCalloutSnippet components={props.components} />
</Step>


</Steps>

## Next Steps

- Check out [how to customize the suggestions look](/guides/custom-look-and-feel/bring-your-own-components#suggestions).
- Check out the [useCopilotChatSuggestions reference](/reference/hooks/useCopilotChatSuggestions) for more details.



================================================
FILE: docs/content/docs/(root)/guides/copilot-textarea.mdx
================================================
---
title: "Copilot Textarea"
description: "Learn how to use the Copilot Textarea for AI-powered autosuggestions."
icon: "lucide/TextSelect"
---

<Frame>
  <img src="/images/CopilotTextarea.gif" width="500" />
</Frame>

`<CopilotTextarea>` is a React component that acts as a drop-in replacement for the standard `<textarea>`,
 offering enhanced autocomplete features powered by AI. It is context-aware, integrating seamlessly with the
[`useCopilotReadable`](/reference/hooks/useCopilotReadable) hook to provide intelligent suggestions based on the application context.
 
In addition, it provides a hovering editor window (available by default via `Cmd + K` on Mac and `Ctrl + K` on Windows) that allows the user to
suggest changes to the text, for example providing a summary or rephrasing the text.

<Callout type="warn">
  This guide assumes you have completed the [quickstart](/quickstart) and have successfully set up CopilotKit.
</Callout>

<Steps>
<Step>
### Install `@copilotkit/react-textarea`
    
```package-install
npm install @copilotkit/react-textarea
```
</Step>
<Step>
### Import Styles 
Import the default styles in your root component (typically `layout.tsx`) :

```tsx title="layout.tsx"
import "@copilotkit/react-textarea/styles.css";
```
</Step>
<Step>
### Add `CopilotTextarea` to Your Component 
Below you can find several examples showing how to use the `CopilotTextarea` component in your application.

<Tabs groupId="example" items={["Example 1", "Example 2"]}>
  <Tab value="Example 1">
    ```tsx title="TextAreaComponent.tsx"
    import { FC, useState } from "react";
    import { CopilotTextarea } from '@copilotkit/react-textarea';

    const ExampleComponent: FC = () => {
      const [text, setText] = useState<string>('');

      return (
        <CopilotTextarea // [!code highlight]
          className="w-full p-4 border border-gray-300 rounded-md"
          value={text}
          onValueChange={setText}
          // [!code highlight:5]
          autosuggestionsConfig={{
            textareaPurpose: "the body of an email message",
            chatApiConfigs: {},
          }}
        />
      );
    };
    ```
  </Tab>
  <Tab value="Example 2">
    ```tsx title="TextAreaComponent.tsx"
    import { FC, useState } from "react";
    import { CopilotTextarea } from "@copilotkit/react-textarea";

    const TextAreaComponent: FC = () => {
      const [text, setText] = useState<string>("");

      return (
        <CopilotTextarea // [!code highlight]
          // standard textarea args
          className="w-full p-4 border border-gray-300 rounded-md"
          value={text}
          onValueChange={setText}
          placeholder="Start typing..."

          // ai-specific configs
          // [!code highlight:10]
          autosuggestionsConfig={{
            textareaPurpose: "Write your message here",
            chatApiConfigs: {
              suggestionsApiConfig: {
                maxTokens: 50,
                stop: ["\n", ".", "?"],
              },
            },
          }}
        />
      );
    };
    ```
  </Tab>
</Tabs>
</Step>
</Steps>

## Next Steps

- We highly recommend that you check out our simple [Copilot Textarea Tutorial](/tutorials/ai-powered-textarea/overview).
- Check out the full [CopilotTextarea reference](/reference/components/CopilotTextarea)


================================================
FILE: docs/content/docs/(root)/guides/custom-ai-assistant-behavior.mdx
================================================
---
title: "Customize Instructions"
description: "Learn how to customize the behavior of your AI assistant."
icon: "lucide/NotepadText"
---

There are three main ways to customize the behavior of your AI assistant:
- [Appending to the prompt](#appending-to-the-prompt-recommended)
- [Passing the `instructions` parameter](#passing-the-instructions-parameter)
- [Overwriting the default `makeSystemMessage`](#overwriting-the-default-makesystemmessage-not-recommended)

## Appending to the prompt (Recommended)
CopilotKit provides the [useCopilotAdditionalInstructions](/reference/hooks/useCopilotAdditionalInstructions) hook which allows you to add content to the prompt with whatever
you want.

```tsx title="Home.tsx"
import { CopilotKit, useCopilotAdditionalInstructions } from "@copilotkit/react-core";
import { CopilotPopup } from "@copilotkit/react-ui"
 
function Chat() {
  useCopilotAdditionalInstructions({
    instructions: "Do not answer questions about the weather.",
  });
  return <CopilotPopup />
}

export function Home() {
  return (
    <CopilotKit>
      <Chat />
    </CopilotKit>
  )
}
```

You can even conditionally add instructions based on the application's state.

```tsx title="Home.tsx"
function Chat() {
  const [showWeather, setShowWeather] = useState(false);

  useCopilotAdditionalInstructions({
    instructions: "Do not answer questions about the weather.",
    available: showWeather ? "enabled" : "disabled"
  }, showWeather);
}
```

## Advanced

If appending to the prompt is not enough, you have some other options, specifically around updating the prompt directly.

### Passing the `instructions` parameter

The `instructions` parameter is the recommended way to customize AI assistant behavior. It will remain compatible with performance optimizations to the CopilotKit platform.

It can be customized for **Copilot UI** as well as **programmatically**:

<Tabs groupId="approach" items={['Copilot UI', 'Headless UI']}>
  <Tab value="Copilot UI">
    Copilot UI components accept an `instructions` property:

    ```tsx title="CustomCopilot.tsx"
    import { CopilotChat } from "@copilotkit/react-ui";

    <CopilotChat
      instructions="You are a helpful assistant specializing in tax preparation. Provide concise and accurate answers to tax-related questions." // [!code highlight]
      labels={{
        title: "Tax Preparation Assistant",
        initial: "How can I help you with your tax preparation today?",
      }}
    />
    ```

  </Tab>

  <Tab value="Headless UI">
    The `instructions` parameter can also be set programmatically via `setChatInstructions` method, coming from `useCopilotContext`, allowing for dynamic customization based on the application's state or user interactions.

    ```tsx title="Home.tsx"
    import { useEffect } from 'react';
    import { useCopilotContext } from "@copilotkit/react-core";

    const Home: React.FC = () => {
      // [!code highlight:6]
      const { setChatInstructions } = useCopilotContext();

      useEffect(() => {
        setChatInstructions("You are assisting the user as best as you can. Answer in the best way possible given the data you have.");
      }, [setChatInstructions]);

      return <>{/* Your components */}</>;
    };
    ```

  </Tab>
</Tabs>


### Overwriting the default system message

For cases requiring complete control over the system message, you can use the `makeSystemMessage` function. We highly recommend reading CopilotKit's default system message before deciding to overwrite it, which can be found [here](https://github.com/CopilotKit/CopilotKit/blob/e48a34a66bb4dfd210e93dc41eee7d0f22d1a0c4/CopilotKit/packages/react-core/src/hooks/use-copilot-chat.ts#L240-L258).

<Callout type="warn">
This approach is **not recommended** as it may interfere with more advanced optimizations made by CopilotKit. **Only use this approach if the other options are not enough.**
</Callout>

<Tabs groupId="approach" items={['Copilot UI', 'Headless UI']}>
  <Tab value="Copilot UI">
    ```tsx filename="CustomCopilot.tsx" showLineNumbers {10}
    import { CopilotChat } from "@copilotkit/react-ui";

    const CustomCopilot: React.FC = () => (
      <CopilotChat
        instructions="You are a knowledgeable tax preparation assistant. Provide accurate and concise answers to tax-related questions, guiding users through the tax filing process."
        labels={{
          title: "Tax Preparation Assistant",
          initial: "How can I assist you with your taxes today?",
        }}
        makeSystemMessage={myCustomTaxSystemMessage} // [!code highlight]
      />
    );
    ```

  </Tab>
  <Tab value="Headless UI">
    ```tsx filename="CustomCopilotHeadless.tsx" showLineNumbers {4, 6}
    import { useCopilotChat } from "@copilotkit/react-core";

    const CustomCopilotHeadless: React.FC = () => {
      // [!code highlight:5]
      const chat = useCopilotChat({
        // ...
        makeSystemMessage: myCustomMakeSystemMessage,
      });

      return (
        <div>
          {/* Render your custom UI using visibleMessages */}
        </div>
      );
    };
    ```
  </Tab>
</Tabs>




================================================
FILE: docs/content/docs/(root)/guides/front-backend-action-pairing.mdx
================================================
---
title: "Frontend - Backend Action Pairing"
description: "Learn how to react to a Backend only operation on the Frontend."
icon: "lucide/Wrench"
---
import { LinkIcon } from "lucide-react";
import UseClientCalloutSnippet from "@/snippets/use-client-callout.mdx";

Some actions, although having UI implications, would need to be performed on a Backend  secured environment.
In order to "render UI from the Backend", it is possible to pair a Frontend only action with its Backend equivalent, so one execution follows the other.

<Steps>

    <Step>
        ### Set up a backend action

        Follow the [Backend Actions guides](/guides/backend-actions) and set up an action on the Backend.

        For demonstration purposes, we'll assume the same action as shown in this guide:
        ```tsx title="/api/copilotkit/route.ts"
        const runtime = new CopilotRuntime({
        // ... existing configuration
        actions: ({properties, url}) => {
        return [
    {
        name: "fetchUser",
        description: "Fetches user name from the database for a given ID.",
        parameters: [
    {
        name: "userId",
        type: "string",
        description: "The ID of the user to fetch data for.",
        required: true,
    },
        ],
        handler: async ({userId}: {userId: string}) => {
        // do something with the userId
        // return the user data
        return {
        name: "Darth Doe",
    };
    },
    },
        ]
    }
    });

        // ... rest of your route definition
        ```
    </Step>

    <Step>
        ### Pair a frontend action

        On the UI layer, define a "frontend" only action which will correspond to the Backend action.
        Notice how the expected parameters match what's returned from the Backend action handler

        ```tsx title="YourComponent.tsx"
        "use client" // only necessary if you are using Next.js with the App Router.
        import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

        export function MyComponent() {
        const [userName, setUserName] = useState<string>('stranger');

        // Define Copilot action
        useCopilotAction({
        name: "displayUser", // Names of the actions match between Backend and Frontend // [!code highlight]
        description: "Display the user name fetched from the backend",
        pairedAction: "fetchUser", // Choose which backed action this is paired with // [!code highlight]
        available: "frontend", // Optional :mark it as frontend only if the FE and BE action name matches // [!code highlight]
        parameters: [
    {
        name: "name",
        type: "string",
        description: "The user name",
    },
        ],
        handler: async ({ name }) => {
        setUserName(name);
    },
    });

        return (
        <h1>
        hello {userName}
    </ul>
    );
    }
    ```
</Step>

<Step>
    <UseClientCalloutSnippet components={props.components} />
</Step>


<Step>
    ### Test it out!
    After adding the action, test it by asking the copilot to perform the task. Observe how it selects the correct task, executes it, and the UI action defined is reflecting the result.
</Step>

</Steps>


## Next Steps

<Cards>
    <Card
        title="useCopilotAction Reference"
        description="Refer to the documentation for the useCopilotAction hook."
        href="/reference/hooks/useCopilotAction"
        icon={<LinkIcon />}
    />
    <Card
        title="Frontend Actions"
        description="Learn how to enable your Copilot to take actions in the frontend."
        href="/guides/frontend-actions"
        icon={<LinkIcon />}
    />
    <Card
        title="Actions + Generative UI"
        description="Learn how to render custom UI components alongside your actions, directly in the CopilotKit chat window."
        href="/guides/generative-ui"
        icon={<LinkIcon />}
    />
    <Card
        title="Backend Actions"
        description="Enable backend services to trigger actions via copilot backend hooks."
        href="/guides/backend-actions"
        icon={<LinkIcon />}
    />
</Cards>


================================================
FILE: docs/content/docs/(root)/guides/frontend-actions.mdx
================================================
---
title: "Frontend Actions"
description: "Learn how to enable your Copilot to take actions in the frontend."
icon: "lucide/Wrench"
---
import { LinkIcon } from "lucide-react";
import UseClientCalloutSnippet from "@/snippets/use-client-callout.mdx";

# Let the Copilot Take Action

<Steps>

<Step>
### `useCopilotAction`

In addition to understanding state, you can empower the copilot to take actions. Use the [`useCopilotAction`](/reference/hooks/useCopilotAction) hook to define specific tasks that the copilot can perform based on user input.

```tsx title="YourComponent.tsx"
"use client" // only necessary if you are using Next.js with the App Router. // [!code highlight]
import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

export function MyComponent() {
  const [todos, setTodos] = useState<string[]>([]);

  // Define Copilot action
  useCopilotAction({
    name: "addTodoItem",
    description: "Add a new todo item to the list",
    parameters: [
      {
        name: "todoText",
        type: "string",
        description: "The text of the todo item to add",
        required: true,
      },
    ],
    handler: async ({ todoText }) => {
      setTodos([...todos, todoText]);
    },
  });

  return (
    <ul>
      {todos.map((todo, index) => (
        <li key={index}>{todo}</li>
      ))}
    </ul>
  );
}
```

<Accordions>
  <Accordion title="Changing where/when the action is executed">
    The `available` prop defaults to `enabled`, but there are other options:
    - `enabled`: The action is enabled and can be used by the LLM or [CoAgent](/coagents/).
    - `disabled`: The action is disabled and cannot be used by the LLM or [CoAgent](/coagents/).
    - `remote`: When using a [CoAgent](/coagents/), the action is only passed to the the CoAgent, but not the LLM.
    - `frontend`: The action will only render a paired backend action. For more information, check the reference documentation for [useCopilotAction](/reference/hooks/useCopilotAction).
  </Accordion>
</Accordions>
</Step>

<Step>
  <UseClientCalloutSnippet components={props.components} />
</Step>


<Step>
### Test it out!
After defining the action, ask the copilot to perform the task. For example, you can now ask the copilot to "select an employee" by specifying the `employeeId`.

<Frame>
  <img 
    src="/images/copilot-action-example.gif" 
    alt="Example of Copilot action" 
    className="rounded-lg shadow-md w-full max-w-md mx-auto"
  />
</Frame>
</Step>

</Steps>


## Next Steps

<Cards>
  <Card
    title="useCopilotAction Reference"
    description="Refer to the documentation for the useCopilotAction hook."
    href="/reference/hooks/useCopilotAction"
    icon={<LinkIcon />}
  />
  <Card
    title="Actions + Generative UI"
    description="Learn how to render custom UI components alongside your actions, directly in the CopilotKit chat window."
    href="/guides/generative-ui"
    icon={<LinkIcon />}
  />
  <Card
    title="Backend Actions"
    description="Enable backend services to trigger actions via copilot backend hooks."
    href="/guides/backend-actions"
    icon={<LinkIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/(root)/guides/generative-ui.mdx
================================================
---
title: "Generative UI"
description: "Learn how to embed custom UI components in the chat window."
icon: "lucide/LayoutDashboard"
---

import UseClientCalloutSnippet from "@/snippets/use-client-callout.mdx";

# Render custom components in the chat UI

When a user interacts with your Copilot, you may want to render a custom UI component. [`useCopilotAction`](/reference/hooks/useCopilotAction) allows to give the LLM the
option to render your custom component through the `render` property.

<Tabs groupId="gen-ui-type" items={['Render a component', 'Fetch data & render', 'renderAndWaitForResponse (HITL)', 'Render strings', 'Catch all renders']}>

  <Tab value="Render a component">
    [`useCopilotAction`](/reference/hooks/useCopilotAction) can be used with a `render` function and without a `handler` to display information or UI elements within the chat.
    
    Here's an example to render a calendar meeting.

    <Frame>
      <img
        src="/images/render-only-example.png"
        alt="Example of render-only Copilot action"
        className="w-full h-auto max-w-md"
      />
    </Frame>

    ```tsx
    "use client" // only necessary if you are using Next.js with the App Router. // [!code highlight]
    import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

    export function YourComponent() {
      useCopilotAction({ // [!code highlight]
        name: "showCalendarMeeting",
        description: "Displays calendar meeting information",
        parameters: [
          {
            name: "date",
            type: "string",
            description: "Meeting date (YYYY-MM-DD)",
            required: true
          },
          {
            name: "time",
            type: "string",
            description: "Meeting time (HH:mm)",
            required: true
          },
          {
            name: "meetingName",
            type: "string",
            description: "Name of the meeting",
            required: false
          }
        ],
        // [!code highlight:15]
        render: ({ status, args }) => {
          const { date, time, meetingName } = args;

          if (status === 'inProgress') {
            return <LoadingView />; // Your own component for loading state
          } else {
            const meetingProps: CalendarMeetingCardProps = {
              date: date,
              time,
              meetingName
            };
            return <CalendarMeetingCardComponent {...meetingProps} />;
          }
        },
      });

      return (
        <>...</>
      );
    }
    ```

  </Tab>

  <Tab value="Fetch data & render">
    The [`useCopilotAction`](/reference/hooks/useCopilotAction) hook accepts both `handler` and `render` methods. The `handler` executes the action, while `render` displays UI in the copilot chat window.

    <Frame>
      <img
        src="/images/fetch-and-render.gif"
        alt="Example of fetch data + render in copilot chat"
        className="w-full h-auto max-w-md"
      />
    </Frame>

    ```tsx
    "use client" // only necessary if you are using Next.js with the App Router. // [!code highlight]
    import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

    useCopilotAction({ // [!code highlight]
      name: "showLastMeetingOfDay",
      description: "Displays the last calendar meeting for a given day",
      parameters: [
        {
          name: "date",
          type: "string",
          description: "Date to fetch the last meeting for (YYYY-MM-DD)",
          required: true
        }
      ],
      // [!code highlight:17]
      handler: async ({ date }) => {
        // some async operation which can return a result:
        const lastMeeting = await fetchLastMeeting(new Date(date));
        return lastMeeting;
      },
      render: ({ status, result }) => {
        if (status === 'executing' || status === 'inProgress') {
          // show a loading view while the action is executing, i.e. while the meeting is being fetched
          return <LoadingView />;
        } else if (status === 'complete') {
          // show the meeting card once the action is complete
          return <CalendarMeetingCardComponent {...result} />;
        } else {
          return <div className="text-red-500">No meeting found</div>;
        }
      },
    });
    ```

  </Tab>

  <Tab value="renderAndWaitForResponse (HITL)">
    The `renderAndWaitForResponse` method allows for returning values asynchronously from the render function.

    This is great for Human-in-the-Loop flows, where the AI assistant can prompt the end-user with a choice (rendered inside the chat UI),
    and the user can make the choice by pressing a button in the chat UI.

    ```tsx
    "use client" // only necessary if you are using Next.js with the App Router. // [!code highlight]
    import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

    useCopilotAction({ // [!code highlight]
      name: "handleMeeting",
      description: "Handle a meeting by booking or canceling",
      parameters: [
        {
          name: "meeting",
          type: "string",
          description: "The meeting to handle",
          required: true,
        },
        {
          name: "date",
          type: "string",
          description: "The date of the meeting",
          required: true,
        },
        {
          name: "title",
          type: "string",
          description: "The title of the meeting",
          required: true,
        },
      ],
      // [!code highlight:12]
      renderAndWaitForResponse: ({ args, respond, status }) => {
        const { meeting, date, title } = args;
        return (
          <MeetingConfirmationDialog
            meeting={meeting}
            date={date}
            title={title}
            onConfirm={() => respond?.('meeting confirmed')}
            onCancel={() => respond?.('meeting canceled')}
          />
        );
      },
    });
    ```

  </Tab>

  <Tab value="Render strings">
    For simple messages, you can return a string from the `render` method. This is useful for quick status updates or simple notifications.

    <Frame className="my-0">
      <img src="/images/concepts/generative-ui/render-string.gif" className="w-[300px] p-0" alt="String rendering example" />
    </Frame>

    ```tsx
    "use client" // only necessary if you are using Next.js with the App Router. // [!code highlight]
    import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

    useCopilotAction({ // [!code highlight]
      name: "simpleAction",
      description: "A simple action with string rendering",
      parameters: [
        {
          name: "taskName",
          type: "string",
          description: "Name of the task",
          required: true,
        },
      ],
      handler: async ({ taskName }) => {
        return await longRunningOperation(taskName);
      },
      // [!code highlight:4]
      render: ({ status, result }) => {
        return status === "complete" ? result : "Processing...";
      },
    });
    ```

  </Tab>

  <Tab value="Catch all renders">
    If you want to render actions that are not explicitly referenced in any `useCopilotAction` call, you can pass `"*"` as the action name.
    In this case, the render method will receive an additional `name` parameter. This is particularly useful when working with agents that may call arbitrary tools - see more in our [Tool-based Generative UI](/crewai-crews/generative-ui/tool-based) guide.

    ```tsx
    import { useCopilotAction, CatchAllActionRenderProps } from "@copilotkit/react-core";

    useCopilotAction({
      name: "*",
      render: ({ name, args, status, result }: CatchAllActionRenderProps<[]>) => {
        return <div>Rendering action: {name}</div>;
      },
    });
    ```
    </Tab>

</Tabs>
<Accordions className="mt-4">
  <Accordion title="What do the different status states mean?">
    - `inProgress`: Arguments are dynamically streamed to the function, allowing you to adjust your UI in real-time.
    - `executing`: The action handler is executing.
    - `complete`: The action handler has completed execution.
  </Accordion>
  <Accordion title='Why do I need "use client" in Next.js with the App Router?'>
    <UseClientCalloutSnippet components={props.components} />
  </Accordion>
</Accordions>

## Test it out!

After defining the action with a render method, ask the copilot to perform the task. For example, you can now ask the copilot to "show tasks" and see the custom UI component rendered in the chat interface.

<Callout type="info">
  You can read more about the `useCopilotAction` hook
  [here](/reference/hooks/useCopilotAction).
</Callout>



================================================
FILE: docs/content/docs/(root)/guides/guardrails.mdx
================================================
---
title: "Guardrails"
icon: "lucide/Shield"
---

## Introduction

CopilotKit Cloud provides content moderation capabilities through the `guardrails_c` configuration, helping ensure safe and appropriate AI interactions. The system uses OpenAI's content moderation capabilities to enforce these guardrails.

This feature is only available with [CopilotKit Cloud](https://cloud.copilotkit.ai/).

## Implementation

```tsx
import { CopilotKit } from "@copilotkit/react-core";

export default function App() {
  return (
    <CopilotKit
      publicApiKey={process.env.COPILOTKIT_PUBLIC_API_KEY}
      guardrails_c={{
        // Topics to explicitly block
        invalidTopics: ["politics", "explicit-content", "harmful-content"],
        // Topics to explicitly allow
        validTopics: ["business", "technology", "general-assistance"],
      }}
    >
      {/* Your app */}
    </CopilotKit>
  );
}
```



================================================
FILE: docs/content/docs/(root)/guides/messages-localstorage.mdx
================================================
---
title: "Saving and restoring messages"
description: "Learn how to save and restore message history."
icon: "lucide/Save"
---

<Callout>
  See [Loading Message History](/coagents/persistence/loading-message-history) for an automated way to load the chat history.
</Callout>

As you're building agentic experiences, you may want to persist the user's chat history across runs. 
One way to do this is through the use of `localstorage` where chat history is saved in the browser. 
In this guide we demonstrate how you can store the state into `localstorage` and how it can be inserted 
into the agent.

The following example shows how to save and restore your message history using `localStorage`:

```typescript
import { useCopilotMessagesContext } from "@copilotkit/react-core";
import { ActionExecutionMessage, ResultMessage, TextMessage } from "@copilotkit/runtime-client-gql";

const { messages, setMessages } = useCopilotMessagesContext();

// save to local storage when messages change
useEffect(() => {
  if (messages.length !== 0) {
    localStorage.setItem("copilotkit-messages", JSON.stringify(messages));
  }
}, [JSON.stringify(messages)]);

// initially load from local storage
useEffect(() => {
  const messages = localStorage.getItem("copilotkit-messages");
  if (messages) {
    const parsedMessages = JSON.parse(messages).map((message: any) => {
      if (message.type === "TextMessage") {
        return new TextMessage({
          id: message.id,
          role: message.role,
          content: message.content,
          createdAt: message.createdAt,
        });
      } else if (message.type === "ActionExecutionMessage") {
        return new ActionExecutionMessage({
          id: message.id,
          name: message.name,
          scope: message.scope,
          arguments: message.arguments,
          createdAt: message.createdAt,
        });
      } else if (message.type === "ResultMessage") {
        return new ResultMessage({
          id: message.id,
          actionExecutionId: message.actionExecutionId,
          actionName: message.actionName,
          result: message.result,
          createdAt: message.createdAt,
        });
      } else {
        throw new Error(`Unknown message type: ${message.type}`);
      }
    });
    setMessages(parsedMessages);
  }
}, []);
```



================================================
FILE: docs/content/docs/(root)/guides/meta.json
================================================
{
  "title": "Guides",
  "pages": [
    "custom-look-and-feel",
    "connect-your-data",
    "generative-ui",
    "frontend-actions",
    "backend-actions",
    "model-context-protocol",
    "custom-ai-assistant-behavior",
    "frontend-backend-action-pairing",
    "authenticated-actions",
    "guardrails",
    "copilot-suggestions",
    "bring-your-own-llm",
    "copilot-textarea",
    "self-hosting",
    "messages-localstorage"
  ]
}



================================================
FILE: docs/content/docs/(root)/guides/model-context-protocol.mdx
================================================
---
title: "Connect to MCP Servers"
description: "Integrate Model Context Protocol (MCP) servers into React applications"
icon: "lucide/Network"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import Link from "next/link";
import {
  Database,
  Code,
  Server,
  Bot,
  SquareTerminal,
  SquareChartGantt,
} from "lucide-react";

## Introduction

The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. With MCP, you can:

- Connect AI applications to your data sources
- Enable AI tools to access and utilize your data securely
- Build AI-powered features that have context about your application

For further reading, check out the [Model Context Protocol](https://modelcontextprotocol.io/introduction) website.

## Quickstart with CopilotKit

<Steps>
  <Step>
    ### Get an MCP Server
    First, we need to make sure we have an MCP server to connect to. You can use any MCP SSE endpoint you have configured.

    <Accordions className="shadow-lg ring-1 ring-indigo-400 selected bg-gradient-to-r from-indigo-100/80 to-purple-200 dark:from-indigo-900/30 dark:to-purple-900/50">
      <Accordion title="Get an MCP Server from Composio">
        <p>
          Composio provides a registry of ready-to-use MCP servers with simple authentication and setup.

          To get started, go to [Composio](https://mcp.composio.dev/), find a server the suits your needs and copy the SSE URL before continuing here.
        </p>
      </Accordion>
    </Accordions>

  </Step>
  <TailoredContent
    className="step"
    id="cli"
    header={
        <div>
            <p className="text-xl font-semibold">Use the CopilotKit CLI</p>
        </div>
    }
  >
    <TailoredContentOption
      id="use-cli"
      title="Use the CopilotKit CLI"
      description="I have a Next.js application and want to get started quickly."
      icon={<SquareTerminal />}
    >
      <Step>
        ### Run the CLI
        Just run this following command in your Next.js application to get started!

        <Accordions>
            <Accordion title="Don't have a Next.js application?">
                No problem! Just use `create-next-app` to make one quickly.
                ```bash
                npx create-next-app@latest
                ```
            </Accordion>
        </Accordions>

        ```bash
        npx copilotkit@latest init -m MCP
        ```
      </Step>
    </TailoredContentOption>
    <TailoredContentOption
        id="do-it-manually"
        title="Code along"
        description="I want to deeply understand what's happening under the hood or don't have a Next.js application."
        icon={<SquareChartGantt />}
    >
      <Step>
        #### Set up the CopilotKit Provider

        Wrap your application with the `CopilotKit` provider:

        ```tsx
        "use client";

        import { CopilotKit } from "@copilotkit/react-core";

        export default function App() {
          return (
            <CopilotKit publicApiKey="<replace_with_your_own>">
              {/* Your app content */}
            </CopilotKit>
          );
        }
        ```
      </Step>
      <Step>
        #### Connect to MCP Servers

        Create a component to manage MCP server connections:

        ```tsx
        "use client";

        import { useCopilotChat } from "@copilotkit/react-core";
        import { useEffect } from "react";

        function McpServerManager() {
          const { setMcpServers } = useCopilotChat();

          useEffect(() => {
            setMcpServers([
              {
                // Try a sample MCP server at https://mcp.composio.dev/
                endpoint: "your_mcp_sse_url",
              },
            ]);
          }, [setMcpServers]);

          return null;
        }

        export default McpServerManager;
        ```
      </Step>
      <Step>
        #### Add the Chat Interface

        Add the `CopilotChat` component to your page:

        ```tsx
        "use client";

        import { CopilotChat } from "@copilotkit/react-ui";
        import McpServerManager from "./McpServerManager";

        export default function ChatInterface() {
          return (
            <div className="flex h-screen p-4">
              <McpServerManager />
              <CopilotChat
                instructions="You are a helpful assistant with access to MCP servers."
                className="flex-grow rounded-lg w-full"
              />
            </div>
          );
        }
        ```
      </Step>
      <Step>
        #### Visualize MCP Tool Calls (Optional)

        Create a component to display MCP tool calls in your UI:

        ```tsx
        "use client";

        import {
          useCopilotAction,
          CatchAllActionRenderProps,
        } from "@copilotkit/react-core";
        import McpToolCall from "./McpToolCall";

        export function ToolRenderer() {
          useCopilotAction({
            /**
             * The asterisk (*) matches all tool calls
             */
            name: "*",
            render: ({ name, status, args, result }: CatchAllActionRenderProps<[]>) => (
              <McpToolCall status={status} name={name} args={args} result={result} />
            ),
          });
          return null;
        }
        ```
      </Step>
      <Step>
        #### Complete Implementation

        Combine all components together:

        ```tsx
        "use client";

        import { CopilotKit } from "@copilotkit/react-core";
        import { CopilotChat } from "@copilotkit/react-ui";
        import McpServerManager from "./McpServerManager";
        import { ToolRenderer } from "./ToolRenderer";

        export default function Page() {
          return (
            <CopilotKit publicApiKey="<replace_with_your_own>">
              <div className="flex h-screen p-4">
                <McpServerManager />
                <CopilotChat
                  instructions="You are a helpful assistant with access to MCP servers."
                  className="flex-grow rounded-lg w-full"
                />
                <ToolRenderer />
              </div>
            </CopilotKit>
          );
        }
        ```
      </Step>
    </TailoredContentOption>

  </TailoredContent>
</Steps>

## Advanced Usage

### Implementing the McpToolCall Component

<details>
<summary>Click to see the McpToolCall component implementation</summary>

```tsx
"use client";

import * as React from "react";

interface ToolCallProps {
  status: "complete" | "inProgress" | "executing";
  name?: string;
  args?: any;
  result?: any;
}

export default function MCPToolCall({
  status,
  name = "",
  args,
  result,
}: ToolCallProps) {
  const [isOpen, setIsOpen] = React.useState(false);

  // Format content for display
  const format = (content: any): string => {
    if (!content) return "";
    const text =
      typeof content === "object"
        ? JSON.stringify(content, null, 2)
        : String(content);
    return text
      .replace(/\\n/g, "\n")
      .replace(/\\t/g, "\t")
      .replace(/\\"/g, '"')
      .replace(/\\\\/g, "\\");
  };

  return (
    <div className="bg-[#1e2738] rounded-lg overflow-hidden w-full">
      <div
        className="p-3 flex items-center cursor-pointer"
        onClick={() => setIsOpen(!isOpen)}
      >
        <span className="text-white text-sm overflow-hidden text-ellipsis">
          {name || "MCP Tool Call"}
        </span>
        <div className="ml-auto">
          <div
            className={`w-2 h-2 rounded-full ${
              status === "complete"
                ? "bg-gray-300"
                : status === "inProgress" || status === "executing"
                ? "bg-gray-500 animate-pulse"
                : "bg-gray-700"
            }`}
          />
        </div>
      </div>

      {isOpen && (
        <div className="px-4 pb-4 text-gray-300 font-mono text-xs">
          {args && (
            <div className="mb-4">
              <div className="text-gray-400 mb-2">Parameters:</div>
              <pre className="whitespace-pre-wrap max-h-[200px] overflow-auto">
                {format(args)}
              </pre>
            </div>
          )}

          {status === "complete" && result && (
            <div>
              <div className="text-gray-400 mb-2">Result:</div>
              <pre className="whitespace-pre-wrap max-h-[200px] overflow-auto">
                {format(result)}
              </pre>
            </div>
          )}
        </div>
      )}
    </div>
  );
}
```

</details>

### Self-Hosting Option

<details>
<summary>Click here to learn how to use MCP with self-hosted runtime</summary>

<Callout type="info" title="Self-Hosting vs Copilot Cloud">
  The Copilot Runtime handles communication with LLMs, message history, and
  state. You can self-host it or use{" "}
  <LinkToCopilotCloud asButton={false}>Copilot Cloud</LinkToCopilotCloud>{" "}
  (recommended). Learn more in our [Self-Hosting Guide](/guides/self-hosting).
</Callout>

To configure your self-hosted runtime with MCP servers, you'll need to implement the `createMCPClient` function that matches this interface:

```typescript
type CreateMCPClientFunction = (
  config: MCPEndpointConfig
) => Promise<MCPClient>;
```

For detailed implementation guidance, refer to the [official MCP SDK documentation](https://github.com/modelcontextprotocol/typescript-sdk?tab=readme-ov-file#writing-mcp-clients).

Here's a basic example of configuring the runtime:

```tsx
import {
  CopilotRuntime,
  OpenAIAdapter,
  copilotRuntimeNextJSAppRouterEndpoint,
} from "@copilotkit/runtime";
import { NextRequest } from "next/server";

const serviceAdapter = new OpenAIAdapter();

const runtime = new CopilotRuntime({
  createMCPClient: async (config) => {
    // Implement your MCP client creation logic here
    // See the MCP SDK docs for implementation details
  },
});

export const POST = async (req: NextRequest) => {
  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
    runtime,
    serviceAdapter,
    endpoint: "/api/copilotkit",
  });

  return handleRequest(req);
};
```

</details>



================================================
FILE: docs/content/docs/(root)/guides/self-hosting.mdx
================================================
---
title: Self Hosting (Copilot Runtime)
description: Learn how to self-host the Copilot Runtime.
icon: "lucide/Server"
---

import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import LLMAdapters from "@/snippets/llm-adapters.mdx";

The Copilot Runtime is the back-end component of CopilotKit, handling the communication with LLM, message history, state and more.

You may choose to self-host the Copilot Runtime, or [use Copilot Cloud](https://cloud.copilotkit.ai) (recommended).

<Frame>
  <div className="w-full pb-4">
  ```mermaid
  sequenceDiagram
    participant core as @copilotkit/react-core
    participant runtime as Copilot Runtime
    participant llm as LLM

    core->>runtime: "Hey, my name is Uli."
    runtime->>llm: Request
    llm->>runtime: Response
    runtime->>core: "Hello Uli, how can I help you?"
  ```
  </div>
</Frame>


## Integration

<Steps>
  <Step>
    ### Step 1: Create an Endpoint
    <SelfHostingCopilotRuntimeCreateEndpoint components={props.components} />
  </Step>

  <Step>
    ### Step 2: Configure the `<CopilotKit>` Provider
    <SelfHostingCopilotRuntimeConfigureCopilotKitProvider components={props.components} />
  </Step>

</Steps>

## Next Steps

- [`CopilotRuntime` Reference](/reference/classes/CopilotRuntime)
- [LLM Adapters](/reference/classes/llm-adapters/OpenAIAdapter)


================================================
FILE: docs/content/docs/(root)/guides/backend-actions/index.mdx
================================================
---
title: "Backend Actions & Agents"
description: "Learn how to enable backend actions & agents in your Copilot."
icon: "lucide/Server"
---

import { LinkIcon } from "lucide-react";

<Cards>
  <Card
    title="TypeScript / Node.js Actions"
    description="Implement backend actions using TypeScript or Node.js within the CopilotRuntime."
    href="/guides/backend-actions/typescript-backend-actions"
    icon={<LinkIcon />}
  />
  <Card
    title="LangChain.js Actions"
    description="Integrate LangChain JS chains as backend actions in your Copilot."
    href="/guides/backend-actions/langchain-js-backend-actions"
    icon={<LinkIcon />}
  />
  <Card
    title="LangServe Integration"
    description="Connect your Copilot to LangChain chains hosted as separate services."
    href="/guides/backend-actions/langserve-backend-actions"
    icon={<LinkIcon />}
  />
  <Card
    title="Python SDK"
    description="Use the CopilotKit Python SDK to create powerful remote actions and agents."
    href="/guides/backend-actions/remote-backend-endpoint"
    icon={<LinkIcon />}
  />
  <Card
    title="CoAgents (LangGraph)"
    description="Deeply embed LangGraph agents in applications"
    href="/coagents"
    icon={<LinkIcon />}
  />
</Cards>


================================================
FILE: docs/content/docs/(root)/guides/backend-actions/langchain-js-backend-actions.mdx
================================================
---
title: "LangChain.js"
description: "Integrate LangChain JS chains as backend actions in your CopilotKit application."
icon: "custom/langchain"
---
import FindCopilotRuntimeSnippet from "@/snippets/find-your-copilot-runtime.mdx";

<Steps>
<Step>
<FindCopilotRuntimeSnippet />
</Step>

<Step>
### Integrate LangChain JS actions with CopilotRuntime

CopilotKit allows actions to return not only values but also LangChain streams. This means you can call LangChain chains directly and return their streams as part of your backend actions. Here's how to implement LangChain JS backend actions:

<Callout>
**Note** that `actions` is not merely an array of actions, but an array **generator**.
This generator takes `properties` and `url` as input.

This means you can **customize which backend actions are made available** according to the current frontend URL, as well as custom properties you can pass from the frontend.
</Callout>


```tsx title="/api/copilotkit/route.ts"
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const runtime = new CopilotRuntime({
  // ... existing configuration
  actions: ({properties, url}) => {
    // Note that actions returns not an array, but an array **generator**.
    // You can use the input parameters to the actions generator to expose different backend actions to the Copilot at different times: 
    // `url` is the current URL on the frontend application.
    // `properties` contains custom properties you can pass from the frontend application.

    return [
      {
        name: "generateJokeForTopic",
        description: "Generates a joke for a given topic.",
        parameters: [
          {
            name: "topic",
            type: "string",
            description: "The topic to generate a joke about.",
            required: true,
          },
        ],
        handler: async ({topic}: {topic: string}) => {
          const prompt = ChatPromptTemplate.fromMessages([
            [
              "system",
              "You are a witty comedian. Generate a short, funny joke about the given topic. But make it sound like a pirate joke!",
            ],
            ["user", "Topic: {topic}"],
          ]);
          const chain = prompt.pipe(new ChatOpenAI());
          // [!code highlight:4]
          return chain.stream({ // return directly chain.stream
            topic: topic,
          });
        },
      },
    ]
  }
});

// ... rest of your route definition
```

</Step>

<Step>
### Test your implementation

After adding the LangChain JS action, test it by asking the copilot to generate a joke about a specific topic. Observe how it uses the LangChain components to generate and stream the response.
</Step>

</Steps>



================================================
FILE: docs/content/docs/(root)/guides/backend-actions/langgraph-platform-endpoint.mdx
================================================
---
title: "Remote Endpoint (LangGraph Platform)"
description: "Connect your CopilotKit application to an agent deployed on LangGraph Platform."
icon: "custom/langchain"
---
import FindCopilotRuntimeSnippet from "@/snippets/find-your-copilot-runtime.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content.tsx";
import CopilotCloudConfigureRemoteEndpointLangGraphSnippet from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotCloudConfigureCopilotkitProviderSnippet from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { FaCloud, FaServer } from "react-icons/fa";

<Callout type="info">
    This guide assumes you've created a LangGraph agent, and have a `langgraph.json` file set up. If you need a quick introduction, check out [this brief example
    from the LangGraph docs](https://langchain-ai.github.io/langgraph/) or follow one of our demos.
</Callout>
## Deploy a Graph to LangGraph Platform

<Steps>

    <Step>
    ### Deploy your agent

    First, you need to host your agent so that CopilotKit can access it.

    <LangGraphPlatformDeploymentTabs components={props.components} />
    </Step>

    <Step>
    ### Setup your Copilot Runtime

    <TailoredContent id="hosting">
        <TailoredContentOption
            id="copilot-cloud"
            title="Copilot Cloud (Recommended)"
            description="I'm already using or want to use Copilot Cloud."
            icon={<FaCloud />}
        >
            If you followed the [Copilot Cloud Quickstart](/docs/quickstart) and opted to use CopilotCloud,
            you only need to add your LangGraph Platform deployment URL and LangSmith API key to your CopilotCloud.

            <Accordions className="my-4">
                <Accordion title="Haven't setup Copilot Cloud yet? Click here!" >
                    Copilot Cloud hooks into your CopilotKit provider, so you'll need to set it up first if you haven't already.
                    <CopilotCloudConfigureCopilotkitProviderSnippet components={props.components} />
                </Accordion>
            </Accordions>
            <CopilotCloudConfigureRemoteEndpointLangGraphSnippet components={props.components} />
        </TailoredContentOption>
        <TailoredContentOption
            id="self-hosted"
            title="Self-Hosted"
            description="I'm using or want to use a self-hosted Copilot Runtime."
            icon={<FaServer />}
        >
            <Steps>
                <Step>
                    <FindCopilotRuntimeSnippet components={props.components} />
                </Step>
                <Step>
                    Update the `CopilotRuntime` config to include the `remoteEndpoints` property:

                    ```tsx
                    const runtime = new CopilotRuntime({
                        // ...existing configuration
                        remoteEndpoints: [ // [!code highlight:9]
                            langGraphPlatformEndpoint({
                                deploymentUrl: "your-api-url",
                                langsmithApiKey: "your-langsmith-api-key",
                                // List of all agents which are available under "graphs" list in your langgraph.json file.
                                agents: [{ name: 'my_agent', description: 'A helpful LLM agent', assistantId: 'ID-of-the-agent' }]
                            }),
                        ],
                    });
                    ```

                    <Callout type="info">
                        Tip: Use the `langGraphPlatformEndpoint` type constructor function
                    </Callout>
                </Step>
            </Steps>
        </TailoredContentOption>
    </TailoredContent>
    </Step>

    <Step>
        ### Test Your Implementation

        After setting up the remote endpoint and modifying your `CopilotRuntime`, you can test your implementation by asking the copilot to perform actions that invoke your agent.<br/>
        The graph and interactions can viewed in [LangGraph Studio](smith.langchain.com/studio) and any logs should be available on [LangSmith](smith.langchain.com)

    </Step>
</Steps>

---

## Troubleshooting

A few things to try if you are running into trouble:

1. Make sure that you listed your agents according to the graphs mentioned in the `langgraph.json` file
2. Make sure the agent names are the same between the agent Python implementation, the `langgraph.json` file and the remote endpoint declaration
3. Make sure the LangGraph Platform deployment has all environment variables listed as you need them to be, according to your agent implementation



================================================
FILE: docs/content/docs/(root)/guides/backend-actions/langserve-backend-actions.mdx
================================================
---
title: "LangServe actions"
description: "Connect your CopilotKit application to LangChain chains hosted as separate services using LangServe."
icon: "custom/langchain"
---
import FindCopilotRuntimeSnippet from "@/snippets/find-your-copilot-runtime.mdx";

<Steps>

<Step>
<FindCopilotRuntimeSnippet />
</Step>

<Step>
### Modify CopilotRuntime to include LangServe integration

Once you've located your `CopilotRuntime`, you can add LangServe integration by returning an array of LangServe function sources in the `langserve` property.

**Note that the input and output types of the chain will be automatically fetched from LangServe -- no need to specify them manually!**

Here's how to implement LangServe integration:

```tsx title="/api/copilotkit/route.ts"
const runtime = new CopilotRuntime({
  // ... existing configuration
  langserve: [ // [!code highlight:7]
    {
      chainUrl: "http://my-langserve.chain",
      name: "performResearch",
      description: "Performs research on a given topic.",
    },
  ],
});

// ... rest of your route definition
```
</Step>

<Step>
### Test your implementation

After adding the LangServe integration, test it by asking the copilot to perform research on a topic. Observe how it connects to the external LangServe chain and returns the results.
</Step>

</Steps>


================================================
FILE: docs/content/docs/(root)/guides/backend-actions/meta.json
================================================
{
  "title": "Backend Actions & Agents",
  "pages": [
    "typescript-backend-actions",
    "langchain-js-backend-actions",
    "langserve-backend-actions",
    "rendering-backend-actions",
    "remote-backend-endpoint",
    "langgraph-platform-endpoint"
  ]
}


================================================
FILE: docs/content/docs/(root)/guides/backend-actions/remote-backend-endpoint.mdx
================================================
---
title: "Remote Endpoint (Python)"
description: "Connect your CopilotKit application to a remote backend endpoint, allowing integration with Python-based services or other non-Node.js backends."
icon: "custom/python"
---
import FindCopilotRuntimeSnippet from "@/snippets/find-your-copilot-runtime.mdx";
import CopilotCloudConfigureRemoteEndpointSnippet from "@/snippets/copilot-cloud-configure-remote-endpoint.mdx";
import CopilotCloudConfigureCopilotkitProviderSnippet from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import { FaCloud, FaServer } from "react-icons/fa";


## Stand up a FastAPI server using the CopilotKit Python SDK
<Steps>

<Step>
### Install CopilotKit Python SDK and Dependencies

To integrate a Python backend with your CopilotKit application, set up your project and install the necessary dependencies by choosing your dependency management solution below.


<Tabs groupId="python-pm" items={['Poetry', 'pip', 'conda']} default="Poetry">
    <Tab value="Poetry">
    
    #### Initialize a New Poetry Project
    
    Run the following command to create and initialize a new Poetry project:
    
    ```bash
    poetry new My-CopilotKit-Remote-Endpoint
    ```
    
    Follow the prompts to set up your `pyproject.toml`.
    
    #### Install Dependencies
    
    After initializing the project, install the dependencies:
    
    ```bash
    poetry add copilotkit fastapi uvicorn
    # or including support for crewai
    poetry add copilotkit[crewai] fastapi uvicorn
    ```
    
    </Tab>
    
    <Tab value="pip">
    
    #### Set Up a Virtual Environment (optional)
    
    Create and activate a virtual environment using `venv`:
    
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```
    
    #### Install Dependencies
    
    With the virtual environment activated, install the dependencies:
    
    ```bash
    pip install copilotkit fastapi uvicorn --extra-index-url https://copilotkit.gateway.scarf.sh/simple/
    # or including support for crewai
    pip install copilotkit[crewai] fastapi uvicorn --extra-index-url https://copilotkit.gateway.scarf.sh/simple/
    ```
    
    </Tab>
    
    <Tab value="conda">
    
    #### Create a New Conda Environment
    
    Create and activate a new Conda environment:
    
    ```bash
    conda create -n your_env_name python=3.8
    conda activate your_env_name
    ```
    
    #### Install Dependencies
    
    With the Conda environment activated, install the dependencies:
    
    ```bash
    conda install copilotkit fastapi uvicorn -c copilotkit-channel
    # or including support for crewai
    conda install copilotkit[crewai] fastapi uvicorn -c copilotkit-channel
    ```
    
    </Tab>
    
</Tabs>


**Dependencies:**

- **copilotkit**: The CopilotKit Python SDK.
- **fastapi**: A modern, fast (high-performance) web framework for building APIs with Python.
- **uvicorn**: A lightning-fast ASGI server for Python.
</Step>


<Step>
### Set Up a FastAPI Server

Create a new Python file `/my_copilotkit_remote_endpoint/server.py` and set up a FastAPI server:

```python title="/my_copilotkit_remote_endpoint/server.py"
from fastapi import FastAPI

app = FastAPI()
```

</Step>

<Step>
### Define Your Backend Actions

Import the CopilotKit SDK and define your backend actions. For example:

```python title="/my_copilotkit_remote_endpoint/server.py"
from fastapi import FastAPI
from copilotkit.integrations.fastapi import add_fastapi_endpoint
from copilotkit import CopilotKitRemoteEndpoint, Action as CopilotAction

app = FastAPI()

# Define your backend action
async def fetch_name_for_user_id(userId: str):
    # Replace with your database logic
    return {"name": "User_" + userId}

# this is a dummy action for demonstration purposes
action = CopilotAction(
    name="fetchNameForUserId",
    description="Fetches user name from the database for a given ID.",
    parameters=[
        {
            "name": "userId",
            "type": "string",
            "description": "The ID of the user to fetch data for.",
            "required": True,
        }
    ],
    handler=fetch_name_for_user_id
)

# Initialize the CopilotKit SDK # [!code highlight:2]
sdk = CopilotKitRemoteEndpoint(actions=[action])

# Add the CopilotKit endpoint to your FastAPI app # [!code highlight:2]
add_fastapi_endpoint(app, sdk, "/copilotkit_remote")

def main():
    """Run the uvicorn server."""
    import uvicorn
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=True)

if __name__ == "__main__":
    main()
```

</Step>

<Step>
### Run Your FastAPI Server

Since we've added the entry point in `server.py`, you can run your FastAPI server directly by executing the script:

<Tabs groupId="python-pm" items={['Poetry', 'pip', 'conda']} default="Poetry">
    <Tab value="Poetry">
        ```bash
        poetry run python3 server.py
        ```
    </Tab>
    <Tab value="pip">
        ```bash
        python3 server.py
        ```
    </Tab>
    <Tab value="conda">
        ```bash
        python3 server.py
        ```
    </Tab>
</Tabs>

**Note:** Ensure that you're in the same directory as `server.py` when running this command.

</Step>
</Steps>


## Connect your app to the remote endpoint

Now that you've set up your FastAPI server with the backend actions, integrate it into your CopilotKit application by modifying your `CopilotRuntime` configuration.

<TailoredContent id="hosting">
    <TailoredContentOption
        id="copilot-cloud"
        title="Copilot Cloud (Recommended)"
        description="I want to use Copilot Cloud to connect to my remote endpoint."
        icon={<FaCloud />}
    >
        <CopilotCloudConfigureRemoteEndpointSnippet components={props.components} />
    </TailoredContentOption>
    <TailoredContentOption
        id="self-hosted"
        title="Self-Hosted Copilot Runtime"
        description="I want to use a self-hosted Copilot Runtime to connect to my remote endpoint."
        icon={<FaServer />}
    >
        <Steps>
            <Step>
                <FindCopilotRuntimeSnippet components={props.components} />
            </Step>
            <Step>
                Update the `CopilotRuntime` to include your new `remote endpoint`.

                ```tsx
                const runtime = new CopilotRuntime({
                    // ...existing configuration
                    remoteEndpoints: [ // [!code highlight:5]
                        { url: "http://localhost:8000/copilotkit_remote" },
                    ],
                });
                ```
            </Step>
        </Steps>

        ## Troubleshooting

        A few things to try if you are running into trouble:

        1. Make sure there is no other local application server running on the 8000 port.
        2. Under `/agent/my_agent/demo.py`, change host from `0.0.0.0` to `127.0.0.1` or to `localhost`

    </TailoredContentOption>
</TailoredContent>

### Test Your Implementation

After setting up the remote endpoint and modifying your `CopilotRuntime`, you can test your implementation by asking the copilot to perform actions that invoke your Python backend. For example, ask the copilot: "Fetch the name for user ID `123`."

### Advanced

#### Configuring the Thread Pool Executor

The request to the remote endpoint is made in a thread pool executor. You can configure the size of the thread pool executor by passing the `max_workers` parameter to the `add_fastapi_endpoint` function.

```python
add_fastapi_endpoint(app, sdk, "/copilotkit_remote", max_workers=10) # default is 10
```

#### Dynamically returning actions and agents

Both the `actions` and `agents` parameters can optionally be functions that return a list of actions or agents. This allows you to dynamically return actions and agents based on the user's request.

For example, to dynamically configure an agent based on properties from the frontend, set the properties on the frontend first:

```tsx
<CopilotKit properties={{someProperty: "xyz"}}>
   <YourApp />
</CopilotKit>
```

Then, in your backend, use a function to return dynamically configured agents:

```python
def build_agents(context):
    return [
        LangGraphAgent(
            name="some_agent",
            description="This agent does something",
            graph=graph,
            langgraph_config={
                "some_property": context["properties"]["someProperty"]
            }
        )
    ]


app = FastAPI()
sdk = CopilotKitRemoteEndpoint(
    agents=build_agents,
)
```

---



================================================
FILE: docs/content/docs/(root)/guides/backend-actions/typescript-backend-actions.mdx
================================================
---
title: "TypeScript (Node.js)"
description: "Implement native backend actions using TypeScript or Node.js in CopilotKit."
icon: "custom/typescript"
---
import FindCopilotRuntimeSnippet from "@/snippets/find-your-copilot-runtime.mdx";

<Steps>

<Step>
<FindCopilotRuntimeSnippet />
</Step>

<Step>
### Modify CopilotRuntime to include TypeScript/Node.js actions

Once you've located your `CopilotRuntime`, you can add TypeScript/Node.js actions by modifying its configuration. Here's how to implement native backend actions:

<Callout>
**Note** that `actions` is not merely an array of actions, but an array **generator**.
This generator takes `properties` and `url` as input.

This means you can **customize which backend actions are made available** according to the current frontend URL, as well as custom properties you can pass from the frontend.
</Callout>

```tsx title="/api/copilotkit/route.ts"
const runtime = new CopilotRuntime({
  // ... existing configuration
  actions: ({properties, url}) => {
    // Note that actions returns not an array, but an array **generator**.
    // You can use the input parameters to the actions generator to expose different backend actions to the Copilot at different times: 
    // `url` is the current URL on the frontend application.
    // `properties` contains custom properties you can pass from the frontend application.
    
    return [
      {
        name: "fetchNameForUserId",
        description: "Fetches user name from the database for a given ID.",
        parameters: [
          {
            name: "userId",
            type: "string",
            description: "The ID of the user to fetch data for.",
            required: true,
          },
        ],
        handler: async ({userId}: {userId: string}) => {
          // do something with the userId
          // return the user data
          return {
            name: "Darth Doe",
          };
        },
      },
    ]
  }
});

// ... rest of your route definition
```

</Step>

<Step>
### Test your implementation

After adding the action, test it by asking the copilot to perform the task. Observe how it selects the correct task, executes it, and streams back relevant responses.
</Step>

</Steps>

## Key Points


- Each action is defined with a name, description, parameters, and a handler function.
- The handler function implements the actual logic of the action and can interact with your backend systems.

By using this method, you can create powerful, context-aware backend actions that integrate seamlessly with your CopilotKit application.


================================================
FILE: docs/content/docs/(root)/guides/connect-your-data/backend.mdx
================================================
---
title: "Backend Data"
description: "Learn how to connect your data to CopilotKit."
icon: "lucide/Server"
---

## Backend Readable State
CopilotKit allows you to define actions on the backend that can be called by your Copilot. Behind the scenes, this is securely binding
the action as a tool to your LLM of choice. 

When you ask the LLM to retrieve the data, it will do so by securely calling the backend action.

<Callout type="info">
  For more information about backend actions, see the [Backend Action](/guides/backend-actions) guides.
</Callout>

```tsx title="/api/copilotkit/route.ts"
const runtime = new CopilotRuntime({
  actions: ({properties, url}) => {
    // You can use the input parameters to the actions generator to expose different backend actions to the Copilot at different times: 
    // `url` is the current URL on the frontend application.
    // `properties` contains custom properties you can pass from the frontend application.
    
    return [
      {
        name: "fetchNameForUserId",
        description: "Fetches user name from the database for a given ID.",
        parameters: [
          {
            name: "userId",
            type: "string",
            description: "The ID of the user to fetch data for.",
            required: true,
          },
        ],
        handler: async ({userId}: {userId: string}) => {
          // do something with the userId
          // return the user data
          const simulateDatabaseCall = async (userId: string) => { return { name: "Darth Doe" } }
          return await simulateDatabaseCall(userId)
        },
      },
    ]
  }
});
```

## Knowledge Bases (Enterprise)

Additional plug-and-play integrations with knowledge bases are available via our enterprise plan. 

Please [reach out](mailto:hello@copilotkit.ai) to enable it.



================================================
FILE: docs/content/docs/(root)/guides/connect-your-data/frontend.mdx
================================================
---
title: "Frontend Data"
description: "Learn how to connect your data to CopilotKit."
icon: "lucide/CodeXml"
---
import UseClientCalloutSnippet from "@/snippets/use-client-callout.mdx";

For your copilot to best answer your users' needs, you will want to provide it with **context-specific**, **user-specific**, and oftentimes **realtime** data. CopilotKit makes it easy to do so.

<Steps>
  <Step>
    ### Add the data to the Copilot

    The [`useCopilotReadable` hook](/reference/hooks/useCopilotReadable) is used to add data as context to the Copilot.

    ```tsx title="YourComponent.tsx" showLineNumbers {1, 7-10}
    "use client" // only necessary if you are using Next.js with the App Router. // [!code highlight]
    import { useCopilotReadable } from "@copilotkit/react-core"; // [!code highlight]
    import { useState } from 'react';
    
    export function YourComponent() {
      // Create colleagues state with some sample data
      const [colleagues, setColleagues] = useState([
        { id: 1, name: "John Doe", role: "Developer" },
        { id: 2, name: "Jane Smith", role: "Designer" },
        { id: 3, name: "Bob Wilson", role: "Product Manager" }
      ]);
    
      // Define Copilot readable state
      // [!code highlight:5]
      useCopilotReadable({
        description: "The current user's colleagues",
        value: colleagues,
      });
      return (
        // Your custom UI component
        <>...</>
      );
    }
    ```
  </Step>

  <Step>
    <UseClientCalloutSnippet components={props.components} />
  </Step>


  <Step>
    ### Test it out!

    The data you provided is now available to the Copilot.
    Test it out by passing some data in the hook and asking the copilot questions about it.

    <div className="mt-2 mb-4">
      <img 
        src="/images/connect-your-data-example.gif" 
        alt="Example of connecting data to Copilot" 
        className="rounded-lg shadow-md w-full max-w-md mx-auto"
      />
    </div>
  </Step>
</Steps>



================================================
FILE: docs/content/docs/(root)/guides/connect-your-data/index.mdx
================================================
---
title: "Connecting Your Data"
description: "Learn how to connect your data to CopilotKit."
icon: "lucide/Database"
---
import { CodeIcon, ServerIcon } from "lucide-react";

CopilotKit allows you to connect your data through the frontend and through the backend. This enables
a variety of use-cases from simple context to RAG-based LLM interactions.

<Cards>
  <Card
    title="Frontend Data"
    icon={<CodeIcon />}
    description="Learn how to connect your data to CopilotKit on the frontend."
    href="/guides/connect-your-data/frontend"
  />
  <Card
    title="Backend Data"
    icon={<ServerIcon />}
    description="Learn how to connect your data to CopilotKit on the backend."
    href="/guides/connect-your-data/backend" />
</Cards>


================================================
FILE: docs/content/docs/(root)/guides/connect-your-data/meta.json
================================================
{
    "pages": [
      "frontend",
      "backend"
    ]
}
  


================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/bring-your-own-components.mdx
================================================
---
title: Custom Sub-Components
icon: "lucide/Puzzle"
---
import { ImageAndCode } from "@/components/react/image-and-code"

You can swap out any of the sub-components of any Copilot UI to build up a completely custom look and feel. All components are fully typed with TypeScript for better development experience.

| Component | Description |
| --- | --- |
| [UserMessage](#usermessage) | Message component for user messages |
| [AssistantMessage](#assistantmessage) | Message component for assistant messages |
| [Window](#window) | Contains the chat |
| [Button](#button) | Button that opens/closes the chat |
| [Header](#header) | The header of the chat |
| [Messages](#messages) | The chat messages area |
| [Suggestions](#suggestions) | Customize how suggestions are displayed |
| [Input](#input) | The chat input |
| [Actions](#actions) | Customize how actions (tools) are displayed |
| [Agent State](#agent-state) | Customize how agent state messages are displayed |

## UserMessage
The user message is what displays when the user sends a message to the chat. In this example, we change the color and add an avatar. 

<ImageAndCode preview="/images/custom-user-message.png">
The main thing to be aware of here is the `message` prop, which is the message text from the user.

```tsx
import { UserMessageProps } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

const CustomUserMessage = (props: UserMessageProps) => {
  const wrapperStyles = "flex items-center gap-2 justify-end mb-4";
  const messageStyles = "bg-blue-500 text-white py-2 px-4 rounded-xl break-words flex-shrink-0 max-w-[80%]";
  const avatarStyles = "bg-blue-500 shadow-sm min-h-10 min-w-10 rounded-full text-white flex items-center justify-center";

  return (
    <div className={wrapperStyles}>
      <div className={messageStyles}>{props.message}</div>
      <div className={avatarStyles}>TS</div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar UserMessage={CustomUserMessage} />
</CopilotKit>
```
</ImageAndCode>

## AssistantMessage
The assistant message is what displays when the LLM responds to a user message. In this example, we remove the background color and add an avatar. 

<ImageAndCode preview="/images/custom-assistant-message.png">
```tsx
import { AssistantMessageProps } from "@copilotkit/react-ui";
import { useChatContext } from "@copilotkit/react-ui";
import { Markdown } from "@copilotkit/react-ui";
import { SparklesIcon } from "@heroicons/react/24/outline";

import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

const CustomAssistantMessage = (props: AssistantMessageProps) => {
  const { icons } = useChatContext();
  const { message, isLoading, subComponent } = props;

  const avatarStyles = "bg-zinc-400 border-zinc-500 shadow-lg min-h-10 min-w-10 rounded-full text-white flex items-center justify-center";
  const messageStyles = "px-4 rounded-xl pt-2";

  const avatar = <div className={avatarStyles}><SparklesIcon className="h-6 w-6" /></div>

  // [!code highlight:13]
  return (
    <div className="py-2">
      <div className="flex items-start">
        {!subComponent && avatar}
        <div className={messageStyles}>
          {message && <Markdown content={message || ""} /> }
          {isLoading && icons.spinnerIcon}
        </div>
      </div>
      <div className="my-2">{subComponent}</div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar AssistantMessage={CustomAssistantMessage} />
</CopilotKit>
```
**Key concepts**
- `subComponent` - This is where any generative UI will be rendered.
- `message` - This is the message text from the LLM, typically in markdown format.
- `isLoading` - This is a boolean that indicates if the message is still loading.

</ImageAndCode>

## Window
The window is the main container for the chat. In this example, we turn it into a more traditional modal.

<ImageAndCode preview="/images/custom-window.png">

```tsx
import { WindowProps, useChatContext, CopilotSidebar } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function Window({ children }: WindowProps) {
  const { open, setOpen } = useChatContext();

  if (!open) return null;

  // [!code highlight:16]
  return (
    <div 
      className="fixed inset-0 bg-black/50 flex items-center justify-center p-4"
      onClick={() => setOpen(false)}
    >
      <div 
        className="bg-white rounded-lg shadow-xl max-w-2xl w-full h-[80vh] overflow-auto"
        onClick={e => e.stopPropagation()}
      >
        <div className="flex flex-col h-full">
          {children}
        </div>
      </div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar Window={Window} />
</CopilotKit>
```
</ImageAndCode>

## Button
The `CopilotSidebar` and `CopilotPopup` components allow you to customize their trigger button by passing in a custom Button component.

<ImageAndCode preview="/images/custom-button.png">

```tsx
import { ButtonProps, useChatContext, CopilotSidebar } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function Button({}: ButtonProps) {
  const { open, setOpen } = useChatContext();

  const wrapperStyles = "w-24 bg-blue-500 text-white p-4 rounded-lg text-center cursor-pointer";

  // [!code highlight:11]
  return (
    <div onClick={() => setOpen(!open)} className={wrapperStyles}>
      <button
        className={`${open ? "open" : ""}`}
        aria-label={open ? "Close Chat" : "Open Chat"}
      >
        Ask AI
      </button>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar Button={Button} />
</CopilotKit>
```
</ImageAndCode>

## Header
The header component is the top of the chat window. In this example, we add a button to the left of the title
with a custom icon.

<ImageAndCode preview="/images/custom-header.png">

```tsx
import { HeaderProps, useChatContext, CopilotSidebar } from "@copilotkit/react-ui";
import { BookOpenIcon } from "@heroicons/react/24/outline";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function Header({}: HeaderProps) {
  const { setOpen, icons, labels } = useChatContext();

  // [!code highlight:16]
  return (
    <div className="flex justify-between items-center p-4 bg-blue-500 text-white">
      <div className="w-24">
        <a href="/">
          <BookOpenIcon className="w-6 h-6" />
        </a>
      </div>
      <div className="text-lg">{labels.title}</div>
      <div className="w-24 flex justify-end">
        <button onClick={() => setOpen(false)} aria-label="Close">
          {icons.headerCloseIcon}
        </button>
      </div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar Header={Header} />
</CopilotKit>
```
</ImageAndCode>

## Messages
The Messages component handles the display and organization of different message types in the chat interface. Its complexity comes from managing various message types (text, actions, results, and agent states) and maintaining proper scroll behavior.

<ImageAndCode preview="/images/custom-messages.png">

```tsx
import { MessagesProps, CopilotSidebar } from "@copilotkit/react-ui";
import { useCopilotChat } from "@copilotkit/react-core";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function CustomMessages({
  messages,
  inProgress,
  RenderTextMessage,
  RenderActionExecutionMessage,
  RenderResultMessage,
  RenderAgentStateMessage,
}: MessagesProps) {
  const wrapperStyles = "p-4 flex flex-col gap-2 h-full overflow-y-auto bg-indigo-300";

  /*
    Message types handled:
    - TextMessage: Regular chat messages
    - ActionExecutionMessage: When the LLM executes an action
    - ResultMessage: Results from actions
    - AgentStateMessage: Status updates from CoAgents
  */
  // [!code highlight:40]
  return (
    <div className={wrapperStyles}>
      {messages.map((message, index) => {
        if (message.isTextMessage()) {
          return <RenderTextMessage 
            key={message.id} 
            message={message} 
            inProgress={inProgress} 
            index={index} 
            isCurrentMessage={index === messages.length - 1}
          />;
        } else if (message.isActionExecutionMessage()) {
          return <RenderActionExecutionMessage 
            key={message.id} 
            message={message} 
            inProgress={inProgress} 
            index={index} 
            isCurrentMessage={index === messages.length - 1}
          />;
        } else if (message.isResultMessage()) {
          return <RenderResultMessage 
            key={message.id} 
            message={message} 
            inProgress={inProgress} 
            index={index} 
            isCurrentMessage={index === messages.length - 1}
          />;
        } else if (message.isAgentStateMessage()) {
          return <RenderAgentStateMessage 
              key={message.id} 
              message={message} 
              inProgress={inProgress} 
              index={index} 
              isCurrentMessage={index === messages.length - 1}
            />;
        }
      })}
    </div>
  );
}

<CopilotKit>
  <CopilotSidebar Messages={CustomMessages} />
</CopilotKit>
```
</ImageAndCode>

## Suggestions
The suggestions component allows you to customize how suggestions are displayed. In this example, we add a label to the list and change the suggestion chip look

<ImageAndCode preview="/images/custom-suggestions-list.png">
    The main thing to be aware of here is the `message` prop, which is the message text from the user.

    ```tsx
        import { CopilotKit } from "@copilotkit/react-core";
        import {
            CopilotSidebar,
            CopilotChatSuggestion,
            RenderSuggestion,
            RenderSuggestionsListProps,
        } from "@copilotkit/react-ui";
        import "@copilotkit/react-ui/styles.css";

        const CustomSuggestionsList = (props: UserMessageProps) => {
            const wrapperStyles = "flex items-center gap-2 justify-end mb-4";
            const messageStyles = "bg-blue-500 text-white py-2 px-4 rounded-xl break-words flex-shrink-0 max-w-[80%]";
            const avatarStyles = "bg-blue-500 shadow-sm min-h-10 min-w-10 rounded-full text-white flex items-center justify-center";

            return (
                <div className="suggestions flex flex-col gap-2 p-4">
                    <h1>Try asking:</h1>
                    <div className="flex gap-2">
                        {suggestions.map((suggestion: CopilotChatSuggestion, index) => (
                            <RenderSuggestion
                            key={index}
                                      title={suggestion.title}
                                      message={suggestion.message}
                                      partial={suggestion.partial}
                                      className="rounded-md border border-gray-500 bg-white px-2 py-1 shadow-md"
                                      onClick={() => onSuggestionClick(suggestion.message)}
                            />
                        ))}
                    </div>
                </div>
            );
        };

        <CopilotKit>
            <CopilotSidebar RenderSuggestionsList={CustomSuggestionsList} />
        </CopilotKit>
    ```
</ImageAndCode>


## Input
The input component that the user interacts with to send messages to the chat. In this example, we customize it
to have a custom "Ask" button and placeholder text.

<ImageAndCode preview="/images/custom-input.png">

```tsx
import { InputProps, CopilotSidebar } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function CustomInput({ inProgress, onSend, isVisible }: InputProps) {
  const handleSubmit = (value: string) => {
    if (value.trim()) onSend(value);
  };

  const wrapperStyle = "flex gap-2 p-4 border-t";
  const inputStyle = "flex-1 p-2 rounded-md border border-gray-300 focus:outline-none focus:border-blue-500 disabled:bg-gray-100";
  const buttonStyle = "px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 disabled:bg-gray-400 disabled:cursor-not-allowed";

  // [!code highlight:28]
  return (
    <div className={wrapperStyle}>
      <input 
        disabled={inProgress}
        type="text" 
        placeholder="Ask your question here..." 
        className={inputStyle}
        onKeyDown={(e) => {
          if (e.key === 'Enter') {
            handleSubmit(e.currentTarget.value);
            e.currentTarget.value = '';
          }
        }}
      />
      <button 
        disabled={inProgress}
        className={buttonStyle}
        onClick={(e) => {
          const input = e.currentTarget.previousElementSibling as HTMLInputElement;
          handleSubmit(input.value);
          input.value = '';
        }}
      >
        Ask
      </button>
    </div>
  );
}

<CopilotKit>
  <CopilotSidebar Input={CustomInput} />
</CopilotKit>
```
</ImageAndCode>

## Actions
Actions allow the LLM to interact with your application's functionality. When an action is called by the LLM, you can provide custom components to visualize its execution and results. This example demonstrates a calendar meeting card implementation.

<ImageAndCode preview="/images/render-only-example.png">

```tsx
"use client" // only necessary if you are using Next.js with the App Router.
import { useCopilotAction } from "@copilotkit/react-core"; 
 
export function YourComponent() {
  useCopilotAction({ 
    name: "showCalendarMeeting",
    description: "Displays calendar meeting information",
    parameters: [
      {
        name: "date",
        type: "string",
        description: "Meeting date (YYYY-MM-DD)",
        required: true
      },
      {
        name: "time",
        type: "string",
        description: "Meeting time (HH:mm)",
        required: true
      },
      {
        name: "meetingName",
        type: "string",
        description: "Name of the meeting",
        required: false
      }
    ],
    render: ({ status, args }) => {
      const { date, time, meetingName } = args;
 
      if (status === 'inProgress') {
        return <LoadingView />; // Your own component for loading state
      } else {
        const meetingProps: CalendarMeetingCardProps = {
          date: date,
          time,
          meetingName
        };
        return <CalendarMeetingCardComponent {...meetingProps} />;
      }
    },
  });
 
  return (
    <>...</>
  );
}
```
</ImageAndCode>

## Agent State
The Agent State component allows you to visualize the internal state and progress of your CoAgents. When working with CoAgents, you can provide a custom component to render the agent's state. This example demonstrates a progress bar that updates as the agent runs.

<Callout title="Not started with CoAgents yet?">
If you haven't gotten started with CoAgents yet, you can get started in 10 minutes with the [quickstart guide](/coagents/quickstart/langgraph).
</Callout>

<ImageAndCode preview="/images/coagents/AgenticGenerativeUI.gif">

```tsx
"use client"; // only necessary if you are using Next.js with the App Router.
 
import { useCoAgentStateRender } from "@copilotkit/react-core";
import { Progress } from "./progress";

type AgentState = {
  logs: string[];
}

useCoAgentStateRender<AgentState>({
  name: "basic_agent",
  render: ({ state, nodeName, status }) => {
    if (!state.logs || state.logs.length === 0) {
      return null;
    }

    // Progress is a component we are omitting from this example for brevity.
    return <Progress logs={state.logs} />; 
  },
});
```
</ImageAndCode>


================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/built-in-ui-components.mdx
================================================
---
title: "Prebuilt Copilot UI"
icon: "lucide/MessageCircle"
---
import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";

<ConnectCopilotUI components={props.components} />



================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/customize-built-in-ui-components.mdx
================================================
---
title: "Styling Copilot UI"
icon: "lucide/Brush"
---
import { CopilotKitCSS, InteractiveCSSInspector } from "@/components/react/copilotkit-css";

CopilotKit has a variety of ways to customize colors and structures of the Copilot UI components.
- [CSS Variables](#css-variables-easiest)
- [Custom CSS](#custom-css)
- [Custom Icons](#custom-icons)
- [Custom Labels](#custom-labels)

If you want to customize the style as well as the functionality of the Copilot UI, you can also try the following:
- [Custom Sub-Components](/guides/custom-look-and-feel/bring-your-own-components)
- [Fully Headless UI](/guides/custom-look-and-feel/headless-ui)

## CSS Variables (Easiest)
The easiest way to change the colors using in the Copilot UI components is to override CopilotKit CSS variables.

<Callout type="info">
  Hover over the interactive UI elements below to see the available CSS variables.
</Callout>

<CopilotKitCSS />
<InteractiveCSSInspector />

Once you've found the right variable, you can import `CopilotKitCSSProperties` and simply wrap CopilotKit in a div and override the CSS variables. 

```tsx
import { CopilotKitCSSProperties } from "@copilotkit/react-ui";

<div
  // [!code highlight:6]
  style={
    {
      "--copilot-kit-primary-color": "#222222",
    } as CopilotKitCSSProperties
  }
>
  <CopilotSidebar .../>
</div>
```

### Reference

| CSS Variable | Description |
|-------------|-------------|
| `--copilot-kit-primary-color` | Main brand/action color - used for buttons, interactive elements |
| `--copilot-kit-contrast-color` | Color that contrasts with primary - used for text on primary elements |
| `--copilot-kit-background-color` | Main page/container background color |
| `--copilot-kit-secondary-color` | Secondary background - used for cards, panels, elevated surfaces |
| `--copilot-kit-secondary-contrast-color` | Primary text color for main content |
| `--copilot-kit-separator-color` | Border color for dividers and containers |
| `--copilot-kit-muted-color` | Muted color for disabled/inactive states |

## Custom CSS

In addition to customizing the colors, the CopilotKit CSS is structured to easily allow customization via CSS classes.

```css title="globals.css"
.copilotKitButton {
  border-radius: 0;
}

.copilotKitMessages {
  padding: 2rem;
}

.copilotKitUserMessage {
  background: #007AFF;
}
```

### Reference

<Callout>
For a full list of styles and classes used in CopilotKit, click [here](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-ui/src/css/).
</Callout>

| CSS Class | Description |
|-----------|-------------|
| `.copilotKitMessages` | Main container for all chat messages with scroll behavior and spacing |
| `.copilotKitInput` | Text input container with typing area and send button |
| `.copilotKitUserMessage` | Styling for user messages including background, text color and bubble shape |
| `.copilotKitAssistantMessage` | Styling for AI responses including background, text color and bubble shape |
| `.copilotKitHeader` | Top bar of chat window containing title and controls |
| `.copilotKitButton` | Primary chat toggle button with hover and active states |
| `.copilotKitWindow` | Root container defining overall chat window dimensions and position |
| `.copilotKitMarkdown` | Styles for rendered markdown content including lists, links and quotes |
| `.copilotKitCodeBlock` | Code snippet container with syntax highlighting and copy button |
| `.copilotKitChat` | Base chat layout container handling positioning and dimensions |
| `.copilotKitSidebar` | Styles for sidebar chat mode including width and animations |
| `.copilotKitPopup` | Styles for popup chat mode including position and animations |
| `.copilotKitButtonIcon` | Icon styling within the main chat toggle button |
| `.copilotKitButtonIconOpen` `.copilotKitButtonIconClose` | Icon states for when chat is open/closed |
| `.copilotKitCodeBlockToolbar` | Top bar of code blocks with language and copy controls |
| `.copilotKitCodeBlockToolbarLanguage` | Language label styling in code block toolbar |
| `.copilotKitCodeBlockToolbarButtons` | Container for code block action buttons |
| `.copilotKitCodeBlockToolbarButton` | Individual button styling in code block toolbar |
| `.copilotKitSidebarContentWrapper` | Inner container for sidebar mode content |
| `.copilotKitInputControls` | Container for input area buttons and controls |
| `.copilotKitActivityDot1` `.copilotKitActivityDot2` `.copilotKitActivityDot3` | Animated typing indicator dots |
| `.copilotKitDevConsole` | Development debugging console container |
| `.copilotKitDevConsoleWarnOutdated` | Warning styles for outdated dev console |
| `.copilotKitVersionInfo` | Version information display styles |
| `.copilotKitDebugMenuButton` | Debug menu toggle button styling |
| `.copilotKitDebugMenu` | Debug options menu container |
| `.copilotKitDebugMenuItem` | Individual debug menu option styling |

## Custom Fonts
You can customize the fonts by updating the `fontFamily` property in the various CSS classes that are used in the CopilotKit.

```css title="globals.css"
.copilotKitMessages {
  font-family: "Arial, sans-serif";
}

.copilotKitInput {
  font-family: "Arial, sans-serif";
}
```

### Reference
You can update the main content classes to change the font family for the various components.

| CSS Class | Description |
|-----------|-------------|
| `.copilotKitMessages` | Main container for all messages |
| `.copilotKitInput` | The input field |
| `.copilotKitMessage` | Base styling for all chat messages |
| `.copilotKitUserMessage` | User messages |
| `.copilotKitAssistantMessage` | AI responses |

## Custom Icons

You can customize the icons by passing the `icons` property to the `CopilotSidebar`, `CopilotPopup` or `CopilotChat` component.

```tsx
<CopilotChat
  icons={{
    // Use your own icons here – any React nodes
    openIcon: <YourOpenIconComponent />,
    closeIcon: <YourCloseIconComponent />,
  }}
/>
```

### Reference

| Icon | Description |
|--------------|-------------|
| `openIcon` | The icon to use for the open chat button |
| `closeIcon` | The icon to use for the close chat button |
| `headerCloseIcon` | The icon to use for the close chat button in the header |
| `sendIcon` | The icon to use for the send button |
| `activityIcon` | The icon to use for the activity indicator |
| `spinnerIcon` | The icon to use for the spinner |
| `stopIcon` | The icon to use for the stop button |
| `regenerateIcon` | The icon to use for the regenerate button |
| `pushToTalkIcon` | The icon to use for push to talk |

## Custom Labels

To customize labels, pass the `labels` property to the `CopilotSidebar`, `CopilotPopup` or `CopilotChat` component.

```tsx
<CopilotChat
  labels={{
    initial: "Hello! How can I help you today?",
    title: "My Copilot",
    placeholder: "Ask me anything!",
    stopGenerating: "Stop",
    regenerateResponse: "Regenerate",
  }} 
/>
```

### Reference

| Label | Description |
|---------------|-------------|
| `initial` | The initial message(s) to display in the chat window |
| `title` | The title to display in the header |
| `placeholder` | The placeholder to display in the input |
| `stopGenerating` | The label to display on the stop button |
| `regenerateResponse` | The label to display on the regenerate button |




================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/headless-ui.mdx
================================================
---
title: "Fully Headless UI"
description: "Fully customize your Copilot's UI from the ground up using headless UI"
icon: "lucide/Settings"
---

import { ImageAndCode } from "@/components/react/image-and-code"

The built-in Copilot UI can be customized in many ways -- both through CSS and by passing in custom sub-components.

CopilotKit also offers **fully custom headless UI** through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

```tsx
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function CustomChatInterface() {
  const {
    visibleMessages,
    appendMessage,
    setMessages,
    deleteMessage,
    reloadMessages,
    stopGeneration,
    isLoading,
  } = useCopilotChat();

  const sendMessage = (content: string) => {
    appendMessage(new TextMessage({ content, role: Role.User }));
  };

  return (
    <div>
      {/* Implement your custom chat UI here */}
    </div>
  );
}
```

## Resetting the chat history
In some cases, users may want to reset the chat to clear the conversation history and start fresh. This can be useful when:
- The current conversation has become too long or confusing.
- You want to test different prompts or approaches from a clean slate.
- A user needs to reset the context to ensure the AI responds appropriately.

This simple method allows you to reset the chat state with a button click.

<Callout title="Why Reset the Chat?">
Resetting the chat clears all conversation history, helping you start fresh or troubleshoot AI responses.
</Callout>

<ImageAndCode preview="/images/concepts/customize-look-and-feel/reset-chat.gif" >

```tsx

"use client"; // only necessary if you are using Next.js with the App Router.

import { InputProps, CopilotSidebar } from "@copilotkit/react-ui";
import { useCopilotChat } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";

function CustomInput({ inProgress, onSend, isVisible }: InputProps) {
  const { reset } = useCopilotChat(); // Get reset function

  return (
    <div style={{ display: isVisible ? "flex" : "none", alignItems: "center", gap: "10px", padding: "10px", borderTop: "1px solid #eee" }}>
      {/* Text Input */}
      <input
        disabled={inProgress}
        type="text"
        placeholder="Ask your question here..."
        style={{
          flex: 1,
          padding: "8px",
          borderRadius: "4px",
          border: "1px solid #ccc",
          outline: "none",
        }}
        onKeyDown={(e) => {
          if (e.key === "Enter") {
            onSend(e.currentTarget.value);
            e.currentTarget.value = "";
          }
        }}
      />

      {/* Send Button */}
      <button
        disabled={inProgress}
        style={{
          padding: "8px 12px",
          border: "none",
          borderRadius: "4px",
          background: "#007bff",
          color: "white",
          cursor: "pointer",
        }}
        onClick={(e) => {
          const input = e.currentTarget.previousElementSibling as HTMLInputElement;
          onSend(input.value);
          input.value = "";
        }}
      >
        Send
      </button>

      {/* Reset Chat Button */}
      <button
        style={{
          padding: "8px 12px",
          border: "none",
          borderRadius: "4px",
          background: "#f44336",
          color: "white",
          cursor: "pointer",
        }}
        onClick={() => reset()}
      >
        Reset
      </button>
    </div>
  );
}
```
</ImageAndCode> 



================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/index.mdx
================================================
---
title: "Customize UI"
description: "Customize the look, feel, and functionality of CopilotKit's UI components."
icon: "lucide/Settings"
---
import { MessageCircleIcon, BrushIcon, PuzzleIcon, SettingsIcon } from "lucide-react";

CopilotKit offers a variety of ways to create a UI interface for your Copilots and CoAgents. This ranges
from using our built-in UI components to fully customizing the UI with headless UI.

<Cards>
  <Card
    title="Prebuilt Copilot UI"
    icon={<MessageCircleIcon />}
    description="Get started quickly with CopilotKit's ready-to-use UI components."
    href="/guides/custom-look-and-feel/built-in-ui-components"
  />
  <Card
    title="Styling Copilot UI"
    icon={<BrushIcon />}
    description="Customize the appearance of CopilotKit's pre-built components with your own styles."
    href="/guides/custom-look-and-feel/customize-built-in-ui-components"
  />
  <Card
    title="Custom Components"
    icon={<PuzzleIcon />}
    description="Replace the Copilot UI components with your own while keeping the core functionality."
    href="/guides/custom-look-and-feel/bring-your-own-components"
  />
  <Card
    title="Fully Custom UI"
    icon={<SettingsIcon />}
    description="Build your UI from scratch using CopilotKit's hooks and core functionality."
    href="/guides/custom-look-and-feel/headless-ui"
  />
</Cards>


================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/markdown-rendering.mdx
================================================
---
title: Markdown rendering
icon: "lucide/MessageSquareCode"
---
import { Frame } from "@/components/react/frame"

When rendering an assistant message, CopilotKit uses [`react-markdown`](https://remarkjs.github.io/react-markdown/) under the hood.
This allows us to render rich text with links, headers and other UI components.

If you wish to modify this behavior, you can either enrich and override the individual markdown components, or replace the entire `<AssistantMessage />` entirely.
This is useful for displaying elements within the assistant answer text, such as source citing, reasoning steps etc.

<Frame>
    <img className="rounded-none w-80" src="/images/custom-markdown-example.png" />
</Frame>

Here's how it can be done:

## Replacing/Providing the markdown components with your own
We will be adding a chip component. Similar to the one available with ChatGPT when sources are cited.
<Steps>
<Step>
First, let's create a chip component
```tsx
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar, ComponentsMap } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";
// We will include the styles in a separate css file, for convenience
import "./styles.css";

function YourComponent() {
    const customMarkdownTagRenderers: ComponentsMap<{ "reference-chip": { href: string } }> = {
        // You can make up your own tags, or use existing, valid HTML ones!
        "reference-chip": ({ children, href }) => {
            return (
                <a
                href={href}
                target="_blank"
                rel="noopener noreferrer"
                className="w-fit border rounded-xl py-1 px-2 text-xs" // Classes list trimmed for brevity
                >
                    {children}
                    <LinkIcon className="w-3.5 h-3.5" />
                </a>
            );
        },
    };

    return (
        <CopilotKit>
          <CopilotSidebar
            // For demonstration, we'll force the LLM to return our reference chip in every message
            instructions={`
                You are a helpful assistant.
                End each message with a reference chip,
                like so: <reference-chip href={href}>{title}</reference-chip>
            `}
            markdownTagRenderers={customMarkdownTagRenderers}
          />
        </CopilotKit>
    )
}
```
</Step>
<Step>
Now, let's add styles to the component
```css
.reference-chip {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    background-color: #f0f1f2;
    color: #444;
    border-radius: 12px;
    padding: 2px 8px;
    font-size: 0.8rem;
    font-weight: 500;
    text-decoration: none;
    margin: 0 2px;
    border: 1px solid #e0e0e0;
    cursor: pointer;
    box-shadow: 0 1px 2px rgba(0,0,0,0.05);
}
```
</Step>
</Steps>

## Replacing the entire markdown renderer

If you wish to avoid the markdown renderer altogether, you can replace the `<AssistantMessage />` component, which is the one to use it.
See [Custom Sub-Components](/guides/custom-look-and-feel/bring-your-own-components)


================================================
FILE: docs/content/docs/(root)/guides/custom-look-and-feel/meta.json
================================================
{
  "title": "Customize UI",
  "icon": "lucide/Paintbrush",
  "pages": [
    "built-in-ui-components",
    "customize-built-in-ui-components",
    "bring-your-own-components",
    "markdown-rendering",
    "headless-ui"
  ]
}


================================================
FILE: docs/content/docs/(root)/troubleshooting/common-issues.mdx
================================================
---
title: Common Issues
description: Common issues you may encounter when using Copilots.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

Welcome to the CopilotKit Troubleshooting Guide! Here, you can find answers to common issues

<Callout>
    Have an issue not listed here? Open a ticket on [GitHub](https://github.com/CopilotKit/CopilotKit/issues) or reach out on [Discord](https://discord.com/invite/6dffbvGU3D)
    and we'll be happy to help.

    We also highly encourage any open source contributors that want to add their own troubleshooting issues to [Github as a pull request](https://github.com/CopilotKit/CopilotKit/blob/main/CONTRIBUTING.md).

</Callout>

## I am getting network errors / API not found error

If you're encountering network or API errors, here's how to troubleshoot:

<Accordions>
    <Accordion title="Check your endpoint configuration">
        Verify your endpoint configuration in your CopilotKit setup:

        ```tsx
        <CopilotKit
          runtimeUrl="/api/copilotkit"
        >
          {/* Your app */}
        </CopilotKit>
        ```

        or, if using CopilotCloud
        ```tsx
        <CopilotKit
            publicApiKey="<your-copilot-cloud-public-api-key>"
        >
            {/* Your app */}
        </CopilotKit>
        ```

        Common issues:
        - Missing leading slash in endpoint path
        - Incorrect path relative to your app's base URL, or, if using absolute paths, incorrect full URL
        - Typos in the endpoint path
        - If using CopilotCloud, make sure to omit the `runtimeUrl` property and provide a valid API key
    </Accordion>
    <Accordion title="localhost vs 127.0.0.1">
        If you're running locally and getting connection errors, try using `127.0.0.1` instead of `localhost`:

        ```bash
        # If this doesn't work:
        http://localhost:3000/api/copilotkit

        # Try this instead:
        http://127.0.0.1:3000/api/copilotkit
        ```

        This is often due to local DNS resolution issues in `/etc/hosts` or network configuration.
    </Accordion>
    <Accordion title="Verify your backend is running">
        Make sure your backend server is:
        - Running on the expected port
        - Accessible from your frontend
        - Not blocked by CORS or firewalls

        Check the [quickstart](/quickstart) to see how to set it up
    </Accordion>

</Accordions>

## I am getting "CopilotKit's Remote Endpoint" not found error

If you're getting a "CopilotKit's Remote Endpoint not found" error, it usually means the server serving `/info` endpoint isn't accessible. Here's how to fix it:

<Accordions>
    <Accordion title="Check your FastAPI setup (if using python's FastAPI)">
        Make sure your FastAPI app has the CopilotKitSDK properly set up.<br/>
        Refer to [Remote Python Endpoint](/guides/backend-actions/remote-backend-endpoint) to see how to set it up
    </Accordion>
    <Accordion title="Test your endpoint">
        The `/info` endpoint should return agent or action information. Test it directly:

        ```bash
        curl -v -d '{}' http://localhost:8000/copilotkit/info
        ```
        The response looks something like this:
        ```bash
        * Host localhost:8000 was resolved.
        * IPv6: ::1
        * IPv4: 127.0.0.1
        *   Trying [::1]:8000...
        * connect to ::1 port 8000 from ::1 port 55049 failed: Connection refused
        *   Trying 127.0.0.1:8000...
        * Connected to localhost (127.0.0.1) port 8000
        > POST /copilotkit/info HTTP/1.1
        > Host: localhost:8000
        > User-Agent: curl/8.7.1
        > Accept: */*
        > Content-Length: 2
        > Content-Type: application/x-www-form-urlencoded
        >
        * upload completely sent off: 2 bytes
        < HTTP/1.1 200 OK
        < date: Thu, 16 Jan 2025 17:45:05 GMT
        < server: uvicorn
        < content-length: 214
        < content-type: application/json
        <
        * Connection #0 to host localhost left intact
        {"actions":[],"agents":[{"name":"my_agent","description":"A helpful agent.","type":"langgraph"},],"sdkVersion":"0.1.32"}%
        ```

        As you can see, it's a JSON response with your registered agents and actions, as well as the `200 OK` HTTP response status.
        If you see a different response, check your FastAPI logs for errors.
    </Accordion>

</Accordions>

## Connection issues with tunnel creation

If you notice the tunnel creation process spinning indefinitely, your router or ISP might be blocking the connection to CopilotKit's tunnel service.

<Accordions>
    <Accordion title="Router or ISP blocking tunnel connections">
        To verify connectivity to the tunnel service, try these commands:

        ```bash
        ping tunnels.devcopilotkit.com
        curl -I https://tunnels.devcopilotkit.com
        telnet tunnels.devcopilotkit.com 443
        ```

        If these fail, your router's security features or ISP might be blocking the connection. Common solutions:
        - Check router security settings
        - Contact your ISP to verify if they're blocking the connection
        - Try a different network to confirm the issue
    </Accordion>

</Accordions>



================================================
FILE: docs/content/docs/(root)/troubleshooting/meta.json
================================================
{
  "title": "Troubleshooting",
  "pages": [
    "common-issues",
    "migrate-to-1.8.2"
  ]
}



================================================
FILE: docs/content/docs/(root)/troubleshooting/migrate-to-1.8.2.mdx
================================================
---
title: Migrate to 1.8.2
description: Migration guide for CopilotKit 1.8.2
---
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
import { NewLookAndFeelPreview } from "@/components/react/component-previews/new-look-and-feel";

## What's changed?

### New Look and Feel

CopilotKit 1.8.2 introduces a new default look and feel. This includes new use of theming variables, new components, and generally a fresh look.

**Click the button in the bottom right to see the new look and feel in action!**

### Thumbs Up/Down Handlers

The chat components now have `onThumbsUp` and `onThumbsDown` handlers. Specifying these will add icons to each message
on hover allowing the user to provide feedback.

```tsx
<CopilotChat 
  onThumbsUp={(message) => console.log(message)} 
  onThumbsDown={(message) => console.log(message)}     
/>
```

This was previously achievable in our framework, but we're making it first class now! You can use this to help fine-tune your model through CopilotKit
or just generally track user feedback.

### ResponseButton prop removed

The `ResponseButton` prop has been removed. This was a prop that was used to customize the button that appears after a response was generated
in the chat. 

In its place, we now place buttons below each message for:
- Thumbs up
- Thumbs down
- Copy
- Regenerate

The behvior, icons and styling for each of these buttons can be customized. Checkout our [look and feel guides](/guides/custom-look-and-feel) for more details.

### Out-of-the-box dark mode support

CopilotKit now has out-of-the-box dark mode support. This is controlled by the `.dark` class (Tailwind) as well as the 
`color-scheme` CSS selector.

If you would like to make a custom theme, you can do so by checking out the [custom look and feel](/guides/custom-look-and-feel) guides.

<NewLookAndFeelPreview/>



================================================
FILE: docs/content/docs/(root)/tutorials/meta.json
================================================
{
  "title": "tutorials",
  "pages": [
    "ai-todo-app",
    "ai-powered-textarea"
  ]
}


================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/meta.json
================================================
{
  "title": "Tutorial: AI Powered Textarea",
  "icon": "lucide/TextSelect",
  "pages": [
    "overview",
    "step-1-checkout-repo",
    "step-2-setup-copilotkit",
    "step-3-copilot-textarea",
    "step-4-copilot-readable-state",
    "next-steps"
  ]
}


================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/next-steps.mdx
================================================
---
title: "Next Steps"
---

This is the end of the tutorial. You can now start building your own copilot-powered apps!

## Source code

You can find the source code and interactive sandboxes here:

- **Start app:** [GitHub](https://github.com/CopilotKit/example-textarea/tree/base-start-here) | [Stackblitz Sandbox](https://stackblitz.com/github/copilotkit/example-textarea/tree/base-start-here?file=lib%2Fhooks%2Fuse-tasks.tsx)
- **Final app:** [GitHub](https://github.com/CopilotKit/example-textarea/tree/final) | [Stackblitz Sandbox](https://stackblitz.com/github/copilotkit/example-textarea/tree/final?file=lib%2Fhooks%2Fuse-tasks.tsxd)

## What's next?

For next steps, here are some ideas:

- Add a chat element to your copilot using the [`<CopilotPopup />`](/reference/components/chat/CopilotPopup) component.
- Add actions to your copilot using the [`useCopilotAction`](/reference/hooks/useCopilotAction) hook.
- Follow the [Todos App Copilot tutorial](/tutorials/ai-todo-app/overview) to learn more about CopilotKit.

We have more tutorials coming soon.

## Need help?

If you have any questions, feel free to reach out to us on [Discord](https://discord.gg/6dffbvGU3D).



================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/overview.mdx
================================================
---
title: Overview
---
import { YouTubeVideo } from "@/components/react/youtube-video";
import { FaGithub } from "react-icons/fa";
import Link from "next/link";

<div>
  <div>**Time to complete:** 5 minutes</div>
  <div>**Difficulty:** Easy</div>
</div>

<br />

<YouTubeVideo videoId="C7px2wxr0k4" defaultPlaybackRate={1.25} />

## What you'll learn

In this tutorial, you will take a simple email application and add AI-powered autocompletion to it. The app is a simple email client, with a regular textarea used to compose an email. You're going to add CopilotKit to the app, so that the textarea provides relevant autocompletions as you type. The textarea will be aware of the full email history.

You will learn:

- 💡 How to use `useCopilotReadable` to allow your copilot to read the state of your app
- 💡 How to use the `<CopilotTextarea />` component to get instant context-aware autocompletions in your app
- 💡 How to use the Copilot Textarea Action Popup to generate text or adjust existing text in the textarea

## Try it out!

You can try out an interactive example of the end result below:

<Link href="https://github.com/CopilotKit/example-textarea?ref=docs-tutorial" className="no-underline" target="_blank">
  <button className="bg-neutral-800 text-white px-4 py-2 rounded-lg flex items-center gap-2 mt-2 font-medium">
    <FaGithub className="w-4 h-4" />
    <span>View source code on GitHub</span>
  </button>
</Link>

<div className="flex flex-col shadow-lg rounded-lg my-4">
  <div className="bg-neutral-800 h-11 rounded-t-lg flex items-center px-4">
    <div className="flex-1 text-center text-white font-medium">CopilotKit Todo List Copilot Demo</div>
  </div>
  <iframe
    className="rounded-b-lg h-[850px]"
    src="https://example-textarea.vercel.app/"
    width="100%"
    referrerPolicy="strict-origin-when-cross-origin"
    title="CopilotKit Textarea Demo"
    frameBorder="0"
    allowFullScreen
    ></iframe>
</div>

In the next step, we'll start building our copilot.


================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/step-1-checkout-repo.mdx
================================================
---
title: "Step 1: Checkout the repo"
---

<Steps>
<Step>
### Checkout the repository
We'll begin by checking out the base code of the todo list app. We'll start from the `base-start-here` branch.

```shell
git clone -b base-start-here https://github.com/CopilotKit/example-textarea.git
cd example-textarea
```
</Step>
<Step>
### Install dependencies

To install the dependencies, run the following:

```shell
npm install
```
</Step>
<Step>
### Start the project

Now, you are ready to start the project by running:

```shell
npm run dev
```

You should be able to go to [http://localhost:3000](http://localhost:3000) and see the todo list app. Feel free to play around with the app to get a feel for it.
</Step>
</Steps>

Next, let's start adding some AI copilot superpowers to this app.


================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/step-2-setup-copilotkit.mdx
================================================
---
title: "Step 2: Setup CopilotKit"
---
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content";
import { FaCloud, FaServer } from "react-icons/fa";

Now that we have our todo list app running, we're ready to integrate CopilotKit. For this tutorial, we will install the following dependencies:

- `@copilotkit/react-core`: The core library for CopilotKit, which contains the CopilotKit provider and useful hooks.
- `@copilotkit/react-textarea`: The textarea component for CopilotKit, which enables you to get instant context-aware autocompletions in your app.

## Install Dependencies

To install the CopilotKit dependencies, run the following:

```package-install
npm install @copilotkit/react-core @copilotkit/react-textarea
```

## Setup CopilotKit

<TailoredContent id="hosting">
<TailoredContentOption
  id="copilot-cloud"
  title="Copilot Cloud (Recommended)"
  description="Use our hosted backend endpoint to get started quickly (OpenAI only)."
  icon={<FaCloud />}
>
In order to use CopilotKit, we'll need to configure the CopilotKit provider.

<CopilotCloudConfigureCopilotKitProvider components={props.components} />
</TailoredContentOption>
<TailoredContentOption
  id="self-hosted"
  title="Self-hosting"
  description="Learn to host CopilotKit's runtime yourself with your own backend."
  icon={<FaServer />}
>
<Steps>
<Step>
### Set up Copilot Runtime Endpoint
<SelfHostingCopilotRuntimeCreateEndpoint components={props.components} />
</Step>
<Step>
### Configure the CopilotKit Provider

```tsx title="app/page.tsx" showLineNumbers {5,10,14}
"use client";

import { EmailThread } from "@/components/EmailThread";
import { EmailsProvider } from "@/lib/hooks/use-emails";
import { CopilotKit } from "@copilotkit/react-core"; // [!code highlight]
import "@copilotkit/react-textarea/styles.css"; // [!code highlight]

export default function Home() {
  return (
    <CopilotKit runtimeUrl="/api/copilotkit"> // [!code highlight]
      <EmailsProvider>
        <EmailThread />
      </EmailsProvider>
    </CopilotKit> // [!code highlight]
  );
}
```
</Step>
</Steps>
</TailoredContentOption>
</TailoredContent>

Let's break this down:

- First, we imported the `CopilotKit` provider from `@copilotkit/react-core`.
- Then, we wrapped the page with the `<CopilotKit>` provider.
- We imported the built-in styles from `@copilotkit/react-textarea`.

In the next step, we'll implement the AI-powered textarea as a replacement for our existing input component.



================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/step-3-copilot-textarea.mdx
================================================
---
title: "Step 4: Copilot Textarea"
---

Currently, our app has a simple textarea for replying to emails. Let's replace this with an AI-powered textarea so that we can benefit from our helpful AI assistant.

## The `<Reply />` Component

Head over to the [`/components/Reply.tsx`](https://github.com/CopilotKit/example-textarea/blob/base-start-here/components/Reply.tsx) file.

At a glance, you can see that this component uses `useState` to hold the current input value and provide it to the textarea. We also use the `onChange` prop of the textarea to update the state.

## Implementing `<CopilotTextarea />`

The `<CopilotTextarea />` component was designed to be a drop-in replacement for the `<textarea />` component. Let's implement it!

```tsx title="components/Reply.tsx"
// ... the rest of the file

import { CopilotTextarea } from "@copilotkit/react-textarea"; // [!code highlight]

export function Reply() {
  // ...
  return (
    <div className="mt-4 pt-4 space-y-2 bg-background p-4 rounded-md border">
      <CopilotTextarea // [!code highlight]
        className="min-h-40 border h-40 p-2 overflow-hidden"
        value={input}
        onChange={(e) => setInput(e.target.value)}
        placeholder="Write your reply..."
        // [!code highlight:5]
        autosuggestionsConfig={{
          textareaPurpose: `Assist me in replying to this email thread. Remember all important details.`,
          chatApiConfigs: {}
        }}
      />
      <Button disabled={!input} onClick={handleReply}>
        Reply
      </Button>
    </div>
  );
}
```

We import the `<CopilotTextarea />` component and use it in place of the `<textarea />` component. There are also some optional style changes made here.

We can provide more specific instructions for this particular textarea via the `autoSuggestionsConfig.textareaPurpose` property.

## Try it out!

Now, go back to the app and type anything in the textarea. You will see that the AI assistant provides suggestions as you type. How cool is that?

## The `CMD + K`/`CTRL + K` Shortcut

While focused on the textarea, you can use the `CMD + K` (macOS) or `CTRL + K` (Windows) shortcut to open the action popup. Here, you can give the copilot specific instructions, such as:

- `Rephrase the text to be more formal`
- `Make the reply shorter`
- `Tell John that I'm happy to help`

<br />
<hr />

We have implemented the `<CopilotTextarea />` component, but there is an issue - the copilot assistant is not aware of the email thread. In the next step, we'll make CopilotKit aware of our email history.



================================================
FILE: docs/content/docs/(root)/tutorials/ai-powered-textarea/step-4-copilot-readable-state.mdx
================================================
---
title: "Step 3: Copilot Readable State"
---

At this point, we have set up our CopilotKit provider and `<CopilotTextarea />`, and we already benefit from a great AI assistant. However, there is one last problem - the copilot assistant is not aware of the email thread. Let's fix that.

## Our App's State

Let's quickly review how our app's state works. Open up the [`lib/hooks/use-emails.tsx`](https://github.com/CopilotKit/example-textarea/blob/base-start-here/lib/hooks/use-emails.tsx) file.

At a glance, we can see that the file exposes a provider (`EmailsProvider`) which holds our `emails`. This is the context we need to provide to our copilot to get AI autocompletions. 

## The `useCopilotReadable` hook

Our goal is to make our copilot aware of this state, so that it can provide more accurate and helpful responses. We can easily achieve this by using the [`useCopilotReadable`](/reference/hooks/useCopilotReadable) hook.

```tsx title="libs/hooks/use-emails.tsx"
// ... the rest of the file

import { useCopilotReadable } from "@copilotkit/react-core"; // [!code highlight]

export const EmailsProvider = ({ children }: { children: ReactNode }) => {
  const [emails, setEmails] = useState<Email[]>(emailHistory);

  // [!code highlight:5]
  useCopilotReadable({
    description: "The history of this email thread",
    value: emails
  });

  // ... the rest of the file
}
```

In this example, we use the `useCopilotReadable` hook to provide the copilot with the state of our email thread.

- For the `description` property, we provide a concise description that tells the copilot what this piece of readable data means.
- For the `value` property, we pass the entire state as a JSON string.

In the next step, we'll set up our AI-powered textarea, which will use this readable state to provide accurate and helpful responses.

## Try it out!

Now, go back to the app and start typing things related to the email thread. Some ideas:

- `"Thanks Jo..."` (the assistant will complete John's name)
- `"I'm glad Spac..."` (the assistant will complete the company's name to SpaceY)
- `"I'm glad they liked my..."` (the assistant will add context)

Your textarea is now fully aware of the email thread, and therefore it provides helpful, relevant autocompletions. 🚀



================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/meta.json
================================================
{
  "title": "Tutorial: AI Todo App",
  "icon": "lucide/ListChecks",
  "pages": [
    "overview",
    "step-1-checkout-repo",
    "step-2-setup-copilotkit",
    "step-3-copilot-readable-state",
    "step-4-copilot-actions",
    "next-steps"
  ]
}


================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/next-steps.mdx
================================================
---
title: "Next Steps"
---

This is the end of the tutorial. You can now start building your own copilot-powered apps!

## Source code

You can find the source code and interactive sandboxes here:

- **Start app:** [GitHub](https://github.com/CopilotKit/example-todos-app/tree/base-start-here) | [Stackblitz Sandbox](https://stackblitz.com/github/copilotkit/example-todos-app/tree/base-start-here?file=lib%2Fhooks%2Fuse-tasks.tsx)
- **Final app:** [GitHub](https://github.com/CopilotKit/example-todos-app/tree/final) | [Stackblitz Sandbox](https://stackblitz.com/github/copilotkit/example-todos-app/tree/final?file=lib%2Fhooks%2Fuse-tasks.tsxd)

## What's next?

For next steps, here are some ideas:

- Add suggestions to your copilot, using the [`useCopilotChatSuggestions`](/reference/hooks/useCopilotChatSuggestions) hook.
- Add an initial assistant message to your chat window (for more info, check the documentation for [`<CopilotPopup />`](/reference/components/chat/CopilotPopup)).
- Dive deeper into the useful [`useCopilotChat`](/reference/hooks/useCopilotChat) hook, which enables you to set the system message, append messages, and more.
- Implement autocompletion using the [`<CopilotTextarea />`](/reference/components/CopilotTextarea) component.
- Follow the [Textarea Autocomplete tutorial](/tutorials/ai-powered-textarea/overview) to learn more about CopilotKit.

We have more tutorials coming soon.

## Need help?

If you have any questions, feel free to reach out to us on [Discord](https://discord.gg/6dffbvGU3D).



================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/overview.mdx
================================================
---
title: Overview
---
import { YouTubeVideo } from "@/components/react/youtube-video";
import { FaGithub } from "react-icons/fa";
import Link from "next/link";

# AI Todo List Copilot Tutorial

<div>
  <div>**Time to complete:** 5 minutes</div>
  <div>**Difficulty:** Easy</div>
</div>

<br />

<YouTubeVideo videoId="n1lJyaLam7g" defaultPlaybackRate={1.25} />

## What you'll learn

In this tutorial, you will take a simple todo list app and supercharge it with a copilot. You will learn:

- 💡 How to embed an in-app copilot with a chat UI
- 💡 How to use `useCopilotReadable` to allow your copilot to read the state of your app
- 💡 How to use `useCopilotAction` to allow your copilot to perform actions

## Try it out!

You can try out an interactive example of the end result below:

<Link href="https://github.com/CopilotKit/example-todos-app?ref=docs-tutorial" className="no-underline" target="_blank">
  <button className="bg-neutral-800 text-white px-4 py-2 rounded-lg flex items-center gap-2 mt-2 font-medium">
    <FaGithub className="w-4 h-4" />
    <span>View source code on GitHub</span>
  </button>
</Link>

<div className="flex flex-col shadow-lg rounded-lg my-4">
  <div className="bg-neutral-800 h-11 rounded-t-lg flex items-center px-4">
    <div className="flex-1 text-center text-white font-medium">CopilotKit Todo List Copilot Demo</div>
  </div>
  <iframe
    className="rounded-b-lg"
    src="https://example-todos-app.vercel.app/"
    width="100%"
    height="700"
    referrerPolicy="strict-origin-when-cross-origin"
    title="CopilotKit Todo List Copilot Demo"
    frameBorder="0"
    allowFullScreen
    ></iframe>
</div>

In the next step, we'll start building our copilot.


================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/step-1-checkout-repo.mdx
================================================
---
title: "Step 1: Checkout the repo"
---

<Steps>
<Step>
### Checkout the repository
We'll begin by checking out the base code of the todo list app. We'll start from the `base-start-here` branch.

```shell
git clone -b base-start-here https://github.com/CopilotKit/example-todos-app.git
cd example-todos-app
```
</Step>
<Step>
### Install dependencies

To install the dependencies, run the following:

```shell
npm install
```
</Step>
<Step>
### Start the project

Now, you are ready to start the project by running:

```shell
npm run dev
```

You should be able to go to [http://localhost:3000](http://localhost:3000) and see the todo list app. Feel free to play around with the app to get a feel for it.
</Step>
</Steps>

Next, let's start adding some AI copilot superpowers to this app.


================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/step-2-setup-copilotkit.mdx
================================================
---
title: "Step 2: Setup CopilotKit"
---
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content";
import { FaCloud, FaServer } from "react-icons/fa";

Now that we have our todo list app running, we're ready to integrate CopilotKit. For this tutorial, we will install the following dependencies:

- `@copilotkit/react-core`: The core library for CopilotKit, which contains the CopilotKit provider and useful hooks.
- `@copilotkit/react-ui`: The UI library for CopilotKit, which contains the CopilotKit UI components such as the sidebar, chat popup, textarea and more.

## Install Dependencies

To install the CopilotKit dependencies, run the following:

```package-install
npm install @copilotkit/react-core @copilotkit/react-ui
```

## Setup CopilotKit

<TailoredContent id="hosting">
<TailoredContentOption
  id="copilot-cloud"
  title="Copilot Cloud (Recommended)"
  description="Use our hosted backend endpoint to get started quickly (OpenAI only)."
  icon={<FaCloud />}
>
In order to use CopilotKit, we'll need to configure the `CopilotKit` provider.

<CopilotCloudConfigureCopilotKitProvider components={props.components} />
</TailoredContentOption>
<TailoredContentOption
  id="self-hosted"
  title="Self-hosting"
  description="Learn to host CopilotKit's runtime yourself with your own backend."
  icon={<FaServer />}
>

<Steps>
<Step>
### Set up Copilot Runtime Endpoint
<SelfHostingCopilotRuntimeCreateEndpoint components={props.components} />
</Step>
<Step>

### Configure the CopilotKit Provider

<SelfHostingCopilotRuntimeConfigureCopilotKitProvider components={props.components} />

</Step>
</Steps>
</TailoredContentOption>
</TailoredContent>

### CopilotKit Chat Popup

We provide several plug-and-play components for you to interact with your copilot. Some of these are `<CopilotPopup/>`, `<CopilotSidebar/>`, and `<CopilotChat/>`. You can of course use CopilotKit in headless mode and provide your own fully custom UI via [`useCopilotChat`](/reference/hooks/useCopilotChat).

In this tutorial, we'll use the `<CopilotPopup/>` component to display the chat popup.

```tsx title="app/page.tsx" showLineNumbers {6-7,15}
"use client";

import { TasksList } from "@/components/TasksList";
import { TasksProvider } from "@/lib/hooks/use-tasks";
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotPopup } from "@copilotkit/react-ui"; // [!code highlight]
import "@copilotkit/react-ui/styles.css"; // [!code highlight]

export default function Home() {
  return (
    <>
      <TasksProvider>
        <TasksList />
      </TasksProvider>
      <CopilotPopup /> // [!code highlight]
    </>
  );
}
```

Here's what we did:

- We imported the `<CopilotPopup />` component from `@copilotkit/react-ui`.
- We wrapped the page with the `<CopilotKit>` provider.
- We imported the built-in styles from `@copilotkit/react-ui`.

Now, head back to your app and you'll find a chat popup in the bottom right corner of the page. At this point, you can start interacting with your copilot! 🎉

In the next step, we'll make our assistant smarter by providing it with readable state about our todo list.



================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/step-3-copilot-readable-state.mdx
================================================
---
title: "Step 3: Copilot Readable State"
---

At this point, we have a chat popup in our app and we're able to chat directly with our copilot. This is great, but our copilot doesn't know anything about our app. In this step, we'll provide our copilot with the state of our todos.

In this step, you'll learn how to provide knowledge to the copilot. In our case, we want the copilot to know about the tasks in our app.

## Our App's State

Let's quickly review how our app's state works. Open up the [`lib/hooks/use-tasks.tsx`](https://github.com/CopilotKit/example-todos-app/blob/base-start-here/lib/hooks/use-tasks.tsx) file.

At a glance, we can see that the file exposes a provider (`TasksProvider`), which defines a useful things:

- The state of our tasks (`tasks`)
- A function to add a task (`addTask`)
- A function to update a task (`updateTask`)
- A function to delete a task (`deleteTask`)

All of this is consumable by a `useTasks` hook, which we use in the rest of our application (feel free to check out the `TasksList`, `AddTask` and `Task` components).

This resembles the majority of React apps, where frontend state, either for a feature or the entire app, is managed by a context or state management library.

## The `useCopilotReadable` hook

Our goal is to make our copilot aware of this state, so that it can provide more accurate and helpful responses. We can easily achieve this by using the [`useCopilotReadable`](/reference/hooks/useCopilotReadable) hook.

```tsx title="lib/hooks/use-tasks.tsx" {3,8-11}
// ... the rest of the file

import { useCopilotReadable } from "@copilotkit/react-core"; // [!code highlight]

export const TasksProvider = ({ children }: { children: ReactNode }) => {
  const [tasks, setTasks] = useState<Task[]>(defaultTasks);

  // [!code highlight:5]
  useCopilotReadable({
    description: "The state of the todo list",
    value: JSON.stringify(tasks)
  });

  // ... the rest of the file
}
```

In this example, we use the `useCopilotReadable` hook to provide the copilot with the state of our tasks.

- For the `description` property, we provide a concise description that tells the copilot what this piece of readable data means.
- For the `value` property, we pass the entire state as a JSON string.

## Try it out!

Now, try it out! Ask your Copilot a question about the state of the todo list. For example:

> How many tasks do I still need to get done?

Magical, isn't it? ✨ In the next step, you'll learn how to make the copilot take actions based on the state of your app.




================================================
FILE: docs/content/docs/(root)/tutorials/ai-todo-app/step-4-copilot-actions.mdx
================================================
---
title: "Step 4: Copilot Actions"
---

Now it's time to make our copilot even more useful by taking actions.

## Available Actions

Once again, let's take a look at our app's state in the [`lib/hooks/use-tasks.tsx`](https://github.com/CopilotKit/example-todos-app/blob/base-start-here/lib/hooks/use-tasks.tsx#L19-L33) file.

Essentially, we want our copilot to be able to call the `addTask`, `setTaskStatus` and `deleteTask` functions.

## The `useCopilotAction` hook

The [`useCopilotAction`](/reference/hooks/useCopilotAction) hook makes actions available to our copilot. Let's implement it in the [`lib/hooks/use-tasks.tsx`](https://github.com/CopilotKit/example-todos-app/blob/base-start-here/lib/hooks/use-tasks.tsx) file.

```tsx filename="lib/hooks/use-tasks.tsx" showLineNumbers {3-3,8-22,24-38,40-61}
// ... the rest of the file

import { useCopilotReadable, useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]

export const TasksProvider = ({ children }: { children: ReactNode }) => {
  const [tasks, setTasks] = useState<Task[]>(defaultTasks);

  // [!code highlight:16]
  useCopilotAction({
    name: "addTask",
    description: "Adds a task to the todo list",
    parameters: [
      {
        name: "title",
        type: "string",
        description: "The title of the task",
        required: true,
      },
    ],
    handler: ({ title }) => {
      addTask(title);
    },
  });

  // [!code highlight:16]
  useCopilotAction({
    name: "deleteTask",
    description: "Deletes a task from the todo list",
    parameters: [
      {
        name: "id",
        type: "number",
        description: "The id of the task",
        required: true,
      },
    ],
    handler: ({ id }) => {
      deleteTask(id);
    },
  });

  // [!code highlight:23]
  useCopilotAction({
    name: "setTaskStatus",
    description: "Sets the status of a task",
    parameters: [
      {
        name: "id",
        type: "number",
        description: "The id of the task",
        required: true,
      },
      {
        name: "status",
        type: "string",
        description: "The status of the task",
        enum: Object.values(TaskStatus),
        required: true,
      },
    ],
    handler: ({ id, status }) => {
      setTaskStatus(id, status);
    },
  });

  // ... the rest of the file
};
```

The `useCopilotAction` hook is a powerful hook that allows us to register actions with our copilot. It takes an object with the following properties:

- `name` is the name of the action.
- `description` is a description of the action. It's important to choose a good description so that our copilot can choose the right action.
- `parameters` is an array of parameters that the action takes. It follows the [JSON Schema](https://json-schema.org/) format.
- `handler` is a function that will be called when the action is triggered. It's even type safe!

You can check out the full reference for the `useCopilotAction` hook [here](https://docs.copilotkit.ai/reference/hooks/useCopilotAction).

## Try it out!

Now, head back to the app and ask your pilot to do any of the following:

- "Create a task about inviting Daniel to my birthday"
- "Delete all outstanding tasks"
- "Mark task with ID 2 as done"
- etc.

Your copilot is now more helpful than ever 💪



================================================
FILE: docs/content/docs/ag2/agentic-chat-ui.mdx
================================================
---
title: Chat with an Agent
icon: "lucide/SendHorizontal"
description: Chat with an agent using CopilotKit's UI components.
---

import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import ComponentExamples from "@/snippets/component-examples.mdx";
import { UserIcon, PaintbrushIcon, WrenchIcon, RepeatIcon } from "lucide-react";

<video
  src="/images/coagents/agentic-chat-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-AG2)
  repo with various Copilot UI components applied to it!
</Callout>

## What is this?

Agentic chat UIs are ways for your users to interact with your agent. CopilotKit provides a variety of different components to choose from, each
with their own unique use cases.

If you've gone through the [quick start guide](/ag2/quickstart/ag2) **you already have a agentic chat UI setup**! Nothing else is needed
to get started.

## When should I use this?

CopilotKit provides a variety of different batteries-included components to choose from to create agent native applications. They scale
from simple chat UIs to completely custom applications.

<ComponentExamples components={props.components} /> 


================================================
FILE: docs/content/docs/ag2/frontend-actions.mdx
================================================
---
title: Frontend Actions
icon: "lucide/Wrench"
description: Create frontend actions and use them within your agent.
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/frontend-actions-demo.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-AG2)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## When should I use this?

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## Implementation

<Steps>
    <Step>
        ### Setup CopilotKit

        To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here.

        Check out our [getting started guide](/ag2/quickstart/ag2) and come back here when you're setup!
    </Step>

    <Step>
        ### Create a frontend action

        First, you'll need to create a frontend action using the [useCopilotAction](/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
        that says hello to the user.

        ```tsx title="page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core" // [!code highlight]

        export function Page() {
          // ...

          // [!code highlight:16]
          useCopilotAction({
            name: "sayHello",
            description: "Say hello to the user",
            available: "remote", // optional, makes it so the action is *only* available to the agent
            parameters: [
              {
                name: "name",
                type: "string",
                description: "The name of the user to say hello to",
                required: true,
              },
            ],
            handler: async ({ name }) => {
              alert(`Hello, ${name}!`);
            },
          });

          // ...
        }
        ```
    </Step>
    <Step>
        ###  Modify your agent
        Now, we'll need to modify the agent to access these frontend actions. Open up for your agent's folder and continue from there!
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Inheriting from CopilotKitState

        To access the frontend actions provided by CopilotKit, you can inherit from CopilotKitState in your agent's state definition:

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                # your code goes here...
                ```
            </Tab>
        </Tabs>

        By doing this, your agent's state will include the `copilotkit` property, which contains the frontend actions that can be accessed and invoked.
    </Step>
    <Step>
        ### Accessing Frontend Actions

        Once your agent's state includes the `copilotkit` property, you can access the frontend actions and utilize them within your agent's logic.

        Here's how you can call a frontend action from your agent:

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                # your code goes here...
                ```
            </Tab>
        </Tabs>

        These actions are automatically populated by CopilotKit and are compatible with LiteLLM's tool call definitions, making it straightforward to integrate them into your agent's workflow.
    </Step>
    <Step>
        ### Give it a try!
        You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/ag2/index.mdx
================================================
---
title: Introduction
icon: "lucide/Sparkles"
description: Build Agent-Native Applications (ANAs) powered by CopilotKit and AG2 Agents.
---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { FaDiscord } from "react-icons/fa";
import Link from "next/link";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import {
  LuPlane,
  LuBookOpen,
  LuLightbulb,
  LuLayoutTemplate,
  LuBrainCog,
  LuUserCog,
  LuWand2,
  LuPlay,
  LuMessageSquare,
  LuWrench,
} from "react-icons/lu";
import { CoAgentsExamples } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { FaSync } from "react-icons/fa";
import { Socials } from "@/components/react/socials";

<div className="p-4 mb-6 rounded-lg bg-indigo-50 dark:bg-indigo-950 border border-indigo-200 dark:border-indigo-800">
  <div className="flex items-center gap-2 mb-2">
    <LuBrainCog className="h-5 w-5 text-indigo-500 dark:text-indigo-300" />
    <h3 className="text-lg font-semibold text-indigo-700 dark:text-indigo-300">AG2 Overview</h3>
  </div>
  <p className="text-indigo-700 dark:text-indigo-300">
    Visit the <a href="https://v0-ag2-land.vercel.app/" target="_blank" rel="noopener noreferrer" className="font-medium underline underline-offset-4 decoration-indigo-400 dark:decoration-indigo-500 hover:text-indigo-600 dark:hover:text-indigo-200">AG2 Overview Page</a> to learn more about AG2's capabilities and features.
  </p>
</div>

# Copilot Infrastructure for AG2 Agents

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).


<div className="w-full border border-2 border-indigo-500/70 rounded-lg h-[550px] p-1 pb-6 my-10 shadow-lg flex flex-col items-center">
  <div className="w-full flex flex-col items-center border-b pb-4">
    <h2 className="text-xl font-semibold mb-2 text-center">Travel Planner Demo</h2>
    <h3 className="text-center text-sm text-gray-500 dark:text-gray-400 font-normal mb-4">Play around with a simple "travel agent" application built with AG2 Agents below.</h3>
  </div>
  <iframe src="https://ag2-starter.vercel.app/" className="w-full h-full dark" />
</div> 

## Building blocks of a CoAgent

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuMessageSquare className="text-indigo-500" />}
    title="Agentic Chat UI"
    description="In-app chat powered by your agent."
    href="/ag2/agentic-chat-ui"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuUserCog className="text-indigo-500" />}
    title="Human-in-the-Loop"
    description="Set smart checkpoints where humans can guide your agents."
    href="/ag2/human-in-the-loop"
  />
</Cards>

## Ready to get started?

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

<Cards>
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlay className="text-indigo-500" />}
    title="Quickstart"
    description="Learn how to build your first CoAgent in 5 minutes."
    href="/ag2/quickstart"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlay className="text-indigo-500" />}
    title="Feature Overview"
    description="Try the key features of CoAgents powered by AG2 Agents."
    href="https://ag2-feature-viewer.vercel.app/"
    target="_blank"
  />
</Cards>

{/* TODO: Add example tutorials for AG2 Agents */}
{/* TODO: Add CoAgents in action section for AG2 Agents */}

## Common Questions

Have a question about CoAgents? You're in the right place!

<Accordions>
<Accordion title="Can you explain what a CoAgent is in more detail?">
Sure! CoAgents are what we call "agentic copilots". Well, what's an agentic copilot then?

Think of a Copilot as a simple and fully LLM controlled assistant that has relatively limited capabilities. An Agentic Copilot then is a copilot
that has been enhanced with the ability to use AG2 agents to perform more complex tasks. This is an extremely powerful way to build AI
powered applications because it gives you, the developer, the ability to control the agent's behavior in a deterministic way while still letting
the agent do its magic.

</Accordion>
</Accordions> 


================================================
FILE: docs/content/docs/ag2/meta.json
================================================
{
  "title": "CoAgents",
  "root": true,
  "pages": [
    "index",
    "quickstart",
    "[lucide/Telescope][Feature Viewer](https://ag2-feature-viewer.vercel.app/)",
    "---Guides---",
    "agentic-chat-ui",
    "human-in-the-loop",
    "---Learn---",
    "...concepts"
  ]
}



================================================
FILE: docs/content/docs/ag2/quickstart.mdx
================================================
---
title: Quickstart
description: Turn your AG2 Agents into an agent-native application in 5 minutes.
icon: "lucide/Play"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import { FaPython, FaJs, FaCloud } from "react-icons/fa";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureRemoteEndpointLangGraph from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotKitCloudCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";
import CloudCopilotKitProvider from "@/snippets/coagents/cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/coagents/self-host-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeLangGraphEndpoint from "@/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx";
import SelfHostingCopilotRuntimeStarter from "@/snippets/self-hosting-copilot-runtime-starter.mdx";
import SelfHostingRemoteEndpoints from "@/snippets/self-hosting-remote-endpoints.mdx";
import {
  UserIcon,
  PaintbrushIcon,
  WrenchIcon,
  RepeatIcon,
  ServerIcon,
} from "lucide-react";
import CopilotUI from "@/snippets/copilot-ui.mdx";

<video
  src="/images/coagents/chat-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

## Introduction

This quickstart guide shows how to create a simple **Personalized Travel Planner** using AG2 and CopilotKit. In just minutes, you'll build an application that collects user travel preferences and generates custom day-by-day itineraries tailored to their destination, budget, and interests.

## Prerequisites

Before you begin, you'll need the following:

- **Python 3.9** or newer for running the AG2 backend
- <a href="https://nodejs.org/en/download" target="_blank">Node.js</a> 18.18.0 or newer (specifically: ^18.18.0 || ^19.8.0 || >= 20.0.0)
- <a href="https://pnpm.io/installation" target="_blank">pnpm</a> (for package management)
- <a href="https://platform.openai.com/api-keys" target="_blank">OpenAI API key</a>

## Getting started

<Steps>
    <Step>
        ### Clone the Starter Repository

        <Tabs groupId="language" items={["Python"]}>
            <Tab value="Python">
                ```bash
                git clone https://github.com/ag2ai/ag2-copilotkit-starter.git
                cd ag2-copilotkit-starter
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Set Up the AG2 Backend

        <Callout type="info">
            We recommend using a virtual environment for your project to keep your packages contained. See <a href="https://docs.python.org/3/library/venv.html" target="_blank">venv</a>.
        </Callout>

        #### Install the dependencies and set your `OPENAI_API_KEY`:

        ```bash
        cd agent-py
        pip install -r requirements.txt
        ```

        #### Set up your `OPENAI_API_KEY`:

        ```sh
        export OPENAI_API_KEY="your_openai_api_key"
        ```

        #### Launch your AG2 agent:

        ```bash
        uvicorn simple_workflow:app --port 8008 --reload
        ```
        The backend server will start at http://localhost:8008.
    </Step>
    <Step>
        ### Set Up the CopilotKit UI
        
        The last step is to use CopilotKit's UI components to render the chat interaction with your agent.

        In a new terminal:

        ```bash
        cd ui
        pnpm i
        pnpm run dev
        ```

        The frontend application will start at http://localhost:3000.
    </Step>
    <Step>
        ### 🎉 Talk to your agent!

        Congrats! You've successfully integrated a AG2 Agent chatbot to your application. To start, try asking a few questions to your agent.

        ```
        I plan to visit the USA for 4 days on a budget.
        ```

        ```
        I want to plan a trip to Paris for 5 days. I have a mid-range budget and I'm interested in art, history, and food.
        ```

        ```
        I'd like a luxury weekend in New York with focus on Broadway shows and fine dining.
        ```

        <img src="/images/coagents/ag2/quick-start-1.png" className="rounded-lg shadow-xl"/>
        <img src="/images/coagents/ag2/quick-start-2.png" className="rounded-lg shadow-xl"/>
    </Step>

</Steps>

---

## What's next?

You've now got a simple Personalized Travel Planner running with CopilotKit! This demonstrates how quickly you can build practical AI applications by combining AG2's conversational capabilities with CopilotKit's user interface components.

<Cards>
  <Card
    title="Implement Human in the Loop"
    description="Allow your users and agents to collaborate together on tasks."
    href="/ag2/human-in-the-loop"
    icon={<UserIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/ag2/concepts/ag2.mdx
================================================
---
title: AG2
description: An agentic framework for building LLM applications that can be used with Copilotkit.
icon: custom/ag2
---

<Frame>
  <img
    src="/images/coagents/ag2/AG2-CopilotKit.png"
    alt="AG2 CopilotKit"
    className="mb-10"
  />
</Frame>

AG2 is an agentic framework for building LLM applications that can be used with CopilotKit. This integration allows developers to combine and coordinate AI tasks efficiently, providing a robust framework for building sophisticated AI applications.

## AG2 as CoAgents

CopilotKit now integrates with AG2, bringing together AG2's multi-agent orchestration capabilities with CopilotKit's React UI components. This integration creates a more seamless development experience for building AI-powered applications.
At its core, CopilotKit is a set of tools that make it easy to let your users work alongside Large Language Models (LLMs) to accomplish generative tasks directly in your application. Instead of just using the LLM to generate content, you can let it take direct action alongside your users.
Key features of the AG2 and CopilotKit integration include:

- **Multi-Agent Orchestration**: AG2 enables sophisticated agent workflows and orchestration patterns
- **Human-in-the-Loop**: Human in the Loop (HITL) is a powerful pattern that enables your AG2 agents to collaborate with humans during their workflow. Instead of making all decisions independently, agents can check with human operators at critical decision points, combining AI efficiency with human judgment.

For a detailed guide on setting up AG2 CoAgents with CopilotKit, check out our [quickstart guide](/ag2/quickstart/ag2). 

## Learn More

For more information about AG2, check out the [AG2 documentation](https://docs.ag2.ai).



================================================
FILE: docs/content/docs/ag2/concepts/agentic-copilots.mdx
================================================
---
title: Agentic Copilots
description: Agentic copilots provide you with advanced control and orchestration over your agents.
icon: lucide/Bot
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content";
import { BsFillCloudHaze2Fill as CloudIcon } from "react-icons/bs";
import { FaServer as SelfHostIcon } from "react-icons/fa6";
import { SiLangchain } from "react-icons/si";
import { LinkIcon } from "lucide-react";
import {
  RocketIcon,
  GraduationCapIcon,
  CodeIcon,
  VideoIcon,
} from "lucide-react";

### What are Agents?
AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from
simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized
frameworks like AG2 become essential.

### What is AG2?
AG2 is a framework that gives you precise control over AI agents. AG2 agents allow developers to combine and coordinate coding tasks efficiently,
providing a robust framework for building sophisticated AI automations.

### What are Agentic Copilots?
Agentic copilots are how CopilotKit brings AG2 agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that
understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ)
for quick implementation, Agentic copilots give you AG2's full orchestration capabilities when you need more control over your agent's behavior.

### What are CoAgents?
CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

### When should I use CopilotKit's CoAgents?
You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [AG2](https://ag2.ai/).
With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.

The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's
functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
up to 100% of the Copilot's tasks (see [agent-lock mode](/ag2/multi-agent-flows) for the 100% case).

### Examples
An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-research-canvas).

More specifically, it demonstrates how CoAgents allow for AI driven experiences with:
- Precise state management across agent interactions
- Sophisticated multi-step reasoning capabilities
- Seamless orchestration of multiple AI tools
- Interactive human-AI collaboration features
- Real-time state updates and progress streaming

## Next Steps

Want to get started? You have some options!

<Cards>
    <Card
        title="Build your first CoAgent"
        description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
        href="/ag2/quickstart/ag2"
        icon={<RocketIcon />}
    />
    <Card
        title="Learn more CoAgent concepts"
        description="Learn more about the concepts used to talk about CoAgents and how to use them."
        href="/ag2/concepts/terminology"
        icon={<GraduationCapIcon />}
    />
</Cards>



================================================
FILE: docs/content/docs/ag2/concepts/meta.json
================================================
{
  "title": "Concepts",
  "root": true,
  "pages": [
    "terminology",
    "agentic-copilots",
    "ag2"
  ]
}



================================================
FILE: docs/content/docs/ag2/concepts/terminology.mdx
================================================
---
title: Terminology
icon: lucide/Book
---

Here are the key terms and concepts used throughout CoAgents:

| Term                         | Definition                                                                                                                                                                                         |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agentic Copilot              | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously.                                                                                     |
| CoAgent                      | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot.                                                            |
| Agent State                  | The current data and context maintained by a AG2 agent during its execution, including both internal state and data that can be synchronized with the frontend UI.                              |
| Agentic Generative UI        | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth                 | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents.            |
| Human-in-the-Loop (HITL)     | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points.                                         |
| Intermediate State           | The updates to agent state that occur during function execution, rather than only at flow transitions, enabling real-time feedback about the agent's progress.                                     |
| [AG2](https://ag2.ai) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management.                               |
| Agent Lock Mode              | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control.                                    |
| Router Mode                  | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows.                                   |
| State Streaming              | The real-time synchronization of agent state between the backend and frontend, enabling immediate updates to the UI as the agent performs tasks.                                                   |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications. 


================================================
FILE: docs/content/docs/ag2/human-in-the-loop/hitl.mdx
================================================
---
title: AG2 Agents
description: Learn how to implement Human-in-the-Loop (HITL) using AG2 Agents.
icon: lucide/Share2
---

import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";
import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/coagents/node-hitl.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

<Callout type="info">
The illustration above is from the [Coagent Starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter), included here for demonstration purposes.
</Callout>

## What is Human-in-the-Loop?

Human-in-the-Loop (HITL) adds a layer of human oversight to your AI agents. It allows agents to request human approval before taking important actions, creating a perfect balance between AI efficiency and human judgment. For a deeper dive into HITL concepts, check out the [AG2 documentation](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/human-in-the-loop).

## Our Enhanced Travel Agent

In this guide, we'll enhance our travel agent from the [Quick Start](/ag2/quickstart/ag2) guide with HITL functionality. The best part? We only need to modify the AG2 backend, no changes to the CopilotKit frontend are required!

You can find the complete code for this example in the [AG2-CopilotKit starter](https://github.com/ag2ai/ag2-copilotkit-starter/blob/main/agent-py/hitl_workflow.py) repository.

**Our travel agent will:**

- Ask for a member ID
- Request human approval before accessing customer data
- Retrieve travel preferences
- Seek human approval again before generating an itinerary

```mermaid
sequenceDiagram
    participant User
    participant CopilotKit as CopilotKit UI
    participant TravelAgent as Travel Agent (AG2)
    participant Functions as Backend Functions

    User->>CopilotKit: Provides member ID
    CopilotKit->>TravelAgent: Forwards member ID
    TravelAgent->>CopilotKit: Requests to call lookup_member()
    CopilotKit->>User: Shows approval request
    User->>CopilotKit: Approves function call
    CopilotKit->>TravelAgent: Approval granted
    TravelAgent->>Functions: Calls lookup_member()
    Functions->>TravelAgent: Returns member data
    TravelAgent->>CopilotKit: Requests travel details
    User->>CopilotKit: Provides travel details
    CopilotKit->>TravelAgent: Forwards travel details
    TravelAgent->>CopilotKit: Requests to call create_itinerary()
    CopilotKit->>User: Shows approval request
    User->>CopilotKit: Approves function call
    CopilotKit->>TravelAgent: Approval granted
    TravelAgent->>Functions: Calls create_itinerary()
    Functions->>TravelAgent: Returns personalized itinerary
    TravelAgent->>CopilotKit: Displays itinerary to user
    CopilotKit->>User: Shows final itinerary
```

## Implementation

Let's build our HITL-enabled travel planning system step by step:

### Step 1: Setup and Prerequisites

First, we need to set up our project environment:

- **Reuse the Quick Start project**: This guide builds directly on the [Quick Start](/ag2/quickstart/ag2) example. Begin by completing that setup if you haven't already.
- **No CopilotKit changes needed**: The HITL implementation only requires changes to the AG2 backend. Your existing CopilotKit frontend will automatically handle the approval UI without any modifications.

Let's start by importing the necessary libraries and setting up the basic structure. You can either create the `agent-py/hitl_workflow.py` file from scratch if you wish to follow along, or you can copy the code from the [AG2-CopilotKit starter](https://github.com/ag2ai/ag2-copilotkit-starter/blob/main/agent-py/hitl_workflow.py) repository.

```python title="agent-py/hitl_workflow.py"
import os
from typing import Any, Annotated

from autogen import ConversableAgent, LLMConfig, register_function
from fastapi import FastAPI

from fastagency import UI
from fastagency.adapters.awp import AWPAdapter
from fastagency.runtimes.ag2 import Workflow

# Configure LLM
llm_config = LLMConfig(
    model="gpt-4o-mini",
    api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.8,
)

wf = Workflow()

# Initial message to user
INITIAL_MESSAGE = """Hi there! 👋 I'm your personal Travel Guide, here to help you plan an unforgettable trip.

To get started, could you please share your membership ID? This will help me tailor recommendations based on your preferences and travel style.

(Hint: You can try using one of these IDs: P12345, P67890, S12345, S67890. And when the agent is asking your permission to execute the function, please say "continue" to proceed.)
"""
```

### Step 2: Create Functions Requiring Approval

In this step, we'll create functions that will require human approval before execution. These represent both sensitive operation like accessing customer data and non-sensitive operations like generating itineraries.

#### Database Simulation

First, let's create a mock customer database:

```python title="agent-py/hitl_workflow.py"
# Mock customer database
MEMBER_DATABASE = {
    "P12345": {
        "name": "Alex Johnson",
        "membership": "premium",
        "preferences": [
            "5-star hotels",
            "fine dining",
            "private tours",
            "exclusive experiences",
        ],
    },
    "P67890": {
        "name": "Taylor Williams",
        "membership": "premium",
        "preferences": [
            "boutique hotels",
            "local cuisine",
            "cultural experiences",
            "adventure activities",
        ],
    },
    "S12345": {
        "name": "Jordan Smith",
        "membership": "standard",
        "preferences": ["budget-friendly", "popular attractions"],
    },
    "S67890": {
        "name": "Casey Brown",
        "membership": "standard",
        "preferences": ["family-friendly", "group tours"],
    },
}
```

This mock database simulates what might be a real customer database in a production application. In a real application, this would likely be an API call to a secure database.

#### Member Lookup Function

Next, we'll create a function that requires human approval to access customer information:

```python title="agent-py/hitl_workflow.py"
# Function to look up member information
def lookup_member(
    member_id: Annotated[str, "User's membership ID"]
) -> dict[str, Any]:
    """Look up member details from the database"""
    # This function will require human approval before execution
    # because it accesses potentially sensitive customer information
    if member_id in MEMBER_DATABASE:
        return {
            "found": True,
            "name": MEMBER_DATABASE[member_id]["name"],
            "membership": MEMBER_DATABASE[member_id]["membership"],
            "preferences": MEMBER_DATABASE[member_id]["preferences"]
        }
    else:
        return {
            "found": False,
            "message": "Member ID not found in our system"
        }
```
This function accesses customer data based on a member ID. Here we are simulating a database lookup. In a real application, this would be a call to a secure database.

#### Itinerary Creation Function

We'll also create a function for generating travel itineraries, which will also require approval:

```python title="agent-py/hitl_workflow.py"
# Function to create personalized itinerary
def create_itinerary(
    destination: Annotated[str, "Travel destination (e.g., New York, Paris, Tokyo)"],
    days: Annotated[int, "Number of days for the trip"],
    membership_type: Annotated[str, "Type of membership (premium or standard)"],
    preferences: Annotated[list, "Traveler preferences (e.g., fine dining, cultural tours)"]
) -> dict[str, Any]:
    """Create a realistic, personalized travel itinerary based on member details."""
    # This function will require human approval before execution
    # because it's generating content that should be reviewed
    
    if not destination or days <= 0:
        return {"error": "Invalid destination or number of days."}

    itinerary = []
    for day in range(1, days + 1):
        day_plan = {
            "day": f"Day {day}",
            "morning": "",
            "afternoon": "",
            "evening": "",
        }

        if membership_type == "premium":
            day_plan["morning"] = f"Private tour or exclusive experience aligned with: {', '.join(preferences)}"
            day_plan["afternoon"] = "Relax at a luxury spa, explore high-end shopping districts, or enjoy curated local experiences."
            day_plan["evening"] = "Dine at a top-rated restaurant with a reservation made just for you."
        else:
            day_plan["morning"] = f"Join a small group tour covering key attractions related to: {', '.join(preferences)}"
            day_plan["afternoon"] = "Take a self-guided walk or visit a popular local spot recommended by travel experts."
            day_plan["evening"] = "Enjoy a casual dinner at a popular neighborhood restaurant."

        itinerary.append(day_plan)

    return {
        "destination": destination,
        "days": days,
        "itinerary": itinerary,
        "accommodation": "5-star hotel" if membership_type == "premium" else "3-star or boutique hotel",
        "transportation": "Private car service" if membership_type == "premium" else "Local transport and shared rides",
        "is_draft": True
    }
```

This function generates personalized itineraries based on user preferences.

### Step 3: Configure AG2 Agent with HITL

Now, we'll configure our AG2 agent to use Human-in-the-Loop functionality.

#### System Message

First, let's create a detailed system message that guides the travel agent's behavior:
```python title="agent-py/hitl_workflow.py"
SYSTEM_MESSAGE="""You are a professional travel agent who creates detailed, personalized day-by-day travel itineraries for any destination.

WORKFLOW:
1. Greet the customer warmly and ask for their member ID.
2. Use the `lookup_member` function to retrieve their profile information.
3. Address the customer by name and acknowledge their membership level (premium or standard).
4. Ask for their desired destination, specific cities (if applicable), travel start date, and trip duration.
    - If the customer mentions only a country (e.g., "USA" or "Croatia"), ask them which cities they'd like to visit.
    - If they're unsure, suggest 2–3 well-known cities in that country based on general travel knowledge.
5. Use the `create_itinerary` function to generate a personalized day-by-day itinerary that:
    - Aligns with their membership level (e.g., premium → luxury hotels, fine dining; standard → comfort & value).
    - Includes named hotels, restaurants, attractions, and activities based on typical travel knowledge for the selected cities.
    - Provides specific daily structure: morning, afternoon, evening.
    - Minimizes travel time by grouping activities geographically.
    - Feels locally authentic and realistic even though this is a demo (do not say "sample" or "example" in the response).
    - If the user provides no preferences, generate a balanced mix of culture, food, leisure, and exploration.
6. Present the itinerary with clear headers (e.g., Day 1, Day 2), using markdown-style formatting if supported.
7. Ask if the customer would like to modify any days, switch cities, or add/remove experiences.
8. Once finalized, confirm the itinerary and thank them for using the service.

Tone: Friendly, professional, and knowledgeable. You are a helpful concierge who wants the user to have an amazing experience.

Important: When a membership ID is not found in the system, politely inform the user that something may be wrong and ask them to double-check their ID."""
```

This system message instructs our travel agent how to behave and what steps to follow. Note that it references our functions that will require human approval.

#### Function Registration with HITL

Now comes the critical part, registering functions with Human-in-the-Loop approval:

```python title="agent-py/hitl_workflow.py"
@wf.register(name="hitl_workflow", description="A travel itinerary generator with human approval")
def hitl_workflow(ui: UI, params: dict[str, Any]) -> str:
    initial_message = ui.text_input(
        sender="Workflow",
        recipient="User",
        prompt=INITIAL_MESSAGE,
    )
    
    # Create the travel agent
    with llm_config:
        travel_agent = ConversableAgent(
                name="travel_agent",
                system_message=SYSTEM_MESSAGE
            )
        
    # Create the customer agent (human input)
    customer = ConversableAgent(
        name="customer",
        human_input_mode="ALWAYS",  # Always ask for human input
    )

    # Register the functions for the travel agent
    register_function(
        lookup_member,
        caller=travel_agent,  # The agent that can call this function
        executor=customer,    # The agent that must approve the call
        description="Look up member details from the database"
    )

    register_function(
        create_itinerary,
        caller=travel_agent,  # The agent that can call this function
        executor=customer,    # The agent that must approve the call
        description="Create a personalized travel itinerary based on member details"
    )

    # Start the conversation
    response = customer.run(
        travel_agent,
        message=initial_message,
        summary_method="reflection_with_llm"
    )

    return ui.process(response)

# Set up FastAPI with the AWP adapter
def without_customer_messages(message: Any) -> bool:
    return not (message.type == "text" and message.content.sender == "customer")


adapter = AWPAdapter(
    provider=wf, wf_name="hitl_workflow", filter=without_customer_messages
)
app = FastAPI()
app.include_router(adapter.router)
```

The key to HITL functionality is in the `register_function` calls:

  - `caller=travel_agent`: Specifies that the travel agent can call this function
  - `executor=customer`: Specifies that the customer (the human) must approve the function call before it can execute

**This creates our approval workflow:**

  - When the travel agent attempts to call a function
  - The request is routed to the customer agent
  - A human must approve the function call in the UI
  - Only after approval will the function actually execute


### Step 4: Launch Your Application

Now that we've built our HITL-enabled travel agent, let's launch it:

- Save the file as `hitl_workflow.py` in your agent-py directory
- Start the AG2 backend. From the root of your project, run:
```bash
cd agent-py
uvicorn hitl_workflow:app --port 8008 --reload
```
- In a separate terminal, start the CopilotKit frontend:
```bash
cd ui
pnpm run dev
```
- Visit [http://localhost:3000](http://localhost:3000) to interact with your HITL-enabled travel agent!

## Example Interaction flow

When you interact with your travel agent:

- The agent asks for your member ID
- When you provide it, the agent requests permission to look up your data
(You'll see an approval prompt in the UI, type **continue** in the chat box to approve the function call)
- After approval, the agent retrieves your data and asks for travel details
- When you provide travel details, the agent requests permission to create an itinerary
(Another approval prompt appears, type **continue** in the chat box to approve)
- After approval, the agent generates and displays your personalized itinerary

This approach ensures sensitive operations like accessing customer data and creating itineraries only happen with explicit human approval.

<Callout type="info">
Whenever the `travel_agent` wants to call a function, it will send a message in the chat window for approval, For example:

**AG2 wants to invoke tool: lookup_member**

**Replying as `customer`. Provide feedback to `travel_agent`. Answer continue to skip and use auto-reply, or type 'exit' to end the conversation:**


In such cases, you can type **continue** to approve the function call or **exit** to end the conversation.
</Callout>

<img src="/images/coagents/ag2/hitl-1.png" className="rounded-lg shadow-xl"/>
<img src="/images/coagents/ag2/hitl-2.png" className="rounded-lg shadow-xl"/>

## Conclusion

You've successfully enhanced your travel agent with Human-in-the-Loop functionality! By requiring human approval for sensitive operations, you've created a more secure and transparent AI application.

## Next Steps

To explore more advanced features, check out how to enable your AI agents to directly interact with your application's UI in our Frontend Actions guide.



================================================
FILE: docs/content/docs/ag2/human-in-the-loop/index.mdx
================================================
---
title: Human in the Loop (HITL)
icon: "lucide/User"
description: Allow your agent and users to collaborate on complex tasks.
---

import { CTACards } from "@/components/react/cta-cards";
import { Pause, Share2 } from "lucide-react";

<video
  src="/images/coagents/human-in-the-loop-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

{/* TODO: Add Example */}
{/* <Callout>
This video shows an example of our [AI Travel App](/coagents/tutorials/ai-travel-app) using HITL to get user feedback.

</Callout> */}

## What is Human-in-the-Loop (HITL)?

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

<Frame className="my-0">
  <img
    src="/images/coagents/coagents-hitl-infographic.png"
    alt="Agentic Copilot Human in the Loop"
    className="mt-4 mb-0 shadow-md"
  />
</Frame>

## When should I use this?

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## How can I use this?

Read more about the approach to HITL in AG2 Agents.

<CTACards
  columns={1}
  cards={[
    {
      icon: Share2,
      title: "HITL Workflows",
      description:
        "Utilize AG2 Agents to create Human-in-the-Loop workflows.",
      href: "/ag2/human-in-the-loop/hitl",
    },
  ]}
/> 


================================================
FILE: docs/content/docs/ag2/human-in-the-loop/meta.json
================================================
{
  "pages": ["hitl"]
}



================================================
FILE: docs/content/docs/coagents/agentic-chat-ui.mdx
================================================
---
title: Chat with an Agent
icon: "lucide/SendHorizontal"
description: Chat with an agent using CopilotKit's UI components.
---
import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import ComponentExamples from "@/snippets/component-examples.mdx";
import { UserIcon, PaintbrushIcon, WrenchIcon, RepeatIcon } from "lucide-react";

<video src="/images/coagents/agentic-chat-ui.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
    This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with various Copilot UI components applied to it!
</Callout>

## What is this?

Agentic chat UIs are ways for your users to interact with your agent. CopilotKit provides a variety of different components to choose from, each
with their own unique use cases.

If you've gone through the [getting started guide](/coagents/quickstart/langgraph) **you already have a agentic chat UI setup**! Nothing else is needed
to get started.

## When should I use this?
CopilotKit provides a variety of different batteries-included components to choose from to create agent native applications. They scale
from simple chat UIs to completely custom applications.

<ComponentExamples components={props.components} />



================================================
FILE: docs/content/docs/coagents/frontend-actions.mdx
================================================
---
title: Frontend Actions
icon: "lucide/Wrench"
description: Create frontend actions and use them within your agent.
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"

<video src="/images/frontend-actions-demo.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
    This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## When should I use this?

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## Implementation

<Steps>
    <Step>
        ### Setup CopilotKit

        To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here. 

        Check out our [getting started guide](/coagents/quickstart/langgraph) and come back here when you're setup!
    </Step>

    <Step>
        ### Create a frontend action

        First, you'll need to create a frontend action using the [useCopilotAction](/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
        that says hello to the user.

        ```tsx title="page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core" // [!code highlight]
            
        export function Page() {
          // ...

          // [!code highlight:16]
          useCopilotAction({
            name: "sayHello",
            description: "Say hello to the user",
            available: "remote", // optional, makes it so the action is *only* available to the agent
            parameters: [
              {
                name: "name",
                type: "string",
                description: "The name of the user to say hello to",
                required: true,
              },
            ],
            handler: async ({ name }) => {
              alert(`Hello, ${name}!`);
            },
          });

          // ...
        }
        ```
    </Step>
    <Step>
        ###  Modify your agent
        Now, we'll need to modify the agent to access these frontend actions. Open up for your agent's folder and continue from there!
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Inheriting from CopilotKitState

        To access the frontend actions provided by CopilotKit, you can inherit from CopilotKitState in your agent's state definition:

        <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                from copilotkit import CopilotKitState # [!code highlight]

                class YourAgentState(CopilotKitState): # [!code highlight]
                    your_additional_properties: str
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript title="agent-js/src/agent.ts"
                import { Annotation } from "@langchain/langgraph";
                import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph"; // [!code highlight]

                export const YourAgentStateAnnotation = Annotation.Root({
                    yourAdditionalProperty: Annotation<string>,
                    ...CopilotKitStateAnnotation.spec, // [!code highlight]
                });
                export type YourAgentState = typeof YourAgentStateAnnotation.State;
                ```
            </Tab>
        </Tabs>

        By doing this, your agent's state will include the `copilotkit` property, which contains the frontend actions that can be accessed and invoked.
    </Step>
    <Step>
        ### Accessing Frontend Actions

        Once your agent's state includes the `copilotkit` property, you can access the frontend actions and utilize them within your agent's logic.

        Here's how you can call a frontend action from your agent:

        <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                async def agent_node(state: YourAgentState, config: RunnableConfig):
                    # Access the actions from the copilotkit property

                    actions = state.get("copilotkit", {}).get("actions", []) # [!code highlight]
                    model = ChatOpenAI(model="gpt-4o").bind_tools(actions)

                    # ...
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript title="agent-js/src/agent.ts"
                async function agentNode(state: YourAgentState, config: RunnableConfig): Promise<YourAgentState> {
                    // Access the actions from the copilotkit property

                    const actions = state.copilotkit?.actions; // [!code highlight]
                    const model = ChatOpenAI({ model: 'gpt-4o' }).bindTools(actions);

                    // ...
                }
                ```
            </Tab>
        </Tabs>

        These actions are automatically populated by CopilotKit and are compatible with LangChain's tool call definitions, making it straightforward to integrate them into your agent's workflow.
    </Step>
    <Step>
        ### Give it a try!
        You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.
    </Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/index.mdx
================================================
---
title: Introduction
icon: "lucide/Sparkles"
description: Build Agent-Native Applications (ANAs) powered by CopilotKit and LangGraph.
---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { FaDiscord } from "react-icons/fa";
import {TelescopeIcon} from "lucide-react"
import Link from "next/link";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import {
  LuPlane,
  LuBookOpen,
  LuLightbulb,
  LuLayoutTemplate,
  LuBrainCog,
  LuUserCog,
  LuWand2,
  LuPlay,
  LuMessageSquare,
  LuWrench,
} from "react-icons/lu";
import { CoAgentsExamples } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { FaSync } from "react-icons/fa";
import { Socials } from "@/components/react/socials";

<div className="p-4 mb-6 rounded-lg bg-indigo-50 dark:bg-indigo-950 border border-indigo-200 dark:border-indigo-800">
  <div className="flex items-center gap-2 mb-2">
    <TelescopeIcon className="h-5 w-5 text-indigo-500 dark:text-indigo-300" />
    <h3 className="text-lg font-semibold text-indigo-700 dark:text-indigo-300">LangGraph Overview</h3>
  </div>
  <p className="text-indigo-700 dark:text-indigo-300">
    Visit the <a href="https://v0-langgraph-land.vercel.app/" target="_blank" rel="noopener noreferrer" className="font-medium underline underline-offset-4 decoration-indigo-400 dark:decoration-indigo-500 hover:text-indigo-600 dark:hover:text-indigo-200">LangGraph Overview Page</a> to learn more about LangGraph's capabilities and features.
  </p>
</div>

# Copilot Infrastructure for LangGraph Agents

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).

<Frame className="mt-0 mb-6 rounded-lg">
  <img
    src="/images/CoAgents.gif"
    alt="CoAgents demonstration"
    className="w-auto"
  />
</Frame>

## Building blocks of a CoAgent

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuMessageSquare className="text-indigo-500 dark:text-indigo-300" />}
    title="Agentic Chat UI"
    description="In-app chat powered by your agent."
    href="/coagents/agentic-chat-ui"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<FaSync className="text-indigo-500 dark:text-indigo-300" />}
    title="Shared State"
    description="Your agent can see everything in your app, and vice versa."
    href="/coagents/shared-state"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuLayoutTemplate className="text-indigo-500 dark:text-indigo-300" />}
    title="Generative UI"
    description="UI that updates in real-time based on your agent's state."
    href="/coagents/generative-ui"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuWand2 className="text-indigo-500 dark:text-indigo-300" />}
    title="Frontend Tools"
    description="Give your agent the ability to take action in your application."
    href="/coagents/frontend-actions"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuUserCog className="text-indigo-500 dark:text-indigo-300" />}
    title="Human-in-the-Loop"
    description="Set smart checkpoints where humans can guide your agents."
    href="/coagents/human-in-the-loop"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuWand2 className="text-indigo-500 dark:text-indigo-300" />}
    title="Multi-Agent Coordination"
    description="Route your agent to the right agent based on the user's request."
    href="/coagents/multi-agent-flows"
  />
</Cards>

## CoAgents in action
In this example, we've built an agentic travel assistant that can you help you plan your next trip. It uses LangGraph
to coordinate chat and task execution.

<div className="flex justify-center mb-10">
<iframe src="https://examples-coagents-ai-travel-app.vercel.app/" className="w-[600px] h-[600px] rounded-xl border" />
</div>

<Accordions>
<Accordion title="Looking for more examples?">
We've made a lot!
- Checkout our [Use cases](https://copilotkit.ai/examples) page for more interactive examples
- Checkout our [examples](https://github.com/CopilotKit/CopilotKit/tree/main/examples) folder for every example we've made.
</Accordion>
</Accordions>

## Ready to get started?

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlay className="text-indigo-500 dark:text-indigo-300" />}
    title="Quickstart"
    description="Learn how to build your first CoAgent in 10 minutes."
    href="/coagents/quickstart/langgraph"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlay className="text-indigo-500 dark:text-indigo-300" />}
    title="Feature Overview"
    description="Try the key features of CoAgents powered by CopilotKit & LangGraph."
    href="https://feature-viewer-langgraph.vercel.app/"
    target="_blank"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlane className="text-indigo-500 dark:text-indigo-300" />}
    title="Travel Agent"
    description="Learn how to build an agent-native travel app with CopilotKit & LangGraph."
    href="/coagents/tutorials/ai-travel-app"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuBookOpen className="text-indigo-500 dark:text-indigo-300" />}
    title="Researcher Agent"
    description="Learn how to build an agent-native researcher with CopilotKit & LangGraph."
    href="/coagents/videos/research-canvas"
  />
</Cards>

## Common Questions

Have a question about CoAgents? You're in the right place!

<Accordions>
<Accordion title="Can you explain what a CoAgent is in more detail?">
Sure! CoAgents are what we call "agentic copilots". Well, what's an agentic copilot then?

Think of a Copilot as a simple and fully LLM controlled assistant that has relatively limited capabilities. An Agentic Copilot then is a copilot
that has been enhanced with the ability to use LangGraph agents to perform more complex tasks. This is an extremely powerful way to build AI
powered applications because it gives you, the developer, the ability to control the agent's behavior in a deterministic way while still letting
the agent do its magic.

For more on this topic, checkout our [agentic copilot](/coagents/concepts/agentic-copilots) concept page.

</Accordion>
<Accordion title="Can I attach to an existing thread?">
Yes, check out our [Guide on Threads](/coagents/persistence/loading-message-history) for more information.

</Accordion>
<Accordion title="Can I use CopilotKit without LangGraph?">

CopilotKit is a complete framework for building AI-powered applications and can be used standalone.

If you want to integrate with an agent framework, we currently support a variety of frameworks. Check in the top left bar for more information!

</Accordion>
</Accordions>



================================================
FILE: docs/content/docs/coagents/meta.json
================================================
{
  "title": "CoAgents",
  "root": true,
  "pages": [
    "index",
    "quickstart",
    "[lucide/Telescope][Feature Viewer](https://feature-viewer-langgraph.vercel.app/)",
    "---Guides---",
    "custom-look-and-feel",
    "agentic-chat-ui",
    "generative-ui",
    "human-in-the-loop",
    "shared-state",
    "frontend-actions",
    "multi-agent-flows",
    "persistence",
    "advanced",
    "---Tutorials & Videos---",
    "...tutorials",
    "...videos",
    "---Learn---",
    "...concepts",
    "---Troubleshooting---",
    "...troubleshooting"
  ]
}



================================================
FILE: docs/content/docs/coagents/multi-agent-flows.mdx
================================================
---
title: Multi-Agent Flows
description: Use multiple agents to orchestrate complex flows.
icon: "lucide/Users"
---
import { Callout } from "fumadocs-ui/components/callout";

<Frame>
    <img src="/images/coagents/multi-agent-flows.png" alt="Multi-Agent Flows" />
</Frame>

## What are Multi-Agent Flows?

When building agentic applications, you often want to orchestrate complex flows together that require the coordination of multiple
agents. This is traditionally called multi-agent orchestration.

## When should I use this?

Multi-agent flows are useful when you want to orchestrate complex flows together that require the coordination of multiple agents. As
your agentic application grows, delegation of sub-tasks to other agents can help you scale key pieces of your application.
- Divide context into smaller chunks
- Delegate sub-tasks to other agents
- Use a single agent to orchestrate the flow

## How does CopilotKit support this?

CopilotKit can be used in either of two distinct modes: **Router Mode**, or **Agent Lock**. By default, CopilotKit
will use Router Mode, leveraging your defined LLM to route requests between agents.

### Router Mode (default)
Router Mode is enabled by default when using CoAgents. To use it, specify a runtime URL prop in the `CopilotKit` provider component and omit the `agent` prop, like so:
```tsx
<CopilotKit runtimeUrl="<copilot-runtime-url>">
  {/* Your application components */}
</CopilotKit>
```

In router mode, CopilotKit acts as a central hub, dynamically selecting and _routing_ requests between different agents or actions based on the user's input. This mode can be good for chat-first experiences where an LLM chatbot is the entry point for a range of interactions, which can stay in the chat UI or expand to include native React UI widgets.

In this mode, CopilotKit will intelligently route requests to the most appropriate agent or action based on the context and user input.

Be advised that when using this mode, you'll have to "exit the workflow" explicitly in your agent code.
You can find more information about it in the ["Exiting the agent loop" section](https://docs.copilotkit.ai/coagents/advanced/exit-agent).

<Callout type="warn">
    Router mode requires that you set up an LLM adapter. See how in ["Set up a copilot runtime"](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint) section of the docs.
</Callout>

### Agent Lock Mode
To use Agent Lock Mode, specify the agent name in the `CopilotKit` component with the `agent` prop:
```tsx
// [!code word:agent]
<CopilotKit runtimeUrl="<copilot-runtime-url>" agent="<the-name-of-the-agent>">
  {/* Your application components */}
</CopilotKit>
```

In this mode, CopilotKit is configured to work exclusively with a specific agent. This mode is useful when you want to focus on a particular task or domain. Whereas in Router Mode the LLM and CopilotKit's router are free to switch between agents to handle user requests, in Agent Lock Mode all requests will stay within a single workflow graph, ensuring precise control over the workflow.

Use whichever mode works best for your app experience! Also, note that while you cannot nest `CopilotKit` providers, you can use different agents or modes in different areas of your app — for example, you may want a chatbot in router mode that can call on any agent or tool, but may also want to integrate one specific agent elsewhere for a more focused workflow.


================================================
FILE: docs/content/docs/coagents/quickstart.mdx
================================================
---
title: Quickstart
description: Turn your LangGraph into an agent-native application in 10 minutes.
icon: "lucide/Play"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import { FaPython, FaJs, FaCloud } from "react-icons/fa";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureRemoteEndpointLangGraph from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotKitCloudCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";
import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import CloudCopilotKitProvider from "@/snippets/coagents/cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/coagents/self-host-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeLangGraphEndpoint from "@/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx";
import SelfHostingCopilotRuntimeStarter from "@/snippets/self-hosting-copilot-runtime-starter.mdx";
import SelfHostingRemoteEndpoints from "@/snippets/self-hosting-remote-endpoints.mdx";
import {
  UserIcon,
  PaintbrushIcon,
  WrenchIcon,
  RepeatIcon,
  ServerIcon,
} from "lucide-react";
import { SiLangchain } from "react-icons/si";
import CopilotUI from "@/snippets/copilot-ui.mdx";
import { PathIcon } from "lucide-react";
import { SquareTerminal, SquareChartGantt } from "lucide-react";

<video
  src="/images/coagents/chat-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

## Prerequisites

Before you begin, you'll need the following:

- [**LangSmith API key**](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key#api-keys)
- [**OpenAI API key**](https://platform.openai.com/api-keys)

## Getting started

<Steps>
    <TailoredContent
        className="step"
        id="path"
        header={
            <div>
                <p className="text-xl font-semibold">How do you want to get started?</p>
                <p className="text-base">
                    Bootstrap with the new <span className="text-indigo-500 dark:text-indigo-400">CopilotKit CLI (Beta)</span> or code along with us to get started.
                </p>
            </div>
        }
    >
        <TailoredContentOption
            id="cli"
            title="Use the CopilotKit CLI (NextJS only)"
            description="I have a Next.js application and want to get started quickly."
            icon={<SquareTerminal />}
        >
            <Step>
                ### Run the CLI
                Just run this following command in your Next.js application to get started!

                <Accordions>
                    <Accordion title="Don't have a Next.js application?">
                        No problem! Just use `create-next-app` to make one quickly.
                        ```bash
                        npx create-next-app@latest
                        ```
                    </Accordion>
                </Accordions>

                ```bash
                npx copilotkit@latest init -m LangGraph
                ```
            </Step>
            <Step>
                ### 🎉 Talk to your agent!

                Congrats! You've successfully integrated a LangGraph agent chatbot to your application. Depending on the
                template you chose, you may see some different UI elements. To start, try asking a few questions to your agent.

                ```
                Can you tell me a joke?
                ```

                ```
                Can you help me understand AI?
                ```

                ```
                What do you think about React?
                ```

                <Accordions className="mb-4">
                    <Accordion title="Having trouble?">
                        - Make sure your agent folder contains a `langgraph.json` file.
                        - In the `langgraph.json` file, reference the path to a `.env` file.
                        - In the `.env` file, include your `LANGSMITH_API_KEY`.
                        - Make sure you're in the same folder as your `langgraph.json` file when running the `langgraph dev` command.
                        - Try changing the host to `0.0.0.0` or `127.0.0.1` instead of `localhost`.
                    </Accordion>
                </Accordions>
            </Step>
        </TailoredContentOption>
        <TailoredContentOption
            id="code-along"
            title="Code along"
            description="I want to deeply understand what's happening under the hood or don't have a Next.js application."
            icon={<SquareChartGantt />}
        >
            <Step>
                ### Install CopilotKit
                First, install the latest packages for CopilotKit into your frontend.
                ```package-install
                npm install @copilotkit/react-ui @copilotkit/react-core
                ```
            </Step>
            <TailoredContent
                className="step"
                id="agent"
                header={
                    <div>
                        <p className="text-xl font-semibold">Do you already have a LangGraph agent?</p>
                        <p className="text-base">
                            You will need a LangGraph agent to get started with CoAgents!
                        </p>
                        <p className="text-base">
                            Either bring your own or feel free to use our starter repo.
                        </p>
                    </div>
                }
            >
                <TailoredContentOption
                    id="bring-your-own"
                    title="Bring your own LangGraph agent"
                    description="I already have a LangGraph agent and want to use it with CopilotKit."
                    icon={<SiLangchain />}
                />
                <TailoredContentOption
                    id="coagents-starter"
                    title="Use the CoAgents Starter repo"
                    description="I don't have a LangGraph agent yet, but want to get started quickly."
                    icon={<img src="/images/copilotkit-logo.svg" alt="CopilotKit Logo" width={20} height={20} />}
                >
                    <Step>
                        ### Clone the `coagents-starter` repo and install dependencies:

                        <Tabs groupId="language" items={["Python", "TypeScript"]}>
                            <Tab value="Python">
                                ```bash
                                git clone -n --depth=1 --filter=tree:0 https://github.com/CopilotKit/CopilotKit && cd CopilotKit && git sparse-checkout set --no-cone examples/coagents-starter/agent-py && git checkout && cd ..
                                cd CopilotKit/examples/coagents-starter/agent-py
                                ```

                                #### Install dependencies:
                                ```bash
                                poetry install
                                ```
                            </Tab>
                            <Tab value="TypeScript">
                                ```bash
                                git clone -n --depth=1 --filter=tree:0 https://github.com/CopilotKit/CopilotKit && cd CopilotKit && git sparse-checkout set --no-cone examples/coagents-starter/agent-js && git checkout && cd ..
                                cd CopilotKit/examples/coagents-starter/agent-js
                                ```

                                #### Install dependencies:
                                ```bash
                                pnpm install
                                ```
                            </Tab>
                        </Tabs>
                    </Step>
                    <Step>
                        ### Create a `.env` file

                        ```bash
                        touch .env
                        ```
                    </Step>
                    <Step>
                        ### Add your API keys

                        Then add your **OpenAI API key** and **LangSmith API key** to the `.env` file.

                        ```plaintext title=".env"
                        OPENAI_API_KEY=your_openai_api_key
                        LANGSMITH_API_KEY=your_langsmith_api_key
                        ```
                    </Step>
                </TailoredContentOption>
            </TailoredContent>
            <Step>
                ### Start your LangGraph Agent

                <LangGraphPlatformDeploymentTabs components={props.components} />
            </Step>

            <TailoredContent
                className="step"
                id="copilot-hosting"
                header={
                    <div>
                        <p className="text-xl font-semibold">Choose your connection method</p>
                        <p className="text-base">
                            Now you need to connect your LangGraph agent to CopilotKit.
                        </p>
                    </div>
                }
            >
                <TailoredContentOption
                    id="copilot-cloud"
                    title="Copilot Cloud (Recommended)"
                    description="I want to host my Copilot on Copilot Cloud"
                    icon={<FaCloud />}
                >
                    <Step>
                        ### Add a remote endpoint for your LangGraph agent
                        Using Copilot Cloud, you need to connect a remote endpoint that will connect to your LangGraph agent.
                        <Tabs groupId="lg-deployment-type" items={['Local (LangGraph Studio)', 'Self hosted (FastAPI)', 'LangGraph Platform']}>
                            <Tab value="Local (LangGraph Studio)">
                                When running your LangGraph agent locally, you can open a tunnel to it so Copilot Cloud can connect to it.
                                First, make sure you're logged in to [Copilot Cloud](https://cloud.copilotkit.ai), and then authenticate the CLI by running:
                                ```bash
                                npx copilotkit@latest login
                                ```
                                Once authenticated, run:
                                ```bash
                                npx copilotkit@latest dev --port 8000
                                ```

                                <Accordions className="mb-4">
                                    <Accordion title="Having trouble?">
                                      If you encounter issues while tunneling on Windows, try the following solutions:
                                        - Make sure the following lines are uncommented in your `hosts` file:  
                                        ```bash  
                                        127.0.0.1 localhost  
                                        ::1       localhost
                                        ```  
                                        - Try starting the langgraph server using
                                        ```bash
                                        langgraph dev --host :: --port 8000
                                        ```
                                    </Accordion>
                                </Accordions>
                            </Tab>
                            <Tab value="Self hosted (FastAPI)">
                                **Running your FastAPI server locally**

                                If you're running your FastAPI server locally, you can open a tunnel to it so Copilot Cloud can connect to it.
                                First, make sure you're logged in to [Copilot Cloud](https://cloud.copilotkit.ai), and then authenticate the CLI by running:
                                ```bash
                                npx copilotkit@latest login
                                ```
                                Once authenticated, run:
                                ```bash
                                npx copilotkit@latest dev --port 8000
                                ```

                                **Running your FastAPI server in production**

                                Head over to [Copilot Cloud](https://cloud.copilotkit.ai) sign up and setup a remote endpoint with the following information:
                                - OpenAI API key
                                - LangSmith API key
                                - Your FastAPI server URL

                                <Accordions className="mb-4">
                                    <Accordion title="Having trouble?">
                                      If you encounter issues while tunneling on Windows, try the following solutions:
                                        - Make sure the following lines are uncommented in your `hosts` file:
                                        ```bash  
                                        127.0.0.1 localhost  
                                        ::1       localhost
                                        ```  
                                        - In the `demo.py` file, use `::` as the host to enable IPv6 binding.
                                    </Accordion>
                                </Accordions>
                            </Tab>
                            <Tab value="LangGraph Platform">
                                Head over to [Copilot Cloud](https://cloud.copilotkit.ai) sign up and setup a remote endpoint to LangGraph Platform with the following information:
                                - OpenAI API key
                                - LangSmith API key
                                - LangGraph agent deployment URL
                                <Accordions className="mb-4">
                                    <Accordion title="Show me how">
                                        <Frame>
                                            <img src="/images/copilot-cloud/cpk-cloud-lgp-endpoint.gif" alt="Copilot Cloud Remote Endpoint" />
                                        </Frame>
                                    </Accordion>
                                </Accordions>
                            </Tab>
                        </Tabs>
                    </Step>
                    <Step>
                        ### Setup your CopilotKit provider
                        The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                        it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

                        Since we're using Copilot CLoud, we need to grab our public API key from the [Copilot Cloud dashboard](https://cloud.copilotkit.ai).

                        <CloudCopilotKitProvider components={props.components} />

                        <Callout type="info">
                            Looking for a way to run multiple LangGraph agents? Check out our [Multi-Agent](/coagents/multi-agent-flows) guide.
                        </Callout>
                    </Step>
                </TailoredContentOption>
                <TailoredContentOption
                    id="self-hosted"
                    title="Self-Hosted Copilot Runtime"
                    description="I want to self-host the Copilot Runtime"
                    icon={<ServerIcon />}
                >
                    <Step>
                        ### Install Copilot Runtime
                        Copilot Runtime is a production-ready proxy for your LangGraph agents. In your frontend, go ahead and install it.

                        ```package-install
                        @copilotkit/runtime class-validator
                        ```
                    </Step>
                    <Step>
                        ### Setup a Copilot Runtime Endpoint
                        Now we need to setup a Copilot Runtime endpoint and point your frontend to it.
                        <SelfHostingCopilotRuntimeStarter components={props.components}/>
                    </Step>
                    <Step>
                        ### Add your LangGraph deployment to Copilot Runtime
                        Now we need to add your LangGraph deployment to Copilot Runtime. This will make it
                        so your frontend can find your LangGraph agents correctly.
                        <SelfHostingRemoteEndpoints components={props.components}/>
                    </Step>
                    <Step>
                        ### Configure the CopilotKit Provider
                        The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                        it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.
                        <SelfHostingCopilotRuntimeConfigureCopilotKitProvider components={props.components}/>
                        <Callout type="info">
                            Looking for a way to run multiple LangGraph agents? Check out our [Multi-Agent](/coagents/multi-agent-flows) guide.
                        </Callout>
                    </Step>
                </TailoredContentOption>
            </TailoredContent>
            <Step>
                ## Choose a Copilot UI

                You are almost there! Now it's time to setup your Copilot UI.

                <ConnectCopilotUI components={props.components} />
            </Step>
            <Step>
                ### 🎉 Talk to your agent!

                Congrats! You've successfully integrated a LangGraph agent chatbot to your application. To start, try asking a few questions to your agent.

                ```
                Can you tell me a joke?
                ```

                ```
                Can you help me understand AI?
                ```

                ```
                What do you think about React?
                ```

                <video src="/images/coagents/chat-example.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

                <Accordions className="mb-4">
                    <Accordion title="Having trouble?">
                        - Make sure your agent folder contains a `langgraph.json` file.
                        - In the `langgraph.json` file, reference the path to a `.env` file.
                        - In the `.env` file, include your `LANGSMITH_API_KEY`.
                        - Make sure you're in the same folder as your `langgraph.json` file when running the `langgraph dev` command.
                        - Try changing the host to `0.0.0.0` or `127.0.0.1` instead of `localhost`.
                    </Accordion>
                </Accordions>
            </Step>
            </TailoredContentOption>
        </TailoredContent>

</Steps>

---

## What's next?

You've now got a LangGraph agent running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

<Cards>
  <Card
    title="Implement Human in the Loop"
    description="Allow your users and agents to collaborate together on tasks."
    href="/coagents/human-in-the-loop"
    icon={<UserIcon />}
  />
  <Card
    title="Utilize Shared State"
    description="Learn how to synchronize your agent's state with your UI's state, and vice versa."
    href="/coagents/shared-state"
    icon={<RepeatIcon />}
  />
  <Card
    title="Add some generative UI"
    description="Render your agent's progress and output in the UI."
    href="/coagents/generative-ui"
    icon={<PaintbrushIcon />}
  />
  <Card
    title="Setup frontend actions"
    description="Give your agent the ability to call frontend tools, directly updating your application."
    href="/coagents/frontend-actions"
    icon={<WrenchIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/coagents/advanced/adding-runtime-configuration.mdx
================================================
---
title: "Using Agent Execution Parameters"
icon: "lucide/Bolt"
description: "Using agent execution parameters when communicating with an agent."
---

## What is this?
LangGraph agents are able to take execution parameters, such as auth tokens and similar properties.
You can add these using this feature.

If you wish to read further, you can refer to [the configuration guide by LangGraph](https://langchain-ai.github.io/langgraph/how-tos/configuration/)

## When should I use this?

This is useful when you want to send execution-time configuration information (such as different tokens or metadata for a given session) that should not be part of the agent state.

## Implementation

By default, LangGraph agents are invoked with a `config` argument. This config has a `configurable` property which can be accessed and filled with your data.

<Steps>
<Step>
### Pass configuration from the frontend
First, pass the configuration properties as you would like to receive them in the agent

```tsx title="app/page.tsx"
import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

function YourMainContent() {
  // ...

  useCoAgent<AgentState>({
    name: "sample_agent",
    // [!code highlight:7]
    config: {
      configurable: {
        authToken: 'example-token'
      },
      recursion_limit: 50,
    }
  })

  // ...

  return (... your component UI markdown)
}
```
</Step>
<Step>
### Use configurables in agent
Now you can simply pull the values from the provided config argument in any agent node

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python
        async def agent_node(state: AgentState, config: RunnableConfig):
            
            auth_token = config['configurable'].get('authToken', None)

            return state
        ```
    </Tab>
    <Tab value="TypeScript">
        ```typescript
        async function agentNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
            const authToken = config.configurable?.authToken ?? null;

            return state;
        }
        ```
    </Tab>
</Tabs>
</Step>
<Step>
    ### Optional: Define configurables schema
    If you'd like, you can define a schema to indicate which configurables you wish to receive.
    Any item passed to "configurables" which is not included in the schema, will be filtered out.

    You can read more about this (here)[https://langchain-ai.github.io/langgraph/how-tos/configuration/#define-graph]
    <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
        <Tab value="Python">
            ```python
            from typing import TypedDict

            # define which properties will be allowed in the configuration
            class ConfigSchema(TypedDict):
              authToken: str

            # ...add all necessary graph nodes

            # when defining the state graph, apply the config schema
            workflow = StateGraph(AgentState, config_schema=ConfigSchema)
            ```
        </Tab>
        <Tab value="TypeScript">
            ```typescript
            import { Annotation } from "@langchain/langgraph";

            // define which properties will be allowed in the configuration
            export const ConfigSchemaAnnotation = Annotation.Root({
              authToken: Annotation<string>
            })

            // ...add all necessary graph nodes

            // when defining the state graph, apply the config schema
            const workflow = new StateGraph(AgentStateAnnotation, ConfigSchemaAnnotation)
            ```
        </Tab>
    </Tabs>
</Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/advanced/disabling-state-streaming.mdx
================================================
---
title: "Disabling state streaming"
icon: "lucide/Cog"
description: "Granularly control what is streamed to the frontend."
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"

## What is this?
By default, CopilotKit will stream both your state and tool calls to the frontend.
You can disable this by using CopilotKit's custom `RunnableConfig`.

## When should I use this?

Occasionally, you'll want to disable streaming temporarily — for example, the LLM may be
doing something the current user should not see, like emitting tool calls or questions 
pertaining to other employees in an HR system.

## Implementation

### Disable all streaming
You can disable all message streaming and tool call streaming by passing `emit_messages=False` and `emit_tool_calls=False` to the CopilotKit config.

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python
        from copilotkit.langgraph import copilotkit_customize_config

        async def frontend_actions_node(state: AgentState, config: RunnableConfig):
            
            # 1) Configure CopilotKit not to emit messages
            modifiedConfig = copilotkit_customize_config(
                config,
                emit_messages=False, # if you want to disable message streaming # [!code highlight]
                emit_tool_calls=False # if you want to disable tool call streaming # [!code highlight]
            )

            # 2) Provide the actions to the LLM
            model = ChatOpenAI(model="gpt-4o").bind_tools([
              *state["copilotkit"]["actions"],
              # ... any tools you want to make available to the model
            ])

            # 3) Call the model with CopilotKit's modified config  # [!code highlight]
            response = await model.ainvoke(state["messages"], modifiedConfig) # [!code highlight]

            # don't return the new response to hide it from the user
            return state
        ```

    <Callout type="warn" title="BEWARE!">
        In LangGraph Python, the `config` variable in the surrounding namespace is **implicitly** passed into LangChain LLM calls, even when not explicitly provided.
        
        This is why we create a new variable `modifiedConfig` rather than modifying `config` directly. If we modified `config` itself, it would change the default configuration for all subsequent LLM calls in that namespace.

        ```python
        # if we override the config variable name with a new value
        config = copilotkit_customize_config(config, ...)

        # it will affect every subsequent LangChain LLM call in the same namespace, even when `config` is not explicitly provided
        response = await model2.ainvoke(*state["messages"]) # implicitly uses the modified config!
        ```
    </Callout>
    </Tab>
    <Tab value="TypeScript">
        ```typescript
        import { copilotkitCustomizeConfig } from '@copilotkit/sdk-js/langgraph';

        async function frontendActionsNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
            // 1) Configure CopilotKit not to emit messages
            const modifiedConfig = copilotkitCustomizeConfig(config, {
                emitMessages: false, // if you want to disable message streaming
                emitToolCalls: false, // if you want to disable tool call streaming
            });

            // 2) Provide the actions to the LLM
            const model = new ChatOpenAI({ temperature: 0, model: "gpt-4o" });
            const modelWithTools = model.bindTools!([
                ...convertActionsToDynamicStructuredTools(state.copilotkit?.actions || []),
                ...tools,
            ]);

            // 3) Call the model with CopilotKit's modified config
            const response = await modelWithTools.invoke(state.messages, modifiedConfig);

            // don't return the new response to hide it from the user
            return state;
        }
        ```
    </Tab>
</Tabs>




================================================
FILE: docs/content/docs/coagents/advanced/emit-messages.mdx
================================================
---
title: "Manually emitting messages"
icon: "lucide/Radio"
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"
import RunAndConnectSnippet from "@/snippets/coagents/run-and-connect-agent.mdx"

While most agent interactions happen automatically through shared state updates as the agent runs, you can also **manually send messages from within your agent code** to provide immediate feedback to users.

<video src="/images/coagents/emit-messages.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
    This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

In LangGraph, messages are only emitted when a node is completed. CopilotKit allows you to manually emit messages
in the middle of a node's execution to provide immediate feedback to the user.

## When should I use this?

Manually emitted messages are great for **when you don't want to wait for the node** to complete **and you**:
- Have a long running task that you want to provide feedback on
- Want to provide a status update to the user
- Want to provide a warning or error message

## Implementation

<Steps>
    <Step>
        ### Run and Connect Your Agent to CopilotKit
        <RunAndConnectSnippet />
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Manually emit a message
        The `copilotkit_emit_message` method allows you to emit messages early in a node's execution to communicate status updates to the user. This is particularly useful for long running tasks.

        <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
            <Tab value="Python">
                ```python
                from langchain_core.messages import SystemMessage, AIMessage
                from langchain_openai import ChatOpenAI
                from langchain_core.runnables import RunnableConfig
                from copilotkit.langgraph import copilotkit_emit_message # [!code highlight]
                # ...

                async def chat_node(state: AgentState, config: RunnableConfig):
                    model = ChatOpenAI(model="gpt-4o")

                    # [!code highlight:3]
                    intermediate_message = "Thinking really hard..."
                    await copilotkit_emit_message(config, intermediate_message)

                    # simulate a long running task
                    await asyncio.sleep(2) 

                    response = await model.ainvoke([
                        SystemMessage(content="You are a helpful assistant."),
                        *state["messages"]
                    ], config)
                    
                    return Command(
                        goto=END,
                        update={
                            # Make sure to include the emitted message in the messages history # [!code highlight:2]
                            "messages": [AIMessage(content=intermediate_message), response]
                        }
                    )
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript
                import { AIMessage, SystemMessage } from "@langchain/core/messages";
                import { ChatOpenAI } from "@langchain/openai";
                import { RunnableConfig } from "@langchain/core/runnables";
                import { copilotkitEmitMessage } from "@copilotkit/sdk-js/langgraph"; // [!code highlight]
                // ...

                async function chat_node(state: AgentState, config: RunnableConfig) {
                    const model = new ChatOpenAI({ model: "gpt-4o" });

                    // [!code highlight:3]
                    const intermediateMessage = "Thinking really hard...";
                    await copilotkitEmitMessage(config, intermediateMessage);

                    // simulate a long-running task
                    await new Promise(resolve => setTimeout(resolve, 2000));

                    const response = await model.invoke([
                        new SystemMessage({content: "You are a helpful assistant."}),
                        ...state.messages
                    ], config);

                    return {
                        // Make sure to include the emitted message in the messages history # [!code highlight:2]
                        messages: [new AIMessage(intermediateMessage), response],
                    };
                }
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Give it a try!
        Now when you talk to your agent you'll notice that it immediately responds with the message "Thinking really hard..."
        before giving you a response 2 seconds later.
    </Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/advanced/exit-agent.mdx
================================================
---
title: "Exiting the agent loop"
icon: "lucide/DoorOpen"
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"

After your agent has finished a workflow, you'll usually want to explicitly end that loop by calling the CopilotKit exit method in your agent code.

Exiting the agent has different effects depending on mode:

- **Router Mode**: Exiting the agent hands responsibility for handling input back to the router, which can initiate chat, call actions, other agents, etc. The router can return to this agent later (starting a new loop) to satisfy a user request.

- **Agent Lock Mode**: Exiting the agent restarts the workflow loop for the current agent.

In this example from [our email-sending app](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-qa), the `send_email` node explicitly exits, then manually sends a response back to the user as a `ToolMessage`:

<Steps>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Exit the agent loop
        This will exit the agent session as soon as the current LangGraph run is finished, either by a breakpoint or by reaching the `END` node.

        <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
            <Tab value="Python">
                ```python
                from copilotkit.langgraph import (copilotkit_exit)
                # ...
                async def send_email_node(state: EmailAgentState, config: RunnableConfig):
                    """Send an email."""

                    await copilotkit_exit(config) # [!code highlight]

                    # get the last message and cast to ToolMessage
                    last_message = cast(ToolMessage, state["messages"][-1])
                    if last_message.content == "CANCEL":
                        return {
                            "messages": [AIMessage(content="❌ Cancelled sending email.")],
                        }
                    else:
                        return {
                            "messages": [AIMessage(content="✅ Sent email.")],
                        }
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript
                import { copilotkitExit } from "@copilotkit/sdk-js/langgraph";

                // ...

                async function sendEmailNode(state: EmailAgentState, config: RunnableConfig): Promise<{ messages: any[] }> {
                    // Send an email.

                    await copilotkitExit(config); // [!code highlight]

                    // get the last message and cast to ToolMessage
                    const lastMessage = state.messages[state.messages.length - 1] as ToolMessage;
                    if (lastMessage.content === "CANCEL") {
                        return {
                            messages: [new AIMessage(content="❌ Cancelled sending email.")],
                        }
                    } else {
                        return {
                            messages: [new AIMessage(content="✅ Sent email.")],
                        }
                    }
                }
                ```
            </Tab>
        </Tabs>
    </Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/advanced/meta.json
================================================
{
    "title": "Advanced",
    "icon": "lucide/Cog"
}


================================================
FILE: docs/content/docs/coagents/concepts/agentic-copilots.mdx
================================================
---
title: Agentic Copilots
description: Agentic copilots provide you with advanced control and orchestration over your agents.
icon: lucide/Bot
---

import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content";
import { BsFillCloudHaze2Fill as CloudIcon } from "react-icons/bs";
import { FaServer as SelfHostIcon } from "react-icons/fa6";
import { SiLangchain } from "react-icons/si";
import { LinkIcon } from "lucide-react";
import { RocketIcon, GraduationCapIcon, CodeIcon, VideoIcon } from "lucide-react";

Before we dive into what agentic copilots are, help us help you by telling us your level of experience with LangGraph. We'll explain things in a way that best suits your experience level.

<TailoredContent id="experience" defaultOptionIndex={0}>
    <TailoredContentOption 
        id="new"
        title="I'm new to LangGraph" 
        description="Help me understand what agentic copilots are, where LangGraph fits in, and how to get started." 
        icon={<img src="/images/copilotkit-logo.svg" width={7} height={7} />}
    >
        <Frame>
            <img src="/images/coagents/SharedStateCoAgents.gif" alt="CoAgents Shared State" className="mt-0 mb-12"/>
        </Frame>

        ### What are Agents?
        AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from 
        simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

        As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized 
        frameworks like LangGraph become essential.

        ### What is LangGraph?
        LangGraph is a framework that gives you precise control over AI agents. It uses a graph-based approach where each step in an agent's decision-making process is represented 
        by a `node`. These nodes are connected by `edges` to form a directed acyclic graph (DAG), creating a clear map of possible actions and decisions.

        The key advantage of LangGraph is its tight control over the agent's decision making process. Since all of this is defined in code by you, the behavior is much more
        deterministic and predictable.

        ### What are Agentic Copilots?
        Agentic copilots are how CopilotKit brings LangGraph agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that 
        understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ) 
        for quick implementation, Agentic copilots give you LangGraph's full orchestration capabilities when you need more control over your agent's behavior.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ### When should I use CopilotKit's CoAgents?
        You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [LangGraph](https://langchain-ai.github.io/langgraph/).
        With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

        We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.
        
        The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's 
        functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
        up to 100% of the Copilot's tasks (see [agent-lock mode](/coagents/multi-agent-flows) for the 100% case).

        ### Examples
        An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](/coagents/videos/research-canvas).
        
        More specifically, it demonstrates how CoAgents allow for AI driven experiences with:
        - Precise state management across agent interactions
        - Sophisticated multi-step reasoning capabilities
        - Seamless orchestration of multiple AI tools
        - Interactive human-AI collaboration features
        - Real-time state updates and progress streaming

        ## Next Steps

        Want to get started? You have some options!

        <Cards>
            <Card
                title="Build your first CoAgent"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/coagents/quickstart/langgraph"
                icon={<RocketIcon />}
            />
            <Card
                title="Learn more CoAgent concepts"
                description="Learn more about the concepts used to talk about CoAgents and how to use them."
                href="/coagents/concepts/terminology"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Read the reference documentation"
                description="Just here for some reference? Checkout the reference documentation for more details."
                href="/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="See examples of CoAgents in action"
                description="Checkout our video examples of CoAgents in action."
                href="/coagents/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>
    <TailoredContentOption 
        id="intermediate"
        title="I'm already using LangGraph" 
        description="Help me understand what agentic copilots are, what Copilotkit does to integrate with LangGraph, and how to get started." 
        icon={<SiLangchain />}
    >

        <Frame className="mt-0 mb-12">
            <img
                src="/images/CoAgents.gif"
                alt="CoAgents demonstration"
                className="w-auto"
            />
        </Frame>

        LangChain's LangGraph is a framework for building deeply customizable AI agents.

        CopilotKit's Agentic Copilots is infrastruture for in-app agent-user interaction, i.e. for transforming agents from autonomous processes to user-interactive 'virtual colleagues' that live inside applications.

        Any LangGraph-based agent can be transformed into an Agentic Copilot with a minimal amount
        of effort to get industry leading agnetic UX such as:
        - Shared state between the agent and the application.
        - Intermediate result and state progress streaming
        - Human-in-the-loop collaboration
        - Agentic generative UI
        - And more!

        All of these features are essential to delight instead of frustrate your users with AI features.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ## Next Steps
        Want to get started? You have some options!

        <Cards>
            <Card
                title="Quickstart"
                description="Integrate your LangGraph agent with CopilotKit in a few minutes."
                href="/coagents/quickstart/langgraph"
                icon={<RocketIcon />}
            />
            <Card
                title="Tutorial: AI Travel App"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/coagents/tutorials/ai-travel-app/overview"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Reference"
                description="Learn more about the terms used to talk about CoAgents and how to use them."
                href="/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="Examples"
                description="Checkout our video examples of CoAgents in action."
                href="/coagents/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>
</TailoredContent>



================================================
FILE: docs/content/docs/coagents/concepts/copilotkit-config.mdx
================================================
---
title: Streaming and Tool Calls
description: CoAgents support streaming your messages and tool calls to the frontend.
---

If you'd like to change how LangGraph agents behave as CoAgents you can utilize our Copilotkit SDK which provides a collection
of functions and utilities for interacting with the agent's state or behavior. One example of this is the Copilotkit config 
which is a wrapper of the LangGraph `config` object. This allows you to extend the configuration of your LangGraph nodes to 
change how LangGraph and Copilotkit interact with each other. This allows you to change how messages and tool calls are emitted and
streamed to the frontend.

## Message Streaming
If you did not change anything in your LangGraph node, message streaming will be on by default. This allows for a message to be
streamed to Copilotkit as it is being generated, allowing for a more responsive experience. However, you can disable this if you
want to have the message only be sent after the agent has finished generating it.

```python
config = copilotkit_customize_config(
    config,
    # True or False
    emit_messages=False,
)
```

## Emitting Tool Calls
Emission of tool calls are off by default. This means that tool calls will not be sent to Copilotkit for processing and rendering.
However, within a node you can extend the LangGraph `config` object to emit tool calls to Copilotkit. This is useful in situations
where you may to emit what a potential tool call will look like prior to being executed.

```python
config = copilotkit_customize_config(
    config,
    # Can set to True, False, or a list of tool call names to emit.
    emit_tool_calls=["tool_name"],
)
```

For more information on how tool calls are utilized check out our [frontend actions](/coagents/frontend-actions)
documentation.



================================================
FILE: docs/content/docs/coagents/concepts/langgraph.mdx
================================================
---
title: LangGraph
description: An agentic framework for building LLM applications that can be used with Copilotkit.
icon: custom/langchain
---

<Frame>
    <img src="/images/coagents/coagents-highlevel-overview.png" alt="CoAgents High Level Overview" className="mb-10"/>
</Frame>

LangGraph is an agentic framework for building LLM applications that can be used with Copilotkit. It is built on top of LangChain's
[LangGraph](https://langchain-ai.github.io/langgraph/) library and extends it with additional functionality for building agentic
applications. 

## CoAgents and LangGraph

How do CoAgents extend LangGraph? Let's read the first sentence of their [project page](https://langchain-ai.github.io/langgraph/) to understand.

> LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. 

There are some key terms here so let's break them down and understand how they relate to and are implemented by CoAgents.

- **Stateful**: CoAgents have bi-directional state sharing with the agent and UI. This allows for the agent to remember
  information from previous messages and the UI to update the agent with new information. Read more about how state sharing works
  [here](/coagents/shared-state).
- **Multi-actor**: CoAgents allow for multiple agents to interact with each other. Copilotkit acts as the "ground-truth"
  when transitioning between agents. Read more about how multi-actor workflows work [here](/coagents/multi-agent-flows)
  and how messages are managed [here](/coagents/concepts/message-management).
- **LLMs**: CoAgents use large language models to generate responses. This is useful for building applications that need to
  generate natural language responses.

Some additional functionality not mentioned here is:
- **Human in the loop**: CoAgents enabled human review and approval of generated responses. Read more about how this works
  [here](/coagents/human-in-the-loop).
- **Tool calling**: Tool calling is a fundamental building block for agentic workflows. They allow for greater control over what
  the agent can do and can be used to interact with external systems. CoAgents allow you to easily render in-progress
  tool calls in the UI so your users know what's happening. Read more about streaming tool calls [here](/coagents/shared-state/predictive-state-updates).

## Building with Python or JavaScript

You can natively build LangGraph applications using Python or JavaScript. Throughout our documentation of integrating with LangGraph
you will see options for building in Python or JavaScript.

For a quick refresher on each, check out the [Python](https://langchain-ai.github.io/langgraph) and
[JavaScript](https://langchain-ai.github.io/langgraphjs/) guides from LangGraph:

## LangGraph Platform

LangGraph Platform is a platform for building and deploying LangGraph applications. It is built on top of the LangGraph library and
allows you to build, manage, and deploy graphs that Copilotkit can interface with. For more information checkout the official
[LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform) documentation.

If you want to take the next step to deploy your LangGraph application as an CoAgent, check out our [quickstart guide](/coagents/quickstart/langgraph).



================================================
FILE: docs/content/docs/coagents/concepts/message-management.mdx
================================================
---
title: Message flow
icon: lucide/MessageCircle
---

Message management in CoAgents operates with CopilotKit as the "ground truth" for the full chat session. 
When an CoAgent session begins, it receives the existing CopilotKit chat history to maintain conversational
continuity across different agents.

<Callout>
While all of this information is great to know, in most cases you won't need to worry about these details to
build rich agentic applications. Use the information here as a reference when getting really deep into 
the CoAgent internals.
</Callout>

### Can I modify the message history?

You can modify the message history from LangGraph by using the `RemoveMessage` class. For example to remove all messages from the chat history: 

```python
from langchain_core.messages import RemoveMessage

def a_node(state: AgentState, config):
    # ...
    return {"messages":  [RemoveMessage(id=m.id) for m in state['messages']]}
```

See the [LangGraph documentation](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/) for more information.

<Callout>
Editing the message history is not currently supported on the front-end, but will be soon.
</Callout>

### Can I persist chat history?

Yes! There are a few ways to persist various portions of a chat's history:
- [Threads](/coagents/persistence/threads)
- [Message Persistence](/coagents/persistence/message-persistence)
- [Agent State](/coagents/persistence/loading-agent-state)

## Types of LLM Messages

Modern LLM interactions produce two distinct types of messages:

1. **Communication Messages**: Direct responses and interactions with users
2. **Internal Messages**: Agent "thoughts" and reasoning processes

A well known example of this pattern is OpenAI's o1 model, which has sophisticated reasoning capabilities and thoughts. Its internal
thought processes are presented distinctly from 'communication messages' which are clearly visible to the end-user.

LangGraph agents can operate similarly. An LLM call's output can be considered either a communication message, or an internal message.

### Emitting Messages for long running tasks

Sometimes you'll have a task that is running for a long time, and you want the user to be aware of what's happening. By default, LangGraph does not support this, because messages are only emitted on node transitions. However, CopilotKit allows you to accomplish this by using the `copilotkit_emit_message` function.

```python
async def ask_name_node(state: GreetAgentState, config: RunnableConfig):
    """
    Ask the user for their name.
    """

    content = "Hey, what is your name? 🙂"
 
    await copilotkit_emit_message(config, content)

    # something long running here...
 
    return {
        "messages": AIMessage(content=content),
    }
```

Want some more help managing messages in your CoAgent application? Check out our guide on [emitting messages](/coagents/advanced/emit-messages).

## Message Flow
Messages flow between CopilotKit and LangGraph in a specific way:

- All messages from LangGraph are forwarded to CopilotKit
- On a fresh agent invocation, the full CopilotKit chat history is provided to the LangGraph agent as its pre-existing chat history.

When a CoAgent completes its execution, its relevant messages become part of CopilotKit's persistent chat history. This allows for all future agent invocations to get context from the full chat history.



================================================
FILE: docs/content/docs/coagents/concepts/meta.json
================================================
{
    "title": "Concepts",
    "root": true,
    "pages": [
      "terminology",
      "agentic-copilots",
      "langgraph",
      "message-management"
    ]
  }



================================================
FILE: docs/content/docs/coagents/concepts/state.mdx
================================================
---
title: Shared State
description: CoAgents maintain a shared state across your UI and agent execution.
---

<Frame className="mb-10">
    <img src="/images/coagents/coagents-state-diagram.png" alt="Agentic Copilot State Diagram" />
</Frame>

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:
- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

The foundation of this system is built on LangGraph's stateful architecture. Unlike traditional LangChains, LangGraphs maintain their
internal state throughout execution, which you can access via the `useCoAgentState` hook.

### Understanding Predicted State

While your agent runs, you can emit state updates using CopilotKit's `emit_intermediate_state` function, ensuring your UI stays synchronized
with the agent's progress. The emitted state is called the **predicted state** and is used to provide immediate feedback about ongoing
operations.

While the core shared state reflects the agent's current node in the execution graph, the predicted state provides immediate
feedback about ongoing operations. Accordingly, this creates a more fluid user experience by showing real-time progress before the agent
completes its current task.

When the state is updated (when a node finishes executing), 

For example, when your agent is processing a request, the predicted state might show a loading indicator or partial results, while the actual
shared state updates once the operation is complete.

Want help implementing this into your CoAgent application? Check out our [intermediate state streaming](/coagents/shared-state/predictive-state-updates)
documentation.




================================================
FILE: docs/content/docs/coagents/concepts/terminology.mdx
================================================
---
title: Terminology
icon: lucide/Book
---

Here are the key terms and concepts used throughout CoAgents:

| Term | Definition |
|------|------------|
| Agentic Copilot | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously. |
| CoAgent | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot. |
| Agent State | The current data and context maintained by a LangGraph agent during its execution, including both internal state and data that can be synchronized with the frontend UI. |
| Agentic Generative UI | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents. |
| Human-in-the-Loop (HITL) | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points. |
| Intermediate State | The updates to agent state that occur during node execution, rather than only at node transitions, enabling real-time feedback about the agent's progress. |
| [LangGraph](https://langchain-ai.github.io/langgraph/) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management. |
| Agent Lock Mode | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control. |
| Router Mode | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows. |
| State Streaming | The real-time synchronization of agent state between the backend and frontend, enabling immediate updates to the UI as the agent performs tasks. |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications.



================================================
FILE: docs/content/docs/coagents/custom-look-and-feel/bring-your-own-components.mdx
================================================
---
title: Custom Sub-Components
icon: "lucide/Puzzle"
---
import { ImageAndCode } from "@/components/react/image-and-code"

You can swap out any of the sub-components of any Copilot UI to build up a completely custom look and feel. All components are fully typed with TypeScript for better development experience.

| Component | Description |
| --- | --- |
| [UserMessage](#usermessage) | Message component for user messages |
| [AssistantMessage](#assistantmessage) | Message component for assistant messages |
| [Window](#window) | Contains the chat |
| [Button](#button) | Button that opens/closes the chat |
| [Header](#header) | The header of the chat |
| [Messages](#messages) | The chat messages area |
| [Input](#input) | The chat input |
| [Actions](#actions) | Customize how actions (tools) are displayed |
| [Agent State](#agent-state) | Customize how agent state messages are displayed |

## UserMessage
The user message is what displays when the user sends a message to the chat. In this example, we change the color and add an avatar. 

<ImageAndCode preview="/images/custom-user-message.png">
The main thing to be aware of here is the `message` prop, which is the message text from the user.

```tsx
import { UserMessageProps } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

const CustomUserMessage = (props: UserMessageProps) => {
  const wrapperStyles = "flex items-center gap-2 justify-end mb-4";
  const messageStyles = "bg-blue-500 text-white py-2 px-4 rounded-xl break-words flex-shrink-0 max-w-[80%]";
  const avatarStyles = "bg-blue-500 shadow-sm min-h-10 min-w-10 rounded-full text-white flex items-center justify-center";

  return (
    <div className={wrapperStyles}>
      <div className={messageStyles}>{props.message}</div>
      <div className={avatarStyles}>TS</div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar UserMessage={CustomUserMessage} />
</CopilotKit>
```
</ImageAndCode>

## AssistantMessage
The assistant message is what displays when the LLM responds to a user message. In this example, we remove the background color and add an avatar. 

<ImageAndCode preview="/images/custom-assistant-message.png">
```tsx
import { AssistantMessageProps } from "@copilotkit/react-ui";
import { useChatContext } from "@copilotkit/react-ui";
import { Markdown } from "@copilotkit/react-ui";
import { SparklesIcon } from "@heroicons/react/24/outline";

import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

const CustomAssistantMessage = (props: AssistantMessageProps) => {
  const { icons } = useChatContext();
  const { message, isLoading, subComponent } = props;

  const avatarStyles = "bg-zinc-400 border-zinc-500 shadow-lg min-h-10 min-w-10 rounded-full text-white flex items-center justify-center";
  const messageStyles = "px-4 rounded-xl pt-2";

  const avatar = <div className={avatarStyles}><SparklesIcon className="h-6 w-6" /></div>

  // [!code highlight:13]
  return (
    <div className="py-2">
      <div className="flex items-start">
        {!subComponent && avatar}
        <div className={messageStyles}>
          {message && <Markdown content={message || ""} /> }
          {isLoading && icons.spinnerIcon}
        </div>
      </div>
      <div className="my-2">{subComponent}</div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar AssistantMessage={CustomAssistantMessage} />
</CopilotKit>
```
**Key concepts**
- `subComponent` - This is where any generative UI will be rendered.
- `message` - This is the message text from the LLM, typically in markdown format.
- `isLoading` - This is a boolean that indicates if the message is still loading.

</ImageAndCode>

## Window
The window is the main container for the chat. In this example, we turn it into a more traditional modal.

<ImageAndCode preview="/images/custom-window.png">

```tsx
import { WindowProps, useChatContext, CopilotSidebar } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function Window({ children }: WindowProps) {
  const { open, setOpen } = useChatContext();

  if (!open) return null;

  // [!code highlight:16]
  return (
    <div 
      className="fixed inset-0 bg-black/50 flex items-center justify-center p-4"
      onClick={() => setOpen(false)}
    >
      <div 
        className="bg-white rounded-lg shadow-xl max-w-2xl w-full h-[80vh] overflow-auto"
        onClick={e => e.stopPropagation()}
      >
        <div className="flex flex-col h-full">
          {children}
        </div>
      </div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar Window={Window} />
</CopilotKit>
```
</ImageAndCode>

## Button
The `CopilotSidebar` and `CopilotPopup` components allow you to customize their trigger button by passing in a custom Button component.

<ImageAndCode preview="/images/custom-button.png">

```tsx
import { ButtonProps, useChatContext, CopilotSidebar } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function Button({}: ButtonProps) {
  const { open, setOpen } = useChatContext();

  const wrapperStyles = "w-24 bg-blue-500 text-white p-4 rounded-lg text-center cursor-pointer";

  // [!code highlight:11]
  return (
    <div onClick={() => setOpen(!open)} className={wrapperStyles}>
      <button
        className={`${open ? "open" : ""}`}
        aria-label={open ? "Close Chat" : "Open Chat"}
      >
        Ask AI
      </button>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar Button={Button} />
</CopilotKit>
```
</ImageAndCode>

## Header
The header component is the top of the chat window. In this example, we add a button to the left of the title
with a custom icon.

<ImageAndCode preview="/images/custom-header.png">

```tsx
import { HeaderProps, useChatContext, CopilotSidebar } from "@copilotkit/react-ui";
import { BookOpenIcon } from "@heroicons/react/24/outline";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function Header({}: HeaderProps) {
  const { setOpen, icons, labels } = useChatContext();

  // [!code highlight:16]
  return (
    <div className="flex justify-between items-center p-4 bg-blue-500 text-white">
      <div className="w-24">
        <a href="/">
          <BookOpenIcon className="w-6 h-6" />
        </a>
      </div>
      <div className="text-lg">{labels.title}</div>
      <div className="w-24 flex justify-end">
        <button onClick={() => setOpen(false)} aria-label="Close">
          {icons.headerCloseIcon}
        </button>
      </div>
    </div>
  );
};

<CopilotKit>
  <CopilotSidebar Header={Header} />
</CopilotKit>
```
</ImageAndCode>

## Messages
The Messages component handles the display and organization of different message types in the chat interface. Its complexity comes from managing various message types (text, actions, results, and agent states) and maintaining proper scroll behavior.

<ImageAndCode preview="/images/custom-messages.png">

```tsx
import { MessagesProps, CopilotSidebar } from "@copilotkit/react-ui";
import { useCopilotChat } from "@copilotkit/react-core";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function CustomMessages({
  messages,
  inProgress,
  RenderTextMessage,
  RenderActionExecutionMessage,
  RenderResultMessage,
  RenderAgentStateMessage,
}: MessagesProps) {
  const wrapperStyles = "p-4 flex flex-col gap-2 h-full overflow-y-auto bg-indigo-300";

  /*
    Message types handled:
    - TextMessage: Regular chat messages
    - ActionExecutionMessage: When the LLM executes an action
    - ResultMessage: Results from actions
    - AgentStateMessage: Status updates from CoAgents
  */
  // [!code highlight:40]
  return (
    <div className={wrapperStyles}>
      {messages.map((message, index) => {
        if (message.isTextMessage()) {
          return <RenderTextMessage 
            key={message.id} 
            message={message} 
            inProgress={inProgress} 
            index={index} 
            isCurrentMessage={index === messages.length - 1}
          />;
        } else if (message.isActionExecutionMessage()) {
          return <RenderActionExecutionMessage 
            key={message.id} 
            message={message} 
            inProgress={inProgress} 
            index={index} 
            isCurrentMessage={index === messages.length - 1}
          />;
        } else if (message.isResultMessage()) {
          return <RenderResultMessage 
            key={message.id} 
            message={message} 
            inProgress={inProgress} 
            index={index} 
            isCurrentMessage={index === messages.length - 1}
          />;
        } else if (message.isAgentStateMessage()) {
          return <RenderAgentStateMessage 
              key={message.id} 
              message={message} 
              inProgress={inProgress} 
              index={index} 
              isCurrentMessage={index === messages.length - 1}
            />;
        }
      })}
    </div>
  );
}

<CopilotKit>
  <CopilotSidebar Messages={CustomMessages} />
</CopilotKit>
```
</ImageAndCode>

## Input
The input component that the user interacts with to send messages to the chat. In this example, we customize it
to have a custom "Ask" button and placeholder text.

<ImageAndCode preview="/images/custom-input.png">

```tsx
import { InputProps, CopilotSidebar } from "@copilotkit/react-ui";
import { CopilotKit } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";
function CustomInput({ inProgress, onSend, isVisible }: InputProps) {
  const handleSubmit = (value: string) => {
    if (value.trim()) onSend(value);
  };

  const wrapperStyle = "flex gap-2 p-4 border-t";
  const inputStyle = "flex-1 p-2 rounded-md border border-gray-300 focus:outline-none focus:border-blue-500 disabled:bg-gray-100";
  const buttonStyle = "px-4 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 disabled:bg-gray-400 disabled:cursor-not-allowed";

  // [!code highlight:28]
  return (
    <div className={wrapperStyle}>
      <input 
        disabled={inProgress}
        type="text" 
        placeholder="Ask your question here..." 
        className={inputStyle}
        onKeyDown={(e) => {
          if (e.key === 'Enter') {
            handleSubmit(e.currentTarget.value);
            e.currentTarget.value = '';
          }
        }}
      />
      <button 
        disabled={inProgress}
        className={buttonStyle}
        onClick={(e) => {
          const input = e.currentTarget.previousElementSibling as HTMLInputElement;
          handleSubmit(input.value);
          input.value = '';
        }}
      >
        Ask
      </button>
    </div>
  );
}

<CopilotKit>
  <CopilotSidebar Input={CustomInput} />
</CopilotKit>
```
</ImageAndCode>

## Actions
Actions allow the LLM to interact with your application's functionality. When an action is called by the LLM, you can provide custom components to visualize its execution and results. This example demonstrates a calendar meeting card implementation.

<ImageAndCode preview="/images/render-only-example.png">

```tsx
"use client" // only necessary if you are using Next.js with the App Router.
import { useCopilotAction } from "@copilotkit/react-core"; 
 
export function YourComponent() {
  useCopilotAction({ 
    name: "showCalendarMeeting",
    description: "Displays calendar meeting information",
    parameters: [
      {
        name: "date",
        type: "string",
        description: "Meeting date (YYYY-MM-DD)",
        required: true
      },
      {
        name: "time",
        type: "string",
        description: "Meeting time (HH:mm)",
        required: true
      },
      {
        name: "meetingName",
        type: "string",
        description: "Name of the meeting",
        required: false
      }
    ],
    render: ({ status, args }) => {
      const { date, time, meetingName } = args;
 
      if (status === 'inProgress') {
        return <LoadingView />; // Your own component for loading state
      } else {
        const meetingProps: CalendarMeetingCardProps = {
          date: date,
          time,
          meetingName
        };
        return <CalendarMeetingCardComponent {...meetingProps} />;
      }
    },
  });
 
  return (
    <>...</>
  );
}
```
</ImageAndCode>

## Agent State
The Agent State component allows you to visualize the internal state and progress of your CoAgents. When working with CoAgents, you can provide a custom component to render the agent's state. This example demonstrates a progress bar that updates as the agent runs.

<Callout title="Not started with CoAgents yet?">
If you haven't gotten started with CoAgents yet, you can get started in 10 minutes with the [quickstart guide](/coagents/quickstart/langgraph).
</Callout>

<ImageAndCode preview="/images/coagents/AgenticGenerativeUI.gif">

```tsx
"use client"; // only necessary if you are using Next.js with the App Router.
 
import { useCoAgentStateRender } from "@copilotkit/react-core";
import { Progress } from "./progress";

type AgentState = {
  logs: string[];
}

useCoAgentStateRender<AgentState>({
  name: "basic_agent",
  render: ({ state, nodeName, status }) => {
    if (!state.logs || state.logs.length === 0) {
      return null;
    }

    // Progress is a component we are omitting from this example for brevity.
    return <Progress logs={state.logs} />; 
  },
});
```
</ImageAndCode>




================================================
FILE: docs/content/docs/coagents/custom-look-and-feel/built-in-ui-components.mdx
================================================
---
title: "Prebuilt Copilot UI"
icon: "lucide/MessageCircle"
---
import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";

<ConnectCopilotUI components={props.components} />



================================================
FILE: docs/content/docs/coagents/custom-look-and-feel/customize-built-in-ui-components.mdx
================================================
---
title: "Styling Copilot UI"
icon: "lucide/Brush"
---
import { CopilotKitCSS, InteractiveCSSInspector } from "@/components/react/copilotkit-css";

CopilotKit has a variety of ways to customize colors and structures of the Copilot UI components.
- [CSS Variables](#css-variables-easiest)
- [Custom CSS](#custom-css)
- [Custom Icons](#custom-icons)
- [Custom Labels](#custom-labels)

If you want to customize the style as well as the functionality of the Copilot UI, you can also try the following:
- [Custom Sub-Components](/guides/custom-look-and-feel/bring-your-own-components)
- [Fully Headless UI](/guides/custom-look-and-feel/headless-ui)

## CSS Variables (Easiest)
The easiest way to change the colors using in the Copilot UI components is to override CopilotKit CSS variables.

<Callout type="info">
  Hover over the interactive UI elements below to see the available CSS variables.
</Callout>

<CopilotKitCSS />
<InteractiveCSSInspector />

Once you've found the right variable, you can import `CopilotKitCSSProperties` and simply wrap CopilotKit in a div and override the CSS variables. 

```tsx
import { CopilotKitCSSProperties } from "@copilotkit/react-ui";

<div
  // [!code highlight:6]
  style={
    {
      "--copilot-kit-primary-color": "#222222",
    } as CopilotKitCSSProperties
  }
>
  <CopilotSidebar .../>
</div>
```

### Reference

| CSS Variable | Description |
|-------------|-------------|
| `--copilot-kit-primary-color` | Main brand/action color - used for buttons, interactive elements |
| `--copilot-kit-contrast-color` | Color that contrasts with primary - used for text on primary elements |
| `--copilot-kit-background-color` | Main page/container background color |
| `--copilot-kit-secondary-color` | Secondary background - used for cards, panels, elevated surfaces |
| `--copilot-kit-secondary-contrast-color` | Primary text color for main content |
| `--copilot-kit-separator-color` | Border color for dividers and containers |
| `--copilot-kit-muted-color` | Muted color for disabled/inactive states |

## Custom CSS

In addition to customizing the colors, the CopilotKit CSS is structured to easily allow customization via CSS classes.

```css title="globals.css"
.copilotKitButton {
  border-radius: 0;
}

.copilotKitMessages {
  padding: 2rem;
}

.copilotKitUserMessage {
  background: #007AFF;
}
```

### Reference

<Callout>
For a full list of styles and classes used in CopilotKit, click [here](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-ui/src/css/).
</Callout>

| CSS Class | Description |
|-----------|-------------|
| `.copilotKitMessages` | Main container for all chat messages with scroll behavior and spacing |
| `.copilotKitInput` | Text input container with typing area and send button |
| `.copilotKitUserMessage` | Styling for user messages including background, text color and bubble shape |
| `.copilotKitAssistantMessage` | Styling for AI responses including background, text color and bubble shape |
| `.copilotKitHeader` | Top bar of chat window containing title and controls |
| `.copilotKitButton` | Primary chat toggle button with hover and active states |
| `.copilotKitWindow` | Root container defining overall chat window dimensions and position |
| `.copilotKitMarkdown` | Styles for rendered markdown content including lists, links and quotes |
| `.copilotKitCodeBlock` | Code snippet container with syntax highlighting and copy button |
| `.copilotKitChat` | Base chat layout container handling positioning and dimensions |
| `.copilotKitSidebar` | Styles for sidebar chat mode including width and animations |
| `.copilotKitPopup` | Styles for popup chat mode including position and animations |
| `.copilotKitButtonIcon` | Icon styling within the main chat toggle button |
| `.copilotKitButtonIconOpen` `.copilotKitButtonIconClose` | Icon states for when chat is open/closed |
| `.copilotKitCodeBlockToolbar` | Top bar of code blocks with language and copy controls |
| `.copilotKitCodeBlockToolbarLanguage` | Language label styling in code block toolbar |
| `.copilotKitCodeBlockToolbarButtons` | Container for code block action buttons |
| `.copilotKitCodeBlockToolbarButton` | Individual button styling in code block toolbar |
| `.copilotKitSidebarContentWrapper` | Inner container for sidebar mode content |
| `.copilotKitInputControls` | Container for input area buttons and controls |
| `.copilotKitActivityDot1` `.copilotKitActivityDot2` `.copilotKitActivityDot3` | Animated typing indicator dots |
| `.copilotKitDevConsole` | Development debugging console container |
| `.copilotKitDevConsoleWarnOutdated` | Warning styles for outdated dev console |
| `.copilotKitVersionInfo` | Version information display styles |
| `.copilotKitDebugMenuButton` | Debug menu toggle button styling |
| `.copilotKitDebugMenu` | Debug options menu container |
| `.copilotKitDebugMenuItem` | Individual debug menu option styling |

## Custom Fonts
You can customize the fonts by updating the `fontFamily` property in the various CSS classes that are used in the CopilotKit.

```css title="globals.css"
.copilotKitMessages {
  font-family: "Arial, sans-serif";
}

.copilotKitInput {
  font-family: "Arial, sans-serif";
}
```

### Reference
You can update the main content classes to change the font family for the various components.

| CSS Class | Description |
|-----------|-------------|
| `.copilotKitMessages` | Main container for all messages |
| `.copilotKitInput` | The input field |
| `.copilotKitMessage` | Base styling for all chat messages |
| `.copilotKitUserMessage` | User messages |
| `.copilotKitAssistantMessage` | AI responses |

## Custom Icons

You can customize the icons by passing the `icons` property to the `CopilotSidebar`, `CopilotPopup` or `CopilotChat` component.

```tsx
<CopilotChat
  icons={{
    // Use your own icons here – any React nodes
    openIcon: <YourOpenIconComponent />,
    closeIcon: <YourCloseIconComponent />,
  }}
/>
```

### Reference

| Icon | Description |
|--------------|-------------|
| `openIcon` | The icon to use for the open chat button |
| `closeIcon` | The icon to use for the close chat button |
| `headerCloseIcon` | The icon to use for the close chat button in the header |
| `sendIcon` | The icon to use for the send button |
| `activityIcon` | The icon to use for the activity indicator |
| `spinnerIcon` | The icon to use for the spinner |
| `stopIcon` | The icon to use for the stop button |
| `regenerateIcon` | The icon to use for the regenerate button |
| `pushToTalkIcon` | The icon to use for push to talk |

## Custom Labels

To customize labels, pass the `labels` property to the `CopilotSidebar`, `CopilotPopup` or `CopilotChat` component.

```tsx
<CopilotChat
  labels={{
    initial: "Hello! How can I help you today?",
    title: "My Copilot",
    placeholder: "Ask me anything!",
    stopGenerating: "Stop",
    regenerateResponse: "Regenerate",
  }} 
/>
```

### Reference

| Label | Description |
|---------------|-------------|
| `initial` | The initial message(s) to display in the chat window |
| `title` | The title to display in the header |
| `placeholder` | The placeholder to display in the input |
| `stopGenerating` | The label to display on the stop button |
| `regenerateResponse` | The label to display on the regenerate button |




================================================
FILE: docs/content/docs/coagents/custom-look-and-feel/headless-ui.mdx
================================================
---
title: "Fully Headless UI"
description: "Fully customize your Copilot's UI from the ground up using headless UI"
icon: "lucide/Settings"
---

import { ImageAndCode } from "@/components/react/image-and-code"

The built-in Copilot UI can be customized in many ways -- both through CSS and by passing in custom sub-components.

CopilotKit also offers **fully custom headless UI** through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

```tsx
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function CustomChatInterface() {
  const {
    visibleMessages,
    appendMessage,
    setMessages,
    deleteMessage,
    reloadMessages,
    stopGeneration,
    isLoading,
  } = useCopilotChat();

  const sendMessage = (content: string) => {
    appendMessage(new TextMessage({ content, role: Role.User }));
  };

  return (
    <div>
      {/* Implement your custom chat UI here */}
    </div>
  );
}
```

## Resetting the chat history
In some cases, users may want to reset the chat to clear the conversation history and start fresh. This can be useful when:
- The current conversation has become too long or confusing.
- You want to test different prompts or approaches from a clean slate.
- A user needs to reset the context to ensure the AI responds appropriately.

This simple method allows you to reset the chat state with a button click.

<Callout title="Why Reset the Chat?">
Resetting the chat clears all conversation history, helping you start fresh or troubleshoot AI responses.
</Callout>

<ImageAndCode preview="/images/concepts/customize-look-and-feel/reset-chat.gif" >

```tsx

"use client"; // only necessary if you are using Next.js with the App Router.

import { InputProps, CopilotSidebar } from "@copilotkit/react-ui";
import { useCopilotChat } from "@copilotkit/react-core";
import "@copilotkit/react-ui/styles.css";

function CustomInput({ inProgress, onSend, isVisible }: InputProps) {
  const { reset } = useCopilotChat(); // Get reset function

  return (
    <div style={{ display: isVisible ? "flex" : "none", alignItems: "center", gap: "10px", padding: "10px", borderTop: "1px solid #eee" }}>
      {/* Text Input */}
      <input
        disabled={inProgress}
        type="text"
        placeholder="Ask your question here..."
        style={{
          flex: 1,
          padding: "8px",
          borderRadius: "4px",
          border: "1px solid #ccc",
          outline: "none",
        }}
        onKeyDown={(e) => {
          if (e.key === "Enter") {
            onSend(e.currentTarget.value);
            e.currentTarget.value = "";
          }
        }}
      />

      {/* Send Button */}
      <button
        disabled={inProgress}
        style={{
          padding: "8px 12px",
          border: "none",
          borderRadius: "4px",
          background: "#007bff",
          color: "white",
          cursor: "pointer",
        }}
        onClick={(e) => {
          const input = e.currentTarget.previousElementSibling as HTMLInputElement;
          onSend(input.value);
          input.value = "";
        }}
      >
        Send
      </button>

      {/* Reset Chat Button */}
      <button
        style={{
          padding: "8px 12px",
          border: "none",
          borderRadius: "4px",
          background: "#f44336",
          color: "white",
          cursor: "pointer",
        }}
        onClick={() => reset()}
      >
        Reset
      </button>
    </div>
  );
}
```
</ImageAndCode> 



================================================
FILE: docs/content/docs/coagents/custom-look-and-feel/index.mdx
================================================
---
title: "Customize UI"
description: "Customize the look, feel, and functionality of CopilotKit's UI components."
icon: "lucide/Settings"
---
import { MessageCircleIcon, BrushIcon, PuzzleIcon, SettingsIcon } from "lucide-react";

CopilotKit offers a variety of ways to create a UI interface for your Copilots and CoAgents. This ranges
from using our built-in UI components to fully customizing the UI with headless UI.

<Cards>
  <Card
    title="Prebuilt Copilot UI"
    icon={<MessageCircleIcon />}
    description="Get started quickly with CopilotKit's ready-to-use UI components."
    href="/guides/custom-look-and-feel/built-in-ui-components"
  />
  <Card
    title="Styling Copilot UI"
    icon={<BrushIcon />}
    description="Customize the appearance of CopilotKit's pre-built components with your own styles."
    href="/guides/custom-look-and-feel/customize-built-in-ui-components"
  />
  <Card
    title="Custom Components"
    icon={<PuzzleIcon />}
    description="Replace the Copilot UI components with your own while keeping the core functionality."
    href="/guides/custom-look-and-feel/bring-your-own-components"
  />
  <Card
    title="Fully Custom UI"
    icon={<SettingsIcon />}
    description="Build your UI from scratch using CopilotKit's hooks and core functionality."
    href="/guides/custom-look-and-feel/headless-ui"
  />
</Cards>


================================================
FILE: docs/content/docs/coagents/custom-look-and-feel/meta.json
================================================
{
  "title": "Customize UI",
  "icon": "lucide/Paintbrush",
  "pages": [
    "built-in-ui-components",
    "customize-built-in-ui-components",
    "bring-your-own-components",
    "headless-ui"
  ]
}



================================================
FILE: docs/content/docs/coagents/generative-ui/agentic.mdx
================================================
---
title: Agentic Generative UI
icon: "lucide/Bot"
description: Render the state of your agent with custom UI components.
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

<video src="/images/coagents/agentic-generative-ui.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
  This video demonstrates the [implementation](#implementation) section applied to out [coagents starter project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter).
</Callout>

## What is this?

All LangGraph agents are stateful. This means that as your agent progresses through nodes, a state object is passed between them perserving
the overall state of a session. CopilotKit allows you to render this state in your application with custom UI components, which we call **Agentic Generative UI**.

## When should I use this?

Rendering the state of your agent in the UI is useful when you want to provide the user with feedback about the overall state of a session. A great example of this
is a situation where a user and an agent are working together to solve a problem. The agent can store a draft in its state which is then rendered in the UI.

## Implementation

<Steps>
  <Step>
    ### Run and Connect your LangGraph to CopilotKit
    First, you'll need to make sure you have a running LangGraph. If you haven't already done this, you can follow the [getting started guide](/coagents/quickstart/langgraph)

    This guide uses the [CoAgents starter repo](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) as its starting point.

  </Step>
  <Step>
    ### Define your agent state
    If you're not familiar with LangGraph, your graphs are stateful. As you progress through nodes, a state object is passed between them. CopilotKit
    allows you to easily render this state in your application. 
    
    For the sake of this guide, let's say our state looks like this in our agent.

    <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
        <Tab value="Python">
          ```python title="agent-py/sample_agent/agent.py"
          # ...
          from copilotkit import CopilotKitState # extends MessagesState
          # ...

          # This is the state of the agent.
          # It inherits from the CopilotKitState properties from CopilotKit.
          class AgentState(CopilotKitState):
              searches: list[dict]
          ```
        </Tab>
        <Tab value="TypeScript">
          ```typescript title="agent-js/src/agent.ts"
          // ...
          import { Annotation } from "@langchain/langgraph";
          import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";
          // ...

          // This is the state of the agent.
          // It inherits from the CopilotKitState properties from CopilotKit.
          export const AgentStateAnnotation = Annotation.Root({
            searches: Annotation<object[]>,
            ...CopilotKitStateAnnotation.spec,
          });
          export type AgentState = typeof AgentStateAnnotation.State;
          ```
        </Tab>
    </Tabs>
  </Step>
  <Step>
    ### Simulate state updates
    Next, let's write some logic into our agent that will simulate state updates occurring.

    <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        import asyncio
        from typing import TypedDict
        from langchain_core.runnables import RunnableConfig
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import SystemMessage
        from copilotkit import CopilotKitState
        from copilotkit.langgraph import copilotkit_emit_state

        class Searches(TypedDict):
            query: str
            done: bool

        class AgentState(CopilotKitState):
            searches: list[Searches] = []

        async def chat_node(state: AgentState, config: RunnableConfig):
            state["searches"] = [
                {"query": "Initial research", "done": False},
                {"query": "Retrieving sources", "done": False},
                {"query": "Forming an answer", "done": False},
            ]
            await copilotkit_emit_state(config, state)

            # Simulate state updates # [!code highlight:5]
            for search in state["searches"]:
                await asyncio.sleep(1)
                search["done"] = True
                await copilotkit_emit_state(config, state)

            # Run the model to generate a response
            response = await ChatOpenAI(model="gpt-4o").ainvoke([
                SystemMessage(content="You are a helpful assistant."),
                *state["messages"],
            ], config)
        ```
      </Tab>
      <Tab value="TypeScript">
        ```typescript title="agent-js/src/agent.ts"
        import { RunnableConfig } from "@langchain/core/runnables";
        import { ChatOpenAI } from "@langchain/openai";
        import { Annotation } from "@langchain/langgraph";
        import { SystemMessage } from "@langchain/core/messages";
        import { copilotkitEmitState, CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

        type Search = {
          query: string;
          done: boolean;
        }

        export const AgentStateAnnotation = Annotation.Root({
          searches: Annotation<Search[]>,
          ...CopilotKitStateAnnotation.spec,
        });

        async function chat_node(state: AgentState, config: RunnableConfig) {
          state.searches = [
            { query: "Initial research", done: false },
            { query: "Retrieving sources", done: false },
            { query: "Forming an answer", done: false },
          ];
          await copilotkitEmitState(config, state);

          // Simulate state updates # [!code highlight:5]
          for (const search of state.searches) {
            await new Promise(resolve => setTimeout(resolve, 1000));
            search.done = true;
            await copilotkitEmitState(config, state);
          }

          const response = await new ChatOpenAI({ model: "gpt-4o" }).invoke([
            new SystemMessage({ content: "You are a helpful assistant."}),
            ...state.messages,
          ], config);
        ```
      </Tab>
    </Tabs>
  </Step>
  <Step>
    ### Render state of the agent in the chat
    Now we can utilize `useCoAgentStateRender` to render the state of our agent **in the chat**.

    ```tsx title="app/page.tsx"
    // ...
    import { useCoAgentStateRender } from "@copilotkit/react-core";
    // ...

    // Define the state of the agent, should match the state of the agent in your LangGraph.
    type AgentState = {
      searches: {
        query: string;
        done: boolean;
      }[];
    };

    function YourMainContent() {
      // ... 

      // [!code highlight:14]
      // styles omitted for brevity
      useCoAgentStateRender<AgentState>({
        name: "sample_agent", // the name the agent is served as
        render: ({ state }) => (
          <div>
            {state.searches?.map((search, index) => (
              <div key={index}>
                {search.done ? "✅" : "❌"} {search.query}{search.done ? "" : "..."}
              </div>
            ))}
          </div>
        ),
      });

      // ...

      return <div>...</div>;
    }
    ```
  </Step>
  <Step>
    ### Render state outside of the chat
    You can also render the state of your agent **outside of the chat**. This is useful when you want to render the state of your agent anywhere
    other than the chat.

    ```tsx title="app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]
    // ...

    // Define the state of the agent, should match the state of the agent in your LangGraph.
    type AgentState = {
      searches: {
        query: string;
        done: boolean;
      }[];
    };

    function YourMainContent() {
      // ... 

      // [!code highlight:5]
      const { state } = useCoAgent<AgentState>({
        name: "sample_agent", // the name the agent is served as
      })

      // ...

      return (
        <div>
          {/* ... */}
          <div className="flex flex-col gap-2 mt-4">
            // [!code highlight:6]
            {state.searches?.map((search, index) => (
              <div key={index} className="flex flex-row">
                {search.done ? "✅" : "❌"} {search.query}
              </div>
            ))}
          </div>
        </div>
      )
    }
    ```
  </Step>
  <Step>
    ### Give it a try!

    You've now created a component that will render the agent's state in the chat.
  </Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/generative-ui/index.mdx
================================================
---
title: Generative UI
icon: "lucide/Paintbrush"
description: Render your agent's behavior with custom UI components.
---
import {CTACards} from "@/components/react/cta-cards"
import { WrenchIcon, BotIcon } from "lucide-react"

<Frame>
  <img 
    src="/images/coagents/AgenticGenerativeUI.gif" 
    className="my-0" 
    alt="Demo of Generative UI showing a meeting scheduling agent"
  />
</Frame>

<Callout>
    This example shows our [Research Canvas](/coagents/videos/research-canvas) making use of Generative UI!
</Callout>

## What is Generative UI?

Generative UI lets you render your agent's state, progress, outputs, and tool calls with custom UI components in real-time. It bridges the gap between AI
agents and user interfaces. As your agent processes information and makes decisions, you can render custom UI components that:

- Show loading states and progress indicators
- Display structured data in tables, cards, or charts
- Create interactive elements for user input
- Animate transitions between different states

## How can I use this?

There are two main variants of Generative UI.

<CTACards
  columns={2}
  cards={[
    {
      icon: BotIcon,
      title: "Agentic",
      description: "Render your agent's state, progress, and outputs with custom UI components.",
      href: "/coagents/generative-ui/agentic"
    },
    {
      icon: WrenchIcon,
      title: "Tool-based",
      description: "Render your agent's tool calls with custom UI components.",
      href: "/coagents/generative-ui/tool-based"
    },
  ]}
/>




================================================
FILE: docs/content/docs/coagents/generative-ui/tool-based.mdx
================================================
---
title: Tool-based Generative UI
icon: "lucide/Wrench"
description: Render your agent's tool calls with custom UI components.
---
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx"

<video src="/images/coagents/tool-based-gen-ui.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
  This video demonstrates the [implementation](#implementation) section applied to out [coagents starter project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter).
</Callout>

## What is this?

Tools are a way for the LLM to call predefined, typically, deterministic functions. CopilotKit allows you to render these tools in the UI
as a custom component, which we call **Generative UI**.

## When should I use this?

Rendering tools in the UI is useful when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
<Step>
### Run and connect your agent
<RunAndConnectAgentSnippet />
</Step>
<Step>
### Give your agent a tool to call

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        from langchain_openai import ChatOpenAI
        from langchain.tools import tool
        # ...

        # [!code highlight:7]
        @tool
        def get_weather(location: str):
            """
            Get the weather for a given location.
            """
            return f"The weather for {location} is 70 degrees."

        # ...

        async def chat_node(state: AgentState, config: RunnableConfig):
            model = ChatOpenAI(model="gpt-4o")
            model_with_tools = model.bind_tools([get_weather]) # [!code highlight]

            response = await model_with_tools.ainvoke([
                SystemMessage(content=f"You are a helpful assistant.")
                *state["messages"],
            ], config)

            # ...
        ```
    </Tab>
    <Tab value="TypeScript">
        ```typescript title="agent-js/src/agent.ts"
        import { ChatOpenAI } from "@langchain/openai";
        import { tool } from "@langchain/core/tools";

        // [!code highlight:13]
        const get_weather = tool(
          (args) => {
            return `The weather for ${args.location} is 70 degrees.`;
          },
          {
            name: "get_weather",
            description: "Get the weather for a given location.",
            schema: z.object({
              location: z.string().describe("The location to get weather for"),
            }),
          }
        );

        async function chat_node(state: AgentState, config: RunnableConfig) {
          const model = new ChatOpenAI({ temperature: 0, model: "gpt-4o" });
          const modelWithTools = model.bindTools([get_weather]); // [!code highlight]

          const response = await modelWithTools.invoke([
            new SystemMessage("You are a helpful assistant."),
            ...state.messages,
          ], config);

          // ...
        }
        ```
    </Tab>
</Tabs>
</Step>
<Step>
### Render the tool call in your frontend
At this point, your agent will be able to call the `get_weather` tool. Now 
we just need to add a `useCopilotAction` hook to render the tool call in
the UI.

<Callout type="info" title="Important">
  In order to render a tool call in the UI, the name of the action must match the name of the tool.
</Callout>

```tsx title="app/page.tsx"
import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]
// ...

const YourMainContent = () => {
  // ...
  // [!code highlight:13]
  useCopilotAction({
    name: "get_weather",
    available: "disabled", // Don't allow the agent or UI to call this tool as its only for rendering
    render: ({status, args}) => {
      return (
        <p className="text-gray-500 mt-2">
          {status !== "complete" && "Calling weather API..."}
          {status === "complete" && `Called the weather API for ${args.location}.`}
        </p>
      );
    },
  });
  // ...
}
```

</Step>
<Step>
### Give it a try!

Try asking the agent to get the weather for a location. You should see the custom UI component that we added
render the tool call and display the arguments that were passed to the tool.

</Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/human-in-the-loop/index.mdx
================================================
---
title: Human in the Loop (HITL)
icon: "lucide/User"
description: Allow your agent and users to collaborate on complex tasks.
---
import { CTACards } from "@/components/react/cta-cards"
import { Pause, Share2 } from "lucide-react"

<video src="/images/coagents/human-in-the-loop-example.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

<Callout>
  This video shows an example of our [AI Travel App](/coagents/tutorials/ai-travel-app) using HITL to get user feedback.
</Callout>

## What is Human-in-the-Loop (HITL)?

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

<Frame className="my-0">
    <img src="/images/coagents/coagents-hitl-infographic.png" alt="Agentic Copilot Human in the Loop" className="mt-4 mb-0 shadow-md" />
</Frame>

<Callout type="info">
  Learn more about HITL in [LangGraph's concept guide](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/).
</Callout>

## When should I use this?

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## How can I use this?

Copilotkit provides two main approaches for HITL LangGraph workflows - interrupt and node-based.

<Callout>
  Unsure which approach to use? We recommend starting with the [Interrupt](/coagents/human-in-the-loop/interrupt-flow) flow.
</Callout>

<CTACards
  columns={2}
  cards={[
    {
      icon: Pause,
      title: "Interrupt",
      description: "Utilize LangGraph's interrupt function to pause the agent and wait for user input.",
      href: "/coagents/human-in-the-loop/interrupt-flow"
    },
    {
      icon: Share2,
      title: "Node-based",
      description: "Utilize nodes and tools to create LLM driven Human-in-the-Loop workflows.",
      href: "/coagents/human-in-the-loop/node-flow"
    }
  ]}
/>



================================================
FILE: docs/content/docs/coagents/human-in-the-loop/interrupt-flow.mdx
================================================
---
title: Interrupt
icon: "lucide/CirclePause"
description: Learn how to implement Human-in-the-Loop (HITL) using a interrupt-based flow.
---
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"
import {
    TailoredContent,
    TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx"
import { MessageCircle, PanelsTopLeft } from "lucide-react";

<video src="/images/coagents/interrupt-flow.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

<Callout type="info">
  Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) with
  the implementation below applied!
</Callout>


## What is this?

[LangGraph's interrupt flow](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/) provides an intuitive way to implement Human-in-the-loop workflows.

This guide will show you how to both use `interrupt` and how to integrate it with CopilotKit.

## When should I use this?

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

Interrupt-based flows are a very intuitive way to implement HITL. Instead of having a node await user input before or after its execution,
nodes can be interrupted in the middle of their execution to allow for user input. The trade-off is that the agent is not aware of the 
interaction, however [CopilotKit's SDKs provide helpers to alleviate this](#make-your-agent-aware-of-interruptions).

## Implementation

<Steps>
<Step>
### Run and connect your agent
<RunAndConnectAgentSnippet />
</Step>
<Step>
  ### Install the CopilotKit SDK
  <InstallSDKSnippet components={props.components}/>
</Step>
<Step>
### Setup your agent state
We're going to have the agent ask us to name it, so we'll need a state property to store the name.

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        # ...
        from copilotkit import CopilotKitState # extends MessagesState
        # ...
        
        # This is the state of the agent.
        # It inherits from the CopilotKitState properties from CopilotKit.
        class AgentState(CopilotKitState):
            agent_name: str
        ```
    </Tab>
    <Tab value="TypeScript">
        ```typescript title="agent-js/src/agent.ts"
        // ...
        import { Annotation } from "@langchain/langgraph";
        import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";
        // ...
        
        // This is the state of the agent.
        // It inherits from the CopilotKitState properties from CopilotKit.
        export const AgentStateAnnotation = Annotation.Root({
          agentName: Annotation<string>,
          ...CopilotKitStateAnnotation.spec,
        });
        export type AgentState = typeof AgentStateAnnotation.State;
        ```
    </Tab>
</Tabs>

</Step>
    <TailoredContent
        className="step"
        id="interrupt-type"
        header={
            <div>
                <p className="text-xl font-semibold">Choose how to display the interrupt to the user</p>
            </div>
        }
    >
        <TailoredContentOption
            id="langgraph-interrupt"
            title="As a Custom Chat UI"
            description="I'd like to display a custom UI in the chat window"
            icon={<PanelsTopLeft />}
        >
            <Step>
                ### Call `interrupt` in your LangGraph agent
                Now we can call `interrupt` in our LangGraph agent.

                <Callout type="info">
                    Your agent will not be aware of the `interrupt` interaction by default in LangGraph.

                    If you want this behavior, see the [section on it below](#make-your-agent-aware-of-interruptions).
                </Callout>

                <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
                    <Tab value="Python">
                        ```python title="agent/sample_agent/agent.py"
                        from langgraph.types import interrupt # [!code highlight]
                        from langchain_core.messages import SystemMessage
                        from langchain_openai import ChatOpenAI
                        from copilotkit import CopilotKitState

                        # add the agent state definition from the previous step
                        class AgentState(CopilotKitState):
                            agent_name: str

                        def chat_node(state: AgentState, config: RunnableConfig):
                            if not state.get("agent_name"):
                                # Interrupt and wait for the user to respond with a name
                                state["agent_name"] = interrupt("Before we start, what would you like to call me?") # [!code highlight]

                            # Tell the agent its name
                            system_message = SystemMessage(
                                content=f"You are a helpful assistant named {state.get('agent_name')}..."
                            )

                            response = ChatOpenAI(model="gpt-4o").invoke(
                                [system_message, *state["messages"]],
                                config
                            )

                            return {
                                **state,
                                "messages": response,
                            }
                        ```
                    </Tab>
                    <Tab value="TypeScript">
                        ```typescript title="agent-js/src/agent.ts"
                        import { interrupt } from "@langchain/langgraph"; // [!code highlight]
                        import { SystemMessage } from "@langchain/core/messages";
                        import { ChatOpenAI } from "@langchain/openai";

                        // add the agent state definition from the previous step
                        export const AgentStateAnnotation = Annotation.Root({
                            agentName: Annotation<string>,
                            ...CopilotKitStateAnnotation.spec,
                        });
                        export type AgentState = typeof AgentStateAnnotation.State;

                        async function chat_node(state: AgentState, config: RunnableConfig) {
                            const agentName = state.agentName
                            ?? interrupt("Before we start, what would you like to call me?"); // [!code highlight]

                            // Tell the agent its name
                            const systemMessage = new SystemMessage({
                                content: `You are a helpful assistant named ${state.agentName}...`,
                            });

                            const response = await new ChatOpenAI({ model: "gpt-4o" }).invoke(
                                [systemMessage, ...state.messages],
                                config
                            );

                            return {
                                ...state,
                                agentName
                                messages: response,
                            };
                        }
                        ```
                    </Tab>
                </Tabs>
            </Step>
            <Step>
                ### Handle the interrupt in your frontend
                At this point, your LangGraph agent's `interrupt` will be called. However, we currently have no handling for rendering or
                responding to the interrupt in the frontend.

                To do this, we'll use the `useLangGraphInterrupt` hook, give it a component to render, and then call `resolve` with the user's response.

                ```tsx title="app/page.tsx"
                import { useLangGraphInterrupt } from "@copilotkit/react-core"; // [!code highlight]
                // ...

                const YourMainContent = () => {
                // ...
                // [!code highlight:16]
                // styles omitted for brevity
                useLangGraphInterrupt({
                    render: ({ event, resolve }) => (
                        <div>
                            <p>{event.value}</p>
                            <form onSubmit={(e) => {
                                e.preventDefault();
                                resolve((e.target as HTMLFormElement).response.value);
                            }}>
                                <input type="text" name="response" placeholder="Enter your response" />
                                <button type="submit">Submit</button>
                            </form>
                        </div>
                    )
                });
                // ...

                return <div>{/* ... */}</div>
                }
                ```

            </Step>
        </TailoredContentOption>
        <TailoredContentOption
            id="cpk-interrupt"
            title="As Message"
            description="I'd like to display the interrupt as a copilot message"
            icon={<MessageCircle />}
        >
            <Step>
                ### Call `copilotkit_interrupt` in your LangGraph agent
                Now we can call `copilotkit_interrupt` in our LangGraph agent.

                With `copilotkit_interrupt` we can render a simple message for the user to answer, or an action defined with `useCopilotAction` hook

                <Callout type="info">
                    Your agent will not be aware of the `interrupt` interaction by default in LangGraph.

                    If you want this behavior, see the [section on it below](#make-your-agent-aware-of-interruptions).
                </Callout>

                <Tabs groupId="implementation" items={["Message", "Action"]}>
                    <Tab value="Message">
                        <div className="py-6">
                            <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
                                <Tab value="Python">
                                    ```python title="agent/sample_agent/agent.py"
                                    from copilotkit.langgraph import copilotkit_interrupt # [!code highlight]
                                    from langchain_core.messages import SystemMessage
                                    from langchain_openai import ChatOpenAI
                                    # ...

                                    def chat_node(state: AgentState, config: RunnableConfig):
                                      if not state.get("agent_name"):
                                        # Interrupt and wait for the user to respond with a name
                                        answer, messages = copilotkit_interrupt(message='Before we start, what would you like to call me?') # [!code highlight]
                                        state["agent_name"] = answer
                                        state["messages"] = [*state["messages"], *messages]

                                      # Tell the agent its name
                                      system_message = SystemMessage(
                                        content=f"You are a helpful assistant named {state.get('agent_name')}..."
                                      )

                                      response = ChatOpenAI(model="gpt-4o").invoke(
                                        [system_message, *state["messages"]],
                                        config
                                      )

                                      return {
                                        **state,
                                        # messages receives from the interrupt are not automatically saved to state, don't forget to add them!
                                        "messages": [*state["messages"], response],
                                      }
                                    ```
                                </Tab>
                                <Tab value="TypeScript">
                                    ```typescript title="agent-js/src/agent.ts"
                                    import { copilotKitInterrupt } from "@copilotkit/sdk-js/langgraph"; // [!code highlight]
                                    import { SystemMessage } from "@langchain/core/messages";
                                    import { ChatOpenAI } from "@langchain/openai";

                                    // ... add here the agent state from previous step

                                    async function chat_node(state: AgentState, config: RunnableConfig) {
                                      if (!state.agentName) {
                                        const { answer, messages } = copilotKitInterrupt({ message: 'Before we start, what would you like to call me?' }); // [!code highlight]
                                        state.agentName = answer
                                        state.messages = [...state.messages, ...messages]
                                      }

                                      // Tell the agent its name
                                      const systemMessage = new SystemMessage({
                                        content: `You are a helpful assistant named ${state.agentName}...`,
                                      });

                                      const response = await new ChatOpenAI({ model: "gpt-4o" }).invoke(
                                        [systemMessage, ...state.messages],
                                        config
                                      );

                                      return {
                                        ...state,
                                        // messages receives from the interrupt are not automatically saved to state, remember to add them!
                                        messages: [...state.messages, response],
                                      };
                                    }
                                    ```
                                </Tab>
                            </Tabs>
                        </div>
                    </Tab>
                    <Tab value="Action" className="py-6">
                        Let's assume an "AskName" action that takes message as argument:

                        ```tsx title="your-component.tsx"
                        "use client" // only necessary if you are using Next.js with the App Router.
                        import { useCopilotAction } from "@copilotkit/react-core";

                        export function YourComponent() {
                          useCopilotAction({
                            name: "AskName",
                            description: "Ask the user how they would like to call you",
                            parameters: [
                              {
                                  name: "message",
                                  type: "string",
                                  description: "The message that asks for the name",
                                  required: true
                              },
                            ],
                            render: ({ status, args }) => {
                              const { message } = args;

                              return <div>{ message }</div>;
                            },
                          });

                          return (
                            <>...</>
                          );
                        }
                        ```
                        <div className="py-6">
                            <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
                                <Tab value="Python">
                                    ```python title="agent/sample_agent/agent.py"
                                    from copilotkit.langgraph import copilotkit_interrupt # [!code highlight]
                                    from langchain_core.messages import SystemMessage
                                    from langchain_openai import ChatOpenAI
                                    # ...

                                    def chat_node(state: AgentState, config: RunnableConfig):
                                      if not state.get("agent_name"):
                                        # Interrupt and wait for the user to respond with a name
                                        # [!code highlight:5]
                                        answer, messages = copilotkit_interrupt(
                                         action='AskName', # The action name you defined in an existing useCopilotAction hook
                                         args={ "message": "Before we start, what would you like to call me?" } # The arguments to pass when the tool is called.
                                        )
                                        state["agent_name"] = answer
                                        state["messages"] = [*state["messages"], *messages]

                                      # Tell the agent its name
                                      system_message = SystemMessage(
                                        content=f"You are a helpful assistant named {state.get('agent_name')}..."
                                      )

                                      response = ChatOpenAI(model="gpt-4o").invoke(
                                        [system_message, *state["messages"]],
                                        config
                                      )

                                      return {
                                        **state,
                                        # messages receives from the interrupt are not automatically saved to state, don't forget to add them!
                                        "messages": [*state["messages"], response],
                                      }
                                    ```
                                </Tab>
                                <Tab value="TypeScript">
                                    ```typescript title="agent-js/src/agent.ts"
                                    import { copilotKitInterrupt } from "@copilotkit/sdk-js/langgraph"; // [!code highlight]
                                    import { SystemMessage } from "@langchain/core/messages";
                                    import { ChatOpenAI } from "@langchain/openai";

                                    // ... add here the agent state from previous step

                                    async function chat_node(state: AgentState, config: RunnableConfig) {
                                      if (!state.agentName) {
                                        // [!code highlight:5]
                                        const { answer, messages } = copilotKitInterrupt({
                                          action: 'AskName', // The action name you defined in an existing useCopilotAction hook
                                          args: { message: 'Before we start, what would you like to call me?' }, // The arguments to pass when the tool is called.
                                        }); // [!code highlight]
                                        state.agentName = answer
                                        state.messages = [...state.messages, ...messages]
                                      }

                                    // Tell the agent its name
                                      const systemMessage = new SystemMessage({
                                        content: `You are a helpful assistant named ${state.agentName}...`,
                                      });

                                      const response = await new ChatOpenAI({ model: "gpt-4o" }).invoke(
                                        [systemMessage, ...state.messages],
                                        config
                                      );

                                      return {
                                        ...state,
                                        // messages receives from the interrupt are not automatically saved to state, don't forget to add them!
                                        messages: [...state.messages, response],
                                      };
                                    }
                                    ```
                                </Tab>
                            </Tabs>
                        </div>
                    </Tab>
                </Tabs>
            </Step>
        </TailoredContentOption>
    </TailoredContent>
<Step>
### Give it a try!
Try talking to your agent, you'll see that it now pauses execution and waits for you to respond!
</Step>
</Steps>

## Make your agent aware of interruptions

By default, your agent will not be made aware of LangGraph `interrupts`. This is because the decision is not saved into the message's state.
For simple and sensitive flows, this is ideal. However, you may want to make your agent aware of these interactions.

If you've been using the "As Message" implementation, you may have noticed that the messages are returned from the interrupt function.
These can be used to notify the LLM about the recent communication:

<Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
    <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from copilotkit import copilotkit_interrupt

        # ...
        async def chat_node(state: AgentState, config: RunnableConfig)
            agent_name, new_messages = copilotkit_interrupt(message="Before we start, what would you like to call me?")
            state["messages"] = state["messages"] + new_messages
            state["agent_name"] = agent_name
            # ... add the rest of the node implementation, including LLM calls etc.

            # Don't forget to return the messages list with our newly added interrupt messages, and the new agent name
            return { "messages": state["messages"], "agent_name": state["agent_name"] }
        # ...
        ```
    </Tab>
    <Tab value="TypeScript">
        ```typescript title="agent-js/src/agent.ts"
        import { copilotKitInterrupt } from "@copilotkit/sdk-js/langgraph";

        // ...
        async function chat_node(state: AgentState, config: RunnableConfig) {
            const { agentName, messages } = copilotKitInterrupt({ message: "Before we start, what would you like to call me?" });
            state.messages = [...state.messages, ...messages];
            state.agentName = agentName;
            // ... add the rest of the node implementation, including LLM calls etc.

            // Don't forget to return the messages list with our newly added interrupt messages, and the new agent name
            return { messages: state.messages, agentName: state.agentName }
        }
        ```
    </Tab>
</Tabs>

## Condition UI executions

When opting for custom chat UI while having multiple `interrupt` events in the agent, there could be conflicts between multiple `useLangGraphInterrupt` hooks calls in the UI.
For this reason, the hook can take an `enabled` argument which will apply it conditionally:

<Steps>
    <Step>
        ### Define multiple interrupts
        First, let's define two different interrupts. We will include a "type" property to differentiate them.
        <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
            <Tab value="Python">
                ```python title="agent/sample_agent/agent.py"
                from langgraph.types import interrupt # [!code highlight]
                from langchain_core.messages import SystemMessage
                from langchain_openai import ChatOpenAI

                # ... your full state definition

                def chat_node(state: AgentState, config: RunnableConfig):

                  state["approval"] = interrupt({ "type": "approval", "content": "please approve" }) # [!code highlight]

                  if not state.get("agent_name"):
                    # Interrupt and wait for the user to respond with a name
                    state["agent_name"] = interrupt({ "type": "ask", "content": "Before we start, what would you like to call me?" }) # [!code highlight]

                  # Tell the agent its name
                  system_message = SystemMessage(
                    content=f"You are a helpful assistant..."
                  )

                  response = ChatOpenAI(model="gpt-4o").invoke(
                    [system_message, *state["messages"]],
                    config
                  )

                  return {
                    **state,
                    "messages": response,
                  }
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript title="agent-js/src/agent.ts"
                import { interrupt } from "@langchain/langgraph"; // [!code highlight]
                import { SystemMessage } from "@langchain/core/messages";
                import { ChatOpenAI } from "@langchain/openai";

                // ... your full state definition

                async function chat_node(state: AgentState, config: RunnableConfig) {
                  state.approval = await interrupt({ type: "approval", content: "please approve" }); // [!code highlight]

                  if (!state.agentName) {
                    state.agentName = await interrupt({ type: "ask", content: "Before we start, what would you like to call me?" }); // [!code highlight]
                  }

                  // Tell the agent its name
                  const systemMessage = new SystemMessage({
                    content: `You are a helpful assistant...`,
                  });

                  const response = await new ChatOpenAI({ model: "gpt-4o" }).invoke(
                    [systemMessage, ...state.messages],
                    config
                  );

                  return {
                    ...state,
                    messages: response,
                  };
                }
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Add multiple frontend handlers
        With the differentiator in mind, we will add a handler that takes care of any "ask" and any "approve" types.
        With two `useLangGraphInterrupt` hooks in our page, we can leverage the `enabled` property to enable each in the right time:

        ```tsx title="app/page.tsx"
        import { useLangGraphInterrupt } from "@copilotkit/react-core"; // [!code highlight]
        // ...

        const ApproveComponent = ({ content, onAnswer }: { content: string; onAnswer: (approved: boolean) => void }) => (
            // styles omitted for brevity
            <div>
                <h1>Do you approve?</h1>
                <button onClick={() => onAnswer(true)}>Approve</button>
                <button onClick={() => onAnswer(false)}>Reject</button>
            </div>
        )

        const AskComponent = ({ question, onAnswer }: { question: string; onAnswer: (answer: string) => void }) => (
        // styles omitted for brevity
            <div>
                <p>{question}</p>
                <form onSubmit={(e) => {
                    e.preventDefault();
                    onAnswer((e.target as HTMLFormElement).response.value);
                }}>
                    <input type="text" name="response" placeholder="Enter your response" />
                    <button type="submit">Submit</button>
                </form>
            </div>
        )

        const YourMainContent = () => {
            // ...
            // [!code highlight:14]
            useLangGraphInterrupt({
                enabled: ({ eventValue }) => eventValue.type === 'ask',
                render: ({ event, resolve }) => (
                    <AskComponent question={event.value.content} onAnswer={answer => resolve(answer)} />
                )
            });

            useLangGraphInterrupt({
                enabled: ({ eventValue }) => eventValue.type === 'approval',
                render: ({ event, resolve }) => (
                    <ApproveComponent content={event.value.content} onAnswer={answer => resolve(answer)} />
                )
            });

            // ...
        }
    ```
    </Step>
</Steps>

## Preprocessing of an interrupt and programmatically handling an interrupt value

When opting for custom chat UI, some cases may require pre-processing of the incoming values of interrupt event or even resolving it entirely without showing a UI for it.
This can be achieved using the `handler` property, which is not required to return a React component.

The return value of the handler will be passed to the `render` method as the `result` argument.
```tsx title="app/page.tsx"
// We will assume an interrupt event in the following shape
type Department = 'finance' | 'engineering' | 'admin'
interface AuthorizationInterruptEvent {
    type: 'auth',
    accessDepartment: Department,
}

import { useLangGraphInterrupt } from "@copilotkit/react-core";

const YourMainContent = () => {
    const [userEmail, setUserEmail] = useState({ email: 'example@user.com' })
    function getUserByEmail(email: string): { id: string; department: Department } {
        // ... an implementation of user fetching
    }

    // ...
    // styles omitted for brevity
    // [!code highlight:30]
    useLangGraphInterrupt({
        handler: async ({ result, event, resolve }) => {
            const { department } = await getUserByEmail(userEmail)
            if (event.value.accessDepartment === department || department === 'admin') {
                // Following the resolution of the event, we will not proceed to the render method
                resolve({ code: 'AUTH_BY_DEPARTMENT' })
                return;
            }

            return { department, userId }
        },
        render: ({ result, event, resolve }) => (
            <div>
                <h1>Request for {event.value.type}</h1>
                <p>Members from {result.department} department cannot access this information</p>
                <p>You can request access from an administrator to continue.</p>
                <button
                    onClick={() => resolve({ code: 'REQUEST_AUTH', data: { department: result.department, userId: result.userId } })}
                >
                    Request Access
                </button>
                <button
                    onClick={() => resolve({ code: 'CANCEL' })}
                >
                    Cancel
                </button>
            </div>
        )
    });
    // ...

    return <div>{/* ... */}</div>
}
```



================================================
FILE: docs/content/docs/coagents/human-in-the-loop/meta.json
================================================
{
    "pages": [
        "interrupt-flow",
        "node-flow"
    ]
}


================================================
FILE: docs/content/docs/coagents/human-in-the-loop/node-flow.mdx
================================================
---
title: Node-based
description: Learn how to implement Human-in-the-Loop (HITL) using a node-based flow.
icon: lucide/Share2
---
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx"
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"

<Callout type="error">
    The usage of node based interrupt is [now discouraged](https://langchain-ai.github.io/langgraph/concepts/v0-human-in-the-loop/) by both LangGraph and CopilotKit.
    As of LangGraph 0.2.57, the recommended way to set breakpoints is using [the interrupt function](https://https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow) as it simplifies human-in-the-loop patterns.
</Callout>

<video src="/images/coagents/node-hitl.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

<Callout type="info">
  Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) with
  the implementation below applied!
</Callout>

## What is this?
[Node based flows](https://langchain-ai.github.io/langgraph/concepts/v0-human-in-the-loop/#dynamic-breakpoints) are predicated on LangGraph concept
of `breakpoints` which will interrupt a node before or after its execution to allow for user input.

CopilotKit allows you to add custom UI to take user input and then pass it back to the agent upon completion.

## Why should I use this?

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

Node-based flows are a great way to implement HITL for more complex workflows where you want to ensure the agent is aware
of everything that has happened during a HITL interaction. This is contrasted with interrupt-based flows, where the agent
is interrupted and then resumes execution from where it left off, unaware of the context of the interaction by default.

## Implementation

<Steps>
    <Step>
        ### Run and connect your agent
        <RunAndConnectAgentSnippet />
    </Step>
    
    <Step>
      ### Install the CopilotKit SDK
      <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Add a `useCopilotAction` to your Frontend
        First, we'll create a component that renders the agent's essay draft and waits for user approval.

        ```tsx title="ui/app/page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core"
        import { Markdown } from "@copilotkit/react-ui"

        function YourMainContent() {
          // ...

          useCopilotAction({ 
            name: "writeEssay",
            available: "remote",
            description: "Writes an essay and takes the draft as an argument.",
            parameters: [
              { name: "draft", type: "string", description: "The draft of the essay", required: true },
            ],
            // [!code highlight:25]
            renderAndWaitForResponse: ({ args, respond, status }) => {
              return (
                <div>
                  <Markdown content={args.draft || 'Preparing your draft...'} />
                  
                  <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
                    <button 
                      onClick={() => respond?.("CANCEL")}
                      disabled={status !== "executing"}
                      className="border p-2 rounded-xl w-full"
                    >
                      Try Again
                    </button>
                    <button
                      onClick={() => respond?.("SEND")}
                      disabled={status !== "executing"} 
                      className="bg-blue-500 text-white p-2 rounded-xl w-full"
                    >
                      Approve Draft
                    </button>
                  </div>
                </div>
              );
            },
          });

          // ...
        }
        ```
    </Step>

    <Step>
    ### Setup the LangGraph Agent
    Now we'll setup the LangGraph agent. Node-based flows are hard to understand without a complete example, so below
    is the complete implementation of the agent with explanations.

    Some main things to note:
    - The agent's state inherits from `CopilotKitState` to bring in the CopilotKit actions.
    - CopilotKit's actions are binded to the model as tools.
    - If the `writeEssay` action is found in the model's response, the agent will transition to the `user_feedback_node`.
    - The agent is interrupted before the `user_feedback_node` to allow for user input.

    <Tabs groupId="language" items={["Python", "TypeScript"]}>
      <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        from typing_extensions import Literal
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import SystemMessage, AIMessage
        from langchain_core.runnables import RunnableConfig
        from langgraph.graph import StateGraph, END
        from langgraph.checkpoint.memory import MemorySaver
        from langgraph.types import Command
        from copilotkit import CopilotKitState

        # 1. Define our agent's state and inherit from CopilotKitState, this brings in the CopilotKit actions
        class AgentState(CopilotKitState): # [!code highlight]
            # 1.1 Define any other state variables
            pass

        # 2. Define the chat node, this will be where the agent will talk to user and
        #    decide if it needs to call the writeEssay tool
        async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["user_feedback_node", "__end__"]]:
            # 2.1 Define the model and bind CopilotKit's actions as tools
            model = ChatOpenAI(model="gpt-4o")
            model_with_tools = model.bind_tools([*state.get("copilotkit", {}).get("actions", [])]) # [!code highlight]

            # 2.2 Define the system message
            system_message = SystemMessage(
                content="You write essays. Use your tools to write an essay, don't just write it in plain text."
            )

            # 2.3 Run the model to generate a response
            response = await model_with_tools.ainvoke([
                system_message,
                *state["messages"],
            ], config)

            # [!code highlight:6]
            # 2.4 Check for the writeEssay tool call and, if found, go  to the
            #     user_feedback_node to handle the user's response
            if isinstance(response, AIMessage) and response.tool_calls:
                if response.tool_calls[0].get("name") == "writeEssay":
                    return Command(goto="interrupt_node", update={"messages": response})

            # 2.5 If no tool call is found, end the agent
            return Command(goto=END, update={"messages": response})

        # 3. Define an empty interrupt node to act as buffer as we use the interrupt_after property
        def interrupt_node(state: AgentState, config: RunnableConfig):
          pass

        # 4. Define the user_feedback_node, this node will be interrupted before execution
        #    where CopilotKit's renderAndWaitForResponse provide the user's response.
        def user_feedback_node(state: AgentState, config: RunnableConfig) -> Command[Literal["chat_node"]]:
            # [!code highlight:4]
            # 3.1 Get the last message from the state, this will be 
            #     what is returned by respond() in the frontend
            last_message = state["messages"][-1]

            # 3.2 If the user declined the essay, ask them how they'd like to improve it
            if last_message.content != "SEND":
                return Command(goto="chat_node", update={
                    "messages": [SystemMessage(content="The user declined they essay, please ask them how they'd like to improve it")]
                })

            # 3.3 If the user approved the essay, ask them if they'd like anything else
            return Command(goto="chat_node", update={
                "messages": [SystemMessage(content="The user approved the essay, ask them if they'd like anything else")]
            })

        # 5. Configure the workflow
        workflow = StateGraph(AgentState)
        workflow.add_node("chat_node", chat_node)
        workflow.add_node("interrupt_node", interrupt_node)
        workflow.add_node("user_feedback_node", user_feedback_node)
        workflow.add_edge("interrupt_node", "user_feedback_node")
        workflow.set_entry_point("chat_node")

        # [!code highlight:3]
        # 6. Compile the workflow and set the interrupt_after property
        graph = workflow.compile(MemorySaver(), interrupt_after=["interrupt_node"])
        ```
      </Tab>
      <Tab value="TypeScript">
        ```tsx title="agent/sample_agent/agent.ts"
        import { z } from "zod";
        import { RunnableConfig } from "@langchain/core/runnables";
        import { tool } from "@langchain/core/tools";
        import { ToolNode } from "@langchain/langgraph/prebuilt";
        import { AIMessage, HumanMessage, SystemMessage, ToolMessage } from "@langchain/core/messages";
        import { Command, END, MemorySaver, START, StateGraph } from "@langchain/langgraph";
        import { Annotation } from "@langchain/langgraph";
        import { ChatOpenAI } from "@langchain/openai";

        // // 1. Import necessary helpers for CopilotKit actions
        import { convertActionsToDynamicStructuredTools } from "@copilotkit/sdk-js/langgraph";
        import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

        // 2. Define graph state, inherit from CopilotKitState to bring in CopilotKit actions
        //    and messages.
        export const AgentStateAnnotation = Annotation.Root({
            ...CopilotKitStateAnnotation.spec,
        });
        export type AgentState = typeof AgentStateAnnotation.State;

        // 3. Define the chat node, this will be the main entry point that a user interacts with
        async function chatNode(state: AgentState, config: RunnableConfig) {
          // 3.1 Define the model, lower temperature for deterministic responses
          const model = new ChatOpenAI({ temperature: 0, model: "gpt-4o" });

          // 3.2 Bind the tools to the model, include CopilotKit actions. This allows
          //     the model to call tools that are defined in CopilotKit by the frontend.
          const modelWithTools = model.bindTools!(
            [ ...convertActionsToDynamicStructuredTools(state.copilotkit?.actions || [])],
          );

          // 3.3 Define the system message, which will be used to guide the model.
          const systemMessage = new SystemMessage({
            content: `You are a helpful assistant.`,
          });

          // 3.4 Invoke the model with the system message and the messages in the state
          const response = await modelWithTools.invoke(
            [systemMessage, ...state.messages],
            config
          );

          // 3.5 Check if the response contains a tool call
          if (response.tool_calls?.length) {
            const toolCall = response.tool_calls[0];

            // 3.5.1 If the tool call is "writeEssay", we need to get feedback from the user
            //       by going to the getFeedback node which will be interrupted after
            //       execution, giving CopilotKit a chance to get feedback from the user.
            //       
            //       The "writeEssay" tool is a CopilotKit action and is binded in step 3.2.
            if (toolCall.name === "writeEssay") {
              return new Command({
                goto: "getFeedback",
                update: {
                  messages: [response],
                }
              });
            }
          }

          // 3.6 If there was no tool call, we can just update message state and end the graph
          return new Command({
            goto: END,
            update: {
              messages: [response],
            }
          });
        }

        // 4. Target node for interruption, this node will be executed and after
        //    execution the graph be interrupted, waiting for CopilotKit to get feedback
        //    from the user.
        const getFeedback = async (state: AgentState) => {
          return state;
        }

        // 5. Node for handling the feedback awaited in the getFeedback node.
        const handleFeedback = async (state: AgentState) => {
          // 5.1 Get the last message from the state
          const userResponse = state.messages[state.messages.length - 1].content

          // 5.2 Process a informative message for the AI based on the user response
          const informativeMessage = userResponse === "SEND" ? 
            "The user accepted the essay, please ask them how you can help now." : 
            "The user declined the essay, please ask them how to improve it.";

          // 5.3 Return the new state with the informative message as a system message
          //     so it doesn't appear in the chat history.
          return {
            messages: [new SystemMessage(informativeMessage)],
          }
        }

        // 6. Define the graph and compile the graph
        export const graph = new StateGraph(AgentStateAnnotation)
          .addNode("chatNode", chatNode, { ends: ["getFeedback"] })
          .addNode("getFeedback", getFeedback)
          .addNode("handleFeedback", handleFeedback)
          .addEdge("__start__", "chatNode")
          .addEdge("getFeedback", "handleFeedback")
          .addEdge("handleFeedback", "chatNode")
          .compile({
            checkpointer: new MemorySaver(),
            interruptAfter: ["getFeedback"],
          });

        ```
      </Tab>
    </Tabs>
    </Step>
    <Step>
        ### Give it a try!
        Try asking your agent to write an essay about the benefits of AI. You'll see that it will generate an essay,
        stream the progress and eventually ask you to review it.
    </Step>
</Steps>


================================================
FILE: docs/content/docs/coagents/persistence/loading-agent-state.mdx
================================================
---
title: Loading Agent State
description: Learn how threadId is used to load previous agent states.
icon: "lucide/ChartBar"
---

### Setting the threadId

When setting the `threadId` property in CopilotKit, i.e:

<Callout>
  When using LangGraph platform, the `threadId` must be a UUID.
</Callout>

```tsx
<CopilotKit threadId="2140b272-7180-410d-9526-f66210918b13">
  <YourApp />
</CopilotKit>
```

CopilotKit will restore the complete state of the thread, including the messages, from the database. (See [Message Persistence](/coagents/persistence/message-persistence) for more details.)

### Loading Agent State

This means that the state of any agent will also be restored. For example:

```tsx
const { state } = useCoAgent({name: "research_agent"});

// state will now be the state of research_agent in the thread id given above
```

### Learn More

To learn more about persistence and state in CopilotKit, see:

- [Reading agent state](/coagents/shared-state/in-app-agent-read)
- [Writing agent state](/coagents/shared-state/in-app-agent-write)
- [Loading Message History](/coagents/persistence/loading-message-history)



================================================
FILE: docs/content/docs/coagents/persistence/loading-message-history.mdx
================================================
---
title: Threads
description: Learn how to load chat messages and threads within the CopilotKit framework.
icon: "lucide/MessagesSquare"
---

LangGraph supports threads, a way to group messages together and ultimately maintain a continuous chat history. CopilotKit
provides a few different ways to interact with this concept.

This guide assumes you have already gone through the [quickstart](/quickstart) guide.

## Loading an Existing Thread

To load an existing thread in CopilotKit, you can simply set the `threadId` property on `<CopilotKit>` like so.

<Callout>
  When using LangGraph platform, the `threadId` must be a UUID.
</Callout>

```tsx
import { CopilotKit } from "@copilotkit/react-core";

<CopilotKit threadId="37aa68d0-d15b-45ae-afc1-0ba6c3e11353"> // [!code highlight]
  <YourApp />
</CopilotKit>
```

## Dynamically Switching Threads

You can also make the `threadId` dynamic. Once it is set, CopilotKit will load the previous messages for that thread.

```tsx
import { useState } from "react";
import { CopilotKit } from "@copilotkit/react-core";

const Page = () => {
  const [threadId, setThreadId] = useState("af2fa5a4-36bd-4e02-9b55-2580ab584f89"); // [!code highlight]
  return (
    <CopilotKit threadId={threadId}> // [!code highlight]
      <YourApp setThreadId={setThreadId} /> // [!code highlight]
    </CopilotKit>
  )
}

const YourApp = () => {
  return (
    <Button onClick={() => setThreadId("679e8da5-ee9b-41b1-941b-80e0cc73a008")}> // [!code highlight]
      Change Thread
    </Button>
  )
}
```

## Using setThreadId

CopilotKit will also return the current `threadId` and a `setThreadId` function from the `useCopilotContext` hook. You can use `setThreadId` to change the `threadId`.

```tsx
import { useCopilotContext } from "@copilotkit/react-core";

const ChangeThreadButton = () => {
  const { threadId, setThreadId } = useCopilotContext(); // [!code highlight]
  return (
    <Button onClick={() => setThreadId("d73c22f3-1f8e-4a93-99db-5c986068d64f")}> // [!code highlight]
      Change Thread
    </Button>
  )
}
```




================================================
FILE: docs/content/docs/coagents/persistence/message-persistence.mdx
================================================
---
title: "Message Persistence"
icon: "lucide/Database"
---

<Callout>
  To learn about how to load previous messages and agent states, check out the [Loading Message History](/coagents/persistence/loading-message-history) and [Loading Agent State](/coagents/persistence/loading-agent-state) pages.
</Callout>

To persist LangGraph messages to a database, you can use either `AsyncPostgresSaver` or `AsyncSqliteSaver`. Set up the asynchronous memory by configuring the graph within a lifespan function, as follows:

```python
from contextlib import asynccontextmanager
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver

@asynccontextmanager
async def lifespan(app: FastAPI):
    async with AsyncPostgresSaver.from_conn_string(
        "postgresql://postgres:postgres@127.0.0.1:5432/postgres"
    ) as checkpointer:
        # NOTE: you need to call .setup() the first time you're using your checkpointer
        await checkpointer.setup()
        # Create an async graph
        graph = workflow.compile(checkpointer=checkpointer)

        # Create SDK with the graph
        sdk = CopilotKitRemoteEndpoint(
            agents=[
                LangGraphAgent(
                    name="research_agent",
                    description="Research agent.",
                    graph=graph,
                ),
            ],
        )

        # Add the CopilotKit FastAPI endpoint
        add_fastapi_endpoint(app, sdk, "/copilotkit")
        yield

app = FastAPI(lifespan=lifespan)
```

To learn more about persistence in LangGraph, check out the [LangGraph documentation](https://langchain-ai.github.io/langgraph/how-tos/#persistence).


================================================
FILE: docs/content/docs/coagents/persistence/meta.json
================================================
{
    "title": "Persistence",
    "icon": "lucide/Database"
}


================================================
FILE: docs/content/docs/coagents/shared-state/in-app-agent-read.mdx
================================================
---
title: Reading agent state
icon: "lucide/ArrowLeft"
description: Read the realtime agent state in your native application.
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';

<Frame>
  <ImageZoom src="/images/coagents/read-agent-state.png" alt="read agent state" width={1000} height={1000} className="my-0"/>
</Frame>

<Callout type="info">
  Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) with
  the [implementation](#implementation) section applied!
</Callout>

## What is this?

You can easily use the realtime agent state not only in the chat UI, but also in the native application UX.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent's state. As your agent's 
state update you can reflect these updates natively in your application.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
    as this guide uses it as a starting point.
  </Step>
  <Step>
    ### Define the Agent State
    LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
    let's assume that our agent state looks something like this.

    <Tabs groupId="language" items={["Python", "TypeScript"]}>
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from copilotkit import CopilotKitState
        from typing import Literal

        class AgentState(CopilotKitState):
            language: Literal["english", "spanish"] = "spanish"

        def chat_node(state: AgentState, config: RunnableConfig):
          # If language is not defined, set a value.
          # this is because a default value in a state class is not read on runtime
          language = state.get("language", "spanish")

          # ... add the rest of the node implementation and use the language variable

          return {
            # ... add the rest of state to return
            # return the language to make it available for the next nodes & frontend to read
            "language": language
          }
        ```
      </Tab>
      <Tab value="TypeScript">
        ```ts title="agent-js/src/agent.ts"
        import { Annotation } from "@langchain/langgraph";
        import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

        export const AgentStateAnnotation = Annotation.Root({
            language: Annotation<"english" | "spanish">,
            ...CopilotKitStateAnnotation.spec,
        });
        export type AgentState = typeof AgentStateAnnotation.State;

        async function chat_node(state: AgentState, config: RunnableConfig) {
          // If language is not defined, use a default value.
          const language = state.language ?? 'spanish'

          // ... add the rest of the node implementation and use the language variable

          return {
            // ... add the rest of state to return
            // return the language to make it available for the next nodes & frontend to read
            language
          }
        }
        ```
      </Tab>
    </Tabs>
  </Step>
  <Step>
    ### Use the `useCoAgent` Hook
    With your agent connected and running all that is left is to call the [useCoAgent](/reference/hooks/useCoAgent) hook, pass the agent's name, and
    optionally provide an initial state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    function YourMainContent() {
      const { state } = useCoAgent<AgentState>({ // [!code highlight:4]
        name: "sample_agent",
        initialState: { language: "spanish" }  // optionally provide an initial state
      });

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your main content</h1>
          <p>Language: {state.language}</p> // [!code highlight]
        </div>
      );
    }
    ```
    <Callout type="info">
      The `state` in `useCoAgent` is reactive and will automatically update when the agent's state changes.
    </Callout>
  </Step>
  <Step>
    ### Give it a try!
    As the agent state updates, your `state` variable will automatically update with it! In this case, you'll see the
    language set to "spanish" as that's the initial state we set.
  </Step>
</Steps>

## Rendering agent state in the chat

You can also render the agent's state in the chat UI. This is useful for informing the user about the agent's state in a 
more in-context way. To do this, you can use the [useCoAgentStateRender](/reference/hooks/useCoAgentStateRender) hook.

```tsx title="ui/app/page.tsx"
import { useCoAgentStateRender } from "@copilotkit/react-core"; // [!code highlight]

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
}

function YourMainContent() {
  // ...
  // [!code highlight:8]
  useCoAgentStateRender({
    name: "sample_agent",
    render: ({ state }) => {
      if (!state.language) return null;
      return <div>Language: {state.language}</div>;
    },
  });
  // ...
}
```

<Callout type="info">
  The `state` in `useCoAgentStateRender` is reactive and will automatically update when the agent's state changes.
</Callout>

## Intermediately Stream and Render Agent State
By default, the LangGraph agent state will only update *between* LangGraph node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](/coagents/shared-state/predictive-state-updates).**



================================================
FILE: docs/content/docs/coagents/shared-state/in-app-agent-write.mdx
================================================
---
title: Writing agent state
icon: "lucide/ArrowRight"
description: Write to agent's state from your application.
---

<video src="/images/coagents/write-agent-state.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
  This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the previous steps applied to it!
</Callout>

## What is this?

This guide shows you how to write to your agent's state from your application.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Define the Agent State
    LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
    let's assume that our agent state looks something like this.

    <Tabs groupId="language" items={["Python", "TypeScript"]}>
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from copilotkit import CopilotKitState
        from typing import Literal

        class AgentState(CopilotKitState):
            language: Literal["english", "spanish"] = "english"
        ```
      </Tab>
      <Tab value="TypeScript">
        ```ts title="agent-js/src/agent.ts"
        import { Annotation } from "@langchain/langgraph";
        import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

        export const AgentStateAnnotation = Annotation.Root({
            language: Annotation<"english" | "spanish">,
            ...CopilotKitStateAnnotation.spec,
        });
        export type AgentState = typeof AgentStateAnnotation.State;
        ```
      </Tab>
    </Tabs>
  </Step>
  <Step>
    ### Call `setState` function from the `useCoAgent` hook
    `useCoAgent` returns a `setState` function that you can use to update the agent state. Calling this
    will update the agent state and trigger a rerender of anything that depends on the agent state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    // Example usage in a pseudo React component
    function YourMainContent() {
      const { state, setState } = useCoAgent<AgentState>({ // [!code highlight]
        name: "sample_agent",
        initialState: { language: "spanish" }  // optionally provide an initial state
      });

      // ...

      const toggleLanguage = () => {
        setState({ language: state.language === "english" ? "spanish" : "english" }); // [!code highlight]
      };

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your main content</h1>
          <p>Language: {state.language}</p> // [!code highlight:2]
          <button onClick={toggleLanguage}>Toggle Language</button>
        </div>
      );
    }
    ```
  </Step>
  <Step>
    ### Give it a try!
    You can now use the `setState` function to update the agent state and `state` to read it. Try toggling the language button
    and talking to your agent. You'll see the language change to match the agent's state.
  </Step>
</Steps>

## Advanced Usage

### Re-run the agent with a hint about what's changed

The new agent state will be used next time the agent runs.
If you want to re-run it manually, use the `run` argument on the `useCoAgent` hook.

The agent will be re-run, and it will get not only the latest updated state, but also a **hint** that can depend on the data delta between the previous and the current state.

```tsx title="ui/app/page.tsx"
import { useCoAgent } from "@copilotkit/react-core";
import { TextMessage, MessageRole } from "@copilotkit/runtime-client-gql";  // [!code highlight]

// ...

function YourMainContent() {
  const { state, setState, run } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // setup to be called when some event in the app occurs
  const toggleLanguage = () => {
    const newLanguage = state.language === "english" ? "spanish" : "english";
    setState({ language: newLanguage });

    // re-run the agent and provide a hint about what's changed
    run(({ previousState, currentState }) => { // [!code highlight:6]
      return new TextMessage({
        role: MessageRole.User,
        content: `the language has been updated to ${currentState.language}`,
      });
    });
  };

  return (
    // ...
  );
}
```

### Intermediately Stream and Render Agent State
By default, the LangGraph agent state will only update *between* LangGraph node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](/coagents/shared-state/intermediate-state-streaming).**



================================================
FILE: docs/content/docs/coagents/shared-state/index.mdx
================================================
---
title: Shared State
description: Create a two-way connection between your UI and agent state.
icon: "lucide/Repeat"
---
import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<ImageZoom 
    src="/images/coagents/SharedStateCoAgents.gif" 
    alt="Shared State Demo" 
    width={1000} 
    height={1000} 
    className="rounded-lg shadow-lg border mt-0"
/>

<Callout>
    This video demonstrates the [Research Canvas](/coagents/examples/research-canvas) utilizing shared state.
</Callout>


## What is shared state?

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:
- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

<Frame>
    <img src="/images/coagents/coagents-state-diagram.png" alt="Agentic Copilot State Diagram" />
</Frame>

The foundation of this system is built on LangGraph's stateful architecture. Unlike traditional LangChains, LangGraphs maintain their
internal state throughout execution, which you can access via the `useCoAgentState` hook.

## When should I use this?
State streaming is perfect when you want to faciliate collaboration between your agent and the user. Any state that your LangGraph agent
persists will be automatically shared by the UI. Similarly, any state that the user updates in the UI will be automatically reflected

This allows for a consistent experience where both the agent and the user are on the same page.




================================================
FILE: docs/content/docs/coagents/shared-state/meta.json
================================================
{
    "pages": [
        "in-app-agent-read",
        "in-app-agent-write",
        "state-inputs-outputs",
        "predictive-state-updates"
    ]
}


================================================
FILE: docs/content/docs/coagents/shared-state/predictive-state-updates.mdx
================================================
---
title: "Predictive state updates"
icon: "lucide/Podcast"
description: Stream in-progress agent state updates to the frontend.
---
import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import InstallSDKSnippet from "@/snippets/install-sdk.mdx"
import { FaWrench } from "react-icons/fa";
import { FaArrowUp } from "react-icons/fa";

<video src="/images/coagents/intermediate-state-render.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />
<Callout>
  This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

A LangGraph agent's state updates discontinuosly; only across node transitions in the graph.
But even a _single node_ in the graph often takes many seconds to run and contain sub-steps of interest to the user.

**Agent-native applications** reflect to the end-user what the agent is doing **as continuously possible.**

CopilotKit enables this through its concept of **_predictive state updates_**.


## When should I use this?
You can use this when you want to provide the user with feedback about what your agent is doing, specifically to:

- **Keep users engaged** by avoiding long loading indicators
- **Build trust** by demonstrating what the agent is working on
- Enable **agent steering** - allowing users to course-correct the agent if needed

## Important Note

When a node in your LangGraph finishes executing, **its returned state becomes the single source of truth**. While intermediate state updates are great for real-time feedback, any changes you want to persist must be explicitly included in the node's final returned state. Otherwise, they will be overwritten when the node completes.


## Implementation

<Steps>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Define the state
        We'll be defining a `observed_steps` field in the state, which will be updated as the agent writes different sections of the report.

        <Tabs groupId="language" items={["Python", "TypeScript"]}>
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                from copilotkit import CopilotKitState
                from typing import Literal

                class AgentState(CopilotKitState):
                    observed_steps: list[str]  # Array of completed steps
                ```
            </Tab>
            <Tab value="TypeScript">
                ```ts title="agent-js/src/agent.ts"
                import { Annotation } from "@langchain/langgraph";
                import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

                export const AgentStateAnnotation = Annotation.Root({
                    observed_steps: Annotation<string[]>,  // Array of completed steps
                    ...CopilotKitStateAnnotation.spec,
                });
                export type AgentState = typeof AgentStateAnnotation.State;
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Emit the intermediate state
        <TailoredContent
            id="state-emission"
            header={
                <div>
                    <p className="text-xl font-semibold">How would you like to emit state updates?</p>
                    <p className="text-base">
                        You can either manually emit state updates or configure specific tool calls to emit updates.
                    </p>
                </div>
            }
        >
            <TailoredContentOption
                id="manual-emission"
                title="Manual Predictive State Updates"
                description="Manually emit state updates for maximum control over when updates occur."
                icon={<FaArrowUp />}
            >
                For long-running tasks, you can emit state updates progressively as predictions of the final state. In this example, we simulate a long-running task by executing a series of steps with a one second delay between each update.
                <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
                    <Tab value="Python">
                        ```python title="agent-py/sample_agent/agent.py"
                        from copilotkit.langgraph import copilotkit_emit_state # [!code highlight]
                        # ...
                        async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["cpk_action_node", "tool_node", "__end__"]]:
                            # ...

                            # Simulate executing steps one by one
                            steps = [
                                "Analyzing input data...",
                                "Identifying key patterns...",
                                "Generating recommendations...",
                                "Formatting final output..."
                            ]
                            
                            for step in steps:
                                self.state["observed_steps"] = self.state.get("observed_steps", []) + [step]
                                await copilotkit_emit_state(config, state) # [!code highlight]
                                await asyncio.sleep(1)

                            # ...
                        ```
                    </Tab>
                    <Tab value="TypeScript">
                        ```ts title="agent-js/src/agent.ts"
                        import { copilotkitEmitState } from "@copilotkit/sdk-js/langgraph"; // [!code highlight]
                        // ...
                        async function chat_node(state: AgentState, config: RunnableConfig) {
                            // ...

                            // Simulate executing steps one by one
                            const steps = [
                                "Analyzing input data...",
                                "Identifying key patterns...",
                                "Generating recommendations...",
                                "Formatting final output..."
                            ];
                            
                            for (const step of steps) {
                                state.observed_steps = [...(state.observed_steps ?? []), step];
                                copilotkitEmitState(config, state);
                                await new Promise(resolve => setTimeout(resolve, 1000));
                            }
                        }
                        ```
                    </Tab>
                </Tabs>
            </TailoredContentOption>

            <TailoredContentOption
                id="tool-emission"
                title="Tool-Based Predictive State Updates" 
                description="Configure specific tool calls to automatically emit intermediate state updates."
                icon={<FaWrench />}
            >
                For long-running tasks, you can configure CopilotKit to automatically predict state updates when specific tool calls are made. In this example, we'll configure CopilotKit to predict state updates whenever the LLM calls the step progress tool.
                <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
                    <Tab value="Python">
                        ```python
                        from copilotkit.langgraph import copilotkit_customize_config
                        from copilotkit import CopilotKitState
                        from langgraph.types import Command
                        from langgraph.graph import END
                        from langchain.tools import tool
                        from langchain_openai import ChatOpenAI
                        from langchain_core.messages import SystemMessage, AIMessage
                        from langchain_core.runnables import RunnableConfig

                        # Define a step progress tool for the llm to report the steps
                        @tool
                        def step_progress_tool(steps: list[str])
                            """Reads and reports steps"""

                        async def frontend_actions_node(state: AgentState, config: RunnableConfig):
                            # Configure CopilotKit to treat step progress tool calls as predictive of the final state
                            config = copilotkit_customize_config(
                                config,
                                emit_intermediate_state=[
                                    {
                                        "state_key": "observed_steps",
                                        "tool": "step_progress_tool",
                                        "tool_argument": "steps"
                                    },
                                ]
                            )

                            system_message = SystemMessage(
                                content=f"You are a task performer. Pretend doing tasks you are given, report the steps using step_progress_tool."
                            )

                            # Provide the actions to the LLM
                            model = ChatOpenAI(model="gpt-4").bind_tools(
                                [
                                    *state["copilotkit"]["actions"],
                                    step_progress_tool
                                    # your other tools here
                                ],
                            )

                            # Call the model with CopilotKit's modified config
                            response = await model.ainvoke([
                                system_message,
                                *state["messages"],
                            ], config)

                            # Set the steps in state so they are persisted and communicated to the frontend
                            if isinstance(response, AIMessage) and response.tool_calls and response.tool_calls[0].get("name") == 'step_progress_tool':
                                return Command(
                                    goto=END,
                                    update={
                                        "messages": response,
                                        "observed_steps": response.tool_calls[0].get("args", None).get('steps')
                                    }
                                )

                            return Command(goto=END, update={"messages": response})
                        ```
                    </Tab>
                    <Tab value="TypeScript">
                        ```typescript
                        import { copilotkitCustomizeConfig } from '@copilotkit/sdk-js/langgraph';

                        async function frontendActionsNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
                            const modifiedConfig = copilotkitCustomizeConfig(config, {
                                emitIntermediateState: [
                                {
                                    stateKey: "observed_steps",
                                    tool: "StepProgressTool",
                                    toolArgument: "steps",
                                },
                                ],
                            });

                            const stepProgress = tool(
                                async (args) => args,
                                {
                                    name: "StepProgressTool",
                                    description: "Records progress by updating the steps array",
                                    schema: z.object({
                                        steps: z.array(z.string()),
                                    }),
                                }
                            );

                            const model = new ChatOpenAI({
                                model: "gpt-4o",
                            }).bindTools([stepProgress]);

                            const system_message = new SystemMessage("You are a task performer. Pretend doing tasks you are given, report the steps using StepProgressTool.")
                            const response = await model.invoke([system_message, ...state.messages], modifiedConfig);


                            if (response.tool_calls?.length) {
                                return {
                                    messages: response;
                                    observed_steps: response.tool_calls[0].args.steps,
                                }

                            return { messages: response };
                        }
                        ```
                    </Tab>
                </Tabs>
            </TailoredContentOption>
        </TailoredContent>
    </Step>
    <Step>
        ### Observe the predictions
        These predictions will be emitted as the agent runs, allowing you to track its progress before the final state is determined.

        ```tsx title="ui/app/page.tsx"
        import { useCoAgent, useCoAgentStateRender } from '@copilotkit/react-core';

        // ...
        type AgentState = {
            observed_steps: string[];
        };
        
        const YourMainContent = () => {
            // Get access to both predicted and final states
            const { state } = useCoAgent<AgentState>({ name: "sample_agent" });

            // Add a state renderer to observe predictions
            useCoAgentStateRender({
                name: "sample_agent",
                render: ({ state }) => {
                    if (!state.observed_steps?.length) return null;
                    return (
                        <div>
                            <h3>Current Progress:</h3>
                            <ul>
                                {state.observed_steps.map((step, i) => (
                                    <li key={i}>{step}</li>
                                ))}
                            </ul>
                        </div>
                    );
                },
            });

            return (
                <div>
                    <h1>Agent Progress</h1>
                    {state.observed_steps?.length > 0 && (
                        <div>
                            <h3>Final Steps:</h3>
                            <ul>
                                {state.observed_steps.map((step, i) => (
                                    <li key={i}>{step}</li>
                                ))}
                            </ul>
                        </div>
                    )}
                </div>
            )
        }
        ```
    </Step>
    <Step>
        ### Give it a try!
        Now you'll notice that the state predictions are emitted as the agent makes progress, giving you insight into its work before the final state is determined.
        You can apply this pattern to any long-running task in your agent.
    </Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/shared-state/state-inputs-outputs.mdx
================================================
---
title: Agent state inputs and outputs
icon: "lucide/ArrowRightLeft"
description: Decide which state properties are received and returned to the frontend
---

## What is this?

Not all state properties are relevant for frontend-backend sharing.
This guide shows how to ensure only the right portion of state is communicated back and forth.

This guide is based on [LangGraph's Input/Output Schema feature](https://langchain-ai.github.io/langgraph/how-tos/input_output_schema/)

## When should I use this?

Depending on your implementation, some properties are meant to be processed internally, while some others are the way for the UI to communicate user input.
In addition, some state properties contain a lot of information. Syncing them back and forth between the agent and UI can be costly, while it might not have any practical benefit.

## Implementation

<Steps>
  <Step>
      ### Examine our old state
      LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
      let's assume that the state our agent should be using, can be described like this:
      <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
        <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from copilotkit import CopilotKitState
        from typing import Literal

        class AgentState(CopilotKitState):
            question: str
            answer: str
            resources: List[str]
        ```
        </Tab>
        <Tab value="TypeScript">
        ```typescript title="agent-js/sample_agent/agent.ts"
        import { Annotation } from "@langchain/langgraph";
        import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

        const AgentState = Annotation.Root({
          ...CopilotKitStateAnnotation.spec,
          question: Annotation<string>,
          answer: Annotation<string>,
          resources: Annotation<string[]>,
        })
        ```
        </Tab>
    </Tabs>
  </Step>
  <Step>
    ### Divide state to Input and Output
    Our example case lists several state properties, which with its own purpose:
      - The question is being asked by the user, expecting the llm to answer
      - The answer is what the LLM returns
      - The resources list will be used by the LLM to answer the question, and should not be communicated to the user, or set by them.

      <Tabs groupId="language" items={['Python', 'TypeScript']} default="Python">
          <Tab value="Python">
          ```python title="agent-py/sample_agent/agent.py"
          from copilotkit import CopilotKitState
          from typing import Literal

          # Divide the state to 3 parts

          # Input schema for inputs you are willing to accept from the frontend
          class InputState(CopilotKitState):
            question: str

          # Output schema for output you are willing to pass to the frontend
          class OutputState(CopilotKitState):
            answer: str

          # The full schema, including the inputs, outputs and internal state ("resources" in our case)
          class OverallState(InputState, OutputState):
            resources: List[str]

          async def answer_node(state: OverallState, config: RunnableConfig):
            """
            Standard chat node, meant to answer general questions.
            """

            model = ChatOpenAI()

            # add the input question in the system prompt so it's passed to the LLM
            system_message = SystemMessage(
              content=f"You are a helpful assistant. Answer the question: {state.get('question')}"
            )

            response = await model.ainvoke([
              system_message,
              *state["messages"],
            ], config)

            # ...add the rest of the agent implementation

            # extract the answer, which will be assigned to the state soon
            answer = response.content

            return {
               "messages": response,
                # include the answer in the returned state
               "answer": answer
            }


          # finally, before compiling the graph, we define the 3 state components
          builder = StateGraph(OverallState, input=InputState, output=OutputState)

          # add all the different nodes and edges and compile the graph
          builder.add_node("answer_node", answer_node)
          builder.add_edge(START, "answer_node")
          builder.add_edge("answer_node", END)
          graph = builder.compile()
          ```
          </Tab>
          <Tab value="TypeScript">
            <Callout type="warn">
              While we work on adding Zod schema support for LangGraph TypeScript, a workaround is required to ignore a typescript error when defining "full state".

              You can see this at the very end of the TypeScript implementation snippet.
            </Callout>
            ```typescript title="agent-js/sample_agent/agent.ts"
              import { Annotation } from "@langchain/langgraph";
              import { CopilotKitStateAnnotation } from "@copilotkit/sdk-js/langgraph";

              // Divide the state to 3 parts

              // An input schema for inputs you are willing to accept from the frontend
              const InputAnnotation = Annotation.Root({
                ...CopilotKitStateAnnotation.spec,
                question: Annotation<string>,
              });

              // Output schema for output you are willing to pass to the frontend
              const OutputAnnotation = Annotation.Root({
                ...CopilotKitStateAnnotation.spec,
                answer: Annotation<string>,
              });

              // The full schema, including the inputs, outputs and internal state ("resources" in our case)
              export const AgentStateAnnotation = Annotation.Root({
                ...CopilotKitStateAnnotation.spec,
                ...OutputAnnotation.spec,
                ...InputAnnotation.spec,
                resources: Annotation<string[]>,
              });

              // Define a typed state that supports the entire
              export type AgentState = typeof AgentStateAnnotation.State;

              async function answerNode(state: AgentState, config: RunnableConfig) {
                const model = new ChatOpenAI()

                const systemMessage = new SystemMessage({
                  content: `You are a helpful assistant. Answer the question: ${state.question}.`,
                });

                const response = await modelWithTools.invoke(
                  [systemMessage, ...state.messages],
                  config
                );

                // ...add the rest of the agent implementation
                // extract the answer, which will be assigned to the state soon
                const answer = response.content

                return {
                  messages: response,
                  // include the answer in the returned state
                  answer,
                }
              }

              // finally, before compiling the graph, we define the 3 state components
              const workflow = new StateGraph({
                input: InputAnnotation,
                output: OutputAnnotation,
                // @ts-expect-error -- LangGraph does not expect a "full schema with internal properties".
                stateSchema: AgentStateAnnotation,
              })
                .addNode("answer_node", answerNode) // add all the different nodes and edges and compile the graph
                .addEdge(START, "answer_node")
                .addEdge("answer_node", END)
              export const graph = workflow.compile()
            ```
          </Tab>
      </Tabs>
  </Step>
  <Step>
    ### Give it a try!
    Now that we know which state properties our agent emits, we can inspect the state and expect the following to happen:
    - While we are able to provide a question, we will not receive it back from the agent. If we are using it in our UI, we need to remember the UI is the source of truth for it
    - Answer will change once it's returned back from the agent
    - The UI has no access to resources.

    ```tsx
    import { useCoAgent } from "@copilotkit/react-core";

    type AgentState = {
      question: string;
      answer: string;
    }

    const { state } = useCoAgent<AgentState>({
      name: "sample_agent",
      initialState: {
        question: "How's is the weather in SF?",
      }
    });

    console.log(state) // You can expect seeing "answer" change, while the others are not returned from the agent
    ```
  </Step>
</Steps>



================================================
FILE: docs/content/docs/coagents/troubleshooting/common-issues.mdx
================================================
---
title: Common Issues
description: Common issues you may encounter when using CoAgents.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

Welcome to the CoAgents Troubleshooting Guide! If you're having trouble getting tool calls to work, you've come to the right place.

<Callout>
    Have an issue not listed here? Open a ticket on [GitHub](https://github.com/CopilotKit/CopilotKit/issues) or reach out on [Discord](https://discord.com/invite/6dffbvGU3D)
    and we'll be happy to help.

    We also highly encourage any open source contributors that want to add their own troubleshooting issues to [Github as a pull request](https://github.com/CopilotKit/CopilotKit/blob/main/CONTRIBUTING.md).

</Callout>

## My tool calls are not being streamed

This could be due to a few different reasons.

First, we strongly recommend checking out our [Human In the Loop](/coagents/human-in-the-loop) guide to follow a more in depth example of how to stream tool calls
in your LangGraph agents. You can also check out our [travel tutorial](/coagents/tutorials/ai-travel-app/step-6-human-in-the-loop) which talks about how to stream
tool calls in a more complex example.

If you have already done that, you can check the following:

<Accordions>
    <Accordion title="You have not specified the tool call in the `copilotkit_customize_config`">
        In your LangGraph agent, you have must specify which tool calls will be emitted to the CopilotKit runtime. By default,
        only streamed messages are emitted. You can fix this by adding the following to the node making the tool call.

        ```python
        from copilotkit.langgraph import copilotkit_customize_config, copilotkit_emit_message
        from langgraph_core.runnables import RunnableConfig
        from langchain.tools import tool

        @tool
        def say_hello_to(name: str) -> str:
            return f"Hello, {name}!"

        async def my_node(state: State, config: RunnableConfig) -> State:
            # ...
            config = copilotkit_customize_config(config, emit_tool_calls=["say_hello_to"]) # [code highlight]
            # ...
            return state
        ```
    </Accordion>
    <Accordion title="You're using llm.invoke() instead of llm.ainvoke()">
        <p>
            When you invoke your LangGraph agent, you can invoke it synchronously or asynchronously. If you invoke it synchronously,
            the tool calls will not be streamed progressively, only the final result will be streamed. If you invoke it asynchronously,
            the tool calls will be streamed progressively.

            ```python
            config = copilotkit_customize_config(config, emit_tool_calls=["say_hello_to"])
            response = await llm_with_tools.ainvoke(
                [ SystemMessage(content=system_message), *state["messages"] ],
                config=config
            )
            ```
        </p>
    </Accordion>

</Accordions>

## Error: `'AzureOpenAI' object has no attribute 'bind_tools'`

This error is typically due to the use of an incorrect import from LangGraph. Instead of importing `AzureOpenAI` import `AzureChatOpenAI` and your
issue will be resolved.

```python
from langchain_openai import AzureOpenAI # [!code --]
from langchain_openai import AzureChatOpenAI # [!code ++]
```

## I am getting "agent not found" error

If you're seeing this error, it means CopilotKit couldn't find the LangGraph agent you're trying to use. Here's how to fix it:

<Accordions>
    <Accordion title="Verify your agent lock mode configuration">
        If you're using [agent lock mode](/coagents/multi-agent-flows),
        check that the agent defined in `langgraph.json` matches what's defined in the CopilotKit provider:

        ```json title="langgraph.json"
        {
            "python_version": "3.12",
            "dockerfile_lines": [],
            "dependencies": ["."],
            "graphs": {
                "my_agent": "./src/agent.py:graph"// In this case, "my_agent" is the agent you're using // [!code highlight]
            },
            "env": ".env"
        }
        ```

        ```tsx title="layout.tsx"
        <CopilotKit agent="my_agent"> // [!code highlight]
            {/* Your application components */}
        </CopilotKit>
        ```

        Common issues:
        - Typos in agent names
        - Case sensitivity mismatches
        - Missing entries in `langgraph.json`
    </Accordion>
    <Accordion title="Check your agent registration on a LangGraph Platform endpoint">
        When using LangGraph Platform endpoint, make sure your agents are properly specified and are following the definition in your `langgraph.json`:

        ```json title="langgraph.json"
        {
            "python_version": "3.12",
            "dockerfile_lines": [],
            "dependencies": ["."],
            "graphs": {
                "my_agent": "./src/agent.py:graph"// In this case, "my_agent" is the agent you're using // [!code highlight]
            },
            "env": ".env"
        }
        ```

        ```typescript title="/copilotkit/api/route.ts"
        langGraphPlatformEndpoint({
            deploymentUrl,
            langsmithApiKey,
            agents: [
                {
                    name: "my_agent",
                    description: "A helpful agent",
                },
            ],
        })
        ```
    </Accordion>
    <Accordion title="Check your agent name in useCoAgent">
        Make sure the that the agent defined in `langgraph.json` matches what you use n `useCoAgent` hook:

        ```json title="langgraph.json"
        {
            "python_version": "3.12",
            "dockerfile_lines": [],
            "dependencies": ["."],
            "graphs": {
                "my_agent": "./src/agent.py:graph"// In this case, "my_agent" is the agent you're using // [!code highlight]
            },
            "env": ".env"
        }
        ```

        ```tsx title="MyComponent.tsx"
        // Your React component
        useCoAgent({
            name: "my_agent", // [!code focus] This must match exactly
        });
        ```
    </Accordion>
    <Accordion title="Check your agent name in useCoAgentStateRender">
        Make sure the that the agent defined in `langgraph.json` matches what you use n `useCoAgent` hook:

        ```json title="langgraph.json"
        {
            "python_version": "3.12",
            "dockerfile_lines": [],
            "dependencies": ["."],
            "graphs": {
                "my_agent": "./src/agent.py:graph"// In this case, "my_agent" is the agent you're using // [!code highlight]
            },
            "env": ".env"
        }
        ```

        ```tsx title="MyComponent.tsx"
        // Your React component
        useCoAgentStateRender({
            name: "my_agent", // [!code focus] This must match exactly
        });
        ```
    </Accordion>

</Accordions>

## Connection issues with tunnel creation

If you notice the tunnel creation process spinning indefinitely, your router or ISP might be blocking the connection to CopilotKit's tunnel service.

<Accordions>
    <Accordion title="Router or ISP blocking tunnel connections">
        To verify connectivity to the tunnel service, try these commands:

        ```bash
        ping tunnels.devcopilotkit.com
        curl -I https://tunnels.devcopilotkit.com
        telnet tunnels.devcopilotkit.com 443
        ```

        If these fail, your router's security features or ISP might be blocking the connection. Common solutions:
        - Check router security settings
        - Consider checking with your ISP about any connection restrictions
        - Try using a mobile hotspot
    </Accordion>

</Accordions>

## I am getting "Failed to find or contact remote endpoint at url, Make sure the API is running and that it's indeed a LangGraph platform url" error

If you're seeing this error, it means the LangGraph platform client cannot connect to your endpoint.

<Accordions>
    <Accordion title="Verify the endpoint is reachable">
        Check the logs for the backend API running on the remote endpoint url. Make sure it is up and ready to receive requests
    </Accordion>
    <Accordion title="Verify running a LangGraph platform endpoint using LangGraph deployment tools">
        Verify that the backend API is running using `langgraph dev`, `langgraph up`, on a LangGraph cloud url or equivalent methods supplied by LangGraph
    </Accordion>
    <Accordion title="Verify the remote endpoint matches the endpoint definition type">
        If you are running your remote endpoint using FastAPI, even if it uses LangGraph for the agent, it is not considered a LangGraph platform endpoint.
        You may need to change your `remoteEndpoints` definition for this endpoint to match the expected format.

        Change the endpoint definition, from:
        ```
        new CopilotRuntime({
          remoteEndpoints: [
            langGraphPlatformEndpoint({
            deploymentUrl: "https://your-fastapi-endpoint:port",
            langsmithApiKey: <langsmith API key>
            agents: [], // Your previous agents definition
          ],
        });
        ```

        To:
        ```
        new CopilotRuntime({
          remoteEndpoints: [
            copilotKitEndpoint({ url: "https://your-fastapi-endpoint:port/copilotkit" });
          ]
        });
        ```
    </Accordion>
</Accordions>

## I am getting a "No checkpointer set" error when using LangGraph with FastAPI

If you're encountering this error, it means you are missing a checkpointer in your compiled graph.
You can visit the [LangGraph Persistence guide](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) to understand what a checkpointer is and how to add it.

## I see messages being streamed and disappear

LangGraph agents are stateful. As a graph is traversed, the state is saved at the end of each node. CopilotKit uses the agent's state as
the source of truth for what to display in the frontend chat. However, since state is only emitted at the end of a node,  CopilotKit allows
you to stream predictive state updates *in the middle of a node*. By default, CopilotKit will stream messages and tool calls being actively
generated to the frontend chat that initiated the interaction. **If this predictive state is not persisted at the end of the node, it will 
disappear in the frontend chat**.

In this situation, the most likely scenario is that the `messages` property in the state is being updated in the middle of a node but those edits are not being
persisted at the end of a node. 

<img src="/images/coagents/message-state-diagram.png" />

<Accordions>
    <Accordion title="I want these messages to be persisted">
        To fix this, you can simply persist the messages by returning the new messages at the end of the node.

         <Tabs groupId="language" items={["Python", "TypeScript"]}>
            <Tab value="Python">
                ```python
                from copilotkit.langgraph import copilotkit_customize_config
 
                async def chat_node(state: AgentState, config: RunnableConfig):
                    # 1) Call the model with CopilotKit's modified config
                    model = ChatOpenAI(model="gpt-4o")
                    response = await model.ainvoke(state["messages"], modifiedConfig) 
                
                    # 2) Make sure to return the new messages
                    return {
                        messages: response,
                    }
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript
                import { copilotkitCustomizeConfig } from '@copilotkit/sdk-js/langgraph';
 
                async function chatNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
                    // 1) Call the model with CopilotKit's modified config
                    const model = new ChatOpenAI({ temperature: 0, model: "gpt-4o" });
                    const response = await model.invoke(state.messages, modifiedConfig);
                
                    // 2) Make sure to return the new messages
                    return {
                        messages: response,
                    }
                }
                ```
            </Tab>
        </Tabs>
    </Accordion>
    <Accordion title="I don't want these messages to streamed at all">
        In this case, you can reference our document on [disabling streaming](/coagents/advanced/disabling-state-streaming). More specifically,
        you can use the copilotkit config to disable emitting messages anywhere you'd like a message to not be streamed.

        <Tabs groupId="language" items={["Python", "TypeScript"]}>
            <Tab value="Python">
                ```python
                from copilotkit.langgraph import copilotkit_customize_config
 
                async def chat_node(state: AgentState, config: RunnableConfig):
                    # 1) Configure CopilotKit not to emit messages
                    modifiedConfig = copilotkit_customize_config(
                        config,
                        emit_messages=False, # if you want to disable message streaming
                    )
                
                    # 2) Call the model with CopilotKit's modified config
                    model = ChatOpenAI(model="gpt-4o")
                    response = await model.ainvoke(state["messages"], modifiedConfig) 
                
                    # 3) Don't return the new response to hide it from the user
                    return state
                ```
            </Tab>
            <Tab value="TypeScript">
                ```typescript
                import { copilotkitCustomizeConfig } from '@copilotkit/sdk-js/langgraph';
 
                async function chatNode(state: AgentState, config: RunnableConfig): Promise<AgentState> {
                    // 1) Configure CopilotKit not to emit messages
                    const modifiedConfig = copilotkitCustomizeConfig(config, {
                        emitMessages: false, // if you want to disable message streaming
                    });
                
                    // 2) Call the model with CopilotKit's modified config
                    const model = new ChatOpenAI({ temperature: 0, model: "gpt-4o" });
                    const response = await model.invoke(state.messages, modifiedConfig);
                
                    // 3) Don't return the new response to hide it from the user
                    return state;
                }
                ```
            </Tab>
        </Tabs>

        <Callout title="Running a subgraph or langchain?">
            Just make sure to pass the modified config we defined above as your `RunnableConfig` for the subgraph or langchain!
        </Callout>
    </Accordion>
</Accordions>






================================================
FILE: docs/content/docs/coagents/troubleshooting/migrate-from-v0.2-to-v0.3.mdx
================================================
---
title: Migrate from v0.2 to v0.3
description: How to migrate from v0.2 to v0.3.
---

## What's new in v0.3?

Starting with `v0.3`, we changed how messages are synced between the agent (LangGraph) and CopilotKit. Essentially, both will now share exactly the same message history.

This means that you need to return the messages you want to appear in CopilotKit chat from your LangGraph nodes, for example:

```python
def my_node(state: State, config: RunnableConfig) -> State:
    response = # ... llm call ...
    return {
        "messages": response,
    }
```

All tool messages are now emitted by default, so you don't need to manually call `copilotkit_customize_config` to configure tool call emissions.

<Frame>
    <img src="/images/coagents-v-0-3-migration-image.png" />
</Frame>

## How do I migrate?

1. Make sure to return any messages (tool calls or text messages) you want to be part of the message history from your LangGraph nodes.

2. Optionally, remove manual `copilotkit_customize_config` calls when you want to emit tool calls.

3. If you want to hide tool calls or messages from the chat, use `copilotkit_customize_config` and set `emit_tool_calls` or `emit_messages` to `False`. Make sure to not return these messages in your nodes so they don't become part of the message history.



================================================
FILE: docs/content/docs/coagents/tutorials/meta.json
================================================
{
    "title": "coagents",
    "root": true,
    "pages": [
      "agent-native-app",
      "ai-travel-app"
    ]
  }


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/index.mdx
================================================
---
title: Overview
icon: "lucide/Bot"
---
import { YouTubeVideo } from "@/components/react/youtube-video";
import { FaGithub } from "react-icons/fa";
import { PiMonitor } from "react-icons/pi";
import { Button } from "@/components/ui/button";
import Link from "next/link";

# Research Agent Native Application (ANA)

<div>
  <div>**Time to complete:** 15 minutes</div>
  <div>**Difficulty:** Medium</div>
</div>

<video src="/images/coagents/tutorials/research-ana/final-results.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

<div className="flex flex-row gap-2">
  <Button size="lg" asChild className="flex gap-2 items-center">
    <Link href="https://github.com/CopilotKit/open-research-ANA" className="no-underline" target="_blank">
      <FaGithub className="w-6 h-6 mr-2" />
      <span>View on GitHub</span>
    </Link>
  </Button>

  <Button size="lg" asChild className="flex gap-2 items-center">
    <Link href="https://open-research-ana.vercel.app/" className="no-underline" target="_blank">
      <PiMonitor className="w-6 h-6 mr-2" />
      <span>View live app</span>
    </Link>
  </Button>
</div>

<br />

## What you'll learn

In this tutorial, we'll build a Research Agent Native Application (ANA) using CopilotKit. Starting with a basic application, we'll add agent capabilities step by step.

You'll learn:
- 🎯 Core principles of agent native applications
- 🔄 How LangGraph helps structure LLM behavior
- 🧱 Building blocks of a Copilot Agent (CoAgent)
- 🛠️ Creating interactive agent experiences with CopilotKit

## Let's get started!
Next, we'll set up the project and install dependencies.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/meta.json
================================================
{
  "title": "Tutorial: Research ANA",
  "pages": [
    "step-1-checkout-repo",
    "step-2-start-the-agent",
    "step-3-setup-copilotkit",
    "step-4-agentic-chat-ui",
    "step-5-human-in-the-loop",
    "step-6-shared-state",
    "step-7-generative-ui",
    "step-8-progressive-state-updates",
    "next-steps"
  ]
}


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/next-steps.mdx
================================================
---
title: "Next Steps"
---

This is the end of the tutorial. You now know the basics of how to build complex agentic experiences into your own applications.

## Source code

You can find the source code and interactive sandboxes here:
- [Start app](https://github.com/CopilotKit/open-research-ANA/tree/tutorial-start)
- [Final app](https://github.com/CopilotKit/open-research-ANA/tree/main)

## What's next?

For next steps, here are some ideas:

- Add persistence for [messages](/coagents/persistence/loading-message-history) and [agent state](/coagents/persistence/loading-agent-state).
- Enhance the back-and-fourth with the agent by adding more tools that can update the agent's state.
- Allow the human to ask for inline editing of the research report.

We have more tutorials coming soon, please let us know if you have any ideas for what you'd like to see next!

## Need help?

If you have any questions, feel free to reach out to us on [Discord](https://discord.gg/6dffbvGU3D).



================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-1-checkout-repo.mdx
================================================
---
title: "Step 1: Checkout the repo"
---

<Steps>
<Step>
## Get the starting code
We'll use the [open-research-ana repository](https://github.com/CopilotKit/open-research-ana) as our starting point. Clone the `tutorial-start` branch:

```shell
git clone -b tutorial-start https://github.com/CopilotKit/open-research-ana.git
cd open-research-ana
```

The repository contains:
- `frontend/`: A NextJS application where we'll integrate our agent
- `agent/`: A Python-based LangGraph agent we'll enhance with CopilotKit

</Step>
<Step>
## Install frontend dependencies
Navigate to the frontend directory and install dependencies:

```shell
cd frontend
pnpm install
```
</Step>
<Step>
## Start the application
Launch the development server:

```shell
pnpm run dev
```

Visit [http://localhost:3000](http://localhost:3000) to see the initial application. You'll see an empty chat interface and document - this is our starting point.
</Step>
</Steps>

Next, we'll explore how our LangGraph agent works.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-2-start-the-agent.mdx
================================================
---
title: "Step 2: Start the Agent"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom'

Before we start integrating the LangGraph agent, let's understand how it works. 

For the sake of this tutorial we won't be building the LangGraph together from scratch. 
Instead, we'll be using the LangGraph constructed in the `agent/` directory. It will 
contain all of the logic we need to build our research ANA except for the CopilotKit
features, which we'll add together.

<Callout>
If you're interested in a step-by-step guide for building a LangGraph agent, you can checkout the 
[LangGraph quickstart guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/).
</Callout>

Let's walk through the LangGraph agent to understand how it works before we integrate it into the application.

<Steps>
<Step>
### Get API keys
You'll need two API keys:
- [OpenAI API key](https://platform.openai.com/api-keys)
- [Tavily API key](https://tavily.com/)

</Step>
<Step>
### Setup the `.env` file
Create and configure the agent's environment:

```shell
cd agent
touch .env
```

Add your API keys:
```txt title=".env"
OPENAI_API_KEY=<your-openai-api-key>
TAVILY_API_KEY=<your-tavily-api-key>
```

</Step>
<Step>
### Start the agent
Install and run the LangGraph CLI:

```shell
pip install -r requirements.txt # Install dependencies
brew install langgraph-cli # Install LangGraph CLI
langgraph dev --host localhost --port 8000 # Start the agent
```

This opens LangGraph Studio in your brwoser where you can visualize and interact with your agent.

<Callout>
The agent will be available at https://localhost:8000 for later steps.
</Callout>

<ImageZoom src="/images/coagents/tutorials/research-ana/lgs-overview.png" height={1000} width={1000} className="rounded-lg shadow-lg"/>

</Step>
<Step>

### Understanding the LangGraph Agent

As we're building this agent into an agentic experience, we'll want to understand how it works. The key concepts at play here are:

- **State**: The state is the data that the agent is using to make and communicate its decisions. You can see all of the state variables in the bottom left of the screen. **State will only update between node transitions.**
- **Nodes**: Nodes are the building blocks of a LangGraph agent. They are the steps that the agent will take to complete a task. In this case, we have nodes for the **agent**, **tools** and **human input** and **processing feedback**.
- **Edges**: Edges are the arrows that connect nodes together. They define the logic for how the agent will move from one node to the next. They are defined in code and conditional logic is handled with a `route` function.
- **Interrupts**: Interrupts are a way to allow for a user to work along side the agent and review its decisions. In this case, we have an **interrupt** after the **human** node which blocks the agent from proceeding until the user provides feedback.

</Step>
<Step>
### Testing the LangGraph Agent

You can submit a message to the agent by adding a message to the `messages` state variable and then clicking "Submit". This agent is paired
down for this tutorial and is meant to represent a simple research agent.

We'll be making this fancy in later steps, but for now you can ask it to do some research and see what behavior we'll be 
integrating into the application.
</Step>
</Steps>

## Recap
Now we have a running agent! It will be available at `https://localhost:8000`. Here's what we did:
- Installed LangGraph Studio
- Setup the `.env` file
- Started, visualized and tested the LangGraph agent

In the next step, we'll be integrating the LangGraph agent into the application as a Copilot Agent (CoAgent).


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-3-setup-copilotkit.mdx
================================================
---
title: "Step 3: Setup CopilotKit"
---
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content.tsx";
import { GoServer } from "react-icons/go";
import { FaCloud } from "react-icons/fa";
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';

Now that we have both our application and agent running, let's connect them using CopilotKit. The necessary dependencies are already installed in the `frontend` directory:

- `@copilotkit/react-core`: Core CopilotKit functionality and hooks
- `@copilotkit/react-ui`: Pre-built UI components for chat interfaces

<Accordions>
<Accordion title="Install command (optional)">
  **The package versions in this tutorial are pinned, so updating the dependencies could break the tutorial.**

  ```package-install
  @copilotkit/react-core @copilotkit/react-ui
  ```
</Accordion>
</Accordions>

<Steps>
<Step>
### Set up Copilot Cloud
Create a [Copilot Cloud account](https://cloud.copilotkit.ai/sign-in) to get started. This provides a production-ready proxy to your LLMs.

<Callout>
Copilot Cloud includes free LLM credits for development.
</Callout>

</Step>
<Step>
### Get a Copilot Cloud API Key

Once logged in, you'll see some on boarding steps. The main thing we'll need is a public API key. To do this,
you'll need to create an OpenAI API key and provide it to Copilot Cloud.

<ImageZoom src="/images/coagents/tutorials/ai-travel-app/cpkCloudSetup.png" alt="CopilotCloud API Key" height={1000} width={1000} />

</Step>
<Step>
### Configure environment variables
Create and populate the frontend environment file:

```shell
touch frontend/.env
```

Then, add your Copilot Cloud API key to the file like so:

```txt title="frontend/.env"
NEXT_PUBLIC_CPK_PUBLIC_API_KEY=...
```

</Step>
<Step>
### Add the CopilotKit provider
Wrap your application with the CopilotKit provider:

```tsx title="frontend/src/app/layout.tsx"
"use client";

// ...
import { CopilotKit } from "@copilotkit/react-core"; // [!code ++]
import "@copilotkit/react-ui/styles.css"; // [!code ++]
// ...

export default function RootLayout({ children }: Readonly<{ children: React.ReactNode }>) {
    return (
      <html lang="en" className="h-full">
        <body className={`${lato.variable} ${noto.className} antialiased h-full`}>
          // [!code ++:4]
          <CopilotKit
            publicApiKey={process.env.NEXT_PUBLIC_CPK_PUBLIC_API_KEY}
          >
            <TooltipProvider>
              <ResearchProvider>
                {children}
              </ResearchProvider>
            </TooltipProvider>
          </CopilotKit> // [!code ++]
        </body>
      </html>
    );
}
```

</Step>
<Step>

### Adding a chat interface

We provide several customizeable components for you to interact with your copilot. Some of these are [`<CopilotPopup/>`](/reference/components/chat/CopilotPopup), [`<CopilotSidebar/>`](/reference/components/chat/CopilotSidebar), and [`<CopilotChat/>`](/reference/components/chat/CopilotChat), and your own fully custom UI via [`useCopilotChat`](/reference/hooks/useCopilotChat).

In this tutorial, we'll use the `<CopilotChat/>` component as we want to aim for a non-modal chat interface.

<Callout>
  The `Chat` component will serve as a wrapper around the CopilotKit `CopilotChat` component. This is to help simplify
  what you'll need to write along the way.
</Callout>

```tsx title="frontend/src/components/Chat.tsx"
"use client"

import { CopilotChat } from "@copilotkit/react-ui";
import { INITIAL_MESSAGE, MAIN_CHAT_INSTRUCTIONS, MAIN_CHAT_TITLE } from "@/lib/consts";

export default function Chat({ onSubmitMessage }: { onSubmitMessage: () => void }) {
  return (
      // [!code ++:10]
      <CopilotChat
          instructions={MAIN_CHAT_INSTRUCTIONS}
          labels={{
              title: MAIN_CHAT_TITLE,
              initial: INITIAL_MESSAGE,
          }}
          className="h-full w-full font-noto"
          onSubmitMessage={onSubmitMessage}
      />
      // [!code --:4]
      <h1 className="text-2xl font-bold flex items-center justify-center h-full mx-auto mr-20">
        It'd be really cool if we had chat here!
      </h1>
  )
}
```

</Step>
</Steps>

## Recap

And we're done! Here's what we did:

- We setup our Copilot cloud account and got an API key.
- We configured the CopilotKit provider in our application to use our API key.
- We added the CopilotSidebar to our application.

Now, head back to the app and you'll find a chat interface on the left side of the page. At this point, you can start interacting with your copilot! 🎉 

<Frame>
  <ImageZoom src="/images/coagents/tutorials/research-ana/fe-step-3-finish.png" alt="step-3-finish" height={1000} width={1000} />
</Frame>

This is a very simple copilot that isn't talking to our LangGraph yet. In the next step, we'll be adding the LangGraph agent to the mix.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-4-agentic-chat-ui.mdx
================================================
---
title: "Step 4: Agentic Chat UI"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';

At this point, we have a LangGraph agent running in LangGraph Studio and have a simple copilot. Now, let's 
combine the two together to make an copilot agent (CoAgent)!

<Steps>
<Step>
## Connect the agent to CopilotKit
We need to make CopilotKit aware of our running LangGraph agent. To do this, we will setup a remote 
endpoint to connect to our locally running agent.

Since we're using Copilot Cloud, this is as simple as running the following command for local development.

```bash
npx copilotkit@latest dev --port 8000
```
```sh
✔ Select a project Local (ID: <project_id>)
✅ LangGraph Platform endpoint detected
⠹ Creating tunnel...

Tunnel Information:

• Tunnel URL:            https://<tunnel_id>.tunnels.devcopilotkit.com
• Endpoint Type:         LangGraph Platform
• Project:               projects/<project_id>

Press Ctrl+C to stop the tunnel

✔ 🚀 Local tunnel is live and linked to Copilot Cloud!
```

This allows Copilot Cloud to know where to send requests to when the agent is called.

</Step>
<Step>
## Specify the agent to use

Now we need to let the CopilotKit provider know which agent to use, we can do this by specifying the `agent` prop.
<Accordions>
<Accordion title="Multi-Agent Routing">
By default, CopilotKit will intelligently route requests to the appropriate agent based on context. This allows 
you to have multiple agents and actions and not have to worry about manually routing requests.

In our case however, we only have a single agent and its ideal to lock all requests to that agent. We can do this
by updating the props of our `CopilotKit` provider.

<Callout>
Want to learn more about multi-agent routing? Checkout out the [multi-agent concept guide](/coagents/multi-agent-flows).
</Callout>

</Accordion>
</Accordions>

Our agent name is `agent` which is specified in the `langgraph.json` file.

```tsx title="frontend/src/app/layout.tsx"
// ...
<CopilotKit
  // ...
  agent="agent" // [!code ++]
>
  {...}
</CopilotKit>
```
</Step>
</Steps>

## Recap
And we're done! Here's what we did:

- We connected the agent to CopilotKit.
- We specified the agent to use.

Now when you head back to the app, you'll notice that we're talking to our LangGraph agent!

<Frame>
  <ImageZoom src="/images/coagents/tutorials/research-ana/fe-step-4-finish.png" alt="step-4-finish" height={1000} width={1000} />
</Frame>

Next, let's process and sync the state between our application and the agent.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-5-human-in-the-loop.mdx
================================================
---
title: "Step 5: Human in the Loop"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';

Now that we have the ability to chat with our agent, we can move on to implementing human-in-the-loop. This is where the user can review the agent's output and provide feedback. We'll be
implementing this in our application by allowing the user to review and approve an outline prior to the research being conducted.

<Steps>
<Step>
## Understanding Human-in-the-Loop

In LangGraph, the current suggested way to implement human-in-the-loop is to use the [interrupt](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/) method. Calling this
function will pause the node at the call site and rerun the node with the user's decision. You can learn more about interrupt [here](https://langchain-ai.github.io/langgraph/cloud/how-tos/interrupt_concurrent/?h=interrupt).

All together, this process will look like this:

<Frame>
    <img src="/images/coagents/coagents-hitl-infographic.png" alt="Human in the loop" />
</Frame>

The implementation of all of this is actually quite simple, but understanding how it all fits together is key.
</Step>
<Step>
## Add `useLangGraphInterrupt` to the frontend

If you recall from when we started the agent, the interrupt will stop the node when its time to review a proposed research outline.

CopilotKit allows us to render a UI to get the user's decision for this interrupt and respond accordingly via the `useLangGraphInterrupt` hook.

In our `page.tsx` file, add the following code.
```tsx title="frontend/src/app/page.tsx"
// ...
import { useLangGraphInterrupt } from "@copilotkit/react-core"; // [!code ++]
// ...

export default function HomePage() {
    // ...
    const { state: researchState, setResearchState } = useResearch()

    const streamingSection = useStreamingContent(researchState);

    // [!code ++:12]
    useLangGraphInterrupt<Proposal>({
      render: ({ resolve, event }) => {
        return <ProposalViewer
          proposal={event.value}
          onSubmit={(approved, proposal) => resolve(
            JSON.stringify({
              ...proposal,
              approved,
            })
          )}
        />
      }
    })
    // ...
}
```

Now, when the LangGraph is interrupted the `ProposalViewer` component will be rendered to the user with the `event.value` as the proposal. On submit, the hook's `resolve` function
will be called with the user's decision.

<Callout>
Checkout the `ProposalViewer` component code in the `frontend/src/components/ProposalViewer.tsx` file for more details about rendering.

It's just a standard React component with some styling, a form, and a submit button.
</Callout>
</Step>
</Steps>

## Recap
It is really as simple as that! Now, we've implemented human-in-the-loop for our agent. To recap, we did the following:
- Learned about human-in-the-loop in LangGraph.
- Added the `useLangGraphInterrupt` hook to our application.
- Rendered a `ProposalViewer` component to the user in the chat

Try asking the agent to research something, like Dogs. Eventually you'll see it ask you for feedback about the proposal.

```
Please research dogs!
```

<Frame className="mt-0">
  <ImageZoom className="mt-0" src="/images/coagents/tutorials/research-ana/fe-step-5-finish.png" alt="CopilotCloud API Key" height={1000} width={1000} />
</Frame>

Now, we can completely run our agent from start to finish to conduct research. However, you may notice that the research does not populate in the right window
as it completes. In the next step, we'll leverage the CoAgent concept of shared state to populate the research in the right window.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-6-shared-state.mdx
================================================
---
title: "Step 6: Shared State"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';

In LangGraph, your agents are stateful. This means that they as your graph traverses nodes, the overall application state will be updated and persisted.

CopilotKit allows you to easily read and update this state through the use of two main hooks:
- [`useCoAgent`](/reference/hooks/useCoAgent) - Provides a way to read and write Agent state anywhere in your application.
- [`useCoAgentStateRender`](/reference/hooks/useCoAgentStateRender) - Provides a way to render Agent state in the chat.

With this in mind, our current goal is to create a bidirectional connection between the application's state and the LangGraph agent's state. This will
allow us to render the agent's completed research in the right panel. 

For this, we'll be using the `useCoAgent` hook.

<Callout>
The `useCoAgentStateRender` will be used in the next step to render the agent's progress in the chat.
</Callout>

<Steps>
<Step>
## Understanding our agent's state
The state of our agent can be found in `agent/state.py`.

```python title="agent/state.py"
# ...
from typing import Dict, Union, List
from langgraph.graph import MessagesState

class ResearchState(MessagesState):
    title: str
    proposal: Dict[str, Union[str, bool, Dict[str, Union[str, bool]]]]  # Stores proposed structure before user approval
    outline: dict
    sections: List[dict]  # list of dicts with 'title','content',and 'idx'
    footnotes: str
    sources: Dict[str, Dict[str, Union[str, float]]]
    tool: str
    logs: List[dict]  # list of dicts logs to be sent to frontend with 'message', 'status'
```

There are a few things to note here, but let's focus on the `proposal` field and `sections` field.

- The `proposal` field is a dictionary that stores the proposed research structure before the user approves it.
- The `sections` field is a list of dictionaries, each containing a `title`, `content`, and `idx`. This is the actual research that will be displayed in the right panel.

We've already wired up the approval of the `proposal` field in the previous step, so now we need to wire up rendering for the `sections` field.

</Step>
<Step>

## The `useCoAgent` hook
Our current goal is to create a bidirectional connection between these two states. Luckily, the [`useCoAgent`](/reference/hooks/useCoAgent) hook makes this easy.

In the `useResearch` hook, we'll just replace our React state objects with the `useCoAgent` hook.

```tsx title="frontend/src/components/research-context.tsx" {3,8-11}
// ...
import { useCoAgent } from "@copilotkit/react-core"; // [!code ++]
// ...

interface ResearchContextType {
    state: ResearchState;
    setResearchState: (newState: ResearchState | ((prevState: ResearchState) => ResearchState)) => void
    sourcesModalOpen: boolean
    setSourcesModalOpen: (open: boolean) => void
    runAgent: () => void
}

const ResearchContext = createContext<ResearchContextType | undefined>(undefined)

export function ResearchProvider({ children }: { children: ReactNode }) {
    const [sourcesModalOpen, setSourcesModalOpen] = useState<boolean>(false)
    // [!code ++:5]
    const { state, setState, run } = useCoAgent<ResearchState>({
        name: 'agent',
        initialState: {},
    });
    const [state, setState] = useState<ResearchState>({} as ResearchState) // [!code --]

    // ...

    return (
        <ResearchContext.Provider 
            value={{ 
              state, 
              setResearchState: setState as ResearchContextType['setResearchState'], 
              setSourcesModalOpen, 
              sourcesModalOpen, 
              runAgent: run  // [!code ++]
              runAgent: () => {} // [!code --]
            }}>
            {children}
        </ResearchContext.Provider>
    )
}

export function useResearch() {
    const context = useContext(ResearchContext)
    if (context === undefined) {
        throw new Error('useResearch must be used within a ResearchProvider')
    }
    return context
}
```

<Callout>
The `useCoAgent` hook is generic. What this means is that we can specify a type for that represents the state of the LangGraph agent.
If you are going to specify a type, you should be very careful that the type has the same shape as the state of your LangGraph agent.

It is not recommended, but you can ditch the type parameter and instead get an `any` type.
</Callout>

In this example, we use the `useCoAgent` hook to wire up the application's state to the LangGraph agent's state.
- For the generic type, we pass the `AgentState` type that was already defined for the application in `@/lib/types.ts`.
- For the `name` parameter, we pass the name of the graph as defined in `agent/langgraph.json`.
- For the `initialState` parameter, we pass the initial state of the LangGraph agent which is already defined in `@/lib/trips.ts`.
</Step>
</Steps>


## Recap
Now we can see the final result of the research in the right panel! To recap, we did the following:
- Learned about the agent's state.
- Added the `useCoAgent` hook to our application to render the `sections` field.

Now, try running the agent again and going through the same steps. At the end, you'll see the completed research in the right panel.

```
Please research dogs!
```

<Frame className="mt-0">
  <ImageZoom className="mt-0" src="/images/coagents/tutorials/research-ana/fe-step-6-finish.png" alt="CopilotCloud API Key" height={1000} width={1000} />
</Frame>

Now, we can completely run our agent from start to finish *and* see the finalized research in the right window. 

However, you may notice that the research takes a long time to complete without any indication of progress. In the next step, we'll leverage the CoAgent concepts
of **generative ui** to communicate the agent's progress in the chat.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-7-generative-ui.mdx
================================================
---
title: "Step 7: Agentic Generative UI"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';
import InstallPythonSDK from "@/snippets/install-python-sdk.mdx";

We're almost done! In this step, we're going to add generative UI to the application so that we can visualize the agent
state in the chat UI. The end goal with this is to allow the user to see the progress of the agent's research as it is
completed.

<Callout>
We call UI that is rendered from the state of the agent or its tool calls "Generative UI".
</Callout>

For this guide, we're going to start using the CopilotKit SDK to emit the state of the agent manually. This is because
in LangGraph, state is only updated when a node change occurs (i.e, an edge is traversed). 

As such, in-progress work is not emitted to the user by default. However, we can manually emit the state using the `copilotkit_emit_state`
function. With that emitted state, we'll be using the `useCoAgentStateRender` hook to render updates in the chat to give the user
a sense of progress.




<Steps>
<Step>
## CopilotKit Python SDK
This tutorial already comes with the CopilotKit Python SDK installed. This allows us to utilize various CopilotKit specific
features, such as emitting state.

<Accordions>
<Accordion title="Install command (optional)">
  **The package versions in this tutorial are pinned, so updating the dependencies could break the tutorial.**

  <InstallPythonSDK components={props.components} />
</Accordion>
</Accordions>

</Step>
<Step>
## Manually emit state
The research ANA emits state in a variety of places. For the sake of simplicity, we'll be adding the `copilotkit_emit_state` function
to the `agent/graph.py` file so you can understand how it works. However, state is also emitted in the following files if you'd like to
look at them:
- `agent/tools/outline_writer.py`
- `agent/tools/section_writer.py`
- `agent/tools/tavily_extract.py`
- `agent/tools/tavily_search.py`

Each of these files will write their progress to the `logs` field of the agent's state. Directly after that, we call `copilotkit_emit_state` to emit the state to the frontend.

For example, in the `tool_node` we update some state based on the tool result and then use `copilotkit_emit_state` to emit the state to the frontend.

```python title="agent/graph.py"
# ...
from copilotkit.langchain import copilotkit_emit_state # [!code ++]
#...

async def tool_node(self, state: ResearchState, config: RunnableConfig) -> Command[Literal["process_feedback_node", "call_model_node"]]:
        # ...
        for tool_call in state["messages"][-1].tool_calls:
            # ...

            tool_state = {
                "title": new_state.get("title", ""),
                "outline": new_state.get("outline", {}),
                "sections": new_state.get("sections", []),
                "sources": new_state.get("sources", {}),
                "proposal": new_state.get("proposal", {}),
                "logs": new_state.get("logs", []),
                "tool": new_state.get("tool", {}),
                "messages": msgs
            }
            await copilotkit_emit_state(config, tool_state) # [!code ++]

        return tool_state
```

As this loop is iterated through, the intermediate state that the tools write will be emitted to the frontend. Basically, any time that
you want to emit state to the frontend, you can do so by calling `copilotkit_emit_state`.

</Step>
<Step>
## Render the emitted state
Now, our state is being emitted to the frontend. However, we need to render it in the chat. To do this, we'll be using the `useCoAgentStateRender` hook.

```tsx title="frontend/src/app/layout.tsx"
import { useCoAgentStateRender, useLangGraphInterrupt } from "@copilotkit/react-core"; // [!code ++]

export default function HomePage() {
    //...
    const { state: researchState, setResearchState } = useResearch()
    // ...

    // [!code ++:10]
    useCoAgentStateRender<ResearchState>({
        name: 'agent',
        render: ({ state }) => {
            if (state.logs?.length > 0) {
                return <Progress logs={state.logs} />;
            }
            return null;
        },
    }, [researchState]);

    // ...
}
```
</Step>
</Steps>


## Recap
Try running the agent again and going through the same steps. You'll now notice that the state is streaming intermediately and 
the user can see the progress of the agent's research.

```
Please research dogs!
```

<Frame className="mt-0">
  <ImageZoom className="mt-0" src="/images/coagents/tutorials/research-ana/fe-step-7-finish.png" alt="CopilotCloud API Key" height={1000} width={1000} />
</Frame>

To recap, we did the following:
- Learned about how to emit state whenever we want with `copilotkit_emit_state`.
- Added the `useCoAgentStateRender` hook to our application to render the intermediate state in the chat.

We're almost done, just one step to go! Now we're going to learn about **progressive state updates** which will allow us to render the sections as they are written into state. This will
complete the agentic experience.


================================================
FILE: docs/content/docs/coagents/tutorials/agent-native-app/step-8-progressive-state-updates.mdx
================================================
---
title: "Step 8: Progressive State Updates"
---
import { ImageZoom } from 'fumadocs-ui/components/image-zoom';

At this point, we've got a pretty functional application. We can run the agent, see the progress in the chat, and see the final research in the right panel.

However, we're still missing one thing. We don't see the LLM actually generating the research, we just see the final result.

In this step, we'll learn how to leverage predictive state rendering to render the agent's progress in the chat. Specifically, we'll be rendering the 
sections of the research as they are generated.

For this, we'll be using the `copilotkit_customize_config`.

<Callout>
The `copilotkit_customize_config` function will be used in the next step to render the agent's progress in the chat.
</Callout>

## Create a copilotkit_customize_config and emit intermediate state
CopilotKit allows you to customize the configuration of how your frontend and agent interact with each other. In this case, we want to
setup the `emit_intermediate_state` property. We define a list of objects which will be used to emit the state to the frontend based on
tool calls.

```python title="agent/section_writer.py"
from copilotkit.langchain import copilotkit_customize_config, copilotkit_emit_state // [!code ++]

# ...
@tool("section_writer", args_schema=SectionWriterInput, return_direct=True)
async def section_writer(research_query, section_title, idx, state):
    """Writes a specific section of a research report based on the query, section title, and provided sources."""

    # ...

    # Define the state keys that we want to emit, pre-created for this tutorial
    content_state = {
        "state_key": f"section_stream.content.{idx}.{section_id}.{section_title}",
        "tool": "WriteSection",
        "tool_argument": "content"
    }
    footer_state = {
        "state_key": f"section_stream.footer.{idx}.{section_id}.{section_title}",
        "tool": "WriteSection",
        "tool_argument": "footer"
    }

    # [!code ++:5]
    config = copilotkit_customize_config(
        config,
        emit_intermediate_state=[content_state, footer_state]
    )

    # ...

    # [!code highlight:4]
    # The LLM will take this new config and the tool calls
    # we defined will be emitted to the frontend predictively.
    response = await model.bind_tools([WriteSection]).ainvoke(lc_messages, config)

    # ...

```

There are three main pieces to predictively emit state:
1. The `state_key` is the key of the agent's state that we want to emit.
2. The `tool` is the tool that will be called to generate the state.
3. The `tool_argument` is the argument that will be passed to the tool which will be the predicted state.

## Recap
That's it! Now when the LLM calls the tools that we defined, the state will be predictively emitted to the frontend.

To give it a try, go through the full flow of conducting research. You'll now be able to see the sections as they are being generated.

```
Please research dogs!
```

<video src="/images/coagents/tutorials/research-ana/fe-step-8-finish.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

To recap, we did the following:
- Learned about the `copilotkit_customize_config` function.
- Used the config to emit the state of the agent predictively

You've successfully created a CoAgent using the core concepts of CopilotKit. In the next step, we'll wrap up this tutorial by recapping the entire process
and showing some next steps.


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/index.mdx
================================================
---
title: Overview
icon: "lucide/Plane"
---
import { YouTubeVideo } from "@/components/react/youtube-video";
import { FaGithub } from "react-icons/fa";
import { PiMonitor } from "react-icons/pi";
import { Button } from "@/components/ui/button";
import Link from "next/link";

# AI Travel Agentic Copilot Tutorial

<div>
  <div>**Time to complete:** 20 minutes</div>
  <div>**Difficulty:** Medium</div>
</div>

<br />

<YouTubeVideo videoId="9v3kXiOY3vg" defaultPlaybackRate={1.25} />

## What you'll learn

In this tutorial, you will take a simple travel application and supercharge it with an agentic copilot. You will learn:

- 💡 What an agentic copilot is and how it can be used to enhance your application
- 💡 How to use `useCoAgent` to allow for shared state between your UI and agent execution
- 💡 How to use `useCoAgentStateRender` to implement human-in-the-loop workflows
- 💡 How to render intermediate states of your agent's execution

<Frame>
  <video controls autoPlay muted loop 
    src="/images/coagents/tutorials/ai-travel-app/demo.mp4"
    alt="Travel app demo" 
    className="w-full h-full [h-800px] shadow-xl">
  </video>
</Frame>

<div className="flex flex-row gap-2">
  <Button size="lg" asChild className="flex gap-2 items-center">
    <Link href="https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-travel?ref=travel-tutorial" className="no-underline" target="_blank">
      <FaGithub className="w-6 h-6 mr-2" />
      <span>View on GitHub</span>
    </Link>
  </Button>

  <Button size="lg" asChild className="flex gap-2 items-center">
    <Link href="https://examples-coagents-ai-travel-app.vercel.app/" className="no-underline" target="_blank">
      <PiMonitor className="w-6 h-6 mr-2" />
      <span>View live app</span>
    </Link>
  </Button>
</div>


In the next step, we'll checkout the repo, install dependencies, and start the project locally.


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/meta.json
================================================
{
  "title": "Tutorial: AI Travel App",
  "pages": [
    "step-1-checkout-repo",
    "step-2-langgraph-agent",
    "step-3-setup-copilotkit",
    "step-4-integrate-the-agent",
    "step-5-stream-progress",
    "step-6-human-in-the-loop",
    "next-steps"
  ]
}


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/next-steps.mdx
================================================
---
title: "Next Steps"
---

This is the end of the tutorial. You can now start building your own CoAgents into your appications!

## Source code

You can find the source code and interactive sandboxes here:
- [Start app](https://github.com/CopilotKit/CopilotKit/tree/coagents-travel-tutorial-start/examples/coagents-travel)
- [Final app](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-travel)

## What's next?

For next steps, here are some ideas:

- Add suggestions to your copilot, using the [`useCopilotChatSuggestions`](/reference/hooks/useCopilotChatSuggestions) hook.
- Implement a custom UI for your agent, using the [`useCopilotChat`](/reference/hooks/useCopilotChat) hook.
- Add human editing of tool call arguments to the human in the loop implementation.

We have more tutorials coming soon.

## Need help?

If you have any questions, feel free to reach out to us on [Discord](https://discord.gg/6dffbvGU3D).



================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/step-1-checkout-repo.mdx
================================================
---
title: "Step 1: Checkout the repo"
---

<Steps>
<Step>
### Checkout the starting branch
We'll be working with the CopilotKit repository, specifically using a branch called `coagents-travel-tutorial-start`. This branch contains the starting code for our travel app tutorial.

```shell
git clone -b coagents-travel-tutorial-start https://github.com/CopilotKit/CopilotKit.git
cd CopilotKit
```

The tutorial code is located in the `examples/coagents-travel` directory, which contains:
- `ui/`: A NextJS application where we'll integrate our LangGraph agent
- `agent/`: A Python-based LangGraph agent that we'll be enhancing

Go ahead and navigate to the example directory:

```shell
cd examples/coagents-travel
```
</Step>
<Step>
### Install dependencies
First, let's set up the NextJS application. Navigate to the `ui` directory and install the dependencies:

```shell
cd ui
pnpm install
```
</Step>
<Step>
### Start the project
Launch the development server:

```shell
pnpm run dev
```

Visit [http://localhost:3000](http://localhost:3000) to see the travel app in action. Take some time to explore the interface and familiarize yourself with its features.
</Step>
</Steps>

Next, let's understand the LangGraph agent and how it works.


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/step-2-langgraph-agent.mdx
================================================
---
title: "Step 2: LangGraph Agent"
---

Before we start integrating the LangGraph agent, let's understand how it works. 

For the sake of this tutorial we won't be building the LangGraph together from scratch. 
Instead, we'll be using the LangGraph constructed in the `agent/` directory.

<Callout>
If you're interested in a step-by-step guide for building a LangGraph agent, you can checkout the 
[LangGraph quickstart guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/).
</Callout>

Let's walk through the LangGraph agent to understand how it works before we integrate it into the application.

<Steps>
<Step>
### Install LangGraph Studio

LangGraph Studio is a tool for visualizing and debugging LangGraph workflows. It is not required for using CopilotKit but it is highly recommended
for understanding how LangGraph works. 

To install LangGraph Studio, checkout the [setup guide](https://studio.langchain.com/).

</Step>
<Step>
### Retreive API keys

For this application, we'll need two API keys:
- OpenAI API key: You can get an API key from the OpenAI console [here](https://platform.openai.com/api-keys).
- Google Maps API key: This can be retrieved from the Google Cloud Console [here](https://developers.google.com/maps/documentation/places/web-service/get-api-key#creating-api-keys).

</Step>
<Step>
### Setup the .env file

In a new terminal, navigate to the agent directory.

```shell
cd examples/coagents-travel/agent
```

Now create a .env file there.

```shell
touch .env
```

With that created, we'll want to add your OPENAI_API_KEY and GOOGLE_MAPS_API_KEY to the file.

```txt title=".env"
OPENAI_API_KEY=<your-openai-api-key>
GOOGLE_MAPS_API_KEY=<your-google-maps-api-key>
```

</Step>
<Step>
### Visualizing the LangGraph Agent

With LangGraph Studio installed, you can run and visualize the LangGraph agent by opening the `examples/coagents-travel/agent/` directory in the studio.

The agent will take some time to load as things get setup but once finished it will look something like this.

![LangGraph Studio](/images/coagents/tutorials/ai-travel-app/lgs-overview.png)


</Step>
<Step>

### Understanding the LangGraph Agent

As we're building this agent into an agentic experience, we'll want to understand how it works. The key concepts at play here are:

- **State**: The state is the data that the agent is using to make and communicate its decisions. You can see all of the state variables in the bottom left of the screen.
- **Nodes**: Nodes are the building blocks of a LangGraph agent. They are the steps that the agent will take to complete a task. In this case, we have nodes for **chatting**, **searching** and **performing operations** on trips.
- **Edges**: Edges are the arrows that connect nodes together. They define the logic for how the agent will move from one node to the next. They are defined in code and conditional logic is handled with a `route` function.
- **Interrupts**: Interrupts are a way to allow for a user to work along side the agent and review its decisions. In this case, we have an **interrupt** before the **trips_node** which blocks the agent from proceeding until the user has approved the Agent's actions.

</Step>
<Step>
### Testing the LangGraph Agent

You can submit a message to the agent by adding a message to the `messages` state variable and then clicking "Submit".

You'll see the agent respond in the chat and direct appropriately through the various nodes. In this case, you should notice that the
agent calls the `search_node` and, once it has received a response, will add a new trip based on its findings to the state via the 
`trips_node`.

</Step>
<Step>
### Understanding breakpoints
A very important concept for agentic copilots is [human-in-the-loop](/coagents/human-in-the-loop). This is the idea that the agent should be able to pause and wait for a human to review and approve its decisions.
LangGraph allows for this by using **breakpoints**. Let's take a look at what that looks like in action.

First, click on the `trips_node` and select the `interrupt_after` option.

Now, try to have the agent create a new trip again. You'll notice that it now asks for approval before proceeding via a `continue` button.

![LangGraph Studio Progress](/images/coagents/tutorials/ai-travel-app/lgs-progress.png)

Make sure to remove the `interrupt_after` option before proceeding, this will break things later if you don't.

</Step>
<Step>
### Leave LangGraph Studio running

In order to create an agentic copilot, you'll need to have your LangGraph agent running somewhere. In our case, LangGraph studio is 
running this locally for us. We can see this by looking at the URL at the bottom left of the application.

![LangGraph Studio URL](/images/coagents/tutorials/ai-travel-app/lgs-url.png)

Later in this tutorial, we'll be using this URL to connect CopilotKit to the LangGraph agent.

</Step>
</Steps>
Here's what we did:
- Installed LangGraph Studio
- Setup the .env file
- Visualized the LangGraph agent
- Tested the LangGraph agent
- Left LangGraph Studio running

In the next step, we'll be integrating the LangGraph agent into the application as an agentic copilot.


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/step-3-setup-copilotkit.mdx
================================================
---
title: "Step 3: Setup CopilotKit"
---
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content.tsx";
import { GoServer } from "react-icons/go";
import { FaCloud } from "react-icons/fa";

Now that we have the application and agent running, we're ready to connect both via CopilotKit. For this tutorial, we will install the following dependencies:

- `@copilotkit/react-core`: The core library for CopilotKit, which contains the CopilotKit provider and useful hooks.
- `@copilotkit/react-ui`: The UI library for CopilotKit, which contains the CopilotKit UI components such as the sidebar, chat popup, textarea and more.

## Install Dependencies

Navigate back to the `ui` directory and install the CopilotKit dependencies:

```shell
pnpm add @copilotkit/react-core @copilotkit/react-ui
```

## Setup CopilotKit

There are two ways of setting up CopilotKit, either by using Copilot Cloud or by self-hosting. Self-hosting will give you more control
over CopilotKit's runtime (our interface to the LLM) but will also require you to manage the extra complexity of running a server. Copilot Cloud
on the other hand is a fully managed service that you can get started with in just a few clicks.

For this tutorial, you can select either option.

<TailoredContent id="hosting">
<TailoredContentOption
  id="copilot-cloud"
  title="Copilot Cloud (Recommended)"
  icon={<FaCloud />}
  description="I want get started as fast as possible by using Copilot Cloud."
>
We're using CopiloKit cloud as a hosted version of the CopilotKit runtime. The runtime serves as an interface between the application and the LLM
(agentic or not). Copilot Cloud will manage all of the complexity for us but in return we need to provide a valid API key.
<Steps>
<Step>
### Create an account on Copilot Cloud

First, you'll need to create an account for Copilot Cloud [here](https://cloud.copilotkit.ai/sign-in). You can
use whatever authentication method you'd like.

</Step>
<Step>
### Get a Copilot Cloud API Key

Once logged in, you'll see some steps guiding you to getting our Copilot Cloud public API key. For this, you'll need an OpenAI API key since it's the only
provider currently supported (more providers coming soon!). 

Set your OpenAI API key, click the green checkmark and you'll see your API key created right below the input.

<Frame>
<img src="/images/coagents/tutorials/ai-travel-app/cpkCloudSetup.png" alt="CopilotCloud API Key" />
</Frame>

</Step>
<Step>
### Setting up the environment variables

First, create a `.env` file in the `ui` directory.

```shell
touch ui/.env
```

Then, add your Copilot Cloud API key to the file like so:

```txt title="ui/.env"
NEXT_PUBLIC_CPK_PUBLIC_API_KEY=...
```

</Step>
<Step>
### Configure the CopilotKit Provider

Now we're ready to configure the CopilotKit provider in our application.

```tsx title="ui/app/page.tsx" showLineNumbers
"use client";

import { CopilotKit } from "@copilotkit/react-core"; // [!code ++]

export default function Home() {
  // [!code ++:5]
  return (
    <CopilotKit
      publicApiKey={process.env.NEXT_PUBLIC_CPK_PUBLIC_API_KEY}
    >
      <TooltipProvider>
        <TripsProvider>
          <main className="h-screen w-screen">
            <MapCanvas />
          </main>
        </TripsProvider>
      </TooltipProvider>
    </CopilotKit> // [!code ++]
  );
}
```
<Step>

### CopilotKit Chat Popup

We provide several plug-and-play components for you to interact with your copilot. Some of these are `<CopilotPopup/>`, `<CopilotSidebar/>`, and `<CopilotChat/>`. You can of course use CopilotKit in headless mode and provide your own fully custom UI via [`useCopilotChat`](/reference/hooks/useCopilotChat).

In this tutorial, we'll use the `<CopilotSidebar/>` component to display the chat sidebar.

```tsx title="ui/app/page.tsx" showLineNumbers {6-7,15}
"use client";

import { TasksList } from "@/components/TasksList";
import { TasksProvider } from "@/lib/hooks/use-tasks";
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui"; // [!code ++]
import "@copilotkit/react-ui/styles.css"; // [!code ++]

export default function Home() {
  return (
    <CopilotKit
      publicApiKey={process.env.NEXT_PUBLIC_CPK_PUBLIC_API_KEY}
    >
      /* [!code ++:9] */
      <CopilotSidebar
        defaultOpen={true}
        clickOutsideToClose={false}
        labels={{
          title: "Travel Planner",
          initial: "Hi! 👋 I'm here to plan your trips. I can help you manage your trips, add places to them, or just generally work with you to plan a new one.",
        }}
      />
      <TooltipProvider>
        <TripsProvider>
          <main className="h-screen w-screen">
            <MapCanvas />
          </main>
        </TripsProvider>
      </TooltipProvider>
    </CopilotKit>
  );
}
```

And we're done! Here's what we did:

- We setup our Copilot cloud account and got an API key.
- We configured the CopilotKit provider in our application to use our API key.
- We added the CopilotSidebar to our application.
</Step>

</Step>
</Steps>
</TailoredContentOption>
<TailoredContentOption 
  id="self-hosted"
  title="Self-hosted"
  icon={<GoServer />}
  description="I want to learn how to self-host CopilotKit and will own the extra complexity."
>
<Steps>
<Step>
### Set up Copilot Runtime Endpoint
<SelfHostingCopilotRuntimeCreateEndpoint components={props.components} />
</Step>
<Step>

### Configure the CopilotKit Provider
```tsx title="app/page.tsx" showLineNumbers
"use client";

import { TasksList } from "@/components/TasksList";
import { TasksProvider } from "@/lib/hooks/use-tasks";
import { CopilotKit } from "@copilotkit/react-core"; // [!code ++]

export default function Home() {
  return (
    <CopilotKit runtimeUrl="/api/copilotkit"> // [!code ++]
      <TasksProvider>
        <TasksList />
      </TasksProvider>
    </CopilotKit> // [!code ++]
  );
}
```
</Step>
</Steps>

### CopilotKit Chat Popup

We provide several plug-and-play components for you to interact with your copilot. Some of these are `<CopilotPopup/>`, `<CopilotSidebar/>`, and `<CopilotChat/>`. You can of course use CopilotKit in headless mode and provide your own fully custom UI via [`useCopilotChat`](/reference/hooks/useCopilotChat).

In this tutorial, we'll use the `<CopilotSidebar/>` component to display the chat sidebar.

```tsx title="ui/app/page.tsx" showLineNumbers {6-7,15}
"use client";

import { TasksList } from "@/components/TasksList";
import { TasksProvider } from "@/lib/hooks/use-tasks";
import { CopilotKit } from "@copilotkit/react-core";
import { CopilotSidebar } from "@copilotkit/react-ui"; // [!code ++]
import "@copilotkit/react-ui/styles.css"; // [!code ++]

export default function Home() {
  return (
    <CopilotKit
      publicApiKey={process.env.NEXT_PUBLIC_CPK_PUBLIC_API_KEY}
    >
      /* [!code ++:9] */
      <CopilotSidebar
        defaultOpen={true}
        clickOutsideToClose={false}
        labels={{
          title: "Travel Planner",
          initial: "Hi! 👋 I'm here to plan your trips. I can help you manage your trips, add places to them, or just generally work with you to plan a new one.",
        }}
      />
      <TooltipProvider>
        <TripsProvider>
          <main className="h-screen w-screen">
            <MapCanvas />
          </main>
        </TripsProvider>
      </TooltipProvider>
    </CopilotKit>
  );
}
```

Here's what we did:

- We imported the `<CopilotSidebar />` component from `@copilotkit/react-ui`.
- We wrapped the page with the `<CopilotKit>` provider.
- We imported the built-in styles from `@copilotkit/react-ui`.
</TailoredContentOption>
</TailoredContent>

Now, head back to the app and you'll find a chat sidebar on the left side of the page. At this point, you can start interacting with your copilot! 🎉 

This is very exciting! In the next step we'll be making this copilot agentic through the use of LangGraph.


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/step-4-integrate-the-agent.mdx
================================================
---
title: "Step 4: Integrate the Agent"
---
At this point, we have a LangGraph agent running in LangGraph Studioand have our own non-agentic copilot that we can interact with. Now, let's 
combine the two together to make an agentic copilot!

## The React State

Let's quickly review how the app's state works. Open up the [`lib/hooks/use-trips.tsx`](https://github.com/CopilotKit/CopilotKit/blob/coagents-travel-tutorial-start/examples/coagents-travel/ui/lib/hooks/use-trips.tsx) file.

At a glance, we can see that the file exposes a provider (`TripsProvider`), which defines a lot useful things. The main thing we care about is the `state` object which takes the shape of the `AgentState` type. This is consumable by a `useTrips` hook, which we use in the rest of the application (feel free to check out the `TripCard`, 
`TripContent` and `TripSelect` components).

This resembles the majority of React apps, where frontend state, either for a feature or the entire app, is managed by a context or state management library.

## Integrate the Agent

To integrate the agent into this state, we're going to need to setup a remote endpoint and then use the `useCoAgent` hook to connect the two.

<Steps>
<Step>
## Setup a remote endpoint

Make sure you have the LangGraph Studio endpoint from the previous step!

<Tabs groupId="hosting" items={['Copilot Cloud', 'Self-Hosted']}>
<Tab value="Copilot Cloud">
We're going to use the CopilotKit CLI to setup a tunnel between our locally running LangGraph agent and Copilot Cloud. You'll 
need the port number of the LangGraph Studio endpoint we setup earlier.

<Callout title="Looking for the port number?">
It'll be on the bottom left of the LangGraph Studio interface like this.

<Frame>
  <img src="/images/coagents/tutorials/ai-travel-app/lgs-endpoint.png" alt="LangGraph Studio Endpoint" />
</Frame>

</Callout>

To open a tunnel, run the following command.

```bash
# replace <port_number> with the port number of the LangGraph Studio endpoint
npx copilotkit@latest dev --port <port_number>
```

It will guide you through the process of selecting a project and creating a tunnel. You should see output similar to the following.

```bash
✔ Select a project Local (ID: <project_id>)
✅ LangGraph Platform endpoint detected
⠹ Creating tunnel...

Tunnel Information:

• Tunnel URL:            https://<tunnel_id>.tunnels.devcopilotkit.com
• Endpoint Type:         LangGraph Platform
• Project:               projects/<project_id>

Press Ctrl+C to stop the tunnel

✔ 🚀 Local tunnel is live and linked to Copilot Cloud!
```

</Tab>
<Tab value="Self-Hosted">

In our previously setup `/api/copilotkit` route, we're going to add the following.

```tsx title="ui/app/api/copilotkit/route.ts"
// ...

import { langGraphPlatformEndpoint } from '@copilotkit/runtime'; // [!code ++]

// ...

const runtime = new CopilotRuntime();// [!code --]
// [!code ++:13]
 const runtime = new CopilotRuntime({
    remoteEndpoints: [
      langGraphPlatformEndpoint({
        deploymentUrl: "http://localhost:<port_number>",
        langsmithApiKey: "your-langsmith-api-key",
        agents: [{ 
          name: 'travel', 
          description: 'A travel assistant that can help with planning trips.' 
        }]
      }),
    ],
});

// ...
```

<Callout>
The `deploymentUrl` is the URL from LangGraph Studio but it can also be a graph hosted in LangGraph Platform!
</Callout>
</Tab>
</Tabs>

This allows CopilotKit to know where to send requests to when the agent is called.

</Step>
<Step>
## Lock the agent

By default, CopilotKit will intelligently route requests to the appropriate agent based on context. This allows 
you to have multiple agents and actions and not have to worry about manually routing requests.

In our case however, we only have a single agent and its ideal to lock all requests to that agent. We can do this
by updating the props of our `CopilotKit` provider.

<Callout>
Want to learn more about multi-agent routing? Checkout out the [multi-agent concept guide](/coagents/multi-agent-flows).
</Callout>

```tsx title="ui/app/page.tsx"
// ...
<CopilotKit
  // ...
  agent="travel" // [!code ++]
>
  {...}
</CopilotKit>
```

This will ensure that every request is sent to the `travel` agent. The `travel` name is defined in the [agents/langgraph.json](https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-travel/agent/langgraph.json)
file. When we deploy our agent to Copilot Cloud this is automatically handled for us. When self-hosting, we need to specify the name of the agent in the `langGraphPlatformEndpoint` constructor.
</Step>
<Step>

## The `useCoAgent` hook

LangGraph agents are stateful, meaning that they can maintain their own state. We saw this earlier when we were using LangGraph Studio, in the bottom left. We
also have the application's state through React.

Our current goal is to create a bidirectional connection between these two states. Luckily, the [`useCoAgent`](/reference/hooks/useCoAgent) hook makes this easy.

```tsx title="ui/lib/hooks/use-trips.tsx" {3,8-11}
// ...
// [!code word:AgentState:1]
import { Trip, Place, AgentState, defaultTrips} from "@/lib/trips"; 
import { useCoAgent } from "@copilotkit/react-core"; // [!code ++]

export const TripsProvider = ({ children }: { children: ReactNode }) => {
  // [!code --:5]
  const [state, setState] = useState<{ trips: Trip[], selected_trip_id: string | null }>({ 
    trips: defaultTrips, 
    selected_trip_id: defaultTrips && defaultTrips[0] ? defaultTrips[0].id : null 
  });
  // [!code ++:9]
  const { state, setState } = useCoAgent<AgentState>({
    name: "travel",
    initialState: {
      trips: defaultTrips,
      selected_trip_id: defaultTrips[0].id,
    },
  });

  // ...
```

<Callout>
The `useCoAgent` hook is generic. What this means is that we can specify a type for that represents the state of the LangGraph agent.
If you are going to specify a type, you should be very careful that the type has the same shape as the state of your LangGraph agent.

It is not recommended, but you can ditch the type parameter and instead get an `any` type.
</Callout>

In this example, we use the `useCoAgent` hook to wire up the application's state to the LangGraph agent's state.
- For the generic type, we pass the `AgentState` type that was already defined for the application in `@/lib/types.ts`.
- For the `name` parameter, we pass the name of the graph as defined in `agent/langgraph.json`.
- For the `initialState` parameter, we pass the initial state of the LangGraph agent which is already defined in `@/lib/trips.ts`.
</Step>
</Steps>

## Try it out!

Now, try it out! Ask the Copilot something about the state of your trips. For example:

```
What trips do I currently have?
```

The state is shared between the application and the agent, so you can edit a trip manually, ask the same question,
and the agent will know about it.

```
What trips do I have now?
```

In the same vein, you can ask the agent to update your trips and it will render in the UI. For example:

```
Add some hotels to my NYC trip
```

Its really that simple, you have now integrated a LangGraph agent into the application as an agentic copilot. In the following 
steps, we'll be improving the user experience but the core agent is now accessible through the application's chat interface.




================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/step-5-stream-progress.mdx
================================================
---
title: "Step 5: Stream Progress"
---

Now that we have integrated the LangGraph agent into the application, we can start utilizing features that will enhance the
user agentic experience even further. For example, what if we could stream the progress of a search to the user?

In this step, we'll be doing just that. To do so we'll be using the `copilotkit_emit_state` CopilotKit SDK function in the
`search_node` of our LangGraph agent.

## Install the CopilotKit SDK

CopilotKit comes ready with an SDK for building both Python and Typescript agents. In this case, the agent is written in Python
(manged with `poetry`), so we'll be installing the Python SDK.

<Callout>
Don't have poetry installed? [Install it here](https://python-poetry.org/docs/#installation).
</Callout>

```shell title="agent/"
poetry add copilotkit
# or including support for crewai
poetry add copilotkit[crewai]
```

Now we're ready to use the CopilotKit SDK in our agent! Since we're editing the `search_node` in agent, we'll be
editing the `search.py` file.

## Manually emitting the agent's state

With CoAgents, the LangGraph agent's state is only emitted when node change occurs (i.e, an edge is traversed). This means
that in-progress work is not emitted to the user by default. However, we can manually emit the state using the `copilotkit_emit_state`
function that we mentioned earlier.

<Steps>
<Step>
### Add the custom CopilotKit config to the `search_node`
First, we're going to add a custom copilotkit config to the `search_node` to describe what intermediate state
we'll be emitting.

```python title="agent/travel/search.py" {3-5}
# ...
from copilotkit.langgraph import copilotkit_emit_state, copilotkit_customize_config # [!code ++]

async def search_node(state: AgentState, config: RunnableConfig):
    """
    The search node is responsible for searching the for places.
    """
    ai_message = cast(AIMessage, state["messages"][-1])

    # [!code ++:9]
    config = copilotkit_customize_config(
        config,
        emit_intermediate_state=[{
            "state_key": "search_progress",
            "tool": "search_for_places",
            "tool_argument": "search_progress",
        }],
    )

    # ...
```
</Step>
<Step>
### Emit the intermediate state
Now we can call `copilotkit_emit_state` to emit the intermediate state wherever we want. In this case, we'll be emitting it
progress at the beginning of our search and as we receive results.

<Callout>
One piece of this that has already been setup for you is the `search_progress` state key. In order to emit progress, we add
an object to our state that we'll manually update with the results and progress of our search. Then we'll be calling `copilotkit_emit_state`
to manually emit that state.
</Callout>

```python title="agent/travel/search.py"
# ...
async def search_node(state: AgentState, config: RunnableConfig):
    """
    The search node is responsible for searching the for places.
    """
    ai_message = cast(AIMessage, state["messages"][-1])

    config = copilotkit_customize_config(
        config,
        emit_intermediate_state=[{
            "state_key": "search_progress",
            "tool": "search_for_places",
            "tool_argument": "search_progress",
        }],
    )

    # ^ Previous code

    state["search_progress"] = state.get("search_progress", [])
    queries = ai_message.tool_calls[0]["args"]["queries"]

    for query in queries:
        state["search_progress"].append({
            "query": query,
            "results": [],
            "done": False
        })

    await copilotkit_emit_state(config, state) # [!code ++]

    # ...
```

Now the state of our search will be emitted through the `search_progress` state key to CopilotKit! However, we still need to update this
state as we receive results from our search.

```python title="agent/travel/search.py"
# ...
async def search_node(state: AgentState, config: RunnableConfig):
    """
    The search node is responsible for searching the for places.
    """
    ai_message = cast(AIMessage, state["messages"][-1])
  
    config = copilotkit_customize_config(
        config,
        emit_intermediate_state=[{
            "state_key": "search_progress",
            "tool": "search_for_places",
            "tool_argument": "search_progress",
        }],
    )
  
    state["search_progress"] = state.get("search_progress", [])
    queries = ai_message.tool_calls[0]["args"]["queries"]
  
    for query in queries:
        state["search_progress"].append({
            "query": query,
            "results": [],
            "done": False
        })
  
    await copilotkit_emit_state(config, state) 

    # ^ Previous code

    places = []
    for i, query in enumerate(queries):
        response = gmaps.places(query)
        for result in response.get("results", []):
            place = {
                "id": result.get("place_id", f"{result.get('name', '')}-{i}"),
                "name": result.get("name", ""),
                "address": result.get("formatted_address", ""),
                "latitude": result.get("geometry", {}).get("location", {}).get("lat", 0),
                "longitude": result.get("geometry", {}).get("location", {}).get("lng", 0),
                "rating": result.get("rating", 0),
            }
            places.append(place)
        state["search_progress"][i]["done"] = True
        await copilotkit_emit_state(config, state) # [!code ++]

    state["search_progress"] = []
    await copilotkit_emit_state(config, state) # [!code ++]

    # ...

```
</Step>
</Steps>

## Recieving and rendering the manaully emitted state

Now that we are manually emitting the state of our search, we can recieve and render that state in the UI. To do this, 
we'll be using the [useCoAgentStateRender](/reference/hooks/useCoAgentStateRender) function in our `use-trips.tsx` hook.


All we need to do is tell CopilotKit to conditionally render the `search_progress` state key through the `useCoAgentStateRender` hook.

```tsx title="ui/lib/hooks/use-trips.tsx"
// ...
import { useCoAgent } from "@copilotkit/react-core"; // [!code --] 
import { useCoAgent, useCoAgentStateRender } from "@copilotkit/react-core"; // [!code ++]
import { SearchProgress } from "@/components/SearchProgress"; // [!code ++]

export const TripsProvider = ({ children }: { children: ReactNode }) => {
  // ...
  
  const { state, setState } = useCoAgent<AgentState>({
    name: "travel",
    initialState: {
      trips: defaultTrips,
      selected_trip_id: defaultTrips[0].id,
    },
  });

  // [!code ++:10]
  useCoAgentStateRender<AgentState>({
    name: "travel",
    render: ({ state }) => {
      if (state.search_progress) {
        return <SearchProgress progress={state.search_progress} />
      }
      return null;
    },
  });

  // ...
}

```

The `<SearchProgress />` component is a custom component that was created for you ahead of time. If you'd like to
learn more about it feel free to check it out in `ui/components/SearchProgress.tsx`!

<Callout>
One other thing done for you ahead of time is that the `search_progress` key is already present in the `AgentState` type. You
can look at that type in `ui/lib/types.ts`.
</Callout>

Give it a try! Ask the agent to search for places and we'll see the progress of each search as it comes in. 

The final step is to add human in the loop to the application to allow the user to approve or reject mutative actions the 
agent wants to perform.


================================================
FILE: docs/content/docs/coagents/tutorials/ai-travel-app/step-6-human-in-the-loop.mdx
================================================
---
title: "Step 6: Human in the Loop"
---

Now its time to add human in the loop to the application. This will allow the user to approve, reject, or modify mutative actions the 
agent wants to perform. For simplicity, we'll be only implementing approve and reject actions in this step.

Our plan is to add a "breakpoint" to the application. This is a LangGraph concept that will force the agent to pause and wait for the 
human approval before continuing execution. 

<Callout>
You can learn more about breakpoints [here](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/?h=breakp).
</Callout>

The breakpoint will then be communicated to our front-end which we'll use to render and take the user's decision. Finally, the user's
decision will be communicated back to the agent and execution will continue.

All together, this process will look like this:

<Frame>
    <img src="/images/coagents/coagents-hitl-infographic.png" alt="Human in the loop" />
</Frame>

If you'd like to learn even more about human in the loop before proceeding, checkout our [Human in the Loop concept guide](/coagents/human-in-the-loop).

Otherwise, let's get started!

<Steps>
<Step>
## Add the breakpoint to the `trips_node`

The way that this LangGraph has been implemented allows for easy human in the loop integration. Essentially, we have a `trips_node`
that serves as a proxy to the `perform_trips_node`. This means that we can block entrance to the `perform_trips_node` by adding a breakpoint
to the `trips_node`. This will then force the agent to pause and wait for the human to approve the action before execution can continue.

To add a breakpoint to the agent, we'll be editing the graph definition in the `agent/travel/agent.py` file.

At the very bottom of the file, add the following line to the `compile` function:
```python title="agent/travel/agent.py"
# ...

graph = graph_builder.compile(
    checkpointer=MemorySaver(),
    interrupt_after=["trips_node"], # [!code ++]
)
```

This will force the agent to pause execution at the `trips_node` and wait for the human to approve the action before continuing.
</Step>
<Step>
## Update the perform_trips_node node to properly handle the user's decision

Prior to this step, entrance to the `perform_trips_node` was standard. We would recieve the requested tool call, call the appropriate
tool, edit the message state to reflect the tool call results, and then move on to the next node.

However, this will no longer work since we've added a breakpoint to the `trips_node`. In a future step, we'll be utilizing this
breakpoint to render a UI to the user for approval or rejection. Their decision will be communicated back via the message state.

In this step, we'll be retrieving that decison from the message state and acting accordingly.

First, let's grab the tool call message and the tool call being requested.

```python title="agent/travel/trips.py"
# ...

async def perform_trips_node(state: AgentState, config: RunnableConfig):
    """Execute trip operations"""
    ai_message = state["messages"][-1] # [!code --]
    ai_message = cast(AIMessage, state["messages"][-2]) # [!code ++]
    tool_message = cast(ToolMessage, state["messages"][-1]) # [!code ++]

    # ...
```

Now, let's add a conditional that will check the user's decision and act accordingly.

```python title="agent/travel/trips.py"
from copilotkit.langchain import copilotkit_emit_message # [!code ++]

# ...
async def perform_trips_node(state: AgentState, config: RunnableConfig):
    """Execute trip operations"""
    ai_message = cast(AIMessage, state["messages"][-2])
    tool_message = cast(ToolMessage, state["messages"][-1])

    # [!code ++:8]
    if tool_message.content == "CANCEL":
      await copilotkit_emit_message(config, "Cancelled operation of trip.")
      return state
    
    # handle the edge case where the AI message is not an AIMessage or does not have tool calls, should never happen.
    if not isinstance(ai_message, AIMessage) or not ai_message.tool_calls:
        return state
    
    # ...
```

In this case, we are checking if the user decided to cancel the operation. If so, we emit a message to the UI and return the state. Any
other decision returned will result in the requested actions being performed.

</Step>
<Step>
## Emitting the tool calls
In order for the front-end to recieve the breakpoint and take the user's decision, we'll need to emit the tool calls that the agent is requesting.
To do this, we'll be editing the `chat_node` in the `chat.py` file.
```python title="agent/travel/chat.py"
# ...
from copilotkit.langchain import copilotkit_customize_config # [!code ++]
async def chat_node(state: AgentState, config: RunnableConfig):
    """Handle chat operations"""
    # [!code ++:5]
    config = copilotkit_customize_config(
        config,
        emit_tool_calls=["add_trips", "update_trips", "delete_trips"],
    )
    # ...
```
<Callout>
We don't want to just set True here because doing so will emit all tool calls. By specifying these, we hand are handing off tool
handling to CopilotKit. If, for example, `search_for_places` was called here then it would break the state of tool calls.
</Callout>
With that, our work on the agent is complete and we are ready to update the front-end to properly take and communicate the user's decision.

</Step>
<Step>

## Rendering the tool calls and taking the user's decision

Now we need to update the front-end to render the tool calls and emit the user's decision back to the agent. To do this, 
we'll be adding `useCopilotAction` hooks for each tool call with the `renderAndWait` option.

```typescript title="ui/lib/hooks/use-trips.tsx"
// ...
import { AddTrips, EditTrips, DeleteTrips } from "@/components/humanInTheLoop"; // [!code ++]
import { useCoAgent, useCoAgentStateRender } from "@copilotkit/react-core"; // [!code --]
import { useCoAgent, useCoAgentStateRender, useCopilotAction } from "@copilotkit/react-core"; // [!code ++]
// ...

export const TripsProvider = ({ children }: { children: ReactNode }) => {
  // ...

  useCoAgentStateRender<AgentState>({
    name: "travel",
    render: ({ state }) => {
      return <SearchProgress progress={state.search_progress} />
    },
  });

  // [!code ++:42]
  useCopilotAction({ 
    name: "add_trips",
    description: "Add some trips",
    parameters: [
      {
        name: "trips",
        type: "object[]",
        description: "The trips to add",
        required: true,
      },
    ],
    renderAndWait: AddTrips,
  });

  useCopilotAction({
    name: "update_trips",
    description: "Update some trips",
    parameters: [
      {
        name: "trips",
        type: "object[]",
        description: "The trips to update",
        required: true,
      },
    ],
    renderAndWait: EditTrips,
  });

  useCopilotAction({
    name: "delete_trips",
    description: "Delete some trips",
    parameters: [
      {
        name: "trip_ids",
        type: "string[]",
        description: "The ids of the trips to delete",
        required: true,
      },
    ],
    renderAndWait: (props) => DeleteTrips({ ...props, trips: state.trips }),
  });

  // ...
```

With that, our front-end is now ready to render the tool calls and take the user's decision. One thing we glossed over
are all of the imported `humanInTheLoop` components. They're provided for the convenience of this tutorial, but we should
note one very important thing - how they send the user's decision back to the agent.

</Step>
<Step>
## (optional) Understanding the `humanInTheLoop` components

Let's look at the `DeleteTrips` component as an example, but the same logic applies to the `AddTrips` and `EditTrips` components.

```tsx title="ui/lib/components/humanInTheLoop/DeleteTrips.tsx"
import { Trip } from "@/lib/types";
import { PlaceCard } from "@/components/PlaceCard";
import { X, Trash } from "lucide-react";
import { ActionButtons } from "./ActionButtons"; // [!code highlight]
import { RenderFunctionStatus } from "@copilotkit/react-core";

export type DeleteTripsProps = {
  args: any;
  status: RenderFunctionStatus;
  handler: any;
  trips: Trip[];
};

export const DeleteTrips = ({ args, status, handler, trips }: DeleteTripsProps) => {
  const tripsToDelete = trips.filter((trip: Trip) => args?.trip_ids?.includes(trip.id));

  return (
    <div className="space-y-4 w-full bg-secondary p-6 rounded-lg">
    <h1 className="text-sm">The following trips will be deleted:</h1>
      {status !== "complete" && tripsToDelete?.map((trip: Trip) => (
        <div key={trip.id} className="flex flex-col gap-4">
          <>
            <hr className="my-2" />
            <div className="flex flex-col gap-4">
            <h2 className="text-lg font-bold">{trip.name}</h2>
            {trip.places?.map((place) => (
              <PlaceCard key={place.id} place={place} />
            ))}
            </div>
          </>
        </div>
      ))}
      { status !== "complete" && (
        /* [!code highlight:7] */
        <ActionButtons
          status={status} 
          handler={handler} 
          approve={<><Trash className="w-4 h-4 mr-2" /> Delete</>} 
          reject={<><X className="w-4 h-4 mr-2" /> Cancel</>} 
        />
      )}
    </div>
  );
};
```

As you can see, this is a fairly standard component that renders the trips that will be deleted. The important part is the `ActionButtons`
component. Let's take a look at it.

```tsx title="ui/lib/components/humanInTheLoop/ActionButtons.tsx"
import { RenderFunctionStatus } from "@copilotkit/react-core";
import { Button } from "../ui/button";

export type ActionButtonsProps = {
    status: RenderFunctionStatus;
    handler: any;
    approve: React.ReactNode;
    reject: React.ReactNode;
}

export const ActionButtons = ({ status, handler, approve, reject }: ActionButtonsProps) => (
  <div className="flex gap-4 justify-between">
    <Button 
      className="w-full"
      variant="outline"
      disabled={status === "complete" || status === "inProgress"} 
      onClick={() => handler?.("CANCEL")} // [!code highlight]
    >
      {reject}
    </Button>
    <Button 
      className="w-full"
      disabled={status === "complete" || status === "inProgress"} 
      onClick={() => handler?.("SEND")} // [!code highlight]
    >
      {approve}
    </Button>
  </div>
);
```

The important piece here is that the `onClick` handlers emit the user's decision back to the agent. If the user clicks the `Delete` button
then the `handler?.("SEND")` is called. If the user clicks the `Cancel` button then the `handler?.("CANCEL")` is called. This is how the 
agent recieves the user's decision. 

<Callout>
If you wanted to implement a more complex UI that allows for the human to edit the tool call arguments before sending them back to the agent,
you could do so by adding additional logic to the `onClick` handlers and the agent's handling of the tool call.
</Callout>

</Step>
</Steps>

With that, we've now completed the human in the loop implementation! Try asking the agent to add, edit, or delete some trips and see it in
action.


================================================
FILE: docs/content/docs/coagents/videos/meta.json
================================================
{
  "title": "Videos",
  "pages": [
    "research-canvas",
    "perplexity-clone"
  ]
}


================================================
FILE: docs/content/docs/coagents/videos/perplexity-clone.mdx
================================================
---
title: "Video: Perplexity Clone" 
icon: "lucide/Search"
---
import { YouTubeVideo } from "@/components/react/youtube-video";

<YouTubeVideo videoId="HvzmwwDF4aM" defaultPlaybackRate={1.25} />

This is a demo of a Perplexity-style search engine using **CopilotKit and LangGraph**.
Combining these technologies enables agentic copilots or, put short, **CoAgents**, which allow for the creation of human in the loop AI agents.
Instead of relying entirely on AI, CoAgents let users step in to guide or adjust the search as needed.

In this demo, the CoAgent will come up with a list of topics to research, and combine the results
into a comprehensive answer, including references to the sources used.

The agent state is streamed live to the frontend, so that the user can see the work progressing.

Both the LangGraph and the CopilotKit specific code for this demo is [available
on GitHub](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-ai-researcher).



================================================
FILE: docs/content/docs/coagents/videos/research-canvas.mdx
================================================
---
title: "Video: Research Canvas"
icon: "lucide/BookOpen"
---
import { YouTubeVideo } from "@/components/react/youtube-video";

<YouTubeVideo videoId="0b6BVqPwqA0" defaultPlaybackRate={1.25} />

This is a step by step walkthrough of building an Agent-Native Research canvas using **CopilotKit and LangGraph**.

You can run the app here: https://examples-coagents-research-canvas-ui.vercel.app/

The full source code is [available on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-research-canvas/readme.md).




================================================
FILE: docs/content/docs/crewai-crews/agentic-chat-ui.mdx
================================================
---
title: Crew-based Chat
icon: "lucide/SendHorizontal"
description: Create interactive chat experiences with CrewAI crews.
---

import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import ComponentExamples from "@/snippets/component-examples.mdx";
import { UserIcon, PaintbrushIcon, WrenchIcon, RepeatIcon } from "lucide-react";

<video
  src="/images/coagents/agentic-chat-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews)
  repo with various Copilot UI components applied to it!
</Callout>

## What is this?
CopilotKit allows you to chat with an LLM that has the ability to kick off your crews. This is a great way to enable natural conversations that flow
in and out of your crews. In addition to this, this chat serves as a shared communication channel for your executing crews to report their thoughts,
progress, and results.

If you've gone through the [getting started guide](/crewai-crews/quickstart/crewai) **you've already got this working**!

## How does this work?
CopilotKit provides a *"llm-in-the-middle"* chat that will communicate with your user to determine which Crew to kick off and gather the necessary input data
in order to kick off the Crew.

Once the Crew is kicked-off, CopilotKit will handle streaming thoughts, progress, interrupts, and results back to the user.

## When should I use this?
The crew-based chat interface is ideal when you need to:

- **Enable natural conversations with complex crews** - Let users interact with multiple specialized Crews through a single chat interface
- **Support long-running crew tasks** - Provide real-time feedback during research, analysis, and other time-intensive operations
- **Create guided experiences** - Allow your CrewAI crew to ask for inputs, provide outputs, and maintain context throughout an interaction

## Implementation

CopilotKit provides a variety of different batteries-included components to choose from when creating Crew-enabled applications. They scale
from simple chat UIs to completely custom interfaces.

<ComponentExamples components={props.components} />



================================================
FILE: docs/content/docs/crewai-crews/frontend-actions.mdx
================================================
---
title: Frontend Actions
icon: "lucide/Wrench"
description: Create frontend actions and use them within your agent.
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

<video
  src="/images/frontend-actions-demo.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## When should I use this?

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## Implementation

<Steps>
    <Step>
        ### Setup CopilotKit

        To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here.

        Check out our [getting started guide](/crewai-crews/quickstart/crewai) and come back here when you're setup!
    </Step>

    <Step>
        ### Create a frontend action

        First, you'll need to create a frontend action using the [useCopilotAction](/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
        that says hello to the user.

        ```tsx title="page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core" // [!code highlight]

        export function Page() {
          // ...

          // [!code highlight:16]
          useCopilotAction({
            name: "sayHello",
            description: "Say hello to the user",
            available: "remote", // optional, makes it so the action is *only* available to the agent
            parameters: [
              {
                name: "name",
                type: "string",
                description: "The name of the user to say hello to",
                required: true,
              },
            ],
            handler: async ({ name }) => {
              alert(`Hello, ${name}!`);
            },
          });

          // ...
        }
        ```
    </Step>
    <Step>
        ###  Frontend actions are made available automatically to Crews
        We don't need to do anything special to access these frontend actions from within a CrewAI Crew, since they're automatically available.
    </Step>
    <Step>
        ### Give it a try!
        You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.
    </Step>

</Steps>



================================================
FILE: docs/content/docs/crewai-crews/index.mdx
================================================
---
title: Introduction
icon: "lucide/Sparkles"
description: Build Agent-Native Applications (ANAs) powered by CopilotKit and CrewAI Flows.
---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { TelescopeIcon } from "lucide-react";
import { FaDiscord } from "react-icons/fa";
import Link from "next/link";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import {
  LuPlane,
  LuBookOpen,
  LuLightbulb,
  LuLayoutTemplate,
  LuBrainCog,
  LuUserCog,
  LuWand2,
  LuPlay,
  LuMessageSquare,
  LuWrench,
} from "react-icons/lu";
import { CoAgentsExamples } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { FaSync } from "react-icons/fa";
import { Socials } from "@/components/react/socials";

<div className="p-4 mb-6 rounded-lg bg-orange-50 dark:bg-orange-950 border border-orange-200 dark:border-orange-800">
  <div className="flex items-center gap-2 mb-2">
    <TelescopeIcon className="h-5 w-5 text-orange-500 dark:text-orange-300" />
    <h3 className="text-lg font-semibold text-orange-700 dark:text-orange-300">CrewAI Overview</h3>
  </div>
  <p className="text-orange-700 dark:text-orange-300">
    Visit the <a href="https://v0-crew-land.vercel.app/" target="_blank" rel="noopener noreferrer" className="font-medium underline underline-offset-4 decoration-orange-400 dark:decoration-orange-500 hover:text-orange-600 dark:hover:text-orange-200">CrewAI Overview Page</a> to learn more about CrewAI's capabilities and features.
  </p>
</div>

# Copilot Infrastructure for CrewAI Crews

Full user-interaction and rendering infrastructure for your [Crews](https://docs.crewai.com/), right out of the box. Allow your 
Crew's thoughts, progress, and results to be rendered in and take control of your application's UI.

## Building blocks of a CoAgent

All of the features you'll need to deeply integrate your Crews into your application.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuMessageSquare className="text-orange-500 dark:text-orange-300" />}
    title="Crew-based Chat"
    description="In-app chat to kickoff, render and analyze the result of your Crews."
    href="/crewai-crews/agentic-chat-ui"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<FaSync className="text-orange-500 dark:text-orange-300" />}
    title="Shared State"
    description="Render your Crew's thoughts, progress, and results in real-time."
    href="/crewai-crews/shared-state"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuLayoutTemplate className="text-orange-500 dark:text-orange-300" />}
    title="Generative UI"
    description="UI based on what your Crew is thinking and doing."
    href="/crewai-crews/generative-ui"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuWand2 className="text-orange-500 dark:text-orange-300" />}
    title="Frontend Tools"
    description="Give your Crew the ability to take action directly in your application."
    href="/crewai-crews/frontend-actions"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuUserCog className="text-orange-500 dark:text-orange-300" />}
    title="Multi-Agent Coordination"
    description="Use AI to route between multiple Crews or agents based on the user's request."
    href="/crewai-crews/multi-agent-flows"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuUserCog className="text-orange-500 dark:text-orange-300" />}
    title="Human-in-the-Loop"
    description="Set smart checkpoints where humans can guide your Crews."
    href="/crewai-crews/human-in-the-loop"
  />
</Cards>

## Ready to get started?

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlay className="text-orange-500 dark:text-orange-300" />}
    title="Quickstart"
    description="Learn how to build your first CoAgent in 10 minutes."
    href="/crewai-crews/quickstart/crewai"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<TelescopeIcon className="text-orange-500 dark:text-orange-300" />}
    title="Feature Overview"
    description="Try the key features of CoAgents powered by CrewAI Crews."
    href="https://demo-viewer-five.vercel.app/"
    target="_blank"
  />
</Cards>

## Common Questions

Have a question about CoAgents? You're in the right place!

<Accordions>
<Accordion title="Can you explain what a CoAgent is in more detail?">
Sure! CoAgents are what we call "agentic copilots". Well, what's an agentic copilot then?

Think of a Copilot as a simple and fully LLM controlled assistant that has relatively limited capabilities. An Agentic Copilot then is a copilot
that has been enhanced with the ability to use CrewAI agents to perform more complex tasks. This is an extremely powerful way to build AI
powered applications because it gives you, the developer, the ability to control the agent's behavior in a deterministic way while still letting
the agent do its magic.

For more on this topic, checkout our [agentic copilot](/crewai-crews/concepts/agentic-copilots) concept page.

</Accordion>
</Accordions>



================================================
FILE: docs/content/docs/crewai-crews/meta.json
================================================
{
  "title": "Crews",
  "root": true,
  "pages": [
    "index",
    "quickstart",
    "[lucide/Telescope][Feature Viewer](https://demo-viewer-five.vercel.app/ )",
    "---Guides---",
    "agentic-chat-ui",
    "generative-ui",
    "human-in-the-loop",
    "shared-state",
    "frontend-actions",
    "multi-agent-flows",
    "advanced",
    "components",
    "---Learn---",
    "...concepts"
  ]
}



================================================
FILE: docs/content/docs/crewai-crews/multi-agent-flows.mdx
================================================
---
title: Multi-Agent Flows
description: Use multiple agents to orchestrate complex flows.
icon: "lucide/Users"
---

import { Callout } from "fumadocs-ui/components/callout";

## What are Multi-Agent Flows?

When building agentic applications, you often want to orchestrate complex flows together that require the coordination of multiple
agents. This is traditionally called multi-agent orchestration.

## When should I use this?

Multi-agent flows are useful when you want to orchestrate complex flows together that require the coordination of multiple agents. As
your agentic application grows, delegation of sub-tasks to other agents can help you scale key pieces of your application.

- Divide context into smaller chunks
- Delegate sub-tasks to other agents
- Use a single agent to orchestrate the flow

## How does CopilotKit support this?

CopilotKit can be used in either of two distinct modes: **Router Mode**, or **Agent Lock**. By default, CopilotKit
will use Router Mode, leveraging your defined LLM to route requests between agents.

### Router Mode (default)

Router Mode is enabled by default when using CoAgents. To use it, specify a runtime URL prop in the `CopilotKit` provider component and omit the `agent` prop, like so:

```tsx
<CopilotKit runtimeUrl="<copilot-runtime-url>">
  {/* Your application components */}
</CopilotKit>
```

In router mode, CopilotKit acts as a central hub, dynamically selecting and _routing_ requests between different agents or actions based on the user's input. This mode can be good for chat-first experiences where an LLM chatbot is the entry point for a range of interactions, which can stay in the chat UI or expand to include native React UI widgets.

In this mode, CopilotKit will intelligently route requests to the most appropriate agent or action based on the context and user input.

<Callout type="warn">
  Router mode requires that you set up an LLM adapter. See how in ["Set up a
  copilot
  runtime"](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint)
  section of the docs.
</Callout>

### Agent Lock Mode

To use Agent Lock Mode, specify the agent name in the `CopilotKit` component with the `agent` prop:

```tsx
// [!code word:agent]
<CopilotKit runtimeUrl="<copilot-runtime-url>" agent="<the-name-of-the-agent>">
  {/* Your application components */}
</CopilotKit>
```

In this mode, CopilotKit is configured to work exclusively with a specific agent. This mode is useful when you want to focus on a particular task or domain. Whereas in Router Mode the LLM and CopilotKit's router are free to switch between agents to handle user requests, in Agent Lock Mode all requests will stay within a single workflow graph, ensuring precise control over the workflow.

Use whichever mode works best for your app experience! Also, note that while you cannot nest `CopilotKit` providers, you can use different agents or modes in different areas of your app — for example, you may want a chatbot in router mode that can call on any agent or tool, but may also want to integrate one specific agent elsewhere for a more focused workflow.



================================================
FILE: docs/content/docs/crewai-crews/quickstart.mdx
================================================
---
title: Quickstart
description: Turn your CrewAI Crews into an agent-native application in 10 minutes.
icon: "lucide/Play"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { SquareTerminal, SquareChartGantt } from "lucide-react";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import { FaPython, FaJs, FaCloud } from "react-icons/fa";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureRemoteEndpointLangGraph from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotKitCloudCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";
import CloudCopilotKitProvider from "@/snippets/coagents/cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/coagents/self-host-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeLangGraphEndpoint from "@/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx";
import SelfHostingCopilotRuntimeStarter from "@/snippets/self-hosting-copilot-runtime-starter.mdx";
import SelfHostingRemoteEndpoints from "@/snippets/self-hosting-remote-endpoints.mdx";
import {
  UserIcon,
  PaintbrushIcon,
  WrenchIcon,
  RepeatIcon,
  ServerIcon,
} from "lucide-react";
import { SiCrewai } from "@icons-pack/react-simple-icons";
import CopilotUI from "@/snippets/copilot-ui.mdx";
import CrewQuickStart from "@/snippets/crew-quickstart.mdx";

## Prerequisites

Before you begin, you'll need the following:

- [**OpenAI API key**](https://platform.openai.com/api-keys)
- [**Enterprise Crew**](https://docs.crewai.com/enterprise/introduction)

## Getting started

<Steps>
    <TailoredContent
        className="step"
        id="cli"
        header={
            <div>
                <p className="text-xl font-semibold">How do you want to get started?</p>
                <p className="text-base">
                    Bootstrap with the new <span className="text-indigo-500 dark:text-indigo-400">CopilotKit CLI (Beta)</span> or code along with us to get started.
                </p>
            </div>
        }
    >
        <TailoredContentOption
            id="use-cli"
            title="Use the CopilotKit CLI (NextJS only)"
            description="I have a Next.js application and want to get started quickly."
            icon={<SquareTerminal />}
        >
            <Step>
                ### Run the CLI
                Just run this following command in your Next.js application to get started!

                <Accordions>
                    <Accordion title="Don't have a Next.js application?">
                        No problem! Just use `create-next-app` to make one quickly.
                        ```bash
                        npx create-next-app@latest
                        ```
                    </Accordion>
                </Accordions>

                ```bash
                npx copilotkit@latest init -m CrewAI --crew-type Crews
                ```
            </Step>

        </TailoredContentOption>
        <TailoredContentOption
            id="do-it-manually"
            title="Code along"
            description="I want to deeply understand what's happening under the hood or don't have a Next.js application."
            icon={<SquareChartGantt />}
        >
            <Step>
                ### Connect to Copilot Cloud
                1. Go to [Copilot Cloud](https://cloud.copilotkit.ai), sign in and click Get Started
                2. Add your OpenAI API key to the "Provide OpenAI API Key" section
                3. Click "Add Remote Endpoint" and fill in the details of your Crew. Note: If your Agent Name contains multiple words, use underscores (`_`) as separators.
                4. Click "Save Endpoint"
                5. Copy the Copilot Cloud Public API Key

                <img src="/images/copilot-cloud/crew-cpk-setup.gif" alt="CrewAI Copilot Setup" className="rounded-lg shadow-xl mt-4" />
            </Step>

            <Step>
                ## Setup the CopilotKit Provider
                The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.
                <CloudCopilotKitProvider components={props.components} />
            </Step>
            <Step>
                ## Choose a Copilot UI
                You are almost there! Now it's time to setup your Copilot UI.
                <CopilotUI components={props.components} />
            </Step>
            <Step>
                ## Create a Crew-Quickstart component
                Place the following snippet in your **main page** (e.g. `page.tsx` in Next.js) or wherever you want to use CopilotKit. It simply imports the `QuickstartCrew` component from our **crew-quickstart.tsx** file and renders it.

                ```tsx title="page.tsx"
                "use client";
                import React from "react";
                import useCrewQuickstart from "./use-crew-quickstart";

                export default function YourApp() {
                useCrewQuickstart({
                    crewName: "<REPLACE_WITH_YOUR_CREW_NAME>",
                    /**
                     * List of input required to start your crew (location e.g)
                    */
                    inputs: ["location"]
                })
                return (
                    <>
                    {/* Existing markup */}
                    </>
                );
                }
                ```
                <CrewQuickStart components={props.components} />
            </Step>
        </TailoredContentOption>
    </TailoredContent>
    <Step>
        ### 🎉 Talk to your agent!
        Congrats! You've successfully integrated your CrewAI Enterprise agent with CopilotKit.
        Try talking to your Copilot. Chat with it to provide the information needed to run your Crew from your app.

        You can also check out our [demo](https://crew-ai-enterprise-demo.vercel.app) to see everything in action.
    </Step>

</Steps>

---

## What's next?

You've now got a CrewAI Crew running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

<Cards>
  <Card
    title="Implement Human in the Loop"
    description="Allow your users and agents to collaborate together on tasks."
    href="/crewai-crews/human-in-the-loop"
    icon={<UserIcon />}
  />
  <Card
    title="Utilize the Shared State"
    description="Learn how to synchronize your agent's state with your UI's state, and vice versa."
    href="/crewai-crews/shared-state"
    icon={<RepeatIcon />}
  />
  <Card
    title="Add some generative UI"
    description="Render your agent's progress and output in the UI."
    href="/crewai-crews/generative-ui"
    icon={<PaintbrushIcon />}
  />
  <Card
    title="Setup frontend actions"
    description="Give your agent the ability to call frontend tools, directly updating your application."
    href="/crewai-crews/frontend-actions"
    icon={<WrenchIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/crewai-crews/advanced/exit-agent.mdx
================================================
---
title: "Exiting the agent loop"
icon: "lucide/DoorOpen"
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

After your agent has finished running a crew, it will automatically exit the agent loop

Exiting the agent has different effects depending on mode:

- **Router Mode**: Exiting the agent hands responsibility for handling input back to the router, which can initiate chat, call actions, other agents, etc. The router can return to this agent later (starting a new loop) to satisfy a user request.

- **Agent Lock Mode**: Exiting the agent restarts the workflow loop for the current agent.



================================================
FILE: docs/content/docs/crewai-crews/advanced/meta.json
================================================
{
    "title": "Advanced",
    "icon": "lucide/Cog"
}


================================================
FILE: docs/content/docs/crewai-crews/concepts/agentic-copilots.mdx
================================================
---
title: Agentic Copilots
description: Agentic copilots provide you with advanced control and orchestration over your agents.
icon: lucide/Bot
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content";
import { BsFillCloudHaze2Fill as CloudIcon } from "react-icons/bs";
import { FaServer as SelfHostIcon } from "react-icons/fa6";
import { SiLangchain } from "react-icons/si";
import { LinkIcon } from "lucide-react";
import {
  RocketIcon,
  GraduationCapIcon,
  CodeIcon,
  VideoIcon,
} from "lucide-react";

Before we dive into what agentic copilots are, help us help you by telling us your level of experience with CrewAI. We'll explain things in a way that best suits your experience level.

<TailoredContent id="experience" defaultOptionIndex={0}>
    <TailoredContentOption 
        id="new"
        title="I'm new to CrewAI" 
        description="Help me understand what agentic copilots are, where CrewAI fits in, and how to get started." 
        icon={<img src="/images/copilotkit-logo.svg" width={7} height={7} />}
    >
        <Frame>
            <img src="/images/coagents/SharedStateCoAgents.gif" alt="CoAgents Shared State" className="mt-0 mb-12"/>
        </Frame>

        ### What are Agents?
        AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from
        simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

        As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized
        frameworks like CrewAI become essential.

        ### What is CrewAI?
        CrewAI is a framework that gives you precise control over AI agents. CrewAI flows allow developers to combine and coordinate coding tasks and Crews efficiently,
        providing a robust framework for building sophisticated AI automations.

        ### What are Agentic Copilots?
        Agentic copilots are how CopilotKit brings CrewAI agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that
        understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ)
        for quick implementation, Agentic copilots give you CrewAI's full orchestration capabilities when you need more control over your agent's behavior.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ### When should I use CopilotKit's CoAgents?
        You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [CrewAI](https://crewai.com/).
        With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

        We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.

        The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's
        functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
        up to 100% of the Copilot's tasks (see [agent-lock mode](/crewai-crews/multi-agent-flows) for the 100% case).

        ### Examples
        An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-research-canvas).

        More specifically, it demonstrates how CoAgents allow for AI driven experiences with:
        - Precise state management across agent interactions
        - Sophisticated multi-step reasoning capabilities
        - Seamless orchestration of multiple AI tools
        - Interactive human-AI collaboration features
        - Real-time state updates and progress streaming

        ## Next Steps

        Want to get started? You have some options!

        <Cards>
            <Card
                title="Build your first CoAgent"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/crewai-crews/quickstart/crewai"
                icon={<RocketIcon />}
            />
            <Card
                title="Learn more CoAgent concepts"
                description="Learn more about the concepts used to talk about CoAgents and how to use them."
                href="/crewai-crews/concepts/terminology"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Read the reference documentation"
                description="Just here for some reference? Checkout the reference documentation for more details."
                href="/crewai-crews/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="See examples of CoAgents in action"
                description="Checkout our video examples of CoAgents in action."
                href="/crewai-crews/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>
    <TailoredContentOption
        id="intermediate"
        title="I'm already using CrewAI"
        description="Help me understand what agentic copilots are, what Copilotkit does to integrate with CrewAI, and how to get started."
        icon={<SiLangchain />}
    >

        <Frame className="mt-0 mb-12">
            <img
                src="/images/CoAgents.gif"
                alt="CoAgents demonstration"
                className="w-auto"
            />
        </Frame>

        CrewAI is a framework for building deeply customizable AI agents.

        CopilotKit's Agentic Copilots is infrastructure for in-app agent-user interaction, i.e. for transforming agents from autonomous processes to user-interactive 'virtual colleagues' that live inside applications.

        Any CrewAI-based agent can be transformed into an Agentic Copilot with a minimal amount
        of effort to get industry leading agentic UX such as:
        - Shared state between the agent and the application.
        - Intermediate result and state progress streaming
        - Human-in-the-loop collaboration
        - Agentic generative UI
        - And more!

        All of these features are essential to delight instead of frustrate your users with AI features.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ## Next Steps
        Want to get started? You have some options!

        <Cards>
            <Card
                title="Quickstart"
                description="Integrate your CrewAI agent with CopilotKit in a few minutes."
                href="/crewai-crews/quickstart/crewai"
                icon={<RocketIcon />}
            />
            <Card
                title="Tutorial: AI Travel App"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/crewai-crews/tutorials/ai-travel-app/overview"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Reference"
                description="Learn more about the terms used to talk about CoAgents and how to use them."
                href="/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="Examples"
                description="Checkout our video examples of CoAgents in action."
                href="/crewai-crews/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>

</TailoredContent>



================================================
FILE: docs/content/docs/crewai-crews/concepts/copilotkit-stream.mdx
================================================
---
title: Streaming and Tool Calls
description: CoAgents support streaming your messages and tool calls to the frontend.
---

If you'd like to stream messages from your CrewAI agents you can utilize our Copilotkit SDK which provides a collection
of functions and utilities for interacting with the agent's state or behavior. This allows you to choose how messages and
tool calls are emitted and streamed to the frontend.

## Message Streaming

If you just call the LiteLLM `completion` function from your CrewAI agent, messages will not be streamed by default.
To stream messages, wrap the `completion` function with the `copilotkit_stream` function. This will enable streaming
of both the messages and tool calls to the frontend.

```python
response = copilotkit_stream(
    completion(
        model="openai/gpt-4o",
        messages=[
            {"role": "system", "content": my_prompt},
            *self.state["messages"]
        ],
        stream=True
    )
)
```

For more information on how tool calls are utilized check out our [frontend actions](/crewai-crews/frontend-actions)
documentation.



================================================
FILE: docs/content/docs/crewai-crews/concepts/crewai.mdx
================================================
---
title: CrewAI
description: An agentic framework for building LLM applications that can be used with Copilotkit.
icon: custom/langchain
---

<Frame>
  <img
    src="/images/coagents/coagents-highlevel-overview.png"
    alt="CoAgents High Level Overview"
    className="mb-10"
  />
</Frame>

CrewAI is an agentic framework for building LLM applications that can be used with Copilotkit. CrewAi Flows allow developers
to combine and coordinate coding tasks and Crews efficiently, providing a robust framework for building sophisticated AI automations.

## CoAgents and CrewAI

How do CoAgents extend CrewAI? Let's read the first sentence of their [page on Flows](https://docs.crewai.com/concepts/flows) to understand.

> Flows allow you to create structured, event-driven workflows. They provide a seamless way to connect multiple tasks, manage state, and control the flow of execution in your AI applications.

Let's break down some key terms and understand how they relate to and are implemented by CoAgents.

- **Manage state**: CoAgents have bi-directional state sharing with the agent and UI. This allows for the agent to remember
  information from previous messages and the UI to update the agent with new information. Read more about how state sharing works
  [here](/crewai-crews/shared-state).
- **Multi-actor**: CoAgents allow for multiple agents to interact with each other. Copilotkit acts as the "ground-truth"
  when transitioning between agents. Read more about how multi-actor workflows work [here](/crewai-crews/multi-agent-flows)
  and how messages are managed [here](/crewai-crews/concepts/message-management).
- **LLMs**: CoAgents use large language models to generate responses. This is useful for building applications that need to
  generate natural language responses.

Some additional functionality not mentioned here is:

- **Human in the loop**: CoAgents enabled human review and approval of generated responses. Read more about how this works
  [here](/crewai-crews/human-in-the-loop).
- **Tool calling**: Tool calling is a fundamental building block for agentic workflows. They allow for greater control over what
  the agent can do and can be used to interact with external systems. CoAgents allow you to easily render in-progress
  tool calls in the UI so your users know what's happening. Read more about streaming tool calls [here](/crewai-crews/shared-state/predictive-state-updates).

## Building with Python

You can build CrewAI applications using Python. Check out the [CrewAI docs](https://docs.crewai.com/introduction) for more information.

## CrewAI Enterprise

Turn any crew into an API within seconds
Connect to your apps using hooks, REST, gRPC and more
Get access to templates, custom tools and early UI
Get business support, SLA, private VPC

CrewAI enterprise is a platform for deploying and monitoring CrewAI applications. Read more about it on the
[CrewAI website](https://www.crewai.com/enterprise).

If you want to take the next step to deploy your CrewAI application as an CoAgent, check out our [quickstart guide](/crewai-crews/quickstart/crewai).



================================================
FILE: docs/content/docs/crewai-crews/concepts/message-management.mdx
================================================
---
title: Message flow
icon: lucide/MessageCircle
---

Message management in CoAgents operates with CopilotKit as the "ground truth" for the full chat session.
When an CoAgent session begins, it receives the existing CopilotKit chat history to maintain conversational
continuity across different agents.

<Callout>
  While all of this information is great to know, in most cases you won't need
  to worry about these details to build rich agentic applications. Use the
  information here as a reference when getting really deep into the CoAgent
  internals.
</Callout>

### Can I modify the message history?

You can modify the message history from CrewAI Flows by using the `"messages"` key in the state. For example to remove all messages from the chat history:

```python

def a_flow_function():
    # ...
    self.state["messages"] = []
```

### Can I persist chat history?

Yes! There are a few ways to persist various portions of a chat's history:

- [Threads](/crewai-crews/persistence/threads)
- [Message Persistence](/crewai-crews/persistence/message-persistence)
- [Agent State](/crewai-crews/persistence/loading-agent-state)

## Types of LLM Messages

Modern LLM interactions produce two distinct types of messages:

1. **Communication Messages**: Direct responses and interactions with users
2. **Internal Messages**: Agent "thoughts" and reasoning processes

A well known example of this pattern is OpenAI's o1 model, which has sophisticated reasoning capabilities and thoughts. Its internal
thought processes are presented distinctly from 'communication messages' which are clearly visible to the end-user.

CrewAI agents can operate similarly. An LLM call's output can be considered either a communication message, or an internal message.

### Emitting Messages for long running tasks

Sometimes you'll have a task that is running for a long time, and you want the user to be aware of what's happening.
CopilotKit allows you to accomplish this by using the `copilotkit_emit_message` function.

```python
@listen("route_to_ask_name")
async def ask_name():
    """
    Ask the user for their name.
    """

    content = "Hey, what is your name? 🙂"

    await copilotkit_emit_message(content)

    # something long running here...

    self.state["messages"].append({"role": "assistant", "content": content, "id": str(uuid.uuid4())})

```

Want some more help managing messages in your CoAgent application? Check out our guide on [emitting messages](/crewai-crews/advanced/emit-messages).

## Message Flow

Messages flow between CopilotKit and CrewAI in a specific way:

- All messages from CrewAI are forwarded to CopilotKit
- On a fresh agent invocation, the full CopilotKit chat history is provided to the CrewAI agent as its pre-existing chat history.

When a CoAgent completes its execution, its relevant messages become part of CopilotKit's persistent chat history. This allows for all future agent invocations to get context from the full chat history.



================================================
FILE: docs/content/docs/crewai-crews/concepts/meta.json
================================================
{
  "title": "Concepts",
  "root": true,
  "pages": ["terminology", "agentic-copilots", "crewai", "message-management"]
}



================================================
FILE: docs/content/docs/crewai-crews/concepts/state.mdx
================================================
---
title: Shared State
description: CoAgents maintain a shared state across your UI and agent execution.
---

<Frame className="mb-10">
  <img
    src="/images/coagents/coagents-state-diagram.png"
    alt="Agentic Copilot State Diagram"
  />
</Frame>

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:

- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

The foundation of this system is built on CrewAI's stateful architecture. CrewAI Flow agents maintain their
internal state throughout execution, which you can access via the `useCoAgentState` hook.

### Understanding Predicted State

While your agent runs, you can emit state updates using CopilotKit's `emit_intermediate_state` function, ensuring your UI stays synchronized
with the agent's progress. The emitted state is called the **predicted state** and is used to provide immediate feedback about ongoing
operations.

While the core shared state reflects the agent's current function in the flow, the predicted state provides immediate
feedback about ongoing operations. Accordingly, this creates a more fluid user experience by showing real-time progress before the agent
completes its current task.

When the state is updated (when a function finishes executing), the predicted state is updated with the new state.

For example, when your agent is processing a request, the predicted state might show a loading indicator or partial results, while the actual
shared state updates once the operation is complete.

Want help implementing this into your CoAgent application? Check out our [intermediate state streaming](/crewai-crews/shared-state/predictive-state-updates)
documentation.



================================================
FILE: docs/content/docs/crewai-crews/concepts/terminology.mdx
================================================
---
title: Terminology
icon: lucide/Book
---

Here are the key terms and concepts used throughout CoAgents:

| Term                         | Definition                                                                                                                                                                                         |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agentic Copilot              | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously.                                                                                     |
| CoAgent                      | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot.                                                            |
| Agent State                  | The current data and context maintained by a CrewAI agent during its execution, including both internal state and data that can be synchronized with the frontend UI.                              |
| Agentic Generative UI        | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth                 | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents.            |
| Human-in-the-Loop (HITL)     | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points.                                         |
| Intermediate State           | The updates to agent state that occur during function execution, rather than only at flow transitions, enabling real-time feedback about the agent's progress.                                     |
| [CrewAI](https://crewai.com) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management.                               |
| Agent Lock Mode              | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control.                                    |
| Router Mode                  | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows.                                   |
| State Streaming              | The real-time synchronization of agent state between the backend and frontend, enabling immediate updates to the UI as the agent performs tasks.                                                   |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications.



================================================
FILE: docs/content/docs/crewai-crews/generative-ui/agentic.mdx
================================================
---
title: Agentic Generative UI
icon: "lucide/Bot"
description: Render the state of your agent with custom UI components.
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

<video
  src="/images/coagents/agentic-generative-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews).
</Callout>

## What is this?

All CrewAI Crew agents support `inputs` to the crew and `outputs`, i.e. the overall result generated by the crew. The state of the `outputs` is available to your React frontend by using the `useCoAgent` hook, which allows you to easily render the state of your agent in your application. We call this feature **Agentic Generative UI**.

## When should I use this?

Rendering the outputs of your crew in the UI is essential to provide the user with the end result of a crew run. The agent can provide the result to the user which is then rendered in the UI.

## Implementation

<Steps>
  <Step>
    ### Run and Connect your CrewAI Crew to CopilotKit
    First, you'll need to make sure you have a running CrewAI Crew. If you haven't already done this, you can follow the [getting started guide](/crewai-crews/quickstart/crewai)

    This guide uses the [CoAgents starter repo](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews) as its starting point.

  </Step>
  <Step>
    ### Render state of the agent in the chat
    Now we can utilize `useCoAgentStateRender` to render the state of our agent **in the chat**.

    ```tsx title="app/page.tsx"
    // ...
    import { useCoAgent } from "@copilotkit/react-core";
    // ...

    // Define the state of the agent, should match the state of the agent.
    type AgentState = {
      inputs: {
        topic: string,
        current_year: string,
      },
      outputs: string,
    };

    function YourMainContent() {
      // ...

      // [!code highlight:14]
      // styles omitted for brevity
      const { state } = useCoAgent<AgentState>({
        name: "research_crew",
        initialState: {
          outputs: "Report will appear here",
        },
      });

      return (
        <div
            id="result"
          >
            <MarkdownRenderer content={state.outputs} />
          </div>
      )
    }
    ```

  </Step>
  <Step>
    ### Give it a try!

    You've now created a component that will render the agent's state in the chat.

  </Step>
</Steps>



================================================
FILE: docs/content/docs/crewai-crews/generative-ui/index.mdx
================================================
---
title: Generative UI
icon: "lucide/Paintbrush"
description: Render your agent's behavior with custom UI components.
---

import { CTACards } from "@/components/react/cta-cards";
import { Callout } from "fumadocs-ui/components/callout";
import { Bot, Wrench } from "lucide-react";
import { LuLayoutTemplate } from "react-icons/lu";

<Frame>
  <img
    src="/images/coagents/AgenticGenerativeUI.gif"
    className="my-0"
    alt="Demo of Generative UI showing a meeting scheduling agent"
  />
</Frame>

<Callout>
  This example shows our [Research Canvas](/crewai-crews/videos/research-canvas)
  making use of Generative UI!
</Callout>

## What is Generative UI?

Generative UI lets you render your agent's state, progress, outputs, and tool calls with custom UI components in real-time. It bridges the gap between AI
agents and user interfaces. As your agent processes information and makes decisions, you can render custom UI components that:

- Show loading states and progress indicators
- Display structured data in tables, cards, or charts
- Create interactive elements for user input
- Animate transitions between different states

## How can I use this?

There are two main variants of Generative UI.

<CTACards
  columns={2}
  cards={[
    {
      icon: Bot,
      title: "Agentic",
      description:
        "Render your agent's state, progress, and outputs with custom UI components.",
      href: "/crewai-crews/generative-ui/agentic",
    },
    {
      icon: Wrench,
      title: "Tool-based",
      description: "Render your agent's tool calls with custom UI components.",
      href: "/crewai-crews/generative-ui/tool-based",
    },
  ]}
/>



================================================
FILE: docs/content/docs/crewai-crews/generative-ui/tool-based.mdx
================================================
---
title: Tool-based Generative UI
icon: "lucide/Wrench"
description: Render your agent's tool calls with custom UI components.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";

<video
  src="/images/coagents/tool-based-gen-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews).
</Callout>

## What is this?

Tools are a way for the LLM to call predefined, typically, deterministic functions. CopilotKit allows you to render these tools in the UI
as a custom component, which we call **Generative UI**.

## When should I use this?

Rendering tools in the UI is useful when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
<Step>
### Run and connect your agent

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](/crewai-crews/quickstart/crewai) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews) as a starting point
as this guide uses it as a starting point.

</Step>
<Step>
### Render the tool call in your frontend

In the case of CrewAI Crew agents, there is one tool call that indicates that the crew is being executed. It has the same name as the crew. In this example, the crew is named `research_crew`. To display progress of the crew, we just need to add a `useCopilotAction` hook to render the tool call in
the UI.

<Callout type="info" title="Important">
  In order to render a tool call in the UI, the name of the action must match
  the name of the tool.
</Callout>

```tsx title="app/page.tsx"
import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]
// ...

const YourMainContent = () => {
  // ...
  // [!code highlight:21]
  useCopilotAction({
    name: "research_crew",
    parameters: [
      {
        name: "topic",
      },
      {
        name: "current_year",
      },
    ],
    render({ args, status }) {
      return (
        <div className="m-4 p-4 bg-gray-100 rounded shadow">
          <h1 className="text-center text-sm">
            Researching {args.topic} in {args.current_year}{" "}
            {status == "complete" ? "✅" : "⏳"}
          </h1>
        </div>
      );
    },
  });
  // ...
};
```

</Step>
<Step>
### Give it a try!

Try giving the crew enough information to complete the task, i.e. "Research the state of AI in 2025". You should see the custom UI component that we added render the tool call and display the arguments that were passed to the tool.

</Step>
</Steps>

## Rendering Arbitrary Tool Calls

When working with agents, they may call tools that you haven't explicitly defined UI components for. You can use a catch-all action to render these tool calls:

```tsx
import {
  useCopilotAction,
  CatchAllActionRenderProps,
} from "@copilotkit/react-core";

useCopilotAction({
  name: "*",
  followUp: false,
  render: ({ name, args, status, result }: CatchAllActionRenderProps<[]>) => {
    return (
      <div className="m-4 p-4 bg-gray-100 rounded shadow">
        <h2 className="text-sm font-medium">Tool: {name}</h2>
        <pre className="mt-2 text-xs overflow-auto">
          {JSON.stringify(args, null, 2)}
        </pre>
        {status === "complete" && (
          <div className="mt-2 text-xs text-green-600">✓ Complete</div>
        )}
      </div>
    );
  },
});
```

This will render any tool call that doesn't have a specific UI component defined for it, displaying the tool name, arguments, and completion status.



================================================
FILE: docs/content/docs/crewai-crews/human-in-the-loop/flow.mdx
================================================
---
title: CrewAI Crews
description: Learn how to implement Human-in-the-Loop (HITL) using CrewAI Crews.
icon: lucide/Share2
---

import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";  
import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

<video
  src="/images/coagents/node-hitl.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

<Callout type="info">  
  Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter-crewai-crews)  
  with the implementation below applied!  
</Callout>

## What is this?

[Crew-based agents](https://docs.crewai.com/concepts/crews) are stateful agents that support interruption and resumption, enabling user input mid-execution.

CopilotKit provides custom UI hooks to capture that input and feed it back into the agent—making it easy to implement Human-in-the-Loop (HITL) workflows.

> **Important**  
> To implement HITL with CrewAI, you'll need:
> - [CrewAI](https://www.crewai.com/) for managing and orchestrating the agents  
> - [CopilotKit Cloud](https://cloud.copilotkit.ai/) to handle UI workflows and communication

## Why should I use this?

Human-in-the-loop ensures your agent stays on track by letting users approve or modify actions during execution. This is especially useful for production-grade workflows that need more control, auditing, or fine-tuning.

Crew-based agents are ideal for HITL because they preserve execution state and context, even when paused for human input.

## Implementation

<Steps>
  <Step>
    ### Run and connect your agent

    Make sure your agent is running and connected to CopilotKit. If you haven’t set this up, start with the [Getting Started guide](/crewai-crews/quickstart/crewai).

  </Step>


  <Step>
    ### Add a `useCopilotAction` to your frontend

    Create a component that displays the crew’s output and asks the user for approval before proceeding.

    ```tsx title="ui/app/page.tsx"
    import { useCopilotAction } from "@copilotkit/react-core";
    import { Markdown } from "@copilotkit/react-ui";

    function YourMainContent() {
      useCopilotAction({
        name: "crew_requesting_feedback",
        description: "Request feedback from the user on the crew's output",
        renderAndWaitForResponse: ({ args, respond, status }) => (
          <div>
            <pre>{args}</pre>
            <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
              <button
                onClick={() => respond?.("Reject")}
                disabled={status !== "executing"}
                className="border p-2 rounded-xl w-full"
              >
                Cancel
              </button>
              <button
                onClick={() => respond?.("Approve")}
                disabled={status !== "executing"}
                className="bg-blue-500 text-white p-2 rounded-xl w-full"
              >
                Approve Kickoff
              </button>
            </div>
          </div>
        ),
      });
    }
    ```
  </Step>

  <Step>
    ### Set up HITL on your Crew

    You’ll need to configure your CrewAI Crew to pause and wait for human input before continuing.

    - Follow this CrewAI guide: [Human Input on Execution](https://docs.crewai.com/how-to/human-input-on-execution)  
    - Reference this working example: [restaurant-finder-crew with HITL](https://github.com/suhasdeshpande/restaurant-finder-crew/tree/main/src/similar_company_finder_template)

    > Reminder: To make this work end-to-end, you must run your crew on [CrewAI](https://www.crewai.com/) and connect it to [CopilotKit Cloud](https://cloud.copilotkit.ai/). These hosted solutions take care of message passing, HITL state syncing, and UI orchestration.
  </Step>

  <Step>
    ### Try it out!

    Run a test prompt like:  
    **"Research the state of AI in 2025."**

    You’ll see your custom UI appear, giving you the chance to approve or cancel the crew’s execution before it continues.
  </Step>
</Steps>



================================================
FILE: docs/content/docs/crewai-crews/human-in-the-loop/index.mdx
================================================
---
title: Human in the Loop (HITL)
icon: "lucide/User"
description: Allow your agent and users to collaborate on complex tasks.
---

import { CTACards } from "@/components/react/cta-cards";
import { Pause, Share2 } from "lucide-react";

<video
  src="/images/coagents/human-in-the-loop-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

{/* TODO-DOCS-CREWAI-CREWS: Add Travel App Example */}

## What is Human-in-the-Loop (HITL)?

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

<Frame className="my-0">
  <img
    src="/images/coagents/coagents-hitl-infographic.png"
    alt="Agentic Copilot Human in the Loop"
    className="mt-4 mb-0 shadow-md"
  />
</Frame>

## When should I use this?

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## How can I use this?

Read more about the approach to HITL in CrewAI Crews.

<CTACards
  columns={1}
  cards={[
    {
      icon: Share2,
      title: "Flow-based",
      description:
        "Utilize CrewAI Crews to create Human-in-the-Loop workflows.",
      href: "/crewai-crews/human-in-the-loop/flow",
    },
  ]}
/>



================================================
FILE: docs/content/docs/crewai-crews/human-in-the-loop/meta.json
================================================
{
  "pages": ["flow"]
}



================================================
FILE: docs/content/docs/crewai-crews/shared-state/in-app-agent-read.mdx
================================================
---
title: Reading the outputs
icon: "lucide/ArrowLeft"
description: Read the agent state in your native application.
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<Frame>
  <ImageZoom
    src="/images/coagents/read-agent-state.png"
    alt="read agent state"
    width={1000}
    height={1000}
    className="my-0"
  />
</Frame>

<Callout type="info">
  Pictured above is the [coagent
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter)
  with the [implementation](#implementation) section applied!
</Callout>

## What is this?

You can easily use the realtime agent state in the native application UX.

## When should I use this?

You can use this when you want to provide the user with a way to read the outputs of a CrewAI Crew from your application.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter-crewai-crews) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Use the `useCoAgent` Hook
    With your agent connected and running all that is left is to call the [useCoAgent](/reference/hooks/useCoAgent) hook, pass the agent's name, and
    optionally provide an initial state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent


    function YourMainContent() {
      const { state } = useCoAgent({
        name: "research_crew",
        initialState: {
          inputs: {
            topic: "",
            current_year: "2025",
          },
          outputs: "Report will appear here",
        },
      });

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your report:</h1>
          <p>{state.outputs}</p> // [!code highlight]
        </div>
      );
    }
    ```
    <Callout type="info">
      The `state` in `useCoAgent` is reactive and will automatically update when the agent's state changes.
    </Callout>

  </Step>
  <Step>
    ### Give it a try!
    As the agent state updates, your `state` variable will automatically update with it! In this case, you'll see the report update when the crew is done running.
  </Step>
</Steps>



================================================
FILE: docs/content/docs/crewai-crews/shared-state/in-app-agent-write.mdx
================================================
---
title: Setting the inputs
icon: "lucide/ArrowRight"
description: Write to the inputs of a CrewAI Crew from your application.
---

<video
  src="/images/coagents/write-agent-state.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews)
  repo with the previous steps applied to it!
</Callout>

## What is this?

This guide shows you how to write to your agent's state from your application.

## When should I use this?

You can use this when you want to provide the user with a way to update the inputs of a CrewAI Crew from your application. CopilotKit allows you to fully customize how these UI components are rendered.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already, you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter-crewai-crews) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Calling `setState` function from the `useCoAgent` hook
    `useCoAgent` returns a `setState` function that you can use to update the agent state. Calling this will update the agent state and trigger a rerender of anything that depends on the agent state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    // Example usage in a pseudo React component
    function YourMainContent() {
      const { state, setState } = useCoAgent({ // [!code highlight]
        name: "research_crew",
        initialState: { // optionally provide an initial state
          inputs: {
            topic: "",
            current_year: "2025",
          },
          outputs: "Report will appear here",
        },
      });
      // ...

      return (
        // style excluded for brevity
        <div>
          <label htmlFor="topic">
            Topic
          </label>
          <input
            type="text"
            value={state.inputs.topic}
            onChange={(e) =>
              setState({
                ...state,
                inputs: { ...state.inputs, topic: e.target.value },
              })
            }
          />
        </div>
      );
    }
    ```

  </Step>
  <Step>
    ### Give it a try!
    You can now use the `setState` function to update the crew `inputs` and `state` to read it. Try setting  a topic and talking to your agent.
  </Step>
</Steps>



================================================
FILE: docs/content/docs/crewai-crews/shared-state/index.mdx
================================================
---
title: Shared State
description: Create a two-way connection between your UI and agent state.
icon: "lucide/Repeat"
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<ImageZoom
  src="/images/coagents/SharedStateCoAgents.gif"
  alt="Shared State Demo"
  width={1000}
  height={1000}
  className="rounded-lg shadow-lg border mt-0"
/>

<Callout>
  This video demonstrates the [Research
  Canvas](/crewai-crews/examples/research-canvas) utilizing shared state.
</Callout>

## What is shared state?

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. In the case of CrewAI Crews, the shared state system allows you to:

- Update and send the `inputs` of the crew to the agent
- Receive the `outputs` of the crew
- React to state changes in real-time across your application

<Frame>
  <img
    src="/images/coagents/coagents-state-diagram.png"
    alt="Agentic Copilot State Diagram"
  />
</Frame>

## When should I use this?

Shared state is perfect when you want to facilitate collaboration between your agent and the user. Updates to the outputs will be automatically shared by the UI. Similarly, any `inputs` that the user updates in the UI will be automatically reflected in the crews execution.

This allows for a consistent experience where both the agent and the user are on the same page.



================================================
FILE: docs/content/docs/crewai-crews/shared-state/meta.json
================================================
{
  "pages": ["in-app-agent-read", "in-app-agent-write"]
}



================================================
FILE: docs/content/docs/crewai-flows/agentic-chat-ui.mdx
================================================
---
title: Chat with an Agent
icon: "lucide/SendHorizontal"
description: Chat with an agent using CopilotKit's UI components.
---

import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import ComponentExamples from "@/snippets/component-examples.mdx";
import { UserIcon, PaintbrushIcon, WrenchIcon, RepeatIcon } from "lucide-react";

<video
  src="/images/coagents/agentic-chat-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows)
  repo with various Copilot UI components applied to it!
</Callout>

## What is this?

Agentic chat UIs are ways for your users to interact with your agent. CopilotKit provides a variety of different components to choose from, each
with their own unique use cases.

If you've gone through the [getting started guide](/crewai-flows/quickstart/crewai) **you already have a agentic chat UI setup**! Nothing else is needed
to get started.

## When should I use this?

CopilotKit provides a variety of different batteries-included components to choose from to create agent native applications. They scale
from simple chat UIs to completely custom applications.

<ComponentExamples components={props.components} />



================================================
FILE: docs/content/docs/crewai-flows/frontend-actions.mdx
================================================
---
title: Frontend Actions
icon: "lucide/Wrench"
description: Create frontend actions and use them within your agent.
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

<video
  src="/images/frontend-actions-demo.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## When should I use this?

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## Implementation

<Steps>
    <Step>
        ### Setup CopilotKit

        To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here.

        Check out our [getting started guide](/crewai-flows/quickstart/crewai/crewai-flows) and come back here when you're setup!
    </Step>

    <Step>
        ### Create a frontend action

        First, you'll need to create a frontend action using the [useCopilotAction](/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
        that says hello to the user.

        ```tsx title="page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core" // [!code highlight]

        export function Page() {
          // ...

          // [!code highlight:16]
          useCopilotAction({
            name: "sayHello",
            description: "Say hello to the user",
            available: "remote", // optional, makes it so the action is *only* available to the agent
            parameters: [
              {
                name: "name",
                type: "string",
                description: "The name of the user to say hello to",
                required: true,
              },
            ],
            handler: async ({ name }) => {
              alert(`Hello, ${name}!`);
            },
          });

          // ...
        }
        ```
    </Step>
    <Step>
        ###  Modify your agent
        Now, we'll need to modify the agent to access these frontend actions. Open up for your agent's folder and continue from there!
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Inheriting from CopilotKitState

        To access the frontend actions provided by CopilotKit, you can inherit from CopilotKitState in your agent's state definition:

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                from copilotkit import CopilotKitState # [!code highlight]

                class YourAgentState(CopilotKitState): # [!code highlight]
                    your_additional_properties: str
                ```
            </Tab>
        </Tabs>

        By doing this, your agent's state will include the `copilotkit` property, which contains the frontend actions that can be accessed and invoked.
    </Step>
    <Step>
        ### Accessing Frontend Actions

        Once your agent's state includes the `copilotkit` property, you can access the frontend actions and utilize them within your agent's logic.

        Here's how you can call a frontend action from your agent:

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                async def agent(self):
                    response = await copilotkit_stream(
                        completion(
                            model="openai/gpt-4o",
                            messages=[
                                {"role": "system", "content": prompt},
                                *self.state.get("messages", [])
                            ],
                            # Access the actions from the copilotkit property
                            tools=self.state["copilotkit"]["actions"], # [!code highlight]
                            tool_choice="required",
                            stream=True
                        )
                    )

                    # ...
                ```
            </Tab>
        </Tabs>

        These actions are automatically populated by CopilotKit and are compatible with LiteLLM's tool call definitions, making it straightforward to integrate them into your agent's workflow.
    </Step>
    <Step>
        ### Give it a try!
        You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.
    </Step>

</Steps>



================================================
FILE: docs/content/docs/crewai-flows/index.mdx
================================================
---
title: Introduction
icon: "lucide/Sparkles"
description: Build Agent-Native Applications (ANAs) powered by CopilotKit and CrewAI Flows.
---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { FaDiscord } from "react-icons/fa";
import Link from "next/link";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { TelescopeIcon } from "lucide-react";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import {
  LuPlane,
  LuBookOpen,
  LuLightbulb,
  LuLayoutTemplate,
  LuBrainCog,
  LuUserCog,
  LuWand2,
  LuPlay,
  LuMessageSquare,
  LuWrench,
} from "react-icons/lu";
import { CoAgentsExamples } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { FaSync } from "react-icons/fa";
import { Socials } from "@/components/react/socials";

<div className="p-4 mb-6 rounded-lg bg-orange-50 dark:bg-orange-950 border border-orange-200 dark:border-orange-800">
  <div className="flex items-center gap-2 mb-2">
    <TelescopeIcon className="h-5 w-5 text-orange-500 dark:text-orange-300" />
    <h3 className="text-lg font-semibold text-orange-700 dark:text-orange-300">CrewAI Overview</h3>
  </div>
  <p className="text-orange-700 dark:text-orange-300">
    Visit the <a href="https://v0-crew-land.vercel.app/" target="_blank" rel="noopener noreferrer" className="font-medium underline underline-offset-4 decoration-orange-400 dark:decoration-orange-500 hover:text-orange-600 dark:hover:text-orange-200">CrewAI Overview Page</a> to learn more about CrewAI's capabilities and features.
  </p>
</div>

# Copilot Infrastructure for CrewAI Flows

Full user-interaction infrastructure for your Flows, to turn them into Copilot Agents (CoAgents).

<Frame className="mt-0 mb-6">
  <video
    src="/images/coagents/crew-ai/flows/crews-interaction-layer.mp4"
    alt="CoAgents demonstration"
    className="rounded-lg shadow-xl"
    playsInline
    autoPlay
    muted
    loop
  />
</Frame>

## Building blocks of a CoAgent

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuMessageSquare className="text-orange-500 dark:text-orange-300" />}
    title="Agentic Chat UI"
    description="In-app chat to kickoff, render and analyze the result of your Crews."
    href="/crewai-flows/agentic-chat-ui"
  />
    <Card
    className="p-6 rounded-xl text-base"
    icon={<FaSync className="text-orange-500 dark:text-orange-300" />}
    title="Shared State"
    description="Your agent can see/update everything in your app, and vice versa."
    href="/crewai-flows/shared-state"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuLayoutTemplate className="text-orange-500 dark:text-orange-300" />}
    title="Generative UI"
    description="UI that updates in real-time based on your agent's state."
    href="/crewai-flows/generative-ui"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuWand2 className="text-orange-500 dark:text-orange-300" />}
    title="Frontend Tools"
    description="Give your agent the ability to take action in your application."
    href="/crewai-flows/frontend-actions"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuWand2 className="text-orange-500 dark:text-orange-300" />}
    title="Multi-Agent Coordination"
    description="Route your agent to the right agent based on the user's request."
    href="/crewai-flows/multi-agent-flows"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuUserCog className="text-orange-500 dark:text-orange-300" />}
    title="Human-in-the-Loop"
    description="Set smart checkpoints where humans can guide your agents."
    href="/crewai-flows/human-in-the-loop"
  />
</Cards>

## Ready to get started?

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base"
    icon={<LuPlay className="text-orange-500 dark:text-orange-300" />}
    title="Quickstart"
    description="Learn how to build your first CoAgent in 10 minutes."
    href="/crewai-flows/quickstart/crewai"
  />
  <Card
    className="p-6 rounded-xl text-base"
    icon={<TelescopeIcon className="text-orange-500 dark:text-orange-300" />}
    title="Feature Overview"
    description="Try the key features of CoAgents powered by CrewAI Crews."
    href="https://demo-viewer-five.vercel.app/"
    target="_blank"
  />
</Cards>

## Common Questions

Have a question about CoAgents? You're in the right place!

<Accordions>
<Accordion title="Can you explain what a CoAgent is in more detail?">
Sure! CoAgents are what we call "agentic copilots". Well, what's an agentic copilot then?

Think of a Copilot as a simple and fully LLM controlled assistant that has relatively limited capabilities. An Agentic Copilot then is a copilot
that has been enhanced with the ability to use CrewAI agents to perform more complex tasks. This is an extremely powerful way to build AI
powered applications because it gives you, the developer, the ability to control the agent's behavior in a deterministic way while still letting
the agent do its magic.

For more on this topic, checkout our [agentic copilot](/crewai-flows/concepts/agentic-copilots) concept page.

</Accordion>
</Accordions>



================================================
FILE: docs/content/docs/crewai-flows/meta.json
================================================
{
  "title": "CoAgents",
  "root": true,
  "pages": [
    "index",
    "quickstart",
    "[lucide/Telescope][Feature Viewer](https://demo-viewer-five.vercel.app/ )",
    "---Guides---",
    "agentic-chat-ui",
    "generative-ui",
    "human-in-the-loop",
    "shared-state",
    "frontend-actions",
    "multi-agent-flows",
    "persistence",
    "advanced",
    "---Learn---",
    "...concepts"
  ]
}



================================================
FILE: docs/content/docs/crewai-flows/multi-agent-flows.mdx
================================================
---
title: Multi-Agent Flows
description: Use multiple agents to orchestrate complex flows.
icon: "lucide/Users"
---
import { Callout } from "fumadocs-ui/components/callout";

## What are Multi-Agent Flows?

When building agentic applications, you often want to orchestrate complex flows together that require the coordination of multiple
agents. This is traditionally called multi-agent orchestration.

## When should I use this?

Multi-agent flows are useful when you want to orchestrate complex flows together that require the coordination of multiple agents. As
your agentic application grows, delegation of sub-tasks to other agents can help you scale key pieces of your application.
- Divide context into smaller chunks
- Delegate sub-tasks to other agents
- Use a single agent to orchestrate the flow

## How does CopilotKit support this?

CopilotKit can be used in either of two distinct modes: **Router Mode**, or **Agent Lock**. By default, CopilotKit
will use Router Mode, leveraging your defined LLM to route requests between agents.

### Router Mode (default)
Router Mode is enabled by default when using CoAgents. To use it, specify a runtime URL prop in the `CopilotKit` provider component and omit the `agent` prop, like so:
```tsx
<CopilotKit runtimeUrl="<copilot-runtime-url>">
  {/* Your application components */}
</CopilotKit>
```

In router mode, CopilotKit acts as a central hub, dynamically selecting and _routing_ requests between different agents or actions based on the user's input. This mode can be good for chat-first experiences where an LLM chatbot is the entry point for a range of interactions, which can stay in the chat UI or expand to include native React UI widgets.

In this mode, CopilotKit will intelligently route requests to the most appropriate agent or action based on the context and user input.

<Callout type="warn">
    Router mode requires that you set up an LLM adapter. See how in ["Set up a copilot runtime"](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint) section of the docs.
</Callout>

### Agent Lock Mode
To use Agent Lock Mode, specify the agent name in the `CopilotKit` component with the `agent` prop:
```tsx
// [!code word:agent]
<CopilotKit runtimeUrl="<copilot-runtime-url>" agent="<the-name-of-the-agent>">
  {/* Your application components */}
</CopilotKit>
```

In this mode, CopilotKit is configured to work exclusively with a specific agent. This mode is useful when you want to focus on a particular task or domain. Whereas in Router Mode the LLM and CopilotKit's router are free to switch between agents to handle user requests, in Agent Lock Mode all requests will stay within a single workflow graph, ensuring precise control over the workflow.

Use whichever mode works best for your app experience! Also, note that while you cannot nest `CopilotKit` providers, you can use different agents or modes in different areas of your app — for example, you may want a chatbot in router mode that can call on any agent or tool, but may also want to integrate one specific agent elsewhere for a more focused workflow.


================================================
FILE: docs/content/docs/crewai-flows/quickstart.mdx
================================================
---
title: Quickstart
description: Turn your CrewAI Flows into an agent-native application in 10 minutes.
icon: "lucide/Play"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import { FaPython, FaJs, FaCloud } from "react-icons/fa";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureRemoteEndpointLangGraph from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotKitCloudCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";
import CloudCopilotKitProvider from "@/snippets/coagents/cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/coagents/self-host-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeLangGraphEndpoint from "@/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx";
import SelfHostingCopilotRuntimeStarter from "@/snippets/self-hosting-copilot-runtime-starter.mdx";
import SelfHostingRemoteEndpoints from "@/snippets/self-hosting-remote-endpoints.mdx";
import { SquareTerminal, SquareChartGantt } from "lucide-react";
import {
  UserIcon,
  PaintbrushIcon,
  WrenchIcon,
  RepeatIcon,
  ServerIcon,
} from "lucide-react";
import { SiCrewai } from "@icons-pack/react-simple-icons";
import CopilotUI from "@/snippets/copilot-ui.mdx";

<video
  src="/images/coagents/chat-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

## Prerequisites

Before you begin, you'll need the following:

- [**OpenAI API key**](https://platform.openai.com/api-keys)

## Getting started

<Steps>
<TailoredContent
    className="step"
    id="path"
    header={
        <div>
            <p className="text-xl font-semibold">How do you want to get started?</p>
            <p className="text-base">
                Bootstrap with the new <span className="text-indigo-500 dark:text-indigo-400">CopilotKit CLI (Beta)</span> or code along with us to get started.
            </p>
        </div>
    }
>
    <TailoredContentOption
        id="cli"
        title="Use the CopilotKit CLI (NextJS only)"
        description="I have a Next.js application and want to get started quickly."
        icon={<SquareTerminal />}
    >
        <Step>
            ### Run the CLI
            Just run this following command in your Next.js application to get started!

            <Accordions>
                <Accordion title="Don't have a Next.js application?">
                    No problem! Just use `create-next-app` to make one quickly.
                    ```bash
                    npx create-next-app@latest
                    ```
                </Accordion>
            </Accordions>

            ```bash
            npx copilotkit@latest init -m CrewAI --crew-type Flows
            ```
        </Step>
        <Step>
            ### 🎉 Talk to your agent!

            Congrats! You've successfully integrated a CrewAI Flow agent chatbot to your application. Depending on the
            template you chose, you may see some different UI elements. To start, try asking a few questions to your agent.

            ```
            Can you tell me a joke?
            ```

            ```
            Can you help me understand AI?
            ```

            ```
            What do you think about React?
            ```
        </Step>
    </TailoredContentOption>
    <TailoredContentOption
        id="code-along"
        title="Code along"
        description="I want to deeply understand what's happening under the hood or don't have a Next.js application."
        icon={<SquareChartGantt />}
    >
        <Step>
            ### Install CopilotKit
            First, install the latest packages for CopilotKit into your frontend.
            ```package-install
            npm install @copilotkit/react-ui @copilotkit/react-core
            ```
        </Step>
        <TailoredContent
            className="step"
            id="agent"
            header={
                <div>
                    <p className="text-xl font-semibold">Do you already have a CrewAI Flow agent?</p>
                    <p className="text-base">
                        You will need a CrewAI Flow agent to get started!
                    </p>
                    <p className="text-base">
                        Either bring your own or feel free to use our starter repo.
                    </p>
                </div>
            }
        >
            <TailoredContentOption
                id="bring-your-own"
                title="Bring your own CrewAI Flow agent"
                description="I already have a CrewAI Flow agent and want to use it with CopilotKit."
                icon={<SiCrewai />}
            />
            <TailoredContentOption
                id="coagents-starter"
                title="Use the CoAgents Starter repo"
                description="I don't have a CrewAI Flow agent yet, but want to get started quickly."
                icon={<img src="/images/copilotkit-logo.svg" alt="CopilotKit Logo" width={20} height={20} />}
            >
                <Step>
                    ### Clone the `coagents-starter` repo

                    <Tabs groupId="language" items={["Python"]}>
                        <Tab value="Python">
                            ```bash
                            git clone https://github.com/CopilotKit/CopilotKit
                            cd CopilotKit/examples/coagents-starter-crewai-flows/agent-py
                            ```
                        </Tab>
                    </Tabs>
                </Step>
                <Step>
                    ### Create a `.env` file

                    ```bash
                    touch .env
                    ```
                </Step>
                <Step>
                    ### Add your API keys

                    Then add your **OpenAI API key** to the `.env` file.

                    ```plaintext title=".env"
                    OPENAI_API_KEY=your_openai_api_key
                    ```
                </Step>
            </TailoredContentOption>
        </TailoredContent>
        <Step>
            ### Launch your local agent

            Start your local CrewAI Flow agent:

            ```bash
            # Install dependencies
            poetry lock
            poetry install
            # Start the server
            poetry run demo
            ```
            This will start a local agent server that you can connect to.
        </Step>

        <TailoredContent
            className="step"
            id="copilot-hosting"
            header={
                <div>
                    <p className="text-xl font-semibold">Choose your connection method</p>
                    <p className="text-base">
                        Now you need to connect your CrewAI Flow to CopilotKit.
                    </p>
                </div>
            }
        >
            <TailoredContentOption
                id="copilot-cloud"
                title="Copilot Cloud (Recommended)"
                description="I want to host my Copilot on Copilot Cloud"
                icon={<FaCloud />}
            >
                <Step>
                    ### Add a remote endpoint for your CrewAI Flow
                    Using Copilot Cloud, you need to connect a remote endpoint that will connect to your CrewAI Flow.
                    <Tabs groupId="lg-deployment-type" items={['Self hosted (FastAPI)', 'CrewAI Enterprise']}>
                        <Tab value="Self hosted (FastAPI)">
                            **Running your FastAPI server in production**

                            Head over to [Copilot Cloud](https://cloud.copilotkit.ai) sign up and setup a remote endpoint with the following information:
                            - OpenAI API key
                            - Your FastAPI server URL

                            **Running your FastAPI server locally**

                            If you're running your FastAPI server locally, you can open a tunnel to it so Copilot Cloud can connect to it.

                            ```bash
                            npx copilotkit@latest dev --port 8000
                            ```
                        </Tab>
                        <Tab value="CrewAI Enterprise">
                            Coming soon!
                        </Tab>
                    </Tabs>
                </Step>
                <Step>
                    ### Setup your CopilotKit provider
                    The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                    it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

                    <CloudCopilotKitProvider components={props.components} />

                    <Callout type="info">
                        Looking for a way to run multiple CrewAI Flows? Check out our [Multi-Agent](/crewai-flows/multi-agent-flows) guide.
                    </Callout>
                </Step>
            </TailoredContentOption>
            <TailoredContentOption
                id="self-hosted"
                title="Self-Hosted Copilot Runtime"
                description="I want to self-host the Copilot Runtime"
                icon={<ServerIcon />}
            >
                <Step>
                    ### Install Copilot Runtime
                    Copilot Runtime is a production-ready proxy for your CrewAI Flows. In your frontend, go ahead and install it.

                    ```package-install
                    @copilotkit/runtime
                    ```
                </Step>
                <Step>
                    ### Setup a Copilot Runtime Endpoint
                    Now we need to setup a Copilot Runtime endpoint and point your frontend to it.
                    <SelfHostingCopilotRuntimeStarter components={props.components}/>
                </Step>
                <Step>
                    ### Add your CrewAI Flow deployment to Copilot Runtime
                    Now we need to add your CrewAI Flow deployment to Copilot Runtime. This will make it
                    so your frontend can find your CrewAI Flows correctly.
                    ```ts
                    import {
                    CopilotRuntime,
                    // ...
                    } from "@copilotkit/runtime";
                    // ...
                    const runtime = new CopilotRuntime({
                    remoteEndpoints: [
                        // [!code highlight:3]
                        // Our FastAPI endpoint URL
                        { url: "http://localhost:8000/copilotkit" },
                    ],
                    });
                    // ...
                    ```
                </Step>
                <Step>
                    ### Configure the CopilotKit Provider
                    The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                    it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.
                    <SelfHostingCopilotRuntimeConfigureCopilotKitProvider components={props.components}/>
                    <Callout type="info">
                        Looking for a way to run multiple CrewAI Flows? Check out our [Multi-Agent](/crewai-flows/multi-agent-flows) guide.
                    </Callout>
                </Step>
            </TailoredContentOption>
        </TailoredContent>
        <Step>
            ### Setup the Copilot UI
            The last step is to use CopilotKit's UI components to render the chat interaction with your agent. In most situations,
            this is done alongside your core page components, e.g. in your `page.tsx` file.

            ```tsx title="page.tsx"
            // [!code highlight:3]
            import "@copilotkit/react-ui/styles.css";
            import { CopilotPopup } from "@copilotkit/react-ui";

            export function YourApp() {
            return (
                <main>
                <h1>Your main content</h1>
                // [!code highlight:7]
                <CopilotPopup
                    labels={{
                        title: "Popup Assistant",
                        initial: "Hi! I'm connected to an agent. How can I help?",
                    }}
                />
                </main>
            );
            }
            ```

            <Callout type="info">
                Looking for other chat component options? Check out our [Agentic Chat UI](/crewai-flows/agentic-chat-ui) guide.
            </Callout>
        </Step>
        <Step>
            ### 🎉 Talk to your agent!

            Congrats! You've successfully integrated a CrewAI Flow chatbot to your application. To start, try asking a few questions to your agent.

            ```
            Can you tell me a joke?
            ```

            ```
            Can you help me understand AI?
            ```

            ```
            What do you think about React?
            ```

            <video src="/images/coagents/chat-example.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

            <Accordions className="mb-4">
                <Accordion title="Having trouble?">
                    - Try changing the host to `0.0.0.0` or `127.0.0.1` instead of `localhost`.
                </Accordion>
            </Accordions>
        </Step>
    </TailoredContentOption>
    </TailoredContent>

</Steps>

---

## What's next?

You've now got a CrewAI Flow running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

<Cards>
  <Card
    title="Implement Human in the Loop"
    description="Allow your users and agents to collaborate together on tasks."
    href="/crewai-flows/human-in-the-loop"
    icon={<UserIcon />}
  />
  <Card
    title="Utilize the Shared State"
    description="Learn how to synchronize your agent's state with your UI's state, and vice versa."
    href="/crewai-flows/shared-state"
    icon={<RepeatIcon />}
  />
  <Card
    title="Add some generative UI"
    description="Render your agent's progress and output in the UI."
    href="/crewai-flows/generative-ui"
    icon={<PaintbrushIcon />}
  />
  <Card
    title="Setup frontend actions"
    description="Give your agent the ability to call frontend tools, directly updating your application."
    href="/crewai-flows/frontend-actions"
    icon={<WrenchIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/crewai-flows/advanced/disabling-state-streaming.mdx
================================================
---
title: "Disabling state streaming"
icon: "lucide/Cog"
description: "Granularly control what is streamed to the frontend."
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

## What is this?

By default, CopilotKit will stream both your messages and tool calls to the frontend when you use `copilotkit_stream`. You can disable this by choosing when to use `copilotkit_stream` vs calling `completion` directly.

## When should I use this?

Occasionally, you'll want to disable streaming temporarily — for example, the LLM may be doing something the current user should not see, like emitting tool calls or questions pertaining to other employees in an HR system.

## Implementation

### Disable all streaming

You can control whether to stream messages or tool calls by selectively wrapping calls to `completion` with `copilotkit_stream`.

<Tabs groupId="language" items={['Python']} default="Python">
    <Tab value="Python">
        ```python
        from copilotkit.crewai import copilotkit_stream
        from typing import cast, Any
        from litellm import completion

        @start()
        async def start(self):

            # 1) Do not emit messages or tool calls, keeping the LLM call private.
            response = completion(
                model="openai/gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant"},
                    *self.state.messages
                ],
            )
            message = response.choices[0].message

            # 2) Or wrap the LLM call with `copilotkit_stream` to stream message tokens.
            #    Note that we pass `stream=True` to the inner `completion` call.
            response = await copilotkit_stream(
                completion(
                    model="openai/gpt-4o",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant"},
                        *self.state.messages
                    ],
                    stream=True
                )
            )
            message = cast(Any, response).choices[0]["message"]
        ```
    </Tab>

</Tabs>



================================================
FILE: docs/content/docs/crewai-flows/advanced/emit-messages.mdx
================================================
---
title: "Manually emitting messages"
icon: "lucide/Radio"
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";
import RunAndConnectSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";

While most agent interactions happen automatically through shared state updates as the agent runs, you can also **manually send messages from within your agent code** to provide immediate feedback to users.

<video
  src="/images/coagents/emit-messages.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

In CrewAI, messages are only emitted when a function is completed. CopilotKit allows you to manually emit messages
in the middle of a function's execution to provide immediate feedback to the user.

## When should I use this?

Manually emitted messages are great for **when you don't want to wait for the function** to complete **and you**:

- Have a long running task that you want to provide feedback on
- Want to provide a status update to the user
- Want to provide a warning or error message

## Implementation

<Steps>
    <Step>
        ### Run and Connect Your Agent to CopilotKit
        <RunAndConnectSnippet />
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Manually emit a message
        The `copilotkit_emit_message` method allows you to emit messages early in a functions's execution to communicate status updates to the user. This is particularly useful for long running tasks.

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python
                from litellm import completion
                from crewai.flow.flow import start
                from copilotkit.crewai import copilotkit_emit_message # [!code highlight]
                # ...

                @start()
                async def start(self):
                    # [!code highlight:3]
                    intermediate_message = "Thinking really hard..."
                    await copilotkit_emit_message(intermediate_message)

                    # simulate a long running task
                    await asyncio.sleep(2)

                    response = copilotkit_stream(
                        completion(
                            model="openai/gpt-4o",
                            messages=[
                                {"role": "system", "content": "You are a helpful assistant."},
                                *self.state["messages"]
                            ],
                            stream=True
                        )
                    )
                     message = response.choices[0]["message"]

                    self.state["messages"].append(message)
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Give it a try!
        Now when you talk to your agent you'll notice that it immediately responds with the message "Thinking really hard..."
        before giving you a response 2 seconds later.
    </Step>

</Steps>



================================================
FILE: docs/content/docs/crewai-flows/advanced/exit-agent.mdx
================================================
---
title: "Exiting the agent loop"
icon: "lucide/DoorOpen"
---

import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

After your agent has finished a workflow, you'll usually want to explicitly end that loop by calling the `copilotkit_exit()` method in your Python code.

Exiting the agent has different effects depending on mode:

- **Router Mode**: Exiting the agent hands responsibility for handling input back to the router, which can initiate chat, call actions, other agents, etc. The router can return to this agent later (starting a new loop) to satisfy a user request.

- **Agent Lock Mode**: Exiting the agent restarts the workflow loop for the current agent.

In this example from [our email-sending app](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-qa), the `send_email` node explicitly exits, then manually sends a response back to the user as a `ToolMessage`:

<Steps>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Exit the agent loop
        This will exit the agent session as soon as the current CrewAI run is finished, either by a breakpoint or by reaching the `END` node.

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python
                import uuid
                from litellm import completion
                from crewai.flow.flow import start
                from copilotkit.crewai import copilotkit_exit
                # ...
                @start()
                async def send_email(self):
                    """Send an email."""


                    # get the last message and cast to ToolMessage
                    last_message = self.state["messages"][-1]
                    if last_message["content"] == "CANCEL":
                        text_message = "❌ Cancelled sending email."
                    else:
                        text_message = "✅ Sent email."
                    self.state["messages"].append({"role": "assistant", "content": text_message, "id": str(uuid.uuid4())})
                    # Exit the agent loop after processing
                    await copilotkit_exit() # [!code highlight]
                ```
            </Tab>
        </Tabs>
    </Step>

</Steps>



================================================
FILE: docs/content/docs/crewai-flows/advanced/meta.json
================================================
{
    "title": "Advanced",
    "icon": "lucide/Cog"
}


================================================
FILE: docs/content/docs/crewai-flows/concepts/agentic-copilots.mdx
================================================
---
title: Agentic Copilots
description: Agentic copilots provide you with advanced control and orchestration over your agents.
icon: lucide/Bot
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content";
import { BsFillCloudHaze2Fill as CloudIcon } from "react-icons/bs";
import { FaServer as SelfHostIcon } from "react-icons/fa6";
import { SiLangchain } from "react-icons/si";
import { LinkIcon } from "lucide-react";
import {
  RocketIcon,
  GraduationCapIcon,
  CodeIcon,
  VideoIcon,
} from "lucide-react";

Before we dive into what agentic copilots are, help us help you by telling us your level of experience with CrewAI. We'll explain things in a way that best suits your experience level.

<TailoredContent id="experience" defaultOptionIndex={0}>
    <TailoredContentOption 
        id="new"
        title="I'm new to CrewAI" 
        description="Help me understand what agentic copilots are, where CrewAI fits in, and how to get started." 
        icon={<img src="/images/copilotkit-logo.svg" width={7} height={7} />}
    >
        <Frame>
            <img src="/images/coagents/SharedStateCoAgents.gif" alt="CoAgents Shared State" className="mt-0 mb-12"/>
        </Frame>

        ### What are Agents?
        AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from
        simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

        As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized
        frameworks like CrewAI become essential.

        ### What is CrewAI?
        CrewAI is a framework that gives you precise control over AI agents. CrewAI flows allow developers to combine and coordinate coding tasks and Crews efficiently,
        providing a robust framework for building sophisticated AI automations.

        ### What are Agentic Copilots?
        Agentic copilots are how CopilotKit brings CrewAI agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that
        understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ)
        for quick implementation, Agentic copilots give you CrewAI's full orchestration capabilities when you need more control over your agent's behavior.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ### When should I use CopilotKit's CoAgents?
        You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [CrewAI](https://crewai.com/).
        With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

        We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.

        The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's
        functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
        up to 100% of the Copilot's tasks (see [agent-lock mode](/crewai-flows/multi-agent-flows) for the 100% case).

        ### Examples
        An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-research-canvas).

        More specifically, it demonstrates how CoAgents allow for AI driven experiences with:
        - Precise state management across agent interactions
        - Sophisticated multi-step reasoning capabilities
        - Seamless orchestration of multiple AI tools
        - Interactive human-AI collaboration features
        - Real-time state updates and progress streaming

        ## Next Steps

        Want to get started? You have some options!

        <Cards>
            <Card
                title="Build your first CoAgent"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/crewai-flows/quickstart/crewai"
                icon={<RocketIcon />}
            />
            <Card
                title="Learn more CoAgent concepts"
                description="Learn more about the concepts used to talk about CoAgents and how to use them."
                href="/crewai-flows/concepts/terminology"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Read the reference documentation"
                description="Just here for some reference? Checkout the reference documentation for more details."
                href="/crewai-flows/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="See examples of CoAgents in action"
                description="Checkout our video examples of CoAgents in action."
                href="/crewai-flows/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>
    <TailoredContentOption
        id="intermediate"
        title="I'm already using CrewAI"
        description="Help me understand what agentic copilots are, what Copilotkit does to integrate with CrewAI, and how to get started."
        icon={<SiLangchain />}
    >

        <Frame className="mt-0 mb-12">
            <img
                src="/images/CoAgents.gif"
                alt="CoAgents demonstration"
                className="w-auto"
            />
        </Frame>

        CrewAI is a framework for building deeply customizable AI agents.

        CopilotKit's Agentic Copilots is infrastructure for in-app agent-user interaction, i.e. for transforming agents from autonomous processes to user-interactive 'virtual colleagues' that live inside applications.

        Any CrewAI-based agent can be transformed into an Agentic Copilot with a minimal amount
        of effort to get industry leading agentic UX such as:
        - Shared state between the agent and the application.
        - Intermediate result and state progress streaming
        - Human-in-the-loop collaboration
        - Agentic generative UI
        - And more!

        All of these features are essential to delight instead of frustrate your users with AI features.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ## Next Steps
        Want to get started? You have some options!

        <Cards>
            <Card
                title="Quickstart"
                description="Integrate your CrewAI agent with CopilotKit in a few minutes."
                href="/crewai-flows/quickstart/crewai"
                icon={<RocketIcon />}
            />
            <Card
                title="Tutorial: AI Travel App"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/crewai-flows/tutorials/ai-travel-app/overview"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Reference"
                description="Learn more about the terms used to talk about CoAgents and how to use them."
                href="/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="Examples"
                description="Checkout our video examples of CoAgents in action."
                href="/crewai-flows/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>

</TailoredContent>



================================================
FILE: docs/content/docs/crewai-flows/concepts/copilotkit-stream.mdx
================================================
---
title: Streaming and Tool Calls
description: CoAgents support streaming your messages and tool calls to the frontend.
---

If you'd like to stream messages from your CrewAI agents you can utilize our Copilotkit SDK which provides a collection
of functions and utilities for interacting with the agent's state or behavior. This allows you to choose how messages and
tool calls are emitted and streamed to the frontend.

## Message Streaming

If you just call the LiteLLM `completion` function from your CrewAI agent, messages will not be streamed by default.
To stream messages, wrap the `completion` function with the `copilotkit_stream` function. This will enable streaming
of both the messages and tool calls to the frontend.

```python
response = copilotkit_stream(
    completion(
        model="openai/gpt-4o",
        messages=[
            {"role": "system", "content": my_prompt},
            *self.state["messages"]
        ],
        stream=True
    )
)
```

For more information on how tool calls are utilized check out our [frontend actions](/crewai-flows/frontend-actions)
documentation.



================================================
FILE: docs/content/docs/crewai-flows/concepts/crewai.mdx
================================================
---
title: CrewAI
description: An agentic framework for building LLM applications that can be used with Copilotkit.
icon: custom/langchain
---

<Frame>
  <img
    src="/images/coagents/coagents-highlevel-overview.png"
    alt="CoAgents High Level Overview"
    className="mb-10"
  />
</Frame>

CrewAI is an agentic framework for building LLM applications that can be used with Copilotkit. CrewAi Flows allow developers
to combine and coordinate coding tasks and Crews efficiently, providing a robust framework for building sophisticated AI automations.

## CoAgents and CrewAI

How do CoAgents extend CrewAI? Let's read the first sentence of their [page on Flows](https://docs.crewai.com/concepts/flows) to understand.

> Flows allow you to create structured, event-driven workflows. They provide a seamless way to connect multiple tasks, manage state, and control the flow of execution in your AI applications.

Let's break down some key terms and understand how they relate to and are implemented by CoAgents.

- ** manage state**: CoAgents have bi-directional state sharing with the agent and UI. This allows for the agent to remember
  information from previous messages and the UI to update the agent with new information. Read more about how state sharing works
  [here](/crewai-flows/shared-state).
- **Multi-actor**: CoAgents allow for multiple agents to interact with each other. Copilotkit acts as the "ground-truth"
  when transitioning between agents. Read more about how multi-actor workflows work [here](/crewai-flows/multi-agent-flows)
  and how messages are managed [here](/crewai-flows/concepts/message-management).
- **LLMs**: CoAgents use large language models to generate responses. This is useful for building applications that need to
  generate natural language responses.

Some additional functionality not mentioned here is:

- **Human in the loop**: CoAgents enabled human review and approval of generated responses. Read more about how this works
  [here](/crewai-flows/human-in-the-loop).
- **Tool calling**: Tool calling is a fundamental building block for agentic workflows. They allow for greater control over what
  the agent can do and can be used to interact with external systems. CoAgents allow you to easily render in-progress
  tool calls in the UI so your users know what's happening. Read more about streaming tool calls [here](/crewai-flows/shared-state/predictive-state-updates).

## Building with Python

You can build CrewAI applications using Python. Check out the [CrewAI docs](https://docs.crewai.com/introduction) for more information.

## CrewAI Enterprise

Turn any crew into an API within seconds
Connect to your apps using hooks, REST, gRPC and more
Get access to templates, custom tools and early UI
Get business support, SLA, private VPC

CrewAI enterprise is a platform for deploying and monitoring CrewAI applications. Read more about it on the
[CrewAI website](https://www.crewai.com/enterprise).

If you want to take the next step to deploy your CrewAI application as an CoAgent, check out our [quickstart guide](/crewai-flows/quickstart/crewai).



================================================
FILE: docs/content/docs/crewai-flows/concepts/message-management.mdx
================================================
---
title: Message flow
icon: lucide/MessageCircle
---

Message management in CoAgents operates with CopilotKit as the "ground truth" for the full chat session.
When an CoAgent session begins, it receives the existing CopilotKit chat history to maintain conversational
continuity across different agents.

<Callout>
  While all of this information is great to know, in most cases you won't need
  to worry about these details to build rich agentic applications. Use the
  information here as a reference when getting really deep into the CoAgent
  internals.
</Callout>

### Can I modify the message history?

You can modify the message history from CrewAI Flows by using the `"messages"` key in the state. For example to remove all messages from the chat history:

```python

def a_flow_function():
    # ...
    self.state["messages"] = []
```

### Can I persist chat history?

Yes! There are a few ways to persist various portions of a chat's history:

- [Threads](/crewai-flows/persistence/threads)
- [Message Persistence](/crewai-flows/persistence/message-persistence)
- [Agent State](/crewai-flows/persistence/loading-agent-state)

## Types of LLM Messages

Modern LLM interactions produce two distinct types of messages:

1. **Communication Messages**: Direct responses and interactions with users
2. **Internal Messages**: Agent "thoughts" and reasoning processes

A well known example of this pattern is OpenAI's o1 model, which has sophisticated reasoning capabilities and thoughts. Its internal
thought processes are presented distinctly from 'communication messages' which are clearly visible to the end-user.

CrewAI agents can operate similarly. An LLM call's output can be considered either a communication message, or an internal message.

### Emitting Messages for long running tasks

Sometimes you'll have a task that is running for a long time, and you want the user to be aware of what's happening.
CopilotKit allows you to accomplish this by using the `copilotkit_emit_message` function.

```python
@listen("route_to_ask_name")
async def ask_name():
    """
    Ask the user for their name.
    """

    content = "Hey, what is your name? 🙂"

    await copilotkit_emit_message(content)

    # something long running here...

    self.state["messages"].append({"role": "assistant", "content": content, "id": str(uuid.uuid4())})

```

Want some more help managing messages in your CoAgent application? Check out our guide on [emitting messages](/crewai-flows/advanced/emit-messages).

## Message Flow

Messages flow between CopilotKit and CrewAI in a specific way:

- All messages from CrewAI are forwarded to CopilotKit
- On a fresh agent invocation, the full CopilotKit chat history is provided to the CrewAI agent as its pre-existing chat history.

When a CoAgent completes its execution, its relevant messages become part of CopilotKit's persistent chat history. This allows for all future agent invocations to get context from the full chat history.



================================================
FILE: docs/content/docs/crewai-flows/concepts/meta.json
================================================
{
  "title": "Concepts",
  "root": true,
  "pages": ["terminology", "agentic-copilots", "crewai", "message-management"]
}



================================================
FILE: docs/content/docs/crewai-flows/concepts/state.mdx
================================================
---
title: Shared State
description: CoAgents maintain a shared state across your UI and agent execution.
---

<Frame className="mb-10">
  <img
    src="/images/coagents/coagents-state-diagram.png"
    alt="Agentic Copilot State Diagram"
  />
</Frame>

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:

- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

The foundation of this system is built on CrewAI's stateful architecture. CrewAI Flow agents maintain their
internal state throughout execution, which you can access via the `useCoAgentState` hook.

### Understanding Predicted State

While your agent runs, you can emit state updates using CopilotKit's `emit_intermediate_state` function, ensuring your UI stays synchronized
with the agent's progress. The emitted state is called the **predicted state** and is used to provide immediate feedback about ongoing
operations.

While the core shared state reflects the agent's current function in the flow, the predicted state provides immediate
feedback about ongoing operations. Accordingly, this creates a more fluid user experience by showing real-time progress before the agent
completes its current task.

When the state is updated (when a function finishes executing), the predicted state is updated with the new state.

For example, when your agent is processing a request, the predicted state might show a loading indicator or partial results, while the actual
shared state updates once the operation is complete.

Want help implementing this into your CoAgent application? Check out our [intermediate state streaming](/crewai-flows/shared-state/predictive-state-updates)
documentation.



================================================
FILE: docs/content/docs/crewai-flows/concepts/terminology.mdx
================================================
---
title: Terminology
icon: lucide/Book
---

Here are the key terms and concepts used throughout CoAgents:

| Term                         | Definition                                                                                                                                                                                         |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agentic Copilot              | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously.                                                                                     |
| CoAgent                      | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot.                                                            |
| Agent State                  | The current data and context maintained by a CrewAI agent during its execution, including both internal state and data that can be synchronized with the frontend UI.                              |
| Agentic Generative UI        | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth                 | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents.            |
| Human-in-the-Loop (HITL)     | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points.                                         |
| Intermediate State           | The updates to agent state that occur during function execution, rather than only at flow transitions, enabling real-time feedback about the agent's progress.                                     |
| [CrewAI](https://crewai.com) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management.                               |
| Agent Lock Mode              | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control.                                    |
| Router Mode                  | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows.                                   |
| State Streaming              | The real-time synchronization of agent state between the backend and frontend, enabling immediate updates to the UI as the agent performs tasks.                                                   |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications.



================================================
FILE: docs/content/docs/crewai-flows/generative-ui/agentic.mdx
================================================
---
title: Agentic Generative UI
icon: "lucide/Bot"
description: Render the state of your agent with custom UI components.
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

<video
  src="/images/coagents/agentic-generative-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows).
</Callout>

## What is this?

All CrewAI Flow agents are stateful. This means that as your agent progresses through nodes, a state object is passed between them perserving
the overall state of a session. CopilotKit allows you to render this state in your application with custom UI components, which we call **Agentic Generative UI**.

## When should I use this?

Rendering the state of your agent in the UI is useful when you want to provide the user with feedback about the overall state of a session. A great example of this
is a situation where a user and an agent are working together to solve a problem. The agent can store a draft in its state which is then rendered in the UI.

## Implementation

<Steps>
  <Step>
    ### Run and Connect your CrewAI Flow to CopilotKit
    First, you'll need to make sure you have a running CrewAI Flow. If you haven't already done this, you can follow the [getting started guide](/crewai-flows/quickstart/crewai)

    This guide uses the [CoAgents starter repo](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows) as its starting point.

  </Step>
  <Step>
    ### Define your agent state
    If you're not familiar with CrewAI, your flows are stateful. As you progress through function, a state object is updated between them. CopilotKit
    allows you to easily render this state in your application. 
    
    For the sake of this guide, let's say our state looks like this in our agent.

    <Tabs groupId="language" items={['Python']} default="Python">
        <Tab value="Python">
          ```python title="agent-py/sample_agent/agent.py"
          # ...
          from copilotkit.crewai import CopilotKitState # extends MessagesState
          # ...

          # This is the state of the agent.
          # It inherits from the CopilotKitState properties from CopilotKit.
          class AgentState(CopilotKitState):
              searches: list[dict]
          ```
        </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Simulate state updates
    Next, let's write some logic into our agent that will simulate state updates occurring.

    <Tabs groupId="language" items={['Python']} default="Python">
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from crewai.flow.flow import start
        from litellm import completion
        from copilotkit.crewai import copilotkit_stream, CopilotKitState, copilotkit_emit_state
        import asyncio
        from typing import TypedDict

        class Searches(TypedDict):
            query: str
            done: bool

        class AgentState(CopilotKitState):
            searches: list[Searches] = [] # [!code highlight]

        @start
        async def chat(self):
            self.state.searches = [
                {"query": "Initial research", "done": False},
                {"query": "Retrieving sources", "done": False},
                {"query": "Forming an answer", "done": False},
            ]
            await copilotkit_emit_state(self.state)

            # Simulate state updates # [!code highlight:5]
            for search in self.state.searches:
                await asyncio.sleep(1)
                search["done"] = True
                await copilotkit_emit_state(self.state)

            # Run the model to generate a response
            response = await copilotkit_stream(
                completion(
                    model="openai/gpt-4o",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant."},
                        *self.state.get("messages", [])
                    ],
                    stream=True
                )
            )
        ```
      </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Render state of the agent in the chat
    Now we can utilize `useCoAgentStateRender` to render the state of our agent **in the chat**.

    ```tsx title="app/page.tsx"
    // ...
    import { useCoAgent, useCoAgentStateRender } from "@copilotkit/react-core";
    // ...

    // Define the state of the agent, should match the state of the agent in your Flow.
    type AgentState = {
      searches: {
        query: string;
        done: boolean;
      }[];
    };

    function YourMainContent() {
      // ...

      // [!code highlight:14]
      // styles omitted for brevity
      useCoAgentStateRender<AgentState>({
        name: "sample_agent", // the name the agent is served as
        render: ({ state }) => (
          <div>
            {state.searches?.map((search, index) => (
              <div key={index}>
                {search.done ? "✅" : "❌"} {search.query}{search.done ? "" : "..."}
              </div>
            ))}
          </div>
        ),
      });

      // ...

      return <div>...</div>;
    }
    ```

  </Step>
  <Step>
    ### Render state outside of the chat
    You can also render the state of your agent **outside of the chat**. This is useful when you want to render the state of your agent anywhere
    other than the chat.

    ```tsx title="app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]
    // ...

    // Define the state of the agent, should match the state of the agent in your Flow.
    type AgentState = {
      searches: {
        query: string;
        done: boolean;
      }[];
    };

    function YourMainContent() {
      // ...

      // [!code highlight:5]
      const { state } = useCoAgent<AgentState>({
        name: "sample_agent", // the name the agent is served as
      })

      // ...

      return (
        <div>
          {/* ... */}
          <div className="flex flex-col gap-2 mt-4">
            // [!code highlight:6]
            {state.searches?.map((search, index) => (
              <div key={index} className="flex flex-row">
                {search.done ? "✅" : "❌"} {search.query}
              </div>
            ))}
          </div>
        </div>
      )
    }
    ```

  </Step>
  <Step>
    ### Give it a try!

    You've now created a component that will render the agent's state in the chat.

  </Step>
</Steps>



================================================
FILE: docs/content/docs/crewai-flows/generative-ui/index.mdx
================================================
---
title: Generative UI
icon: "lucide/Paintbrush"
description: Render your agent's behavior with custom UI components.
---

import { CTACards } from "@/components/react/cta-cards";
import { WrenchIcon, BotIcon } from "lucide-react";

<Frame>
  <img
    src="/images/coagents/AgenticGenerativeUI.gif"
    className="my-0"
    alt="Demo of Generative UI showing a meeting scheduling agent"
  />
</Frame>

<Callout>
  This example shows our [Research Canvas](/crewai-flows/videos/research-canvas)
  making use of Generative UI!
</Callout>

## What is Generative UI?

Generative UI lets you render your agent's state, progress, outputs, and tool calls with custom UI components in real-time. It bridges the gap between AI
agents and user interfaces. As your agent processes information and makes decisions, you can render custom UI components that:

- Show loading states and progress indicators
- Display structured data in tables, cards, or charts
- Create interactive elements for user input
- Animate transitions between different states

## How can I use this?

There are two main variants of Generative UI.

<CTACards
  columns={2}
  cards={[
    {
      icon: BotIcon,
      title: "Agentic",
      description:
        "Render your agent's state, progress, and outputs with custom UI components.",
      href: "/crewai-flows/generative-ui/agentic",
    },
    {
      icon: WrenchIcon,
      title: "Tool-based",
      description: "Render your agent's tool calls with custom UI components.",
      href: "/crewai-flows/generative-ui/tool-based",
    },
  ]}
/>



================================================
FILE: docs/content/docs/crewai-flows/generative-ui/tool-based.mdx
================================================
---
title: Tool-based Generative UI
icon: "lucide/Wrench"
description: Render your agent's tool calls with custom UI components.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";

<video
  src="/images/coagents/tool-based-gen-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows).
</Callout>

## What is this?

Tools are a way for the LLM to call predefined, typically, deterministic functions. CopilotKit allows you to render these tools in the UI
as a custom component, which we call **Generative UI**.

## When should I use this?

Rendering tools in the UI is useful when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
<Step>
### Run and connect your agent

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](/crewai-flows/quickstart/crewai) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows) as a starting point
as this guide uses it as a starting point.

</Step>
<Step>
### Give your agent a tool to call

<Tabs groupId="language" items={['Python']} default="Python">
    <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        from crewai.flow.flow import start
        from litellm import completion
        # ...

        # [!code highlight:17]
        WEATHER_TOOL = {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get the weather for a given location.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "The location to get weather for"
                        }
                    },
                    "required": ["location"]
                }
            }
        }

        # ...

        @start
        async def chat(self):

            response = await copilotkit_stream(
                completion(
                    model="openai/gpt-4o",
                    messages=[
                        {"role": "system", "content": prompt},
                        *self.state.get("messages", [])
                    ],
                    tools=[WEATHER_TOOL],
                    stream=True
                )
            )

            # ...
        ```
    </Tab>

</Tabs>
</Step>
<Step>
### Render the tool call in your frontend
At this point, your agent will be able to call the `get_weather` tool. Now 
we just need to add a `useCopilotAction` hook to render the tool call in
the UI.

<Callout type="info" title="Important">
  In order to render a tool call in the UI, the name of the action must match
  the name of the tool.
</Callout>

```tsx title="app/page.tsx"
import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]
// ...

const YourMainContent = () => {
  // ...
  // [!code highlight:13]
  useCopilotAction({
    name: "get_weather",
    available: "disabled", // Don't allow the agent or UI to call this tool as its only for rendering
    render: ({ status, args }) => {
      return (
        <p className="text-gray-500 mt-2">
          {status !== "complete" && "Calling weather API..."}
          {status === "complete" &&
            `Called the weather API for ${args.location}.`}
        </p>
      );
    },
  });
  // ...
};
```

</Step>
<Step>
### Give it a try!

Try asking the agent to get the weather for a location. You should see the custom UI component that we added
render the tool call and display the arguments that were passed to the tool.

</Step>
</Steps>



================================================
FILE: docs/content/docs/crewai-flows/human-in-the-loop/flow.mdx
================================================
---
title: CrewAI Flows
description: Learn how to implement Human-in-the-Loop (HITL) using CrewAI Flows.
icon: lucide/Share2
---

import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";
import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";

<video
  src="/images/coagents/node-hitl.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

<Callout type="info">
  Pictured above is the [coagent
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter)
  with the implementation below applied!
</Callout>

## What is this?

[Flow based agents](https://docs.crewai.com/concepts/flows) are stateful agents that can be interrupted and resumed
to allow for user input.

CopilotKit lets you to add custom UI to take user input and then pass it back to the agent upon completion.

## Why should I use this?

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

Flow based agents are a great way to implement HITL for more complex workflows where you want to ensure the agent is aware
of everything that has happened during a HITL interaction.

## Implementation

<Steps>
    <Step>
        ### Run and connect your agent

        You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
        you can follow the instructions in the [Getting Started](/crewai-flows/quickstart/crewai) guide.

        If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows) as a starting point
        as this guide uses it as a starting point.
    </Step>

    <Step>
      ### Install the CopilotKit SDK
      <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Add a `useCopilotAction` to your Frontend
        First, we'll create a component that renders the agent's essay draft and waits for user approval.

        ```tsx title="ui/app/page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core"
        import { Markdown } from "@copilotkit/react-ui"

        function YourMainContent() {
          // ...

          useCopilotAction({
            name: "writeEssay",
            available: "remote",
            description: "Writes an essay and takes the draft as an argument.",
            parameters: [
              { name: "draft", type: "string", description: "The draft of the essay", required: true },
            ],
            // [!code highlight:25]
            renderAndWaitForResponse: ({ args, respond, status }) => {
              return (
                <div>
                  <Markdown content={args.draft || 'Preparing your draft...'} />

                  <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
                    <button
                      onClick={() => respond?.("CANCEL")}
                      disabled={status !== "executing"}
                      className="border p-2 rounded-xl w-full"
                    >
                      Try Again
                    </button>
                    <button
                      onClick={() => respond?.("SEND")}
                      disabled={status !== "executing"}
                      className="bg-blue-500 text-white p-2 rounded-xl w-full"
                    >
                      Approve Draft
                    </button>
                  </div>
                </div>
              );
            },
          });

          // ...
        }
        ```
    </Step>

    <Step>
    ### Setup the CrewAI Agent
    Now we'll setup the CrewAI agent. The flow is hard to understand without a complete example, so below
    is the complete implementation of the agent with explanations.

    Some main things to note:
    - The agent's state inherits from `CopilotKitState` to bring in the CopilotKit actions.
    - CopilotKit's actions are bound to the model as tools.
    - If the `writeEssay` action is found in the model's response, the agent will pass control back to the frontend
      to get user feedback.

    <Tabs groupId="language" items={["Python"]}>
      <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        from typing import Any, cast
        from crewai.flow.flow import Flow, start, listen
        from copilotkit import CopilotKitState
        from copilotkit.crewai import copilotkit_stream
        from litellm import completion


        class AgentState(CopilotKitState):
            pass


        class SampleAgentFlow(Flow[AgentState]):

            @start()
            async def check_for_user_feedback(self):
                if not self.state.get("messages"):
                    return

                last_message = cast(Any, self.state["messages"][-1])

                # Expecting the result of a CopilotKit tool call (SEND/CANCEL)
                if last_message["role"] == "tool":
                    user_response = last_message.get("content")

                    if user_response == "SEND":
                        self.state["messages"].append({
                            "role": "assistant",
                            "content": "✅ Great! Sending your essay via email.",
                        })
                        return

                    if user_response == "CANCEL":
                        self.state["messages"].append({
                            "role": "assistant",
                            "content": "❌ Okay, we can improve the draft. What would you like to change?",
                        })
                        return

                # If no tool result yet, or it's a user message, prompt next step
                if last_message.get("role") == "user":
                    self.state["messages"].append({
                        "role": "system",
                        "content": (
                            "You write essays. Use your tools to write an essay; "
                            "don’t just write it in plain text."
                        )
                    })

            @listen(check_for_user_feedback)
            async def chat(self):
                messages = self.state.get("messages", [])

                system_message = {
                    "role": "system",
                    "content": (
                        "You write essays. Use your tools to write an essay; "
                        "don’t just write it in plain text."
                    )
                }

                response = await copilotkit_stream(
                    completion(
                        model="openai/gpt-4o",
                        messages=[system_message, *messages],
                        tools=self.state["copilotkit"]["actions"],
                        stream=True
                    )
                )

                self.state["messages"].append(response.choices[0].message)  
        ```
      </Tab>
    </Tabs>
    </Step>
    <Step>
        ### Give it a try!
        Try asking your agent to write an essay about the benefits of AI. You'll see that it will generate an essay,
        stream the progress and eventually ask you to review it.
    </Step>

</Steps>



================================================
FILE: docs/content/docs/crewai-flows/human-in-the-loop/index.mdx
================================================
---
title: Human in the Loop (HITL)
icon: "lucide/User"
description: Allow your agent and users to collaborate on complex tasks.
---

import { CTACards } from "@/components/react/cta-cards";
import { Pause, Share2 } from "lucide-react";

<video
  src="/images/coagents/human-in-the-loop-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

{/* TODO-DOCS-CREWAI-FLOWS: Add Travel App Example */}
{/* <Callout>
This video shows an example of our [AI Travel App](/coagents/tutorials/ai-travel-app) using HITL to get user feedback.

</Callout> */}

## What is Human-in-the-Loop (HITL)?

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

<Frame className="my-0">
  <img
    src="/images/coagents/coagents-hitl-infographic.png"
    alt="Agentic Copilot Human in the Loop"
    className="mt-4 mb-0 shadow-md"
  />
</Frame>

## When should I use this?

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## How can I use this?

Read more about the approach to HITL in CrewAI Flows.

<CTACards
  columns={1}
  cards={[
    {
      icon: Share2,
      title: "Flow-based",
      description:
        "Utilize CrewAI Flows to create Human-in-the-Loop workflows.",
      href: "/crewai-flows/human-in-the-loop/flow",
    },
  ]}
/>



================================================
FILE: docs/content/docs/crewai-flows/human-in-the-loop/meta.json
================================================
{
  "pages": ["flow"]
}



================================================
FILE: docs/content/docs/crewai-flows/persistence/loading-agent-state.mdx
================================================
---
title: Loading Agent State
description: Learn how threadId is used to load previous agent states.
icon: "lucide/ChartBar"
---

### Setting the threadId

When setting the `threadId` property in CopilotKit, i.e:

```tsx
<CopilotKit threadId="2140b272-7180-410d-9526-f66210918b13">
  <YourApp />
</CopilotKit>
```

CopilotKit will restore the complete state of the thread, including the messages, from the database.
(See [Message Persistence](/crewai-flows/persistence/message-persistence) for more details.)

### Loading Agent State

<Callout>
  **Important:** For agent state to be loaded correctly, you must first ensure
  that message history and persistence are properly configured. Follow the
  guides on [Threads &
  Persistence](/crewai-flows/persistence/loading-message-history) and [Message
  Persistence](/crewai-flows/persistence/message-persistence).
</Callout>

This means that the state of any agent will also be restored. For example:

```tsx
const { state } = useCoAgent({ name: "research_agent" });

// state will now be the state of research_agent in the thread id given above
```

### Learn More

To learn more about persistence and state in CopilotKit, see:

- [Reading agent state](/crewai-flows/shared-state/in-app-agent-read)
- [Writing agent state](/crewai-flows/shared-state/in-app-agent-write)
- [Loading Message History](/crewai-flows/persistence/loading-message-history)



================================================
FILE: docs/content/docs/crewai-flows/persistence/loading-message-history.mdx
================================================
---
title: Threads
description: Learn how to maintain persistent conversations across sessions with CrewAI Flows.
icon: "lucide/MessagesSquare"
---

# Understanding Thread Persistence

CrewAI Flows supports threads, a way to group messages together and maintain a continuous chat history across sessions. CopilotKit provides mechanisms to ensure conversation state is properly persisted between the frontend and backend.

This guide assumes you have already gone through the [quickstart](/quickstart) guide.

<Callout>
  **Note:** While the frontend uses `threadId` to manage conversation sessions,
  true persistence across sessions requires backend setup. The backend agent
  needs to implement a persistence mechanism (like the one shown in
  [Message Persistence](/crewai-flows/persistence/message-persistence))
  to save and load the state associated with each `threadId`.

See the [sample agent implementation](https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-starter-crewai-flows/agent-py/sample_agent/agent.py#L291)
for a concrete example.

</Callout>

## Frontend: Setting the ThreadId

### Loading an Existing Thread

To load an existing thread in CopilotKit, set the `threadId` property on `<CopilotKit>`:

```tsx
import { CopilotKit } from "@copilotkit/react-core";

<CopilotKit threadId="37aa68d0-d15b-45ae-afc1-0ba6c3e11353">
  <YourApp />
</CopilotKit>;
```

### Dynamically Switching Threads

You can make the `threadId` dynamic. Once set, CopilotKit will load previous messages for that thread.

```tsx
import { useState } from "react";
import { CopilotKit } from "@copilotkit/react-core";

const Page = () => {
  const [threadId, setThreadId] = useState(
    "af2fa5a4-36bd-4e02-9b55-2580ab584f89"
  );
  return (
    <CopilotKit threadId={threadId}>
      <YourApp setThreadId={setThreadId} />
    </CopilotKit>
  );
};

const YourApp = ({ setThreadId }) => {
  return (
    <Button onClick={() => setThreadId("679e8da5-ee9b-41b1-941b-80e0cc73a008")}>
      Change Thread
    </Button>
  );
};
```

### Using setThreadId

CopilotKit provides the current `threadId` and a `setThreadId` function from the `useCopilotContext` hook:

```tsx
import { useCopilotContext } from "@copilotkit/react-core";

const ChangeThreadButton = () => {
  const { threadId, setThreadId } = useCopilotContext();
  return (
    <Button onClick={() => setThreadId("d73c22f3-1f8e-4a93-99db-5c986068d64f")}>
      Change Thread
    </Button>
  );
};
```



================================================
FILE: docs/content/docs/crewai-flows/persistence/message-persistence.mdx
================================================
---
title: "Message Persistence"
icon: "lucide/Database"
---

<Callout>
  To learn about how to load previous messages and agent states, check out the
  [Loading Message History](/crewai-flows/persistence/loading-message-history)
  and [Loading Agent State](/crewai-flows/persistence/loading-agent-state)
  pages.
</Callout>

To persist CrewAI Flow messages to a database, you can use the `@persist` decorator. For example, you might use the default `SQLiteFlowPersistence` or provide your own custom persistence class.

For a concrete example of how a custom persistence class like `InMemoryFlowPersistence` can be implemented and used with the `@persist` decorator, see the [sample agent implementation](https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-starter-crewai-flows/agent-py/sample_agent/agent.py).

Read more about persistence in the [CrewAI Flows documentation](https://docs.crewai.com/concepts/flows#class-level-persistence).



================================================
FILE: docs/content/docs/crewai-flows/persistence/meta.json
================================================
{
    "title": "Persistence",
    "icon": "lucide/Database"
}


================================================
FILE: docs/content/docs/crewai-flows/shared-state/in-app-agent-read.mdx
================================================
---
title: Reading agent state
icon: "lucide/ArrowLeft"
description: Read the realtime agent state in your native application.
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<Frame>
  <ImageZoom
    src="/images/coagents/read-agent-state.png"
    alt="read agent state"
    width={1000}
    height={1000}
    className="my-0"
  />
</Frame>

<Callout type="info">
  Pictured above is the [coagent
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter)
  with the [implementation](#implementation) section applied!
</Callout>

## What is this?

You can easily use the realtime agent state not only in the chat UI, but also in the native application UX.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent's state. As your agent's
state update you can reflect these updates natively in your application.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Define the Agent State
    CrewAI Flows are stateful. As you transition through the flow, that state is updated and available to the next function. For this example,
    let's assume that our agent state looks something like this.

    <Tabs groupId="language" items={["Python"]}>
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from copilotkit.crewai import CopilotKitState
        from typing import Literal

        class AgentState(CopilotKitState):
            language: Literal["english", "spanish"] = "english"
        ```
      </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Use the `useCoAgent` Hook
    With your agent connected and running all that is left is to call the [useCoAgent](/reference/hooks/useCoAgent) hook, pass the agent's name, and
    optionally provide an initial state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    function YourMainContent() {
      const { state } = useCoAgent<AgentState>({ // [!code highlight:4]
        name: "sample_agent",
        initialState: { language: "spanish" }  // optionally provide an initial state
      });

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your main content</h1>
          <p>Language: {state.language}</p> // [!code highlight]
        </div>
      );
    }
    ```
    <Callout type="info">
      The `state` in `useCoAgent` is reactive and will automatically update when the agent's state changes.
    </Callout>

  </Step>
  <Step>
    ### Give it a try!
    As the agent state updates, your `state` variable will automatically update with it! In this case, you'll see the
    language set to "spanish" as that's the initial state we set.
  </Step>
</Steps>

## Rendering agent state in the chat

You can also render the agent's state in the chat UI. This is useful for informing the user about the agent's state in a
more in-context way. To do this, you can use the [useCoAgentStateRender](/reference/hooks/useCoAgentStateRender) hook.

```tsx title="ui/app/page.tsx"
import { useCoAgentStateRender } from "@copilotkit/react-core"; // [!code highlight]

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
};

function YourMainContent() {
  // ...
  // [!code highlight:8]
  useCoAgentStateRender({
    name: "sample_agent",
    render: ({ state }) => {
      if (!state.language) return null;
      return <div>Language: {state.language}</div>;
    },
  });
  // ...
}
```

<Callout type="info">
  The `state` in `useCoAgentStateRender` is reactive and will automatically
  update when the agent's state changes.
</Callout>

## Intermediately Stream and Render Agent State

By default, the CrewAI Flow agent state will only update _between_ CrewAI Flow node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](/crewai-flows/shared-state/predictive-state-updates).**



================================================
FILE: docs/content/docs/crewai-flows/shared-state/in-app-agent-write.mdx
================================================
---
title: Writing agent state
icon: "lucide/ArrowRight"
description: Write to agent's state from your application.
---

<video
  src="/images/coagents/write-agent-state.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows)
  repo with the previous steps applied to it!
</Callout>

## What is this?

This guide shows you how to write to your agent's state from your application.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Define the Agent State
    CrewAI Flows are stateful. As you transition through the flow, that state is updated and available to the next function. For this example,
    let's assume that our agent state looks something like this.

    <Tabs groupId="language" items={["Python", "TypeScript"]}>
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        from copilotkit.crewai import CopilotKitState
        from typing import Literal

        class AgentState(CopilotKitState):
            language: Literal["english", "spanish"] = "english"
        ```
      </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Call `setState` function from the `useCoAgent` hook
    `useCoAgent` returns a `setState` function that you can use to update the agent state. Calling this
    will update the agent state and trigger a rerender of anything that depends on the agent state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    // Example usage in a pseudo React component
    function YourMainContent() {
      const { state, setState } = useCoAgent<AgentState>({ // [!code highlight]
        name: "sample_agent",
        initialState: { language: "spanish" }  // optionally provide an initial state
      });

      // ...

      const toggleLanguage = () => {
        setState({ language: state.language === "english" ? "spanish" : "english" }); // [!code highlight]
      };

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your main content</h1>
          <p>Language: {state.language}</p> // [!code highlight:2]
          <button onClick={toggleLanguage}>Toggle Language</button>
        </div>
      );
    }
    ```

  </Step>
  <Step>
    ### Give it a try!
    You can now use the `setState` function to update the agent state and `state` to read it. Try toggling the language button
    and talking to your agent. You'll see the language change to match the agent's state.
  </Step>
</Steps>

## Advanced Usage

### Re-run the agent with a hint about what's changed

The new agent state will be used next time the agent runs.
If you want to re-run it manually, use the `run` argument on the `useCoAgent` hook.

The agent will be re-run, and it will get not only the latest updated state, but also a **hint** that can depend on the data delta between the previous and the current state.

```tsx title="ui/app/page.tsx"
import { useCoAgent } from "@copilotkit/react-core";
import { TextMessage, MessageRole } from "@copilotkit/runtime-client-gql";  // [!code highlight]

// ...

function YourMainContent() {
  const { state, setState, run } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // setup to be called when some event in the app occurs
  const toggleLanguage = () => {
    const newLanguage = state.language === "english" ? "spanish" : "english";
    setState({ language: newLanguage });

    // re-run the agent and provide a hint about what's changed
    run(({ previousState, currentState }) => { // [!code highlight:6]
      return new TextMessage({
        role: MessageRole.User,
        content: `the language has been updated to ${currentState.language}`,
      });
    });
  };

  return (
    // ...
  );
}
```

### Intermediately Stream and Render Agent State

By default, the CrewAI Flow agent state will only update _between_ CrewAI Flow node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](/crewai-flows/shared-state/intermediate-state-streaming).**



================================================
FILE: docs/content/docs/crewai-flows/shared-state/index.mdx
================================================
---
title: Shared State
description: Create a two-way connection between your UI and agent state.
icon: "lucide/Repeat"
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<ImageZoom
  src="/images/coagents/SharedStateCoAgents.gif"
  alt="Shared State Demo"
  width={1000}
  height={1000}
  className="rounded-lg shadow-lg border mt-0"
/>

<Callout>
  This video demonstrates the [Research
  Canvas](/crewai-flows/examples/research-canvas) utilizing shared state.
</Callout>

## What is shared state?

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:

- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

<Frame>
  <img
    src="/images/coagents/coagents-state-diagram.png"
    alt="Agentic Copilot State Diagram"
  />
</Frame>

The foundation of this system is built on CrewAI's stateful architecture.

## When should I use this?

State streaming is perfect when you want to facilitate collaboration between your agent and the user. Any state that your CrewAI Flow
persists will be automatically shared by the UI. Similarly, any state that the user updates in the UI will be automatically reflected

This allows for a consistent experience where both the agent and the user are on the same page.



================================================
FILE: docs/content/docs/crewai-flows/shared-state/meta.json
================================================
{
    "pages": [
        "in-app-agent-read",
        "in-app-agent-write",
        "predictive-state-updates"
    ]
}


================================================
FILE: docs/content/docs/crewai-flows/shared-state/predictive-state-updates.mdx
================================================
---
title: "Predictive state updates"
icon: "lucide/Podcast"
description: Stream in-progress agent state updates to the frontend.
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import InstallSDKSnippet from "@/snippets/install-python-sdk-crew.mdx";
import { FaWrench } from "react-icons/fa";
import { FaArrowUp } from "react-icons/fa";

<video
  src="/images/coagents/intermediate-state-render.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-flows)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

A CrewAI Flow's state updates discontinuosly; only across function transitions in the flow.
But even a _single function_ in the flow often takes many seconds to run and contain sub-steps of interest to the user.

**Agent-native applications** reflect to the end-user what the agent is doing **as continuously possible.**

CopilotKit enables this through its concept of **_predictive state updates_**.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent is doing, specifically to:

- **Keep users engaged** by avoiding long loading indicators
- **Build trust** by demonstrating what the agent is working on
- Enable **agent steering** - allowing users to course-correct the agent if needed

## Important Note

When a function in your CrewAI flow finishes executing, **its returned state becomes the single source of truth**.
While intermediate state updates are great for real-time feedback, any changes you want to persist must be explicitly
included in the function's final returned state. Otherwise, they will be overwritten when the function completes.

## Implementation

<Steps>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Define the state
        We'll be defining a `observed_steps` field in the state, which will be updated as the agent writes different sections of the report.

        <Tabs groupId="language" items={["Python"]}>
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                from copilotkit.crewai import CopilotKitState
                from typing import Literal

                class AgentState(CopilotKitState):
                    observed_steps: list[str]  # Array of completed steps
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Emit the intermediate state
        <TailoredContent
            className="step"
            id="state-emission"
            header={
                <div>
                    <p className="text-xl font-semibold">How would you like to emit state updates?</p>
                    <p className="text-base">
                        You can either manually emit state updates or configure specific tool calls to emit updates.
                    </p>
                </div>
            }
        >
            <TailoredContentOption
                id="manual-emission"
                title="Manual Predictive State Updates"
                description="Manually emit state updates for maximum control over when updates occur."
                icon={<FaArrowUp />}
            >
                For long-running tasks, you can emit state updates progressively as predictions of the final state. In this example, we simulate a long-running task by executing a series of steps with a one second delay between each update.
                <Tabs groupId="language" items={['Python']} default="Python">
                    <Tab value="Python">
                        ```python title="agent-py/sample_agent/agent.py"
                        from copilotkit.crewai import copilotkit_emit_state # [!code highlight]
                        from crewai.flow.flow import Flow, start
                        import asyncio

                        class SampleAgentFlow(Flow):
                            # ...
                            @start()
                            async def start_flow(self):
                                # ...

                                # Simulate executing steps one by one
                                steps = [
                                    "Analyzing input data...",
                                    "Identifying key patterns...",
                                    "Generating recommendations...",
                                    "Formatting final output..."
                                ]

                                for step in steps:
                                    self.state["observed_steps"] = self.state.get("observed_steps", []) + [step]
                                    await copilotkit_emit_state(self.state) # [!code highlight]
                                    await asyncio.sleep(1)

                            # ...
                        ```
                    </Tab>
                </Tabs>
            </TailoredContentOption>

            <TailoredContentOption
                id="tool-emission"
                title="Tool-Based Predictive State Updates"
                description="Configure specific tool calls to automatically emit intermediate state updates."
                icon={<FaWrench />}
            >
                For long-running tasks, you can configure CopilotKit to automatically predict state updates when specific tool calls are made. In this example, we'll configure CopilotKit to predict state updates whenever the LLM calls the step progress tool.
                <Tabs groupId="language" items={['Python']} default="Python">
                    <Tab value="Python">
                        ```python
                        from copilotkit.crewai import copilotkit_predict_state
                        from crewai.flow.flow import Flow, start

                        class SampleAgentFlow(Flow):

                            @start
                            async def start_flow(self):
                                # Tell CopilotKit to treat step progress tool calls as predictive of the final state
                                copilotkit_predict_state({
                                    "observed_steps": {
                                        "tool": "StepProgressTool",
                                        "tool_argument": "steps"
                                    }
                                })

                                step_progress_tool = {
                                    "type": "function",
                                    "function": {
                                        "name": "StepProgressTool",
                                        "description": "Records progress by updating the steps array",
                                        "parameters": {
                                            "type": "object",
                                            "properties": {
                                                "steps": {
                                                    "type": "array",
                                                    "items": {"type": "string"},
                                                    "description": "Array of completed steps"
                                                }
                                            },
                                            "required": ["steps"]
                                        }
                                    }
                                }

                                # Provide the tool to the LLM and call the model
                                response = await copilotkit_stream(
                                    completion(
                                        model="openai/gpt-4o",
                                        messages=[
                                            {
                                                "role": "system",
                                                "content": "You are a task performer. Pretend doing tasks you are given, report the steps using StepProgressTool." # [!code highlight]
                                            },
                                            *self.state.get("messages", [])
                                        ],
                                        tools=[step_progress_tool],
                                        stream=True
                                    )
                                )
                        ```
                    </Tab>
                </Tabs>
            </TailoredContentOption>
        </TailoredContent>
    </Step>
    <Step>
        ### Observe the predictions
        These predictions will be emitted as the agent runs, allowing you to track its progress before the final state is determined.

        ```tsx title="ui/app/page.tsx"
        import { useCoAgent, useCoAgentStateRender } from '@copilotkit/react-core';

        // ...

        const YourMainContent = () => {
            // Get access to both predicted and final states
            const { state } = useCoAgent({ name: "sample_agent" });

            // Add a state renderer to observe predictions
            useCoAgentStateRender({
                name: "sample_agent",
                render: ({ state }) => {
                    if (!state.observed_steps?.length) return null;
                    return (
                        <div>
                            <h3>Current Progress:</h3>
                            <ul>
                                {state.observed_steps.map((step, i) => (
                                    <li key={i}>{step}</li>
                                ))}
                            </ul>
                        </div>
                    );
                },
            });

            return (
                <div>
                    <h1>Agent Progress</h1>
                    {state.observed_steps?.length > 0 && (
                        <div>
                            <h3>Final Steps:</h3>
                            <ul>
                                {state.observed_steps.map((step, i) => (
                                    <li key={i}>{step}</li>
                                ))}
                            </ul>
                        </div>
                    )}
                </div>
            )
        }
        ```
    </Step>
    <Step>
        ### Give it a try!
        Now you'll notice that the state predictions are emitted as the agent makes progress, giving you insight into its work before the final state is determined.
        You can apply this pattern to any long-running task in your agent.
    </Step>

</Steps>



================================================
FILE: docs/content/docs/crewai-flows/troubleshooting/common-issues.mdx
================================================
---
title: Common Issues
description: Common issues you may encounter when using CoAgents.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

Welcome to the CoAgents Troubleshooting Guide! If you're having trouble getting tool calls to work, you've come to the right place.

<Callout>
    Have an issue not listed here? Open a ticket on [GitHub](https://github.com/CopilotKit/CopilotKit/issues) or reach out on [Discord](https://discord.com/invite/6dffbvGU3D)
    and we'll be happy to help.

    We also highly encourage any open source contributors that want to add their own troubleshooting issues to [Github as a pull request](https://github.com/CopilotKit/CopilotKit/blob/main/CONTRIBUTING.md).

</Callout>

## My tool calls are not being streamed

This could be due to a few different reasons.

First, we strongly recommend checking out our [Human In the Loop](/coagents/human-in-the-loop) guide to follow a more in depth example of how to stream tool calls
in your Flow agents. You can also check out our [travel tutorial](/coagents/tutorials/ai-travel-app/step-6-human-in-the-loop) which talks about how to stream
tool calls in a more complex example.

If you have already done that, you can check the following:

<Accordions>
    <Accordion title="You have not specified the tool call in the `copilotkit_customize_config`">
        In your Flow agent, you have must specify which tool calls will be emitted to the CopilotKit runtime. By default,
        only streamed messages are emitted. You can fix this by adding the following to the node making the tool call.

        ```python
        from copilotkit.Flow import copilotkit_customize_config, copilotkit_emit_message
        from langgraph_core.runnables import RunnableConfig
        from langchain.tools import tool

        @tool
        def say_hello_to(name: str) -> str:
            return f"Hello, {name}!"

        async def my_node(state: State, config: RunnableConfig) -> State:
            # ...
            config = copilotkit_customize_config(config, emit_tool_calls=["say_hello_to"]) # [code highlight]
            # ...
            return state
        ```
    </Accordion>
    <Accordion title="You're using llm.invoke() instead of llm.ainvoke()">
        <p>
            When you invoke your Flow agent, you can invoke it synchronously or asynchronously. If you invoke it synchronously,
            the tool calls will not be streamed progressively, only the final result will be streamed. If you invoke it asynchronously,
            the tool calls will be streamed progressively.

            ```python
            config = copilotkit_customize_config(config, emit_tool_calls=["say_hello_to"])
            response = await llm_with_tools.ainvoke(
                [ SystemMessage(content=system_message), *state["messages"] ],
                config=config
            )
            ```
        </p>
    </Accordion>

</Accordions>

## Error: `'AzureOpenAI' object has no attribute 'bind_tools'`

This error is typically due to the use of an incorrect import from Flow. Instead of importing `AzureOpenAI` import `AzureChatOpenAI` and your
issue will be resolved.

```python
from langchain_openai import AzureOpenAI # [!code --]
from langchain_openai import AzureChatOpenAI # [!code ++]
```

## I am getting "agent not found" error

If you're seeing this error, it means CopilotKit couldn't find the Flow agent you're trying to use. Here's how to fix it:

<Accordions>
    <Accordion title="Verify your agent lock mode configuration">
        If you're using [agent lock mode](/coagents/multi-agent-flows),
        check that the agent defined in `Flow.json` matches what's defined in the CopilotKit provider:

        ```json title="Flow.json"
        {
            "python_version": "3.12",
            "dockerfile_lines": [],
            "dependencies": ["."],
            "graphs": {
                "my_agent": "./src/agent.py:graph"// In this case, "my_agent" is the agent you're using // [!code highlight]
            },
            "env": ".env"
        }
        ```

        ```tsx title="layout.tsx"
        <CopilotKit agent="my_agent"> // [!code highlight]
            {/* Your application components */}
        </CopilotKit>
        ```

        Common issues:
        - Typos in agent names
        - Case sensitivity mismatches
        - Missing entries in `Flow.json`
    </Accordion>
</Accordions>

## Connection issues with tunnel creation

If you notice the tunnel creation process spinning indefinitely, your router or ISP might be blocking the connection to CopilotKit's tunnel service.

<Accordions>
    <Accordion title="Router or ISP blocking tunnel connections">
        To verify connectivity to the tunnel service, try these commands:

        ```bash
        ping tunnels.devcopilotkit.com
        curl -I https://tunnels.devcopilotkit.com
        telnet tunnels.devcopilotkit.com 443
        ```

        If these fail, your router's security features or ISP might be blocking the connection. Common solutions:
        - Check router security settings
        - Consider checking with your ISP about any connection restrictions
        - Try using a mobile hotspot
    </Accordion>

</Accordions>



================================================
FILE: docs/content/docs/crewai-flows/troubleshooting/migrate-from-v0.2-to-v0.3.mdx
================================================
---
title: Migrate from v0.2 to v0.3
description: How to migrate from v0.2 to v0.3.
---

## What's new in v0.3?

Starting with `v0.3`, we changed how messages are synced between the agent (Flow) and CopilotKit. Essentially, both will now share exactly the same message history.

This means that you need to return the messages you want to appear in CopilotKit chat from your Flow nodes, for example:

```python
def my_node(state: State, config: RunnableConfig) -> State:
    response = # ... llm call ...
    return {
        "messages": response,
    }
```

All tool messages are now emitted by default, so you don't need to manually call `copilotkit_customize_config` to configure tool call emissions.

<Frame>
    <img src="/images/coagents-v-0-3-migration-image.png" />
</Frame>

## How do I migrate?

1. Make sure to return any messages (tool calls or text messages) you want to be part of the message history from your LangGraph nodes.

2. Optionally, remove manual `copilotkit_customize_config` calls when you want to emit tool calls.

3. If you want to hide tool calls or messages from the chat, use `copilotkit_customize_config` and set `emit_tool_calls` or `emit_messages` to `False`. Make sure to not return these messages in your nodes so they don't become part of the message history.



================================================
FILE: docs/content/docs/mastra/agentic-chat-ui.mdx
================================================
---
title: Chat with an Agent
icon: "lucide/SendHorizontal"
description: Chat with an agent using CopilotKit's UI components.
---

import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import ComponentExamples from "@/snippets/component-examples.mdx";
import { UserIcon, PaintbrushIcon, WrenchIcon, RepeatIcon } from "lucide-react";

<video
  src="/images/coagents/agentic-chat-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/mastra/starter)
  repo with various Copilot UI components applied to it!
</Callout>

## What is this?

Agentic chat UIs are ways for your users to interact with your agent. CopilotKit provides a variety of different components to choose from, each
with their own unique use cases.

If you've gone through the [getting started guide](/mastra/quickstart/mastra) **you already have a agentic chat UI setup**! Nothing else is needed
to get started.

## When should I use this?

CopilotKit provides a variety of different batteries-included components to choose from to create agent native applications. They scale
from simple chat UIs to completely custom applications.

<ComponentExamples components={props.components} /> 


================================================
FILE: docs/content/docs/mastra/frontend-actions.mdx
================================================
---
title: Frontend Actions
icon: "lucide/Wrench"
description: Create frontend actions and use them within your agent.
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/frontend-actions-demo.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-mastra)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## When should I use this?

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## Implementation

<Steps>
    <Step>
        ### Setup CopilotKit

        To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here.

        Check out our [getting started guide](/mastra/quickstart/mastra) and come back here when you're setup!
    </Step>

    <Step>
        ### Create a frontend action

        First, you'll need to create a frontend action using the [useCopilotAction](/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
        that says hello to the user.

        ```tsx title="page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core" // [!code highlight]

        export function Page() {
          // ...

          // [!code highlight:16]
          useCopilotAction({
            name: "sayHello",
            description: "Say hello to the user",
            available: "remote", // optional, makes it so the action is *only* available to the agent
            parameters: [
              {
                name: "name",
                type: "string",
                description: "The name of the user to say hello to",
                required: true,
              },
            ],
            handler: async ({ name }) => {
              alert(`Hello, ${name}!`);
            },
          });

          // ...
        }
        ```
    </Step>
    <Step>
        ###  Modify your agent
        Now, we'll need to modify the agent to access these frontend actions. Open up for your agent's folder and continue from there!
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Accessing Frontend Actions

        Since Mastra includes native support for the AG-UI protocol, frontend actions are automatically available to the agent as
        tools.
    </Step>
    <Step>
        ### Give it a try!
        You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/mastra/index.mdx
================================================
---
title: Introduction
icon: "lucide/Sparkles"
description: Build Agent-Native Applications (ANAs) powered by CopilotKit and Mastra Agents.
---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { FaDiscord } from "react-icons/fa";
import Link from "next/link";
import { TelescopeIcon } from "lucide-react";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import {
  LuPlane,
  LuBookOpen,
  LuLightbulb,
  LuLayoutTemplate,
  LuBrainCog,
  LuUserCog,
  LuWand2,
  LuPlay,
  LuMessageSquare,
  LuWrench,
} from "react-icons/lu";
import { CoAgentsExamples } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { FaSync } from "react-icons/fa";
import { Socials } from "@/components/react/socials";

<div className="p-4 mb-6 rounded-lg bg-gray-100 dark:bg-gray-800 border border-gray-200 dark:border-gray-700">
  <div className="flex items-center gap-2 mb-2">
    <TelescopeIcon className="h-5 w-5 text-gray-700 dark:text-gray-300" />
    <h3 className="text-lg font-semibold text-gray-700 dark:text-gray-300">Mastra Overview</h3>
  </div>
  <p className="text-gray-700 dark:text-gray-300">
    Visit the <a href="https://v0-mastra-land.vercel.app/" target="_blank" rel="noopener noreferrer" className="font-medium underline underline-offset-4 decoration-gray-400 dark:decoration-gray-500 hover:text-gray-900 dark:hover:text-gray-100">Mastra Overview Page</a> to learn more about Mastra's capabilities and features.
  </p>
</div>

# Copilot Infrastructure for Mastra Agents

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).


## Building blocks of a CoAgent

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<LuMessageSquare />}
    title="Agentic Chat UI"
    description="In-app chat powered by your agent."
    href="/mastra/agentic-chat-ui"
  />
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<LuLayoutTemplate />}
    title="Generative UI"
    description="UI that updates in real-time based on your agent's state."
    href="/mastra/generative-ui"
  />
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<LuWand2 />}
    title="Frontend Tools"
    description="Give your agent the ability to take action in your application."
    href="/mastra/frontend-actions"
  />
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<LuWand2 />}
    title="Multi-Agent Coordination"
    description="Route your agent to the right agent based on the user's request."
    href="/mastra/multi-agent-flows"
  />
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<LuUserCog />}
    title="Human-in-the-Loop"
    description="Set smart checkpoints where humans can guide your agents."
    href="/mastra/human-in-the-loop"
  />
</Cards>

## Ready to get started?

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

<Cards className="gap-6">
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<LuPlay />}
    title="Quickstart"
    description="Learn how to build your first CoAgent in 10 minutes."
    href="/mastra/quickstart"
  />
  <Card
    className="p-6 rounded-xl text-base border-black dark:border-white"
    icon={<TelescopeIcon />}
    title="Feature Overview"
    description="Try the key features of CoAgents powered by Mastra Agents."
    href="https://copilotkit-mastra-feature-viewer.vercel.app/"
    target="_blank"
  />
</Cards>

{/* TODO: Add example tutorials for Mastra Agents */}

## Common Questions

Have a question about CoAgents? You're in the right place!

<Accordions>
<Accordion title="Can you explain what a CoAgent is in more detail?">
Sure! CoAgents are what we call "agentic copilots". Well, what's an agentic copilot then?

Think of a Copilot as a simple and fully LLM controlled assistant that has relatively limited capabilities. An Agentic Copilot then is a copilot
that has been enhanced with the ability to use Mastra agents to perform more complex tasks. This is an extremely powerful way to build AI
powered applications because it gives you, the developer, the ability to control the agent's behavior in a deterministic way while still letting
the agent do its magic.

For more on this topic, checkout our [agentic copilot](/mastra/concepts/agentic-copilots) concept page.

</Accordion>
</Accordions> 


================================================
FILE: docs/content/docs/mastra/meta.json
================================================
{
  "title": "CoAgents",
  "root": true,
  "pages": [
    "index",
    "quickstart",
    "[lucide/Telescope][Feature Viewer](https://copilotkit-mastra-feature-viewer.vercel.app/)",
    "---Guides---",
    "agentic-chat-ui",
    "generative-ui",
    "human-in-the-loop",
    "frontend-actions",
    "multi-agent-flows",
    "---Learn---",
    "...concepts"
  ]
}



================================================
FILE: docs/content/docs/mastra/multi-agent-flows.mdx
================================================
---
title: Multi-Agent Flows
description: Use multiple agents to orchestrate complex flows.
icon: "lucide/Users"
---
import { Callout } from "fumadocs-ui/components/callout";

## What are Multi-Agent Flows?

When building agentic applications, you often want to orchestrate complex flows together that require the coordination of multiple
agents. This is traditionally called multi-agent orchestration.

## When should I use this?

Multi-agent flows are useful when you want to orchestrate complex flows together that require the coordination of multiple agents. As
your agentic application grows, delegation of sub-tasks to other agents can help you scale key pieces of your application.
- Divide context into smaller chunks
- Delegate sub-tasks to other agents
- Use a single agent to orchestrate the flow

## How does CopilotKit support this?

CopilotKit can be used in either of two distinct modes: **Router Mode**, or **Agent Lock**. By default, CopilotKit
will use Router Mode, leveraging your defined LLM to route requests between agents.

### Router Mode (default)
Router Mode is enabled by default when using CoAgents. To use it, specify a runtime URL prop in the `CopilotKit` provider component and omit the `agent` prop, like so:
```tsx
<CopilotKit runtimeUrl="<copilot-runtime-url>">
  {/* Your application components */}
</CopilotKit>
```

In router mode, CopilotKit acts as a central hub, dynamically selecting and _routing_ requests between different agents or actions based on the user's input. This mode can be good for chat-first experiences where an LLM chatbot is the entry point for a range of interactions, which can stay in the chat UI or expand to include native React UI widgets.

In this mode, CopilotKit will intelligently route requests to the most appropriate agent or action based on the context and user input.

<Callout type="warn">
    Router mode requires that you set up an LLM adapter. See how in ["Set up a copilot runtime"](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint) section of the docs.
</Callout>

### Agent Lock Mode
To use Agent Lock Mode, specify the agent name in the `CopilotKit` component with the `agent` prop:
```tsx
// [!code word:agent]
<CopilotKit runtimeUrl="<copilot-runtime-url>" agent="<the-name-of-the-agent>">
  {/* Your application components */}
</CopilotKit>
```

In this mode, CopilotKit is configured to work exclusively with a specific agent. This mode is useful when you want to focus on a particular task or domain. Whereas in Router Mode the LLM and CopilotKit's router are free to switch between agents to handle user requests, in Agent Lock Mode all requests will stay within a single workflow graph, ensuring precise control over the workflow.

Use whichever mode works best for your app experience! Also, note that while you cannot nest `CopilotKit` providers, you can use different agents or modes in different areas of your app — for example, you may want a chatbot in router mode that can call on any agent or tool, but may also want to integrate one specific agent elsewhere for a more focused workflow. 


================================================
FILE: docs/content/docs/mastra/quickstart.mdx
================================================
---
title: Quickstart
description: Turn your Mastra Agents into an agent-native application in 10 minutes.
icon: "lucide/Play"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import { FaPython, FaJs, FaCloud } from "react-icons/fa";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureRemoteEndpointLangGraph from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotKitCloudCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";
import CloudCopilotKitProvider from "@/snippets/coagents/cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/coagents/self-host-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeLangGraphEndpoint from "@/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx";
import SelfHostingCopilotRuntimeStarter from "@/snippets/self-hosting-copilot-runtime-starter.mdx";
import SelfHostingRemoteEndpoints from "@/snippets/self-hosting-remote-endpoints.mdx";
import {
  UserIcon,
  PaintbrushIcon,
  WrenchIcon,
  RepeatIcon,
  ServerIcon,
} from "lucide-react";
import CopilotUI from "@/snippets/copilot-ui.mdx";

<video
  src="/images/coagents/chat-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

## Prerequisites

Before you begin, you'll need the following:

- [**OpenAI API key**](https://platform.openai.com/api-keys)

## Getting started

<Steps>
    <Step>
        ### Install CopilotKit
        First, install the latest packages for CopilotKit into your frontend.
        ```package-install
        npm install @copilotkit/react-ui @copilotkit/react-core
        ```
    </Step>
    <TailoredContent
        className="step"
        id="agent"
        header={
            <div>
                <p className="text-xl font-semibold">Do you already have a Mastra Agent?</p>
                <p className="text-base">
                    You will need a Mastra Agent to get started!
                </p>
                <p className="text-base">
                    Either bring your own or feel free to use our starter repo.
                </p>
            </div>
        }
    >
        <TailoredContentOption
            id="bring-your-own"
            title="Bring your own Mastra Agent"
            description="I already have a Mastra Agent and want to use it with CopilotKit."
            icon={<img src="/images/copilotkit-logo.svg" alt="CopilotKit Logo" width={20} height={20} />}
        />
        <TailoredContentOption
            id="coagents-starter"
            title="Use the CoAgents Starter repo"
            description="I don't have a Mastra Agent yet, but want to get started quickly."
            icon={<img src="/images/copilotkit-logo.svg" alt="CopilotKit Logo" width={20} height={20} />}
        >
            <Step>
                ### Clone the `mastra/starter` repo

                ```bash
                git clone https://github.com/CopilotKit/CopilotKit
                cd CopilotKit/examples/mastra/starter
                ```
            </Step>
            <Step>
                ### Create a `.env` file

                ```bash
                touch .env
                ```
            </Step>
            <Step>
                ### Add your API keys

                Then add your **OpenAI API key** to the `.env` file.

                ```plaintext title=".env"
                OPENAI_API_KEY=your_openai_api_key
                ```
            </Step>
        </TailoredContentOption>
    </TailoredContent>
    <Step>
        ### Launch your local agent
        To launch the local agent, let's install the `mastra` CLI first:

        ```bash
        npm i -g mastra
        ```

        Start your local Mastra Agent:

        ```bash
        mastra dev
        ```
        This will start a local agent server that you can connect to.
    </Step>
    <Step>
        ### Install Copilot Runtime
        Copilot Runtime is a production-ready proxy for your Mastra Agents. In your frontend, go ahead and install it.

        ```package-install
        @copilotkit/runtime
        ```
    </Step>
    <Step>
        ### Setup a Copilot Runtime Endpoint
        Now we need to setup a Copilot Runtime endpoint and point your frontend to it.
        ```ts
        import {
            CopilotRuntime,
            ExperimentalEmptyAdapter,
            copilotRuntimeNextJSAppRouterEndpoint,
            langGraphPlatformEndpoint
        } from "@copilotkit/runtime";;
        import { NextRequest } from "next/server";
        
        // You can use any service adapter here for multi-agent support.
        const serviceAdapter = new ExperimentalEmptyAdapter();
        
        const runtime = new CopilotRuntime({
            agents: {
                // added in next step...
            },
        });
        
        export const POST = async (req: NextRequest) => {
        const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
            runtime,
            serviceAdapter,
            endpoint: "/api/copilotkit",
        });
        
        return handleRequest(req);
        };
        ```
    </Step>
    <Step>
        ### Add your Mastra Agent deployment to Copilot Runtime
        Now we need to add your Mastra Agent deployment to Copilot Runtime. This will make it
        so your frontend can find your Mastra Agents correctly.
        ```ts
        // ...
        import { MastraClient } from "@mastra/client-js";
        // ...
        const mastra = new MastraClient({
            "http://localhost:4111",
        });
        const mastraAgents = await mastra.getAGUI();
        const runtime = new CopilotRuntime({
            agents: mastraAgents,
        });
        // ...
        ```
    </Step>
    <Step>
        ### Configure the CopilotKit Provider
        The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
        it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.
        <SelfHostingCopilotRuntimeConfigureCopilotKitProvider components={props.components}/>
        <Callout type="info">
            Looking for a way to run multiple Mastra Agents? Check out our [Multi-Agent](/mastra/multi-agent-flows) guide.
        </Callout>
    </Step>
    <Step>
        ### Setup the Copilot UI
        The last step is to use CopilotKit's UI components to render the chat interaction with your agent. In most situations,
        this is done alongside your core page components, e.g. in your `page.tsx` file.

        ```tsx title="page.tsx"
        // [!code highlight:3]
        import "@copilotkit/react-ui/styles.css";
        import { CopilotPopup } from "@copilotkit/react-ui";

        export function YourApp() {
          return (
            <main>
              <h1>Your main content</h1>
              // [!code highlight:7]
              <CopilotPopup
                labels={{
                    title: "Popup Assistant",
                    initial: "Hi! I'm connected to an agent. How can I help?",
                }}
              />
            </main>
          );
        }
        ```

        <Callout type="info">
            Looking for other chat component options? Check out our [Agentic Chat UI](/mastra/agentic-chat-ui) guide.
        </Callout>
    </Step>
    <Step>
        ### 🎉 Talk to your agent!

        Congrats! You've successfully integrated a Mastra Agent chatbot to your application. To start, try asking a few questions to your agent.

        ```
        Can you tell me a joke?
        ```

        ```
        Can you help me understand AI?
        ```

        ```
        What do you think about React?
        ```

        <video src="/images/coagents/chat-example.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

        <Accordions className="mb-4">
            <Accordion title="Having trouble?">
                - Try changing the host to `0.0.0.0` or `127.0.0.1` instead of `localhost`.
            </Accordion>
        </Accordions>
    </Step>

</Steps>

---

## What's next?

You've now got a Mastra Agent running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

<Cards>
  <Card
    title="Implement Human in the Loop"
    description="Allow your users and agents to collaborate together on tasks."
    href="/mastra/human-in-the-loop"
    icon={<UserIcon />}
  />
  <Card
    title="Add some generative UI"
    description="Render your agent's progress and output in the UI."
    href="/mastra/generative-ui"
    icon={<PaintbrushIcon />}
  />
  <Card
    title="Setup frontend actions"
    description="Give your agent the ability to call frontend tools, directly updating your application."
    href="/mastra/frontend-actions"
    icon={<WrenchIcon />}
  />
</Cards> 


================================================
FILE: docs/content/docs/mastra/concepts/agentic-copilots.mdx
================================================
---
title: Agentic Copilots
description: Agentic copilots provide you with advanced control and orchestration over your agents.
icon: lucide/Bot
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content";
import { BsFillCloudHaze2Fill as CloudIcon } from "react-icons/bs";
import { FaServer as SelfHostIcon } from "react-icons/fa6";
import { LinkIcon } from "lucide-react";
import {
  RocketIcon,
  GraduationCapIcon,
  CodeIcon,
  VideoIcon,
} from "lucide-react";
import { AG2Icon, MastraIcon } from "@/lib/icons/custom-icons";


Before we dive into what agentic copilots are, help us help you by telling us your level of experience with Mastra. We'll explain things in a way that best suits your experience level.

<TailoredContent id="experience" defaultOptionIndex={0}>
    <TailoredContentOption 
        id="new"
        title="I'm new to Mastra" 
        description="Help me understand what agentic copilots are, where Mastra fits in, and how to get started." 
        icon={<img src="/images/copilotkit-logo.svg" width={7} height={7} />}
    >
        <Frame>
            <img src="/images/coagents/SharedStateCoAgents.gif" alt="CoAgents Shared State" className="mt-0 mb-12"/>
        </Frame>

        ### What are Agents?
        AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from
        simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

        As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized
        frameworks like Mastra become essential.

        ### What is Mastra?
        Mastra is a framework that gives you precise control over AI agents. Mastra agents allow developers to combine and coordinate coding tasks efficiently,
        providing a robust framework for building sophisticated AI automations.

        ### What are Agentic Copilots?
        Agentic copilots are how CopilotKit brings Mastra agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that
        understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ)
        for quick implementation, Agentic copilots give you Mastra's full orchestration capabilities when you need more control over your agent's behavior.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ### When should I use CopilotKit's CoAgents?
        You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [Mastra](https://mastra.ai/).
        With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

        We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.

        The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's
        functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
        up to 100% of the Copilot's tasks (see [agent-lock mode](/mastra/multi-agent-flows) for the 100% case).

        ### Examples
        An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-research-canvas).

        More specifically, it demonstrates how CoAgents allow for AI driven experiences with:
        - Precise state management across agent interactions
        - Sophisticated multi-step reasoning capabilities
        - Seamless orchestration of multiple AI tools
        - Interactive human-AI collaboration features
        - Real-time state updates and progress streaming

        ## Next Steps

        Want to get started? You have some options!

        <Cards>
            <Card
                title="Build your first CoAgent"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/mastra/quickstart/mastra"
                icon={<RocketIcon />}
            />
            <Card
                title="Learn more CoAgent concepts"
                description="Learn more about the concepts used to talk about CoAgents and how to use them."
                href="/mastra/concepts/terminology"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Read the reference documentation"
                description="Just here for some reference? Checkout the reference documentation for more details."
                href="/reference"
                icon={<CodeIcon />}
            />
        </Cards>
    </TailoredContentOption>
    <TailoredContentOption
        id="intermediate"
        title="I'm already using Mastra"
        description="Help me understand what agentic copilots are, what Copilotkit does to integrate with Mastra, and how to get started."
        icon={<MastraIcon />}
    >

        Mastra is a framework for building deeply customizable AI agents.

        CopilotKit's Agentic Copilots is infrastructure for in-app agent-user interaction, i.e. for transforming agents from autonomous processes to user-interactive 'virtual colleagues' that live inside applications.

        Any Mastra-based agent can be transformed into an Agentic Copilot with a minimal amount
        of effort to get industry leading agentic UX such as:
        - Intermediate result and state progress streaming
        - Human-in-the-loop collaboration
        - Agentic generative UI
        - And more!

        All of these features are essential to delight instead of frustrate your users with AI features.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ## Next Steps
        Want to get started? You have some options!

        <Cards>
            <Card
                title="Quickstart"
                description="Integrate your Mastra agent with CopilotKit in a few minutes."
                href="/mastra/quickstart/mastra"
                icon={<RocketIcon />}
            />
            <Card
                title="Reference"
                description="Learn more about the terms used to talk about CoAgents and how to use them."
                href="/reference"
                icon={<CodeIcon />}
            />           
        </Cards>
    </TailoredContentOption>

</TailoredContent> 


================================================
FILE: docs/content/docs/mastra/concepts/mastra.mdx
================================================
---
title: Mastra
description: An agentic framework for building LLM applications that can be used with Copilotkit.
icon: custom/mastra
---

Mastra is an agentic framework for building LLM applications that can be used with Copilotkit. Mastra Agents allow developers
to combine and coordinate tasks efficiently, providing a robust framework for building sophisticated AI automations.

## CoAgents and Mastra

How do CoAgents extend Mastra?


- **Multi-actor**: CoAgents allow for multiple agents to interact with each other. Copilotkit acts as the "ground-truth"
  when transitioning between agents. Read more about how multi-actor workflows work [here](/mastra/multi-agent-flows)
  and how messages are managed [here](/mastra/concepts/message-management).
- **LLMs**: CoAgents use large language models to generate responses. This is useful for building applications that need to
  generate natural language responses.
- **Human in the loop**: CoAgents enabled human review and approval of generated responses. Read more about how this works
  [here](/mastra/human-in-the-loop).
- **Tool calling**: Tool calling is a fundamental building block for agentic workflows. They allow for greater control over what
  the agent can do and can be used to interact with external systems. CoAgents allow you to easily render in-progress
  tool calls in the UI so your users know what's happening. Read more about streaming tool calls [here](/mastra/frontend-actions).

## Building with TypeScript

You can build Mastra applications using TypeScript. Check out the [Mastra docs](https://mastra.ai/en/docs) for more information.

## Mastra Cloud

Mastra Cloud is a platform for deploying and monitoring Mastra applications. Read more about it on the
[Mastra website](https://mastra.ai/cloud-beta).

If you want to take the next step to deploy your Mastra application as an CoAgent, check out our [quickstart guide](/mastra/quickstart/mastra). 


================================================
FILE: docs/content/docs/mastra/concepts/meta.json
================================================
{
  "title": "Concepts",
  "root": true,
  "pages": ["terminology", "agentic-copilots", "mastra"]
}



================================================
FILE: docs/content/docs/mastra/concepts/terminology.mdx
================================================
---
title: Terminology
icon: lucide/Book
---

Here are the key terms and concepts used throughout CoAgents:

| Term                         | Definition                                                                                                                                                                                         |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agentic Copilot              | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously.                                                                                     |
| CoAgent                      | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot.                                                            |
| Agentic Generative UI        | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth                 | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents.            |
| Human-in-the-Loop (HITL)     | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points.                                         |
| [Mastra](https://mastra.ai) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management.                               |
| Agent Lock Mode              | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control.                                    |
| Router Mode                  | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows.                                   |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications. 


================================================
FILE: docs/content/docs/mastra/generative-ui/index.mdx
================================================
---
title: Generative UI
icon: "lucide/Paintbrush"
description: Render your agent's behavior with custom UI components.
---

import { CTACards } from "@/components/react/cta-cards";
import { WrenchIcon, BotIcon } from "lucide-react";

<Frame>
  <img
    src="/images/coagents/AgenticGenerativeUI.gif"
    className="my-0"
    alt="Demo of Generative UI showing a meeting scheduling agent"
  />
</Frame>

<Callout>
  This example shows our [Research Canvas](/mastra/videos/research-canvas)
  making use of Generative UI!
</Callout>

## What is Generative UI?

Generative UI lets you render your agent's state, progress, outputs, and tool calls with custom UI components in real-time. It bridges the gap between AI
agents and user interfaces. As your agent processes information and makes decisions, you can render custom UI components that:

- Show loading states and progress indicators
- Display structured data in tables, cards, or charts
- Create interactive elements for user input
- Animate transitions between different states

## How can I use this?

With the CopilotKit &lt;&gt; Mastra integration, you can use tool calls to render your agent's behavior with custom UI components.

<CTACards
  columns={2}
  cards={[
    {
      icon: WrenchIcon,
      title: "Tool-based",
      description: "Render your agent's tool calls with custom UI components.",
      href: "/mastra/generative-ui/tool-based",
    },
  ]}
/> 


================================================
FILE: docs/content/docs/mastra/generative-ui/tool-based.mdx
================================================
---
title: Tool-based Generative UI
icon: "lucide/Wrench"
description: Render your agent's tool calls with custom UI components.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";

<video
  src="/images/coagents/tool-based-gen-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-Mastra).
</Callout>

## What is this?

Tools are a way for the LLM to call predefined, typically, deterministic functions. CopilotKit allows you to render these tools in the UI
as a custom component, which we call **Generative UI**.

## When should I use this?

Rendering tools in the UI is useful when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
<Step>
### Run and connect your agent

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](/mastra/quickstart/mastra) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-Mastra) as a starting point
as this guide uses it as a starting point.

</Step>
<Step>
### Give your agent a tool to call

Add a new tool definition:

```ts title="src/mastra/tools/weatherInfo.ts"
import { createTool } from "@mastra/core/tools";
import { z } from "zod";
 
export const weatherInfo = createTool({
  id: "weatherInfo",
  inputSchema: z.object({
    city: z.string(),
  }),
  description: `Fetches the current weather information for a given city`,
  execute: async ({ context: { city } }) => {
    // Tool logic here (e.g., API call)
    console.log("Using tool to fetch weather information for", city);
    return { temperature: 20, conditions: "Sunny" }; // Example return
  },
});
```

Then, pass the tool to the agent:

```ts title="src/mastra/agents/weatherAgent.ts"
import { Agent } from "@mastra/core/agent";
import { openai } from "@ai-sdk/openai";
import { weatherInfo } from "../tools/weatherInfo";
 
export const weatherAgent = new Agent({
  name: "Weather Agent",
  instructions:
    "You are a helpful assistant that provides current weather information. When asked about the weather, use the weather information tool to fetch the data.",
  model: openai("gpt-4o-mini"),
  tools: {
    weatherInfo,
  },
});
```
    
</Step>
<Step>
### Render the tool call in your frontend
At this point, your agent will be able to call the `weatherInfo` tool. Now 
we just need to add a `useCopilotAction` hook to render the tool call in
the UI.

<Callout type="info" title="Important">
  In order to render a tool call in the UI, the name of the action must match
  the name of the tool.
</Callout>

```tsx title="app/page.tsx"
import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]
// ...

const YourMainContent = () => {
  // ...
  // [!code highlight:13]
  useCopilotAction({
    name: "weatherInfo",
    available: "disabled", // Don't allow the agent or UI to call this tool as its only for rendering
    render: ({ status, args }) => {
      return (
        <p className="text-gray-500 mt-2">
          {status !== "complete" && "Calling weather API..."}
          {status === "complete" &&
            `Called the weather API for ${args.location}.`}
        </p>
      );
    },
  });
  // ...
};
```

</Step>
<Step>
### Give it a try!

Try asking the agent to get the weather for a location. You should see the custom UI component that we added
render the tool call and display the arguments that were passed to the tool.

</Step>
</Steps> 



================================================
FILE: docs/content/docs/mastra/human-in-the-loop/index.mdx
================================================
---
title: Human in the Loop (HITL)
icon: "lucide/User"
description: Allow your agent and users to collaborate on complex tasks.
---

import { CTACards } from "@/components/react/cta-cards";
import { Pause, Share2 } from "lucide-react";

<video
  src="/images/coagents/human-in-the-loop-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

{/* TODO: Add Example */}
{/* <Callout>
This video shows an example of our [AI Travel App](/coagents/tutorials/ai-travel-app) using HITL to get user feedback.

</Callout> */}

## What is Human-in-the-Loop (HITL)?

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

<Frame className="my-0">
  <img
    src="/images/coagents/coagents-hitl-infographic.png"
    alt="Agentic Copilot Human in the Loop"
    className="mt-4 mb-0 shadow-md"
  />
</Frame>

## When should I use this?

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## How can I use this?

Read more about the approach to HITL in Mastra Agents.

<CTACards
  columns={1}
  cards={[
    {
      icon: Share2,
      title: "Tool-based",
      description:
        "Utilize Mastra Agents to create Human-in-the-Loop workflows.",
      href: "/mastra/human-in-the-loop/tool-based",
    },
  ]}
/> 


================================================
FILE: docs/content/docs/mastra/human-in-the-loop/meta.json
================================================
{
  "pages": ["flow"]
}



================================================
FILE: docs/content/docs/mastra/human-in-the-loop/tool-based.mdx
================================================
---
title: Tool-based
description: Learn how to implement Human-in-the-Loop (HITL) using Mastra Agents.
icon: lucide/Share2
---

import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";
import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/coagents/node-hitl.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

<Callout type="info">
  Pictured above is the [coagent
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter)
  with the implementation below applied!
</Callout>

## What is this?


CopilotKit lets you to add custom UI to take user input and then pass it back to the agent upon completion.

## Why should I use this?

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

## Implementation

<Steps>
    <Step>
        ### Run and connect your agent

        You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
        you can follow the instructions in the [Getting Started](/mastra/quickstart/mastra) guide.

        If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/mastra/starter) as a starting point
        as this guide uses it as a starting point.
    </Step>

    <Step>
      ### Install the CopilotKit SDK
      <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Add a `useCopilotAction` to your Frontend
        First, we'll create a component that renders the agent's essay draft and waits for user approval.

        ```tsx title="ui/app/page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core"
        import { Markdown } from "@copilotkit/react-ui"

        function YourMainContent() {
          // ...

          useCopilotAction({
            name: "writeEssay",
            available: "remote",
            description: "Writes an essay and takes the draft as an argument.",
            parameters: [
              { name: "draft", type: "string", description: "The draft of the essay", required: true },
            ],
            // [!code highlight:25]
            renderAndWaitForResponse: ({ args, respond, status }) => {
              return (
                <div>
                  <Markdown content={args.draft || 'Preparing your draft...'} />

                  <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
                    <button
                      onClick={() => respond?.("CANCEL")}
                      disabled={status !== "executing"}
                      className="border p-2 rounded-xl w-full"
                    >
                      Try Again
                    </button>
                    <button
                      onClick={() => respond?.("SEND")}
                      disabled={status !== "executing"}
                      className="bg-blue-500 text-white p-2 rounded-xl w-full"
                    >
                      Approve Draft
                    </button>
                  </div>
                </div>
              );
            },
          });

          // ...
        }
        ```
    </Step>

    <Step>
    ### Setup the Mastra Agent
    On the agent side, we are already done! Mastra natively supports the AG-UI protocol and will automatically
    pass control back to the frontend when the `writeEssay` action is found in the model's response.
    </Step>
    <Step>
        ### Give it a try!
        Try asking your agent to write an essay about the benefits of AI. You'll see that it will generate an essay,
        stream the progress and eventually ask you to review it.
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/reference/index.mdx
================================================
---
title: "API Reference"
description: "API Reference for CopilotKit's components, classes and hooks."
---

import { LinkIcon } from "lucide-react";

<Cards>
  <Card
    title="UI Components"
    description="See the list of all available UI components in CopilotKit."
    href="/reference/components/chat/CopilotChat"
    icon={<LinkIcon />}
  />
  <Card
    title="Hooks"
    description="See the list of all available hooks in CopilotKit."
    href="/reference/hooks/useCopilotReadable"
    icon={<LinkIcon />}
  />
  <Card
    title="Classes"
    description="See the list of all available classes in CopilotKit."
    href="/reference/classes/CopilotRuntime"
    icon={<LinkIcon />}
  />
  <Card
    title="LLM Adapters"
    description="See the list of all available LLM Adapters in CopilotKit."
    href="/reference/classes/llm-adapters/OpenAIAdapter"
    icon={<LinkIcon />}
  />
  <Card
    title="SDKs"
    description="Python and JavaScript SDKs for CopilotKit."
    href="/reference/sdk/python/LangGraph"
    icon={<LinkIcon />}
  />
</Cards>



================================================
FILE: docs/content/docs/reference/meta.json
================================================
{
  "title": "reference",
  "root": true,
  "pages": [
    "index",
    "---UI Components---",
    "...components",
    "---Hooks---",
    "...hooks",
    "---Classes---",
    "...classes",
    "---SDKs---",
    "...sdk"
  ]
}



================================================
FILE: docs/content/docs/reference/classes/CopilotRuntime.mdx
================================================
---
title: "CopilotRuntime"
description: "Copilot Runtime is the back-end component of CopilotKit, enabling interaction with LLMs."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/lib/runtime/copilot-runtime.ts
  */
}
<Callout type="info">
  This is the reference for the `CopilotRuntime` class. For more information and example code snippets, please see [Concept: Copilot Runtime](/concepts/copilot-runtime).
</Callout>
 
## Usage
 
```tsx
import { CopilotRuntime } from "@copilotkit/runtime";
 
const copilotKit = new CopilotRuntime();
```

## Constructor Parameters

<PropertyReference name="middleware" type="Middleware"  > 
Middleware to be used by the runtime.
 
  ```ts
  onBeforeRequest: (options: {
    threadId?: string;
    runId?: string;
    inputMessages: Message[];
    properties: any;
  }) => void | Promise<void>;
  ```
 
  ```ts
  onAfterRequest: (options: {
    threadId?: string;
    runId?: string;
    inputMessages: Message[];
    outputMessages: Message[];
    properties: any;
  }) => void | Promise<void>;
  ```
</PropertyReference>

<PropertyReference name="actions" type="ActionsConfiguration<T>"  > 
A list of server side actions that can be executed. Will be ignored when remoteActions are set
</PropertyReference>

<PropertyReference name="remoteActions" type="CopilotKitEndpoint[]"  > 
Deprecated: Use `remoteEndpoints`.
</PropertyReference>

<PropertyReference name="remoteEndpoints" type="EndpointDefinition[]"  > 
A list of remote actions that can be executed.
</PropertyReference>

<PropertyReference name="langserve" type="RemoteChainParameters[]"  > 
An array of LangServer URLs.
</PropertyReference>

<PropertyReference name="agents" type="Record<string, AbstractAgent>"  > 
A map of agent names to AGUI agents.
  Example agent config:
  ```ts
  import { AbstractAgent } from "@ag-ui/client";
  // ...
  agents: {
    "support": new CustomerSupportAgent(),
    "technical": new TechnicalAgent()
  }
  ```
</PropertyReference>

<PropertyReference name="delegateAgentProcessingToServiceAdapter" type="boolean"  > 
Delegates agent state processing to the service adapter.
 
  When enabled, individual agent state requests will not be processed by the agent itself.
  Instead, all processing will be handled by the service adapter.
</PropertyReference>

<PropertyReference name="observability_c" type="CopilotObservabilityConfig"  > 
Configuration for LLM request/response logging.
  Requires publicApiKey from CopilotKit component to be set:
 
  ```tsx
  <CopilotKit publicApiKey="ck_pub_..." />
  ```
 
  Example logging config:
  ```ts
  logging: {
    enabled: true, // Enable or disable logging
    progressive: true, // Set to false for buffered logging
    logger: {
      logRequest: (data) => langfuse.trace({ name: "LLM Request", input: data }),
      logResponse: (data) => langfuse.trace({ name: "LLM Response", output: data }),
      logError: (errorData) => langfuse.trace({ name: "LLM Error", metadata: errorData }),
    },
  }
  ```
</PropertyReference>

<PropertyReference name="mcpServers" type="MCPEndpointConfig[]"  > 
Configuration for connecting to Model Context Protocol (MCP) servers.
  Allows fetching and using tools defined on external MCP-compliant servers.
  Requires providing the `createMCPClient` function during instantiation.
  @experimental
</PropertyReference>

<PropertyReference name="createMCPClient" type="CreateMCPClientFunction"  > 
A function that creates an MCP client instance for a given endpoint configuration.
  This function is responsible for using the appropriate MCP client library
  (e.g., `@copilotkit/runtime`, `ai`) to establish a connection.
  Required if `mcpServers` is provided.
 
  ```typescript
  import { experimental_createMCPClient } from "ai"; // Import from vercel ai library
  // ...
  const runtime = new CopilotRuntime({
    mcpServers: [{ endpoint: "..." }],
    async createMCPClient(config) {
      return await experimental_createMCPClient({
        transport: {
          type: "sse",
          url: config.endpoint,
          headers: config.apiKey
            ? { Authorization: `Bearer ${config.apiKey}` }
            : undefined,
        },
      });
    }
  });
  ```
</PropertyReference>

<PropertyReference name="processRuntimeRequest" type="request: CopilotRuntimeRequest">


  <PropertyReference name="request" type="CopilotRuntimeRequest" required>
  
  </PropertyReference>

</PropertyReference>

<PropertyReference name="discoverAgentsFromEndpoints" type="graphqlContext: GraphQLContext">


  <PropertyReference name="graphqlContext" type="GraphQLContext" required>
  
  </PropertyReference>

</PropertyReference>

<PropertyReference name="loadAgentState" type="graphqlContext: GraphQLContext, threadId: string, agentName: string">


  <PropertyReference name="graphqlContext" type="GraphQLContext" required>
  
  </PropertyReference>

  <PropertyReference name="threadId" type="string" required>
  
  </PropertyReference>

  <PropertyReference name="agentName" type="string" required>
  
  </PropertyReference>

</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/CopilotTask.mdx
================================================
---
title: "CopilotTask"
description: "CopilotTask is used to execute one-off tasks, for example on button click."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/lib/copilot-task.ts
  */
}
This class is used to execute one-off tasks, for example on button press. It can use the context available via [useCopilotReadable](/reference/hooks/useCopilotReadable) and the actions provided by [useCopilotAction](/reference/hooks/useCopilotAction), or you can provide your own context and actions.
 
## Example
In the simplest case, use CopilotTask in the context of your app by giving it instructions on what to do.
 
```tsx
import { CopilotTask, useCopilotContext } from "@copilotkit/react-core";
 
export function MyComponent() {
  const context = useCopilotContext();
 
  const task = new CopilotTask({
    instructions: "Set a random message",
    actions: [
      {
        name: "setMessage",
      description: "Set the message.",
      argumentAnnotations: [
        {
          name: "message",
          type: "string",
          description:
            "A message to display.",
          required: true,
        },
      ],
     }
    ]
  });
 
  const executeTask = async () => {
    await task.run(context, action);
  }
 
  return (
    <>
      <button onClick={executeTask}>
        Execute task
      </button>
    </>
  )
}
```
 
Have a look at the [Presentation Example App](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/examples/next-openai/src/app/presentation/page.tsx) for a more complete example.

## Constructor Parameters

<PropertyReference name="instructions" type="string" required > 
The instructions to be given to the assistant.
</PropertyReference>

<PropertyReference name="actions" type="FrontendAction<any>[]"  > 
An array of action definitions that can be called.
</PropertyReference>

<PropertyReference name="includeCopilotReadable" type="boolean"  > 
Whether to include the copilot readable context in the task.
</PropertyReference>

<PropertyReference name="includeCopilotActions" type="boolean"  > 
Whether to include actions defined via useCopilotAction in the task.
</PropertyReference>

<PropertyReference name="forwardedParameters" type="ForwardedParametersInput"  > 
The forwarded parameters to use for the task.
</PropertyReference>

<PropertyReference name="run" type="context: CopilotContextParams, data?: T">
Run the task.

  <PropertyReference name="context" type="CopilotContextParams" required>
  The CopilotContext to use for the task. Use `useCopilotContext` to obtain the current context.
  </PropertyReference>

  <PropertyReference name="data" type="T" >
  The data to use for the task.
  </PropertyReference>

</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/meta.json
================================================
{
  "title": "Copilot Runtime",
  "pages": [
    "CopilotRuntime",
    "llm-adapters",
    "CopilotTask"
  ]
}


================================================
FILE: docs/content/docs/reference/classes/llm-adapters/AnthropicAdapter.mdx
================================================
---
title: "AnthropicAdapter"
description: "Copilot Runtime adapter for Anthropic."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/service-adapters/anthropic/anthropic-adapter.ts
  */
}
Copilot Runtime adapter for Anthropic.
 
## Example
 
```ts
import { CopilotRuntime, AnthropicAdapter } from "@copilotkit/runtime";
import Anthropic from "@anthropic-ai/sdk";
 
const copilotKit = new CopilotRuntime();
 
const anthropic = new Anthropic({
  apiKey: "<your-api-key>",
});
 
return new AnthropicAdapter({ anthropic });
```

## Constructor Parameters

<PropertyReference name="anthropic" type="Anthropic"  > 
An optional Anthropic instance to use.  If not provided, a new instance will be
  created.
</PropertyReference>

<PropertyReference name="model" type="string"  > 
The model to use.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/llm-adapters/GoogleGenerativeAIAdapter.mdx
================================================
---
title: "GoogleGenerativeAIAdapter"
description: "Copilot Runtime adapter for Google Generative AI (e.g. Gemini)."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/service-adapters/google/google-genai-adapter.ts
  */
}
Copilot Runtime adapter for Google Generative AI (e.g. Gemini).
 
## Example
 
```ts
import { CopilotRuntime, GoogleGenerativeAIAdapter } from "@copilotkit/runtime";
const { GoogleGenerativeAI } = require("@google/generative-ai");
 
const genAI = new GoogleGenerativeAI(process.env["GOOGLE_API_KEY"]);
 
const copilotKit = new CopilotRuntime();
 
return new GoogleGenerativeAIAdapter({ model: "gemini-1.5-pro" });
```

## Constructor Parameters

<PropertyReference name="model" type="string"  > 
A custom Google Generative AI model to use.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/llm-adapters/GroqAdapter.mdx
================================================
---
title: "GroqAdapter"
description: "Copilot Runtime adapter for Groq."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/service-adapters/groq/groq-adapter.ts
  */
}
Copilot Runtime adapter for Groq.
 
## Example
 
```ts
import { CopilotRuntime, GroqAdapter } from "@copilotkit/runtime";
import { Groq } from "groq-sdk";
 
const groq = new Groq({ apiKey: process.env["GROQ_API_KEY"] });
 
const copilotKit = new CopilotRuntime();
 
return new GroqAdapter({ groq, model: "<model-name>" });
```

## Constructor Parameters

<PropertyReference name="groq" type="Groq"  > 
An optional Groq instance to use.
</PropertyReference>

<PropertyReference name="model" type="string"  > 
The model to use.
</PropertyReference>

<PropertyReference name="disableParallelToolCalls" type="boolean"  default="false"> 
Whether to disable parallel tool calls.
  You can disable parallel tool calls to force the model to execute tool calls sequentially.
  This is useful if you want to execute tool calls in a specific order so that the state changes
  introduced by one tool call are visible to the next tool call. (i.e. new actions or readables)
</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/llm-adapters/LangChainAdapter.mdx
================================================
---
title: "LangChainAdapter"
description: "Copilot Runtime adapter for LangChain."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/service-adapters/langchain/langchain-adapter.ts
  */
}
Copilot Runtime adapter for LangChain.
 
## Example
 
```ts
import { CopilotRuntime, LangChainAdapter } from "@copilotkit/runtime";
import { ChatOpenAI } from "@langchain/openai";
 
const copilotKit = new CopilotRuntime();
 
const model = new ChatOpenAI({
  model: "gpt-4o",
  apiKey: "<your-api-key>",
});
 
return new LangChainAdapter({
  chainFn: async ({ messages, tools }) => {
    return model.bindTools(tools).stream(messages);
    // or optionally enable strict mode
    // return model.bindTools(tools, { strict: true }).stream(messages);
  }
});
```
 
The asynchronous handler function (`chainFn`) can return any of the following:
 
- A simple `string` response
- A LangChain stream (`IterableReadableStream`)
- A LangChain `BaseMessageChunk` object
- A LangChain `AIMessage` object

## Constructor Parameters

<PropertyReference name="chainFn" type="(parameters: ChainFnParameters) => Promise<LangChainReturnType>" required > 
A function that uses the LangChain API to generate a response.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/llm-adapters/meta.json
================================================
{
  "title": "LLM Adapters",
  "pages": [
    "OpenAIAdapter",
    "OpenAIAssistantAdapter",
    "AnthropicAdapter",
    "LangChainAdapter",
    "GroqAdapter",
    "GoogleGenerativeAIAdapter"
  ]
}


================================================
FILE: docs/content/docs/reference/classes/llm-adapters/OpenAIAdapter.mdx
================================================
---
title: "OpenAIAdapter"
description: "Copilot Runtime adapter for OpenAI."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/service-adapters/openai/openai-adapter.ts
  */
}
Copilot Runtime adapter for OpenAI.
 
## Example
 
```ts
import { CopilotRuntime, OpenAIAdapter } from "@copilotkit/runtime";
import OpenAI from "openai";
 
const copilotKit = new CopilotRuntime();
 
const openai = new OpenAI({
  organization: "<your-organization-id>", // optional
  apiKey: "<your-api-key>",
});
 
return new OpenAIAdapter({ openai });
```
 
## Example with Azure OpenAI
 
```ts
import { CopilotRuntime, OpenAIAdapter } from "@copilotkit/runtime";
import OpenAI from "openai";
 
// The name of your Azure OpenAI Instance.
// https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource
const instance = "<your instance name>";
 
// Corresponds to your Model deployment within your OpenAI resource, e.g. my-gpt35-16k-deployment
// Navigate to the Azure OpenAI Studio to deploy a model.
const model = "<your model>";
 
const apiKey = process.env["AZURE_OPENAI_API_KEY"];
if (!apiKey) {
  throw new Error("The AZURE_OPENAI_API_KEY environment variable is missing or empty.");
}
 
const copilotKit = new CopilotRuntime();
 
const openai = new OpenAI({
  apiKey,
  baseURL: `https://${instance}.openai.azure.com/openai/deployments/${model}`,
  defaultQuery: { "api-version": "2024-04-01-preview" },
  defaultHeaders: { "api-key": apiKey },
});
 
return new OpenAIAdapter({ openai });
```

## Constructor Parameters

<PropertyReference name="openai" type="OpenAI"  > 
An optional OpenAI instance to use.  If not provided, a new instance will be
  created.
</PropertyReference>

<PropertyReference name="model" type="string"  > 
The model to use.
</PropertyReference>

<PropertyReference name="disableParallelToolCalls" type="boolean"  default="false"> 
Whether to disable parallel tool calls.
  You can disable parallel tool calls to force the model to execute tool calls sequentially.
  This is useful if you want to execute tool calls in a specific order so that the state changes
  introduced by one tool call are visible to the next tool call. (i.e. new actions or readables)
</PropertyReference>

<PropertyReference name="keepSystemRole" type="boolean"  default="false"> 
Whether to keep the role in system messages as "System".
  By default, it is converted to "developer", which is used by newer OpenAI models
</PropertyReference>




================================================
FILE: docs/content/docs/reference/classes/llm-adapters/OpenAIAssistantAdapter.mdx
================================================
---
title: "OpenAIAssistantAdapter"
description: "Copilot Runtime adapter for OpenAI Assistant API."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/runtime/src/service-adapters/openai/openai-assistant-adapter.ts
  */
}
Copilot Runtime adapter for the OpenAI Assistant API.
 
## Example
 
```ts
import { CopilotRuntime, OpenAIAssistantAdapter } from "@copilotkit/runtime";
import OpenAI from "openai";
 
const copilotKit = new CopilotRuntime();
 
const openai = new OpenAI({
  organization: "<your-organization-id>",
  apiKey: "<your-api-key>",
});
 
return new OpenAIAssistantAdapter({
  openai,
  assistantId: "<your-assistant-id>",
  codeInterpreterEnabled: true,
  fileSearchEnabled: true,
});
```

## Constructor Parameters

<PropertyReference name="assistantId" type="string" required > 
The ID of the assistant to use.
</PropertyReference>

<PropertyReference name="openai" type="OpenAI"  > 
An optional OpenAI instance to use. If not provided, a new instance will be created.
</PropertyReference>

<PropertyReference name="codeInterpreterEnabled" type="boolean"  default="true"> 
Whether to enable code interpretation.
</PropertyReference>

<PropertyReference name="fileSearchEnabled" type="boolean"  default="true"> 
Whether to enable file search.
</PropertyReference>

<PropertyReference name="disableParallelToolCalls" type="boolean"  default="false"> 
Whether to disable parallel tool calls.
  You can disable parallel tool calls to force the model to execute tool calls sequentially.
  This is useful if you want to execute tool calls in a specific order so that the state changes
  introduced by one tool call are visible to the next tool call. (i.e. new actions or readables)
</PropertyReference>

<PropertyReference name="keepSystemRole" type="boolean"  default="false"> 
Whether to keep the role in system messages as "System".
  By default, it is converted to "developer", which is used by newer OpenAI models
</PropertyReference>




================================================
FILE: docs/content/docs/reference/components/CopilotKit.mdx
================================================
---
title: "CopilotKit"
description: "The CopilotKit provider component, wrapping your application."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/components/copilot-provider/copilotkit.tsx
  */
}
This component will typically wrap your entire application (or a sub-tree of your application where you want to have a copilot). It provides the copilot context to all other components and hooks.
 
## Example
 
You can find more information about self-hosting CopilotKit [here](/guides/self-hosting).
 
```tsx
import { CopilotKit } from "@copilotkit/react-core";
 
<CopilotKit runtimeUrl="<your-runtime-url>">
  // ... your app ...
</CopilotKit>
```

## Properties

<PropertyReference name="publicApiKey" type="string"  > 
Your Copilot Cloud API key. Don't have it yet? Go to https://cloud.copilotkit.ai and get one for free.
</PropertyReference>

<PropertyReference name="guardrails_c" type="{ validTopics?: string[]; invalidTopics?: string[]; }"  > 
Restrict input to specific topics using guardrails.
  @remarks
 
  This feature is only available when using CopilotKit's hosted cloud service. To use this feature, sign up at https://cloud.copilotkit.ai to get your publicApiKey. The feature allows restricting chat conversations to specific topics.
</PropertyReference>

<PropertyReference name="runtimeUrl" type="string"  > 
The endpoint for the Copilot Runtime instance. [Click here for more information](/concepts/copilot-runtime).
</PropertyReference>

<PropertyReference name="transcribeAudioUrl" type="string"  > 
The endpoint for the Copilot transcribe audio service.
</PropertyReference>

<PropertyReference name="textToSpeechUrl" type="string"  > 
The endpoint for the Copilot text to speech service.
</PropertyReference>

<PropertyReference name="headers" type="Record<string, string>"  > 
Additional headers to be sent with the request.
 
  For example:
  ```json
  {
    "Authorization": "Bearer X"
  }
  ```
</PropertyReference>

<PropertyReference name="children" type="ReactNode" required > 
The children to be rendered within the CopilotKit.
</PropertyReference>

<PropertyReference name="properties" type="Record<string, any>"  > 
Custom properties to be sent with the request
  For example:
  ```js
  {
    'user_id': 'users_id',
  }
  ```
</PropertyReference>

<PropertyReference name="credentials" type="RequestCredentials"  > 
Indicates whether the user agent should send or receive cookies from the other domain
  in the case of cross-origin requests.
</PropertyReference>

<PropertyReference name="showDevConsole" type="boolean | 'auto'"  > 
Whether to show the dev console.
 
  If set to "auto", the dev console will be show on localhost only.
</PropertyReference>

<PropertyReference name="agent" type="string"  > 
The name of the agent to use.
</PropertyReference>

<PropertyReference name="forwardedParameters" type="Pick<ForwardedParametersInput, 'temperature'>"  > 
The forwarded parameters to use for the task.
</PropertyReference>

<PropertyReference name="authConfig_c" type="{ SignInComponent: React.ComponentType<{ onSignInComplete: (authState: AuthState) => void; }>; }"  > 
The auth config to use for the CopilotKit.
  @remarks
 
  This feature is only available when using CopilotKit's hosted cloud service. To use this feature, sign up at https://cloud.copilotkit.ai to get your publicApiKey. The feature allows restricting chat conversations to specific topics.
</PropertyReference>

<PropertyReference name="threadId" type="string"  > 
The thread id to use for the CopilotKit.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/components/CopilotTextarea.mdx
================================================
---
title: "CopilotTextarea"
description: "An AI-powered textarea component for your application, which serves as a drop-in replacement for any textarea."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-textarea/src/components/copilot-textarea/copilot-textarea.tsx
  */
}
<br/>
<img src="/images/CopilotTextarea.gif" width="500" />
 
`<CopilotTextarea>` is a React component that acts as a drop-in replacement for the standard `<textarea>`,
 offering enhanced autocomplete features powered by AI. It is context-aware, integrating seamlessly with the
[`useCopilotReadable`](/reference/hooks/useCopilotReadable) hook to provide intelligent suggestions based on the application context.
 
In addition, it provides a hovering editor window (available by default via `Cmd + K` on Mac and `Ctrl + K` on Windows) that allows the user to
suggest changes to the text, for example providing a summary or rephrasing the text.
 
## Example
 
```tsx
import { CopilotTextarea } from '@copilotkit/react-textarea';
import "@copilotkit/react-textarea/styles.css";
 
<CopilotTextarea
  autosuggestionsConfig={{
    textareaPurpose:
     "the body of an email message",
    chatApiConfigs: {},
  }}
/>
```
 
## Usage
 
### Install Dependencies
 
This component is part of the [@copilotkit/react-textarea](https://npmjs.com/package/@copilotkit/react-textarea) package.
 
```shell npm2yarn \"@copilotkit/react-textarea"\
npm install @copilotkit/react-core @copilotkit/react-textarea
```
 
### Usage
 
Use the CopilotTextarea component in your React application similarly to a standard `<textarea />`,
with additional configurations for AI-powered features.
 
For example:
 
```tsx
import { useState } from "react";
import { CopilotTextarea } from "@copilotkit/react-textarea";
import "@copilotkit/react-textarea/styles.css";
 
export function ExampleComponent() {
  const [text, setText] = useState("");
 
  return (
    <CopilotTextarea
      className="custom-textarea-class"
      value={text}
      onValueChange={(value: string) => setText(value)}
      placeholder="Enter your text here..."
      autosuggestionsConfig={{
        textareaPurpose: "Provide context or purpose of the textarea.",
        chatApiConfigs: {
          suggestionsApiConfig: {
            maxTokens: 20,
            stop: [".", "?", "!"],
          },
        },
      }}
    />
  );
}
```
 
### Look & Feel
 
By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:
```tsx title="YourRootComponent.tsx"
...
import "@copilotkit/react-textarea/styles.css"; // [!code highlight]
 
export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```
For more information about how to customize the styles, check out the [Customize Look & Feel](/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## Properties

<PropertyReference name="disableBranding" type="boolean"  > 
Determines whether the CopilotKit branding should be disabled. Default is `false`.
</PropertyReference>

<PropertyReference name="placeholderStyle" type="React.CSSProperties"  > 
Specifies the CSS styles to apply to the placeholder text.
</PropertyReference>

<PropertyReference name="suggestionsStyle" type="React.CSSProperties"  > 
Specifies the CSS styles to apply to the suggestions list.
</PropertyReference>

<PropertyReference name="hoverMenuClassname" type="string"  > 
A class name to apply to the editor popover window.
</PropertyReference>

<PropertyReference name="value" type="string"  > 
The initial value of the textarea. Can be controlled via `onValueChange`.
</PropertyReference>

<PropertyReference name="onValueChange" type="(value: string) => void"  > 
Callback invoked when the value of the textarea changes.
</PropertyReference>

<PropertyReference name="onChange" type="(event: React.ChangeEvent<HTMLTextAreaElement>) => void"  > 
Callback invoked when a `change` event is triggered on the textarea element.
</PropertyReference>

<PropertyReference name="shortcut" type="string"  > 
The shortcut to use to open the editor popover window. Default is `"Cmd-k"`.
</PropertyReference>

<PropertyReference name="autosuggestionsConfig" type="AutosuggestionsConfigUserSpecified" required > 
Configuration settings for the autosuggestions feature.
  For full reference, [check the interface on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-textarea/src/types/base/base-copilot-textarea-props.tsx#L8).
 
  <PropertyReference name="textareaPurpose" type="string" required={true} >
    The purpose of the text area in plain text.
 
    Example: "The body of the email response"
  </PropertyReference>
 
  <PropertyReference name="chatApiConfigs" type="ChatApiConfigs" >
    The chat API configurations.
 
    <strong>NOTE:</strong> You must provide specify at least one of `suggestionsApiConfig` or `insertionApiConfig`.
 
    <PropertyReference name="suggestionsApiConfig" type="SuggestionsApiConfig">
        For full reference, please [click here](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-textarea/src/types/autosuggestions-config/suggestions-api-config.tsx#L4).
    </PropertyReference>
    <PropertyReference name="insertionApiConfig" type="InsertionApiConfig">
        For full reference, please [click here](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-textarea/src/types/autosuggestions-config/insertions-api-config.tsx#L4).
    </PropertyReference>
  </PropertyReference>
 
  <PropertyReference name="disabled" type="boolean" >
    Whether the textarea is disabled.
  </PropertyReference>
 
  <PropertyReference name="disableBranding" type="boolean" >
    Whether to disable the CopilotKit branding.
  </PropertyReference>
 
  <PropertyReference name="placeholderStyle" type="React.CSSProperties" >
    Specifies the CSS styles to apply to the placeholder text.
  </PropertyReference>
 
  <PropertyReference name="suggestionsStyle" type="React.CSSProperties" >
    Specifies the CSS styles to apply to the suggestions list.
  </PropertyReference>
 
  <PropertyReference name="hoverMenuClassname" type="string" >
    A class name to apply to the editor popover window.
  </PropertyReference>
 
  <PropertyReference name="value" type="string" >
    The initial value of the textarea. Can be controlled via `onValueChange`.
  </PropertyReference>
 
  <PropertyReference name="onValueChange" type="(value: string) => void" >
    Callback invoked when the value of the textarea changes.
  </PropertyReference>
 
  <PropertyReference name="onChange" type="(event: React.ChangeEvent<HTMLTextAreaElement>) => void" >
    Callback invoked when a `change` event is triggered on the textarea element.
  </PropertyReference>
 
  <PropertyReference name="shortcut" type="string" >
    The shortcut to use to open the editor popover window. Default is `"Cmd-k"`.
  </PropertyReference>
</PropertyReference>




================================================
FILE: docs/content/docs/reference/components/meta.json
================================================
{
  "title": "UI Components",
  "pages": [
    "chat",
    "CopilotTextarea",
    "CopilotKit"
  ]
}


================================================
FILE: docs/content/docs/reference/components/chat/CopilotChat.mdx
================================================
---
title: "CopilotChat"
description: "The CopilotChat component, providing a chat interface for interacting with your copilot."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-ui/src/components/chat/Chat.tsx
  */
}
<br/>
<img src="/images/CopilotChat.gif" width="500" />
 
A chatbot panel component for the CopilotKit framework. The component allows for a high degree
of customization through various props and custom CSS.
 
## Install Dependencies
 
This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.
 
```shell npm2yarn \"@copilotkit/react-ui"\
npm install @copilotkit/react-core @copilotkit/react-ui
```
 
## Usage
 
```tsx
import { CopilotChat } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";
 
<CopilotChat
  labels={{
    title: "Your Assistant",
    initial: "Hi! 👋 How can I assist you today?",
  }}
/>
```
 
### Look & Feel
 
By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:
```tsx title="YourRootComponent.tsx"
...
import "@copilotkit/react-ui/styles.css"; // [!code highlight]
 
export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```
For more information about how to customize the styles, check out the [Customize Look & Feel](/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## Properties

<PropertyReference name="instructions" type="string"  > 
Custom instructions to be added to the system message. Use this property to
  provide additional context or guidance to the language model, influencing
  its responses. These instructions can include specific directions,
  preferences, or criteria that the model should consider when generating
  its output, thereby tailoring the conversation more precisely to the
  user's needs or the application's requirements.
</PropertyReference>

<PropertyReference name="onInProgress" type="(inProgress: boolean) => void"  > 
A callback that gets called when the in progress state changes.
</PropertyReference>

<PropertyReference name="onSubmitMessage" type="(message: string) => void | Promise<void>"  > 
A callback that gets called when a new message it submitted.
</PropertyReference>

<PropertyReference name="onStopGeneration" type="OnStopGeneration"  > 
A custom stop generation function.
</PropertyReference>

<PropertyReference name="onReloadMessages" type="OnReloadMessages"  > 
A custom reload messages function.
</PropertyReference>

<PropertyReference name="onRegenerate" type="(messageId: string) => void"  > 
A callback function to regenerate the assistant's response
</PropertyReference>

<PropertyReference name="onCopy" type="(message: string) => void"  > 
A callback function when the message is copied
</PropertyReference>

<PropertyReference name="onThumbsUp" type="(message: string) => void"  > 
A callback function for thumbs up feedback
</PropertyReference>

<PropertyReference name="onThumbsDown" type="(message: string) => void"  > 
A callback function for thumbs down feedback
</PropertyReference>

<PropertyReference name="markdownTagRenderers" type="ComponentsMap"  > 
A list of markdown components to render in assistant message.
  Useful when you want to render custom elements in the message (e.g a reference tag element)
</PropertyReference>

<PropertyReference name="icons" type="CopilotChatIcons"  > 
Icons can be used to set custom icons for the chat window.
</PropertyReference>

<PropertyReference name="labels" type="CopilotChatLabels"  > 
Labels can be used to set custom labels for the chat window.
</PropertyReference>

<PropertyReference name="imageUploadsEnabled" type="boolean"  > 
Enable image upload button (image inputs only supported on some models)
</PropertyReference>

<PropertyReference name="inputFileAccept" type="string"  > 
The 'accept' attribute for the file input used for image uploads.
  Defaults to "image".
</PropertyReference>

<PropertyReference name="makeSystemMessage" type="SystemMessageFunction"  > 
A function that takes in context string and instructions and returns
  the system message to include in the chat request.
  Use this to completely override the system message, when providing
  instructions is not enough.
</PropertyReference>

<PropertyReference name="AssistantMessage" type="React.ComponentType<AssistantMessageProps>"  > 
A custom assistant message component to use instead of the default.
</PropertyReference>

<PropertyReference name="UserMessage" type="React.ComponentType<UserMessageProps>"  > 
A custom user message component to use instead of the default.
</PropertyReference>

<PropertyReference name="Messages" type="React.ComponentType<MessagesProps>"  > 
A custom Messages component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderTextMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderTextMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderActionExecutionMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderActionExecutionMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderAgentStateMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderAgentStateMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderResultMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderResultMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderImageMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderImageMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderSuggestionsList" type="React.ComponentType<RenderSuggestionsListProps>"  > 
A custom suggestions list component to use instead of the default.
</PropertyReference>

<PropertyReference name="Input" type="React.ComponentType<InputProps>"  > 
A custom Input component to use instead of the default.
</PropertyReference>

<PropertyReference name="className" type="string"  > 
A class name to apply to the root element.
</PropertyReference>

<PropertyReference name="children" type="React.ReactNode"  > 
Children to render.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/components/chat/CopilotPopup.mdx
================================================
---
title: "CopilotPopup"
description: "The CopilotPopup component, providing a popup interface for interacting with your copilot."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-ui/src/components/chat/Popup.tsx
  */
}
<br/>
<img src="/images/CopilotPopup.gif" width="500" />
 
A chatbot popup component for the CopilotKit framework. The component allows for a high degree
of customization through various props and custom CSS.
 
See [CopilotSidebar](/reference/components/chat/CopilotSidebar) for a sidebar version of this component.
 
## Install Dependencies
 
This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.
 
```shell npm2yarn \"@copilotkit/react-ui"\
npm install @copilotkit/react-core @copilotkit/react-ui
```
## Usage
 
```tsx
import { CopilotPopup } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";
 
<CopilotPopup
  labels={{
    title: "Your Assistant",
    initial: "Hi! 👋 How can I assist you today?",
  }}
/>
```
 
### Look & Feel
 
By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:
```tsx title="YourRootComponent.tsx"
...
import "@copilotkit/react-ui/styles.css"; // [!code highlight]
 
export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```
For more information about how to customize the styles, check out the [Customize Look & Feel](/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## Properties

<PropertyReference name="instructions" type="string"  > 
Custom instructions to be added to the system message. Use this property to
  provide additional context or guidance to the language model, influencing
  its responses. These instructions can include specific directions,
  preferences, or criteria that the model should consider when generating
  its output, thereby tailoring the conversation more precisely to the
  user's needs or the application's requirements.
</PropertyReference>

<PropertyReference name="onInProgress" type="(inProgress: boolean) => void"  > 
A callback that gets called when the in progress state changes.
</PropertyReference>

<PropertyReference name="onSubmitMessage" type="(message: string) => void | Promise<void>"  > 
A callback that gets called when a new message it submitted.
</PropertyReference>

<PropertyReference name="onStopGeneration" type="OnStopGeneration"  > 
A custom stop generation function.
</PropertyReference>

<PropertyReference name="onReloadMessages" type="OnReloadMessages"  > 
A custom reload messages function.
</PropertyReference>

<PropertyReference name="onRegenerate" type="(messageId: string) => void"  > 
A callback function to regenerate the assistant's response
</PropertyReference>

<PropertyReference name="onCopy" type="(message: string) => void"  > 
A callback function when the message is copied
</PropertyReference>

<PropertyReference name="onThumbsUp" type="(message: string) => void"  > 
A callback function for thumbs up feedback
</PropertyReference>

<PropertyReference name="onThumbsDown" type="(message: string) => void"  > 
A callback function for thumbs down feedback
</PropertyReference>

<PropertyReference name="markdownTagRenderers" type="ComponentsMap"  > 
A list of markdown components to render in assistant message.
  Useful when you want to render custom elements in the message (e.g a reference tag element)
</PropertyReference>

<PropertyReference name="icons" type="CopilotChatIcons"  > 
Icons can be used to set custom icons for the chat window.
</PropertyReference>

<PropertyReference name="labels" type="CopilotChatLabels"  > 
Labels can be used to set custom labels for the chat window.
</PropertyReference>

<PropertyReference name="imageUploadsEnabled" type="boolean"  > 
Enable image upload button (image inputs only supported on some models)
</PropertyReference>

<PropertyReference name="inputFileAccept" type="string"  > 
The 'accept' attribute for the file input used for image uploads.
  Defaults to "image".
</PropertyReference>

<PropertyReference name="makeSystemMessage" type="SystemMessageFunction"  > 
A function that takes in context string and instructions and returns
  the system message to include in the chat request.
  Use this to completely override the system message, when providing
  instructions is not enough.
</PropertyReference>

<PropertyReference name="AssistantMessage" type="React.ComponentType<AssistantMessageProps>"  > 
A custom assistant message component to use instead of the default.
</PropertyReference>

<PropertyReference name="UserMessage" type="React.ComponentType<UserMessageProps>"  > 
A custom user message component to use instead of the default.
</PropertyReference>

<PropertyReference name="Messages" type="React.ComponentType<MessagesProps>"  > 
A custom Messages component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderTextMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderTextMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderActionExecutionMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderActionExecutionMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderAgentStateMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderAgentStateMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderResultMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderResultMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderImageMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderImageMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderSuggestionsList" type="React.ComponentType<RenderSuggestionsListProps>"  > 
A custom suggestions list component to use instead of the default.
</PropertyReference>

<PropertyReference name="Input" type="React.ComponentType<InputProps>"  > 
A custom Input component to use instead of the default.
</PropertyReference>

<PropertyReference name="className" type="string"  > 
A class name to apply to the root element.
</PropertyReference>

<PropertyReference name="children" type="React.ReactNode"  > 
Children to render.
</PropertyReference>

<PropertyReference name="defaultOpen" type="boolean"  default="false"> 
Whether the chat window should be open by default.
</PropertyReference>

<PropertyReference name="clickOutsideToClose" type="boolean"  default="true"> 
If the chat window should close when the user clicks outside of it.
</PropertyReference>

<PropertyReference name="hitEscapeToClose" type="boolean"  default="true"> 
If the chat window should close when the user hits the Escape key.
</PropertyReference>

<PropertyReference name="shortcut" type="string"  default="'/'"> 
The shortcut key to open the chat window.
  Uses Command-[shortcut] on a Mac and Ctrl-[shortcut] on Windows.
</PropertyReference>

<PropertyReference name="onSetOpen" type="(open: boolean) => void"  > 
A callback that gets called when the chat window opens or closes.
</PropertyReference>

<PropertyReference name="Window" type="React.ComponentType<WindowProps>"  > 
A custom Window component to use instead of the default.
</PropertyReference>

<PropertyReference name="Button" type="React.ComponentType<ButtonProps>"  > 
A custom Button component to use instead of the default.
</PropertyReference>

<PropertyReference name="Header" type="React.ComponentType<HeaderProps>"  > 
A custom Header component to use instead of the default.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/components/chat/CopilotSidebar.mdx
================================================
---
title: "CopilotSidebar"
description: "The CopilotSidebar component, providing a sidebar interface for interacting with your copilot."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-ui/src/components/chat/Sidebar.tsx
  */
}
<br/>
<img src="/images/CopilotSidebar.gif" width="500" />
 
A chatbot sidebar component for the CopilotKit framework. Highly customizable through various props and custom CSS.
 
See [CopilotPopup](/reference/components/chat/CopilotPopup) for a popup version of this component.
 
## Install Dependencies
 
This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.
 
```shell npm2yarn \"@copilotkit/react-ui"\
npm install @copilotkit/react-core @copilotkit/react-ui
```
 
## Usage
 
```tsx
import { CopilotSidebar } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";
 
<CopilotSidebar
  labels={{
    title: "Your Assistant",
    initial: "Hi! 👋 How can I assist you today?",
  }}
>
  <YourApp/>
</CopilotSidebar>
```
 
### Look & Feel
 
By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:
```tsx title="YourRootComponent.tsx"
...
import "@copilotkit/react-ui/styles.css"; // [!code highlight]
 
export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```
For more information about how to customize the styles, check out the [Customize Look & Feel](/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## Properties

<PropertyReference name="instructions" type="string"  > 
Custom instructions to be added to the system message. Use this property to
  provide additional context or guidance to the language model, influencing
  its responses. These instructions can include specific directions,
  preferences, or criteria that the model should consider when generating
  its output, thereby tailoring the conversation more precisely to the
  user's needs or the application's requirements.
</PropertyReference>

<PropertyReference name="onInProgress" type="(inProgress: boolean) => void"  > 
A callback that gets called when the in progress state changes.
</PropertyReference>

<PropertyReference name="onSubmitMessage" type="(message: string) => void | Promise<void>"  > 
A callback that gets called when a new message it submitted.
</PropertyReference>

<PropertyReference name="onStopGeneration" type="OnStopGeneration"  > 
A custom stop generation function.
</PropertyReference>

<PropertyReference name="onReloadMessages" type="OnReloadMessages"  > 
A custom reload messages function.
</PropertyReference>

<PropertyReference name="onRegenerate" type="(messageId: string) => void"  > 
A callback function to regenerate the assistant's response
</PropertyReference>

<PropertyReference name="onCopy" type="(message: string) => void"  > 
A callback function when the message is copied
</PropertyReference>

<PropertyReference name="onThumbsUp" type="(message: string) => void"  > 
A callback function for thumbs up feedback
</PropertyReference>

<PropertyReference name="onThumbsDown" type="(message: string) => void"  > 
A callback function for thumbs down feedback
</PropertyReference>

<PropertyReference name="markdownTagRenderers" type="ComponentsMap"  > 
A list of markdown components to render in assistant message.
  Useful when you want to render custom elements in the message (e.g a reference tag element)
</PropertyReference>

<PropertyReference name="icons" type="CopilotChatIcons"  > 
Icons can be used to set custom icons for the chat window.
</PropertyReference>

<PropertyReference name="labels" type="CopilotChatLabels"  > 
Labels can be used to set custom labels for the chat window.
</PropertyReference>

<PropertyReference name="imageUploadsEnabled" type="boolean"  > 
Enable image upload button (image inputs only supported on some models)
</PropertyReference>

<PropertyReference name="inputFileAccept" type="string"  > 
The 'accept' attribute for the file input used for image uploads.
  Defaults to "image".
</PropertyReference>

<PropertyReference name="makeSystemMessage" type="SystemMessageFunction"  > 
A function that takes in context string and instructions and returns
  the system message to include in the chat request.
  Use this to completely override the system message, when providing
  instructions is not enough.
</PropertyReference>

<PropertyReference name="AssistantMessage" type="React.ComponentType<AssistantMessageProps>"  > 
A custom assistant message component to use instead of the default.
</PropertyReference>

<PropertyReference name="UserMessage" type="React.ComponentType<UserMessageProps>"  > 
A custom user message component to use instead of the default.
</PropertyReference>

<PropertyReference name="Messages" type="React.ComponentType<MessagesProps>"  > 
A custom Messages component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderTextMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderTextMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderActionExecutionMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderActionExecutionMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderAgentStateMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderAgentStateMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderResultMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderResultMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderImageMessage" type="React.ComponentType<RenderMessageProps>"  > 
A custom RenderImageMessage component to use instead of the default.
</PropertyReference>

<PropertyReference name="RenderSuggestionsList" type="React.ComponentType<RenderSuggestionsListProps>"  > 
A custom suggestions list component to use instead of the default.
</PropertyReference>

<PropertyReference name="Input" type="React.ComponentType<InputProps>"  > 
A custom Input component to use instead of the default.
</PropertyReference>

<PropertyReference name="className" type="string"  > 
A class name to apply to the root element.
</PropertyReference>

<PropertyReference name="children" type="React.ReactNode"  > 
Children to render.
</PropertyReference>

<PropertyReference name="defaultOpen" type="boolean"  default="false"> 
Whether the chat window should be open by default.
</PropertyReference>

<PropertyReference name="clickOutsideToClose" type="boolean"  default="true"> 
If the chat window should close when the user clicks outside of it.
</PropertyReference>

<PropertyReference name="hitEscapeToClose" type="boolean"  default="true"> 
If the chat window should close when the user hits the Escape key.
</PropertyReference>

<PropertyReference name="shortcut" type="string"  default="'/'"> 
The shortcut key to open the chat window.
  Uses Command-[shortcut] on a Mac and Ctrl-[shortcut] on Windows.
</PropertyReference>

<PropertyReference name="onSetOpen" type="(open: boolean) => void"  > 
A callback that gets called when the chat window opens or closes.
</PropertyReference>

<PropertyReference name="Window" type="React.ComponentType<WindowProps>"  > 
A custom Window component to use instead of the default.
</PropertyReference>

<PropertyReference name="Button" type="React.ComponentType<ButtonProps>"  > 
A custom Button component to use instead of the default.
</PropertyReference>

<PropertyReference name="Header" type="React.ComponentType<HeaderProps>"  > 
A custom Header component to use instead of the default.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/components/chat/index.mdx
================================================
---
title: All Chat Components
---
import { LinkIcon } from "lucide-react"

<Cards>
  <Card
    title="<CopilotChat />"
    description="The CopilotChat component, providing a chat interface for interacting with your copilot."
    href="/reference/components/chat/CopilotChat"
    icon={<LinkIcon />}
  />
  <Card
    title="<CopilotPopup />"
    description="The CopilotPopup component, providing a popup interface for interacting with your copilot."
    href="/reference/components/chat/CopilotPopup"
    icon={<LinkIcon />}
  />
  <Card
    title="<CopilotSidebar />"
    description="The CopilotSidebar component, providing a sidebar interface for interacting with your copilot."
    href="/reference/components/chat/CopilotSidebar"
    icon={<LinkIcon />}
  />
</Cards>




================================================
FILE: docs/content/docs/reference/components/chat/meta.json
================================================
{
  "title": "Chat Components",
  "pages": [
    "CopilotChat",
    "CopilotPopup",
    "CopilotSidebar"
  ]
}


================================================
FILE: docs/content/docs/reference/hooks/meta.json
================================================
{
  "title": "hooks",
  "pages": [
    "useCopilotReadable",
    "useCopilotAction",
    "useCopilotAdditionalInstructions",
    "useCopilotChat",
    "useCopilotChatSuggestions",
    "useCoAgent",
    "useCoAgentStateRender",
    "useLangGraphInterrupt"
  ]
}


================================================
FILE: docs/content/docs/reference/hooks/useCoAgent.mdx
================================================
---
title: "useCoAgent"
description: "The useCoAgent hook allows you to share state bidirectionally between your application and the agent."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/hooks/use-coagent.ts
  */
}
<Callout type="info">
  Usage of this hook assumes some additional setup in your application, for more information
  on that see the CoAgents <span className="text-blue-500">[getting started guide](/coagents/quickstart/langgraph)</span>.
</Callout>
<Frame className="my-12">
  <img
    src="/images/coagents/SharedStateCoAgents.gif"
    alt="CoAgents demonstration"
    className="w-auto"
  />
</Frame>
 
This hook is used to integrate an agent into your application. With its use, you can
render and update the state of an agent, allowing for a dynamic and interactive experience.
We call these shared state experiences agentic copilots, or CoAgents for short.
 
## Usage
 
### Simple Usage
 
```tsx
import { useCoAgent } from "@copilotkit/react-core";
 
type AgentState = {
  count: number;
}
 
const agent = useCoAgent<AgentState>({
  name: "my-agent",
  initialState: {
    count: 0,
  },
});
 
```
 
`useCoAgent` returns an object with the following properties:
 
```tsx
const {
  name,     // The name of the agent currently being used.
  nodeName, // The name of the current LangGraph node.
  state,    // The current state of the agent.
  setState, // A function to update the state of the agent.
  running,  // A boolean indicating if the agent is currently running.
  start,    // A function to start the agent.
  stop,     // A function to stop the agent.
  run,      // A function to re-run the agent. Takes a HintFunction to inform the agent why it is being re-run.
} = agent;
```
 
Finally we can leverage these properties to create reactive experiences with the agent!
 
```tsx
const { state, setState } = useCoAgent<AgentState>({
  name: "my-agent",
  initialState: {
    count: 0,
  },
});
 
return (
  <div>
    <p>Count: {state.count}</p>
    <button onClick={() => setState({ count: state.count + 1 })}>Increment</button>
  </div>
);
```
 
This reactivity is bidirectional, meaning that changes to the state from the agent will be reflected in the UI and vice versa.
 
## Parameters
<PropertyReference name="options" type="UseCoagentOptions<T>" required>
  The options to use when creating the coagent.
  <PropertyReference name="name" type="string" required>
    The name of the agent to use.
  </PropertyReference>
  <PropertyReference name="initialState" type="T | any">
    The initial state of the agent.
  </PropertyReference>
  <PropertyReference name="state" type="T | any">
    State to manage externally if you are using this hook with external state management.
  </PropertyReference>
  <PropertyReference name="setState" type="(newState: T | ((prevState: T | undefined) => T)) => void">
    A function to update the state of the agent if you are using this hook with external state management.
  </PropertyReference>
</PropertyReference>




================================================
FILE: docs/content/docs/reference/hooks/useCoAgentStateRender.mdx
================================================
---
title: "useCoAgentStateRender"
description: "The useCoAgentStateRender hook allows you to render the state of the agent in the chat."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/hooks/use-coagent-state-render.ts
  */
}
The useCoAgentStateRender hook allows you to render UI or text based components on a Agentic Copilot's state in the chat.
This is particularly useful for showing intermediate state or progress during Agentic Copilot operations.
 
## Usage
 
### Simple Usage
 
```tsx
import { useCoAgentStateRender } from "@copilotkit/react-core";
 
type YourAgentState = {
  agent_state_property: string;
}
 
useCoAgentStateRender<YourAgentState>({
  name: "basic_agent",
  nodeName: "optionally_specify_a_specific_node",
  render: ({ status, state, nodeName }) => {
    return (
      <YourComponent
        agentStateProperty={state.agent_state_property}
        status={status}
        nodeName={nodeName}
      />
    );
  },
});
```
 
This allows for you to render UI components or text based on what is happening within the agent.
 
### Example
A great example of this is in our Perplexity Clone where we render the progress of an agent's internet search as it is happening.
You can play around with it below or learn how to build it with its [demo](/coagents/videos/perplexity-clone).
 
<Callout type="info">
  This example is hosted on Vercel and may take a few seconds to load.
</Callout>
 
<iframe src="https://examples-coagents-ai-researcher-ui.vercel.app/" className="w-full rounded-lg border h-[700px] my-4" />

## Parameters

<PropertyReference name="name" type="string" required > 
The name of the coagent.
</PropertyReference>

<PropertyReference name="nodeName" type="string"  > 
The node name of the coagent.
</PropertyReference>

<PropertyReference name="handler" type="(props: CoAgentStateRenderHandlerArguments<T>) => void | Promise<void>"  > 
The handler function to handle the state of the agent.
</PropertyReference>

<PropertyReference name="render" type="| ((props: CoAgentStateRenderProps<T>) => string | React.ReactElement | undefined | null) | string"  > 
The render function to handle the state of the agent.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/hooks/useCopilotAction.mdx
================================================
---
title: "useCopilotAction"
description: "The useCopilotAction hook allows your copilot to take action in the app."
---

<br />
<img src="/images/use-copilot-action/useCopilotAction.gif" width="500" />

`useCopilotAction` is a React hook that you can use in your application to provide
custom actions that can be called by the AI. Essentially, it allows the Copilot to
execute these actions contextually during a chat, based on the user’s interactions
and needs.

Here's how it works:

Use `useCopilotAction` to set up actions that the Copilot can call. To provide
more context to the Copilot, you can provide it with a `description` (for example to explain
what the action does, under which conditions it can be called, etc.).

Then you define the parameters of the action, which can be simple, e.g. primitives like strings or numbers,
or complex, e.g. objects or arrays.

Finally, you provide a `handler` function that receives the parameters and returns a result.
CopilotKit takes care of automatically inferring the parameter types, so you get type safety
and autocompletion for free.

To render a custom UI for the action, you can provide a `render()` function. This function
lets you render a custom component or return a string to display.

## Usage

### Simple Usage

```tsx
useCopilotAction({
  name: "sayHello",
  description: "Say hello to someone.",
  parameters: [
    {
      name: "name",
      type: "string",
      description: "name of the person to say greet",
    },
  ],
  handler: async ({ name }) => {
    alert(`Hello, ${name}!`);
  },
});
```

## Generative UI

This hooks enables you to dynamically generate UI elements and render them in the copilot chat. For more information, check out the [Generative UI](/guides/generative-ui) page.

## Parameters

<PropertyReference name="action" type="Action" required>
  The function made available to the Copilot. See [Action](#action).

    <PropertyReference name="name" type="string" required>
      The name of the action.
    </PropertyReference>

    <PropertyReference name="handler" type="(args) => Promise<any>" required>
      The handler of the action.
    </PropertyReference>

    <PropertyReference name="description" type="string">
      A description of the action. This is used to instruct the Copilot on how to
      use the action.
    </PropertyReference>

    <PropertyReference name="available" type="'enabled' | 'disabled' | 'remote'">
      Use this property to control when the action is available to the Copilot. When set to `"remote"`, the action is 
      available only for remote agents.
    </PropertyReference>

    <PropertyReference name="followUp" type="boolean" default="true">
        Whether to report the result of a function call to the LLM which will then provide a follow-up response. Pass `false` to disable
    </PropertyReference>

    <PropertyReference name="parameters" type="Parameter[]">
      The parameters of the action. See [Parameter](#parameter).

      <PropertyReference name="name" type="string" required>
        The name of the parameter.
      </PropertyReference>

      <PropertyReference
        name="type"
        type="string"
        required
      >
        The type of the argument. One of:
        - `"string"`
        - `"number"`
        - `"boolean"`
        - `"object"`
        - `"object[]"`
        - `"string[]"`
        - `"number[]"`
        - `"boolean[]"`
      </PropertyReference>

      <PropertyReference name="description" type="string">
        A description of the argument. This is used to instruct the Copilot on what
        this argument is used for.
      </PropertyReference>

      <PropertyReference name="enum" type="string[]">
        For string arguments, you can provide an array of possible values.
      </PropertyReference>

      <PropertyReference name="required" type="boolean">
        Whether or not the argument is required. Defaults to true.
      </PropertyReference>

      <PropertyReference name="attributes">
      If the argument is of a complex type, i.e. `object` or `object[]`, this field
      lets you define the attributes of the object. For example:
      ```js
      {
        name: "addresses",
        description: "The addresses extracted from the text.",
        type: "object[]",
        attributes: [
          {
            name: "street",
            type: "string",
            description: "The street of the address.",
          },
          {
            name: "city",
            type: "string",
            description: "The city of the address.",
          },
          // ...
        ],
      }
      ````
      </PropertyReference>
    </PropertyReference>

    <PropertyReference name="render" type="string | (props: ActionRenderProps<T>) => string">
      Render lets you define a custom component or string to render instead of the
      default. You can either pass in a string or a function that takes the following props:

      <div className="ml-8">
        <PropertyReference name="status" type="'inProgress' | 'executing' | 'complete'">
          - `"inProgress"`: arguments are dynamically streamed to the function, allowing you to adjust your UI in real-time.
          - `"executing"`: The action handler is executing.
          - `"complete"`: The action handler has completed execution.
        </PropertyReference>

        <PropertyReference name="args" type="T">
          The arguments passed to the action in real time. When the status is `"inProgress"`, they are
          possibly incomplete.
        </PropertyReference>

        <PropertyReference name="result" type="any">
          The result returned by the action. It is only available when the status is `"complete"`.
        </PropertyReference>
      </div>
    </PropertyReference>

    <PropertyReference name="renderAndWaitForResponse" type="(props: ActionRenderPropsWait<T>) => React.ReactElement">
      This is similar to `render`, but provides a `respond` function in the props that you must call with the user's response. The component will remain rendered until `respond` is called. The response will be passed as the result to the action handler.
      <div className="ml-8">
        <PropertyReference name="status" type="'inProgress' | 'executing' | 'complete'">
          - `"inProgress"`: arguments are dynamically streamed to the function, allowing you to adjust your UI in real-time.
          - `"executing"`: The action handler is executing.
          - `"complete"`: The action handler has completed execution.
        </PropertyReference>

        <PropertyReference name="args" type="T">
          The arguments passed to the action in real time. When the status is `"inProgress"`, they are
          possibly incomplete.
        </PropertyReference>

        <PropertyReference name="respond" type="(result: any) => void">
          A function that must be called with the user's response. The response will be passed as the result to the action handler.
          Only available when status is `"executing"`.
        </PropertyReference>

        <PropertyReference name="result" type="any">
          The result returned by the action. It is only available when the status is `"complete"`.
        </PropertyReference>
      </div>
    </PropertyReference>

</PropertyReference>

<PropertyReference name="dependencies" type="any[]">
  An optional array of dependencies.
</PropertyReference>



================================================
FILE: docs/content/docs/reference/hooks/useCopilotAdditionalInstructions.mdx
================================================
---
title: "useCopilotAdditionalInstructions"
description: "The useCopilotAdditionalInstructions hook allows you to provide additional instructions to the agent."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/hooks/use-copilot-additional-instructions.ts
  */
}
`useCopilotAdditionalInstructions` is a React hook that provides additional instructions
to the Copilot.
 
## Usage
 
### Simple Usage
 
In its most basic usage, useCopilotAdditionalInstructions accepts a single string argument
representing the instructions to be added to the Copilot.
 
```tsx
import { useCopilotAdditionalInstructions } from "@copilotkit/react-core";
 
export function MyComponent() {
  useCopilotAdditionalInstructions({
    instructions: "Do not answer questions about the weather.",
  });
}
```
 
### Conditional Usage
 
You can also conditionally add instructions based on the state of your app.
 
```tsx
import { useCopilotAdditionalInstructions } from "@copilotkit/react-core";
 
export function MyComponent() {
  const [showInstructions, setShowInstructions] = useState(false);
 
  useCopilotAdditionalInstructions({
    available: showInstructions ? "enabled" : "disabled",
    instructions: "Do not answer questions about the weather.",
  });
}
```

## Parameters

<PropertyReference name="instructions" type="string" required > 
The instructions to be added to the Copilot. Will be added to the instructions like so:
 
  ```txt
  You are a helpful assistant.
  Additionally, follow these instructions:
  - Do not answer questions about the weather.
  - Do not answer questions about the stock market.
  ```
</PropertyReference>

<PropertyReference name="available" type="'enabled' | 'disabled'"  > 
Whether the instructions are available to the Copilot.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/hooks/useCopilotChat.mdx
================================================
---
title: "useCopilotChat"
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/hooks/use-copilot-chat.ts
  */
}
`useCopilotChat` is a React hook that lets you directly interact with the
Copilot instance. Use to implement a fully custom UI (headless UI) or to
programmatically interact with the Copilot instance managed by the default
UI.
 
## Usage
 
### Simple Usage
 
```tsx
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";
 
export function YourComponent() {
  const { appendMessage } = useCopilotChat();
 
  appendMessage(
    new TextMessage({
      content: "Hello World",
      role: Role.User,
    }),
  );
 
  // optionally, you can append a message without running chat completion
  appendMessage(yourMessage, { followUp: false });
}
```
 
`useCopilotChat` returns an object with the following properties:
 
```tsx
const {
  visibleMessages, // An array of messages that are currently visible in the chat.
  appendMessage, // A function to append a message to the chat.
  setMessages, // A function to set the messages in the chat.
  deleteMessage, // A function to delete a message from the chat.
  reloadMessages, // A function to reload the messages from the API.
  stopGeneration, // A function to stop the generation of the next message.
  reset, // A function to reset the chat.
  isLoading, // A boolean indicating if the chat is loading.
} = useCopilotChat();
```

## Parameters

<PropertyReference name="id" type="string"  > 
A unique identifier for the chat. If not provided, a random one will be
  generated. When provided, the `useChat` hook with the same `id` will
  have shared states across components.
</PropertyReference>

<PropertyReference name="headers" type="Record<string, string> | Headers"  > 
HTTP headers to be sent with the API request.
</PropertyReference>

<PropertyReference name="initialMessages" type="Message[]"  > 
System messages of the chat. Defaults to an empty array.
</PropertyReference>

<PropertyReference name="makeSystemMessage" type="SystemMessageFunction"  > 
A function to generate the system message. Defaults to `defaultSystemMessage`.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/hooks/useCopilotChatSuggestions.mdx
================================================
---
title: "useCopilotChatSuggestions"
description: "The useCopilotChatSuggestions hook generates suggestions in the chat window based on real-time app state."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-ui/src/hooks/use-copilot-chat-suggestions.tsx
  */
}
<Callout type="warning">
  useCopilotChatSuggestions is experimental. The interface is not final and
  can change without notice.
</Callout>
 
`useCopilotReadable` is a React hook that provides app-state and other information
to the Copilot. Optionally, the hook can also handle hierarchical state within your
application, passing these parent-child relationships to the Copilot.
 
<br/>
<img src="/images/use-copilot-chat-suggestions/use-copilot-chat-suggestions.gif" width="500" />
 
## Usage
 
### Install Dependencies
 
This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.
 
```shell npm2yarn \"@copilotkit/react-ui"\
npm install @copilotkit/react-core @copilotkit/react-ui
```
 
### Simple Usage
 
```tsx
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";
 
export function MyComponent() {
  const [employees, setEmployees] = useState([]);
 
  useCopilotChatSuggestions({
    instructions: `The following employees are on duty: ${JSON.stringify(employees)}`,
  });
}
```
 
### Dependency Management
 
```tsx
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";
 
export function MyComponent() {
  useCopilotChatSuggestions(
    {
      instructions: "Suggest the most relevant next actions.",
    },
    [appState],
  );
}
```
 
In the example above, the suggestions are generated based on the given instructions.
The hook monitors `appState`, and updates suggestions accordingly whenever it changes.
 
### Behavior and Lifecycle
 
The hook registers the configuration with the chat context upon component mount and
removes it on unmount, ensuring a clean and efficient lifecycle management.

## Parameters

<PropertyReference name="instructions" type="string" required > 
A prompt or instructions for the GPT to generate suggestions.
</PropertyReference>

<PropertyReference name="minSuggestions" type="number"  default="1"> 
The minimum number of suggestions to generate. Defaults to `1`.
</PropertyReference>

<PropertyReference name="maxSuggestions" type="number"  default="1"> 
The maximum number of suggestions to generate. Defaults to `3`.
</PropertyReference>

<PropertyReference name="available" type="'enabled' | 'disabled'"  default="enabled"> 
Whether the suggestions are available. Defaults to `enabled`.
</PropertyReference>

<PropertyReference name="className" type="string"  > 
An optional class name to apply to the suggestions.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/hooks/useCopilotReadable.mdx
================================================
---
title: "useCopilotReadable"
description: "The useCopilotReadable hook allows you to provide knowledge to your copilot (e.g. application state)."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/react-core/src/hooks/use-copilot-readable.ts
  */
}
`useCopilotReadable` is a React hook that provides app-state and other information
to the Copilot. Optionally, the hook can also handle hierarchical state within your
application, passing these parent-child relationships to the Copilot.
 
## Usage
 
### Simple Usage
 
In its most basic usage, useCopilotReadable accepts a single string argument
representing any piece of app state, making it available for the Copilot to use
as context when responding to user input.
 
```tsx
import { useCopilotReadable } from "@copilotkit/react-core";
 
export function MyComponent() {
  const [employees, setEmployees] = useState([]);
 
  useCopilotReadable({
    description: "The list of employees",
    value: employees,
  });
}
```
 
### Nested Components
 
Optionally, you can maintain the hierarchical structure of information by passing
`parentId`. This allows you to use `useCopilotReadable` in nested components:
 
```tsx /employeeContextId/1 {17,23}
import { useCopilotReadable } from "@copilotkit/react-core";
 
function Employee(props: EmployeeProps) {
  const { employeeName, workProfile, metadata } = props;
 
  // propagate any information to copilot
  const employeeContextId = useCopilotReadable({
    description: "Employee name",
    value: employeeName
  });
 
  // Pass a parentID to maintain a hierarchical structure.
  // Especially useful with child React components, list elements, etc.
  useCopilotReadable({
    description: "Work profile",
    value: workProfile.description(),
    parentId: employeeContextId
  });
 
  useCopilotReadable({
    description: "Employee metadata",
    value: metadata.description(),
    parentId: employeeContextId
  });
 
  return (
    // Render as usual...
  );
}
```

## Parameters

<PropertyReference name="description" type="string" required > 
The description of the information to be added to the Copilot context.
</PropertyReference>

<PropertyReference name="value" type="any" required > 
The value to be added to the Copilot context. Object values are automatically stringified.
</PropertyReference>

<PropertyReference name="parentId" type="string"  > 
The ID of the parent context, if any.
</PropertyReference>

<PropertyReference name="categories" type="string[]"  > 
An array of categories to control which context are visible where. Particularly useful
  with CopilotTextarea (see `useMakeAutosuggestionFunction`)
</PropertyReference>

<PropertyReference name="available" type="'enabled' | 'disabled'"  > 
Whether the context is available to the Copilot.
</PropertyReference>

<PropertyReference name="convert" type="(description: string, value: any) => string"  > 
A custom conversion function to use to serialize the value to a string. If not provided, the value
  will be serialized using `JSON.stringify`.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/hooks/useLangGraphInterrupt.mdx
================================================
---
title: "useLangGraphInterrupt"
description: "The useLangGraphInterrupt hook allows setting the generative UI to be displayed on LangGraph's Interrupt event."
---

<br />
<video src="/images/coagents/interrupt-flow.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

`useLangGraphInterrupt` is a React hook that you can use in your application to provide
custom UI to be rendered when using `interrupt` by LangGraph.
Once an Interrupt event is emitted, that hook would execute, allowing to receive user input with a user experience to your choice.

## Usage

### Simple Usage

```tsx title="app/page.tsx"
import { useLangGraphInterrupt } from "@copilotkit/react-core"; // [!code highlight]
// ...

const YourMainContent = () => {
  // ...
  // [!code highlight:16]
  // styles omitted for brevity
  useLangGraphInterrupt<string>({
    render: ({ event, resolve }) => (
      <div>
        <p>{event.value}</p>
        <form onSubmit={(e) => {
          e.preventDefault();
          resolve((e.target as HTMLFormElement).response.value);
        }}>
          <input type="text" name="response" placeholder="Enter your response" />
          <button type="submit">Submit</button>
        </form>
      </div>
    )
  });
  // ...

  return <div>{/* ... */}</div>
}
```

## Parameters

<PropertyReference name="action" type="Action" required>
  The action to perform when an Interrupt event is emitted. Either `handler` or `render` must be defined as arguments

    <PropertyReference name="name" type="string" required>
      The name of the action.
    </PropertyReference>

    <PropertyReference name="handler" type="(args: LangGraphInterruptRenderProps<T>) => any | Promise<any>">
      A handler to programmatically resolve the Interrupt, or perform operations which result will be passed to the `render` method
    </PropertyReference>

    <PropertyReference name="render" type="(props: LangGraphInterruptRenderProps<T>) => string | React.ReactElement">
        Render lets you define a custom component or string to render when an Interrupt event is emitted.
    </PropertyReference>

    <PropertyReference name="enabled" type="(args: { eventValue: TEventValue; agentMetadata: AgentSession }) => boolean">
        Method that returns a boolean, indicating if the interrupt action should run. Useful when using multiple interrupts
    </PropertyReference>
</PropertyReference>

<PropertyReference name="dependencies" type="any[]">
  An optional array of dependencies.
</PropertyReference>



================================================
FILE: docs/content/docs/reference/sdk/meta.json
================================================
{
  "pages": ["python", "js"]
}



================================================
FILE: docs/content/docs/reference/sdk/js/LangGraph.mdx
================================================
---
title: "LangGraph SDK"
description: "The CopilotKit LangGraph SDK for JavaScript allows you to build and run LangGraph workflows with CopilotKit."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/packages/sdk-js/src/langgraph.ts
  */
}
## copilotkitCustomizeConfig

Customize the LangGraph configuration for use in CopilotKit.
 
To the CopilotKit SDK, run:
 
```bash
npm install @copilotkit/sdk-js
```
 
### Examples
 
Disable emitting messages and tool calls:
 
```typescript
import { copilotkitCustomizeConfig } from "@copilotkit/sdk-js";
 
config = copilotkitCustomizeConfig(
  config,
  emitMessages=false,
  emitToolCalls=false
)
```
 
To emit a tool call as streaming LangGraph state, pass the destination key in state,
the tool name and optionally the tool argument. (If you don't pass the argument name,
all arguments are emitted under the state key.)
 
```typescript
import { copilotkitCustomizeConfig } from "@copilotkit/sdk-js";
 
config = copilotkitCustomizeConfig(
  config,
  emitIntermediateState=[
    {
      "stateKey": "steps",
      "tool": "SearchTool",
      "toolArgument": "steps",
    },
  ],
)
```

### Parameters

<PropertyReference name="baseConfig" type="RunnableConfig" required > 
The LangChain/LangGraph configuration to customize.
</PropertyReference>

<PropertyReference name="options" type="OptionsConfig"  > 
Configuration options:
  - `emitMessages: boolean?`
    Configure how messages are emitted. By default, all messages are emitted. Pass false to
    disable emitting messages.
  - `emitToolCalls: boolean | string | string[]?`
    Configure how tool calls are emitted. By default, all tool calls are emitted. Pass false to
    disable emitting tool calls. Pass a string or list of strings to emit only specific tool calls.
  - `emitIntermediateState: IntermediateStateConfig[]?`
    Lets you emit tool calls as streaming LangGraph state.
</PropertyReference>

## copilotkitExit

Exits the current agent after the run completes. Calling copilotkit_exit() will
not immediately stop the agent. Instead, it signals to CopilotKit to stop the agent after
the run completes.
 
### Examples
 
```typescript
import { copilotkitExit } from "@copilotkit/sdk-js";
 
async function myNode(state: Any):
  await copilotkitExit(config)
  return state
```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required > 
The LangChain/LangGraph configuration.
</PropertyReference>

## copilotkitEmitState

Emits intermediate state to CopilotKit. Useful if you have a longer running node and you want to
update the user with the current state of the node.
 
### Examples
 
```typescript
import { copilotkitEmitState } from "@copilotkit/sdk-js";
 
for (let i = 0; i < 10; i++) {
  await someLongRunningOperation(i);
  await copilotkitEmitState(config, { progress: i });
}
```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required > 
The LangChain/LangGraph configuration.
</PropertyReference>

<PropertyReference name="state" type="any" required > 
The state to emit.
</PropertyReference>

## copilotkitEmitMessage

Manually emits a message to CopilotKit. Useful in longer running nodes to update the user.
Important: You still need to return the messages from the node.
 
### Examples
 
```typescript
import { copilotkitEmitMessage } from "@copilotkit/sdk-js";
 
const message = "Step 1 of 10 complete";
await copilotkitEmitMessage(config, message);
 
// Return the message from the node
return {
  "messages": [AIMessage(content=message)]
}
```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required > 
The LangChain/LangGraph configuration.
</PropertyReference>

<PropertyReference name="message" type="string" required > 
The message to emit.
</PropertyReference>

## copilotkitEmitToolCall

Manually emits a tool call to CopilotKit.
 
### Examples
 
```typescript
import { copilotkitEmitToolCall } from "@copilotkit/sdk-js";
 
await copilotkitEmitToolCall(config, name="SearchTool", args={"steps": 10})
```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required > 
The LangChain/LangGraph configuration.
</PropertyReference>

<PropertyReference name="name" type="string" required > 
The name of the tool to emit.
</PropertyReference>

<PropertyReference name="args" type="any" required > 
The arguments to emit.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/sdk/js/meta.json
================================================
{
  "title": "JavaScript"
}



================================================
FILE: docs/content/docs/reference/sdk/python/CrewAI.mdx
================================================
---
title: "CrewAI SDK"
description: "The CopilotKit CrewAI SDK for Python allows you to build and run CrewAI agents with CopilotKit."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/../sdk-python/copilotkit/crewai/crewai_sdk.py
  */
}
## copilotkit_predict_state

Stream tool calls as state to CopilotKit.

    To emit a tool call as streaming CrewAI state, pass the destination key in state,
    the tool name and optionally the tool argument. (If you don't pass the argument name,
    all arguments are emitted under the state key.)

    ```python
    from copilotkit.crewai import copilotkit_predict_state

    await copilotkit_predict_state(
        {
            "steps": {
                "tool_name": "SearchTool",
                "tool_argument": "steps",
            },
        }
    )
    ```

### Parameters

<PropertyReference name="config" type="Dict[str, CopilotKitPredictStateConfig]" required> 
The configuration to predict the state.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>

## copilotkit_emit_message

Manually emits a message to CopilotKit. Useful in longer running nodes to update the user.
    Important: You still need to return the messages from the node.

    ### Examples

    ```python
    from copilotkit.crewai import copilotkit_emit_message

    message = "Step 1 of 10 complete"
    await copilotkit_emit_message(message)

    # Return the message from the node
    return {
        "messages": [AIMessage(content=message)]
    }
    ```

### Parameters

<PropertyReference name="message" type="str" required> 
The message to emit.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>

## copilotkit_emit_tool_call

Manually emits a tool call to CopilotKit.

    ```python
    from copilotkit.crewai import copilotkit_emit_tool_call

    await copilotkit_emit_tool_call(name="SearchTool", args={"steps": 10})
    ```

### Parameters

<PropertyReference name="name" type="str" required> 
The name of the tool to emit.
</PropertyReference>

<PropertyReference name="args" type="Dict[str, Any]" required> 
The arguments to emit.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/sdk/python/CrewAIAgent.mdx
================================================
---
title: "CrewAIAgent"
description: "CrewAIAgent lets you define your agent for use with CopilotKit."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/../sdk-python/copilotkit/crewai/crewai_agent.py
  */
}
## CrewAIAgent

CrewAIAgent lets you define your agent for use with CopilotKit.

    To install, run:

    ```bash
    pip install copilotkit[crewai]
    ```

    Every agent must have the `name` and either `crew` or `flow` properties defined. An optional 
    `description` can also be provided. This is used when CopilotKit is dynamically routing requests 
    to the agent.

    ## Serving a Crew based agent

    To serve a Crew based agent, pass in a `Crew` object to the `crew` parameter.

    Note:
    You need to make sure to have a `chat_llm` set on the `Crew` object.
    See [the CrewAI docs](https://docs.crewai.com/concepts/cli#9-chat) for more information.

    ```python
    from copilotkit import CrewAIAgent


    CrewAIAgent(
        name="email_agent_crew",
        description="This crew based agent sends emails",
        crew=SendEmailCrew(),
    )
    ```

    ## Serving a Flow based agent

    To serve a Flow based agent, pass in a `Flow` object to the `flow` parameter.

    ```python
    CrewAIAgent(
        name="email_agent_flow",
        description="This flow based agent sends emails",
        flow=SendEmailFlow(),
    )
    ```

    Note:
    Either a `crew` or `flow` must be provided to CrewAIAgent.

### Parameters

<PropertyReference name="name" type="str" required> 
The name of the agent.
</PropertyReference>

<PropertyReference name="crew" type="Crew" required> 
When using a Crew based agent, pass in a `Crew` object to the `crew` parameter.
</PropertyReference>

<PropertyReference name="flow" type="Flow" required> 
When using a Flow based agent, pass in a `Flow` object to the `flow` parameter.
</PropertyReference>

<PropertyReference name="description" type="Optional[str]" > 
The description of the agent.
</PropertyReference>

<PropertyReference name="copilotkit_config" type="Optional[CopilotKitConfig]" > 
The CopilotKit config to use with the agent.
</PropertyReference>

## CopilotKitConfig

CopilotKit config for CrewAIAgent

    This is used for advanced cases where you want to customize how CopilotKit interacts with
    CrewAI.

    ```python
    # Function signatures:
    def merge_state(
        *,
        state: dict,
        messages: List[BaseMessage],
        actions: List[Any],
        agent_name: str
    ):
        # ...implementation...

    ```

### Parameters

<PropertyReference name="merge_state" type="Callable" required> 
This function lets you customize how CopilotKit merges the agent state.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/sdk/python/LangGraph.mdx
================================================
---
title: "LangGraph SDK"
description: "The CopilotKit LangGraph SDK for Python allows you to build and run LangGraph workflows with CopilotKit."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/../sdk-python/copilotkit/langgraph.py
  */
}
## copilotkit_customize_config

Customize the LangGraph configuration for use in CopilotKit.

    To install the CopilotKit SDK, run:

    ```bash
    pip install copilotkit
    ```

    ### Examples

    Disable emitting messages and tool calls:
    
    ```python
    from copilotkit.langgraph import copilotkit_customize_config

    config = copilotkit_customize_config(
        config,
        emit_messages=False,
        emit_tool_calls=False
    )
    ```

    To emit a tool call as streaming LangGraph state, pass the destination key in state,
    the tool name and optionally the tool argument. (If you don't pass the argument name,
    all arguments are emitted under the state key.)

    ```python
    from copilotkit.langgraph import copilotkit_customize_config

    config = copilotkit_customize_config(
        config,
        emit_intermediate_state=[
           {
                "state_key": "steps",
                "tool": "SearchTool",
                "tool_argument": "steps"
            },
        ]
    )
    ```

### Parameters

<PropertyReference name="base_config" type="Optional[RunnableConfig]" > 
The LangChain/LangGraph configuration to customize. Pass None to make a new configuration.
</PropertyReference>

<PropertyReference name="emit_messages" type="Optional[bool]" > 
Configure how messages are emitted. By default, all messages are emitted. Pass False to disable emitting messages.
</PropertyReference>

<PropertyReference name="emit_tool_calls" type="Optional[Union[bool, str, List[str]]]" > 
Configure how tool calls are emitted. By default, all tool calls are emitted. Pass False to disable emitting tool calls. Pass a string or list of strings to emit only specific tool calls.
</PropertyReference>

<PropertyReference name="emit_intermediate_state" type="Optional[List[IntermediateStateConfig]]" > 
Lets you emit tool calls as streaming LangGraph state.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="RunnableConfig">
The customized LangGraph configuration.
</PropertyReference>

## copilotkit_exit

Exits the current agent after the run completes. Calling copilotkit_exit() will
    not immediately stop the agent. Instead, it signals to CopilotKit to stop the agent after
    the run completes.

    ### Examples

    ```python
    from copilotkit.langgraph import copilotkit_exit

    def my_node(state: Any):
        await copilotkit_exit(config)
        return state
    ```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required> 
The LangGraph configuration.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>

## copilotkit_emit_state

Emits intermediate state to CopilotKit. Useful if you have a longer running node and you want to
    update the user with the current state of the node.

    ### Examples

    ```python
    from copilotkit.langgraph import copilotkit_emit_state

    for i in range(10):
        await some_long_running_operation(i)
        await copilotkit_emit_state(config, {"progress": i})
    ```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required> 
The LangGraph configuration.
</PropertyReference>

<PropertyReference name="state" type="Any" required> 
The state to emit (Must be JSON serializable).
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>

## copilotkit_emit_message

Manually emits a message to CopilotKit. Useful in longer running nodes to update the user.
    Important: You still need to return the messages from the node.

    ### Examples

    ```python
    from copilotkit.langgraph import copilotkit_emit_message

    message = "Step 1 of 10 complete"
    await copilotkit_emit_message(config, message)

    # Return the message from the node
    return {
        "messages": [AIMessage(content=message)]
    }
    ```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required> 
The LangGraph configuration.
</PropertyReference>

<PropertyReference name="message" type="str" required> 
The message to emit.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>

## copilotkit_emit_tool_call

Manually emits a tool call to CopilotKit.

    ```python
    from copilotkit.langgraph import copilotkit_emit_tool_call

    await copilotkit_emit_tool_call(config, name="SearchTool", args={"steps": 10})
    ```

### Parameters

<PropertyReference name="config" type="RunnableConfig" required> 
The LangGraph configuration.
</PropertyReference>

<PropertyReference name="name" type="str" required> 
The name of the tool to emit.
</PropertyReference>

<PropertyReference name="args" type="Dict[str, Any]" required> 
The arguments to emit.
</PropertyReference>

### Returns

<PropertyReference name="returns" type="Awaitable[bool]">
Always return True.
</PropertyReference>




================================================
FILE: docs/content/docs/reference/sdk/python/LangGraphAgent.mdx
================================================
---
title: "LangGraphAgent"
description: "LangGraphAgent lets you define your agent for use with CopilotKit."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/../sdk-python/copilotkit/langgraph_agent.py
  */
}
## LangGraphAgent

LangGraphAgent lets you define your agent for use with CopilotKit.

    To install, run:

    ```bash
    pip install copilotkit
    ```

    ### Examples

    Every agent must have the `name` and `graph` properties defined. An optional `description` 
    can also be provided. This is used when CopilotKit is dynamically routing requests to the 
    agent.

    ```python
    from copilotkit import LangGraphAgent

    LangGraphAgent(
        name="email_agent",
        description="This agent sends emails",
        graph=graph,
    )
    ```

    If you have a custom LangGraph/LangChain config that you want to use with the agent, you can 
    pass it in as the `langgraph_config` parameter.

    ```python
    LangGraphAgent(
        ...
        langgraph_config=config,
    )
    ```

### Parameters

<PropertyReference name="name" type="str" required> 
The name of the agent.
</PropertyReference>

<PropertyReference name="graph" type="CompiledGraph" required> 
The LangGraph graph to use with the agent.
</PropertyReference>

<PropertyReference name="description" type="Optional[str]" > 
The description of the agent.
</PropertyReference>

<PropertyReference name="langgraph_config" type="Optional[RunnableConfig]" > 
The LangGraph/LangChain config to use with the agent.
</PropertyReference>

<PropertyReference name="copilotkit_config" type="Optional[CopilotKitConfig]" > 
The CopilotKit config to use with the agent.
</PropertyReference>

## CopilotKitConfig

CopilotKit config for LangGraphAgent

    This is used for advanced cases where you want to customize how CopilotKit interacts with
    LangGraph.

    ```python
    # Function signatures:
    def merge_state(
        *,
        state: dict,
        messages: List[BaseMessage],
        actions: List[Any],
        agent_name: str
    ):
        # ...implementation...

    def convert_messages(messages: List[Message]):
        # ...implementation...
    ```

### Parameters

<PropertyReference name="merge_state" type="Callable" required> 
This function lets you customize how CopilotKit merges the agent state.
</PropertyReference>

<PropertyReference name="convert_messages" type="Callable" required> 
Use this function to customize how CopilotKit converts its messages to LangChain messages.`
</PropertyReference>




================================================
FILE: docs/content/docs/reference/sdk/python/meta.json
================================================
{
  "pages": [
    "RemoteEndpoints",
    "LangGraphAgent",
    "LangGraph",
    "CrewAIAgent",
    "CrewAI"
  ]
}



================================================
FILE: docs/content/docs/reference/sdk/python/RemoteEndpoints.mdx
================================================
---
title: "Remote Endpoints"
description: "CopilotKit Remote Endpoints allow you to connect actions and agents written in Python to your CopilotKit application."
---

{
 /*
  * ATTENTION! DO NOT MODIFY THIS FILE!
  * This page is auto-generated. If you want to make any changes to this page, changes must be made at:
  * CopilotKit/../sdk-python/copilotkit/sdk.py
  */
}
## CopilotKitRemoteEndpoint

CopilotKitRemoteEndpoint lets you connect actions and agents written in Python to your 
    CopilotKit application.

    To install CopilotKit for Python, run:

    ```bash
    pip install copilotkit
    # or to include crewai
    pip install copilotkit[crewai]
    ```

    ## Adding actions

    In this example, we provide a simple action to the Copilot:

    ```python
    from copilotkit import CopilotKitRemoteEndpoint, Action

    sdk = CopilotKitRemoteEndpoint(
        actions=[
            Action(
                name="greet_user",
                handler=greet_user_handler,
                description="Greet the user",
                parameters=[
                    {
                        "name": "name",
                        "type": "string",
                        "description": "The name of the user"
                    }
                ]
            )
        ]
    )
    ```

    You can also dynamically build actions by providing a callable that returns a list of actions.
    In this example, we use "name" from the `properties` object to parameterize the action handler.

    ```python
    from copilotkit import CopilotKitRemoteEndpoint, Action

    sdk = CopilotKitRemoteEndpoint(
        actions=lambda context: [
            Action(
                name="greet_user",
                handler=make_greet_user_handler(context["properties"]["name"]), 
                description="Greet the user"
            )
        ]
    )
    ```

    Using the same approach, you can restrict the actions available to the Copilot:

    ```python
    from copilotkit import CopilotKitRemoteEndpoint, Action

    sdk = CopilotKitRemoteEndpoint(
        actions=lambda context: (
            [action_a, action_b] if is_admin(context["properties"]["token"]) else [action_a]
        )
    )
    ```

    ## Adding agents

    Serving agents works in a similar way to serving actions:

    ```python
    from copilotkit import CopilotKitRemoteEndpoint, LangGraphAgent
    from my_agent.agent import graph

    sdk = CopilotKitRemoteEndpoint(
        agents=[
            LangGraphAgent(
                name="email_agent",
                description="This agent sends emails",
                graph=graph,
            )
        ]
    )
    ```

    To dynamically build agents, provide a callable that returns a list of agents:

    ```python
    from copilotkit import CopilotKitRemoteEndpoint, LangGraphAgent
    from my_agent.agent import graph

    sdk = CopilotKitRemoteEndpoint(
        agents=lambda context: [
            LangGraphAgent(
                name="email_agent",
                description="This agent sends emails",
                graph=graph,
                langgraph_config={
                    "token": context["properties"]["token"]
                }
            )
        ]
    )
    ```

    To restrict the agents available to the Copilot, simply return a different list of agents based on the `context`:

    ```python
    from copilotkit import CopilotKitRemoteEndpoint
    from my_agents import agent_a, agent_b, is_admin

    sdk = CopilotKitRemoteEndpoint(
        agents=lambda context: (
            [agent_a, agent_b] if is_admin(context["properties"]["token"]) else [agent_a]
        )
    )
    ```

    ## Serving the CopilotKit SDK

    To serve the CopilotKit SDK, you can use the `add_fastapi_endpoint` function from the `copilotkit.integrations.fastapi` module:

    ```python
    from copilotkit.integrations.fastapi import add_fastapi_endpoint
    from fastapi import FastAPI

    app = FastAPI()
    sdk = CopilotKitRemoteEndpoint(...)
    add_fastapi_endpoint(app, sdk, "/copilotkit")

    def main():
        uvicorn.run(
            "your_package:app",
            host="0.0.0.0",
            port=8000,
            reload=True,
        )

    ```

### Parameters

<PropertyReference name="actions" type="Optional[Union[List[Action], Callable[[CopilotKitContext], List[Action]]]]" > 
The actions to make available to the Copilot.
</PropertyReference>

<PropertyReference name="agents" type="Optional[Union[List[Agent], Callable[[CopilotKitContext], List[Agent]]]]" > 
The agents to make available to the Copilot.
</PropertyReference>

## CopilotKitContext

CopilotKit Context

### Parameters

<PropertyReference name="properties" type="Any" required> 
The properties provided to the frontend via `<CopilotKit properties={...} />`
</PropertyReference>

<PropertyReference name="frontend_url" type="Optional[str]" > 
The current URL of the frontend
</PropertyReference>

<PropertyReference name="headers" type="Mapping[str, str]" required> 
The headers of the request
</PropertyReference>




================================================
FILE: docs/content/docs/.coagents-template/agentic-chat-ui.mdx
================================================
---
title: Chat with an Agent
icon: "lucide/SendHorizontal"
description: Chat with an agent using CopilotKit's UI components.
---

import ConnectCopilotUI from "@/snippets/copilot-ui.mdx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx";
import CopilotCloudConfigureCopilotKitProvider from "@/snippets/cloud/cloud-copilotkit-provider.mdx";
import ComponentExamples from "@/snippets/component-examples.mdx";
import { UserIcon, PaintbrushIcon, WrenchIcon, RepeatIcon } from "lucide-react";

<video
  src="/images/coagents/agentic-chat-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--)
  repo with various Copilot UI components applied to it!
</Callout>

## What is this?

Agentic chat UIs are ways for your users to interact with your agent. CopilotKit provides a variety of different components to choose from, each
with their own unique use cases.

If you've gone through the [getting started guide](/--YOUR-FRAMEWORK--/quickstart/your-framework) **you already have a agentic chat UI setup**! Nothing else is needed
to get started.

## When should I use this?

CopilotKit provides a variety of different batteries-included components to choose from to create agent native applications. They scale
from simple chat UIs to completely custom applications.

<ComponentExamples components={props.components} /> 


================================================
FILE: docs/content/docs/.coagents-template/frontend-actions.mdx
================================================
---
title: Frontend Actions
icon: "lucide/Wrench"
description: Create frontend actions and use them within your agent.
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/frontend-actions-demo.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## When should I use this?

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## Implementation

<Steps>
    <Step>
        ### Setup CopilotKit

        To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here.

        Check out our [getting started guide](/--YOUR-FRAMEWORK--/quickstart/your-framework) and come back here when you're setup!
    </Step>

    <Step>
        ### Create a frontend action

        First, you'll need to create a frontend action using the [useCopilotAction](/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
        that says hello to the user.

        ```tsx title="page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core" // [!code highlight]

        export function Page() {
          // ...

          // [!code highlight:16]
          useCopilotAction({
            name: "sayHello",
            description: "Say hello to the user",
            available: "remote", // optional, makes it so the action is *only* available to the agent
            parameters: [
              {
                name: "name",
                type: "string",
                description: "The name of the user to say hello to",
                required: true,
              },
            ],
            handler: async ({ name }) => {
              alert(`Hello, ${name}!`);
            },
          });

          // ...
        }
        ```
    </Step>
    <Step>
        ###  Modify your agent
        Now, we'll need to modify the agent to access these frontend actions. Open up for your agent's folder and continue from there!
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Inheriting from CopilotKitState

        To access the frontend actions provided by CopilotKit, you can inherit from CopilotKitState in your agent's state definition:

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                # your code goes here...
                ```
            </Tab>
        </Tabs>

        By doing this, your agent's state will include the `copilotkit` property, which contains the frontend actions that can be accessed and invoked.
    </Step>
    <Step>
        ### Accessing Frontend Actions

        Once your agent's state includes the `copilotkit` property, you can access the frontend actions and utilize them within your agent's logic.

        Here's how you can call a frontend action from your agent:

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                # your code goes here...
                ```
            </Tab>
        </Tabs>

        These actions are automatically populated by CopilotKit and are compatible with LiteLLM's tool call definitions, making it straightforward to integrate them into your agent's workflow.
    </Step>
    <Step>
        ### Give it a try!
        You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/.coagents-template/index.mdx
================================================
---
title: Introduction
icon: "lucide/Sparkles"
description: Build Agent-Native Applications (ANAs) powered by CopilotKit and --YOUR-FRAMEWORK-- Agents.
---

import { BiSolidMessage as TextIcon } from "react-icons/bi";
import { VscJson as JsonIcon } from "react-icons/vsc";
import { FaDiscord } from "react-icons/fa";
import Link from "next/link";
import { YouTubeVideo } from "@/components/react/youtube-video";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import {
  CoAgentsFeatureToggle,
  CoAgentsFeatureRender,
} from "@/components/react/coagents/coagents-features.tsx";
import { DynamicContentWrapper } from "@/components/react/dynamic-content-wrapper";
import { ExamplesCarousel } from "@/components/react/examples-carousel";
import {
  LuPlane,
  LuBookOpen,
  LuLightbulb,
  LuLayoutTemplate,
  LuBrainCog,
  LuUserCog,
  LuWand2,
  LuPlay,
  LuMessageSquare,
  LuWrench,
} from "react-icons/lu";
import { CoAgentsExamples } from "@/components/react/examples-carousel";
import { CTACards } from "@/components/react/cta-cards";
import { FaSync } from "react-icons/fa";
import { Socials } from "@/components/react/socials";

# Copilot Infrastructure for --YOUR-FRAMEWORK-- Agents

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).

{/* TODO: Add a GIF of this animation for --YOUR-FRAMEWORK-- Agents */}

<Frame className="mt-0 mb-6">
  <video
    src="/images/coagents/your-framework/flows/interaction-layer.mp4"
    alt="CoAgents demonstration"
    className="rounded-lg shadow-xl"
    playsInline
    autoPlay
    muted
    loop
  />
</Frame>

## Building blocks of a CoAgent

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

<CTACards
  columns={2}
  cards={[
    {
      icon: LuMessageSquare,
      title: "Agentic Chat UI",
      description: "In-app chat powered by your agent.",
      href: "/--YOUR-FRAMEWORK--/agentic-chat-ui",
    },
    {
      icon: FaSync,
      title: "Shared State",
      description: "Your agent can see everything in your app, and vice versa.",
      href: "/--YOUR-FRAMEWORK--/shared-state",
    },
    {
      icon: LuLayoutTemplate,
      title: "Generative UI",
      description: "UI that updates in real-time based on your agent's state.",
      href: "/--YOUR-FRAMEWORK--/generative-ui",
    },
    {
      icon: LuWand2,
      title: "Frontend Tools",
      description:
        "Give your agent the ability to take action in your application.",
      href: "/--YOUR-FRAMEWORK--/frontend-actions",
    },
    {
      icon: LuWand2,
      title: "Multi-Agent Coordination",
      description:
        "Route your agent to the right agent based on the user's request.",
      href: "/--YOUR-FRAMEWORK--/multi-agent-flows",
    },
    {
      icon: LuUserCog,
      title: "Human-in-the-Loop",
      description: "Set smart checkpoints where humans can guide your agents.",
      href: "/--YOUR-FRAMEWORK--/human-in-the-loop",
    },
  ]}
/>

{/* TODO: Add CoAgents in action section for --YOUR-FRAMEWORK-- Agents */}

## Ready to get started?

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

<CTACards
  columns={1}
  cards={[
    {
      icon: LuPlay,
      title: "Quickstart",
      description: "Learn how to build your first CoAgent in 10 minutes.",
      href: "/--YOUR-FRAMEWORK--/quickstart/your-framework",
    },
  ]}
/>
{/* TODO: Add example tutorials for --YOUR-FRAMEWORK-- Agents */}

## Common Questions

Have a question about CoAgents? You're in the right place!

<Accordions>
<Accordion title="Can you explain what a CoAgent is in more detail?">
Sure! CoAgents are what we call "agentic copilots". Well, what's an agentic copilot then?

Think of a Copilot as a simple and fully LLM controlled assistant that has relatively limited capabilities. An Agentic Copilot then is a copilot
that has been enhanced with the ability to use --YOUR-FRAMEWORK-- agents to perform more complex tasks. This is an extremely powerful way to build AI
powered applications because it gives you, the developer, the ability to control the agent's behavior in a deterministic way while still letting
the agent do its magic.

For more on this topic, checkout our [agentic copilot](/--YOUR-FRAMEWORK--/concepts/agentic-copilots) concept page.

</Accordion>
<Accordion title="Can I attach to an existing thread?">
Development of CoAgents is ongoing. One part of this is the ability to attach to an existing thread which is a high priority on our roadmap.

Stay tuned for updates!

</Accordion>
</Accordions> 


================================================
FILE: docs/content/docs/.coagents-template/meta.json
================================================
{
  "title": "CoAgents",
  "root": true,
  "pages": [
    "index",
    "[lucide/Telescope][Feature Viewer](https://demo-viewer-five.vercel.app/ )",
    "---Quickstart---",
    "...quickstart",
    "---Guides---",
    "agentic-chat-ui",
    "generative-ui",
    "human-in-the-loop",
    "shared-state",
    "frontend-actions",
    "multi-agent-flows",
    "persistence",
    "advanced",
    "---Learn---",
    "...concepts"
  ]
}



================================================
FILE: docs/content/docs/.coagents-template/multi-agent-flows.mdx
================================================
---
title: Multi-Agent Flows
description: Use multiple agents to orchestrate complex flows.
icon: "lucide/Users"
---
import { Callout } from "fumadocs-ui/components/callout";

<Frame>
    <img src="/images/coagents/multi-agent-flows.png" alt="Multi-Agent Flows" />
</Frame>

## What are Multi-Agent Flows?

When building agentic applications, you often want to orchestrate complex flows together that require the coordination of multiple
agents. This is traditionally called multi-agent orchestration.

## When should I use this?

Multi-agent flows are useful when you want to orchestrate complex flows together that require the coordination of multiple agents. As
your agentic application grows, delegation of sub-tasks to other agents can help you scale key pieces of your application.
- Divide context into smaller chunks
- Delegate sub-tasks to other agents
- Use a single agent to orchestrate the flow

## How does CopilotKit support this?

CopilotKit can be used in either of two distinct modes: **Router Mode**, or **Agent Lock**. By default, CopilotKit
will use Router Mode, leveraging your defined LLM to route requests between agents.

### Router Mode (default)
Router Mode is enabled by default when using CoAgents. To use it, specify a runtime URL prop in the `CopilotKit` provider component and omit the `agent` prop, like so:
```tsx
<CopilotKit runtimeUrl="<copilot-runtime-url>">
  {/* Your application components */}
</CopilotKit>
```

In router mode, CopilotKit acts as a central hub, dynamically selecting and _routing_ requests between different agents or actions based on the user's input. This mode can be good for chat-first experiences where an LLM chatbot is the entry point for a range of interactions, which can stay in the chat UI or expand to include native React UI widgets.

In this mode, CopilotKit will intelligently route requests to the most appropriate agent or action based on the context and user input.

<Callout type="warn">
    Router mode requires that you set up an LLM adapter. See how in ["Set up a copilot runtime"](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint) section of the docs.
</Callout>

### Agent Lock Mode
To use Agent Lock Mode, specify the agent name in the `CopilotKit` component with the `agent` prop:
```tsx
// [!code word:agent]
<CopilotKit runtimeUrl="<copilot-runtime-url>" agent="<the-name-of-the-agent>">
  {/* Your application components */}
</CopilotKit>
```

In this mode, CopilotKit is configured to work exclusively with a specific agent. This mode is useful when you want to focus on a particular task or domain. Whereas in Router Mode the LLM and CopilotKit's router are free to switch between agents to handle user requests, in Agent Lock Mode all requests will stay within a single workflow graph, ensuring precise control over the workflow.

Use whichever mode works best for your app experience! Also, note that while you cannot nest `CopilotKit` providers, you can use different agents or modes in different areas of your app — for example, you may want a chatbot in router mode that can call on any agent or tool, but may also want to integrate one specific agent elsewhere for a more focused workflow. 


================================================
FILE: docs/content/docs/.coagents-template/advanced/disabling-state-streaming.mdx
================================================
---
title: "Disabling state streaming"
icon: "lucide/Cog"
description: "Granularly control what is streamed to the frontend."
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

## What is this?

By default, CopilotKit will stream both your state and tool calls to the frontend.
You can disable this by using CopilotKit's custom `RunnableConfig`.

## When should I use this?

Occasionally, you'll want to disable streaming temporarily — for example, the LLM may be
doing something the current user should not see, like emitting tool calls or questions
pertaining to other employees in an HR system.

## Implementation

### Disable all streaming

You can decide wether to stream messages or tool calls by selectively wrapping calls to `completion`
with `copilotkit_stream`.

<Tabs groupId="language" items={['Python']} default="Python">
    <Tab value="Python">
        ```python
        # your code goes here...
        ```
    </Tab>

</Tabs> 


================================================
FILE: docs/content/docs/.coagents-template/advanced/emit-messages.mdx
================================================
---
title: "Manually emitting messages"
icon: "lucide/Radio"
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";
import RunAndConnectSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";

While most agent interactions happen automatically through shared state updates as the agent runs, you can also **manually send messages from within your agent code** to provide immediate feedback to users.

<video
  src="/images/coagents/emit-messages.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

In --YOUR-FRAMEWORK--, messages are only emitted when a function is completed. CopilotKit allows you to manually emit messages
in the middle of a function's execution to provide immediate feedback to the user.

## When should I use this?

Manually emitted messages are great for **when you don't want to wait for the function** to complete **and you**:

- Have a long running task that you want to provide feedback on
- Want to provide a status update to the user
- Want to provide a warning or error message

## Implementation

<Steps>
    <Step>
        ### Run and Connect Your Agent to CopilotKit
        <RunAndConnectSnippet />
    </Step>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Manually emit a message
        The `copilotkit_emit_message` method allows you to emit messages early in a functions's execution to communicate status updates to the user. This is particularly useful for long running tasks.

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python
                # your code goes here...
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Give it a try!
        Now when you talk to your agent you'll notice that it immediately responds with the message "Thinking really hard..."
        before giving you a response 2 seconds later.
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/.coagents-template/advanced/exit-agent.mdx
================================================
---
title: "Exiting the agent loop"
icon: "lucide/DoorOpen"
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

After your agent has finished a workflow, you'll usually want to explicitly end that loop by calling the `copilotkit_exit()` method in your Python code.

Exiting the agent has different effects depending on mode:

- **Router Mode**: Exiting the agent hands responsibility for handling input back to the router, which can initiate chat, call actions, other agents, etc. The router can return to this agent later (starting a new loop) to satisfy a user request.

- **Agent Lock Mode**: Exiting the agent restarts the workflow loop for the current agent.

In this example from [our email-sending app](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-qa), the `send_email` node explicitly exits, then manually sends a response back to the user as a `ToolMessage`:

<Steps>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Exit the agent loop
        This will exit the agent session as soon as the current --YOUR-FRAMEWORK-- run is finished, either by a breakpoint or by reaching the `END` node.

        <Tabs groupId="language" items={['Python']} default="Python">
            <Tab value="Python">
                ```python
                # your code goes here...
                ```
            </Tab>
        </Tabs>
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/.coagents-template/advanced/meta.json
================================================
{
  "title": "Advanced",
  "icon": "lucide/Cog"
}



================================================
FILE: docs/content/docs/.coagents-template/concepts/agentic-copilots.mdx
================================================
---
title: Agentic Copilots
description: Agentic copilots provide you with advanced control and orchestration over your agents.
icon: lucide/Bot
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content";
import { BsFillCloudHaze2Fill as CloudIcon } from "react-icons/bs";
import { FaServer as SelfHostIcon } from "react-icons/fa6";
import { SiLangchain } from "react-icons/si";
import { LinkIcon } from "lucide-react";
import {
  RocketIcon,
  GraduationCapIcon,
  CodeIcon,
  VideoIcon,
} from "lucide-react";

Before we dive into what agentic copilots are, help us help you by telling us your level of experience with --YOUR-FRAMEWORK--. We'll explain things in a way that best suits your experience level.

<TailoredContent id="experience" defaultOptionIndex={0}>
    <TailoredContentOption 
        id="new"
        title="I'm new to --YOUR-FRAMEWORK--" 
        description="Help me understand what agentic copilots are, where --YOUR-FRAMEWORK-- fits in, and how to get started." 
        icon={<img src="/images/copilotkit-logo.svg" width={7} height={7} />}
    >
        <Frame>
            <img src="/images/coagents/SharedStateCoAgents.gif" alt="CoAgents Shared State" className="mt-0 mb-12"/>
        </Frame>

        ### What are Agents?
        AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from
        simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

        As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized
        frameworks like --YOUR-FRAMEWORK-- become essential.

        ### What is --YOUR-FRAMEWORK--?
        --YOUR-FRAMEWORK-- is a framework that gives you precise control over AI agents. --YOUR-FRAMEWORK-- agents allow developers to combine and coordinate coding tasks efficiently,
        providing a robust framework for building sophisticated AI automations.

        ### What are Agentic Copilots?
        Agentic copilots are how CopilotKit brings --YOUR-FRAMEWORK-- agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that
        understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ)
        for quick implementation, Agentic copilots give you --YOUR-FRAMEWORK--'s full orchestration capabilities when you need more control over your agent's behavior.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ### When should I use CopilotKit's CoAgents?
        You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [--YOUR-FRAMEWORK--](https://--YOUR-FRAMEWORK--.com/).
        With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

        We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.

        The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's
        functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
        up to 100% of the Copilot's tasks (see [agent-lock mode](/--YOUR-FRAMEWORK--/multi-agent-flows) for the 100% case).

        ### Examples
        An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-research-canvas).

        More specifically, it demonstrates how CoAgents allow for AI driven experiences with:
        - Precise state management across agent interactions
        - Sophisticated multi-step reasoning capabilities
        - Seamless orchestration of multiple AI tools
        - Interactive human-AI collaboration features
        - Real-time state updates and progress streaming

        ## Next Steps

        Want to get started? You have some options!

        <Cards>
            <Card
                title="Build your first CoAgent"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/--YOUR-FRAMEWORK--/quickstart/your-framework"
                icon={<RocketIcon />}
            />
            <Card
                title="Learn more CoAgent concepts"
                description="Learn more about the concepts used to talk about CoAgents and how to use them."
                href="/--YOUR-FRAMEWORK--/concepts/terminology"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Read the reference documentation"
                description="Just here for some reference? Checkout the reference documentation for more details."
                href="/--YOUR-FRAMEWORK--/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="See examples of CoAgents in action"
                description="Checkout our video examples of CoAgents in action."
                href="/--YOUR-FRAMEWORK--/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>
    <TailoredContentOption
        id="intermediate"
        title="I'm already using --YOUR-FRAMEWORK--"
        description="Help me understand what agentic copilots are, what Copilotkit does to integrate with --YOUR-FRAMEWORK--, and how to get started."
        icon={<SiLangchain />}
    >

        <Frame className="mt-0 mb-12">
            <img
                src="/images/CoAgents.gif"
                alt="CoAgents demonstration"
                className="w-auto"
            />
        </Frame>

        --YOUR-FRAMEWORK-- is a framework for building deeply customizable AI agents.

        CopilotKit's Agentic Copilots is infrastructure for in-app agent-user interaction, i.e. for transforming agents from autonomous processes to user-interactive 'virtual colleagues' that live inside applications.

        Any --YOUR-FRAMEWORK---based agent can be transformed into an Agentic Copilot with a minimal amount
        of effort to get industry leading agentic UX such as:
        - Shared state between the agent and the application.
        - Intermediate result and state progress streaming
        - Human-in-the-loop collaboration
        - Agentic generative UI
        - And more!

        All of these features are essential to delight instead of frustrate your users with AI features.

        ### What are CoAgents?
        CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

        ## Next Steps
        Want to get started? You have some options!

        <Cards>
            <Card
                title="Quickstart"
                description="Integrate your --YOUR-FRAMEWORK-- agent with CopilotKit in a few minutes."
                href="/--YOUR-FRAMEWORK--/quickstart/your-framework"
                icon={<RocketIcon />}
            />
            <Card
                title="Tutorial: AI Travel App"
                description="Follow a step-by-step tutorial to build a travel app supercharged with CoAgents."
                href="/--YOUR-FRAMEWORK--/tutorials/ai-travel-app/overview"
                icon={<GraduationCapIcon />}
            />
            <Card
                title="Reference"
                description="Learn more about the terms used to talk about CoAgents and how to use them."
                href="/reference"
                icon={<CodeIcon />}
            />
            <Card
                title="Examples"
                description="Checkout our video examples of CoAgents in action."
                href="/--YOUR-FRAMEWORK--/videos/research-canvas"
                icon={<VideoIcon />}
            />
        </Cards>
    </TailoredContentOption>

</TailoredContent> 


================================================
FILE: docs/content/docs/.coagents-template/concepts/copilotkit-stream.mdx
================================================
---
title: Streaming and Tool Calls
description: CoAgents support streaming your messages and tool calls to the frontend.
---

If you'd like to stream messages from your --YOUR-FRAMEWORK-- agents you can utilize our Copilotkit SDK which provides a collection
of functions and utilities for interacting with the agent's state or behavior. This allows you to choose how messages and
tool calls are emitted and streamed to the frontend.

## Message Streaming

If you just call the LiteLLM `completion` function from your --YOUR-FRAMEWORK-- agent, messages will not be streamed by default.
To stream messages, wrap the `completion` function with the `copilotkit_stream` function. This will enable streaming
of both the messages and tool calls to the frontend.

```python
# your code goes here...
```

For more information on how tool calls are utilized check out our [frontend actions](/--YOUR-FRAMEWORK--/frontend-actions)
documentation. 


================================================
FILE: docs/content/docs/.coagents-template/concepts/message-management.mdx
================================================
---
title: Message flow
icon: lucide/MessageCircle
---

Message management in CoAgents operates with CopilotKit as the "ground truth" for the full chat session.
When an CoAgent session begins, it receives the existing CopilotKit chat history to maintain conversational
continuity across different agents.

<Callout>
  While all of this information is great to know, in most cases you won't need
  to worry about these details to build rich agentic applications. Use the
  information here as a reference when getting really deep into the CoAgent
  internals.
</Callout>

### Can I modify the message history?

You can modify the message history from --YOUR-FRAMEWORK-- Agents by using the `"messages"` key in the state. For example to remove all messages from the chat history:

```python
# your code goes here...
```

### Can I persist chat history?

Yes! There are a few ways to persist various portions of a chat's history:

- [Threads](/--YOUR-FRAMEWORK--/persistence/threads)
- [Message Persistence](/--YOUR-FRAMEWORK--/persistence/message-persistence)
- [Agent State](/--YOUR-FRAMEWORK--/persistence/loading-agent-state)

## Types of LLM Messages

Modern LLM interactions produce two distinct types of messages:

1. **Communication Messages**: Direct responses and interactions with users
2. **Internal Messages**: Agent "thoughts" and reasoning processes

A well known example of this pattern is OpenAI's o1 model, which has sophisticated reasoning capabilities and thoughts. Its internal
thought processes are presented distinctly from 'communication messages' which are clearly visible to the end-user.

--YOUR-FRAMEWORK-- agents can operate similarly. An LLM call's output can be considered either a communication message, or an internal message.

### Emitting Messages for long running tasks

Sometimes you'll have a task that is running for a long time, and you want the user to be aware of what's happening.
CopilotKit allows you to accomplish this by using the `copilotkit_emit_message` function.

```python
# your code goes here...
```

Want some more help managing messages in your CoAgent application? Check out our guide on [emitting messages](/--YOUR-FRAMEWORK--/advanced/emit-messages).

## Message Flow

Messages flow between CopilotKit and --YOUR-FRAMEWORK-- in a specific way:

- All messages from --YOUR-FRAMEWORK-- are forwarded to CopilotKit
- On a fresh agent invocation, the full CopilotKit chat history is provided to the --YOUR-FRAMEWORK-- agent as its pre-existing chat history.

When a CoAgent completes its execution, its relevant messages become part of CopilotKit's persistent chat history. This allows for all future agent invocations to get context from the full chat history. 


================================================
FILE: docs/content/docs/.coagents-template/concepts/meta.json
================================================
{
  "title": "Concepts",
  "root": true,
  "pages": [
    "terminology",
    "agentic-copilots",
    "your-framework",
    "message-management",
    "state",
    "copilotkit-stream"
  ]
}



================================================
FILE: docs/content/docs/.coagents-template/concepts/state.mdx
================================================
---
title: Shared State
description: CoAgents maintain a shared state across your UI and agent execution.
---

<Frame className="mb-10">
  <img
    src="/images/coagents/coagents-state-diagram.png"
    alt="Agentic Copilot State Diagram"
  />
</Frame>

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:

- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

The foundation of this system is built on --YOUR-FRAMEWORK--'s stateful architecture. --YOUR-FRAMEWORK-- Agents maintain their
internal state throughout execution, which you can access via the `useCoAgentState` hook.

### Understanding Predicted State

While your agent runs, you can emit state updates using CopilotKit's `emit_intermediate_state` function, ensuring your UI stays synchronized
with the agent's progress. The emitted state is called the **predicted state** and is used to provide immediate feedback about ongoing
operations.

While the core shared state reflects the agent's current function in the flow, the predicted state provides immediate
feedback about ongoing operations. Accordingly, this creates a more fluid user experience by showing real-time progress before the agent
completes its current task.

When the state is updated (when a function finishes executing), the predicted state is updated with the new state.

For example, when your agent is processing a request, the predicted state might show a loading indicator or partial results, while the actual
shared state updates once the operation is complete.

Want help implementing this into your CoAgent application? Check out our [intermediate state streaming](/--YOUR-FRAMEWORK--/shared-state/predictive-state-updates)
documentation. 


================================================
FILE: docs/content/docs/.coagents-template/concepts/terminology.mdx
================================================
---
title: Terminology
icon: lucide/Book
---

Here are the key terms and concepts used throughout CoAgents:

| Term                         | Definition                                                                                                                                                                                         |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Agentic Copilot              | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously.                                                                                     |
| CoAgent                      | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot.                                                            |
| Agent State                  | The current data and context maintained by a --YOUR-FRAMEWORK-- agent during its execution, including both internal state and data that can be synchronized with the frontend UI.                              |
| Agentic Generative UI        | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth                 | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents.            |
| Human-in-the-Loop (HITL)     | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points.                                         |
| Intermediate State           | The updates to agent state that occur during function execution, rather than only at flow transitions, enabling real-time feedback about the agent's progress.                                     |
| [--YOUR-FRAMEWORK--](https://--YOUR-FRAMEWORK--.com) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management.                               |
| Agent Lock Mode              | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control.                                    |
| Router Mode                  | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows.                                   |
| State Streaming              | The real-time synchronization of agent state between the backend and frontend, enabling immediate updates to the UI as the agent performs tasks.                                                   |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications. 


================================================
FILE: docs/content/docs/.coagents-template/concepts/your-framework.mdx
================================================
---
title: --YOUR-FRAMEWORK--
description: An agentic framework for building LLM applications that can be used with Copilotkit.
icon: custom/langchain
---

<Frame>
  <img
    src="/images/coagents/coagents-highlevel-overview.png"
    alt="CoAgents High Level Overview"
    className="mb-10"
  />
</Frame>

--YOUR-FRAMEWORK-- is an agentic framework for building LLM applications that can be used with Copilotkit. --YOUR-FRAMEWORK-- Agents allow developers
to combine and coordinate coding tasks efficiently, providing a robust framework for building sophisticated AI automations.

## CoAgents and --YOUR-FRAMEWORK--

How do CoAgents extend --YOUR-FRAMEWORK--? Let's read about the concept of Flows to understand.

> Flows allow you to create structured, event-driven workflows. They provide a seamless way to connect multiple tasks, manage state, and control the flow of execution in your AI applications.

Let's break down some key terms and understand how they relate to and are implemented by CoAgents.

- ** manage state**: CoAgents have bi-directional state sharing with the agent and UI. This allows for the agent to remember
  information from previous messages and the UI to update the agent with new information. Read more about how state sharing works
  [here](/--YOUR-FRAMEWORK--/shared-state).
- **Multi-actor**: CoAgents allow for multiple agents to interact with each other. Copilotkit acts as the "ground-truth"
  when transitioning between agents. Read more about how multi-actor workflows work [here](/--YOUR-FRAMEWORK--/multi-agent-flows)
  and how messages are managed [here](/--YOUR-FRAMEWORK--/concepts/message-management).
- **LLMs**: CoAgents use large language models to generate responses. This is useful for building applications that need to
  generate natural language responses.

Some additional functionality not mentioned here is:

- **Human in the loop**: CoAgents enabled human review and approval of generated responses. Read more about how this works
  [here](/--YOUR-FRAMEWORK--/human-in-the-loop).
- **Tool calling**: Tool calling is a fundamental building block for agentic workflows. They allow for greater control over what
  the agent can do and can be used to interact with external systems. CoAgents allow you to easily render in-progress
  tool calls in the UI so your users know what's happening. Read more about streaming tool calls [here](/--YOUR-FRAMEWORK--/shared-state/predictive-state-updates).

## Building with Python

You can build --YOUR-FRAMEWORK-- applications using Python. Check out the [--YOUR-FRAMEWORK-- docs](https://docs.--YOUR-FRAMEWORK--.com/introduction) for more information.

## --YOUR-FRAMEWORK-- Enterprise

Turn any application into an API within seconds
Connect to your apps using hooks, REST, gRPC and more
Get access to templates, custom tools and early UI
Get business support, SLA, private VPC

--YOUR-FRAMEWORK-- enterprise is a platform for deploying and monitoring --YOUR-FRAMEWORK-- applications. Read more about it on the
[--YOUR-FRAMEWORK-- website](https://www.--YOUR-FRAMEWORK--.com/enterprise).

If you want to take the next step to deploy your --YOUR-FRAMEWORK-- application as an CoAgent, check out our [quickstart guide](/--YOUR-FRAMEWORK--/quickstart/your-framework). 


================================================
FILE: docs/content/docs/.coagents-template/generative-ui/agentic.mdx
================================================
---
title: Agentic Generative UI
icon: "lucide/Bot"
description: Render the state of your agent with custom UI components.
---

import InstallSDKSnippet from "@/snippets/install-sdk.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

<video
  src="/images/coagents/agentic-generative-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--).
</Callout>

## What is this?

All --YOUR-FRAMEWORK-- Agents are stateful. This means that as your agent progresses through nodes, a state object is passed between them perserving
the overall state of a session. CopilotKit allows you to render this state in your application with custom UI components, which we call **Agentic Generative UI**.

## When should I use this?

Rendering the state of your agent in the UI is useful when you want to provide the user with feedback about the overall state of a session. A great example of this
is a situation where a user and an agent are working together to solve a problem. The agent can store a draft in its state which is then rendered in the UI.

## Implementation

<Steps>
  <Step>
    ### Run and Connect your --YOUR-FRAMEWORK-- Agent to CopilotKit
    First, you'll need to make sure you have a running --YOUR-FRAMEWORK-- Agent. If you haven't already done this, you can follow the [getting started guide](/--YOUR-FRAMEWORK--/quickstart/your-framework)

    This guide uses the [CoAgents starter repo](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--) as its starting point.

  </Step>
  <Step>
    ### Define your agent state
    If you're not familiar with --YOUR-FRAMEWORK--, your flows are stateful. As you progress through function, a state object is updated between them. CopilotKit
    allows you to easily render this state in your application. 
    
    For the sake of this guide, let's say our state looks like this in our agent.

    <Tabs groupId="language" items={['Python']} default="Python">
        <Tab value="Python">
          ```python title="agent-py/sample_agent/agent.py"
          # your code goes here...
          ```
        </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Simulate state updates
    Next, let's write some logic into our agent that will simulate state updates occurring.

    <Tabs groupId="language" items={['Python']} default="Python">
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        # your code goes here...
        ```
      </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Render state of the agent in the chat
    Now we can utilize `useCoAgentStateRender` to render the state of our agent **in the chat**.

    ```tsx title="app/page.tsx"
    // ...
    import { useCoAgent } from "@copilotkit/react-core";
    // ...

    // Define the state of the agent, should match the state of the agent in your LangGraph.
    type AgentState = {
      searches: {
        query: string;
        done: boolean;
      }[];
    };

    function YourMainContent() {
      // ...

      // [!code highlight:14]
      // styles omitted for brevity
      useCoAgentStateRender<AgentState>({
        name: "sample_agent", // the name the agent is served as
        render: ({ state }) => (
          <div>
            {state.searches?.map((search, index) => (
              <div key={index}>
                {search.done ? "✅" : "❌"} {search.query}{search.done ? "" : "..."}
              </div>
            ))}
          </div>
        ),
      });

      // ...

      return <div>...</div>;
    }
    ```

  </Step>
  <Step>
    ### Render state outside of the chat
    You can also render the state of your agent **outside of the chat**. This is useful when you want to render the state of your agent anywhere
    other than the chat.

    ```tsx title="app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]
    // ...

    // Define the state of the agent, should match the state of the agent in your LangGraph.
    type AgentState = {
      searches: {
        query: string;
        done: boolean;
      }[];
    };

    function YourMainContent() {
      // ...

      // [!code highlight:5]
      const { state } = useCoAgent<AgentState>({
        name: "sample_agent", // the name the agent is served as
      })

      // ...

      return (
        <div>
          {/* ... */}
          <div className="flex flex-col gap-2 mt-4">
            // [!code highlight:6]
            {state.searches?.map((search, index) => (
              <div key={index} className="flex flex-row">
                {search.done ? "✅" : "❌"} {search.query}
              </div>
            ))}
          </div>
        </div>
      )
    }
    ```

  </Step>
  <Step>
    ### Give it a try!

    You've now created a component that will render the agent's state in the chat.

  </Step>
</Steps>


================================================
FILE: docs/content/docs/.coagents-template/generative-ui/index.mdx
================================================
---
title: Generative UI
icon: "lucide/Paintbrush"
description: Render your agent's behavior with custom UI components.
---

import { CTACards } from "@/components/react/cta-cards";
import { WrenchIcon, BotIcon } from "lucide-react";

<Frame>
  <img
    src="/images/coagents/AgenticGenerativeUI.gif"
    className="my-0"
    alt="Demo of Generative UI showing a meeting scheduling agent"
  />
</Frame>

<Callout>
  This example shows our [Research Canvas](/--YOUR-FRAMEWORK--/videos/research-canvas)
  making use of Generative UI!
</Callout>

## What is Generative UI?

Generative UI lets you render your agent's state, progress, outputs, and tool calls with custom UI components in real-time. It bridges the gap between AI
agents and user interfaces. As your agent processes information and makes decisions, you can render custom UI components that:

- Show loading states and progress indicators
- Display structured data in tables, cards, or charts
- Create interactive elements for user input
- Animate transitions between different states

## How can I use this?

There are two main variants of Generative UI.

<CTACards
  columns={2}
  cards={[
    {
      icon: BotIcon,
      title: "Agentic",
      description:
        "Render your agent's state, progress, and outputs with custom UI components.",
      href: "/--YOUR-FRAMEWORK--/generative-ui/agentic",
    },
    {
      icon: WrenchIcon,
      title: "Tool-based",
      description: "Render your agent's tool calls with custom UI components.",
      href: "/--YOUR-FRAMEWORK--/generative-ui/tool-based",
    },
  ]}
/> 


================================================
FILE: docs/content/docs/.coagents-template/generative-ui/tool-based.mdx
================================================
---
title: Tool-based Generative UI
icon: "lucide/Wrench"
description: Render your agent's tool calls with custom UI components.
---

import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";

<video
  src="/images/coagents/tool-based-gen-ui.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video demonstrates the [implementation](#implementation) section applied
  to out [coagents starter
  project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--).
</Callout>

## What is this?

Tools are a way for the LLM to call predefined, typically, deterministic functions. CopilotKit allows you to render these tools in the UI
as a custom component, which we call **Generative UI**.

## When should I use this?

Rendering tools in the UI is useful when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
<Step>
### Run and connect your agent

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](/--YOUR-FRAMEWORK--/quickstart/your-framework) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--) as a starting point
as this guide uses it as a starting point.

</Step>
<Step>
### Give your agent a tool to call

<Tabs groupId="language" items={['Python']} default="Python">
    <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        # your code goes here...
        ```
    </Tab>

</Tabs>
</Step>
<Step>
### Render the tool call in your frontend
At this point, your agent will be able to call the `get_weather` tool. Now 
we just need to add a `useCopilotAction` hook to render the tool call in
the UI.

<Callout type="info" title="Important">
  In order to render a tool call in the UI, the name of the action must match
  the name of the tool.
</Callout>

```tsx title="app/page.tsx"
import { useCopilotAction } from "@copilotkit/react-core"; // [!code highlight]
// ...

const YourMainContent = () => {
  // ...
  // [!code highlight:13]
  useCopilotAction({
    name: "get_weather",
    available: "disabled", // Don't allow the agent or UI to call this tool as its only for rendering
    render: ({ status, args }) => {
      return (
        <p className="text-gray-500 mt-2">
          {status !== "complete" && "Calling weather API..."}
          {status === "complete" &&
            `Called the weather API for ${args.location}.`}
        </p>
      );
    },
  });
  // ...
};
```

</Step>
<Step>
### Give it a try!

Try asking the agent to get the weather for a location. You should see the custom UI component that we added
render the tool call and display the arguments that were passed to the tool.

</Step>
</Steps> 


================================================
FILE: docs/content/docs/.coagents-template/human-in-the-loop/flow.mdx
================================================
---
title: --YOUR-FRAMEWORK-- Agents
description: Learn how to implement Human-in-the-Loop (HITL) using --YOUR-FRAMEWORK-- Agents.
icon: lucide/Share2
---

import RunAndConnectAgentSnippet from "@/snippets/coagents/run-and-connect-agent.mdx";
import InstallSDKSnippet from "@/snippets/install-sdk.mdx";

<video
  src="/images/coagents/node-hitl.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

<Callout type="info">
  Pictured above is the [coagent
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter)
  with the implementation below applied!
</Callout>

## What is this?

[Flow based agents](https://docs.--YOUR-FRAMEWORK--.com/concepts/flows) are stateful agents that can be interrupted and resumed
to allow for user input.

CopilotKit lets you to add custom UI to take user input and then pass it back to the agent upon completion.

## Why should I use this?

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

Flow based agents are a great way to implement HITL for more complex workflows where you want to ensure the agent is aware
of everything that has happened during a HITL interaction.

## Implementation

<Steps>
    <Step>
        ### Run and connect your agent

        You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
        you can follow the instructions in the [Getting Started](/--YOUR-FRAMEWORK--/quickstart/your-framework) guide.

        If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--) as a starting point
        as this guide uses it as a starting point.
    </Step>

    <Step>
      ### Install the CopilotKit SDK
      <InstallSDKSnippet components={props.components}/>
    </Step>

    <Step>
        ### Add a `useCopilotAction` to your Frontend
        First, we'll create a component that renders the agent's essay draft and waits for user approval.

        ```tsx title="ui/app/page.tsx"
        import { useCopilotAction } from "@copilotkit/react-core"
        import { Markdown } from "@copilotkit/react-ui"

        function YourMainContent() {
          // ...

          useCopilotAction({
            name: "writeEssay",
            available: "remote",
            description: "Writes an essay and takes the draft as an argument.",
            parameters: [
              { name: "draft", type: "string", description: "The draft of the essay", required: true },
            ],
            // [!code highlight:25]
            renderAndWaitForResponse: ({ args, respond, status }) => {
              return (
                <div>
                  <Markdown content={args.draft || 'Preparing your draft...'} />

                  <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
                    <button
                      onClick={() => respond?.("CANCEL")}
                      disabled={status !== "executing"}
                      className="border p-2 rounded-xl w-full"
                    >
                      Try Again
                    </button>
                    <button
                      onClick={() => respond?.("SEND")}
                      disabled={status !== "executing"}
                      className="bg-blue-500 text-white p-2 rounded-xl w-full"
                    >
                      Approve Draft
                    </button>
                  </div>
                </div>
              );
            },
          });

          // ...
        }
        ```
    </Step>

    <Step>
    ### Setup the --YOUR-FRAMEWORK-- Agent
    Now we'll setup the --YOUR-FRAMEWORK-- agent. The flow is hard to understand without a complete example, so below
    is the complete implementation of the agent with explanations.

    Some main things to note:
    - The agent's state inherits from `CopilotKitState` to bring in the CopilotKit actions.
    - CopilotKit's actions are bound to the model as tools.
    - If the `writeEssay` action is found in the model's response, the agent will pass control back to the frontend
      to get user feedback.

    <Tabs groupId="language" items={["Python"]}>
      <Tab value="Python">
        ```python title="agent/sample_agent/agent.py"
        # your code goes here...
        ```
      </Tab>
    </Tabs>
    </Step>
    <Step>
        ### Give it a try!
        Try asking your agent to write an essay about the benefits of AI. You'll see that it will generate an essay,
        stream the progress and eventually ask you to review it.
    </Step>

</Steps> 


================================================
FILE: docs/content/docs/.coagents-template/human-in-the-loop/index.mdx
================================================
---
title: Human in the Loop (HITL)
icon: "lucide/User"
description: Allow your agent and users to collaborate on complex tasks.
---

import { CTACards } from "@/components/react/cta-cards";
import { Pause, Share2 } from "lucide-react";

<video
  src="/images/coagents/human-in-the-loop-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

{/* TODO: Add Example */}
{/* <Callout>
This video shows an example of our [AI Travel App](/coagents/tutorials/ai-travel-app) using HITL to get user feedback.

</Callout> */}

## What is Human-in-the-Loop (HITL)?

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

<Frame className="my-0">
  <img
    src="/images/coagents/coagents-hitl-infographic.png"
    alt="Agentic Copilot Human in the Loop"
    className="mt-4 mb-0 shadow-md"
  />
</Frame>

## When should I use this?

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## How can I use this?

Read more about the approach to HITL in --YOUR-FRAMEWORK-- Agents.

<CTACards
  columns={1}
  cards={[
    {
      icon: Share2,
      title: "Flow-based",
      description:
        "Utilize --YOUR-FRAMEWORK-- Agents to create Human-in-the-Loop workflows.",
      href: "/--YOUR-FRAMEWORK--/human-in-the-loop/flow",
    },
  ]}
/> 


================================================
FILE: docs/content/docs/.coagents-template/human-in-the-loop/meta.json
================================================
{
  "pages": ["flow"]
}



================================================
FILE: docs/content/docs/.coagents-template/persistence/loading-agent-state.mdx
================================================
---
title: Loading Agent State
description: Learn how threadId is used to load previous agent states.
icon: "lucide/ChartBar"
---

### Setting the threadId

When setting the `threadId` property in CopilotKit, i.e:

```tsx
<CopilotKit threadId="2140b272-7180-410d-9526-f66210918b13">
  <YourApp />
</CopilotKit>
```

CopilotKit will restore the complete state of the thread, including the messages, from the database.
(See [Message Persistence](/--YOUR-FRAMEWORK--/persistence/message-persistence) for more details.)

### Loading Agent State

<Callout>
  **Important:** For agent state to be loaded correctly, you must first ensure
  that message history and persistence are properly configured. Follow the
  guides on [Threads &
  Persistence](/--YOUR-FRAMEWORK--/persistence/loading-message-history) and [Message
  Persistence](/--YOUR-FRAMEWORK--/persistence/message-persistence).
</Callout>

This means that the state of any agent will also be restored. For example:

```tsx
const { state } = useCoAgent({ name: "research_agent" });

// state will now be the state of research_agent in the thread id given above
```

### Learn More

To learn more about persistence and state in CopilotKit, see:

- [Reading agent state](/--YOUR-FRAMEWORK--/shared-state/in-app-agent-read)
- [Writing agent state](/--YOUR-FRAMEWORK--/shared-state/in-app-agent-write)
- [Loading Message History](/--YOUR-FRAMEWORK--/persistence/loading-message-history) 


================================================
FILE: docs/content/docs/.coagents-template/persistence/loading-message-history.mdx
================================================
---
title: Threads
description: Learn how to maintain persistent conversations across sessions with --YOUR-FRAMEWORK-- Agents.
icon: "lucide/MessagesSquare"
---

# Understanding Thread Persistence

--YOUR-FRAMEWORK-- Agents supports threads, a way to group messages together and maintain a continuous chat history across sessions. CopilotKit provides mechanisms to ensure conversation state is properly persisted between the frontend and backend.

This guide assumes you have already gone through the [quickstart](/quickstart) guide.

<Callout>
  **Note:** While the frontend uses `threadId` to manage conversation sessions,
  true persistence across sessions requires backend setup. The backend agent
  needs to implement a persistence mechanism (like the one shown in
  [Message Persistence](/--YOUR-FRAMEWORK--/persistence/message-persistence))
  to save and load the state associated with each `threadId`.

See the [sample agent implementation](https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-starter---YOUR-FRAMEWORK--/agent-py/sample_agent/agent.py#L291)
for a concrete example.

</Callout>

## Frontend: Setting the ThreadId

### Loading an Existing Thread

To load an existing thread in CopilotKit, set the `threadId` property on `<CopilotKit>`:

```tsx
import { CopilotKit } from "@copilotkit/react-core";

<CopilotKit threadId="37aa68d0-d15b-45ae-afc1-0ba6c3e11353">
  <YourApp />
</CopilotKit>;
```

### Dynamically Switching Threads

You can make the `threadId` dynamic. Once set, CopilotKit will load previous messages for that thread.

```tsx
import { useState } from "react";
import { CopilotKit } from "@copilotkit/react-core";

const Page = () => {
  const [threadId, setThreadId] = useState(
    "af2fa5a4-36bd-4e02-9b55-2580ab584f89"
  );
  return (
    <CopilotKit threadId={threadId}>
      <YourApp setThreadId={setThreadId} />
    </CopilotKit>
  );
};

const YourApp = ({ setThreadId }) => {
  return (
    <Button onClick={() => setThreadId("679e8da5-ee9b-41b1-941b-80e0cc73a008")}>
      Change Thread
    </Button>
  );
};
```

### Using setThreadId

CopilotKit provides the current `threadId` and a `setThreadId` function from the `useCopilotContext` hook:

```tsx
import { useCopilotContext } from "@copilotkit/react-core";

const ChangeThreadButton = () => {
  const { threadId, setThreadId } = useCopilotContext();
  return (
    <Button onClick={() => setThreadId("d73c22f3-1f8e-4a93-99db-5c986068d64f")}>
      Change Thread
    </Button>
  );
};
``` 


================================================
FILE: docs/content/docs/.coagents-template/persistence/message-persistence.mdx
================================================
---
title: "Message Persistence"
icon: "lucide/Database"
---

<Callout>
  To learn about how to load previous messages and agent states, check out the
  [Loading Message History](/--YOUR-FRAMEWORK--/persistence/loading-message-history)
  and [Loading Agent State](/--YOUR-FRAMEWORK--/persistence/loading-agent-state)
  pages.
</Callout>

To persist --YOUR-FRAMEWORK-- Agent messages to a database, you can use the appropriate persistence methods for your framework. For example, you might use a database connector or provide your own custom persistence class.

For a concrete example of how a custom persistence class like `InMemoryFlowPersistence` can be implemented and used with your framework, see the [sample agent implementation](https://github.com/CopilotKit/CopilotKit/blob/main/examples/coagents-starter---YOUR-FRAMEWORK--/agent-py/sample_agent/agent.py).

Read more about persistence in the [--YOUR-FRAMEWORK-- Agents documentation](https://docs.--YOUR-FRAMEWORK--.com/concepts/flows). 


================================================
FILE: docs/content/docs/.coagents-template/persistence/meta.json
================================================
{
  "title": "Persistence",
  "icon": "lucide/Database"
}



================================================
FILE: docs/content/docs/.coagents-template/quickstart/meta.json
================================================
{
  "title": "Quickstart",
  "icon": "lucide/Play"
}



================================================
FILE: docs/content/docs/.coagents-template/quickstart/your-framework.mdx
================================================
---
title: Quickstart --YOUR-FRAMEWORK-- Agents
description: Turn your --YOUR-FRAMEWORK-- Agents into an agent-native application in 10 minutes.
icon: "custom/your-framework"
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import { CoAgentsDiagram } from "@/components/react/coagents/coagents-diagram.tsx";
import { FaPython, FaJs, FaCloud } from "react-icons/fa";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import CopilotCloudConfigureRemoteEndpointLangGraph from "@/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx";
import CopilotKitCloudCopilotKitProvider from "@/snippets/copilot-cloud-configure-copilotkit-provider.mdx";
import LangGraphPlatformDeploymentTabs from "@/snippets/langgraph-platform-deployment-tabs.mdx";
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";
import CloudCopilotKitProvider from "@/snippets/coagents/cloud-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeConfigureCopilotKitProvider from "@/snippets/coagents/self-host-configure-copilotkit-provider.mdx";
import SelfHostingCopilotRuntimeLangGraphEndpoint from "@/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx";
import SelfHostingCopilotRuntimeStarter from "@/snippets/self-hosting-copilot-runtime-starter.mdx";
import SelfHostingRemoteEndpoints from "@/snippets/self-hosting-remote-endpoints.mdx";
import {
  UserIcon,
  PaintbrushIcon,
  WrenchIcon,
  RepeatIcon,
  ServerIcon,
} from "lucide-react";
import CopilotUI from "@/snippets/copilot-ui.mdx";

<video
  src="/images/coagents/chat-example.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>

## Prerequisites

Before you begin, you'll need the following:

- [**OpenAI API key**](https://platform.openai.com/api-keys)

## Getting started

<Steps>
    <Step>
        ### Install CopilotKit
        First, install the latest packages for CopilotKit into your frontend.
        ```package-install
        npm install @copilotkit/react-ui @copilotkit/react-core
        ```
    </Step>
    <TailoredContent
        className="step"
        id="agent"
        header={
            <div>
                <p className="text-xl font-semibold">Do you already have a --YOUR-FRAMEWORK-- Agent?</p>
                <p className="text-base">
                    You will need a --YOUR-FRAMEWORK-- Agent to get started!
                </p>
                <p className="text-base">
                    Either bring your own or feel free to use our starter repo.
                </p>
            </div>
        }
    >
        <TailoredContentOption
            id="bring-your-own"
            title="Bring your own --YOUR-FRAMEWORK-- Agent"
            description="I already have a --YOUR-FRAMEWORK-- Agent and want to use it with CopilotKit."
            icon={<img src="/images/your-framework-logo.svg" alt="Your Framework Logo" width={20} height={20} />}
        />
        <TailoredContentOption
            id="coagents-starter"
            title="Use the CoAgents Starter repo"
            description="I don't have a --YOUR-FRAMEWORK-- Agent yet, but want to get started quickly."
            icon={<img src="/images/copilotkit-logo.svg" alt="CopilotKit Logo" width={20} height={20} />}
        >
            <Step>
                ### Clone the `coagents-starter` repo

                <Tabs groupId="language" items={["Python"]}>
                    <Tab value="Python">
                        ```bash
                        git clone https://github.com/CopilotKit/CopilotKit
                        cd CopilotKit/examples/coagents-starter---YOUR-FRAMEWORK--/agent-py
                        ```
                    </Tab>
                </Tabs>
            </Step>
            <Step>
                ### Create a `.env` file

                ```bash
                touch .env
                ```
            </Step>
            <Step>
                ### Add your API keys

                Then add your **OpenAI API key** to the `.env` file.

                ```plaintext title=".env"
                OPENAI_API_KEY=your_openai_api_key
                ```
            </Step>
        </TailoredContentOption>
    </TailoredContent>
    <Step>
        ### Launch your local agent

        Start your local --YOUR-FRAMEWORK-- Agent:

        ```bash
        # your code goes here...
        ```
        This will start a local agent server that you can connect to.
    </Step>

    <TailoredContent
        className="step"
        id="copilot-hosting"
        header={
            <div>
                <p className="text-xl font-semibold">Choose your connection method</p>
                <p className="text-base">
                    Now you need to connect your --YOUR-FRAMEWORK-- Agent to CopilotKit.
                </p>
            </div>
        }
    >
        <TailoredContentOption
            id="copilot-cloud"
            title="Copilot Cloud (Recommended)"
            description="I want to host my Copilot on Copilot Cloud"
            icon={<FaCloud />}
        >
            <Step>
                ### Add a remote endpoint for your --YOUR-FRAMEWORK-- Agent
                Using Copilot Cloud, you need to connect a remote endpoint that will connect to your --YOUR-FRAMEWORK-- Agent.
                <Tabs groupId="lg-deployment-type" items={['Self hosted (FastAPI)', '--YOUR-FRAMEWORK-- Enterprise']}>
                    <Tab value="Self hosted (FastAPI)">
                        **Running your FastAPI server in production**

                        Head over to [Copilot Cloud](https://cloud.copilotkit.ai) sign up and setup a remote endpoint with the following information:
                        - OpenAI API key
                        - Your FastAPI server URL

                        **Running your FastAPI server locally**

                        If you're running your FastAPI server locally, you can open a tunnel to it so Copilot Cloud can connect to it.

                        ```bash
                        npx copilotkit@latest dev --port 8000
                        ```
                    </Tab>
                    <Tab value="--YOUR-FRAMEWORK-- Enterprise">
                        Coming soon!
                    </Tab>
                </Tabs>
            </Step>
            <Step>
                ### Setup your CopilotKit provider
                The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

                <CloudCopilotKitProvider components={props.components} />

                <Callout type="info">
                    Looking for a way to run multiple --YOUR-FRAMEWORK-- Agents? Check out our [Multi-Agent](/--YOUR-FRAMEWORK--/multi-agent-flows) guide.
                </Callout>
            </Step>
        </TailoredContentOption>
        <TailoredContentOption
            id="self-hosted"
            title="Self-Hosted Copilot Runtime"
            description="I want to self-host the Copilot Runtime"
            icon={<ServerIcon />}
        >
            <Step>
                ### Install Copilot Runtime
                Copilot Runtime is a production-ready proxy for your --YOUR-FRAMEWORK-- Agents. In your frontend, go ahead and install it.

                ```package-install
                @copilotkit/runtime
                ```
            </Step>
            <Step>
                ### Setup a Copilot Runtime Endpoint
                Now we need to setup a Copilot Runtime endpoint and point your frontend to it.
                <SelfHostingCopilotRuntimeStarter components={props.components}/>
            </Step>
            <Step>
                ### Add your --YOUR-FRAMEWORK-- Agent deployment to Copilot Runtime
                Now we need to add your --YOUR-FRAMEWORK-- Agent deployment to Copilot Runtime. This will make it
                so your frontend can find your --YOUR-FRAMEWORK-- Agents correctly.
                ```ts
                import {
                CopilotRuntime,
                // ...
                } from "@copilotkit/runtime";
                // ...
                const runtime = new CopilotRuntime({
                remoteEndpoints: [
                    // [!code highlight:3]
                    // Our FastAPI endpoint URL
                    { url: "http://localhost:8000/copilotkit" },
                ],
                });
                // ...
                ```
            </Step>
            <Step>
                ### Configure the CopilotKit Provider
                The [`<CopilotKit>`](/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
                it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.
                <SelfHostingCopilotRuntimeConfigureCopilotKitProvider components={props.components}/>
                <Callout type="info">
                    Looking for a way to run multiple --YOUR-FRAMEWORK-- Agents? Check out our [Multi-Agent](/--YOUR-FRAMEWORK--/multi-agent-flows) guide.
                </Callout>
            </Step>
        </TailoredContentOption>
    </TailoredContent>
    <Step>
        ### Setup the Copilot UI
        The last step is to use CopilotKit's UI components to render the chat interaction with your agent. In most situations,
        this is done alongside your core page components, e.g. in your `page.tsx` file.

        ```tsx title="page.tsx"
        // [!code highlight:3]
        import "@copilotkit/react-ui/styles.css";
        import { CopilotPopup } from "@copilotkit/react-ui";

        export function YourApp() {
          return (
            <main>
              <h1>Your main content</h1>
              // [!code highlight:7]
              <CopilotPopup
                labels={{
                    title: "Popup Assistant",
                    initial: "Hi! I'm connected to an agent. How can I help?",
                }}
              />
            </main>
          );
        }
        ```

        <Callout type="info">
            Looking for other chat component options? Check out our [Agentic Chat UI](/--YOUR-FRAMEWORK--/agentic-chat-ui) guide.
        </Callout>
    </Step>
    <Step>
        ### 🎉 Talk to your agent!

        Congrats! You've successfully integrated a --YOUR-FRAMEWORK-- Agent chatbot to your application. To start, try asking a few questions to your agent.

        ```
        Can you tell me a joke?
        ```

        ```
        Can you help me understand AI?
        ```

        ```
        What do you think about React?
        ```

        <video src="/images/coagents/chat-example.mp4" className="rounded-lg shadow-xl" loop playsInline controls autoPlay muted />

        <Accordions className="mb-4">
            <Accordion title="Having trouble?">
                - Try changing the host to `0.0.0.0` or `127.0.0.1` instead of `localhost`.
            </Accordion>
        </Accordions>
    </Step>

</Steps>

---

## What's next?

You've now got a --YOUR-FRAMEWORK-- Agent running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

<Cards>
  <Card
    title="Implement Human in the Loop"
    description="Allow your users and agents to collaborate together on tasks."
    href="/--YOUR-FRAMEWORK--/human-in-the-loop"
    icon={<UserIcon />}
  />
  <Card
    title="Utilize the Shared State"
    description="Learn how to synchronize your agent's state with your UI's state, and vice versa."
    href="/--YOUR-FRAMEWORK--/shared-state"
    icon={<RepeatIcon />}
  />
  <Card
    title="Add some generative UI"
    description="Render your agent's progress and output in the UI."
    href="/--YOUR-FRAMEWORK--/generative-ui"
    icon={<PaintbrushIcon />}
  />
  <Card
    title="Setup frontend actions"
    description="Give your agent the ability to call frontend tools, directly updating your application."
    href="/--YOUR-FRAMEWORK--/frontend-actions"
    icon={<WrenchIcon />}
  />
</Cards> 


================================================
FILE: docs/content/docs/.coagents-template/shared-state/in-app-agent-read.mdx
================================================
---
title: Reading agent state
icon: "lucide/ArrowLeft"
description: Read the realtime agent state in your native application.
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<Frame>
  <ImageZoom
    src="/images/coagents/read-agent-state.png"
    alt="read agent state"
    width={1000}
    height={1000}
    className="my-0"
  />
</Frame>

<Callout type="info">
  Pictured above is the [coagent
  starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter)
  with the [implementation](#implementation) section applied!
</Callout>

## What is this?

You can easily use the realtime agent state not only in the chat UI, but also in the native application UX.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent's state. As your agent's
state update you can reflect these updates natively in your application.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Define the Agent State
    --YOUR-FRAMEWORK-- Agents are stateful. As you transition through the flow, that state is updated and available to the next function. For this example,
    let's assume that our agent state looks something like this.

    <Tabs groupId="language" items={["Python"]}>
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        # your code goes here...
        ```
      </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Use the `useCoAgent` Hook
    With your agent connected and running all that is left is to call the [useCoAgent](/reference/hooks/useCoAgent) hook, pass the agent's name, and
    optionally provide an initial state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    function YourMainContent() {
      const { state } = useCoAgent<AgentState>({ // [!code highlight:4]
        name: "sample_agent",
        initialState: { language: "spanish" }  // optionally provide an initial state
      });

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your main content</h1>
          <p>Language: {state.language}</p> // [!code highlight]
        </div>
      );
    }
    ```
    <Callout type="info">
      The `state` in `useCoAgent` is reactive and will automatically update when the agent's state changes.
    </Callout>

  </Step>
  <Step>
    ### Give it a try!
    As the agent state updates, your `state` variable will automatically update with it! In this case, you'll see the
    language set to "spanish" as that's the initial state we set.
  </Step>
</Steps>

## Rendering agent state in the chat

You can also render the agent's state in the chat UI. This is useful for informing the user about the agent's state in a
more in-context way. To do this, you can use the [useCoAgentStateRender](/reference/hooks/useCoAgentStateRender) hook.

```tsx title="ui/app/page.tsx"
import { useCoAgentStateRender } from "@copilotkit/react-core"; // [!code highlight]

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
};

function YourMainContent() {
  // ...
  // [!code highlight:8]
  useCoAgentStateRender({
    name: "sample_agent",
    render: ({ state }) => {
      if (!state.language) return null;
      return <div>Language: {state.language}</div>;
    },
  });
  // ...
}
```

<Callout type="info">
  The `state` in `useCoAgentStateRender` is reactive and will automatically
  update when the agent's state changes.
</Callout>

## Intermediately Stream and Render Agent State

By default, the --YOUR-FRAMEWORK-- Agent state will only update _between_ --YOUR-FRAMEWORK-- Agent node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](/--YOUR-FRAMEWORK--/shared-state/predictive-state-updates).** 


================================================
FILE: docs/content/docs/.coagents-template/shared-state/in-app-agent-write.mdx
================================================
---
title: Writing agent state
icon: "lucide/ArrowRight"
description: Write to agent's state from your application.
---

<video
  src="/images/coagents/write-agent-state.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--)
  repo with the previous steps applied to it!
</Callout>

## What is this?

This guide shows you how to write to your agent's state from your application.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## Implementation

<Steps>
  <Step>
    ### Run and Connect Your Agent to CopilotKit

    You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
    you can follow the instructions in the [Getting Started](/getting-started) guide.

    If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagent-starter) as a starting point
    as this guide uses it as a starting point.

  </Step>
  <Step>
    ### Define the Agent State
    --YOUR-FRAMEWORK-- Agents are stateful. As you transition through the flow, that state is updated and available to the next function. For this example,
    let's assume that our agent state looks something like this.

    <Tabs groupId="language" items={["Python", "TypeScript"]}>
      <Tab value="Python">
        ```python title="agent-py/sample_agent/agent.py"
        # your code goes here...
        ```
      </Tab>
    </Tabs>

  </Step>
  <Step>
    ### Call `setState` function from the `useCoAgent` hook
    `useCoAgent` returns a `setState` function that you can use to update the agent state. Calling this
    will update the agent state and trigger a rerender of anything that depends on the agent state.

    ```tsx title="ui/app/page.tsx"
    import { useCoAgent } from "@copilotkit/react-core"; // [!code highlight]

    // Define the agent state type, should match the actual state of your agent
    type AgentState = {
      language: "english" | "spanish";
    }

    // Example usage in a pseudo React component
    function YourMainContent() {
      const { state, setState } = useCoAgent<AgentState>({ // [!code highlight]
        name: "sample_agent",
        initialState: { language: "spanish" }  // optionally provide an initial state
      });

      // ...

      const toggleLanguage = () => {
        setState({ language: state.language === "english" ? "spanish" : "english" }); // [!code highlight]
      };

      // ...

      return (
        // style excluded for brevity
        <div>
          <h1>Your main content</h1>
          <p>Language: {state.language}</p> // [!code highlight:2]
          <button onClick={toggleLanguage}>Toggle Language</button>
        </div>
      );
    }
    ```

  </Step>
  <Step>
    ### Give it a try!
    You can now use the `setState` function to update the agent state and `state` to read it. Try toggling the language button
    and talking to your agent. You'll see the language change to match the agent's state.
  </Step>
</Steps>

## Advanced Usage

### Re-run the agent with a hint about what's changed

The new agent state will be used next time the agent runs.
If you want to re-run it manually, use the `run` argument on the `useCoAgent` hook.

The agent will be re-run, and it will get not only the latest updated state, but also a **hint** that can depend on the data delta between the previous and the current state.

```tsx title="ui/app/page.tsx"
import { useCoAgent } from "@copilotkit/react-core";
import { TextMessage, MessageRole } from "@copilotkit/runtime-client-gql";  // [!code highlight]

// ...

function YourMainContent() {
  const { state, setState, run } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // setup to be called when some event in the app occurs
  const toggleLanguage = () => {
    const newLanguage = state.language === "english" ? "spanish" : "english";
    setState({ language: newLanguage });

    // re-run the agent and provide a hint about what's changed
    run(({ previousState, currentState }) => { // [!code highlight:6]
      return new TextMessage({
        role: MessageRole.User,
        content: `the language has been updated to ${currentState.language}`,
      });
    });
  };

  return (
    // ...
  );
}
```

### Intermediately Stream and Render Agent State

By default, the --YOUR-FRAMEWORK-- Agent state will only update _between_ --YOUR-FRAMEWORK-- Agent node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](/--YOUR-FRAMEWORK--/shared-state/predictive-state-updates).** 


================================================
FILE: docs/content/docs/.coagents-template/shared-state/index.mdx
================================================
---
title: Shared State
description: Create a two-way connection between your UI and agent state.
icon: "lucide/Repeat"
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

<ImageZoom
  src="/images/coagents/SharedStateCoAgents.gif"
  alt="Shared State Demo"
  width={1000}
  height={1000}
  className="rounded-lg shadow-lg border mt-0"
/>

<Callout>
  This video demonstrates the [Research
  Canvas](/--YOUR-FRAMEWORK--/examples/research-canvas) utilizing shared state.
</Callout>

## What is shared state?

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:

- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

<Frame>
  <img
    src="/images/coagents/coagents-state-diagram.png"
    alt="Agentic Copilot State Diagram"
  />
</Frame>

The foundation of this system is built on --YOUR-FRAMEWORK--'s stateful architecture.

## When should I use this?

State streaming is perfect when you want to facilitate collaboration between your agent and the user. Any state that your --YOUR-FRAMEWORK-- Agent
persists will be automatically shared by the UI. Similarly, any state that the user updates in the UI will be automatically reflected

This allows for a consistent experience where both the agent and the user are on the same page. 


================================================
FILE: docs/content/docs/.coagents-template/shared-state/meta.json
================================================
{
  "pages": [
    "in-app-agent-read",
    "in-app-agent-write",
    "predictive-state-updates"
  ]
}



================================================
FILE: docs/content/docs/.coagents-template/shared-state/predictive-state-updates.mdx
================================================
---
title: "Predictive state updates"
icon: "lucide/Podcast"
description: Stream in-progress agent state updates to the frontend.
---

import {
  TailoredContent,
  TailoredContentOption,
} from "@/components/react/tailored-content.tsx";
import { CoAgentsEnterpriseCTA } from "@/components/react/coagents/coagents-enterprise-cta.tsx";
import InstallSDKSnippet from "@/snippets/install-sdk.mdx";
import { FaWrench } from "react-icons/fa";
import { FaArrowUp } from "react-icons/fa";

<video
  src="/images/coagents/intermediate-state-render.mp4"
  className="rounded-lg shadow-xl"
  loop
  playsInline
  controls
  autoPlay
  muted
/>
<Callout>
  This video shows the [coagents
  starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter---YOUR-FRAMEWORK--)
  repo with the [implementation](#implementation) section applied to it!
</Callout>

## What is this?

A --YOUR-FRAMEWORK-- Agent's state updates discontinuosly; only across function transitions in the flow.
But even a _single function_ in the flow often takes many seconds to run and contain sub-steps of interest to the user.

**Agent-native applications** reflect to the end-user what the agent is doing **as continuously possible.**

CopilotKit enables this through its concept of **_predictive state updates_**.

## When should I use this?

You can use this when you want to provide the user with feedback about what your agent is doing, specifically to:

- **Keep users engaged** by avoiding long loading indicators
- **Build trust** by demonstrating what the agent is working on
- Enable **agent steering** - allowing users to course-correct the agent if needed

## Important Note

When a function in your --YOUR-FRAMEWORK-- agent finishes executing, **its returned state becomes the single source of truth**.
While intermediate state updates are great for real-time feedback, any changes you want to persist must be explicitly
included in the function's final returned state. Otherwise, they will be overwritten when the function completes.

## Implementation

<Steps>
    <Step>
        ### Install the CopilotKit SDK
        <InstallSDKSnippet components={props.components}/>
    </Step>
    <Step>
        ### Define the state
        We'll be defining a `observed_steps` field in the state, which will be updated as the agent writes different sections of the report.

        <Tabs groupId="language" items={["Python"]}>
            <Tab value="Python">
                ```python title="agent-py/sample_agent/agent.py"
                # your code goes here...
                ```
            </Tab>
        </Tabs>
    </Step>
    <Step>
        ### Emit the intermediate state
        <TailoredContent
            className="step"
            id="state-emission"
            header={
                <div>
                    <p className="text-xl font-semibold">How would you like to emit state updates?</p>
                    <p className="text-base">
                        You can either manually emit state updates or configure specific tool calls to emit updates.
                    </p>
                </div>
            }
        >
            <TailoredContentOption
                id="manual-emission"
                title="Manual Predictive State Updates"
                description="Manually emit state updates for maximum control over when updates occur."
                icon={<FaArrowUp />}
            >
                For long-running tasks, you can emit state updates progressively as predictions of the final state. In this example, we simulate a long-running task by executing a series of steps with a one second delay between each update.
                <Tabs groupId="language" items={['Python']} default="Python">
                    <Tab value="Python">
                        ```python title="agent-py/sample_agent/agent.py"
                        # your code goes here...
                        ```
                    </Tab>
                </Tabs>
            </TailoredContentOption>

            <TailoredContentOption
                id="tool-emission"
                title="Tool-Based Predictive State Updates"
                description="Configure specific tool calls to automatically emit intermediate state updates."
                icon={<FaWrench />}
            >
                For long-running tasks, you can configure CopilotKit to automatically predict state updates when specific tool calls are made. In this example, we'll configure CopilotKit to predict state updates whenever the LLM calls the step progress tool.
                <Tabs groupId="language" items={['Python']} default="Python">
                    <Tab value="Python">
                        ```python
                        # your code goes here...
                        ```
                    </Tab>
                </Tabs>
            </TailoredContentOption>
        </TailoredContent>
    </Step>
    <Step>
        ### Observe the predictions
        These predictions will be emitted as the agent runs, allowing you to track its progress before the final state is determined.

        ```tsx title="ui/app/page.tsx"
        import { useCoAgent, useCoAgentStateRender } from '@copilotkit/react-core';

        // ...

        const YourMainContent = () => {
            // Get access to both predicted and final states
            const { state } = useCoAgent({ name: "sample_agent" });

            // Add a state renderer to observe predictions
            useCoAgentStateRender({
                name: "sample_agent",
                render: ({ state }) => {
                    if (!state.observed_steps?.length) return null;
                    return (
                        <div>
                            <h3>Current Progress:</h3>
                            <ul>
                                {state.observed_steps.map((step, i) => (
                                    <li key={i}>{step}</li>
                                ))}
                            </ul>
                        </div>
                    );
                },
            });

            return (
                <div>
                    <h1>Agent Progress</h1>
                    {state.observed_steps?.length > 0 && (
                        <div>
                            <h3>Final Steps:</h3>
                            <ul>
                                {state.observed_steps.map((step, i) => (
                                    <li key={i}>{step}</li>
                                ))}
                            </ul>
                        </div>
                    )}
                </div>
            )
        }
        ```
    </Step>
    <Step>
        ### Give it a try!
        Now you'll notice that the state predictions are emitted as the agent makes progress, giving you insight into its work before the final state is determined.
        You can apply this pattern to any long-running task in your agent.
    </Step>

</Steps> 


================================================
FILE: docs/lib/utils.ts
================================================
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}




================================================
FILE: docs/lib/hooks/use-google-analytics.tsx
================================================
"use client";

import { usePathname } from "next/navigation";
import { useEffect } from "react";
import ReactGA from "react-ga4";

export function useGoogleAnalytics() {
  const GA_ID = process.env.NEXT_PUBLIC_GOOGLE_ANALYTICS_TRACKING_ID;

  if (!GA_ID) {
    return;
  }

  const pathname = usePathname();

  useEffect(() => {
    ReactGA.initialize([{ trackingId: GA_ID }]);
  }, []);

  useEffect(() => {
    ReactGA.send({ hitType: "pageview", page: pathname });
  }, [pathname]);
}



================================================
FILE: docs/lib/hooks/use-rb2b.tsx
================================================
"use client"

import { useEffect } from "react";

export function useRB2B() {
  useEffect(() => {
    const RB2B_ID = process.env.NEXT_PUBLIC_RB2B_ID;

    if (!RB2B_ID) {
      return;
    }

    // @ts-ignore
    !(function () {
      var reb2b = ((window as any).reb2b = (window as any).reb2b || []);
      if (reb2b.invoked) return;
      reb2b.invoked = true;
      reb2b.methods = ["identify", "collect"];
      reb2b.factory = function (method: any) {
        return function () {
          var args = Array.prototype.slice.call(arguments);
          args.unshift(method);
          reb2b.push(args);
          return reb2b;
        };
      };
      for (var i = 0; i < reb2b.methods.length; i++) {
        var key = reb2b.methods[i];
        reb2b[key] = reb2b.factory(key);
      }
      reb2b.load = function (key: any) {
        var script = document.createElement("script");
        script.type = "text/javascript";
        script.async = true;
        script.src =
          "https://s3-us-west-2.amazonaws.com/b2bjsstore/b/" +
          key +
          "/reb2b.js.gz";
        var first = document.getElementsByTagName("script")[0];
        first.parentNode?.insertBefore(script, first);
      };
      reb2b.SNIPPET_VERSION = "1.0.1";
      reb2b.load(RB2B_ID);
    })();
  }, []);
}



================================================
FILE: docs/lib/hooks/use-tailored-content.tsx
================================================
import React from "react";
import { createContext, useContext, useEffect, ReactNode } from "react";
import { useLocalStorage } from "usehooks-ts";

type TailoredContentOption = string;

type TailoredContentContextType<T extends TailoredContentOption> = {
  mode: T;
  setMode: any;
};

const TailoredContentContext = createContext<
  TailoredContentContextType<TailoredContentOption> | undefined
>(undefined);

export const TailoredContentProvider = <T extends TailoredContentOption>({
  children,
}: {
  children: ReactNode;
}) => {
  const [mode, setMode] = useLocalStorage<T>(
    "copilotkit-tailored-content",
    "empty" as T
  );

  return (
    <TailoredContentContext.Provider value={{ mode, setMode }}>
      {children}
    </TailoredContentContext.Provider>
  );
};

export const useTailoredContent = <T extends TailoredContentOption>(
  options: T[],
  defaultOption: T
): TailoredContentContextType<T> => {
  const context = useContext(TailoredContentContext);
  if (context === undefined) {
    throw new Error(
      "useTailoredContent must be used within a TailoredContentProvider"
    );
  }

  useEffect(() => {
    if (!options.includes(context.mode as any)) {
      context.setMode(defaultOption);
    }
  }, [context.mode]);

  return context as TailoredContentContextType<T>;
};



================================================
FILE: docs/lib/icons/custom-icons.tsx
================================================
import { FaReact } from "react-icons/fa";
import { HiOutlineServerStack } from "react-icons/hi2";
import { LuBrush, LuZap, LuGlobe } from "react-icons/lu";
import { SiLangchain } from "react-icons/si";
import { TbBrandTypescript } from "react-icons/tb";
import { FaPython } from "react-icons/fa";
import { SiCrewai } from "@icons-pack/react-simple-icons";
import { LuLayoutTemplate } from "react-icons/lu";
import { IconBaseProps } from "react-icons";
export const AG2Icon = (props: IconBaseProps) => (
  <svg
    xmlns="http://www.w3.org/2000/svg"
    width="3em"
    height="3em"
    fill="none"
    viewBox="0 0 90 50"
    style={{ transform: "scale(1.5)" }}
    {...props}
  >
    <path
      fill="currentColor"
      d="M69.285 0h-3.232v3.232h3.232V0Zm-3.232 16.095h-3.21v6.442h3.21v-6.442Zm0-12.863h-3.21v3.21h3.21v-3.21Zm-3.21 9.652h-3.21v3.21h3.21v-3.21Zm0-6.442h-3.21v3.232h3.21V6.442Zm-3.211 3.232H53.19v3.21h6.442v-3.21ZM53.19 6.442H37.095v3.232H53.19V6.442Zm6.442 19.305v-6.42h-3.231v-3.232H33.885v3.232h-3.232v6.42h28.98Zm-9.652-6.42h3.21v3.21h-3.21v-3.21Zm-12.885 0h3.21v3.21h-3.21v-3.21Zm0-9.653h-6.442v3.21h6.442v-3.21Zm-6.442 3.21h-3.21v3.21h3.21v-3.21Zm0-6.442h-3.21v3.232h3.21V6.442Zm-3.211 9.653h-3.21v6.442h3.21v-6.442Zm0-12.863h-3.21v3.21h3.21v-3.21ZM24.232 0H21v3.232h3.232V0Z"
    />
    <path
      fill="currentColor"
      d="M65.867 37.748V34.33H55.615v-3.418h10.252v3.418h3.418v3.417h-3.418Zm-6.834 3.417v-3.417h6.834v3.417h-6.834ZM55.615 48v-6.835h3.418v3.418h10.252V48h-13.67Zm-13.89-13.67v-3.417h10.252v3.418H41.725Zm-3.417 10.253V34.33h3.417v10.252h-3.417Zm10.252 0v-3.418h-3.417v-3.417h6.834v6.835H48.56ZM41.725 48v-3.417h6.835V48h-6.835ZM21 48V34.33h3.417v-3.417h6.835v3.418h3.418V48h-3.418v-6.835h-6.835V48H21Zm3.417-10.252h6.835v-3.28h-6.835v3.28Z"
    />
  </svg>
);

export const MastraIcon = (props: IconBaseProps) => (
  <svg
    width="17"
    height="17"
    viewBox="0 0 34 34"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
  >
    <circle
      cx="16.6532"
      cy="16.9999"
      r="14.0966"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
    <ellipse
      cx="16.6533"
      cy="17"
      rx="14.0966"
      ry="9.45478"
      transform="rotate(45 16.6533 17)"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
    <path
      d="M10.8984 17.0508H22.483"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
    <path
      d="M13.748 19.9932L19.6339 14.1074"
      stroke="currentColor"
      strokeWidth="1.16026"
    />
  </svg>
);

export const customIcons = {
  react: FaReact,
  server: HiOutlineServerStack,
  zap: LuZap,
  brush: LuBrush,
  globe: LuGlobe,
  langchain: SiLangchain,
  typescript: TbBrandTypescript,
  python: FaPython,
  crewai: SiCrewai,
  component: LuLayoutTemplate,
  ag2: AG2Icon,
  mastra: MastraIcon,
};



================================================
FILE: docs/lib/icons/index.tsx
================================================
import { icons as lucideIcons } from "lucide-react";
import { createElement } from "react";
import { customIcons } from "./custom-icons";

export function icon(icon: any) {
  if (!icon) {
    return;
  }

  let iconElement: React.ReactNode = null;

  if (icon.startsWith("lucide/")) {
    const iconName = icon.split("lucide/")[1];
    if (iconName in lucideIcons)
      iconElement = createElement(
        lucideIcons[iconName as keyof typeof lucideIcons]
      );
  }

  if (icon.startsWith("custom/")) {
    const iconName = icon.split("custom/")[1];
    if (iconName in customIcons)
      iconElement = createElement(
        customIcons[iconName as keyof typeof customIcons]
      );
  }

  return (
    <div className="border border-fd-primary/10 rounded-md p-1.5 bg-gradient-to-b from-fd-muted/40 to-fd-muted/80 text-primary">
      {iconElement}
    </div>
  );
}



================================================
FILE: docs/lib/providers/posthog-provider.tsx
================================================
"use client";

import { PostHogProvider as PostHogProviderBase } from "posthog-js/react";
import posthog from "posthog-js";
import { useEffect } from "react";
import { useAuth } from "@clerk/nextjs";
import { usePathname, useSearchParams } from "next/navigation";

const POSTHOG_KEY = process.env.NEXT_PUBLIC_POSTHOG_KEY;
const POSTHOG_HOST = process.env.NEXT_PUBLIC_POSTHOG_HOST;
const isClerkEnabled = process.env.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY;

export function PostHogProvider({ children }: { children: React.ReactNode }) {
  const pathname = usePathname();
  const searchParams = useSearchParams();
  const sessionId = searchParams.get("session_id");
  const { userId } = isClerkEnabled ? useAuth() : { userId: null };

  useEffect(() => {
    if (POSTHOG_KEY && POSTHOG_HOST && !posthog?.__loaded) {
      posthog.init(POSTHOG_KEY, {
        api_host: POSTHOG_HOST,
        person_profiles: "identified_only",
        bootstrap: {
          sessionID: sessionId ?? undefined,
        },
        // Enable debug mode in development
        loaded: (posthog) => {
          if (process.env.NODE_ENV === "development") posthog.debug();
        },
      });
    }
  }, []);

  useEffect(() => {
    if (userId) {
      posthog?.identify(userId);
    }
  }, [userId]);

  useEffect(() => {
    if (POSTHOG_KEY && POSTHOG_HOST) {
      posthog?.capture("$pageview");
    }
  }, [pathname]);

  return <PostHogProviderBase client={posthog}>{children}</PostHogProviderBase>;
}



================================================
FILE: docs/lib/providers/providers-wrapper.tsx
================================================
"use client";

import React, { Suspense } from "react";
import { PostHogProvider } from "@/lib/providers/posthog-provider";
import { ClerkProvider } from "@clerk/clerk-react";
import { ScarfPixel } from "./scarf-pixel";
import { useRB2B } from "@/lib/hooks/use-rb2b";
import { useGoogleAnalytics } from "../hooks/use-google-analytics";

export function ProvidersWrapper({ children }: { children: React.ReactNode }) {
  const clerkPublishableKey = process.env.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY;

  useRB2B();
  useGoogleAnalytics();

  const toRender = (
    <Suspense fallback={null}>
      <PostHogProvider>{children}</PostHogProvider>
      <ScarfPixel />
    </Suspense>
  );

  if (clerkPublishableKey) {
    return (
      <ClerkProvider publishableKey={clerkPublishableKey}>
        {toRender}
      </ClerkProvider>
    );
  } else {
    return toRender;
  }
}



================================================
FILE: docs/lib/providers/scarf-pixel.tsx
================================================
"use client"

import React from 'react';

export function ScarfPixel() {
  const SCARF_PIXEL_ID = process.env.NEXT_PUBLIC_SCARF_PIXEL_ID;
  if (!SCARF_PIXEL_ID) return null;
  return <img referrerPolicy="no-referrer-when-downgrade" src={`https://static.scarf.sh/a.png?x-pxid=${SCARF_PIXEL_ID}`} />;
}


================================================
FILE: docs/public/llms-full.txt
================================================
# http://docs.copilotkit.ai llms-full.txt

## CopilotKit Documentation
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is CopilotKit?

# Introduction

Build production-ready Copilots and Agents effortlessly.

# [What is CopilotKit?](https://docs.copilotkit.ai/\#what-is-copilotkit)

At its core, CopilotKit is a set of tools that make it easy to **let your users work**
**alongside Large Language Models (LLMs) to accomplish generative tasks** directly in
your application. Instead of just using the LLM to generate content, you can let it
take direct action alongside your users.

Interacting with these models can be done directly ( **Standard**) or through agents ( **CoAgents**).

## [Standard](https://docs.copilotkit.ai/\#standard)

Utilize CopilotKit's standard agentic runloop to get started quickly.

[**Quickstart** \\
Get started with CopilotKit directly in your application.](https://docs.copilotkit.ai/quickstart) [**Tutorial** \\
Build an AI todo app with CopilotKit in minutes.](https://docs.copilotkit.ai/tutorials/ai-todo-app/overview)

## [CoAgents](https://docs.copilotkit.ai/\#coagents)

When you need **complete control** over the agentic runloop, you can use **CoAgents**. Bridge the remaining gap between demos and production-ready experiences.

[**LangGraph** \\
User-interactive agents with LangGraph.](https://docs.copilotkit.ai/coagents) [CrewAI\\
**CrewAI Crews** \\
Build multi-agent workflows with CrewAI.](https://docs.copilotkit.ai/crewai-crews) [CrewAI\\
**CrewAI Flows** \\
Build multi-agent workflows with CrewAI.](https://docs.copilotkit.ai/crewai-flows)

## [CopilotKit in Action](https://docs.copilotkit.ai/\#copilotkit-in-action)

Need some inspiration? Check out somethings we've built with CopilotKit.

[**Feature Viewer** \\
Learn about all of the best features CopilotKit has to offer with an interactive experience.](https://feature-viewer-langgraph.vercel.app/) [**Spreadsheet Copilot** \\
A powerful spreadsheet assistant that helps users analyze data, create formulas, and generate insights.](https://spreadsheet-demo-tau.vercel.app/) [**SaaS Copilot** \\
An AI-powered banking interface that helps users understand and interact with their finances.](https://brex-demo-temp.vercel.app/) [**Agent-Native Travel Planner** \\
Interactive travel planning assistant that helps users generate and build travel itineraries.](https://examples-coagents-ai-travel-app.vercel.app/) [**Agent-Native Research Canvas** \\
An intelligent research assistant that helps users synthesize information across multiple sources.](https://examples-coagents-research-canvas-ui.vercel.app/)

## [How does CopilotKit work?](https://docs.copilotkit.ai/\#how-does-copilotkit-work)

CopilotKit is thoughtfully architected to scale with you, your teams, and your product.

![](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Farchitecture-diagram.png&w=3840&q=75)

## [Common Questions](https://docs.copilotkit.ai/\#common-questions)

We've got answers to some common questions!

### What is a Copilot?

### What are the main features of CopilotKit?

### How does it all work?

### Can I use any LLM with CopilotKit?

[Next\\
\\
Quickstart](https://docs.copilotkit.ai/quickstart)

### On this page

[What is CopilotKit?](https://docs.copilotkit.ai/#what-is-copilotkit) [Standard](https://docs.copilotkit.ai/#standard) [CoAgents](https://docs.copilotkit.ai/#coagents) [CopilotKit in Action](https://docs.copilotkit.ai/#copilotkit-in-action) [How does CopilotKit work?](https://docs.copilotkit.ai/#how-does-copilotkit-work) [Common Questions](https://docs.copilotkit.ai/#common-questions) [Concierge](https://docs.copilotkit.ai/#concierge) [Worker](https://docs.copilotkit.ai/#worker) [Batteries included chat components](https://docs.copilotkit.ai/#batteries-included-chat-components) [Deeply integrated Copilots](https://docs.copilotkit.ai/#deeply-integrated-copilots) [Rich agentic experiences](https://docs.copilotkit.ai/#rich-agentic-experiences)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Copilot Infrastructure Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCopilot Infrastructure for LangGraph Agents

# Introduction

Build Agent-Native Applications (ANAs) powered by CopilotKit and LangGraph.

# [Copilot Infrastructure for LangGraph Agents](https://docs.copilotkit.ai/coagents\#copilot-infrastructure-for-langgraph-agents)

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).

![CoAgents demonstration](https://docs.copilotkit.ai/images/CoAgents.gif)

## [Building blocks of a CoAgent](https://docs.copilotkit.ai/coagents\#building-blocks-of-a-coagent)

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

[Agentic Chat UI\\
\\
In-app chat powered by your agent.](https://docs.copilotkit.ai/coagents/agentic-chat-ui)

[Shared State\\
\\
Your agent can see everything in your app, and vice versa.](https://docs.copilotkit.ai/coagents/shared-state)

[Generative UI\\
\\
UI that updates in real-time based on your agent's state.](https://docs.copilotkit.ai/coagents/generative-ui)

[Frontend Tools\\
\\
Give your agent the ability to take action in your application.](https://docs.copilotkit.ai/coagents/frontend-actions)

[Multi-Agent Coordination\\
\\
Route your agent to the right agent based on the user's request.](https://docs.copilotkit.ai/coagents/multi-agent-flows)

[Human-in-the-Loop\\
\\
Set smart checkpoints where humans can guide your agents.](https://docs.copilotkit.ai/coagents/human-in-the-loop)

## [CoAgents in action](https://docs.copilotkit.ai/coagents\#coagents-in-action)

See **CoAgents** in action with some videos and examples we've made to demonstrate their power.

IntroductionAgent-Native Travel Planner (ANA)Agent-Native Research Canvas (ANA)

Introduction

[Demo](https://examples-coagents-research-canvas-ui.vercel.app/)

Hear from the CEO of CopilotKit, Atai Barkai, and learn how CoAgents are paving the way for the next generation of AI-native apps.

CoAgents Public Beta - YouTube

CopilotKit

1.27K subscribers

[CoAgents Public Beta](https://www.youtube.com/watch?v=tVjVYJE-Nic)

CopilotKit

Search

Watch later

Share

Copy link

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

More videos

## More videos

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

[Watch on](https://www.youtube.com/watch?v=tVjVYJE-Nic&embeds_referring_euri=https%3A%2F%2Fdocs.copilotkit.ai%2F&embeds_referring_origin=https%3A%2F%2Fdocs.copilotkit.ai)

0:00

0:00 / 1:48•Live

•

[Watch on YouTube](https://www.youtube.com/watch?v=tVjVYJE-Nic "Watch on YouTube")

## [Ready to get started?](https://docs.copilotkit.ai/coagents\#ready-to-get-started)

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

[Quickstart\\
\\
Learn how to build your first CoAgent in 10 minutes.](https://docs.copilotkit.ai/coagents/quickstart/langgraph)

[Travel Agent\\
\\
Learn how to build an agent-native travel app with CopilotKit & LangGraph.](https://docs.copilotkit.ai/coagents/tutorials/ai-travel-app)

[Researcher Agent\\
\\
Learn how to build an agent-native researcher with CopilotKit & LangGraph.](https://docs.copilotkit.ai/coagents/videos/research-canvas)

## [Common Questions](https://docs.copilotkit.ai/coagents\#common-questions)

Have a question about CoAgents? You're in the right place!

### Can you explain what a CoAgent is in more detail?

### Can I attach to an existing thread?

### Can I use CopilotKit without LangGraph?

[Next\\
\\
Quickstart (LangGraph)](https://docs.copilotkit.ai/coagents/quickstart/langgraph)

### On this page

[Copilot Infrastructure for LangGraph Agents](https://docs.copilotkit.ai/coagents#copilot-infrastructure-for-langgraph-agents) [Building blocks of a CoAgent](https://docs.copilotkit.ai/coagents#building-blocks-of-a-coagent) [CoAgents in action](https://docs.copilotkit.ai/coagents#coagents-in-action) [Ready to get started?](https://docs.copilotkit.ai/coagents#ready-to-get-started) [Common Questions](https://docs.copilotkit.ai/coagents#common-questions)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit API Reference
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# API Reference

API Reference for CopilotKit's components, classes and hooks.

[**UI Components** \\
See the list of all available UI components in CopilotKit.](https://docs.copilotkit.ai/reference/components/chat/CopilotChat) [**Hooks** \\
See the list of all available hooks in CopilotKit.](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable) [**Classes** \\
See the list of all available classes in CopilotKit.](https://docs.copilotkit.ai/reference/classes/CopilotRuntime) [**LLM Adapters** \\
See the list of all available LLM Adapters in CopilotKit.](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter) [**SDKs** \\
Python and JavaScript SDKs for CopilotKit.](https://docs.copilotkit.ai/reference/sdk/python/LangGraph)

[Next\\
\\
All Chat Components](https://docs.copilotkit.ai/reference/components/chat)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Copilot Infrastructure Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCopilot Infrastructure for CrewAI Flows

# Introduction

Build Agent-Native Applications (ANAs) powered by CopilotKit and CrewAI Flows.

# [Copilot Infrastructure for CrewAI Flows](https://docs.copilotkit.ai/crewai-flows\#copilot-infrastructure-for-crewai-flows)

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).

## [Building blocks of a CoAgent](https://docs.copilotkit.ai/crewai-flows\#building-blocks-of-a-coagent)

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

[Agentic Chat UI\\
\\
In-app chat powered by your agent.](https://docs.copilotkit.ai/crewai-flows/agentic-chat-ui)

[Shared State\\
\\
Your agent can see everything in your app, and vice versa.](https://docs.copilotkit.ai/crewai-flows/shared-state)

[Generative UI\\
\\
UI that updates in real-time based on your agent's state.](https://docs.copilotkit.ai/crewai-flows/generative-ui)

[Frontend Tools\\
\\
Give your agent the ability to take action in your application.](https://docs.copilotkit.ai/crewai-flows/frontend-actions)

[Multi-Agent Coordination\\
\\
Route your agent to the right agent based on the user's request.](https://docs.copilotkit.ai/crewai-flows/multi-agent-flows)

[Human-in-the-Loop\\
\\
Set smart checkpoints where humans can guide your agents.](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop)

## [Ready to get started?](https://docs.copilotkit.ai/crewai-flows\#ready-to-get-started)

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

[Quickstart\\
\\
Learn how to build your first CoAgent in 10 minutes.](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai)

## [Common Questions](https://docs.copilotkit.ai/crewai-flows\#common-questions)

Have a question about CoAgents? You're in the right place!

### Can you explain what a CoAgent is in more detail?

### Can I attach to an existing thread?

[Next\\
\\
Quickstart CrewAI Flows](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai)

### On this page

[Copilot Infrastructure for CrewAI Flows](https://docs.copilotkit.ai/crewai-flows#copilot-infrastructure-for-crewai-flows) [Building blocks of a CoAgent](https://docs.copilotkit.ai/crewai-flows#building-blocks-of-a-coagent) [Ready to get started?](https://docs.copilotkit.ai/crewai-flows#ready-to-get-started) [Common Questions](https://docs.copilotkit.ai/crewai-flows#common-questions)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-flows/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagePrerequisites

# Quickstart (LangGraph)

Turn your LangGraph into an agent-native application in 10 minutes.

## [Prerequisites](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#prerequisites)

Before you begin, you'll need the following:

- [**LangSmith API key**](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key#api-keys)
- [**OpenAI API key**](https://platform.openai.com/api-keys)

## [Getting started](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#getting-started)

### [Install CopilotKit](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#install-copilotkit)

First, install the latest packages for CopilotKit into your frontend.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

Do you already have a LangGraph agent?

You will need a LangGraph agent to get started with CoAgents!

Either bring your own or feel free to use our starter repo.

Bring your own LangGraph agent

I already have a LangGraph agent and want to use it with CopilotKit.

![CopilotKit Logo](https://docs.copilotkit.ai/images/copilotkit-logo.svg)

Use the CoAgents Starter repo

I don't have a LangGraph agent yet, but want to get started quickly.

### [Start your LangGraph Agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#start-your-langgraph-agent)

Local (LangGraph Studio)Self hosted (FastAPI)LangGraph Platform

For local development, you can use the [LangGraph CLI](https://langchain-ai.github.io/langgraph/cloud/reference/cli/) to start a development server and LangGraph studio session.

You will need a [LangSmith account](https://smith.langchain.com/) to use this method.

```
# For Python 3.11 or above
langgraph dev --host localhost --port 8000
```

```
# For TypeScript with Node 18 or above
npx @langchain/langgraph-cli dev --host localhost --port 8000
```

After starting the LangGraph server, the deployment URL will be `http://localhost:8000`.

### Having trouble?

Choose your connection method

Now you need to connect your LangGraph agent to CopilotKit.

Copilot Cloud (Recommended)

I want to host my Copilot on Copilot Cloud

Self-Hosted Copilot Runtime

I want to self-host the Copilot Runtime

### [Add a remote endpoint for your LangGraph agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#add-a-remote-endpoint-for-your-langgraph-agent)

Using Copilot Cloud, you need to connect a remote endpoint that will connect to your LangGraph agent.

Local (LangGraph Studio)Self hosted (FastAPI)LangGraph Platform

When running your LangGraph agent locally, you can open a tunnel to it so Copilot Cloud can connect to it.
First, make sure you're logged in to [Copilot Cloud](https://cloud.copilotkit.ai/), and then authenticate the CLI by running:

```
npx copilotkit@latest login
```

Once authenticated, run:

```
npx copilotkit@latest dev --port 8000
```

### [Setup your CopilotKit provider](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#setup-your-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

Since we're using Copilot CLoud, we need to grab our public API key from the [Copilot Cloud dashboard](https://cloud.copilotkit.ai/).

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit
          publicApiKey="<your-copilot-cloud-public-api-key>"
          agent="sample_agent" // the name of the agent you want to use
        >
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

Looking for a way to run multiple LangGraph agents? Check out our [Multi-Agent](https://docs.copilotkit.ai/coagents/multi-agent-flows) guide.

## [Choose a Copilot UI](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#choose-a-copilot-ui)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

`CopilotPopup` is a convenience wrapper for `CopilotChat` that lives at the same level as your main content in the view hierarchy. It provides **a floating chat interface** that can be toggled on and off.

![Popup Example](https://docs.copilotkit.ai/images/popup-example.gif)

```
import { CopilotPopup } from "@copilotkit/react-ui";

export function YourApp() {
  return (
    <>
      <YourMainContent />
      <CopilotPopup
        instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
        labels={{
          title: "Popup Assistant",
          initial: "Need any help?",
        }}
      />
    </>
  );
}
```

### [🎉 Talk to your agent!](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#-talk-to-your-agent)

Congrats! You've successfully integrated a LangGraph agent chatbot to your application. To start, try asking a few questions to your agent.

```
Can you tell me a joke?
```

```
Can you help me understand AI?
```

```
What do you think about React?
```

### Having trouble?

* * *

## [What's next?](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#whats-next)

You've now got a LangGraph agent running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

[**Implement Human in the Loop** \\
Allow your users and agents to collaborate together on tasks.](https://docs.copilotkit.ai/coagents/human-in-the-loop) [**Utilize the Shared State** \\
Learn how to synchronize your agent's state with your UI's state, and vice versa.](https://docs.copilotkit.ai/coagents/shared-state) [**Add some generative UI** \\
Render your agent's progress and output in the UI.](https://docs.copilotkit.ai/coagents/generative-ui) [**Setup frontend actions** \\
Give your agent the ability to call frontend tools, directly updating your application.](https://docs.copilotkit.ai/coagents/frontend-actions)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/coagents) [Next\\
\\
Chat with an Agent](https://docs.copilotkit.ai/coagents/agentic-chat-ui)

### On this page

[Prerequisites](https://docs.copilotkit.ai/coagents/quickstart/langgraph#prerequisites) [Getting started](https://docs.copilotkit.ai/coagents/quickstart/langgraph#getting-started) [Install CopilotKit](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-copilotkit) [Clone the coagents-starter repo and install dependencies:](https://docs.copilotkit.ai/coagents/quickstart/langgraph#clone-the-coagents-starter-repo-and-install-dependencies) [Install dependencies:](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-dependencies) [Install dependencies:](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-dependencies-1) [Create a .env file](https://docs.copilotkit.ai/coagents/quickstart/langgraph#create-a-env-file) [Add your API keys](https://docs.copilotkit.ai/coagents/quickstart/langgraph#add-your-api-keys) [Start your LangGraph Agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph#start-your-langgraph-agent) [Add a remote endpoint for your LangGraph agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph#add-a-remote-endpoint-for-your-langgraph-agent) [Setup your CopilotKit provider](https://docs.copilotkit.ai/coagents/quickstart/langgraph#setup-your-copilotkit-provider) [Install Copilot Runtime](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-copilot-runtime) [Setup a Copilot Runtime Endpoint](https://docs.copilotkit.ai/coagents/quickstart/langgraph#setup-a-copilot-runtime-endpoint) [Add your LangGraph deployment to Copilot Runtime](https://docs.copilotkit.ai/coagents/quickstart/langgraph#add-your-langgraph-deployment-to-copilot-runtime) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/coagents/quickstart/langgraph#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/coagents/quickstart/langgraph#choose-a-copilot-ui) [🎉 Talk to your agent!](https://docs.copilotkit.ai/coagents/quickstart/langgraph#-talk-to-your-agent) [What's next?](https://docs.copilotkit.ai/coagents/quickstart/langgraph#whats-next)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/quickstart/langgraph.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAI Support
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCopilot Infrastructure for CrewAI Crews

# Introduction

Build Agent-Native Applications (ANAs) powered by CopilotKit and CrewAI Flows.

# [Copilot Infrastructure for CrewAI Crews](https://docs.copilotkit.ai/crewai-crews\#copilot-infrastructure-for-crewai-crews)

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).

## [Building blocks of a CoAgent](https://docs.copilotkit.ai/crewai-crews\#building-blocks-of-a-coagent)

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

[Agentic Chat UI\\
\\
In-app chat powered by your agent.](https://docs.copilotkit.ai/crewai-crews/agentic-chat-ui)

[Shared State\\
\\
Your agent can see everything in your app, and vice versa.](https://docs.copilotkit.ai/crewai-crews/shared-state)

[Generative UI\\
\\
UI that updates in real-time based on your agent's state.](https://docs.copilotkit.ai/crewai-crews/generative-ui)

[Frontend Tools\\
\\
Give your agent the ability to take action in your application.](https://docs.copilotkit.ai/crewai-crews/frontend-actions)

[Multi-Agent Coordination\\
\\
Route your agent to the right agent based on the user's request.](https://docs.copilotkit.ai/crewai-crews/multi-agent-flows)

[Human-in-the-Loop\\
\\
Set smart checkpoints where humans can guide your agents.](https://docs.copilotkit.ai/crewai-crews/human-in-the-loop)

## [Ready to get started?](https://docs.copilotkit.ai/crewai-crews\#ready-to-get-started)

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

[Quickstart\\
\\
Learn how to build your first CoAgent in 10 minutes.](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai)

## [Common Questions](https://docs.copilotkit.ai/crewai-crews\#common-questions)

Have a question about CoAgents? You're in the right place!

### Can you explain what a CoAgent is in more detail?

[Next\\
\\
Quickstart CrewAI Crews](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai)

### On this page

[Copilot Infrastructure for CrewAI Crews](https://docs.copilotkit.ai/crewai-crews#copilot-infrastructure-for-crewai-crews) [Building blocks of a CoAgent](https://docs.copilotkit.ai/crewai-crews#building-blocks-of-a-coagent) [Ready to get started?](https://docs.copilotkit.ai/crewai-crews#ready-to-get-started) [Common Questions](https://docs.copilotkit.ai/crewai-crews#common-questions)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-crews/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Self-Hosting Copilot Runtime
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageIntegration

# Self Hosting (Copilot Runtime)

Learn how to self-host the Copilot Runtime.

The Copilot Runtime is the back-end component of CopilotKit, handling the communication with LLM, message history, state and more.

You may choose to self-host the Copilot Runtime, or [use Copilot Cloud](https://cloud.copilotkit.ai/) (recommended).

## [Integration](https://docs.copilotkit.ai/guides/self-hosting\#integration)

### [Step 1: Create an Endpoint](https://docs.copilotkit.ai/guides/self-hosting\#step-1-create-an-endpoint)

##### Choose your provider:

![OpenAI logo](https://docs.copilotkit.ai/icons/openai.png)OpenAI

If you are planning to use a single LangGraph agent in [agent-lock mode](https://docs.copilotkit.ai/coagents/multi-agent-flows) as your agentic backend, your LLM adapter will only be used for peripherals such as suggestions, etc.

If you are not sure yet, simply ignore this note.

### [Add your API key](https://docs.copilotkit.ai/guides/self-hosting\#add-your-api-key)

Next, add your API key to your `.env` file in the root of your project (unless you prefer to provide it directly to the client):

.env

```
OPENAI_API_KEY=your_api_key_here
```

Please note that the code below uses GPT-4o, which requires a paid OpenAI API key. **If you are using a free OpenAI API key**, change the model to a different option such as `gpt-3.5-turbo`.

### [Setup the Runtime Endpoint](https://docs.copilotkit.ai/guides/self-hosting\#setup-the-runtime-endpoint)

### [Serverless Function Timeouts](https://docs.copilotkit.ai/guides/self-hosting\#serverless-function-timeouts)

When deploying to serverless platforms (Vercel, AWS Lambda, etc.), be aware that default function timeouts may be too short for CopilotKit's streaming responses:

- Vercel defaults: 10s (Hobby), 15s (Pro)
- AWS Lambda default: 3s

**Solution options:**

1. Increase function timeout:








```
// vercel.json
{
     "functions": {
       "api/copilotkit/**/*": {
         "maxDuration": 60
       }
     }
}
```

2. Use [Copilot Cloud](https://cloud.copilotkit.ai/) to avoid timeout issues entirely

Next.js App RouterNext.js Pages RouterNode.js ExpressNode.js HTTPNestJS

Create a new route to handle the `/api/copilotkit` endpoint.

app/api/copilotkit/route.ts

```
import {
  CopilotRuntime,
  OpenAIAdapter,
  copilotRuntimeNextJSAppRouterEndpoint,
} from '@copilotkit/runtime';

import { NextRequest } from 'next/server';


const serviceAdapter = new OpenAIAdapter();
const runtime = new CopilotRuntime();

export const POST = async (req: NextRequest) => {
  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
    runtime,
    serviceAdapter,
    endpoint: '/api/copilotkit',
  });

  return handleRequest(req);
};
```

Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.

### [Step 2: Configure the `<CopilotKit>` Provider](https://docs.copilotkit.ai/guides/self-hosting\#step-2-configure-the-copilotkit-provider)

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Make sure to use the URL you configured in the previous step  */}
        <CopilotKit runtimeUrl="/api/copilotkit">
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

## [Next Steps](https://docs.copilotkit.ai/guides/self-hosting\#next-steps)

- [`CopilotRuntime` Reference](https://docs.copilotkit.ai/reference/classes/CopilotRuntime)
- [LLM Adapters](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter)

[Previous\\
\\
Copilot Textarea](https://docs.copilotkit.ai/guides/copilot-textarea) [Next\\
\\
Saving and restoring messages](https://docs.copilotkit.ai/guides/messages-localstorage)

### On this page

[Integration](https://docs.copilotkit.ai/guides/self-hosting#integration) [Step 1: Create an Endpoint](https://docs.copilotkit.ai/guides/self-hosting#step-1-create-an-endpoint) [Step 2: Configure the <CopilotKit> Provider](https://docs.copilotkit.ai/guides/self-hosting#step-2-configure-the-copilotkit-provider) [Next Steps](https://docs.copilotkit.ai/guides/self-hosting#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/self-hosting.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## useCopilotAction Hook
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useCopilotAction

The useCopilotAction hook allows your copilot to take action in the app.

![](https://docs.copilotkit.ai/images/use-copilot-action/useCopilotAction.gif)

`useCopilotAction` is a React hook that you can use in your application to provide
custom actions that can be called by the AI. Essentially, it allows the Copilot to
execute these actions contextually during a chat, based on the user’s interactions
and needs.

Here's how it works:

Use `useCopilotAction` to set up actions that the Copilot can call. To provide
more context to the Copilot, you can provide it with a `description` (for example to explain
what the action does, under which conditions it can be called, etc.).

Then you define the parameters of the action, which can be simple, e.g. primitives like strings or numbers,
or complex, e.g. objects or arrays.

Finally, you provide a `handler` function that receives the parameters and returns a result.
CopilotKit takes care of automatically inferring the parameter types, so you get type safety
and autocompletion for free.

To render a custom UI for the action, you can provide a `render()` function. This function
lets you render a custom component or return a string to display.

## [Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotAction\#usage)

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotAction\#simple-usage)

```
useCopilotAction({
  name: "sayHello",
  description: "Say hello to someone.",
  parameters: [\
    {\
      name: "name",\
      type: "string",\
      description: "name of the person to say greet",\
    },\
  ],
  handler: async ({ name }) => {
    alert(`Hello, ${name}!`);
  },
});
```

## [Generative UI](https://docs.copilotkit.ai/reference/hooks/useCopilotAction\#generative-ui)

This hooks enables you to dynamically generate UI elements and render them in the copilot chat. For more information, check out the [Generative UI](https://docs.copilotkit.ai/guides/generative-ui) page.

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotAction\#parameters)

actionActionrequired

The function made available to the Copilot. See [Action](https://docs.copilotkit.ai/reference/hooks/useCopilotAction#action).

namestringrequired

The name of the action.

handler(args) => Promise<any>required

The handler of the action.

descriptionstring

A description of the action. This is used to instruct the Copilot on how to
use the action.

available'enabled' \| 'disabled' \| 'remote'

Use this property to control when the action is available to the Copilot. When set to `"remote"`, the action is
available only for remote agents.

followUpboolean

Default:"true"

Whether to report the result of a function call to the LLM which will then provide a follow-up response. Pass `false` to disable

parametersParameter\[\]

The parameters of the action. See [Parameter](https://docs.copilotkit.ai/reference/hooks/useCopilotAction#parameter).

namestringrequired

The name of the parameter.

typestringrequired

The type of the argument. One of:

- `"string"`
- `"number"`
- `"boolean"`
- `"object"`
- `"object[]"`
- `"string[]"`
- `"number[]"`
- `"boolean[]"`

descriptionstring

A description of the argument. This is used to instruct the Copilot on what
this argument is used for.

enumstring\[\]

For string arguments, you can provide an array of possible values.

requiredboolean

Whether or not the argument is required. Defaults to true.

attributes

If the argument is of a complex type, i.e. `object` or `object[]`, this field
lets you define the attributes of the object. For example:

```
{
  name: "addresses",
  description: "The addresses extracted from the text.",
  type: "object[]",
  attributes: [\
    {\
      name: "street",\
      type: "string",\
      description: "The street of the address.",\
    },\
    {\
      name: "city",\
      type: "string",\
      description: "The city of the address.",\
    },\
    // ...\
  ],
}
```

renderstring \| (props: ActionRenderProps<T>) => string

Render lets you define a custom component or string to render instead of the
default. You can either pass in a string or a function that takes the following props:

status'inProgress' \| 'executing' \| 'complete'

- `"inProgress"`: arguments are dynamically streamed to the function, allowing you to adjust your UI in real-time.
- `"executing"`: The action handler is executing.
- `"complete"`: The action handler has completed execution.

argsT

The arguments passed to the action in real time. When the status is `"inProgress"`, they are
possibly incomplete.

resultany

The result returned by the action. It is only available when the status is `"complete"`.

renderAndWaitForResponse(props: ActionRenderPropsWait<T>) => React.ReactElement

This is similar to `render`, but provides a `respond` function in the props that you must call with the user's response. The component will remain rendered until `respond` is called. The response will be passed as the result to the action handler.

status'inProgress' \| 'executing' \| 'complete'

- `"inProgress"`: arguments are dynamically streamed to the function, allowing you to adjust your UI in real-time.
- `"executing"`: The action handler is executing.
- `"complete"`: The action handler has completed execution.

argsT

The arguments passed to the action in real time. When the status is `"inProgress"`, they are
possibly incomplete.

respond(result: any) => void

A function that must be called with the user's response. The response will be passed as the result to the action handler.
Only available when status is `"executing"`.

resultany

The result returned by the action. It is only available when the status is `"complete"`.

dependenciesany\[\]

An optional array of dependencies.

[Previous\\
\\
useCopilotReadable](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable) [Next\\
\\
useCopilotAdditionalInstructions](https://docs.copilotkit.ai/reference/hooks/useCopilotAdditionalInstructions)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotAction#usage) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotAction#simple-usage) [Generative UI](https://docs.copilotkit.ai/reference/hooks/useCopilotAction#generative-ui) [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotAction#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useCopilotAction.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## State Machine Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageOverview

# State Machines

Learn how to guide users through multi-step conversations using a state machine pattern.

## [Overview](https://docs.copilotkit.ai/cookbook/state-machine\#overview)

When building chat-based applications, you often need to guide users through a series of steps or **stages**. This recipe shows how to implement a state machine pattern to keep your assistant focused and on-track.

- Live Example: [https://state-machine-copilot.vercel.app/](https://state-machine-copilot.vercel.app/)
- Example Source Code: [https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine)

This recipe assumes you have completed the [quickstart guide](https://docs.copilotkit.ai/quickstart) and have a basic CopilotKit application running.

### [What is a State Machine?](https://docs.copilotkit.ai/cookbook/state-machine\#what-is-a-state-machine)

A state machine is a model where your application can be in exactly one state at a time, with clear rules about how to move between states. For chat applications, this means:

- The assistant knows exactly what stage of the conversation it's in
- Only certain actions are available in each stage
- There are clear rules for moving to the next stage

### [State Machines in CopilotKit](https://docs.copilotkit.ai/cookbook/state-machine\#state-machines-in-copilotkit)

When implementing a state machine in CopilotKit, the main piece that enables this pattern is the `available` prop present in
most of our hooks. This prop will allow you conditionally control what instructions, context, and actions are available to
the assistant.

In this recipe, we combine the `available` prop with React state to control when each stage is active, sometimes through
standard deterministic update (button clicks), and sometimes through LLM-driven actions.

![State Machine Architecture](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Fstate-machine-arch.png&w=3840&q=75)

## [Basic Implementation](https://docs.copilotkit.ai/cookbook/state-machine\#basic-implementation)

### [Create a stage](https://docs.copilotkit.ai/cookbook/state-machine\#create-a-stage)

Each stage is composed of stage-specific instructions, context, and actions. These are enabled or disabled
as the stage changes via the `available` prop. In this example of a stage, we are extracting a user's name
and ensuring it is not in a list of other names.

```
import {
  useCopilotAdditionalInstructions,
  useCopilotAction,
  useCopilotReadable
} from "@copilotkit/react-core";

// ...

/*
 * Not required, but it is convenient to use a dedicated hook to define each
 * stage of the state machine
 */
function useStageOne(
  stage: string,
  setStage: (stage: string) => void,
  setName: (name: string) => void
) {

  /*
   * Each stage can define its own instructions, context, and transitions
   * (implemented via copilotActions). We transition between stages by simply
   * setting the `stage` variable from the handler of the transition:
   */

  // Add additional instructions to the system prompt if this stage is active
  useCopilotAdditionalInstructions({
    instructions: "Ask for the user's name politely.",
    // Use "available" argument to enable this only when the stage is correct!
    available: stage === "one" ? "available" : "disabled"
  })

  // Add context to the system prompt if this stage is active
  useCopilotReadable({
    description: "Other names",
    value: ["John", "Jane", "Jim"],
    available: stage === "one" ? "available" : "disabled"
  })

  // Add an action to the assistant that transitions to the next stage if this stage is active
  useCopilotAction({
    name: "transitionToNextStage",
    description: "Moves to the next stage, only call is the user's name is not in the list of other names",
    available: stage === "one" ? "available" : "disabled",
    parameters: [\
      { name: "name", type: "string", description: "The name of the user", required: true },\
    ],
    handler: ({ name }) => {
      // Perform any state updates given the user's input
      setName(name);

      // Transition to the next stage
      setStage("two");
    }
  });
}
```

### [Create another stage](https://docs.copilotkit.ai/cookbook/state-machine\#create-another-stage)

Now, let's create a second stage that's simple and just greets the user by name as a pirate. This is mainly just to
demonstrate how to add any additional stages. The name will be made available to this stage in the next step.

```
import { useCopilotAdditionalInstructions } from "@copilotkit/react-core";

// ...

function useStageTwo(stage: string) => void) {
  // Add stage-specific instructions - only available in stage "two"
  useCopilotAdditionalInstructions({
    instructions: "Talk to the user about their name and refer to them like a pirate would.",
    available: stage === "two" ? "available" : "disabled"
  })

  // ...
}

// Any additional stages you want to add...
```

### [Put it all together](https://docs.copilotkit.ai/cookbook/state-machine\#put-it-all-together)

Finally, bring everything together into a chat component:

```
import { useState } from "react";
import { CopilotKit, useCopilotReadable } from "@copilotkit/react-core";
import { CopilotChat } from "@copilotkit/react-ui";

// ...

function StateMachineChat() {
  // Track the current stage and user's name
  const [stage, setStage] = useState<string>("one");
  const [name, setName] = useState<string>("");

  // Readable context available across all stages
  useCopilotReadable({
    description: "User's name",
    value: name,
  }, [name])

  // Initialize all stages with their required props
  useStageOne(stage, setStage, setName);
  useStageTwo(stage);
  // any additional stages...

  return (
    <CopilotKit>
      <CopilotChat/>
    </CopilotKit>
  )
}
```

### Full example code

### [🎉 You've implemented a state machine!](https://docs.copilotkit.ai/cookbook/state-machine\#-youve-implemented-a-state-machine)

To recap, each stage hook uses the `available` prop to control when its instructions, context, and actions are accessible to the assistant. This ensures that the assistant only uses the correct tools and context for the current stage.

Next, let's see some advanced patterns you can implement with these fundamentals.

## [Advanced Patterns](https://docs.copilotkit.ai/cookbook/state-machine\#advanced-patterns)

This state machine pattern can be extended for complex interactions. Below are some advanced patterns you can implement with code sourced in our
[car sales example](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine) which you already saw a demo of in the [overview](https://docs.copilotkit.ai/cookbook/state-machine#overview).

### [Stage Transition Approaches](https://docs.copilotkit.ai/cookbook/state-machine\#stage-transition-approaches)

#### [Code-driven Stage Transitions](https://docs.copilotkit.ai/cookbook/state-machine\#code-driven-stage-transitions)

When you want to transition between stages, you can do so by setting the `stage` deterministically, at any point in code.

```
const [stage, setStage] = useState<string>("one");

// ...

<button onClick={() => setStage("two")}>
  Transition to next stage
</button>
```

The car sales demo uses this approach in generative UI (for more on generative UI, see the [section below](https://docs.copilotkit.ai/cookbook/state-machine#generative-ui)) to transition between stages
when a user submits their contact information.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-get-contact-info.tsx)

src/lib/stages/use-stage-get-contact-info.tsx

```
// imports ...

export function useStageGetContactInfo() {
  const { setContactInfo, stage, setStage } = useGlobalState();

  // ...

  // Render the ContactInfo component and wait for the user's response.
  useCopilotAction(
    {
      name: "getContactInformation",
      description: "Get the contact information of the user",
      available: stage === "getContactInfo" ? "enabled" : "disabled",
      renderAndWaitForResponse: ({ status, respond }) => {
        return (
          <ContactInfo
            status={status}

            onSubmit={(name, email, phone) => {
              // Commit the contact information to the global state.
              setContactInfo({ name, email, phone });

              // Let the agent know that the user has submitted their contact information.
              respond?.("User has submitted their contact information.");

              // This move the state machine to the next stage, buildCar deterministically.
              setStage("buildCar");
            }}
          />
        );
      },
    },
    [stage],
  );
}
```

#### [LLM-Driven Stage Transitions](https://docs.copilotkit.ai/cookbook/state-machine\#llm-driven-stage-transitions)

Sometimes you need stages that can transition to different next stages based on user input or LLM-driven actions.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-sell-financing.tsx)

src/lib/stages/use-stage-sell-financing.tsx

```
function useStageSellFinancing() {
  const { stage, setStage } = useGlobalState();
  const isActive = stage === "sellFinancing";

  // Provide context to the AI
  useCopilotReadable({
    description: "Financing Information",
    value: "Current promotion: 0% financing for 60 months...",
    available: isActive ? "enabled" : "disabled"
  });

  // Different paths based on financing choice by user, LLM will decide which path to take

  useCopilotAction({
    name: "selectFinancing",
    description: "Select the financing option",
    available: stage === "sellFinancing" ? "enabled" : "disabled",
    handler: () => setStage("getFinancingInfo"),
  }, [stage]);

  useCopilotAction({
    name: "selectNoFinancing",
    description: "Select the no financing option",
    available: stage === "sellFinancing" ? "enabled" : "disabled",
    handler: () => setStage("getPaymentInfo"),
  }, [stage]);

}
```

### [Generative UI](https://docs.copilotkit.ai/cookbook/state-machine\#generative-ui)

[Generative UI](https://docs.copilotkit.ai/guides/generative-ui) is a pattern where tool calls are streamed and rendered for the user to visualize the progress an agent is making. It can also be combined with the **Human-in-the-loop pattern** to allow checkpoints where the user can intervene and help guide the agent.

When combined with the state machine pattern, you can build deep and interactive conversations with the user. For example, the `buildCar` stage in the car sales demo
uses generative UI to show the user available cars that they can choose from.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-build-car.tsx)

Build Car StageShow Car Component

src/lib/stages/use-stage-build-car.tsx

```
export function useStageBuildCar() {
  const { setSelectedCar, stage, setStage } = useGlobalState();

  // ...

  useCopilotAction({
    name: "showCar",
    description: "Show a single car that you have in mind. Do not call this more than once, call `showMultipleCars` if you have multiple cars to show.",
    available: stage === "buildCar" ? "enabled" : "disabled",
    parameters: [\
      // excluded for brevity, see source code link above for more detail\
    ],
    renderAndWaitForResponse: ({ args, status, respond }) => {
      const { car } = args;
      return (

        <ShowCar
          car={(car as Car) || ({} as Car)}
          status={status}
          onSelect={() => {
            setSelectedCar((car as Car) || ({} as Car));
            respond?.("User has selected a car you can see it in your readables, the system will now move to the next state, do not call call nextState.");
            setStage("sellFinancing");
          }}
          onReject={() => respond?.("User wants to select a different car, please stay in this state and help them select a different car")}
        />
      );
    },
  }, [stage]);
  // ...
}
```

### [Initial message loading](https://docs.copilotkit.ai/cookbook/state-machine\#initial-message-loading)

To add an initial message to the chat, we can use the `appendMessage` function provided by the `useCopilotChat` hook.

Improved experience coming soon

This is a temporary solution and we will be improving this in the near future.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/components/car-sales-chat.tsx)

src/components/car-sales-chat.tsx

```
import { useCopilotChat } from "@copilotkit/react-core";

// ...

const { appendMessage, isLoading } = useCopilotChat();

// Render an initial message when the chat is first loaded
useEffect(() => {
  if (initialMessageSent || isLoading) return;

  setTimeout(() => {
    appendMessage(
      new TextMessage({
        content:
          "Hi, I'm Fio, your AI car salesman. First, let's get your contact information before we get started.",
        role: MessageRole.Assistant,
      }),
    );
    setInitialMessageSent(true);
  }, 500);
}, [initialMessageSent, appendMessage, isLoading]);

// ...
```

### [Tools When Entering a Stage](https://docs.copilotkit.ai/cookbook/state-machine\#tools-when-entering-a-stage)

Sometimes you'll want to guide the AI to call a specific tool when entering a stage.

The payment info stage demonstrates how to guide the AI to make specific tool calls by
adding additional instructions to call the `getPaymentInformation` tool explicitly.

Click here for the [source code](https://github.com/CopilotKit/CopilotKit/tree/main/examples/copilot-state-machine/src/lib/stages/use-stage-get-payment-info.tsx)

src/lib/stages/use-stage-get-payment-info.tsx

```
export function useStageGetPaymentInfo() {
  const { setCardInfo, stage, setStage } = useGlobalState();

  // Conditionally add additional instructions for the agent's prompt.
  useCopilotAdditionalInstructions({
    available: stage === "getPaymentInfo" ? "enabled" : "disabled",

    instructions: `
        CURRENT STATE: You are now getting the payment information of the user.
        Say, 'Great! Now I need to get your payment information.' and MAKE SURE
        to then call the 'getPaymentInformation' action.
    `,
  }, [stage]);

  // ...

}
```

## [Recap](https://docs.copilotkit.ai/cookbook/state-machine\#recap)

This recipe introduced a powerful pattern for building conversational AI applications using state machines. By breaking down complex interactions into discrete stages, each with
focused instructions and actions, we can create more maintainable and user-friendly experiences.

With this pattern, you can start building your own multi-stage conversations.

## [Need Help?](https://docs.copilotkit.ai/cookbook/state-machine\#need-help)

Need help or want to share what you've built? Join our [Discord community](https://discord.gg/6dffbvGU3D) or open an issue on [GitHub](https://github.com/CopilotKit/CopilotKit/issues/new/choose).

[Previous\\
\\
Next Steps](https://docs.copilotkit.ai/tutorials/ai-powered-textarea/next-steps) [Next\\
\\
Common Issues](https://docs.copilotkit.ai/troubleshooting/common-issues)

### On this page

[Overview](https://docs.copilotkit.ai/cookbook/state-machine#overview) [What is a State Machine?](https://docs.copilotkit.ai/cookbook/state-machine#what-is-a-state-machine) [State Machines in CopilotKit](https://docs.copilotkit.ai/cookbook/state-machine#state-machines-in-copilotkit) [Basic Implementation](https://docs.copilotkit.ai/cookbook/state-machine#basic-implementation) [Create a stage](https://docs.copilotkit.ai/cookbook/state-machine#create-a-stage) [Create another stage](https://docs.copilotkit.ai/cookbook/state-machine#create-another-stage) [Put it all together](https://docs.copilotkit.ai/cookbook/state-machine#put-it-all-together) [🎉 You've implemented a state machine!](https://docs.copilotkit.ai/cookbook/state-machine#-youve-implemented-a-state-machine) [Advanced Patterns](https://docs.copilotkit.ai/cookbook/state-machine#advanced-patterns) [Stage Transition Approaches](https://docs.copilotkit.ai/cookbook/state-machine#stage-transition-approaches) [Code-driven Stage Transitions](https://docs.copilotkit.ai/cookbook/state-machine#code-driven-stage-transitions) [LLM-Driven Stage Transitions](https://docs.copilotkit.ai/cookbook/state-machine#llm-driven-stage-transitions) [Generative UI](https://docs.copilotkit.ai/cookbook/state-machine#generative-ui) [Initial message loading](https://docs.copilotkit.ai/cookbook/state-machine#initial-message-loading) [Tools When Entering a Stage](https://docs.copilotkit.ai/cookbook/state-machine#tools-when-entering-a-stage) [Recap](https://docs.copilotkit.ai/cookbook/state-machine#recap) [Need Help?](https://docs.copilotkit.ai/cookbook/state-machine#need-help)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/cookbook/state-machine.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

![State Machine Architecture](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Fstate-machine-arch.png&w=3840&q=75)

## Agent State Management
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useCoAgent

The useCoAgent hook allows you to share state bidirectionally between your application and the agent.

Usage of this hook assumes some additional setup in your application, for more information
on that see the CoAgents [getting started guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph).

![CoAgents demonstration](https://docs.copilotkit.ai/images/coagents/SharedStateCoAgents.gif)

This hook is used to integrate an agent into your application. With its use, you can
render and update the state of an agent, allowing for a dynamic and interactive experience.
We call these shared state experiences agentic copilots, or CoAgents for short.

## [Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgent\#usage)

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgent\#simple-usage)

```
import { useCoAgent } from "@copilotkit/react-core";

type AgentState = {
  count: number;
}

const agent = useCoAgent<AgentState>({
  name: "my-agent",
  initialState: {
    count: 0,
  },
});

```

`useCoAgent` returns an object with the following properties:

```
const {
  name,     // The name of the agent currently being used.
  nodeName, // The name of the current LangGraph node.
  state,    // The current state of the agent.
  setState, // A function to update the state of the agent.
  running,  // A boolean indicating if the agent is currently running.
  start,    // A function to start the agent.
  stop,     // A function to stop the agent.
  run,      // A function to re-run the agent. Takes a HintFunction to inform the agent why it is being re-run.
} = agent;
```

Finally we can leverage these properties to create reactive experiences with the agent!

```
const { state, setState } = useCoAgent<AgentState>({
  name: "my-agent",
  initialState: {
    count: 0,
  },
});

return (
  <div>
    <p>Count: {state.count}</p>
    <button onClick={() => setState({ count: state.count + 1 })}>Increment</button>
  </div>
);
```

This reactivity is bidirectional, meaning that changes to the state from the agent will be reflected in the UI and vice versa.

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useCoAgent\#parameters)

optionsUseCoagentOptions<T>required

The options to use when creating the coagent.

namestringrequired

The name of the agent to use.

initialStateT \| any

The initial state of the agent.

stateT \| any

State to manage externally if you are using this hook with external state management.

setState(newState: T \| ((prevState: T \| undefined) => T)) => void

A function to update the state of the agent if you are using this hook with external state management.

[Previous\\
\\
useCopilotChatSuggestions](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions) [Next\\
\\
useCoAgentStateRender](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgent#usage) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgent#simple-usage) [Parameters](https://docs.copilotkit.ai/reference/hooks/useCoAgent#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useCoAgent.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Component Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

# CopilotKit

The CopilotKit provider component, wrapping your application.

This component will typically wrap your entire application (or a sub-tree of your application where you want to have a copilot). It provides the copilot context to all other components and hooks.

## [Example](https://docs.copilotkit.ai/reference/components/CopilotKit\#example)

You can find more information about self-hosting CopilotKit [here](https://docs.copilotkit.ai/guides/self-hosting).

```
import { CopilotKit } from "@copilotkit/react-core";

<CopilotKit runtimeUrl="<your-runtime-url>">
  // ... your app ...
</CopilotKit>
```

## [Properties](https://docs.copilotkit.ai/reference/components/CopilotKit\#properties)

publicApiKeystring

Your Copilot Cloud API key. Don't have it yet? Go to [https://cloud.copilotkit.ai](https://cloud.copilotkit.ai/) and get one for free.

guardrails\_c{ validTopics?: string\[\]; invalidTopics?: string\[\]; }

Restrict input to specific topics using guardrails.
@remarks

This feature is only available when using CopilotKit's hosted cloud service. To use this feature, sign up at [https://cloud.copilotkit.ai](https://cloud.copilotkit.ai/) to get your publicApiKey. The feature allows restricting chat conversations to specific topics.

runtimeUrlstring

The endpoint for the Copilot Runtime instance. [Click here for more information](https://docs.copilotkit.ai/concepts/copilot-runtime).

transcribeAudioUrlstring

The endpoint for the Copilot transcribe audio service.

textToSpeechUrlstring

The endpoint for the Copilot text to speech service.

headersRecord<string, string>

Additional headers to be sent with the request.

For example:

```
{
  "Authorization": "Bearer X"
}
```

childrenReactNoderequired

The children to be rendered within the CopilotKit.

propertiesRecord<string, any>

Custom properties to be sent with the request
For example:

```
{
  'user_id': 'users_id',
}
```

credentialsRequestCredentials

Indicates whether the user agent should send or receive cookies from the other domain
in the case of cross-origin requests.

showDevConsoleboolean \| 'auto'

Whether to show the dev console.

If set to "auto", the dev console will be show on localhost only.

agentstring

The name of the agent to use.

forwardedParametersPick<ForwardedParametersInput, 'temperature'>

The forwarded parameters to use for the task.

authConfig\_c{ SignInComponent: React.ComponentType<{ onSignInComplete: (authState: AuthState) => void; }>; }

The auth config to use for the CopilotKit.
@remarks

This feature is only available when using CopilotKit's hosted cloud service. To use this feature, sign up at [https://cloud.copilotkit.ai](https://cloud.copilotkit.ai/) to get your publicApiKey. The feature allows restricting chat conversations to specific topics.

threadIdstring

The thread id to use for the CopilotKit.

mcpEndpointsArray<{ endpoint: string; apiKey?: string }>

Config for connecting to Model Context Protocol (MCP) servers.
Enables CopilotKit runtime to access tools on external MCP servers.

This config merges into the `properties` object with each request as `mcpEndpoints`.
It offers a typed method to set up MCP endpoints for requests.

Each array item should have:

- `endpoint`: MCP server URL (mandatory).
- `apiKey`: Optional API key for server authentication.

Note: A `createMCPClient` function is still needed during runtime initialization to manage these endpoints.

[Previous\\
\\
CopilotTextarea](https://docs.copilotkit.ai/reference/components/CopilotTextarea) [Next\\
\\
useCopilotReadable](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable)

### On this page

[Example](https://docs.copilotkit.ai/reference/components/CopilotKit#example) [Properties](https://docs.copilotkit.ai/reference/components/CopilotKit#properties)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/components/CopilotKit.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Frontend Actions Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

# Frontend Actions

Create frontend actions and use them within your agent.

This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the [implementation](https://docs.copilotkit.ai/coagents/frontend-actions#implementation) section applied to it!

## [What is this?](https://docs.copilotkit.ai/coagents/frontend-actions\#what-is-this)

Frontend actions are powerful tools that allow your AI agents to directly interact with and update your application's user interface. Think of them as bridges that connect your agent's decision-making capabilities with your frontend's interactive elements.

## [When should I use this?](https://docs.copilotkit.ai/coagents/frontend-actions\#when-should-i-use-this)

Frontend actions are essential when you want to create truly interactive AI applications where your agent needs to:

- Dynamically update UI elements
- Trigger frontend animations or transitions
- Show alerts or notifications
- Modify application state
- Handle user interactions programmatically

Without frontend actions, agents are limited to just processing and returning data. By implementing frontend actions, you can create rich, interactive experiences where your agent actively drives the user interface.

## [Implementation](https://docs.copilotkit.ai/coagents/frontend-actions\#implementation)

### [Setup CopilotKit](https://docs.copilotkit.ai/coagents/frontend-actions\#setup-copilotkit)

To use frontend actions, you'll need to setup CopilotKit first. For the sake of brevity, we won't cover it here.

Check out our [getting started guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph) and come back here when you're setup!

### [Create a frontend action](https://docs.copilotkit.ai/coagents/frontend-actions\#create-a-frontend-action)

First, you'll need to create a frontend action using the [useCopilotAction](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) hook. Here's a simple one to get you started
that says hello to the user.

page.tsx

```
import { useCopilotAction } from "@copilotkit/react-core"

export function Page() {
  // ...


  useCopilotAction({
    name: "sayHello",
    description: "Say hello to the user",
    available: "remote", // optional, makes it so the action is *only* available to the agent
    parameters: [\
      {\
        name: "name",\
        type: "string",\
        description: "The name of the user to say hello to",\
        required: true,\
      },\
    ],
    handler: async ({ name }) => {
      alert(`Hello, ${name}!`);
    },
  });

  // ...
}
```

### [Modify your agent](https://docs.copilotkit.ai/coagents/frontend-actions\#modify-your-agent)

Now, we'll need to modify the agent to access these frontend actions. Open up for your agent's folder and continue from there!

### [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/frontend-actions\#install-the-copilotkit-sdk)

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic
experiences with CopilotKit requires our LangGraph SDK.

PythonTypeScript

Poetrypipconda

```
poetry add copilotkit
# including support for crewai
poetry add copilotkit[crewai]
```

### [Inheriting from CopilotKitState](https://docs.copilotkit.ai/coagents/frontend-actions\#inheriting-from-copilotkitstate)

To access the frontend actions provided by CopilotKit, you can inherit from CopilotKitState in your agent's state definition:

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState

class YourAgentState(CopilotKitState):
    your_additional_properties: str
```

By doing this, your agent's state will include the `copilotkit` property, which contains the frontend actions that can be accessed and invoked.

### [Accessing Frontend Actions](https://docs.copilotkit.ai/coagents/frontend-actions\#accessing-frontend-actions)

Once your agent's state includes the `copilotkit` property, you can access the frontend actions and utilize them within your agent's logic.

Here's how you can call a frontend action from your agent:

PythonTypeScript

agent-py/sample\_agent/agent.py

```
async def agent_node(state: YourAgentState, config: RunnableConfig):
    # Access the actions from the copilotkit property

    actions = state.get("copilotkit", {}).get("actions", [])
    model = ChatOpenAI(model="gpt-4o").bind_tools(actions)

    # ...
```

These actions are automatically populated by CopilotKit and are compatible with LangChain's tool call definitions, making it straightforward to integrate them into your agent's workflow.

### [Give it a try!](https://docs.copilotkit.ai/coagents/frontend-actions\#give-it-a-try)

You've now given your agent the ability to directly call any CopilotActions you've defined. These actions will be available as tools to the agent where they can be used as needed.

[Previous\\
\\
Predictive state updates](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates) [Next\\
\\
Multi-Agent Flows](https://docs.copilotkit.ai/coagents/multi-agent-flows)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/frontend-actions#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/frontend-actions#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/frontend-actions#implementation) [Setup CopilotKit](https://docs.copilotkit.ai/coagents/frontend-actions#setup-copilotkit) [Create a frontend action](https://docs.copilotkit.ai/coagents/frontend-actions#create-a-frontend-action) [Modify your agent](https://docs.copilotkit.ai/coagents/frontend-actions#modify-your-agent) [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/frontend-actions#install-the-copilotkit-sdk) [Inheriting from CopilotKitState](https://docs.copilotkit.ai/coagents/frontend-actions#inheriting-from-copilotkitstate) [Accessing Frontend Actions](https://docs.copilotkit.ai/coagents/frontend-actions#accessing-frontend-actions) [Give it a try!](https://docs.copilotkit.ai/coagents/frontend-actions#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/frontend-actions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Generative UI Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is Generative UI?

# Generative UI

Render your agent's behavior with custom UI components.

![Demo of Generative UI showing a meeting scheduling agent](https://docs.copilotkit.ai/images/coagents/AgenticGenerativeUI.gif)

This example shows our [Research Canvas](https://docs.copilotkit.ai/coagents/videos/research-canvas) making use of Generative UI!

## [What is Generative UI?](https://docs.copilotkit.ai/coagents/generative-ui\#what-is-generative-ui)

Generative UI lets you render your agent's state, progress, outputs, and tool calls with custom UI components in real-time. It bridges the gap between AI
agents and user interfaces. As your agent processes information and makes decisions, you can render custom UI components that:

- Show loading states and progress indicators
- Display structured data in tables, cards, or charts
- Create interactive elements for user input
- Animate transitions between different states

## [How can I use this?](https://docs.copilotkit.ai/coagents/generative-ui\#how-can-i-use-this)

There are two main variants of Generative UI.

[Agentic\\
\\
Render your agent's state, progress, and outputs with custom UI components.](https://docs.copilotkit.ai/coagents/generative-ui/agentic)

[Tool-based\\
\\
Render your agent's tool calls with custom UI components.](https://docs.copilotkit.ai/coagents/generative-ui/tool-based)

[Previous\\
\\
Chat with an Agent](https://docs.copilotkit.ai/coagents/agentic-chat-ui) [Next\\
\\
Agentic Generative UI](https://docs.copilotkit.ai/coagents/generative-ui/agentic)

### On this page

[What is Generative UI?](https://docs.copilotkit.ai/coagents/generative-ui#what-is-generative-ui) [How can I use this?](https://docs.copilotkit.ai/coagents/generative-ui#how-can-i-use-this)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/generative-ui/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall CopilotKit

# Quickstart

Get started with CopilotKit in under 5 minutes.

Copilot Cloud (Recommended)

Use our hosted backend endpoint to get started quickly (OpenAI only).

Self-hosting

Learn to host CopilotKit's runtime yourself with your own backend.

## [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=CopilotChat\#install-copilotkit)

First, install the latest packages for CopilotKit.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

## [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=CopilotChat\#get-a-copilot-cloud-public-api-key)

Navigate to [Copilot Cloud](https://cloud.copilotkit.ai/) and follow the instructions to get a public API key - it's free!

## [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=CopilotChat\#setup-the-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit publicApiKey="<your-copilot-cloud-public-api-key>">
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

## [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=CopilotChat\#choose-a-copilot-ui)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

`CopilotChat` is a flexible chat interface component that **can be placed anywhere in your app** and can be resized as you desire.

![Popup Example](https://docs.copilotkit.ai/images/copilotchat-example.gif)

```
import { CopilotChat } from "@copilotkit/react-ui";

export function YourComponent() {
  return (
    <CopilotChat
      instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
      labels={{
        title: "Your Assistant",
        initial: "Hi! 👋 How can I assist you today?",
      }}
    />
  );
}
```

* * *

## [Next Steps](https://docs.copilotkit.ai/quickstart?component=CopilotChat\#next-steps)

🎉 Congrats! You've successfully integrated a fully functional chatbot in your application! Give it a try now and see it in action. Want to
take it further? Learn more about what CopilotKit has to offer!

[**Connecting Your Data** \\
Learn how to connect CopilotKit to your data, application state and user state.](https://docs.copilotkit.ai/guides/connect-your-data) [**Generative UI** \\
Learn how to render custom UI components directly in the CopilotKit chat window.](https://docs.copilotkit.ai/guides/generative-ui) [**Frontend Actions** \\
Learn how to allow your copilot to take applications on frontend.](https://docs.copilotkit.ai/guides/frontend-actions) [**CoAgents (LangGraph)** \\
Check out our section about CoAgents, our approach to building agentic copilots and experiences.](https://docs.copilotkit.ai/coagents)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/) [Next\\
\\
Customize UI](https://docs.copilotkit.ai/guides/custom-look-and-feel)

### On this page

[Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=CopilotChat#install-copilotkit) [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=CopilotChat#get-a-copilot-cloud-public-api-key) [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=CopilotChat#setup-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=CopilotChat#choose-a-copilot-ui) [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=CopilotChat#install-copilotkit-1) [Set up a Copilot Runtime Endpoint](https://docs.copilotkit.ai/quickstart?component=CopilotChat#set-up-a-copilot-runtime-endpoint) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=CopilotChat#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=CopilotChat#choose-a-copilot-ui-1) [Next Steps](https://docs.copilotkit.ai/quickstart?component=CopilotChat#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/quickstart.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Message History Management
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Saving and restoring messages

Learn how to save and restore message history.

See [Loading Message History](https://docs.copilotkit.ai/coagents/persistence/loading-message-history) for an automated way to load the chat history.

As you're building agentic experiences, you may want to persist the user's chat history across runs.
One way to do this is through the use of `localstorage` where chat history is saved in the browser.
In this guide we demonstrate how you can store the state into `localstorage` and how it can be inserted
into the agent.

The following example shows how to save and restore your message history using `localStorage`:

```
import { useCopilotMessagesContext } from "@copilotkit/react-core";
import { ActionExecutionMessage, ResultMessage, TextMessage } from "@copilotkit/runtime-client-gql";

const { messages, setMessages } = useCopilotMessagesContext();

// save to local storage when messages change
useEffect(() => {
  if (messages.length !== 0) {
    localStorage.setItem("copilotkit-messages", JSON.stringify(messages));
  }
}, [JSON.stringify(messages)]);

// initially load from local storage
useEffect(() => {
  const messages = localStorage.getItem("copilotkit-messages");
  if (messages) {
    const parsedMessages = JSON.parse(messages).map((message: any) => {
      if (message.type === "TextMessage") {
        return new TextMessage({
          id: message.id,
          role: message.role,
          content: message.content,
          createdAt: message.createdAt,
        });
      } else if (message.type === "ActionExecutionMessage") {
        return new ActionExecutionMessage({
          id: message.id,
          name: message.name,
          scope: message.scope,
          arguments: message.arguments,
          createdAt: message.createdAt,
        });
      } else if (message.type === "ResultMessage") {
        return new ResultMessage({
          id: message.id,
          actionExecutionId: message.actionExecutionId,
          actionName: message.actionName,
          result: message.result,
          createdAt: message.createdAt,
        });
      } else {
        throw new Error(`Unknown message type: ${message.type}`);
      }
    });
    setMessages(parsedMessages);
  }
}, []);
```

[Previous\\
\\
Self Hosting (Copilot Runtime)](https://docs.copilotkit.ai/guides/self-hosting) [Next\\
\\
Overview](https://docs.copilotkit.ai/tutorials/ai-todo-app/overview)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/messages-localstorage.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Copilot Suggestions Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageSimple Usage

# Copilot Suggestions

Learn how to auto-generate suggestions in the chat window based on real time application state.

useCopilotChatSuggestions is experimental. The interface is not final and can
change without notice.

[`useCopilotChatSuggestions`](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions) is a React hook that generates suggestions in the chat window based on real time application state.

![](https://docs.copilotkit.ai/images/use-copilot-chat-suggestions/use-copilot-chat-suggestions.gif)

### [Simple Usage](https://docs.copilotkit.ai/guides/copilot-suggestions\#simple-usage)

```
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";

export function MyComponent() {

  useCopilotChatSuggestions(
    {
      instructions: "Suggest the most relevant next actions.",
      minSuggestions: 1,
      maxSuggestions: 2,
    },
    [relevantState],
  );
}
```

### [Dependency Management](https://docs.copilotkit.ai/guides/copilot-suggestions\#dependency-management)

```
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";

export function MyComponent() {
  useCopilotChatSuggestions(
    {
      instructions: "Suggest the most relevant next actions.",
      minSuggestions: 1,
      maxSuggestions: 2,
    },
    [relevantState],
  );
}
```

In the example above, the suggestions are generated based on the given instructions.
The hook monitors `relevantState`, and updates suggestions accordingly whenever it changes.

### [Specify `"use client"` (Next.js App Router)](https://docs.copilotkit.ai/guides/copilot-suggestions\#specify-use-client-nextjs-app-router)

This is only necessary if you are using Next.js with the App Router.

YourComponent.tsx

```
"use client"
```

Like other React hooks such as `useState` and `useEffect`, this is a **client-side** hook.
If you're using Next.js with the App Router, you'll need to add the `"use client"` directive at the top of any file using this hook.

## [Next Steps](https://docs.copilotkit.ai/guides/copilot-suggestions\#next-steps)

- Check out the [useCopilotChatSuggestions reference](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions) for more details.

[Previous\\
\\
Guardrails](https://docs.copilotkit.ai/guides/guardrails) [Next\\
\\
Bring Your Own LLM](https://docs.copilotkit.ai/guides/bring-your-own-llm)

### On this page

[Simple Usage](https://docs.copilotkit.ai/guides/copilot-suggestions#simple-usage) [Dependency Management](https://docs.copilotkit.ai/guides/copilot-suggestions#dependency-management) [Next Steps](https://docs.copilotkit.ai/guides/copilot-suggestions#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/copilot-suggestions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotTask Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

# CopilotTask

CopilotTask is used to execute one-off tasks, for example on button click.

This class is used to execute one-off tasks, for example on button press. It can use the context available via [useCopilotReadable](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable) and the actions provided by [useCopilotAction](https://docs.copilotkit.ai/reference/hooks/useCopilotAction), or you can provide your own context and actions.

## [Example](https://docs.copilotkit.ai/reference/classes/CopilotTask\#example)

In the simplest case, use CopilotTask in the context of your app by giving it instructions on what to do.

```
import { CopilotTask, useCopilotContext } from "@copilotkit/react-core";

export function MyComponent() {
  const context = useCopilotContext();

  const task = new CopilotTask({
    instructions: "Set a random message",
    actions: [\
      {\
        name: "setMessage",\
      description: "Set the message.",\
      argumentAnnotations: [\
        {\
          name: "message",\
          type: "string",\
          description:\
            "A message to display.",\
          required: true,\
        },\
      ],\
     }\
    ]
  });

  const executeTask = async () => {
    await task.run(context, action);
  }

  return (
    <>
      <button onClick={executeTask}>
        Execute task
      </button>
    </>
  )
}
```

Have a look at the [Presentation Example App](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/examples/next-openai/src/app/presentation/page.tsx) for a more complete example.

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/CopilotTask\#constructor-parameters)

instructionsstringrequired

The instructions to be given to the assistant.

actionsFrontendAction<any>\[\]

An array of action definitions that can be called.

includeCopilotReadableboolean

Whether to include the copilot readable context in the task.

includeCopilotActionsboolean

Whether to include actions defined via useCopilotAction in the task.

forwardedParametersForwardedParametersInput

The forwarded parameters to use for the task.

runcontext: CopilotContextParams, data?: T

Run the task.

contextCopilotContextParamsrequired

The CopilotContext to use for the task. Use `useCopilotContext` to obtain the current context.

dataT

The data to use for the task.

[Previous\\
\\
GoogleGenerativeAIAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter) [Next\\
\\
Remote Endpoints](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints)

### On this page

[Example](https://docs.copilotkit.ai/reference/classes/CopilotTask#example) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/CopilotTask#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/CopilotTask.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Copilot Textarea Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall @copilotkit/react-textarea

# Copilot Textarea

Learn how to use the Copilot Textarea for AI-powered autosuggestions.

![](https://docs.copilotkit.ai/images/CopilotTextarea.gif)

`<CopilotTextarea>` is a React component that acts as a drop-in replacement for the standard `<textarea>`,
offering enhanced autocomplete features powered by AI. It is context-aware, integrating seamlessly with the
[`useCopilotReadable`](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable) hook to provide intelligent suggestions based on the application context.

In addition, it provides a hovering editor window (available by default via `Cmd + K` on Mac and `Ctrl + K` on Windows) that allows the user to
suggest changes to the text, for example providing a summary or rephrasing the text.

This guide assumes you have completed the [quickstart](https://docs.copilotkit.ai/quickstart) and have successfully set up CopilotKit.

### [Install `@copilotkit/react-textarea`](https://docs.copilotkit.ai/guides/copilot-textarea\#install-copilotkitreact-textarea)

npmpnpmyarnbun

```
npm install @copilotkit/react-textarea
```

### [Import Styles](https://docs.copilotkit.ai/guides/copilot-textarea\#import-styles)

Import the default styles in your root component (typically `layout.tsx`) :

layout.tsx

```
import "@copilotkit/react-textarea/styles.css";
```

### [Add `CopilotTextarea` to Your Component](https://docs.copilotkit.ai/guides/copilot-textarea\#add-copilottextarea-to-your-component)

Below you can find several examples showing how to use the `CopilotTextarea` component in your application.

Example 1Example 2

TextAreaComponent.tsx

```
import { FC, useState } from "react";
import { CopilotTextarea } from '@copilotkit/react-textarea';

const ExampleComponent: FC = () => {
  const [text, setText] = useState<string>('');

  return (
    <CopilotTextarea
      className="w-full p-4 border border-gray-300 rounded-md"
      value={text}
      onValueChange={setText}

      autosuggestionsConfig={{
        textareaPurpose: "the body of an email message",
        chatApiConfigs: {},
      }}
    />
  );
};
```

## [Next Steps](https://docs.copilotkit.ai/guides/copilot-textarea\#next-steps)

- We highly recommend that you check out our simple [Copilot Textarea Tutorial](https://docs.copilotkit.ai/tutorials/ai-powered-textarea/overview).
- Check out the full [CopilotTextarea reference](https://docs.copilotkit.ai/reference/components/CopilotTextarea)

[Previous\\
\\
Bring Your Own LLM](https://docs.copilotkit.ai/guides/bring-your-own-llm) [Next\\
\\
Self Hosting (Copilot Runtime)](https://docs.copilotkit.ai/guides/self-hosting)

### On this page

[Install @copilotkit/react-textarea](https://docs.copilotkit.ai/guides/copilot-textarea#install-copilotkitreact-textarea) [Import Styles](https://docs.copilotkit.ai/guides/copilot-textarea#import-styles) [Add CopilotTextarea to Your Component](https://docs.copilotkit.ai/guides/copilot-textarea#add-copilottextarea-to-your-component) [Next Steps](https://docs.copilotkit.ai/guides/copilot-textarea#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/copilot-textarea.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAI Support
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

![CopilotKit Logo](https://docs.copilotkit.ai/images/copilotkit-logo.svg)

# Page Not Found

Oops! The page you're looking for doesn't exist.

[Go to Documentation](https://docs.copilotkit.ai/)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotRuntime Class Reference
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# CopilotRuntime

Copilot Runtime is the back-end component of CopilotKit, enabling interaction with LLMs.

This is the reference for the `CopilotRuntime` class. For more information and example code snippets, please see [Concept: Copilot Runtime](https://docs.copilotkit.ai/concepts/copilot-runtime).

## [Usage](https://docs.copilotkit.ai/reference/classes/CopilotRuntime\#usage)

```
import { CopilotRuntime } from "@copilotkit/runtime";

const copilotKit = new CopilotRuntime();
```

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/CopilotRuntime\#constructor-parameters)

middlewareMiddleware

Middleware to be used by the runtime.

```
onBeforeRequest: (options: {
  threadId?: string;
  runId?: string;
  inputMessages: Message[];
  properties: any;
}) => void | Promise<void>;
```

```
onAfterRequest: (options: {
  threadId?: string;
  runId?: string;
  inputMessages: Message[];
  outputMessages: Message[];
  properties: any;
}) => void | Promise<void>;
```

actionsActionsConfiguration<T>

A list of server side actions that can be executed. Will be ignored when remoteActions are set

remoteActionsCopilotKitEndpoint\[\]

Deprecated: Use `remoteEndpoints`.

remoteEndpointsEndpointDefinition\[\]

A list of remote actions that can be executed.

langserveRemoteChainParameters\[\]

An array of LangServer URLs.

delegateAgentProcessingToServiceAdapterboolean

Delegates agent state processing to the service adapter.

When enabled, individual agent state requests will not be processed by the agent itself.
Instead, all processing will be handled by the service adapter.

observability\_cCopilotObservabilityConfig

Configuration for LLM request/response logging.
Requires publicApiKey from CopilotKit component to be set:

```
<CopilotKit publicApiKey="ck_pub_..." />
```

Example logging config:

```
logging: {
  enabled: true, // Enable or disable logging
  progressive: true, // Set to false for buffered logging
  logger: {
    logRequest: (data) => langfuse.trace({ name: "LLM Request", input: data }),
    logResponse: (data) => langfuse.trace({ name: "LLM Response", output: data }),
    logError: (errorData) => langfuse.trace({ name: "LLM Error", metadata: errorData }),
  },
}
```

mcpEndpointsMCPEndpointConfig\[\]

Configuration for connecting to Model Context Protocol (MCP) servers.
Allows fetching and using tools defined on external MCP-compliant servers.
Requires providing the `createMCPClient` function during instantiation.
@experimental

createMCPClientCreateMCPClientFunction

A function that creates an MCP client instance for a given endpoint configuration.
This function is responsible for using the appropriate MCP client library
(e.g., `@copilotkit/runtime`, `ai`) to establish a connection.
Required if `mcpEndpoints` is provided.

```
import { experimental_createMCPClient } from "ai"; // Import from vercel ai library
// ...
const runtime = new CopilotRuntime({
  mcpEndpoints: [{ endpoint: "..." }],
  async createMCPClient(config) {
    return await experimental_createMCPClient({
      transport: {
        type: "sse",
        url: config.endpoint,
        headers: config.apiKey
          ? { Authorization: `Bearer ${config.apiKey}` }
          : undefined,
      },
    });
  }
});
```

processRuntimeRequestrequest: CopilotRuntimeRequest

// \-\-\- MCP Instruction Injection Method ---

requestCopilotRuntimeRequestrequired

discoverAgentsFromEndpointsgraphqlContext: GraphQLContext

graphqlContextGraphQLContextrequired

loadAgentStategraphqlContext: GraphQLContext, threadId: string, agentName: string

graphqlContextGraphQLContextrequired

threadIdstringrequired

agentNamestringrequired

[Previous\\
\\
useLangGraphInterrupt](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt) [Next\\
\\
OpenAIAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter)

### On this page

[Usage](https://docs.copilotkit.ai/reference/classes/CopilotRuntime#usage) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/CopilotRuntime#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/CopilotRuntime.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph Interrupt Hook
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useLangGraphInterrupt

The useLangGraphInterrupt hook allows setting the generative UI to be displayed on LangGraph's Interrupt event.

`useLangGraphInterrupt` is a React hook that you can use in your application to provide
custom UI to be rendered when using `interrupt` by LangGraph.
Once an Interrupt event is emitted, that hook would execute, allowing to receive user input with a user experience to your choice.

## [Usage](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt\#usage)

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt\#simple-usage)

app/page.tsx

```
import { useLangGraphInterrupt } from "@copilotkit/react-core";
// ...

const YourMainContent = () => {
  // ...

  // styles omitted for brevity
  useLangGraphInterrupt<string>({
    render: ({ event, resolve }) => (
      <div>
        <p>{event.value}</p>
        <form onSubmit={(e) => {
          e.preventDefault();
          resolve((e.target as HTMLFormElement).response.value);
        }}>
          <input type="text" name="response" placeholder="Enter your response" />
          <button type="submit">Submit</button>
        </form>
      </div>
    )
  });
  // ...

  return <div>{/* ... */}</div>
}
```

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt\#parameters)

actionActionrequired

The action to perform when an Interrupt event is emitted. Either `handler` or `render` must be defined as arguments

namestringrequired

The name of the action.

handler(args: LangGraphInterruptRenderProps<T>) => any \| Promise<any>

A handler to programmatically resolve the Interrupt, or perform operations which result will be passed to the `render` method

render(props: LangGraphInterruptRenderProps<T>) => string \| React.ReactElement

Render lets you define a custom component or string to render when an Interrupt event is emitted.

enabled(args: { eventValue: TEventValue; agentMetadata: AgentSession }) => boolean

Method that returns a boolean, indicating if the interrupt action should run. Useful when using multiple interrupts

dependenciesany\[\]

An optional array of dependencies.

[Previous\\
\\
useCoAgentStateRender](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender) [Next\\
\\
CopilotRuntime](https://docs.copilotkit.ai/reference/classes/CopilotRuntime)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt#usage) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt#simple-usage) [Parameters](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useLangGraphInterrupt.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotTextarea Component
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

# CopilotTextarea

An AI-powered textarea component for your application, which serves as a drop-in replacement for any textarea.

![](https://docs.copilotkit.ai/images/CopilotTextarea.gif)

`<CopilotTextarea>` is a React component that acts as a drop-in replacement for the standard `<textarea>`,
offering enhanced autocomplete features powered by AI. It is context-aware, integrating seamlessly with the
[`useCopilotReadable`](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable) hook to provide intelligent suggestions based on the application context.

In addition, it provides a hovering editor window (available by default via `Cmd + K` on Mac and `Ctrl + K` on Windows) that allows the user to
suggest changes to the text, for example providing a summary or rephrasing the text.

## [Example](https://docs.copilotkit.ai/reference/components/CopilotTextarea\#example)

```
import { CopilotTextarea } from '@copilotkit/react-textarea';
import "@copilotkit/react-textarea/styles.css";

<CopilotTextarea
  autosuggestionsConfig={{
    textareaPurpose:
     "the body of an email message",
    chatApiConfigs: {},
  }}
/>
```

## [Usage](https://docs.copilotkit.ai/reference/components/CopilotTextarea\#usage)

### [Install Dependencies](https://docs.copilotkit.ai/reference/components/CopilotTextarea\#install-dependencies)

This component is part of the [@copilotkit/react-textarea](https://npmjs.com/package/@copilotkit/react-textarea) package.

```
npm install @copilotkit/react-core @copilotkit/react-textarea
```

### [Usage](https://docs.copilotkit.ai/reference/components/CopilotTextarea\#usage-1)

Use the CopilotTextarea component in your React application similarly to a standard `<textarea />`,
with additional configurations for AI-powered features.

For example:

```
import { useState } from "react";
import { CopilotTextarea } from "@copilotkit/react-textarea";
import "@copilotkit/react-textarea/styles.css";

export function ExampleComponent() {
  const [text, setText] = useState("");

  return (
    <CopilotTextarea
      className="custom-textarea-class"
      value={text}
      onValueChange={(value: string) => setText(value)}
      placeholder="Enter your text here..."
      autosuggestionsConfig={{
        textareaPurpose: "Provide context or purpose of the textarea.",
        chatApiConfigs: {
          suggestionsApiConfig: {
            maxTokens: 20,
            stop: [".", "?", "!"],
          },
        },
      }}
    />
  );
}
```

### [Look & Feel](https://docs.copilotkit.ai/reference/components/CopilotTextarea\#look--feel)

By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:

YourRootComponent.tsx

```
...
import "@copilotkit/react-textarea/styles.css";

export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```

For more information about how to customize the styles, check out the [Customize Look & Feel](https://docs.copilotkit.ai/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## [Properties](https://docs.copilotkit.ai/reference/components/CopilotTextarea\#properties)

disableBrandingboolean

Determines whether the CopilotKit branding should be disabled. Default is `false`.

placeholderStyleReact.CSSProperties

Specifies the CSS styles to apply to the placeholder text.

suggestionsStyleReact.CSSProperties

Specifies the CSS styles to apply to the suggestions list.

hoverMenuClassnamestring

A class name to apply to the editor popover window.

valuestring

The initial value of the textarea. Can be controlled via `onValueChange`.

onValueChange(value: string) => void

Callback invoked when the value of the textarea changes.

onChange(event: React.ChangeEvent<HTMLTextAreaElement>) => void

Callback invoked when a `change` event is triggered on the textarea element.

shortcutstring

The shortcut to use to open the editor popover window. Default is `"Cmd-k"`.

autosuggestionsConfigAutosuggestionsConfigUserSpecifiedrequired

Configuration settings for the autosuggestions feature.
For full reference, [check the interface on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-textarea/src/types/base/base-copilot-textarea-props.tsx#L8).

textareaPurposestringrequired

The purpose of the text area in plain text.

Example: "The body of the email response"

chatApiConfigsChatApiConfigs

The chat API configurations.

**NOTE:** You must provide specify at least one of `suggestionsApiConfig` or `insertionApiConfig`.

suggestionsApiConfigSuggestionsApiConfig

For full reference, please [click here](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-textarea/src/types/autosuggestions-config/suggestions-api-config.tsx#L4).

insertionApiConfigInsertionApiConfig

For full reference, please [click here](https://github.com/CopilotKit/CopilotKit/blob/main/CopilotKit/packages/react-textarea/src/types/autosuggestions-config/insertions-api-config.tsx#L4).

disabledboolean

Whether the textarea is disabled.

disableBrandingboolean

Whether to disable the CopilotKit branding.

placeholderStyleReact.CSSProperties

Specifies the CSS styles to apply to the placeholder text.

suggestionsStyleReact.CSSProperties

Specifies the CSS styles to apply to the suggestions list.

hoverMenuClassnamestring

A class name to apply to the editor popover window.

valuestring

The initial value of the textarea. Can be controlled via `onValueChange`.

onValueChange(value: string) => void

Callback invoked when the value of the textarea changes.

onChange(event: React.ChangeEvent<HTMLTextAreaElement>) => void

Callback invoked when a `change` event is triggered on the textarea element.

shortcutstring

The shortcut to use to open the editor popover window. Default is `"Cmd-k"`.

[Previous\\
\\
CopilotSidebar](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar) [Next\\
\\
CopilotKit](https://docs.copilotkit.ai/reference/components/CopilotKit)

### On this page

[Example](https://docs.copilotkit.ai/reference/components/CopilotTextarea#example) [Usage](https://docs.copilotkit.ai/reference/components/CopilotTextarea#usage) [Install Dependencies](https://docs.copilotkit.ai/reference/components/CopilotTextarea#install-dependencies) [Usage](https://docs.copilotkit.ai/reference/components/CopilotTextarea#usage-1) [Look & Feel](https://docs.copilotkit.ai/reference/components/CopilotTextarea#look--feel) [Properties](https://docs.copilotkit.ai/reference/components/CopilotTextarea#properties)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/components/CopilotTextarea.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall CopilotKit

# Quickstart

Get started with CopilotKit in under 5 minutes.

Copilot Cloud (Recommended)

Use our hosted backend endpoint to get started quickly (OpenAI only).

Self-hosting

Learn to host CopilotKit's runtime yourself with your own backend.

## [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar\#install-copilotkit)

First, install the latest packages for CopilotKit.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

## [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar\#get-a-copilot-cloud-public-api-key)

Navigate to [Copilot Cloud](https://cloud.copilotkit.ai/) and follow the instructions to get a public API key - it's free!

## [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar\#setup-the-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit publicApiKey="<your-copilot-cloud-public-api-key>">
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

## [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar\#choose-a-copilot-ui)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

`CopilotSidebar` is a convenience wrapper for `CopilotChat` that wraps your main content in the view hierarchy. It provides a **collapsible and expandable sidebar** chat interface.

![Popup Example](https://docs.copilotkit.ai/images/sidebar-example.gif)

```
import { CopilotSidebar } from "@copilotkit/react-ui";

export function YourApp() {
  return (
    <CopilotSidebar
      defaultOpen={true}
      instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
      labels={{
        title: "Sidebar Assistant",
        initial: "How can I help you today?",
      }}
    >
      <YourMainContent />
    </CopilotSidebar>
  );
}
```

* * *

## [Next Steps](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar\#next-steps)

🎉 Congrats! You've successfully integrated a fully functional chatbot in your application! Give it a try now and see it in action. Want to
take it further? Learn more about what CopilotKit has to offer!

[**Connecting Your Data** \\
Learn how to connect CopilotKit to your data, application state and user state.](https://docs.copilotkit.ai/guides/connect-your-data) [**Generative UI** \\
Learn how to render custom UI components directly in the CopilotKit chat window.](https://docs.copilotkit.ai/guides/generative-ui) [**Frontend Actions** \\
Learn how to allow your copilot to take applications on frontend.](https://docs.copilotkit.ai/guides/frontend-actions) [**CoAgents (LangGraph)** \\
Check out our section about CoAgents, our approach to building agentic copilots and experiences.](https://docs.copilotkit.ai/coagents)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/) [Next\\
\\
Customize UI](https://docs.copilotkit.ai/guides/custom-look-and-feel)

### On this page

[Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#install-copilotkit) [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#get-a-copilot-cloud-public-api-key) [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#setup-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#choose-a-copilot-ui) [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#install-copilotkit-1) [Set up a Copilot Runtime Endpoint](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#set-up-a-copilot-runtime-endpoint) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#choose-a-copilot-ui-1) [Next Steps](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/quickstart.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Generative UI Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageRender custom components in the chat UI

# Generative UI

Learn how to embed custom UI components in the chat window.

# [Render custom components in the chat UI](https://docs.copilotkit.ai/guides/generative-ui\#render-custom-components-in-the-chat-ui)

When a user interacts with your Copilot, you may want to render a custom UI component. [`useCopilotAction`](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) allows to give the LLM the
option to render your custom component through the `render` property.

Render a componentFetch data & renderrenderAndWaitForResponse (HITL)Render stringsCatch all renders

[`useCopilotAction`](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) can be used with a `render` function and without a `handler` to display information or UI elements within the chat.

Here's an example to render a calendar meeting.

![Example of render-only Copilot action](https://docs.copilotkit.ai/images/render-only-example.png)

```
"use client" // only necessary if you are using Next.js with the App Router.
import { useCopilotAction } from "@copilotkit/react-core";

export function YourComponent() {
  useCopilotAction({
    name: "showCalendarMeeting",
    description: "Displays calendar meeting information",
    parameters: [\
      {\
        name: "date",\
        type: "string",\
        description: "Meeting date (YYYY-MM-DD)",\
        required: true\
      },\
      {\
        name: "time",\
        type: "string",\
        description: "Meeting time (HH:mm)",\
        required: true\
      },\
      {\
        name: "meetingName",\
        type: "string",\
        description: "Name of the meeting",\
        required: false\
      }\
    ],

    render: ({ status, args }) => {
      const { date, time, meetingName } = args;

      if (status === 'inProgress') {
        return <LoadingView />; // Your own component for loading state
      } else {
        const meetingProps: CalendarMeetingCardProps = {
          date: date,
          time,
          meetingName
        };
        return <CalendarMeetingCardComponent {...meetingProps} />;
      }
    },
  });

  return (
    <>...</>
  );
}
```

### What do the different status states mean?

### Why do I need "use client" in Next.js with the App Router?

## [Test it out!](https://docs.copilotkit.ai/guides/generative-ui\#test-it-out)

After defining the action with a render method, ask the copilot to perform the task. For example, you can now ask the copilot to "show tasks" and see the custom UI component rendered in the chat interface.

You can read more about the `useCopilotAction` hook
[here](https://docs.copilotkit.ai/reference/hooks/useCopilotAction).

[Previous\\
\\
Backend Data](https://docs.copilotkit.ai/guides/connect-your-data/backend) [Next\\
\\
Frontend Actions](https://docs.copilotkit.ai/guides/frontend-actions)

### On this page

[Render custom components in the chat UI](https://docs.copilotkit.ai/guides/generative-ui#render-custom-components-in-the-chat-ui) [Test it out!](https://docs.copilotkit.ai/guides/generative-ui#test-it-out)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/generative-ui.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Chat Suggestions Hook
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useCopilotChatSuggestions

The useCopilotChatSuggestions hook generates suggestions in the chat window based on real-time app state.

useCopilotChatSuggestions is experimental. The interface is not final and
can change without notice.

`useCopilotReadable` is a React hook that provides app-state and other information
to the Copilot. Optionally, the hook can also handle hierarchical state within your
application, passing these parent-child relationships to the Copilot.

![](https://docs.copilotkit.ai/images/use-copilot-chat-suggestions/use-copilot-chat-suggestions.gif)

## [Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions\#usage)

### [Install Dependencies](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions\#install-dependencies)

This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.

```
npm install @copilotkit/react-core @copilotkit/react-ui
```

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions\#simple-usage)

```
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";

export function MyComponent() {
  const [employees, setEmployees] = useState([]);

  useCopilotChatSuggestions({
    instructions: `The following employees are on duty: ${JSON.stringify(employees)}`,
  });
}
```

### [Dependency Management](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions\#dependency-management)

```
import { useCopilotChatSuggestions } from "@copilotkit/react-ui";

export function MyComponent() {
  useCopilotChatSuggestions(
    {
      instructions: "Suggest the most relevant next actions.",
    },
    [appState],
  );
}
```

In the example above, the suggestions are generated based on the given instructions.
The hook monitors `appState`, and updates suggestions accordingly whenever it changes.

### [Behavior and Lifecycle](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions\#behavior-and-lifecycle)

The hook registers the configuration with the chat context upon component mount and
removes it on unmount, ensuring a clean and efficient lifecycle management.

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions\#parameters)

instructionsstringrequired

A prompt or instructions for the GPT to generate suggestions.

minSuggestionsnumber

Default:"1"

The minimum number of suggestions to generate. Defaults to `1`.

maxSuggestionsnumber

Default:"1"

The maximum number of suggestions to generate. Defaults to `3`.

available'enabled' \| 'disabled'

Default:"enabled"

Whether the suggestions are available. Defaults to `enabled`.

classNamestring

An optional class name to apply to the suggestions.

[Previous\\
\\
useCopilotChat](https://docs.copilotkit.ai/reference/hooks/useCopilotChat) [Next\\
\\
useCoAgent](https://docs.copilotkit.ai/reference/hooks/useCoAgent)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions#usage) [Install Dependencies](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions#install-dependencies) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions#simple-usage) [Dependency Management](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions#dependency-management) [Behavior and Lifecycle](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions#behavior-and-lifecycle) [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useCopilotChatSuggestions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Anonymous Telemetry Management
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageHow to opt out of anonymous telemetry

# Anonymous Telemetry

We use anonymous telemetry (metadata-only) to learn how to improve CopilotKit.

- Open-source telemetry is **completely anonymous**
- We **do not collect any data** about end-users (the users interacting with your copilot)
- We **do not collect any application data** flowing through your system, only CopilotKit metadata
- We do not sell or share any data with third parties
- We do not use cookies or trackers in open-source telemetry
- To minimize the frequency of data sent, we apply batching and sampling to telemetry

## [How to opt out of anonymous telemetry](https://docs.copilotkit.ai/telemetry\#how-to-opt-out-of-anonymous-telemetry)

You can opt out of open-source telemetry in multiple ways.

In CopilotRuntime, simply set `COPILOTKIT_TELEMETRY_DISABLED=true`. We also respect [Do Not Track (DNT)](https://consoledonottrack.com/).

Alternatively, you can directly set the `telemetryDisabled` flag to `true` when configuring your Copilot Runtime endpoint.

## [How to adjust telemetry sample rate](https://docs.copilotkit.ai/telemetry\#how-to-adjust-telemetry-sample-rate)

The default sample rate is `0.05` (5%). You can adjust it by setting the `COPILOTKIT_TELEMETRY_SAMPLE_RATE` to any value between 0 and 1.

## [Get in touch](https://docs.copilotkit.ai/telemetry\#get-in-touch)

If you have any questions or concerns, please reach out at [hello@copilotkit.ai](mailto:hello@copilotkit.ai).

[Previous\\
\\
Documentation Contributions](https://docs.copilotkit.ai/contributing/docs-contributions) [Next\\
\\
LangSmith](https://docs.copilotkit.ai/observability/langsmith)

### On this page

[How to opt out of anonymous telemetry](https://docs.copilotkit.ai/telemetry#how-to-opt-out-of-anonymous-telemetry) [How to adjust telemetry sample rate](https://docs.copilotkit.ai/telemetry#how-to-adjust-telemetry-sample-rate) [Get in touch](https://docs.copilotkit.ai/telemetry#get-in-touch)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/(other)/telemetry/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Shared State Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is shared state?

# Shared State

Create a two-way connection between your UI and agent state.

![Shared State Demo](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Fcoagents%2FSharedStateCoAgents.gif&w=3840&q=75)

This video demonstrates the [Research Canvas](https://docs.copilotkit.ai/coagents/examples/research-canvas) utilizing shared state.

## [What is shared state?](https://docs.copilotkit.ai/coagents/shared-state\#what-is-shared-state)

CoAgents maintain a shared state that seamlessly connects your UI with the agent's execution. This shared state system allows you to:

- Display the agent's current progress and intermediate results
- Update the agent's state through UI interactions
- React to state changes in real-time across your application

![Agentic Copilot State Diagram](https://docs.copilotkit.ai/images/coagents/coagents-state-diagram.png)

The foundation of this system is built on LangGraph's stateful architecture. Unlike traditional LangChains, LangGraphs maintain their
internal state throughout execution, which you can access via the `useCoAgentState` hook.

## [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state\#when-should-i-use-this)

State streaming is perfect when you want to faciliate collaboration between your agent and the user. Any state that your LangGraph agent
persists will be automatically shared by the UI. Similarly, any state that the user updates in the UI will be automatically reflected

This allows for a consistent experience where both the agent and the user are on the same page.

[Previous\\
\\
Node-based](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow) [Next\\
\\
Reading agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read)

### On this page

[What is shared state?](https://docs.copilotkit.ai/coagents/shared-state#what-is-shared-state) [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state#when-should-i-use-this)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/shared-state/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

![Shared State Demo](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Fcoagents%2FSharedStateCoAgents.gif&w=3840&q=75)

## Frontend Actions Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageLet the Copilot Take Action

# Frontend Actions

Learn how to enable your Copilot to take actions in the frontend.

# [Let the Copilot Take Action](https://docs.copilotkit.ai/guides/frontend-actions\#let-the-copilot-take-action)

### [`useCopilotAction`](https://docs.copilotkit.ai/guides/frontend-actions\#usecopilotaction)

In addition to understanding state, you can empower the copilot to take actions. Use the [`useCopilotAction`](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) hook to define specific tasks that the copilot can perform based on user input.

YourComponent.tsx

```
"use client" // only necessary if you are using Next.js with the App Router.
import { useCopilotAction } from "@copilotkit/react-core";

export function MyComponent() {
  const [todos, setTodos] = useState<string[]>([]);

  // Define Copilot action
  useCopilotAction({
    name: "addTodoItem",
    description: "Add a new todo item to the list",
    parameters: [\
      {\
        name: "todoText",\
        type: "string",\
        description: "The text of the todo item to add",\
        required: true,\
      },\
    ],
    handler: async ({ todoText }) => {
      setTodos([...todos, todoText]);
    },
  });

  return (
    <ul>
      {todos.map((todo, index) => (
        <li key={index}>{todo}</li>
      ))}
    </ul>
  );
}
```

### Changing where/when the action is executed

### [Specify `"use client"` (Next.js App Router)](https://docs.copilotkit.ai/guides/frontend-actions\#specify-use-client-nextjs-app-router)

This is only necessary if you are using Next.js with the App Router.

YourComponent.tsx

```
"use client"
```

Like other React hooks such as `useState` and `useEffect`, this is a **client-side** hook.
If you're using Next.js with the App Router, you'll need to add the `"use client"` directive at the top of any file using this hook.

### [Test it out!](https://docs.copilotkit.ai/guides/frontend-actions\#test-it-out)

After defining the action, ask the copilot to perform the task. For example, you can now ask the copilot to "select an employee" by specifying the `employeeId`.

![Example of Copilot action](https://docs.copilotkit.ai/images/copilot-action-example.gif)

## [Next Steps](https://docs.copilotkit.ai/guides/frontend-actions\#next-steps)

[**useCopilotAction Reference** \\
Refer to the documentation for the useCopilotAction hook.](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) [**Actions + Generative UI** \\
Learn how to render custom UI components alongside your actions, directly in the CopilotKit chat window.](https://docs.copilotkit.ai/guides/generative-ui) [**Backend Actions** \\
Enable backend services to trigger actions via copilot backend hooks.](https://docs.copilotkit.ai/guides/backend-actions)

[Previous\\
\\
Generative UI](https://docs.copilotkit.ai/guides/generative-ui) [Next\\
\\
Backend Actions & Agents](https://docs.copilotkit.ai/guides/backend-actions)

### On this page

[Let the Copilot Take Action](https://docs.copilotkit.ai/guides/frontend-actions#let-the-copilot-take-action) [useCopilotAction](https://docs.copilotkit.ai/guides/frontend-actions#usecopilotaction) [Test it out!](https://docs.copilotkit.ai/guides/frontend-actions#test-it-out) [Next Steps](https://docs.copilotkit.ai/guides/frontend-actions#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/frontend-actions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Common Issues
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageI am getting network errors / API not found error

# Common Issues

Common issues you may encounter when using Copilots.

Welcome to the CopilotKit Troubleshooting Guide! Here, you can find answers to common issues

Have an issue not listed here? Open a ticket on [GitHub](https://github.com/CopilotKit/CopilotKit/issues) or reach out on [Discord](https://discord.com/invite/6dffbvGU3D)
and we'll be happy to help.

We also highly encourage any open source contributors that want to add their own troubleshooting issues to [Github as a pull request](https://github.com/CopilotKit/CopilotKit/blob/main/CONTRIBUTING.md).

## [I am getting network errors / API not found error](https://docs.copilotkit.ai/troubleshooting/common-issues\#i-am-getting-network-errors--api-not-found-error)

If you're encountering network or API errors, here's how to troubleshoot:

### Check your endpoint configuration

### localhost vs 127.0.0.1

### Verify your backend is running

## [I am getting "CopilotKit's Remote Endpoint" not found error](https://docs.copilotkit.ai/troubleshooting/common-issues\#i-am-getting-copilotkits-remote-endpoint-not-found-error)

If you're getting a "CopilotKit's Remote Endpoint not found" error, it usually means the server serving `/info` endpoint isn't accessible. Here's how to fix it:

### Check your FastAPI setup (if using python's FastAPI)

### Test your endpoint

## [Connection issues with tunnel creation](https://docs.copilotkit.ai/troubleshooting/common-issues\#connection-issues-with-tunnel-creation)

If you notice the tunnel creation process spinning indefinitely, your router or ISP might be blocking the connection to CopilotKit's tunnel service.

### Router or ISP blocking tunnel connections

[Previous\\
\\
State Machines](https://docs.copilotkit.ai/cookbook/state-machine) [Next\\
\\
Migrate to 1.8.2](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2)

### On this page

[I am getting network errors / API not found error](https://docs.copilotkit.ai/troubleshooting/common-issues#i-am-getting-network-errors--api-not-found-error) [I am getting "CopilotKit's Remote Endpoint" not found error](https://docs.copilotkit.ai/troubleshooting/common-issues#i-am-getting-copilotkits-remote-endpoint-not-found-error) [Connection issues with tunnel creation](https://docs.copilotkit.ai/troubleshooting/common-issues#connection-issues-with-tunnel-creation)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/troubleshooting/common-issues.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagePrerequisites

# Quickstart (LangGraph)

Turn your LangGraph into an agent-native application in 10 minutes.

## [Prerequisites](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#prerequisites)

Before you begin, you'll need the following:

- [**LangSmith API key**](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key#api-keys)
- [**OpenAI API key**](https://platform.openai.com/api-keys)

## [Getting started](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#getting-started)

### [Install CopilotKit](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#install-copilotkit)

First, install the latest packages for CopilotKit into your frontend.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

Do you already have a LangGraph agent?

You will need a LangGraph agent to get started with CoAgents!

Either bring your own or feel free to use our starter repo.

Bring your own LangGraph agent

I already have a LangGraph agent and want to use it with CopilotKit.

![CopilotKit Logo](https://docs.copilotkit.ai/images/copilotkit-logo.svg)

Use the CoAgents Starter repo

I don't have a LangGraph agent yet, but want to get started quickly.

### [Start your LangGraph Agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#start-your-langgraph-agent)

Local (LangGraph Studio)Self hosted (FastAPI)LangGraph Platform

For local development, you can use the [LangGraph CLI](https://langchain-ai.github.io/langgraph/cloud/reference/cli/) to start a development server and LangGraph studio session.

You will need a [LangSmith account](https://smith.langchain.com/) to use this method.

```
# For Python 3.11 or above
langgraph dev --host localhost --port 8000
```

```
# For TypeScript with Node 18 or above
npx @langchain/langgraph-cli dev --host localhost --port 8000
```

After starting the LangGraph server, the deployment URL will be `http://localhost:8000`.

### Having trouble?

Choose your connection method

Now you need to connect your LangGraph agent to CopilotKit.

Copilot Cloud (Recommended)

I want to host my Copilot on Copilot Cloud

Self-Hosted Copilot Runtime

I want to self-host the Copilot Runtime

### [Add a remote endpoint for your LangGraph agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#add-a-remote-endpoint-for-your-langgraph-agent)

Using Copilot Cloud, you need to connect a remote endpoint that will connect to your LangGraph agent.

Local (LangGraph Studio)Self hosted (FastAPI)LangGraph Platform

When running your LangGraph agent locally, you can open a tunnel to it so Copilot Cloud can connect to it.
First, make sure you're logged in to [Copilot Cloud](https://cloud.copilotkit.ai/), and then authenticate the CLI by running:

```
npx copilotkit@latest login
```

Once authenticated, run:

```
npx copilotkit@latest dev --port 8000
```

### [Setup your CopilotKit provider](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#setup-your-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

Since we're using Copilot CLoud, we need to grab our public API key from the [Copilot Cloud dashboard](https://cloud.copilotkit.ai/).

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit
          publicApiKey="<your-copilot-cloud-public-api-key>"
          agent="sample_agent" // the name of the agent you want to use
        >
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

Looking for a way to run multiple LangGraph agents? Check out our [Multi-Agent](https://docs.copilotkit.ai/coagents/multi-agent-flows) guide.

## [Choose a Copilot UI](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#choose-a-copilot-ui)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

`CopilotPopup` is a convenience wrapper for `CopilotChat` that lives at the same level as your main content in the view hierarchy. It provides **a floating chat interface** that can be toggled on and off.

![Popup Example](https://docs.copilotkit.ai/images/popup-example.gif)

```
import { CopilotPopup } from "@copilotkit/react-ui";

export function YourApp() {
  return (
    <>
      <YourMainContent />
      <CopilotPopup
        instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
        labels={{
          title: "Popup Assistant",
          initial: "Need any help?",
        }}
      />
    </>
  );
}
```

### [🎉 Talk to your agent!](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#-talk-to-your-agent)

Congrats! You've successfully integrated a LangGraph agent chatbot to your application. To start, try asking a few questions to your agent.

```
Can you tell me a joke?
```

```
Can you help me understand AI?
```

```
What do you think about React?
```

### Having trouble?

* * *

## [What's next?](https://docs.copilotkit.ai/coagents/quickstart/langgraph\#whats-next)

You've now got a LangGraph agent running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

[**Implement Human in the Loop** \\
Allow your users and agents to collaborate together on tasks.](https://docs.copilotkit.ai/coagents/human-in-the-loop) [**Utilize the Shared State** \\
Learn how to synchronize your agent's state with your UI's state, and vice versa.](https://docs.copilotkit.ai/coagents/shared-state) [**Add some generative UI** \\
Render your agent's progress and output in the UI.](https://docs.copilotkit.ai/coagents/generative-ui) [**Setup frontend actions** \\
Give your agent the ability to call frontend tools, directly updating your application.](https://docs.copilotkit.ai/coagents/frontend-actions)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/coagents) [Next\\
\\
Chat with an Agent](https://docs.copilotkit.ai/coagents/agentic-chat-ui)

### On this page

[Prerequisites](https://docs.copilotkit.ai/coagents/quickstart/langgraph#prerequisites) [Getting started](https://docs.copilotkit.ai/coagents/quickstart/langgraph#getting-started) [Install CopilotKit](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-copilotkit) [Clone the coagents-starter repo and install dependencies:](https://docs.copilotkit.ai/coagents/quickstart/langgraph#clone-the-coagents-starter-repo-and-install-dependencies) [Install dependencies:](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-dependencies) [Install dependencies:](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-dependencies-1) [Create a .env file](https://docs.copilotkit.ai/coagents/quickstart/langgraph#create-a-env-file) [Add your API keys](https://docs.copilotkit.ai/coagents/quickstart/langgraph#add-your-api-keys) [Start your LangGraph Agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph#start-your-langgraph-agent) [Add a remote endpoint for your LangGraph agent](https://docs.copilotkit.ai/coagents/quickstart/langgraph#add-a-remote-endpoint-for-your-langgraph-agent) [Setup your CopilotKit provider](https://docs.copilotkit.ai/coagents/quickstart/langgraph#setup-your-copilotkit-provider) [Install Copilot Runtime](https://docs.copilotkit.ai/coagents/quickstart/langgraph#install-copilot-runtime) [Setup a Copilot Runtime Endpoint](https://docs.copilotkit.ai/coagents/quickstart/langgraph#setup-a-copilot-runtime-endpoint) [Add your LangGraph deployment to Copilot Runtime](https://docs.copilotkit.ai/coagents/quickstart/langgraph#add-your-langgraph-deployment-to-copilot-runtime) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/coagents/quickstart/langgraph#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/coagents/quickstart/langgraph#choose-a-copilot-ui) [🎉 Talk to your agent!](https://docs.copilotkit.ai/coagents/quickstart/langgraph#-talk-to-your-agent) [What's next?](https://docs.copilotkit.ai/coagents/quickstart/langgraph#whats-next)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/quickstart/langgraph.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph Framework Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCoAgents and LangGraph

# LangGraph

An agentic framework for building LLM applications that can be used with Copilotkit.

![CoAgents High Level Overview](https://docs.copilotkit.ai/images/coagents/coagents-highlevel-overview.png)

LangGraph is an agentic framework for building LLM applications that can be used with Copilotkit. It is built on top of LangChain's
[LangGraph](https://langchain-ai.github.io/langgraph/) library and extends it with additional functionality for building agentic
applications.

## [CoAgents and LangGraph](https://docs.copilotkit.ai/coagents/concepts/langgraph\#coagents-and-langgraph)

How do CoAgents extend LangGraph? Let's read the first sentence of their [project page](https://langchain-ai.github.io/langgraph/) to understand.

> LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.

There are some key terms here so let's break them down and understand how they relate to and are implemented by CoAgents.

- **Stateful**: CoAgents have bi-directional state sharing with the agent and UI. This allows for the agent to remember
information from previous messages and the UI to update the agent with new information. Read more about how state sharing works
[here](https://docs.copilotkit.ai/coagents/shared-state).
- **Multi-actor**: CoAgents allow for multiple agents to interact with each other. Copilotkit acts as the "ground-truth"
when transitioning between agents. Read more about how multi-actor workflows work [here](https://docs.copilotkit.ai/coagents/multi-agent-flows)
and how messages are managed [here](https://docs.copilotkit.ai/coagents/concepts/message-management).
- **LLMs**: CoAgents use large language models to generate responses. This is useful for building applications that need to
generate natural language responses.

Some additional functionality not mentioned here is:

- **Human in the loop**: CoAgents enabled human review and approval of generated responses. Read more about how this works
[here](https://docs.copilotkit.ai/coagents/human-in-the-loop).
- **Tool calling**: Tool calling is a fundamental building block for agentic workflows. They allow for greater control over what
the agent can do and can be used to interact with external systems. CoAgents allow you to easily render in-progress
tool calls in the UI so your users know what's happening. Read more about streaming tool calls [here](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates).

## [Building with Python or JavaScript](https://docs.copilotkit.ai/coagents/concepts/langgraph\#building-with-python-or-javascript)

You can natively build LangGraph applications using Python or JavaScript. Throughout our documentation of integrating with LangGraph
you will see options for building in Python or JavaScript.

For a quick refresher on each, check out the [Python](https://langchain-ai.github.io/langgraph) and
[JavaScript](https://langchain-ai.github.io/langgraphjs/) guides from LangGraph:

## [LangGraph Platform](https://docs.copilotkit.ai/coagents/concepts/langgraph\#langgraph-platform)

LangGraph Platform is a platform for building and deploying LangGraph applications. It is built on top of the LangGraph library and
allows you to build, manage, and deploy graphs that Copilotkit can interface with. For more information checkout the official
[LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform) documentation.

If you want to take the next step to deploy your LangGraph application as an CoAgent, check out our [quickstart guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph).

[Previous\\
\\
Agentic Copilots](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots) [Next\\
\\
Message flow](https://docs.copilotkit.ai/coagents/concepts/message-management)

### On this page

[CoAgents and LangGraph](https://docs.copilotkit.ai/coagents/concepts/langgraph#coagents-and-langgraph) [Building with Python or JavaScript](https://docs.copilotkit.ai/coagents/concepts/langgraph#building-with-python-or-javascript) [LangGraph Platform](https://docs.copilotkit.ai/coagents/concepts/langgraph#langgraph-platform)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/concepts/langgraph.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Backend Actions Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Backend Actions & Agents

Learn how to enable backend actions & agents in your Copilot.

[**TypeScript / Node.js Actions** \\
Implement backend actions using TypeScript or Node.js within the CopilotRuntime.](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions) [**LangChain.js Actions** \\
Integrate LangChain JS chains as backend actions in your Copilot.](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions) [**LangServe Integration** \\
Connect your Copilot to LangChain chains hosted as separate services.](https://docs.copilotkit.ai/guides/backend-actions/langserve-backend-actions) [**Python SDK** \\
Use the CopilotKit Python SDK to create powerful remote actions and agents.](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint) [**CoAgents (LangGraph)** \\
Deeply embed LangGraph agents in applications](https://docs.copilotkit.ai/coagents)

[Previous\\
\\
Frontend Actions](https://docs.copilotkit.ai/guides/frontend-actions) [Next\\
\\
TypeScript (Node.js)](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/backend-actions/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agent State Rendering
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useCoAgentStateRender

The useCoAgentStateRender hook allows you to render the state of the agent in the chat.

The useCoAgentStateRender hook allows you to render UI or text based components on a Agentic Copilot's state in the chat.
This is particularly useful for showing intermediate state or progress during Agentic Copilot operations.

## [Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender\#usage)

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender\#simple-usage)

```
import { useCoAgentStateRender } from "@copilotkit/react-core";

type YourAgentState = {
  agent_state_property: string;
}

useCoAgentStateRender<YourAgentState>({
  name: "basic_agent",
  nodeName: "optionally_specify_a_specific_node",
  render: ({ status, state, nodeName }) => {
    return (
      <YourComponent
        agentStateProperty={state.agent_state_property}
        status={status}
        nodeName={nodeName}
      />
    );
  },
});
```

This allows for you to render UI components or text based on what is happening within the agent.

### [Example](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender\#example)

A great example of this is in our Perplexity Clone where we render the progress of an agent's internet search as it is happening.
You can play around with it below or learn how to build it with its [demo](https://docs.copilotkit.ai/coagents/videos/perplexity-clone).

This example is hosted on Vercel and may take a few seconds to load.

AI Researcher

# What would you like to know?

0 / 250

Research

🚙Electric cars sold in 2024 vs 2023

💰Top 10 richest people in the world

🌍 Population of the World

⛅️Weather in Seattle VS New York

OpenAI

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender\#parameters)

namestringrequired

The name of the coagent.

nodeNamestring

The node name of the coagent.

handler(props: CoAgentStateRenderHandlerArguments<T>) => void \| Promise<void>

The handler function to handle the state of the agent.

render\| ((props: CoAgentStateRenderProps<T>) => string \| React.ReactElement \| undefined \| null) \| string

The render function to handle the state of the agent.

[Previous\\
\\
useCoAgent](https://docs.copilotkit.ai/reference/hooks/useCoAgent) [Next\\
\\
useLangGraphInterrupt](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender#usage) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender#simple-usage) [Example](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender#example) [Parameters](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useCoAgentStateRender.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## useCopilotReadable Hook
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useCopilotReadable

The useCopilotReadable hook allows you to provide knowledge to your copilot (e.g. application state).

`useCopilotReadable` is a React hook that provides app-state and other information
to the Copilot. Optionally, the hook can also handle hierarchical state within your
application, passing these parent-child relationships to the Copilot.

## [Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable\#usage)

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable\#simple-usage)

In its most basic usage, useCopilotReadable accepts a single string argument
representing any piece of app state, making it available for the Copilot to use
as context when responding to user input.

```
import { useCopilotReadable } from "@copilotkit/react-core";

export function MyComponent() {
  const [employees, setEmployees] = useState([]);

  useCopilotReadable({
    description: "The list of employees",
    value: employees,
  });
}
```

### [Nested Components](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable\#nested-components)

Optionally, you can maintain the hierarchical structure of information by passing
`parentId`. This allows you to use `useCopilotReadable` in nested components:

```
import { useCopilotReadable } from "@copilotkit/react-core";

function Employee(props: EmployeeProps) {
  const { employeeName, workProfile, metadata } = props;

  // propagate any information to copilot
  const employeeContextId = useCopilotReadable({
    description: "Employee name",
    value: employeeName
  });

  // Pass a parentID to maintain a hierarchical structure.
  // Especially useful with child React components, list elements, etc.
  useCopilotReadable({
    description: "Work profile",
    value: workProfile.description(),
    parentId: employeeContextId
  });

  useCopilotReadable({
    description: "Employee metadata",
    value: metadata.description(),
    parentId: employeeContextId
  });

  return (
    // Render as usual...
  );
}
```

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable\#parameters)

descriptionstringrequired

The description of the information to be added to the Copilot context.

valueanyrequired

The value to be added to the Copilot context. Object values are automatically stringified.

parentIdstring

The ID of the parent context, if any.

categoriesstring\[\]

An array of categories to control which context are visible where. Particularly useful
with CopilotTextarea (see `useMakeAutosuggestionFunction`)

available'enabled' \| 'disabled'

Whether the context is available to the Copilot.

convert(description: string, value: any) => string

A custom conversion function to use to serialize the value to a string. If not provided, the value
will be serialized using `JSON.stringify`.

[Previous\\
\\
CopilotKit](https://docs.copilotkit.ai/reference/components/CopilotKit) [Next\\
\\
useCopilotAction](https://docs.copilotkit.ai/reference/hooks/useCopilotAction)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable#usage) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable#simple-usage) [Nested Components](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable#nested-components) [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useCopilotReadable.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotPopup Component
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall Dependencies

[Chat Components](https://docs.copilotkit.ai/reference/components/chat)

# CopilotPopup

The CopilotPopup component, providing a popup interface for interacting with your copilot.

![](https://docs.copilotkit.ai/images/CopilotPopup.gif)

A chatbot popup component for the CopilotKit framework. The component allows for a high degree
of customization through various props and custom CSS.

See [CopilotSidebar](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar) for a sidebar version of this component.

## [Install Dependencies](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup\#install-dependencies)

This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.

```
npm install @copilotkit/react-core @copilotkit/react-ui
```

## [Usage](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup\#usage)

```
import { CopilotPopup } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

<CopilotPopup
  labels={{
    title: "Your Assistant",
    initial: "Hi! 👋 How can I assist you today?",
  }}
/>
```

### [Look & Feel](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup\#look--feel)

By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:

YourRootComponent.tsx

```
...
import "@copilotkit/react-ui/styles.css";

export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```

For more information about how to customize the styles, check out the [Customize Look & Feel](https://docs.copilotkit.ai/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## [Properties](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup\#properties)

instructionsstring

Custom instructions to be added to the system message. Use this property to
provide additional context or guidance to the language model, influencing
its responses. These instructions can include specific directions,
preferences, or criteria that the model should consider when generating
its output, thereby tailoring the conversation more precisely to the
user's needs or the application's requirements.

onInProgress(inProgress: boolean) => void

A callback that gets called when the in progress state changes.

onSubmitMessage(message: string) => void \| Promise<void>

A callback that gets called when a new message it submitted.

onStopGenerationOnStopGeneration

A custom stop generation function.

onReloadMessagesOnReloadMessages

A custom reload messages function.

onRegenerate(messageId: string) => void

A callback function to regenerate the assistant's response

onCopy(message: string) => void

A callback function when the message is copied

onThumbsUp(message: string) => void

A callback function for thumbs up feedback

onThumbsDown(message: string) => void

A callback function for thumbs down feedback

iconsCopilotChatIcons

Icons can be used to set custom icons for the chat window.

labelsCopilotChatLabels

Labels can be used to set custom labels for the chat window.

makeSystemMessageSystemMessageFunction

A function that takes in context string and instructions and returns
the system message to include in the chat request.
Use this to completely override the system message, when providing
instructions is not enough.

AssistantMessageReact.ComponentType<AssistantMessageProps>

A custom assistant message component to use instead of the default.

UserMessageReact.ComponentType<UserMessageProps>

A custom user message component to use instead of the default.

MessagesReact.ComponentType<MessagesProps>

A custom Messages component to use instead of the default.

RenderTextMessageReact.ComponentType<RenderMessageProps>

A custom RenderTextMessage component to use instead of the default.

RenderActionExecutionMessageReact.ComponentType<RenderMessageProps>

A custom RenderActionExecutionMessage component to use instead of the default.

RenderAgentStateMessageReact.ComponentType<RenderMessageProps>

A custom RenderAgentStateMessage component to use instead of the default.

RenderResultMessageReact.ComponentType<RenderMessageProps>

A custom RenderResultMessage component to use instead of the default.

InputReact.ComponentType<InputProps>

A custom Input component to use instead of the default.

classNamestring

A class name to apply to the root element.

childrenReact.ReactNode

Children to render.

defaultOpenboolean

Default:"false"

Whether the chat window should be open by default.

clickOutsideToCloseboolean

Default:"true"

If the chat window should close when the user clicks outside of it.

hitEscapeToCloseboolean

Default:"true"

If the chat window should close when the user hits the Escape key.

shortcutstring

Default:"'/'"

The shortcut key to open the chat window.
Uses Command-\[shortcut\] on a Mac and Ctrl-\[shortcut\] on Windows.

onSetOpen(open: boolean) => void

A callback that gets called when the chat window opens or closes.

WindowReact.ComponentType<WindowProps>

A custom Window component to use instead of the default.

ButtonReact.ComponentType<ButtonProps>

A custom Button component to use instead of the default.

HeaderReact.ComponentType<HeaderProps>

A custom Header component to use instead of the default.

[Previous\\
\\
CopilotChat](https://docs.copilotkit.ai/reference/components/chat/CopilotChat) [Next\\
\\
CopilotSidebar](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar)

### On this page

[Install Dependencies](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup#install-dependencies) [Usage](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup#usage) [Look & Feel](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup#look--feel) [Properties](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup#properties)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/components/chat/CopilotPopup.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CoAgents Troubleshooting
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageMy tool calls are not being streamed

# Common Issues

Common issues you may encounter when using CoAgents.

Welcome to the CoAgents Troubleshooting Guide! If you're having trouble getting tool calls to work, you've come to the right place.

Have an issue not listed here? Open a ticket on [GitHub](https://github.com/CopilotKit/CopilotKit/issues) or reach out on [Discord](https://discord.com/invite/6dffbvGU3D)
and we'll be happy to help.

We also highly encourage any open source contributors that want to add their own troubleshooting issues to [Github as a pull request](https://github.com/CopilotKit/CopilotKit/blob/main/CONTRIBUTING.md).

## [My tool calls are not being streamed](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues\#my-tool-calls-are-not-being-streamed)

This could be due to a few different reasons.

First, we strongly recommend checking out our [Human In the Loop](https://docs.copilotkit.ai/coagents/human-in-the-loop) guide to follow a more in depth example of how to stream tool calls
in your LangGraph agents. You can also check out our [travel tutorial](https://docs.copilotkit.ai/coagents/tutorials/ai-travel-app/step-6-human-in-the-loop) which talks about how to stream
tool calls in a more complex example.

If you have already done that, you can check the following:

### You have not specified the tool call in the \`copilotkit\_customize\_config\`

### You're using llm.invoke() instead of llm.ainvoke()

## [Error: `'AzureOpenAI' object has no attribute 'bind_tools'`](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues\#error-azureopenai-object-has-no-attribute-bind_tools)

This error is typically due to the use of an incorrect import from LangGraph. Instead of importing `AzureOpenAI` import `AzureChatOpenAI` and your
issue will be resolved.

```
from langchain_openai import AzureOpenAI
from langchain_openai import AzureChatOpenAI
```

## [I am getting "agent not found" error](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues\#i-am-getting-agent-not-found-error)

If you're seeing this error, it means CopilotKit couldn't find the LangGraph agent you're trying to use. Here's how to fix it:

### Verify your agent lock mode configuration

### Check your agent registration on a LangGraph Platform endpoint

### Check your agent name in useCoAgent

### Check your agent name in useCoAgentStateRender

## [Connection issues with tunnel creation](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues\#connection-issues-with-tunnel-creation)

If you notice the tunnel creation process spinning indefinitely, your router or ISP might be blocking the connection to CopilotKit's tunnel service.

### Router or ISP blocking tunnel connections

## [I am getting "Failed to find or contact remote endpoint at url, Make sure the API is running and that it's indeed a LangGraph platform url" error](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues\#i-am-getting-failed-to-find-or-contact-remote-endpoint-at-url-make-sure-the-api-is-running-and-that-its-indeed-a-langgraph-platform-url-error)

If you're seeing this error, it means the LangGraph platform client cannot connect to your endpoint.

### Verify the endpoint is reachable

### Verify running a LangGraph platform endpoint using LangGraph deployment tools

### Verify the remote endpoint matches the endpoint definition type

## [I see messages being streamed and disappear](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues\#i-see-messages-being-streamed-and-disappear)

LangGraph agents are stateful. As a graph is traversed, the state is saved at the end of each node. CopilotKit uses the agent's state as
the source of truth for what to display in the frontend chat. However, since state is only emitted at the end of a node, CopilotKit allows
you to stream predictive state updates _in the middle of a node_. By default, CopilotKit will stream messages and tool calls being actively
generated to the frontend chat that initiated the interaction. **If this predictive state is not persisted at the end of the node, it will**
**disappear in the frontend chat**.

In this situation, the most likely scenario is that the `messages` property in the state is being updated in the middle of a node but those edits are not being
persisted at the end of a node.

![](https://docs.copilotkit.ai/images/coagents/message-state-diagram.png)

### I want these messages to be persisted

### I don't want these messages to streamed at all

[Previous\\
\\
Message flow](https://docs.copilotkit.ai/coagents/concepts/message-management) [Next\\
\\
Migrate from v0.2 to v0.3](https://docs.copilotkit.ai/coagents/troubleshooting/migrate-from-v0.2-to-v0.3)

### On this page

[My tool calls are not being streamed](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues#my-tool-calls-are-not-being-streamed) [Error: 'AzureOpenAI' object has no attribute 'bind\_tools'](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues#error-azureopenai-object-has-no-attribute-bind_tools) [I am getting "agent not found" error](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues#i-am-getting-agent-not-found-error) [Connection issues with tunnel creation](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues#connection-issues-with-tunnel-creation) [I am getting "Failed to find or contact remote endpoint at url, Make sure the API is running and that it's indeed a LangGraph platform url" error](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues#i-am-getting-failed-to-find-or-contact-remote-endpoint-at-url-make-sure-the-api-is-running-and-that-its-indeed-a-langgraph-platform-url-error) [I see messages being streamed and disappear](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues#i-see-messages-being-streamed-and-disappear)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/troubleshooting/common-issues.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agentic Generative UI
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Generative UI](https://docs.copilotkit.ai/coagents/generative-ui)

# Agentic Generative UI

Render the state of your agent with custom UI components.

This video demonstrates the [implementation](https://docs.copilotkit.ai/coagents/generative-ui/agentic#implementation) section applied to out [coagents starter project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter).

## [What is this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#what-is-this)

All LangGraph agents are stateful. This means that as your agent progresses through nodes, a state object is passed between them perserving
the overall state of a session. CopilotKit allows you to render this state in your application with custom UI components, which we call **Agentic Generative UI**.

## [When should I use this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#when-should-i-use-this)

Rendering the state of your agent in the UI is useful when you want to provide the user with feedback about the overall state of a session. A great example of this
is a situation where a user and an agent are working together to solve a problem. The agent can store a draft in its state which is then rendered in the UI.

## [Implementation](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#implementation)

### [Run and Connect your LangGraph to CopilotKit](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#run-and-connect-your-langgraph-to-copilotkit)

First, you'll need to make sure you have a running LangGraph. If you haven't already done this, you can follow the [getting started guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph)

This guide uses the [CoAgents starter repo](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) as its starting point.

### [Define your agent state](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#define-your-agent-state)

If you're not familiar with LangGraph, your graphs are stateful. As you progress through nodes, a state object is passed between them. CopilotKit
allows you to easily render this state in your application.

For the sake of this guide, let's say our state looks like this in our agent.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
# ...
from copilotkit import CopilotKitState # extends MessagesState
# ...

# This is the state of the agent.
# It inherits from the CopilotKitState properties from CopilotKit.
class AgentState(CopilotKitState):
    searches: list[dict]
```

### [Simulate state updates](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#simulate-state-updates)

Next, let's write some logic into our agent that will simulate state updates occurring.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
import asyncio
from typing import TypedDict
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from copilotkit import CopilotKitState
from copilotkit.langgraph import copilotkit_emit_state

class Searches(TypedDict):
    query: str
    done: bool

class AgentState(CopilotKitState):
    searches: list[Searches] = []

async def chat_node(state: AgentState, config: RunnableConfig):
    state["searches"] = [\
        {"query": "Initial research", "done": False},\
        {"query": "Retrieving sources", "done": False},\
        {"query": "Forming an answer", "done": False},\
    ]
    await copilotkit_emit_state(config, state)

    # Simulate state updates
    for search in state["searches"]:
        await asyncio.sleep(1)
        search["done"] = True
        await copilotkit_emit_state(config, state)

    # Run the model to generate a response
    response = await ChatOpenAI(model="gpt-4o").ainvoke([\
        SystemMessage(content="You are a helpful assistant."),\
        *state["messages"],\
    ], config)
```

### [Render state of the agent in the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#render-state-of-the-agent-in-the-chat)

Now we can utilize `useCoAgentStateRender` to render the state of our agent **in the chat**.

app/page.tsx

```
// ...
import { useCoAgentStateRender } from "@copilotkit/react-core";
// ...

// Define the state of the agent, should match the state of the agent in your LangGraph.
type AgentState = {
  searches: {
    query: string;
    done: boolean;
  }[];
};

function YourMainContent() {
  // ...


  // styles omitted for brevity
  useCoAgentStateRender<AgentState>({
    name: "sample_agent", // the name the agent is served as
    render: ({ state }) => (
      <div>
        {state.searches?.map((search, index) => (
          <div key={index}>
            {search.done ? "✅" : "❌"} {search.query}{search.done ? "" : "..."}
          </div>
        ))}
      </div>
    ),
  });

  // ...

  return <div>...</div>;
}
```

### [Render state outside of the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#render-state-outside-of-the-chat)

You can also render the state of your agent **outside of the chat**. This is useful when you want to render the state of your agent anywhere
other than the chat.

app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";
// ...

// Define the state of the agent, should match the state of the agent in your LangGraph.
type AgentState = {
  searches: {
    query: string;
    done: boolean;
  }[];
};

function YourMainContent() {
  // ...


  const { state } = useCoAgent<AgentState>({
    name: "sample_agent", // the name the agent is served as
  })

  // ...

  return (
    <div>
      {/* ... */}
      <div className="flex flex-col gap-2 mt-4">

        {state.searches?.map((search, index) => (
          <div key={index} className="flex flex-row">
            {search.done ? "✅" : "❌"} {search.query}
          </div>
        ))}
      </div>
    </div>
  )
}
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#give-it-a-try)

You've now created a component that will render the agent's state in the chat.

[Previous\\
\\
Generative UI](https://docs.copilotkit.ai/coagents/generative-ui) [Next\\
\\
Tool-based Generative UI](https://docs.copilotkit.ai/coagents/generative-ui/tool-based)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/generative-ui/agentic#implementation) [Run and Connect your LangGraph to CopilotKit](https://docs.copilotkit.ai/coagents/generative-ui/agentic#run-and-connect-your-langgraph-to-copilotkit) [Define your agent state](https://docs.copilotkit.ai/coagents/generative-ui/agentic#define-your-agent-state) [Simulate state updates](https://docs.copilotkit.ai/coagents/generative-ui/agentic#simulate-state-updates) [Render state of the agent in the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic#render-state-of-the-agent-in-the-chat) [Render state outside of the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic#render-state-outside-of-the-chat) [Give it a try!](https://docs.copilotkit.ai/coagents/generative-ui/agentic#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/generative-ui/agentic.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agentic Copilots Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat are Agents?

# Agentic Copilots

Agentic copilots provide you with advanced control and orchestration over your agents.

Before we dive into what agentic copilots are, help us help you by telling us your level of experience with LangGraph. We'll explain things in a way that best suits your experience level.

![](https://docs.copilotkit.ai/images/copilotkit-logo.svg)

I'm new to LangGraph

Help me understand what agentic copilots are, where LangGraph fits in, and how to get started.

I'm already using LangGraph

Help me understand what agentic copilots are, what Copilotkit does to integrate with LangGraph, and how to get started.

![CoAgents Shared State](https://docs.copilotkit.ai/images/coagents/SharedStateCoAgents.gif)

### [What are Agents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#what-are-agents)

AI agents are intelligent systems that interact with their environment to achieve specific goals. Think of them as 'virtual colleagues' that can handle tasks ranging from
simple queries like "find the cheapest flight to Paris" to complex challenges like "design a new product layout."

As these AI-driven experiences (or 'Agentic Experiences') become more sophisticated, developers need finer control over how agents make decisions. This is where specialized
frameworks like LangGraph become essential.

### [What is LangGraph?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#what-is-langgraph)

LangGraph is a framework that gives you precise control over AI agents. It uses a graph-based approach where each step in an agent's decision-making process is represented
by a `node`. These nodes are connected by `edges` to form a directed acyclic graph (DAG), creating a clear map of possible actions and decisions.

The key advantage of LangGraph is its tight control over the agent's decision making process. Since all of this is defined in code by you, the behavior is much more
deterministic and predictable.

### [What are Agentic Copilots?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#what-are-agentic-copilots)

Agentic copilots are how CopilotKit brings LangGraph agents into your application. If you're familiar with CopilotKit, you know that copilots are AI assistants that
understand your app's context and can take actions within it. While CopilotKit's standard copilots use a simplified [ReAct pattern](https://www.perplexity.ai/search/what-s-a-react-agent-5hu7ZOaKSAuY7YdFjQLCNQ)
for quick implementation, Agentic copilots give you LangGraph's full orchestration capabilities when you need more control over your agent's behavior.

### [What are CoAgents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#what-are-coagents)

CoAgents are what we call CopilotKit's approach to building agentic experiences! They're interchangeable with agentic copilots being a more descriptive term for the overall concept.

### [When should I use CopilotKit's CoAgents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#when-should-i-use-copilotkits-coagents)

You should use CoAgents when you require tight control over the Agentic runloop, as facilitated by an Agentic Orchestration framework like [LangGraph](https://langchain-ai.github.io/langgraph/).
With CoAgents, you can carry all of your existing CopilotKit-enabled Copilot capabilities into a customized agentic runloop.

We suggest beginning with a basic Copilot and gradually transitioning specific components to CoAgents.

The need for CoAgents spans a broad spectrum across different applications. At one end, their advanced capabilities might not be required at all, or only for a minimal 10% of the application's
functionality. Progressing further, there are scenarios where they become increasingly vital, managing 60-70% of operations. Ultimately, in some cases, CoAgents are indispensable, orchestrating
up to 100% of the Copilot's tasks (see [agent-lock mode](https://docs.copilotkit.ai/coagents/multi-agent-flows) for the 100% case).

### [Examples](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#examples)

An excellent example of the type of experiences you can accomplish with CoAgents applications can be found in our [Research Canvas](https://docs.copilotkit.ai/coagents/videos/research-canvas).

More specifically, it demonstrates how CoAgents allow for AI driven experiences with:

- Precise state management across agent interactions
- Sophisticated multi-step reasoning capabilities
- Seamless orchestration of multiple AI tools
- Interactive human-AI collaboration features
- Real-time state updates and progress streaming

## [Next Steps](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots\#next-steps)

Want to get started? You have some options!

[**Build your first CoAgent** \\
Follow a step-by-step tutorial to build a travel app supercharged with CoAgents.](https://docs.copilotkit.ai/coagents/quickstart/langgraph) [**Learn more CoAgent concepts** \\
Learn more about the concepts used to talk about CoAgents and how to use them.](https://docs.copilotkit.ai/coagents/concepts/terminology) [**Read the reference documentation** \\
Just here for some reference? Checkout the reference documentation for more details.](https://docs.copilotkit.ai/reference) [**See examples of CoAgents in action** \\
Checkout our video examples of CoAgents in action.](https://docs.copilotkit.ai/coagents/videos/research-canvas)

[Previous\\
\\
Terminology](https://docs.copilotkit.ai/coagents/concepts/terminology) [Next\\
\\
LangGraph](https://docs.copilotkit.ai/coagents/concepts/langgraph)

### On this page

[What are Agents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#what-are-agents) [What is LangGraph?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#what-is-langgraph) [What are Agentic Copilots?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#what-are-agentic-copilots) [What are CoAgents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#what-are-coagents) [When should I use CopilotKit's CoAgents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#when-should-i-use-copilotkits-coagents) [Examples](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#examples) [Next Steps](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#next-steps) [What are CoAgents?](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#what-are-coagents-1) [Next Steps](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots#next-steps-1)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/concepts/agentic-copilots.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Connect Your Data
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Connecting Your Data

Learn how to connect your data to CopilotKit.

CopilotKit allows you to connect your data through the frontend and through the backend. This enables
a variety of use-cases from simple context to RAG-based LLM interactions.

[**Frontend Data** \\
Learn how to connect your data to CopilotKit on the frontend.](https://docs.copilotkit.ai/guides/connect-your-data/frontend) [**Backend Data** \\
Learn how to connect your data to CopilotKit on the backend.](https://docs.copilotkit.ai/guides/connect-your-data/backend)

[Previous\\
\\
Fully Headless UI](https://docs.copilotkit.ai/guides/custom-look-and-feel/headless-ui) [Next\\
\\
Frontend Data](https://docs.copilotkit.ai/guides/connect-your-data/frontend)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/connect-your-data/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotChat Component
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall Dependencies

[Chat Components](https://docs.copilotkit.ai/reference/components/chat)

# CopilotChat

The CopilotChat component, providing a chat interface for interacting with your copilot.

![](https://docs.copilotkit.ai/images/CopilotChat.gif)

A chatbot panel component for the CopilotKit framework. The component allows for a high degree
of customization through various props and custom CSS.

## [Install Dependencies](https://docs.copilotkit.ai/reference/components/chat/CopilotChat\#install-dependencies)

This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.

```
npm install @copilotkit/react-core @copilotkit/react-ui
```

## [Usage](https://docs.copilotkit.ai/reference/components/chat/CopilotChat\#usage)

```
import { CopilotChat } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

<CopilotChat
  labels={{
    title: "Your Assistant",
    initial: "Hi! 👋 How can I assist you today?",
  }}
/>
```

### [Look & Feel](https://docs.copilotkit.ai/reference/components/chat/CopilotChat\#look--feel)

By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:

YourRootComponent.tsx

```
...
import "@copilotkit/react-ui/styles.css";

export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```

For more information about how to customize the styles, check out the [Customize Look & Feel](https://docs.copilotkit.ai/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## [Properties](https://docs.copilotkit.ai/reference/components/chat/CopilotChat\#properties)

instructionsstring

Custom instructions to be added to the system message. Use this property to
provide additional context or guidance to the language model, influencing
its responses. These instructions can include specific directions,
preferences, or criteria that the model should consider when generating
its output, thereby tailoring the conversation more precisely to the
user's needs or the application's requirements.

onInProgress(inProgress: boolean) => void

A callback that gets called when the in progress state changes.

onSubmitMessage(message: string) => void \| Promise<void>

A callback that gets called when a new message it submitted.

onStopGenerationOnStopGeneration

A custom stop generation function.

onReloadMessagesOnReloadMessages

A custom reload messages function.

onRegenerate(messageId: string) => void

A callback function to regenerate the assistant's response

onCopy(message: string) => void

A callback function when the message is copied

onThumbsUp(message: string) => void

A callback function for thumbs up feedback

onThumbsDown(message: string) => void

A callback function for thumbs down feedback

iconsCopilotChatIcons

Icons can be used to set custom icons for the chat window.

labelsCopilotChatLabels

Labels can be used to set custom labels for the chat window.

makeSystemMessageSystemMessageFunction

A function that takes in context string and instructions and returns
the system message to include in the chat request.
Use this to completely override the system message, when providing
instructions is not enough.

AssistantMessageReact.ComponentType<AssistantMessageProps>

A custom assistant message component to use instead of the default.

UserMessageReact.ComponentType<UserMessageProps>

A custom user message component to use instead of the default.

MessagesReact.ComponentType<MessagesProps>

A custom Messages component to use instead of the default.

RenderTextMessageReact.ComponentType<RenderMessageProps>

A custom RenderTextMessage component to use instead of the default.

RenderActionExecutionMessageReact.ComponentType<RenderMessageProps>

A custom RenderActionExecutionMessage component to use instead of the default.

RenderAgentStateMessageReact.ComponentType<RenderMessageProps>

A custom RenderAgentStateMessage component to use instead of the default.

RenderResultMessageReact.ComponentType<RenderMessageProps>

A custom RenderResultMessage component to use instead of the default.

InputReact.ComponentType<InputProps>

A custom Input component to use instead of the default.

classNamestring

A class name to apply to the root element.

childrenReact.ReactNode

Children to render.

[Previous\\
\\
All Chat Components](https://docs.copilotkit.ai/reference/components/chat) [Next\\
\\
CopilotPopup](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup)

### On this page

[Install Dependencies](https://docs.copilotkit.ai/reference/components/chat/CopilotChat#install-dependencies) [Usage](https://docs.copilotkit.ai/reference/components/chat/CopilotChat#usage) [Look & Feel](https://docs.copilotkit.ai/reference/components/chat/CopilotChat#look--feel) [Properties](https://docs.copilotkit.ai/reference/components/chat/CopilotChat#properties)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/components/chat/CopilotChat.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAI Components Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

![CopilotKit Logo](https://docs.copilotkit.ai/images/copilotkit-logo.svg)

# Page Not Found

Oops! The page you're looking for doesn't exist.

[Go to Documentation](https://docs.copilotkit.ai/)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall CopilotKit

# Quickstart

Get started with CopilotKit in under 5 minutes.

Copilot Cloud (Recommended)

Use our hosted backend endpoint to get started quickly (OpenAI only).

Self-hosting

Learn to host CopilotKit's runtime yourself with your own backend.

## [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=Headless+UI\#install-copilotkit)

First, install the latest packages for CopilotKit.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

## [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=Headless+UI\#get-a-copilot-cloud-public-api-key)

Navigate to [Copilot Cloud](https://cloud.copilotkit.ai/) and follow the instructions to get a public API key - it's free!

## [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=Headless+UI\#setup-the-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit publicApiKey="<your-copilot-cloud-public-api-key>">
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

## [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=Headless+UI\#choose-a-copilot-ui)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

The built-in Copilot UI can be customized in many ways -- both through css and by passing in custom sub-components.

CopilotKit also offers **fully custom headless UI**, through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

```
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function CustomChatInterface() {
  const {
    visibleMessages,
    appendMessage,
    setMessages,
    deleteMessage,
    reloadMessages,
    stopGeneration,
    isLoading,
  } = useCopilotChat();

  const sendMessage = (content: string) => {
    appendMessage(new TextMessage({ content, role: Role.User }));
  };

  return (
    <div>
      {/* Implement your custom chat UI here */}
    </div>
  );
}
```

* * *

## [Next Steps](https://docs.copilotkit.ai/quickstart?component=Headless+UI\#next-steps)

🎉 Congrats! You've successfully integrated a fully functional chatbot in your application! Give it a try now and see it in action. Want to
take it further? Learn more about what CopilotKit has to offer!

[**Connecting Your Data** \\
Learn how to connect CopilotKit to your data, application state and user state.](https://docs.copilotkit.ai/guides/connect-your-data) [**Generative UI** \\
Learn how to render custom UI components directly in the CopilotKit chat window.](https://docs.copilotkit.ai/guides/generative-ui) [**Frontend Actions** \\
Learn how to allow your copilot to take applications on frontend.](https://docs.copilotkit.ai/guides/frontend-actions) [**CoAgents (LangGraph)** \\
Check out our section about CoAgents, our approach to building agentic copilots and experiences.](https://docs.copilotkit.ai/coagents)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/) [Next\\
\\
Customize UI](https://docs.copilotkit.ai/guides/custom-look-and-feel)

### On this page

[Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=Headless+UI#install-copilotkit) [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=Headless+UI#get-a-copilot-cloud-public-api-key) [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=Headless+UI#setup-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=Headless+UI#choose-a-copilot-ui) [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=Headless+UI#install-copilotkit-1) [Set up a Copilot Runtime Endpoint](https://docs.copilotkit.ai/quickstart?component=Headless+UI#set-up-a-copilot-runtime-endpoint) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=Headless+UI#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=Headless+UI#choose-a-copilot-ui-1) [Next Steps](https://docs.copilotkit.ai/quickstart?component=Headless+UI#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/quickstart.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph SDK Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagecopilotkit\_customize\_config

Python

# LangGraph SDK

The CopilotKit LangGraph SDK for Python allows you to build and run LangGraph workflows with CopilotKit.

## [copilotkit\_customize\_config](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#copilotkit_customize_config)

Customize the LangGraph configuration for use in CopilotKit.

To install the CopilotKit SDK, run:

```
pip install copilotkit
```

### [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#examples)

Disable emitting messages and tool calls:

```
from copilotkit.langgraph import copilotkit_customize_config

config = copilotkit_customize_config(
    config,
    emit_messages=False,
    emit_tool_calls=False
)
```

To emit a tool call as streaming LangGraph state, pass the destination key in state,
the tool name and optionally the tool argument. (If you don't pass the argument name,
all arguments are emitted under the state key.)

```
from copilotkit.langgraph import copilotkit_customize_config

config = copilotkit_customize_config(
    config,
    emit_intermediate_state=[\
       {\
            "state_key": "steps",\
            "tool": "SearchTool",\
            "tool_argument": "steps"\
        },\
    ]
)
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#parameters)

base\_configOptional\[RunnableConfig\]

The LangChain/LangGraph configuration to customize. Pass None to make a new configuration.

emit\_messagesOptional\[bool\]

Configure how messages are emitted. By default, all messages are emitted. Pass False to disable emitting messages.

emit\_tool\_callsOptional\[Union\[bool, str, List\[str\]\]\]

Configure how tool calls are emitted. By default, all tool calls are emitted. Pass False to disable emitting tool calls. Pass a string or list of strings to emit only specific tool calls.

emit\_intermediate\_stateOptional\[List\[IntermediateStateConfig\]\]

Lets you emit tool calls as streaming LangGraph state.

### [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#returns)

returnsRunnableConfig

The customized LangGraph configuration.

## [copilotkit\_exit](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#copilotkit_exit)

Exits the current agent after the run completes. Calling copilotkit\_exit() will
not immediately stop the agent. Instead, it signals to CopilotKit to stop the agent after
the run completes.

### [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#examples-1)

```
from copilotkit.langgraph import copilotkit_exit

def my_node(state: Any):
    await copilotkit_exit(config)
    return state
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#parameters-1)

configRunnableConfigrequired

The LangGraph configuration.

### [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#returns-1)

returnsAwaitable\[bool\]

Always return True.

## [copilotkit\_emit\_state](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#copilotkit_emit_state)

Emits intermediate state to CopilotKit. Useful if you have a longer running node and you want to
update the user with the current state of the node.

### [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#examples-2)

```
from copilotkit.langgraph import copilotkit_emit_state

for i in range(10):
    await some_long_running_operation(i)
    await copilotkit_emit_state(config, {"progress": i})
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#parameters-2)

configRunnableConfigrequired

The LangGraph configuration.

stateAnyrequired

The state to emit (Must be JSON serializable).

### [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#returns-2)

returnsAwaitable\[bool\]

Always return True.

## [copilotkit\_emit\_message](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#copilotkit_emit_message)

Manually emits a message to CopilotKit. Useful in longer running nodes to update the user.
Important: You still need to return the messages from the node.

### [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#examples-3)

```
from copilotkit.langgraph import copilotkit_emit_message

message = "Step 1 of 10 complete"
await copilotkit_emit_message(config, message)

# Return the message from the node
return {
    "messages": [AIMessage(content=message)]
}
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#parameters-3)

configRunnableConfigrequired

The LangGraph configuration.

messagestrrequired

The message to emit.

### [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#returns-3)

returnsAwaitable\[bool\]

Always return True.

## [copilotkit\_emit\_tool\_call](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#copilotkit_emit_tool_call)

Manually emits a tool call to CopilotKit.

```
from copilotkit.langgraph import copilotkit_emit_tool_call

await copilotkit_emit_tool_call(config, name="SearchTool", args={"steps": 10})
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#parameters-4)

configRunnableConfigrequired

The LangGraph configuration.

namestrrequired

The name of the tool to emit.

argsDict\[str, Any\]required

The arguments to emit.

### [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph\#returns-4)

returnsAwaitable\[bool\]

Always return True.

[Previous\\
\\
LangGraphAgent](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent) [Next\\
\\
CrewAIAgent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent)

### On this page

[copilotkit\_customize\_config](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#copilotkit_customize_config) [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#examples) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#parameters) [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#returns) [copilotkit\_exit](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#copilotkit_exit) [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#examples-1) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#parameters-1) [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#returns-1) [copilotkit\_emit\_state](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#copilotkit_emit_state) [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#examples-2) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#parameters-2) [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#returns-2) [copilotkit\_emit\_message](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#copilotkit_emit_message) [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#examples-3) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#parameters-3) [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#returns-3) [copilotkit\_emit\_tool\_call](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#copilotkit_emit_tool_call) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#parameters-4) [Returns](https://docs.copilotkit.ai/reference/sdk/python/LangGraph#returns-4)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/sdk/python/LangGraph.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Remote Endpoints
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCopilotKitRemoteEndpoint

Python

# Remote Endpoints

CopilotKit Remote Endpoints allow you to connect actions and agents written in Python to your CopilotKit application.

## [CopilotKitRemoteEndpoint](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#copilotkitremoteendpoint)

CopilotKitRemoteEndpoint lets you connect actions and agents written in Python to your
CopilotKit application.

To install CopilotKit for Python, run:

```
pip install copilotkit
# or to include crewai
pip install copilotkit[crewai]
```

## [Adding actions](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#adding-actions)

In this example, we provide a simple action to the Copilot:

```
from copilotkit import CopilotKitRemoteEndpoint, Action

sdk = CopilotKitRemoteEndpoint(
    actions=[\
        Action(\
            name="greet_user",\
            handler=greet_user_handler,\
            description="Greet the user",\
            parameters=[\
                {\
                    "name": "name",\
                    "type": "string",\
                    "description": "The name of the user"\
                }\
            ]\
        )\
    ]
)
```

You can also dynamically build actions by providing a callable that returns a list of actions.
In this example, we use "name" from the `properties` object to parameterize the action handler.

```
from copilotkit import CopilotKitRemoteEndpoint, Action

sdk = CopilotKitRemoteEndpoint(
    actions=lambda context: [\
        Action(\
            name="greet_user",\
            handler=make_greet_user_handler(context["properties"]["name"]),\
            description="Greet the user"\
        )\
    ]
)
```

Using the same approach, you can restrict the actions available to the Copilot:

```
from copilotkit import CopilotKitRemoteEndpoint, Action

sdk = CopilotKitRemoteEndpoint(
    actions=lambda context: (
        [action_a, action_b] if is_admin(context["properties"]["token"]) else [action_a]
    )
)
```

## [Adding agents](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#adding-agents)

Serving agents works in a similar way to serving actions:

```
from copilotkit import CopilotKitRemoteEndpoint, LangGraphAgent
from my_agent.agent import graph

sdk = CopilotKitRemoteEndpoint(
    agents=[\
        LangGraphAgent(\
            name="email_agent",\
            description="This agent sends emails",\
            graph=graph,\
        )\
    ]
)
```

To dynamically build agents, provide a callable that returns a list of agents:

```
from copilotkit import CopilotKitRemoteEndpoint, LangGraphAgent
from my_agent.agent import graph

sdk = CopilotKitRemoteEndpoint(
    agents=lambda context: [\
        LangGraphAgent(\
            name="email_agent",\
            description="This agent sends emails",\
            graph=graph,\
            langgraph_config={\
                "token": context["properties"]["token"]\
            }\
        )\
    ]
)
```

To restrict the agents available to the Copilot, simply return a different list of agents based on the `context`:

```
from copilotkit import CopilotKitRemoteEndpoint
from my_agents import agent_a, agent_b, is_admin

sdk = CopilotKitRemoteEndpoint(
    agents=lambda context: (
        [agent_a, agent_b] if is_admin(context["properties"]["token"]) else [agent_a]
    )
)
```

## [Serving the CopilotKit SDK](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#serving-the-copilotkit-sdk)

To serve the CopilotKit SDK, you can use the `add_fastapi_endpoint` function from the `copilotkit.integrations.fastapi` module:

```
from copilotkit.integrations.fastapi import add_fastapi_endpoint
from fastapi import FastAPI

app = FastAPI()
sdk = CopilotKitRemoteEndpoint(...)
add_fastapi_endpoint(app, sdk, "/copilotkit")

def main():
    uvicorn.run(
        "your_package:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
    )
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#parameters)

actionsOptional\[Union\[List\[Action\], Callable\[\[CopilotKitContext\], List\[Action\]\]\]\]

The actions to make available to the Copilot.

agentsOptional\[Union\[List\[Agent\], Callable\[\[CopilotKitContext\], List\[Agent\]\]\]\]

The agents to make available to the Copilot.

## [CopilotKitContext](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#copilotkitcontext)

CopilotKit Context

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints\#parameters-1)

propertiesAnyrequired

The properties provided to the frontend via `<CopilotKit properties={...} />`

frontend\_urlOptional\[str\]

The current URL of the frontend

headersMapping\[str, str\]required

The headers of the request

[Previous\\
\\
CopilotTask](https://docs.copilotkit.ai/reference/classes/CopilotTask) [Next\\
\\
LangGraphAgent](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent)

### On this page

[CopilotKitRemoteEndpoint](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#copilotkitremoteendpoint) [Adding actions](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#adding-actions) [Adding agents](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#adding-agents) [Serving the CopilotKit SDK](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#serving-the-copilotkit-sdk) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#parameters) [CopilotKitContext](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#copilotkitcontext) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints#parameters-1)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/sdk/python/RemoteEndpoints.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph SDK Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagecopilotkitCustomizeConfig

JavaScript

# LangGraph SDK

The CopilotKit LangGraph SDK for JavaScript allows you to build and run LangGraph workflows with CopilotKit.

## [copilotkitCustomizeConfig](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#copilotkitcustomizeconfig)

Customize the LangGraph configuration for use in CopilotKit.

To the CopilotKit SDK, run:

```
npm install @copilotkit/sdk-js
```

### [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#examples)

Disable emitting messages and tool calls:

```
import { copilotkitCustomizeConfig } from "@copilotkit/sdk-js";

config = copilotkitCustomizeConfig(
  config,
  emitMessages=false,
  emitToolCalls=false
)
```

To emit a tool call as streaming LangGraph state, pass the destination key in state,
the tool name and optionally the tool argument. (If you don't pass the argument name,
all arguments are emitted under the state key.)

```
import { copilotkitCustomizeConfig } from "@copilotkit/sdk-js";

config = copilotkitCustomizeConfig(
  config,
  emitIntermediateState=[\
    {\
      "stateKey": "steps",\
      "tool": "SearchTool",\
      "toolArgument": "steps",\
    },\
  ],
)
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#parameters)

baseConfigRunnableConfigrequired

The LangChain/LangGraph configuration to customize.

optionsOptionsConfig

Configuration options:

- `emitMessages: boolean?`
Configure how messages are emitted. By default, all messages are emitted. Pass false to
disable emitting messages.
- `emitToolCalls: boolean | string | string[]?`
Configure how tool calls are emitted. By default, all tool calls are emitted. Pass false to
disable emitting tool calls. Pass a string or list of strings to emit only specific tool calls.
- `emitIntermediateState: IntermediateStateConfig[]?`
Lets you emit tool calls as streaming LangGraph state.

## [copilotkitExit](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#copilotkitexit)

Exits the current agent after the run completes. Calling copilotkit\_exit() will
not immediately stop the agent. Instead, it signals to CopilotKit to stop the agent after
the run completes.

### [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#examples-1)

```
import { copilotkitExit } from "@copilotkit/sdk-js";

async function myNode(state: Any):
  await copilotkitExit(config)
  return state
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#parameters-1)

configRunnableConfigrequired

The LangChain/LangGraph configuration.

## [copilotkitEmitState](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#copilotkitemitstate)

Emits intermediate state to CopilotKit. Useful if you have a longer running node and you want to
update the user with the current state of the node.

### [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#examples-2)

```
import { copilotkitEmitState } from "@copilotkit/sdk-js";

for (let i = 0; i < 10; i++) {
  await someLongRunningOperation(i);
  await copilotkitEmitState(config, { progress: i });
}
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#parameters-2)

configRunnableConfigrequired

The LangChain/LangGraph configuration.

stateanyrequired

The state to emit.

## [copilotkitEmitMessage](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#copilotkitemitmessage)

Manually emits a message to CopilotKit. Useful in longer running nodes to update the user.
Important: You still need to return the messages from the node.

### [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#examples-3)

```
import { copilotkitEmitMessage } from "@copilotkit/sdk-js";

const message = "Step 1 of 10 complete";
await copilotkitEmitMessage(config, message);

// Return the message from the node
return {
  "messages": [AIMessage(content=message)]
}
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#parameters-3)

configRunnableConfigrequired

The LangChain/LangGraph configuration.

messagestringrequired

The message to emit.

## [copilotkitEmitToolCall](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#copilotkitemittoolcall)

Manually emits a tool call to CopilotKit.

### [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#examples-4)

```
import { copilotkitEmitToolCall } from "@copilotkit/sdk-js";

await copilotkitEmitToolCall(config, name="SearchTool", args={"steps": 10})
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph\#parameters-4)

configRunnableConfigrequired

The LangChain/LangGraph configuration.

namestringrequired

The name of the tool to emit.

argsanyrequired

The arguments to emit.

[Previous\\
\\
CrewAI SDK](https://docs.copilotkit.ai/reference/sdk/python/CrewAI)

### On this page

[copilotkitCustomizeConfig](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#copilotkitcustomizeconfig) [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#examples) [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#parameters) [copilotkitExit](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#copilotkitexit) [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#examples-1) [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#parameters-1) [copilotkitEmitState](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#copilotkitemitstate) [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#examples-2) [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#parameters-2) [copilotkitEmitMessage](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#copilotkitemitmessage) [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#examples-3) [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#parameters-3) [copilotkitEmitToolCall](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#copilotkitemittoolcall) [Examples](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#examples-4) [Parameters](https://docs.copilotkit.ai/reference/sdk/js/LangGraph#parameters-4)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/sdk/js/LangGraph.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Multi-Agent Flows
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat are Multi-Agent Flows?

# Multi-Agent Flows

Use multiple agents to orchestrate complex flows.

![Multi-Agent Flows](https://docs.copilotkit.ai/images/coagents/multi-agent-flows.png)

## [What are Multi-Agent Flows?](https://docs.copilotkit.ai/coagents/multi-agent-flows\#what-are-multi-agent-flows)

When building agentic applications, you often want to orchestrate complex flows together that require the coordination of multiple
agents. This is traditionally called multi-agent orchestration.

## [When should I use this?](https://docs.copilotkit.ai/coagents/multi-agent-flows\#when-should-i-use-this)

Multi-agent flows are useful when you want to orchestrate complex flows together that require the coordination of multiple agents. As
your agentic application grows, delegation of sub-tasks to other agents can help you scale key pieces of your application.

- Divide context into smaller chunks
- Delegate sub-tasks to other agents
- Use a single agent to orchestrate the flow

## [How does CopilotKit support this?](https://docs.copilotkit.ai/coagents/multi-agent-flows\#how-does-copilotkit-support-this)

CopilotKit can be used in either of two distinct modes: **Router Mode**, or **Agent Lock**. By default, CopilotKit
will use Router Mode, leveraging your defined LLM to route requests between agents.

### [Router Mode (default)](https://docs.copilotkit.ai/coagents/multi-agent-flows\#router-mode-default)

Router Mode is enabled by default when using CoAgents. To use it, specify a runtime URL prop in the `CopilotKit` provider component and omit the `agent` prop, like so:

```
<CopilotKit runtimeUrl="<copilot-runtime-url>">
  {/* Your application components */}
</CopilotKit>
```

In router mode, CopilotKit acts as a central hub, dynamically selecting and _routing_ requests between different agents or actions based on the user's input. This mode can be good for chat-first experiences where an LLM chatbot is the entry point for a range of interactions, which can stay in the chat UI or expand to include native React UI widgets.

In this mode, CopilotKit will intelligently route requests to the most appropriate agent or action based on the context and user input.

Be advised that when using this mode, you'll have to "exit the workflow" explicitly in your agent code.
You can find more information about it in the ["Exiting the agent loop" section](https://docs.copilotkit.ai/coagents/advanced/exit-agent).

Router mode requires that you set up an LLM adapter. See how in ["Set up a copilot runtime"](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint) section of the docs.

### [Agent Lock Mode](https://docs.copilotkit.ai/coagents/multi-agent-flows\#agent-lock-mode)

To use Agent Lock Mode, specify the agent name in the `CopilotKit` component with the `agent` prop:

```
<CopilotKit runtimeUrl="<copilot-runtime-url>" agent="<the-name-of-the-agent>">
  {/* Your application components */}
</CopilotKit>
```

In this mode, CopilotKit is configured to work exclusively with a specific agent. This mode is useful when you want to focus on a particular task or domain. Whereas in Router Mode the LLM and CopilotKit's router are free to switch between agents to handle user requests, in Agent Lock Mode all requests will stay within a single workflow graph, ensuring precise control over the workflow.

Use whichever mode works best for your app experience! Also, note that while you cannot nest `CopilotKit` providers, you can use different agents or modes in different areas of your app — for example, you may want a chatbot in router mode that can call on any agent or tool, but may also want to integrate one specific agent elsewhere for a more focused workflow.

[Previous\\
\\
Frontend Actions](https://docs.copilotkit.ai/coagents/frontend-actions) [Next\\
\\
Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state)

### On this page

[What are Multi-Agent Flows?](https://docs.copilotkit.ai/coagents/multi-agent-flows#what-are-multi-agent-flows) [When should I use this?](https://docs.copilotkit.ai/coagents/multi-agent-flows#when-should-i-use-this) [How does CopilotKit support this?](https://docs.copilotkit.ai/coagents/multi-agent-flows#how-does-copilotkit-support-this) [Router Mode (default)](https://docs.copilotkit.ai/coagents/multi-agent-flows#router-mode-default) [Agent Lock Mode](https://docs.copilotkit.ai/coagents/multi-agent-flows#agent-lock-mode)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/multi-agent-flows.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Copilot Sidebar Component
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall Dependencies

[Chat Components](https://docs.copilotkit.ai/reference/components/chat)

# CopilotSidebar

The CopilotSidebar component, providing a sidebar interface for interacting with your copilot.

![](https://docs.copilotkit.ai/images/CopilotSidebar.gif)

A chatbot sidebar component for the CopilotKit framework. Highly customizable through various props and custom CSS.

See [CopilotPopup](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup) for a popup version of this component.

## [Install Dependencies](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar\#install-dependencies)

This component is part of the [@copilotkit/react-ui](https://npmjs.com/package/@copilotkit/react-ui) package.

```
npm install @copilotkit/react-core @copilotkit/react-ui
```

## [Usage](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar\#usage)

```
import { CopilotSidebar } from "@copilotkit/react-ui";
import "@copilotkit/react-ui/styles.css";

<CopilotSidebar
  labels={{
    title: "Your Assistant",
    initial: "Hi! 👋 How can I assist you today?",
  }}
>
  <YourApp/>
</CopilotSidebar>
```

### [Look & Feel](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar\#look--feel)

By default, CopilotKit components do not have any styles. You can import CopilotKit's stylesheet at the root of your project:

YourRootComponent.tsx

```
...
import "@copilotkit/react-ui/styles.css";

export function YourRootComponent() {
  return (
    <CopilotKit>
      ...
    </CopilotKit>
  );
}
```

For more information about how to customize the styles, check out the [Customize Look & Feel](https://docs.copilotkit.ai/guides/custom-look-and-feel/customize-built-in-ui-components) guide.

## [Properties](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar\#properties)

instructionsstring

Custom instructions to be added to the system message. Use this property to
provide additional context or guidance to the language model, influencing
its responses. These instructions can include specific directions,
preferences, or criteria that the model should consider when generating
its output, thereby tailoring the conversation more precisely to the
user's needs or the application's requirements.

onInProgress(inProgress: boolean) => void

A callback that gets called when the in progress state changes.

onSubmitMessage(message: string) => void \| Promise<void>

A callback that gets called when a new message it submitted.

onStopGenerationOnStopGeneration

A custom stop generation function.

onReloadMessagesOnReloadMessages

A custom reload messages function.

onRegenerate(messageId: string) => void

A callback function to regenerate the assistant's response

onCopy(message: string) => void

A callback function when the message is copied

onThumbsUp(message: string) => void

A callback function for thumbs up feedback

onThumbsDown(message: string) => void

A callback function for thumbs down feedback

iconsCopilotChatIcons

Icons can be used to set custom icons for the chat window.

labelsCopilotChatLabels

Labels can be used to set custom labels for the chat window.

makeSystemMessageSystemMessageFunction

A function that takes in context string and instructions and returns
the system message to include in the chat request.
Use this to completely override the system message, when providing
instructions is not enough.

AssistantMessageReact.ComponentType<AssistantMessageProps>

A custom assistant message component to use instead of the default.

UserMessageReact.ComponentType<UserMessageProps>

A custom user message component to use instead of the default.

MessagesReact.ComponentType<MessagesProps>

A custom Messages component to use instead of the default.

RenderTextMessageReact.ComponentType<RenderMessageProps>

A custom RenderTextMessage component to use instead of the default.

RenderActionExecutionMessageReact.ComponentType<RenderMessageProps>

A custom RenderActionExecutionMessage component to use instead of the default.

RenderAgentStateMessageReact.ComponentType<RenderMessageProps>

A custom RenderAgentStateMessage component to use instead of the default.

RenderResultMessageReact.ComponentType<RenderMessageProps>

A custom RenderResultMessage component to use instead of the default.

InputReact.ComponentType<InputProps>

A custom Input component to use instead of the default.

classNamestring

A class name to apply to the root element.

childrenReact.ReactNode

Children to render.

defaultOpenboolean

Default:"false"

Whether the chat window should be open by default.

clickOutsideToCloseboolean

Default:"true"

If the chat window should close when the user clicks outside of it.

hitEscapeToCloseboolean

Default:"true"

If the chat window should close when the user hits the Escape key.

shortcutstring

Default:"'/'"

The shortcut key to open the chat window.
Uses Command-\[shortcut\] on a Mac and Ctrl-\[shortcut\] on Windows.

onSetOpen(open: boolean) => void

A callback that gets called when the chat window opens or closes.

WindowReact.ComponentType<WindowProps>

A custom Window component to use instead of the default.

ButtonReact.ComponentType<ButtonProps>

A custom Button component to use instead of the default.

HeaderReact.ComponentType<HeaderProps>

A custom Header component to use instead of the default.

[Previous\\
\\
CopilotPopup](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup) [Next\\
\\
CopilotTextarea](https://docs.copilotkit.ai/reference/components/CopilotTextarea)

### On this page

[Install Dependencies](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar#install-dependencies) [Usage](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar#usage) [Look & Feel](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar#look--feel) [Properties](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar#properties)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/components/chat/CopilotSidebar.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAI Flows Quickstart
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagePrerequisites

# Quickstart CrewAI Flows

Turn your CrewAI Flows into an agent-native application in 10 minutes.

## [Prerequisites](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#prerequisites)

Before you begin, you'll need the following:

- [**OpenAI API key**](https://platform.openai.com/api-keys)

## [Getting started](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#getting-started)

### [Install CopilotKit](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#install-copilotkit)

First, install the latest packages for CopilotKit into your frontend.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

Do you already have a CrewAI Flow agent?

You will need a CrewAI Flow agent to get started!

Either bring your own or feel free to use our starter repo.

CrewAI

Bring your own CrewAI Flow agent

I already have a CrewAI Flow agent and want to use it with CopilotKit.

![CopilotKit Logo](https://docs.copilotkit.ai/images/copilotkit-logo.svg)

Use the CoAgents Starter repo

I don't have a CrewAI Flow agent yet, but want to get started quickly.

### [Launch your local agent](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#launch-your-local-agent)

Start your local CrewAI Flow agent:

```
# Install dependencies
poetry lock
poetry install
# Start the server
poetry run demo
```

This will start a local agent server that you can connect to.

Choose your connection method

Now you need to connect your CrewAI Flow to CopilotKit.

Copilot Cloud (Recommended)

I want to host my Copilot on Copilot Cloud

Self-Hosted Copilot Runtime

I want to self-host the Copilot Runtime

### [Add a remote endpoint for your CrewAI Flow](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#add-a-remote-endpoint-for-your-crewai-flow)

Using Copilot Cloud, you need to connect a remote endpoint that will connect to your CrewAI Flow.

Self hosted (FastAPI)CrewAI Enterprise

**Running your FastAPI server in production**

Head over to [Copilot Cloud](https://cloud.copilotkit.ai/) sign up and setup a remote endpoint with the following information:

- OpenAI API key
- Your FastAPI server URL

**Running your FastAPI server locally**

If you're running your FastAPI server locally, you can open a tunnel to it so Copilot Cloud can connect to it.

```
npx copilotkit@latest dev --port 8000
```

### [Setup your CopilotKit provider](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#setup-your-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit
          publicApiKey="<your-copilot-cloud-public-api-key>"
          agent="sample_agent" // the name of the agent you want to use
        >
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

Looking for a way to run multiple CrewAI Flows? Check out our [Multi-Agent](https://docs.copilotkit.ai/crewai-flows/multi-agent-flows) guide.

### [Setup the Copilot UI](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#setup-the-copilot-ui)

The last step is to use CopilotKit's UI components to render the chat interaction with your agent. In most situations,
this is done alongside your core page components, e.g. in your `page.tsx` file.

page.tsx

```

import "@copilotkit/react-ui/styles.css";
import { CopilotPopup } from "@copilotkit/react-ui";

export function YourApp() {
  return (
    <main>
      <h1>Your main content</h1>

      <CopilotPopup
        labels={{
            title: "Popup Assistant",
            initial: "Hi! I'm connected to an agent. How can I help?",
        }}
      />
    </main>
  );
}
```

Looking for other chat component options? Check out our [Agentic Chat UI](https://docs.copilotkit.ai/crewai-flows/agentic-chat-ui) guide.

### [🎉 Talk to your agent!](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#-talk-to-your-agent)

Congrats! You've successfully integrated a CrewAI Flow chatbot to your application. To start, try asking a few questions to your agent.

```
Can you tell me a joke?
```

```
Can you help me understand AI?
```

```
What do you think about React?
```

### Having trouble?

* * *

## [What's next?](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai\#whats-next)

You've now got a CrewAI Flow running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

[**Implement Human in the Loop** \\
Allow your users and agents to collaborate together on tasks.](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop) [**Utilize the Shared State** \\
Learn how to synchronize your agent's state with your UI's state, and vice versa.](https://docs.copilotkit.ai/crewai-flows/shared-state) [**Add some generative UI** \\
Render your agent's progress and output in the UI.](https://docs.copilotkit.ai/crewai-flows/generative-ui) [**Setup frontend actions** \\
Give your agent the ability to call frontend tools, directly updating your application.](https://docs.copilotkit.ai/crewai-flows/frontend-actions)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/crewai-flows) [Next\\
\\
Chat with an Agent](https://docs.copilotkit.ai/crewai-flows/agentic-chat-ui)

### On this page

[Prerequisites](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#prerequisites) [Getting started](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#getting-started) [Install CopilotKit](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#install-copilotkit) [Clone the coagents-starter repo](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#clone-the-coagents-starter-repo) [Create a .env file](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#create-a-env-file) [Add your API keys](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#add-your-api-keys) [Launch your local agent](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#launch-your-local-agent) [Add a remote endpoint for your CrewAI Flow](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#add-a-remote-endpoint-for-your-crewai-flow) [Setup your CopilotKit provider](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#setup-your-copilotkit-provider) [Install Copilot Runtime](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#install-copilot-runtime) [Setup a Copilot Runtime Endpoint](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#setup-a-copilot-runtime-endpoint) [Add your CrewAI Flow deployment to Copilot Runtime](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#add-your-crewai-flow-deployment-to-copilot-runtime) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#configure-the-copilotkit-provider) [Setup the Copilot UI](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#setup-the-copilot-ui) [🎉 Talk to your agent!](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#-talk-to-your-agent) [What's next?](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai#whats-next)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-flows/quickstart/crewai.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Copilotkit Configuration Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageMessage Streaming

# Streaming and Tool Calls

CoAgents support streaming your messages and tool calls to the frontend.

If you'd like to change how LangGraph agents behave as CoAgents you can utilize our Copilotkit SDK which provides a collection
of functions and utilities for interacting with the agent's state or behavior. One example of this is the Copilotkit config
which is a wrapper of the LangGraph `config` object. This allows you to extend the configuration of your LangGraph nodes to
change how LangGraph and Copilotkit interact with each other. This allows you to change how messages and tool calls are emitted and
streamed to the frontend.

## [Message Streaming](https://docs.copilotkit.ai/coagents/concepts/copilotkit-config\#message-streaming)

If you did not change anything in your LangGraph node, message streaming will be on by default. This allows for a message to be
streamed to Copilotkit as it is being generated, allowing for a more responsive experience. However, you can disable this if you
want to have the message only be sent after the agent has finished generating it.

```
config = copilotkit_customize_config(
    config,
    # True or False
    emit_messages=False,
)
```

## [Emitting Tool Calls](https://docs.copilotkit.ai/coagents/concepts/copilotkit-config\#emitting-tool-calls)

Emission of tool calls are off by default. This means that tool calls will not be sent to Copilotkit for processing and rendering.
However, within a node you can extend the LangGraph `config` object to emit tool calls to Copilotkit. This is useful in situations
where you may to emit what a potential tool call will look like prior to being executed.

```
config = copilotkit_customize_config(
    config,
    # Can set to True, False, or a list of tool call names to emit.
    emit_tool_calls=["tool_name"],
)
```

For more information on how tool calls are utilized check out our [frontend actions](https://docs.copilotkit.ai/coagents/frontend-actions)
documentation.

[Next\\
\\
Introduction](https://docs.copilotkit.ai/)

### On this page

[Message Streaming](https://docs.copilotkit.ai/coagents/concepts/copilotkit-config#message-streaming) [Emitting Tool Calls](https://docs.copilotkit.ai/coagents/concepts/copilotkit-config#emitting-tool-calls)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/concepts/copilotkit-config.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agentic Chat UI
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

# Chat with an Agent

Chat with an agent using CopilotKit's UI components.

This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with various Copilot UI components applied to it!

## [What is this?](https://docs.copilotkit.ai/coagents/agentic-chat-ui\#what-is-this)

Agentic chat UIs are ways for your users to interact with your agent. CopilotKit provides a variety of different components to choose from, each
with their own unique use cases.

If you've gone through the [getting started guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph) **you already have a agentic chat UI setup**! Nothing else is needed
to get started.

## [When should I use this?](https://docs.copilotkit.ai/coagents/agentic-chat-ui\#when-should-i-use-this)

CopilotKit provides a variety of different batteries-included components to choose from to create agent native applications. They scale
from simple chat UIs to completely custom applications.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

`CopilotPopup` is a convenience wrapper for `CopilotChat` that lives at the same level as your main content in the view hierarchy. It provides **a floating chat interface** that can be toggled on and off.

![Popup Example](https://docs.copilotkit.ai/images/popup-example.gif)

```
import { CopilotPopup } from "@copilotkit/react-ui";

export function YourApp() {
  return (
    <>
      <YourMainContent />
      <CopilotPopup
        instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
        labels={{
          title: "Popup Assistant",
          initial: "Need any help?",
        }}
      />
    </>
  );
}
```

[Previous\\
\\
Quickstart (LangGraph)](https://docs.copilotkit.ai/coagents/quickstart/langgraph) [Next\\
\\
Generative UI](https://docs.copilotkit.ai/coagents/generative-ui)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/agentic-chat-ui#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/agentic-chat-ui#when-should-i-use-this)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/agentic-chat-ui.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAIAgent Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCrewAIAgent

Python

# CrewAIAgent

CrewAIAgent lets you define your agent for use with CopilotKit.

## [CrewAIAgent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent\#crewaiagent)

CrewAIAgent lets you define your agent for use with CopilotKit.

To install, run:

```
pip install copilotkit[crewai]
```

Every agent must have the `name` and either `crew` or `flow` properties defined. An optional
`description` can also be provided. This is used when CopilotKit is dynamically routing requests
to the agent.

## [Serving a Crew based agent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent\#serving-a-crew-based-agent)

To serve a Crew based agent, pass in a `Crew` object to the `crew` parameter.

Note:
You need to make sure to have a `chat_llm` set on the `Crew` object.
See [the CrewAI docs](https://docs.crewai.com/concepts/cli#9-chat) for more information.

```
from copilotkit import CrewAIAgent


CrewAIAgent(
    name="email_agent_crew",
    description="This crew based agent sends emails",
    crew=SendEmailCrew(),
)
```

## [Serving a Flow based agent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent\#serving-a-flow-based-agent)

To serve a Flow based agent, pass in a `Flow` object to the `flow` parameter.

```
CrewAIAgent(
    name="email_agent_flow",
    description="This flow based agent sends emails",
    flow=SendEmailFlow(),
)
```

Note:
Either a `crew` or `flow` must be provided to CrewAIAgent.

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent\#parameters)

namestrrequired

The name of the agent.

crewCrewrequired

When using a Crew based agent, pass in a `Crew` object to the `crew` parameter.

flowFlowrequired

When using a Flow based agent, pass in a `Flow` object to the `flow` parameter.

descriptionOptional\[str\]

The description of the agent.

copilotkit\_configOptional\[CopilotKitConfig\]

The CopilotKit config to use with the agent.

## [CopilotKitConfig](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent\#copilotkitconfig)

CopilotKit config for CrewAIAgent

This is used for advanced cases where you want to customize how CopilotKit interacts with
CrewAI.

```
# Function signatures:
def merge_state(
    *,
    state: dict,
    messages: List[BaseMessage],
    actions: List[Any],
    agent_name: str
):
    # ...implementation...
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent\#parameters-1)

merge\_stateCallablerequired

This function lets you customize how CopilotKit merges the agent state.

[Previous\\
\\
LangGraph SDK](https://docs.copilotkit.ai/reference/sdk/python/LangGraph) [Next\\
\\
CrewAI SDK](https://docs.copilotkit.ai/reference/sdk/python/CrewAI)

### On this page

[CrewAIAgent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent#crewaiagent) [Serving a Crew based agent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent#serving-a-crew-based-agent) [Serving a Flow based agent](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent#serving-a-flow-based-agent) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent#parameters) [CopilotKitConfig](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent#copilotkitconfig) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent#parameters-1)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/sdk/python/CrewAIAgent.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAI Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagePrerequisites

# Quickstart CrewAI Crews

Turn your CrewAI Crews into an agent-native application in 10 minutes.

## [Prerequisites](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai\#prerequisites)

Before you begin, you'll need the following:

- [**OpenAI API key**](https://platform.openai.com/api-keys)

## [Getting started](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai\#getting-started)

Use the CopilotKit CLI

Use the CopilotKit CLI

I have a Next.js application and want to get started quickly.

Code along

I want to deeply understand what's happening under the hood or don't have a Next.js application.

### [Run the CLI](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai\#run-the-cli)

Just run this following command in your Next.js application to get started!

### Don't have a Next.js application?

```
npx copilotkit@latest init
```

### [🎉 Talk to your agent!](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai\#-talk-to-your-agent)

Congrats! You've successfully integrated your CrewAI Enterprise agent with CopilotKit.
Try talking to your Copilot. Chat with it to provide the information needed to run your Crew from your app.

You can also check out our [Restaurant Finder Crew demo](https://crew-ai-enterprise-demo.vercel.app/) to see implementation in action.

* * *

## [What's next?](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai\#whats-next)

You've now got a CrewAI Crew running in CopilotKit! Now you can start exploring the various ways that CopilotKit
can help you build power agent native applications.

[**Implement Human in the Loop** \\
Allow your users and agents to collaborate together on tasks.](https://docs.copilotkit.ai/crewai-crews/human-in-the-loop) [**Utilize the Shared State** \\
Learn how to synchronize your agent's state with your UI's state, and vice versa.](https://docs.copilotkit.ai/crewai-crews/shared-state) [**Add some generative UI** \\
Render your agent's progress and output in the UI.](https://docs.copilotkit.ai/crewai-crews/generative-ui) [**Setup frontend actions** \\
Give your agent the ability to call frontend tools, directly updating your application.](https://docs.copilotkit.ai/crewai-crews/frontend-actions)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/crewai-crews) [Next\\
\\
Chat with an Agent](https://docs.copilotkit.ai/crewai-crews/agentic-chat-ui)

### On this page

[Prerequisites](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#prerequisites) [Getting started](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#getting-started) [Run the CLI](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#run-the-cli) [Connect to Copilot Cloud](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#connect-to-copilot-cloud) [Setup the CopilotKit Provider](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#setup-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#choose-a-copilot-ui) [Create a Crew-Quickstart component](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#create-a-crew-quickstart-component) [🎉 Talk to your agent!](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#-talk-to-your-agent) [What's next?](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai#whats-next)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-crews/quickstart/crewai.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraphAgent Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageLangGraphAgent

Python

# LangGraphAgent

LangGraphAgent lets you define your agent for use with CopilotKit.

## [LangGraphAgent](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent\#langgraphagent)

LangGraphAgent lets you define your agent for use with CopilotKit.

To install, run:

```
pip install copilotkit
```

### [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent\#examples)

Every agent must have the `name` and `graph` properties defined. An optional `description`
can also be provided. This is used when CopilotKit is dynamically routing requests to the
agent.

```
from copilotkit import LangGraphAgent

LangGraphAgent(
    name="email_agent",
    description="This agent sends emails",
    graph=graph,
)
```

If you have a custom LangGraph/LangChain config that you want to use with the agent, you can
pass it in as the `langgraph_config` parameter.

```
LangGraphAgent(
    ...
    langgraph_config=config,
)
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent\#parameters)

namestrrequired

The name of the agent.

graphCompiledGraphrequired

The LangGraph graph to use with the agent.

descriptionOptional\[str\]

The description of the agent.

langgraph\_configOptional\[RunnableConfig\]

The LangGraph/LangChain config to use with the agent.

copilotkit\_configOptional\[CopilotKitConfig\]

The CopilotKit config to use with the agent.

## [CopilotKitConfig](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent\#copilotkitconfig)

CopilotKit config for LangGraphAgent

This is used for advanced cases where you want to customize how CopilotKit interacts with
LangGraph.

```
# Function signatures:
def merge_state(
    *,
    state: dict,
    messages: List[BaseMessage],
    actions: List[Any],
    agent_name: str
):
    # ...implementation...

def convert_messages(messages: List[Message]):
    # ...implementation...
```

### [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent\#parameters-1)

merge\_stateCallablerequired

This function lets you customize how CopilotKit merges the agent state.

convert\_messagesCallablerequired

Use this function to customize how CopilotKit converts its messages to LangChain messages.\`

[Previous\\
\\
Remote Endpoints](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints) [Next\\
\\
LangGraph SDK](https://docs.copilotkit.ai/reference/sdk/python/LangGraph)

### On this page

[LangGraphAgent](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent#langgraphagent) [Examples](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent#examples) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent#parameters) [CopilotKitConfig](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent#copilotkitconfig) [Parameters](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent#parameters-1)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/sdk/python/LangGraphAgent.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Guardrails Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageIntroduction

# Guardrails  Cloud Only

## [Introduction](https://docs.copilotkit.ai/guides/guardrails\#introduction)

CopilotKit Cloud provides content moderation capabilities through the `guardrails_c` configuration, helping ensure safe and appropriate AI interactions. The system uses OpenAI's content moderation capabilities to enforce these guardrails.

This feature is only available with [CopilotKit Cloud](https://cloud.copilotkit.ai/).

## [Implementation](https://docs.copilotkit.ai/guides/guardrails\#implementation)

```
import { CopilotKit } from "@copilotkit/react-core";

export default function App() {
  return (
    <CopilotKit
      publicApiKey={process.env.COPILOTKIT_PUBLIC_API_KEY}
      guardrails_c={{
        // Topics to explicitly block
        invalidTopics: ["politics", "explicit-content", "harmful-content"],
        // Topics to explicitly allow
        validTopics: ["business", "technology", "general-assistance"],
      }}
    >
      {/* Your app */}
    </CopilotKit>
  );
}
```

[Previous\\
\\
Authenticated Actions](https://docs.copilotkit.ai/guides/authenticated-actions) [Next\\
\\
Copilot Suggestions](https://docs.copilotkit.ai/guides/copilot-suggestions)

### On this page

[Introduction](https://docs.copilotkit.ai/guides/guardrails#introduction) [Implementation](https://docs.copilotkit.ai/guides/guardrails#implementation)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/guardrails.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangSmith Observability
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

Observability

# LangSmith

To trace your LLM runs with LangSmith, make sure to set up your environment variables:

.env

```
LANGCHAIN_API_KEY="<your-api-key>"
LANGCHAIN_PROJECT="<your-project-name>"
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com""
```

Next, use the `LangChainAdapter` to trace your CopilotKit runs:

```
const { LangChainAdapter } = await import("@copilotkit/runtime");
const { ChatOpenAI } = await import("@langchain/openai");

async function getLangChainOpenAIAdapter() {
  return new LangChainAdapter({
    chainFn: async ({ messages, tools, threadId }) => {
      const model = new ChatOpenAI({
        modelName: "gpt-4-1106-preview",
      }).bindTools(tools, {
        strict: true,
      });
      return model.stream(messages, {
        tools,
        metadata: { conversation_id: threadId },
      });
    },
  });
}
```

Note that `threadId` is passed to the model as `conversation_id` in the metadata.

[Previous\\
\\
Anonymous Telemetry](https://docs.copilotkit.ai/telemetry)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/(other)/observability/langsmith.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Disabling State Streaming
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

Advanced

# Disabling state streaming

Granularly control what is streamed to the frontend.

## [What is this?](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming\#what-is-this)

By default, CopilotKit will stream both your state and tool calls to the frontend.
You can disable this by using CopilotKit's custom `RunnableConfig`.

## [When should I use this?](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming\#when-should-i-use-this)

Occasionally, you'll want to disable streaming temporarily — for example, the LLM may be
doing something the current user should not see, like emitting tool calls or questions
pertaining to other employees in an HR system.

## [Implementation](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming\#implementation)

### [Disable all streaming](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming\#disable-all-streaming)

You can disable all message streaming and tool call streaming by passing `emit_messages=False` and `emit_tool_calls=False` to the CopilotKit config.

PythonTypeScript

```
from copilotkit.langgraph import copilotkit_customize_config

async def frontend_actions_node(state: AgentState, config: RunnableConfig):

    # 1) Configure CopilotKit not to emit messages
    modifiedConfig = copilotkit_customize_config(
        config,
        emit_messages=False, # if you want to disable message streaming
        emit_tool_calls=False # if you want to disable tool call streaming
    )

    # 2) Provide the actions to the LLM
    model = ChatOpenAI(model="gpt-4o").bind_tools([\
      *state["copilotkit"]["actions"],\
      # ... any tools you want to make available to the model\
    ])

    # 3) Call the model with CopilotKit's modified config
    response = await model.ainvoke(state["messages"], modifiedConfig)

    # don't return the new response to hide it from the user
    return state
```

BEWARE!

In LangGraph Python, the `config` variable in the surrounding namespace is **implicitly** passed into LangChain LLM calls, even when not explicitly provided.

This is why we create a new variable `modifiedConfig` rather than modifying `config` directly. If we modified `config` itself, it would change the default configuration for all subsequent LLM calls in that namespace.

```
# if we override the config variable name with a new value
config = copilotkit_customize_config(config, ...)

# it will affect every subsequent LangChain LLM call in the same namespace, even when `config` is not explicitly provided
response = await model2.ainvoke(*state["messages"]) # implicitly uses the modified config!
```

[Previous\\
\\
Using Agent Execution Parameters](https://docs.copilotkit.ai/coagents/advanced/adding-runtime-configuration) [Next\\
\\
Manually emitting messages](https://docs.copilotkit.ai/coagents/advanced/emit-messages)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming#implementation) [Disable all streaming](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming#disable-all-streaming)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/advanced/disabling-state-streaming.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Integrate Your LLM
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Bring Your Own LLM

Learn how to use any LLM with CopilotKit.

LLM Adapters are responsible for executing the request with the LLM and standardizing the request/response format in a way that the Copilot Runtime can understand.

Currently, we support the following LLM adapters natively:

- [OpenAI Adapter (Azure also supported)](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter)
- [OpenAI Assistant Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter)
- [LangChain Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter)
- [Groq Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter)
- [Google Generative AI Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter)
- [Anthropic Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/AnthropicAdapter)

You can use the [LangChain Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter) to use any LLM provider we don't yet natively support!

It's not too hard to write your own LLM adapter from scratch -- see the existing adapters for inspiration. And of course, we would love a contribution! ⭐️

Copilot Cloud (Recommended)

Use our hosted backend endpoint to get started quickly (OpenAI only).

Self-hosting

Learn to host CopilotKit's runtime yourself with your own backend.

Configure the used LLM adapter [on your Copilot Cloud dashboard](https://cloud.copilotkit.ai/)!

[Previous\\
\\
Copilot Suggestions](https://docs.copilotkit.ai/guides/copilot-suggestions) [Next\\
\\
Copilot Textarea](https://docs.copilotkit.ai/guides/copilot-textarea)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/bring-your-own-llm.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Custom UI Options
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Customize UI

Customize the look, feel, and functionality of CopilotKit's UI components.

CopilotKit offers a variety of ways to create a UI interface for your Copilots and CoAgents. This ranges
from using our built-in UI components to fully customizing the UI with headless UI.

[**Prebuilt Copilot UI** \\
Get started quickly with CopilotKit's ready-to-use UI components.](https://docs.copilotkit.ai/guides/custom-look-and-feel/built-in-ui-components) [**Styling Copilot UI** \\
Customize the appearance of CopilotKit's pre-built components with your own styles.](https://docs.copilotkit.ai/guides/custom-look-and-feel/customize-built-in-ui-components) [**Custom Components** \\
Replace the Copilot UI components with your own while keeping the core functionality.](https://docs.copilotkit.ai/guides/custom-look-and-feel/bring-your-own-components) [**Fully Custom UI** \\
Build your UI from scratch using CopilotKit's hooks and core functionality.](https://docs.copilotkit.ai/guides/custom-look-and-feel/headless-ui)

[Previous\\
\\
Quickstart](https://docs.copilotkit.ai/quickstart) [Next\\
\\
Prebuilt Copilot UI](https://docs.copilotkit.ai/guides/custom-look-and-feel/built-in-ui-components)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/custom-look-and-feel/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Self-Host CopilotKit
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall CopilotKit

# Quickstart

Get started with CopilotKit in under 5 minutes.

Copilot Cloud (Recommended)

Use our hosted backend endpoint to get started quickly (OpenAI only).

Self-hosting

Learn to host CopilotKit's runtime yourself with your own backend.

## [Install CopilotKit](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#install-copilotkit-1)

First, install the latest packages for CopilotKit.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core @copilotkit/runtime
```

## [Set up a Copilot Runtime Endpoint](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#set-up-a-copilot-runtime-endpoint)

##### Choose your provider:

![OpenAI logo](https://docs.copilotkit.ai/icons/openai.png)OpenAI

If you are planning to use a single LangGraph agent in [agent-lock mode](https://docs.copilotkit.ai/coagents/multi-agent-flows) as your agentic backend, your LLM adapter will only be used for peripherals such as suggestions, etc.

If you are not sure yet, simply ignore this note.

### [Add your API key](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#add-your-api-key)

Next, add your API key to your `.env` file in the root of your project (unless you prefer to provide it directly to the client):

.env

```
OPENAI_API_KEY=your_api_key_here
```

Please note that the code below uses GPT-4o, which requires a paid OpenAI API key. **If you are using a free OpenAI API key**, change the model to a different option such as `gpt-3.5-turbo`.

### [Setup the Runtime Endpoint](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#setup-the-runtime-endpoint)

### [Serverless Function Timeouts](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#serverless-function-timeouts)

When deploying to serverless platforms (Vercel, AWS Lambda, etc.), be aware that default function timeouts may be too short for CopilotKit's streaming responses:

- Vercel defaults: 10s (Hobby), 15s (Pro)
- AWS Lambda default: 3s

**Solution options:**

1. Increase function timeout:








```
// vercel.json
{
     "functions": {
       "api/copilotkit/**/*": {
         "maxDuration": 60
       }
     }
}
```

2. Use [Copilot Cloud](https://cloud.copilotkit.ai/) to avoid timeout issues entirely

Next.js App RouterNext.js Pages RouterNode.js ExpressNode.js HTTPNestJS

Create a new route to handle the `/api/copilotkit` endpoint.

app/api/copilotkit/route.ts

```
import {
  CopilotRuntime,
  OpenAIAdapter,
  copilotRuntimeNextJSAppRouterEndpoint,
} from '@copilotkit/runtime';

import { NextRequest } from 'next/server';


const serviceAdapter = new OpenAIAdapter();
const runtime = new CopilotRuntime();

export const POST = async (req: NextRequest) => {
  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
    runtime,
    serviceAdapter,
    endpoint: '/api/copilotkit',
  });

  return handleRequest(req);
};
```

Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.

## [Configure the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#configure-the-copilotkit-provider)

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Make sure to use the URL you configured in the previous step  */}
        <CopilotKit runtimeUrl="/api/copilotkit">
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

## [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#choose-a-copilot-ui-1)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

`CopilotPopup` is a convenience wrapper for `CopilotChat` that lives at the same level as your main content in the view hierarchy. It provides **a floating chat interface** that can be toggled on and off.

![Popup Example](https://docs.copilotkit.ai/images/popup-example.gif)

```
import { CopilotPopup } from "@copilotkit/react-ui";

export function YourApp() {
  return (
    <>
      <YourMainContent />
      <CopilotPopup
        instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
        labels={{
          title: "Popup Assistant",
          initial: "Need any help?",
        }}
      />
    </>
  );
}
```

* * *

## [Next Steps](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted\#next-steps)

🎉 Congrats! You've successfully integrated a fully functional chatbot in your application! Give it a try now and see it in action. Want to
take it further? Learn more about what CopilotKit has to offer!

[**Connecting Your Data** \\
Learn how to connect CopilotKit to your data, application state and user state.](https://docs.copilotkit.ai/guides/connect-your-data) [**Generative UI** \\
Learn how to render custom UI components directly in the CopilotKit chat window.](https://docs.copilotkit.ai/guides/generative-ui) [**Frontend Actions** \\
Learn how to allow your copilot to take applications on frontend.](https://docs.copilotkit.ai/guides/frontend-actions) [**CoAgents (LangGraph)** \\
Check out our section about CoAgents, our approach to building agentic copilots and experiences.](https://docs.copilotkit.ai/coagents)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/) [Next\\
\\
Customize UI](https://docs.copilotkit.ai/guides/custom-look-and-feel)

### On this page

[Install CopilotKit](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#install-copilotkit) [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#get-a-copilot-cloud-public-api-key) [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#setup-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#choose-a-copilot-ui) [Install CopilotKit](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#install-copilotkit-1) [Set up a Copilot Runtime Endpoint](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#set-up-a-copilot-runtime-endpoint) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#choose-a-copilot-ui-1) [Next Steps](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/quickstart.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Connect Your Data
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageAdd the data to the Copilot

[Connecting Your Data](https://docs.copilotkit.ai/guides/connect-your-data)

# Frontend Data

Learn how to connect your data to CopilotKit.

For your copilot to best answer your users' needs, you will want to provide it with **context-specific**, **user-specific**, and oftentimes **realtime** data. CopilotKit makes it easy to do so.

### [Add the data to the Copilot](https://docs.copilotkit.ai/guides/connect-your-data/frontend\#add-the-data-to-the-copilot)

The [`useCopilotReadable` hook](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable) is used to add data as context to the Copilot.

YourComponent.tsx

```
"use client" // only necessary if you are using Next.js with the App Router.
import { useCopilotReadable } from "@copilotkit/react-core";
import { useState } from 'react';

export function YourComponent() {
  // Create colleagues state with some sample data
  const [colleagues, setColleagues] = useState([\
    { id: 1, name: "John Doe", role: "Developer" },\
    { id: 2, name: "Jane Smith", role: "Designer" },\
    { id: 3, name: "Bob Wilson", role: "Product Manager" }\
  ]);

  // Define Copilot readable state

  useCopilotReadable({
    description: "The current user's colleagues",
    value: colleagues,
  });
  return (
    // Your custom UI component
    <>...</>
  );
}
```

### [Specify `"use client"` (Next.js App Router)](https://docs.copilotkit.ai/guides/connect-your-data/frontend\#specify-use-client-nextjs-app-router)

This is only necessary if you are using Next.js with the App Router.

YourComponent.tsx

```
"use client"
```

Like other React hooks such as `useState` and `useEffect`, this is a **client-side** hook.
If you're using Next.js with the App Router, you'll need to add the `"use client"` directive at the top of any file using this hook.

### [Test it out!](https://docs.copilotkit.ai/guides/connect-your-data/frontend\#test-it-out)

The data you provided is now available to the Copilot.
Test it out by passing some data in the hook and asking the copilot questions about it.

![Example of connecting data to Copilot](https://docs.copilotkit.ai/images/connect-your-data-example.gif)

[Previous\\
\\
Connecting Your Data](https://docs.copilotkit.ai/guides/connect-your-data) [Next\\
\\
Backend Data](https://docs.copilotkit.ai/guides/connect-your-data/backend)

### On this page

[Add the data to the Copilot](https://docs.copilotkit.ai/guides/connect-your-data/frontend#add-the-data-to-the-copilot) [Test it out!](https://docs.copilotkit.ai/guides/connect-your-data/frontend#test-it-out)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/connect-your-data/frontend.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Loading Message History
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageLoading an Existing Thread

Persistence

# Threads

Learn how to load chat messages and threads within the CopilotKit framework.

LangGraph supports threads, a way to group messages together and ultimately maintain a continuous chat history. CopilotKit
provides a few different ways to interact with this concept.

This guide assumes you have already gone through the [quickstart](https://docs.copilotkit.ai/quickstart) guide.

## [Loading an Existing Thread](https://docs.copilotkit.ai/coagents/persistence/loading-message-history\#loading-an-existing-thread)

To load an existing thread in CopilotKit, you can simply set the `threadId` property on `<CopilotKit>` like so.

When using LangGraph platform, the `threadId` must be a UUID.

```
import { CopilotKit } from "@copilotkit/react-core";

<CopilotKit threadId="37aa68d0-d15b-45ae-afc1-0ba6c3e11353">
  <YourApp />
</CopilotKit>
```

## [Dynamically Switching Threads](https://docs.copilotkit.ai/coagents/persistence/loading-message-history\#dynamically-switching-threads)

You can also make the `threadId` dynamic. Once it is set, CopilotKit will load the previous messages for that thread.

```
import { useState } from "react";
import { CopilotKit } from "@copilotkit/react-core";

const Page = () => {
  const [threadId, setThreadId] = useState("af2fa5a4-36bd-4e02-9b55-2580ab584f89");
  return (
    <CopilotKit threadId={threadId}>
      <YourApp setThreadId={setThreadId} />
    </CopilotKit>
  )
}

const YourApp = () => {
  return (
    <Button onClick={() => setThreadId("679e8da5-ee9b-41b1-941b-80e0cc73a008")}>
      Change Thread
    </Button>
  )
}
```

## [Using setThreadId](https://docs.copilotkit.ai/coagents/persistence/loading-message-history\#using-setthreadid)

CopilotKit will also return the current `threadId` and a `setThreadId` function from the `useCopilotContext` hook. You can use `setThreadId` to change the `threadId`.

```
import { useCopilotContext } from "@copilotkit/react-core";

const ChangeThreadButton = () => {
  const { threadId, setThreadId } = useCopilotContext();
  return (
    <Button onClick={() => setThreadId("d73c22f3-1f8e-4a93-99db-5c986068d64f")}>
      Change Thread
    </Button>
  )
}
```

[Previous\\
\\
Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state) [Next\\
\\
Message Persistence](https://docs.copilotkit.ai/coagents/persistence/message-persistence)

### On this page

[Loading an Existing Thread](https://docs.copilotkit.ai/coagents/persistence/loading-message-history#loading-an-existing-thread) [Dynamically Switching Threads](https://docs.copilotkit.ai/coagents/persistence/loading-message-history#dynamically-switching-threads) [Using setThreadId](https://docs.copilotkit.ai/coagents/persistence/loading-message-history#using-setthreadid)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/persistence/loading-message-history.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Human-in-the-Loop Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is Human-in-the-Loop (HITL)?

# Human in the Loop (HITL)

Allow your agent and users to collaborate on complex tasks.

This video shows an example of our [AI Travel App](https://docs.copilotkit.ai/coagents/tutorials/ai-travel-app) using HITL to get user feedback.

## [What is Human-in-the-Loop (HITL)?](https://docs.copilotkit.ai/coagents/human-in-the-loop\#what-is-human-in-the-loop-hitl)

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

![Agentic Copilot Human in the Loop](https://docs.copilotkit.ai/images/coagents/coagents-hitl-infographic.png)

Learn more about HITL in [LangGraph's concept guide](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/).

## [When should I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop\#when-should-i-use-this)

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## [How can I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop\#how-can-i-use-this)

Copilotkit provides two main approaches for HITL LangGraph workflows - interrupt and node-based.

Unsure which approach to use? We recommend starting with the [Interrupt](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow) flow.

[Interrupt\\
\\
Utilize LangGraph's interrupt function to pause the agent and wait for user input.](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow)

[Node-based\\
\\
Utilize nodes and tools to create LLM driven Human-in-the-Loop workflows.](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow)

[Previous\\
\\
Tool-based Generative UI](https://docs.copilotkit.ai/coagents/generative-ui/tool-based) [Next\\
\\
Interrupt](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow)

### On this page

[What is Human-in-the-Loop (HITL)?](https://docs.copilotkit.ai/coagents/human-in-the-loop#what-is-human-in-the-loop-hitl) [When should I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop#when-should-i-use-this) [How can I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop#how-can-i-use-this)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/human-in-the-loop/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Quickstart Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall CopilotKit

# Quickstart

Get started with CopilotKit in under 5 minutes.

Copilot Cloud (Recommended)

Use our hosted backend endpoint to get started quickly (OpenAI only).

Self-hosting

Learn to host CopilotKit's runtime yourself with your own backend.

## [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=Headless%20UI\#install-copilotkit)

First, install the latest packages for CopilotKit.

npmpnpmyarnbun

```
npm install @copilotkit/react-ui @copilotkit/react-core
```

## [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=Headless%20UI\#get-a-copilot-cloud-public-api-key)

Navigate to [Copilot Cloud](https://cloud.copilotkit.ai/) and follow the instructions to get a public API key - it's free!

## [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=Headless%20UI\#setup-the-copilotkit-provider)

The [`<CopilotKit>`](https://docs.copilotkit.ai/reference/components/CopilotKit) component must wrap the Copilot-aware parts of your application. For most use-cases,
it's appropriate to wrap the CopilotKit provider around the entire app, e.g. in your layout.tsx.

layout.tsx

```
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core";

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */}
        <CopilotKit publicApiKey="<your-copilot-cloud-public-api-key>">
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```

## [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=Headless%20UI\#choose-a-copilot-ui)

You are almost there! Now it's time to setup your Copilot UI.

First, import the default styles in your root component (typically `layout.tsx`) :

```
import "@copilotkit/react-ui/styles.css";
```

Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.

CopilotPopupCopilotSidebarCopilotChatHeadless UI

The built-in Copilot UI can be customized in many ways -- both through css and by passing in custom sub-components.

CopilotKit also offers **fully custom headless UI**, through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

```
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function CustomChatInterface() {
  const {
    visibleMessages,
    appendMessage,
    setMessages,
    deleteMessage,
    reloadMessages,
    stopGeneration,
    isLoading,
  } = useCopilotChat();

  const sendMessage = (content: string) => {
    appendMessage(new TextMessage({ content, role: Role.User }));
  };

  return (
    <div>
      {/* Implement your custom chat UI here */}
    </div>
  );
}
```

* * *

## [Next Steps](https://docs.copilotkit.ai/quickstart?component=Headless%20UI\#next-steps)

🎉 Congrats! You've successfully integrated a fully functional chatbot in your application! Give it a try now and see it in action. Want to
take it further? Learn more about what CopilotKit has to offer!

[**Connecting Your Data** \\
Learn how to connect CopilotKit to your data, application state and user state.](https://docs.copilotkit.ai/guides/connect-your-data) [**Generative UI** \\
Learn how to render custom UI components directly in the CopilotKit chat window.](https://docs.copilotkit.ai/guides/generative-ui) [**Frontend Actions** \\
Learn how to allow your copilot to take applications on frontend.](https://docs.copilotkit.ai/guides/frontend-actions) [**CoAgents (LangGraph)** \\
Check out our section about CoAgents, our approach to building agentic copilots and experiences.](https://docs.copilotkit.ai/coagents)

[Previous\\
\\
Introduction](https://docs.copilotkit.ai/) [Next\\
\\
Customize UI](https://docs.copilotkit.ai/guides/custom-look-and-feel)

### On this page

[Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#install-copilotkit) [Get a Copilot Cloud Public API Key](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#get-a-copilot-cloud-public-api-key) [Setup the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#setup-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#choose-a-copilot-ui) [Install CopilotKit](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#install-copilotkit-1) [Set up a Copilot Runtime Endpoint](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#set-up-a-copilot-runtime-endpoint) [Configure the CopilotKit Provider](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#configure-the-copilotkit-provider) [Choose a Copilot UI](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#choose-a-copilot-ui-1) [Next Steps](https://docs.copilotkit.ai/quickstart?component=Headless%20UI#next-steps)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/quickstart.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Customize AI Assistant
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageAppending to the prompt (Recommended)

# Customize Instructions

Learn how to customize the behavior of your AI assistant.

There are three main ways to customize the behavior of your AI assistant:

- [Appending to the prompt](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#appending-to-the-prompt-recommended)
- [Passing the `instructions` parameter](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#passing-the-instructions-parameter)
- [Overwriting the default `makeSystemMessage`)](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#overwriting-the-default-makesystemmessage-not-recommended)

## [Appending to the prompt (Recommended)](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior\#appending-to-the-prompt-recommended)

CopilotKit provides the [useCopilotAdditionalInstructions](https://docs.copilotkit.ai/reference/hooks/useCopilotAdditionalInstructions) hook which allows you to add content to the prompt with whatever
you want.

Home.tsx

```
import { CopilotKit, useCopilotAdditionalInstructions } from "@copilotkit/react-core";
import { CopilotPopup } from "@copilotkit/react-ui"

function Chat() {
  useCopilotAdditionalInstructions({
    instructions: "Do not answer questions about the weather.",
  });
  return <CopilotPopup />
}

export function Home() {
  return (
    <CopilotKit>
      <Chat />
    </CopilotKit>
  )
}
```

You can even conditionally add instructions based on the application's state.

Home.tsx

```
function Chat() {
  const [showWeather, setShowWeather] = useState(false);

  useCopilotAdditionalInstructions({
    instructions: "Do not answer questions about the weather.",
    available: showWeather ? "enabled" : "disabled"
  }, showWeather);
}
```

## [Advanced](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior\#advanced)

If appending to the prompt is not enough, you have some other options, specifically around updating the prompt directly.

### [Passing the `instructions` parameter](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior\#passing-the-instructions-parameter)

The `instructions` parameter is the recommended way to customize AI assistant behavior. It will remain compatible with performance optimizations to the CopilotKit platform.

It can be customized for **Copilot UI** as well as **programmatically**:

Copilot UIHeadless UI

Copilot UI components accept an `instructions` property:

CustomCopilot.tsx

```
import { CopilotChat } from "@copilotkit/react-ui";

<CopilotChat
  instructions="You are a helpful assistant specializing in tax preparation. Provide concise and accurate answers to tax-related questions."
  labels={{
    title: "Tax Preparation Assistant",
    initial: "How can I help you with your tax preparation today?",
  }}
/>
```

### [Overwriting the default system message](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior\#overwriting-the-default-system-message)

For cases requiring complete control over the system message, you can use the `makeSystemMessage` function. We highly recommend reading CopilotKit's default system message before deciding to overwrite it, which can be found [here](https://github.com/CopilotKit/CopilotKit/blob/e48a34a66bb4dfd210e93dc41eee7d0f22d1a0c4/CopilotKit/packages/react-core/src/hooks/use-copilot-chat.ts#L240-L258).

This approach is **not recommended** as it may interfere with more advanced optimizations made by CopilotKit. **Only use this approach if the other options are not enough.**

Copilot UIHeadless UI

```
import { CopilotChat } from "@copilotkit/react-ui";

const CustomCopilot: React.FC = () => (
  <CopilotChat
    instructions="You are a knowledgeable tax preparation assistant. Provide accurate and concise answers to tax-related questions, guiding users through the tax filing process."
    labels={{
      title: "Tax Preparation Assistant",
      initial: "How can I assist you with your taxes today?",
    }}
    makeSystemMessage={myCustomTaxSystemMessage}
  />
);
```

[Previous\\
\\
Remote Endpoint (LangGraph Platform)](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint) [Next\\
\\
Authenticated Actions](https://docs.copilotkit.ai/guides/authenticated-actions)

### On this page

[Appending to the prompt (Recommended)](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#appending-to-the-prompt-recommended) [Advanced](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#advanced) [Passing the instructions parameter](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#passing-the-instructions-parameter) [Overwriting the default system message](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior#overwriting-the-default-system-message)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/custom-ai-assistant-behavior.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Loading Agent State
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageSetting the threadId

Persistence

# Loading Agent State

Learn how threadId is used to load previous agent states.

### [Setting the threadId](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state\#setting-the-threadid)

When setting the `threadId` property in CopilotKit, i.e:

When using LangGraph platform, the `threadId` must be a UUID.

```
<CopilotKit threadId="2140b272-7180-410d-9526-f66210918b13">
  <YourApp />
</CopilotKit>
```

CopilotKit will restore the complete state of the thread, including the messages, from the database. (See [Message Persistence](https://docs.copilotkit.ai/coagents/persistence/message-persistence) for more details.)

### [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state\#loading-agent-state)

This means that the state of any agent will also be restored. For example:

```
const { state } = useCoAgent({name: "research_agent"});

// state will now be the state of research_agent in the thread id given above
```

### [Learn More](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state\#learn-more)

To learn more about persistence and state in CopilotKit, see:

- [Reading agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read)
- [Writing agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write)
- [Loading Message History](https://docs.copilotkit.ai/coagents/persistence/loading-message-history)

[Previous\\
\\
Multi-Agent Flows](https://docs.copilotkit.ai/coagents/multi-agent-flows) [Next\\
\\
Threads](https://docs.copilotkit.ai/coagents/persistence/loading-message-history)

### On this page

[Setting the threadId](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state#setting-the-threadid) [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state#loading-agent-state) [Learn More](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state#learn-more)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/persistence/loading-agent-state.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## OpenAIAdapter Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

LLM Adapters

# OpenAIAdapter

Copilot Runtime adapter for OpenAI.

Copilot Runtime adapter for OpenAI.

## [Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter\#example)

```
import { CopilotRuntime, OpenAIAdapter } from "@copilotkit/runtime";
import OpenAI from "openai";

const copilotKit = new CopilotRuntime();

const openai = new OpenAI({
  organization: "<your-organization-id>", // optional
  apiKey: "<your-api-key>",
});

return new OpenAIAdapter({ openai });
```

## [Example with Azure OpenAI](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter\#example-with-azure-openai)

```
import { CopilotRuntime, OpenAIAdapter } from "@copilotkit/runtime";
import OpenAI from "openai";

// The name of your Azure OpenAI Instance.
// https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource
const instance = "<your instance name>";

// Corresponds to your Model deployment within your OpenAI resource, e.g. my-gpt35-16k-deployment
// Navigate to the Azure OpenAI Studio to deploy a model.
const model = "<your model>";

const apiKey = process.env["AZURE_OPENAI_API_KEY"];
if (!apiKey) {
  throw new Error("The AZURE_OPENAI_API_KEY environment variable is missing or empty.");
}

const copilotKit = new CopilotRuntime();

const openai = new OpenAI({
  apiKey,
  baseURL: `https://${instance}.openai.azure.com/openai/deployments/${model}`,
  defaultQuery: { "api-version": "2024-04-01-preview" },
  defaultHeaders: { "api-key": apiKey },
});

return new OpenAIAdapter({ openai });
```

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter\#constructor-parameters)

openaiOpenAI

An optional OpenAI instance to use. If not provided, a new instance will be
created.

modelstring

The model to use.

disableParallelToolCallsboolean

Default:"false"

Whether to disable parallel tool calls.
You can disable parallel tool calls to force the model to execute tool calls sequentially.
This is useful if you want to execute tool calls in a specific order so that the state changes
introduced by one tool call are visible to the next tool call. (i.e. new actions or readables)

[Previous\\
\\
CopilotRuntime](https://docs.copilotkit.ai/reference/classes/CopilotRuntime) [Next\\
\\
OpenAIAssistantAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter)

### On this page

[Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter#example) [Example with Azure OpenAI](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter#example-with-azure-openai) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/llm-adapters/OpenAIAdapter.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## GroqAdapter Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

LLM Adapters

# GroqAdapter

Copilot Runtime adapter for Groq.

Copilot Runtime adapter for Groq.

## [Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter\#example)

```
import { CopilotRuntime, GroqAdapter } from "@copilotkit/runtime";
import { Groq } from "groq-sdk";

const groq = new Groq({ apiKey: process.env["GROQ_API_KEY"] });

const copilotKit = new CopilotRuntime();

return new GroqAdapter({ groq, model: "<model-name>" });
```

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter\#constructor-parameters)

groqGroq

An optional Groq instance to use.

modelstring

The model to use.

disableParallelToolCallsboolean

Default:"false"

Whether to disable parallel tool calls.
You can disable parallel tool calls to force the model to execute tool calls sequentially.
This is useful if you want to execute tool calls in a specific order so that the state changes
introduced by one tool call are visible to the next tool call. (i.e. new actions or readables)

[Previous\\
\\
LangChainAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter) [Next\\
\\
GoogleGenerativeAIAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter)

### On this page

[Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter#example) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/llm-adapters/GroqAdapter.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## OpenAI Assistant Adapter
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

LLM Adapters

# OpenAIAssistantAdapter

Copilot Runtime adapter for OpenAI Assistant API.

Copilot Runtime adapter for the OpenAI Assistant API.

## [Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter\#example)

```
import { CopilotRuntime, OpenAIAssistantAdapter } from "@copilotkit/runtime";
import OpenAI from "openai";

const copilotKit = new CopilotRuntime();

const openai = new OpenAI({
  organization: "<your-organization-id>",
  apiKey: "<your-api-key>",
});

return new OpenAIAssistantAdapter({
  openai,
  assistantId: "<your-assistant-id>",
  codeInterpreterEnabled: true,
  fileSearchEnabled: true,
});
```

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter\#constructor-parameters)

assistantIdstringrequired

The ID of the assistant to use.

openaiOpenAI

An optional OpenAI instance to use. If not provided, a new instance will be created.

codeInterpreterEnabledboolean

Default:"true"

Whether to enable code interpretation.

fileSearchEnabledboolean

Default:"true"

Whether to enable file search.

disableParallelToolCallsboolean

Default:"false"

Whether to disable parallel tool calls.
You can disable parallel tool calls to force the model to execute tool calls sequentially.
This is useful if you want to execute tool calls in a specific order so that the state changes
introduced by one tool call are visible to the next tool call. (i.e. new actions or readables)

[Previous\\
\\
OpenAIAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter) [Next\\
\\
AnthropicAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/AnthropicAdapter)

### On this page

[Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter#example) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/llm-adapters/OpenAIAssistantAdapter.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangChainAdapter Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

LLM Adapters

# LangChainAdapter

Copilot Runtime adapter for LangChain.

Copilot Runtime adapter for LangChain.

## [Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter\#example)

```
import { CopilotRuntime, LangChainAdapter } from "@copilotkit/runtime";
import { ChatOpenAI } from "@langchain/openai";

const copilotKit = new CopilotRuntime();

const model = new ChatOpenAI({
  model: "gpt-4o",
  apiKey: "<your-api-key>",
});

return new LangChainAdapter({
  chainFn: async ({ messages, tools }) => {
    return model.bindTools(tools).stream(messages);
    // or optionally enable strict mode
    // return model.bindTools(tools, { strict: true }).stream(messages);
  }
});
```

The asynchronous handler function ( `chainFn`) can return any of the following:

- A simple `string` response
- A LangChain stream ( `IterableReadableStream`)
- A LangChain `BaseMessageChunk` object
- A LangChain `AIMessage` object

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter\#constructor-parameters)

chainFn(parameters: ChainFnParameters) => Promise<LangChainReturnType>required

A function that uses the LangChain API to generate a response.

[Previous\\
\\
AnthropicAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/AnthropicAdapter) [Next\\
\\
GroqAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter)

### On this page

[Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter#example) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/llm-adapters/LangChainAdapter.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Loading Agent State
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageSetting the threadId

Persistence

# Loading Agent State

Learn how threadId is used to load previous agent states.

### [Setting the threadId](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state\#setting-the-threadid)

When setting the `threadId` property in CopilotKit, i.e:

When using LangGraph platform, the `threadId` must be a UUID.

```
<CopilotKit threadId="2140b272-7180-410d-9526-f66210918b13">
  <YourApp />
</CopilotKit>
```

CopilotKit will restore the complete state of the thread, including the messages, from the database. (See [Message Persistence](https://docs.copilotkit.ai/coagents/persistence/message-persistence) for more details.)

### [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state\#loading-agent-state)

This means that the state of any agent will also be restored. For example:

```
const { state } = useCoAgent({name: "research_agent"});

// state will now be the state of research_agent in the thread id given above
```

### [Learn More](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state\#learn-more)

To learn more about persistence and state in CopilotKit, see:

- [Reading agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read)
- [Writing agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write)
- [Loading Message History](https://docs.copilotkit.ai/coagents/persistence/loading-message-history)

[Previous\\
\\
Multi-Agent Flows](https://docs.copilotkit.ai/coagents/multi-agent-flows) [Next\\
\\
Threads](https://docs.copilotkit.ai/coagents/persistence/loading-message-history)

### On this page

[Setting the threadId](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state#setting-the-threadid) [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state#loading-agent-state) [Learn More](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state#learn-more)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/persistence/loading-agent-state.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is CopilotKit?

# Introduction

Build production-ready Copilots and Agents effortlessly.

# [What is CopilotKit?](https://docs.copilotkit.ai/?ref=github_readme\#what-is-copilotkit)

At its core, CopilotKit is a set of tools that make it easy to **let your users work**
**alongside Large Language Models (LLMs) to accomplish generative tasks** directly in
your application. Instead of just using the LLM to generate content, you can let it
take direct action alongside your users.

Interacting with these models can be done directly ( **Standard**) or through agents ( **CoAgents**).

## [Standard](https://docs.copilotkit.ai/?ref=github_readme\#standard)

Utilize CopilotKit's standard agentic runloop to get started quickly.

[**Quickstart** \\
Get started with CopilotKit directly in your application.](https://docs.copilotkit.ai/quickstart) [**Tutorial** \\
Build an AI todo app with CopilotKit in minutes.](https://docs.copilotkit.ai/tutorials/ai-todo-app/overview)

## [CoAgents](https://docs.copilotkit.ai/?ref=github_readme\#coagents)

When you need **complete control** over the agentic runloop, you can use **CoAgents**. Bridge the remaining gap between demos and production-ready experiences.

[**LangGraph** \\
User-interactive agents with LangGraph.](https://docs.copilotkit.ai/coagents) [CrewAI\\
**CrewAI Crews** \\
Build multi-agent workflows with CrewAI.](https://docs.copilotkit.ai/crewai-crews) [CrewAI\\
**CrewAI Flows** \\
Build multi-agent workflows with CrewAI.](https://docs.copilotkit.ai/crewai-flows)

## [CopilotKit in Action](https://docs.copilotkit.ai/?ref=github_readme\#copilotkit-in-action)

Need some inspiration? Check out somethings we've built with CopilotKit.

[**Feature Viewer** \\
Learn about all of the best features CopilotKit has to offer with an interactive experience.](https://feature-viewer-langgraph.vercel.app/) [**Spreadsheet Copilot** \\
A powerful spreadsheet assistant that helps users analyze data, create formulas, and generate insights.](https://spreadsheet-demo-tau.vercel.app/) [**SaaS Copilot** \\
An AI-powered banking interface that helps users understand and interact with their finances.](https://brex-demo-temp.vercel.app/) [**Agent-Native Travel Planner** \\
Interactive travel planning assistant that helps users generate and build travel itineraries.](https://examples-coagents-ai-travel-app.vercel.app/) [**Agent-Native Research Canvas** \\
An intelligent research assistant that helps users synthesize information across multiple sources.](https://examples-coagents-research-canvas-ui.vercel.app/)

## [How does CopilotKit work?](https://docs.copilotkit.ai/?ref=github_readme\#how-does-copilotkit-work)

CopilotKit is thoughtfully architected to scale with you, your teams, and your product.

![](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Farchitecture-diagram.png&w=3840&q=75)

## [Common Questions](https://docs.copilotkit.ai/?ref=github_readme\#common-questions)

We've got answers to some common questions!

### What is a Copilot?

### What are the main features of CopilotKit?

### How does it all work?

### Can I use any LLM with CopilotKit?

[Next\\
\\
Quickstart](https://docs.copilotkit.ai/quickstart)

### On this page

[What is CopilotKit?](https://docs.copilotkit.ai/?ref=github_readme#what-is-copilotkit) [Standard](https://docs.copilotkit.ai/?ref=github_readme#standard) [CoAgents](https://docs.copilotkit.ai/?ref=github_readme#coagents) [CopilotKit in Action](https://docs.copilotkit.ai/?ref=github_readme#copilotkit-in-action) [How does CopilotKit work?](https://docs.copilotkit.ai/?ref=github_readme#how-does-copilotkit-work) [Common Questions](https://docs.copilotkit.ai/?ref=github_readme#common-questions) [Concierge](https://docs.copilotkit.ai/?ref=github_readme#concierge) [Worker](https://docs.copilotkit.ai/?ref=github_readme#worker) [Batteries included chat components](https://docs.copilotkit.ai/?ref=github_readme#batteries-included-chat-components) [Deeply integrated Copilots](https://docs.copilotkit.ai/?ref=github_readme#deeply-integrated-copilots) [Rich agentic experiences](https://docs.copilotkit.ai/?ref=github_readme#rich-agentic-experiences)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Google Generative AI
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageExample

LLM Adapters

# GoogleGenerativeAIAdapter

Copilot Runtime adapter for Google Generative AI (e.g. Gemini).

Copilot Runtime adapter for Google Generative AI (e.g. Gemini).

## [Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter\#example)

```
import { CopilotRuntime, GoogleGenerativeAIAdapter } from "@copilotkit/runtime";
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI(process.env["GOOGLE_API_KEY"]);

const copilotKit = new CopilotRuntime();

return new GoogleGenerativeAIAdapter({ model: "gemini-1.5-pro" });
```

## [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter\#constructor-parameters)

modelstring

A custom Google Generative AI model to use.

[Previous\\
\\
GroqAdapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter) [Next\\
\\
CopilotTask](https://docs.copilotkit.ai/reference/classes/CopilotTask)

### On this page

[Example](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter#example) [Constructor Parameters](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter#constructor-parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/classes/llm-adapters/GoogleGenerativeAIAdapter.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CrewAI Documentation
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCopilot Infrastructure for CrewAI Crews

# Introduction

Build Agent-Native Applications (ANAs) powered by CopilotKit and CrewAI Flows.

# [Copilot Infrastructure for CrewAI Crews](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com\#copilot-infrastructure-for-crewai-crews)

Full user-interaction infrastructure for your agents, to turn your agents into Copilot Agents (CoAgents).

## [Building blocks of a CoAgent](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com\#building-blocks-of-a-coagent)

Everything you need to build Agent-Native Applications (ANAs), right out of the box.

[Agentic Chat UI\\
\\
In-app chat powered by your agent.](https://docs.copilotkit.ai/crewai-crews/agentic-chat-ui)

[Shared State\\
\\
Your agent can see everything in your app, and vice versa.](https://docs.copilotkit.ai/crewai-crews/shared-state)

[Generative UI\\
\\
UI that updates in real-time based on your agent's state.](https://docs.copilotkit.ai/crewai-crews/generative-ui)

[Frontend Tools\\
\\
Give your agent the ability to take action in your application.](https://docs.copilotkit.ai/crewai-crews/frontend-actions)

[Multi-Agent Coordination\\
\\
Route your agent to the right agent based on the user's request.](https://docs.copilotkit.ai/crewai-crews/multi-agent-flows)

[Human-in-the-Loop\\
\\
Set smart checkpoints where humans can guide your agents.](https://docs.copilotkit.ai/crewai-crews/human-in-the-loop)

## [Ready to get started?](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com\#ready-to-get-started)

Get started with CoAgents in as little as 5 minutes with one of our guides or tutorials.

[Quickstart\\
\\
Learn how to build your first CoAgent in 10 minutes.](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai)

## [Common Questions](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com\#common-questions)

Have a question about CoAgents? You're in the right place!

### Can you explain what a CoAgent is in more detail?

[Next\\
\\
Quickstart CrewAI Crews](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai)

### On this page

[Copilot Infrastructure for CrewAI Crews](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com#copilot-infrastructure-for-crewai-crews) [Building blocks of a CoAgent](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com#building-blocks-of-a-coagent) [Ready to get started?](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com#ready-to-get-started) [Common Questions](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com#common-questions)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-crews/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agent State Management
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Shared State](https://docs.copilotkit.ai/coagents/shared-state)

# Agent state inputs and outputs

Decide which state properties are received and returned to the frontend

## [What is this?](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs\#what-is-this)

Not all state properties are relevant for frontend-backend sharing.
This guide shows how to ensure only the right portion of state is communicated back and forth.

This guide is based on [LangGraph's Input/Output Schema feature](https://langchain-ai.github.io/langgraph/how-tos/input_output_schema/)

## [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs\#when-should-i-use-this)

Depending on your implementation, some properties are meant to be processed internally, while some others are the way for the UI to communicate user input.
In addition, some state properties contain a lot of information. Syncing them back and forth between the agent and UI can be costly, while it might not have any practical benefit.

## [Implementation](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs\#implementation)

### [Examine our old state](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs\#examine-our-old-state)

LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
let's assume that the state our agent should be using, can be described like this:

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState
from typing import Literal

class AgentState(CopilotKitState):
    question: str
    answer: str
    resources: List[str]
```

### [Divide state to Input and Output](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs\#divide-state-to-input-and-output)

Our example case lists several state properties, which with its own purpose:

- The question is being asked by the user, expecting the llm to answer
- The answer is what the LLM returns
- The resources list will be used by the LLM to answer the question, and should not be communicated to the user, or set by them.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState
from typing import Literal

# Divide the state to 3 parts

# Input schema for inputs you are willing to accept from the frontend
class InputState(CopilotKitState):
  question: str

# Output schema for output you are willing to pass to the frontend
class OutputState(CopilotKitState):
  answer: str

# The full schema, including the inputs, outputs and internal state ("resources" in our case)
class OverallState(InputState, OutputState):
  resources: List[str]

async def answer_node(state: OverallState, config: RunnableConfig):
  """
  Standard chat node, meant to answer general questions.
  """

  model = ChatOpenAI()

  # add the input question in the system prompt so it's passed to the LLM
  system_message = SystemMessage(
    content=f"You are a helpful assistant. Answer the question: {state.get('question')}"
  )

  response = await model.ainvoke([\
    system_message,\
    *state["messages"],\
  ], config)

  # ...add the rest of the agent implementation

  # extract the answer, which will be assigned to the state soon
  answer = response.content

  return {
     "messages": response,
      # include the answer in the returned state
     "answer": answer
  }


# finally, before compiling the graph, we define the 3 state components
builder = StateGraph(OverallState, input=InputState, output=OutputState)

# add all the different nodes and edges and compile the graph
builder.add_node("answer_node", answer_node)
builder.add_edge(START, "answer_node")
builder.add_edge("answer_node", END)
graph = builder.compile()
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs\#give-it-a-try)

Now that we know which state properties our agent emits, we can inspect the state and expect the following to happen:

- While we are able to provide a question, we will not receive it back from the agent. If we are using it in our UI, we need to remember the UI is the source of truth for it
- Answer will change once it's returned back from the agent
- The UI has no access to resources.

```
import { useCoAgent } from "@copilotkit/react-core";

type AgentState = {
  question: string;
  answer: string;
}

const { state } = useCoAgent<AgentState>({
  name: "sample_agent",
  initialState: {
    question: "How's is the weather in SF?",
  }
});

console.log(state) // You can expect seeing "answer" change, while the others are not returned from the agent
```

[Previous\\
\\
Writing agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write) [Next\\
\\
Predictive state updates](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs#implementation) [Examine our old state](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs#examine-our-old-state) [Divide state to Input and Output](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs#divide-state-to-input-and-output) [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/shared-state/state-inputs-outputs.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Predictive State Updates
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Shared State](https://docs.copilotkit.ai/coagents/shared-state)

# Predictive state updates

Stream in-progress agent state updates to the frontend.

This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the [implementation](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#implementation) section applied to it!

## [What is this?](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#what-is-this)

A LangGraph agent's state updates discontinuosly; only across node transitions in the graph.
But even a _single node_ in the graph often takes many seconds to run and contain sub-steps of interest to the user.

**Agent-native applications** reflect to the end-user what the agent is doing **as continuously possible.**

CopilotKit enables this through its concept of **_predictive state updates_**.

## [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#when-should-i-use-this)

You can use this when you want to provide the user with feedback about what your agent is doing, specifically to:

- **Keep users engaged** by avoiding long loading indicators
- **Build trust** by demonstrating what the agent is working on
- Enable **agent steering** \- allowing users to course-correct the agent if needed

## [Important Note](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#important-note)

When a node in your LangGraph finishes executing, **its returned state becomes the single source of truth**. While intermediate state updates are great for real-time feedback, any changes you want to persist must be explicitly included in the node's final returned state. Otherwise, they will be overwritten when the node completes.

## [Implementation](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#implementation)

### [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#install-the-copilotkit-sdk)

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic
experiences with CopilotKit requires our LangGraph SDK.

PythonTypeScript

Poetrypipconda

```
poetry add copilotkit
# including support for crewai
poetry add copilotkit[crewai]
```

### [Define the state](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#define-the-state)

We'll be defining a `observed_steps` field in the state, which will be updated as the agent writes different sections of the report.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState
from typing import Literal

class AgentState(CopilotKitState):
    observed_steps: list[str]  # Array of completed steps
```

### [Emit the intermediate state](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#emit-the-intermediate-state)

How would you like to emit state updates?

You can either manually emit state updates or configure specific tool calls to emit updates.

Manual Predictive State Updates

Manually emit state updates for maximum control over when updates occur.

Tool-Based Predictive State Updates

Configure specific tool calls to automatically emit intermediate state updates.

For long-running tasks, you can emit state updates progressively as predictions of the final state. In this example, we simulate a long-running task by executing a series of steps with a one second delay between each update.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit.langgraph import copilotkit_emit_state
# ...
async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["cpk_action_node", "tool_node", "__end__"]]:
    # ...

    # Simulate executing steps one by one
    steps = [\
        "Analyzing input data...",\
        "Identifying key patterns...",\
        "Generating recommendations...",\
        "Formatting final output..."\
    ]

    for step in steps:
        self.state["observed_steps"] = self.state.get("observed_steps", []) + [step]
        await copilotkit_emit_state(config, state)
        await asyncio.sleep(1)

    # ...
```

### [Observe the predictions](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#observe-the-predictions)

These predictions will be emitted as the agent runs, allowing you to track its progress before the final state is determined.

ui/app/page.tsx

```
import { useCoAgent, useCoAgentStateRender } from '@copilotkit/react-core';

// ...
type AgentState = {
    observed_steps: string[];
};

const YourMainContent = () => {
    // Get access to both predicted and final states
    const { state } = useCoAgent<AgentState>({ name: "sample_agent" });

    // Add a state renderer to observe predictions
    useCoAgentStateRender({
        name: "sample_agent",
        render: ({ state }) => {
            if (!state.observed_steps?.length) return null;
            return (
                <div>
                    <h3>Current Progress:</h3>
                    <ul>
                        {state.observed_steps.map((step, i) => (
                            <li key={i}>{step}</li>
                        ))}
                    </ul>
                </div>
            );
        },
    });

    return (
        <div>
            <h1>Agent Progress</h1>
            {state.observed_steps?.length > 0 && (
                <div>
                    <h3>Final Steps:</h3>
                    <ul>
                        {state.observed_steps.map((step, i) => (
                            <li key={i}>{step}</li>
                        ))}
                    </ul>
                </div>
            )}
        </div>
    )
}
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates\#give-it-a-try)

Now you'll notice that the state predictions are emitted as the agent makes progress, giving you insight into its work before the final state is determined.
You can apply this pattern to any long-running task in your agent.

[Previous\\
\\
Agent state inputs and outputs](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs) [Next\\
\\
Frontend Actions](https://docs.copilotkit.ai/coagents/frontend-actions)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#when-should-i-use-this) [Important Note](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#important-note) [Implementation](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#implementation) [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#install-the-copilotkit-sdk) [Define the state](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#define-the-state) [Emit the intermediate state](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#emit-the-intermediate-state) [Observe the predictions](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#observe-the-predictions) [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/shared-state/predictive-state-updates.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CopilotKit Migration Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Migrate to 1.8.2

Migration guide for CopilotKit 1.8.2

## [What's changed?](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2\#whats-changed)

### [New Look and Feel](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2\#new-look-and-feel)

CopilotKit 1.8.2 introduces a new default look and feel. This includes new use of theming variables, new components, and generally a fresh look.

**Click the button in the bottom right to see the new look and feel in action!**

### [Thumbs Up/Down Handlers](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2\#thumbs-updown-handlers)

The chat components now have `onThumbsUp` and `onThumbsDown` handlers. Specifying these will add icons to each message
on hover allowing the user to provide feedback.

```
<CopilotChat
  onThumbsUp={(message) => console.log(message)}
  onThumbsDown={(message) => console.log(message)}
/>
```

This was previously achievable in our framework, but we're making it first class now! You can use this to help fine-tune your model through CopilotKit
or just generally track user feedback.

### [ResponseButton prop removed](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2\#responsebutton-prop-removed)

The `ResponseButton` prop has been removed. This was a prop that was used to customize the button that appears after a response was generated
in the chat.

In its place, we now place buttons below each message for:

- Thumbs up
- Thumbs down
- Copy
- Regenerate

The behvior, icons and styling for each of these buttons can be customized. Checkout our [look and feel guides](https://docs.copilotkit.ai/guides/custom-look-and-feel) for more details.

### [Out-of-the-box dark mode support](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2\#out-of-the-box-dark-mode-support)

CopilotKit now has out-of-the-box dark mode support. This is controlled by the `.dark` class (Tailwind) as well as the
`color-scheme` CSS selector.

If you would like to make a custom theme, you can do so by checking out the [custom look and feel](https://docs.copilotkit.ai/guides/custom-look-and-feel) guides.

CopilotKit

Hey there Let's have a fun conversation!

[Previous\\
\\
Common Issues](https://docs.copilotkit.ai/troubleshooting/common-issues) [Next\\
\\
Code Contributions](https://docs.copilotkit.ai/contributing/code-contributions)

### On this page

[What's changed?](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2#whats-changed) [New Look and Feel](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2#new-look-and-feel) [Thumbs Up/Down Handlers](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2#thumbs-updown-handlers) [ResponseButton prop removed](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2#responsebutton-prop-removed) [Out-of-the-box dark mode support](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2#out-of-the-box-dark-mode-support)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/troubleshooting/migrate-to-1.8.2.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Generative UI Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageRender custom components in the chat UI

# Generative UI

Learn how to embed custom UI components in the chat window.

# [Render custom components in the chat UI](https://docs.copilotkit.ai/guides/generative-ui?ref=hackernoon.com\#render-custom-components-in-the-chat-ui)

When a user interacts with your Copilot, you may want to render a custom UI component. [`useCopilotAction`](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) allows to give the LLM the
option to render your custom component through the `render` property.

Render a componentFetch data & renderrenderAndWaitForResponse (HITL)Render stringsCatch all renders

[`useCopilotAction`](https://docs.copilotkit.ai/reference/hooks/useCopilotAction) can be used with a `render` function and without a `handler` to display information or UI elements within the chat.

Here's an example to render a calendar meeting.

![Example of render-only Copilot action](https://docs.copilotkit.ai/images/render-only-example.png)

```
"use client" // only necessary if you are using Next.js with the App Router.
import { useCopilotAction } from "@copilotkit/react-core";

export function YourComponent() {
  useCopilotAction({
    name: "showCalendarMeeting",
    description: "Displays calendar meeting information",
    parameters: [\
      {\
        name: "date",\
        type: "string",\
        description: "Meeting date (YYYY-MM-DD)",\
        required: true\
      },\
      {\
        name: "time",\
        type: "string",\
        description: "Meeting time (HH:mm)",\
        required: true\
      },\
      {\
        name: "meetingName",\
        type: "string",\
        description: "Name of the meeting",\
        required: false\
      }\
    ],

    render: ({ status, args }) => {
      const { date, time, meetingName } = args;

      if (status === 'inProgress') {
        return <LoadingView />; // Your own component for loading state
      } else {
        const meetingProps: CalendarMeetingCardProps = {
          date: date,
          time,
          meetingName
        };
        return <CalendarMeetingCardComponent {...meetingProps} />;
      }
    },
  });

  return (
    <>...</>
  );
}
```

### What do the different status states mean?

### Why do I need "use client" in Next.js with the App Router?

## [Test it out!](https://docs.copilotkit.ai/guides/generative-ui?ref=hackernoon.com\#test-it-out)

After defining the action with a render method, ask the copilot to perform the task. For example, you can now ask the copilot to "show tasks" and see the custom UI component rendered in the chat interface.

You can read more about the `useCopilotAction` hook
[here](https://docs.copilotkit.ai/reference/hooks/useCopilotAction).

[Previous\\
\\
Backend Data](https://docs.copilotkit.ai/guides/connect-your-data/backend) [Next\\
\\
Frontend Actions](https://docs.copilotkit.ai/guides/frontend-actions)

### On this page

[Render custom components in the chat UI](https://docs.copilotkit.ai/guides/generative-ui?ref=hackernoon.com#render-custom-components-in-the-chat-ui) [Test it out!](https://docs.copilotkit.ai/guides/generative-ui?ref=hackernoon.com#test-it-out)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/generative-ui.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agentic Generative UI
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Generative UI](https://docs.copilotkit.ai/coagents/generative-ui)

# Agentic Generative UI

Render the state of your agent with custom UI components.

This video demonstrates the [implementation](https://docs.copilotkit.ai/coagents/generative-ui/agentic#implementation) section applied to out [coagents starter project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter).

## [What is this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#what-is-this)

All LangGraph agents are stateful. This means that as your agent progresses through nodes, a state object is passed between them perserving
the overall state of a session. CopilotKit allows you to render this state in your application with custom UI components, which we call **Agentic Generative UI**.

## [When should I use this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#when-should-i-use-this)

Rendering the state of your agent in the UI is useful when you want to provide the user with feedback about the overall state of a session. A great example of this
is a situation where a user and an agent are working together to solve a problem. The agent can store a draft in its state which is then rendered in the UI.

## [Implementation](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#implementation)

### [Run and Connect your LangGraph to CopilotKit](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#run-and-connect-your-langgraph-to-copilotkit)

First, you'll need to make sure you have a running LangGraph. If you haven't already done this, you can follow the [getting started guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph)

This guide uses the [CoAgents starter repo](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) as its starting point.

### [Define your agent state](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#define-your-agent-state)

If you're not familiar with LangGraph, your graphs are stateful. As you progress through nodes, a state object is passed between them. CopilotKit
allows you to easily render this state in your application.

For the sake of this guide, let's say our state looks like this in our agent.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
# ...
from copilotkit import CopilotKitState # extends MessagesState
# ...

# This is the state of the agent.
# It inherits from the CopilotKitState properties from CopilotKit.
class AgentState(CopilotKitState):
    searches: list[dict]
```

### [Simulate state updates](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#simulate-state-updates)

Next, let's write some logic into our agent that will simulate state updates occurring.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
import asyncio
from typing import TypedDict
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from copilotkit import CopilotKitState
from copilotkit.langgraph import copilotkit_emit_state

class Searches(TypedDict):
    query: str
    done: bool

class AgentState(CopilotKitState):
    searches: list[Searches] = []

async def chat_node(state: AgentState, config: RunnableConfig):
    state["searches"] = [\
        {"query": "Initial research", "done": False},\
        {"query": "Retrieving sources", "done": False},\
        {"query": "Forming an answer", "done": False},\
    ]
    await copilotkit_emit_state(config, state)

    # Simulate state updates
    for search in state["searches"]:
        await asyncio.sleep(1)
        search["done"] = True
        await copilotkit_emit_state(config, state)

    # Run the model to generate a response
    response = await ChatOpenAI(model="gpt-4o").ainvoke([\
        SystemMessage(content="You are a helpful assistant."),\
        *state["messages"],\
    ], config)
```

### [Render state of the agent in the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#render-state-of-the-agent-in-the-chat)

Now we can utilize `useCoAgentStateRender` to render the state of our agent **in the chat**.

app/page.tsx

```
// ...
import { useCoAgentStateRender } from "@copilotkit/react-core";
// ...

// Define the state of the agent, should match the state of the agent in your LangGraph.
type AgentState = {
  searches: {
    query: string;
    done: boolean;
  }[];
};

function YourMainContent() {
  // ...


  // styles omitted for brevity
  useCoAgentStateRender<AgentState>({
    name: "sample_agent", // the name the agent is served as
    render: ({ state }) => (
      <div>
        {state.searches?.map((search, index) => (
          <div key={index}>
            {search.done ? "✅" : "❌"} {search.query}{search.done ? "" : "..."}
          </div>
        ))}
      </div>
    ),
  });

  // ...

  return <div>...</div>;
}
```

### [Render state outside of the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#render-state-outside-of-the-chat)

You can also render the state of your agent **outside of the chat**. This is useful when you want to render the state of your agent anywhere
other than the chat.

app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";
// ...

// Define the state of the agent, should match the state of the agent in your LangGraph.
type AgentState = {
  searches: {
    query: string;
    done: boolean;
  }[];
};

function YourMainContent() {
  // ...


  const { state } = useCoAgent<AgentState>({
    name: "sample_agent", // the name the agent is served as
  })

  // ...

  return (
    <div>
      {/* ... */}
      <div className="flex flex-col gap-2 mt-4">

        {state.searches?.map((search, index) => (
          <div key={index} className="flex flex-row">
            {search.done ? "✅" : "❌"} {search.query}
          </div>
        ))}
      </div>
    </div>
  )
}
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/generative-ui/agentic\#give-it-a-try)

You've now created a component that will render the agent's state in the chat.

[Previous\\
\\
Generative UI](https://docs.copilotkit.ai/coagents/generative-ui) [Next\\
\\
Tool-based Generative UI](https://docs.copilotkit.ai/coagents/generative-ui/tool-based)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/generative-ui/agentic#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/generative-ui/agentic#implementation) [Run and Connect your LangGraph to CopilotKit](https://docs.copilotkit.ai/coagents/generative-ui/agentic#run-and-connect-your-langgraph-to-copilotkit) [Define your agent state](https://docs.copilotkit.ai/coagents/generative-ui/agentic#define-your-agent-state) [Simulate state updates](https://docs.copilotkit.ai/coagents/generative-ui/agentic#simulate-state-updates) [Render state of the agent in the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic#render-state-of-the-agent-in-the-chat) [Render state outside of the chat](https://docs.copilotkit.ai/coagents/generative-ui/agentic#render-state-outside-of-the-chat) [Give it a try!](https://docs.copilotkit.ai/coagents/generative-ui/agentic#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/generative-ui/agentic.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## TypeScript Backend Actions
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageModify CopilotRuntime to include TypeScript/Node.js actions

[Backend Actions & Agents](https://docs.copilotkit.ai/guides/backend-actions)

# TypeScript (Node.js)

Implement native backend actions using TypeScript or Node.js in CopilotKit.

### Find your CopilotRuntime

The starting point for this section is the `CopilotRuntime` you set up during quickstart (the CopilotKit backend endpoint).
For a refresher, see [Self-Hosting](https://docs.copilotkit.ai/guides/self-hosting) (or alternatively, revisit the [quickstart](https://docs.copilotkit.ai/quickstart)).

**First, find your `CopilotRuntime` instance in your code.** You can simply search your codebase for `CopilotRuntime`.

If you followed the quickstart, it'll be where you set up the `/api/copilotkit` endpoint.

### [Modify CopilotRuntime to include TypeScript/Node.js actions](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions\#modify-copilotruntime-to-include-typescriptnodejs-actions)

Once you've located your `CopilotRuntime`, you can add TypeScript/Node.js actions by modifying its configuration. Here's how to implement native backend actions:

**Note** that `actions` is not merely an array of actions, but an array **generator**.
This generator takes `properties` and `url` as input.

This means you can **customize which backend actions are made available** according to the current frontend URL, as well as custom properties you can pass from the frontend.

/api/copilotkit/route.ts

```
const runtime = new CopilotRuntime({
  // ... existing configuration
  actions: ({properties, url}) => {
    // Note that actions returns not an array, but an array **generator**.
    // You can use the input parameters to the actions generator to expose different backend actions to the Copilot at different times:
    // `url` is the current URL on the frontend application.
    // `properties` contains custom properties you can pass from the frontend application.

    return [\
      {\
        name: "fetchNameForUserId",\
        description: "Fetches user name from the database for a given ID.",\
        parameters: [\
          {\
            name: "userId",\
            type: "string",\
            description: "The ID of the user to fetch data for.",\
            required: true,\
          },\
        ],\
        handler: async ({userId}: {userId: string}) => {\
          // do something with the userId\
          // return the user data\
          return {\
            name: "Darth Doe",\
          };\
        },\
      },\
    ]
  }
});

// ... rest of your route definition
```

### [Test your implementation](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions\#test-your-implementation)

After adding the action, test it by asking the copilot to perform the task. Observe how it selects the correct task, executes it, and streams back relevant responses.

## [Key Points](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions\#key-points)

- Each action is defined with a name, description, parameters, and a handler function.
- The handler function implements the actual logic of the action and can interact with your backend systems.

By using this method, you can create powerful, context-aware backend actions that integrate seamlessly with your CopilotKit application.

[Previous\\
\\
Backend Actions & Agents](https://docs.copilotkit.ai/guides/backend-actions) [Next\\
\\
LangChain.js](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions)

### On this page

[Modify CopilotRuntime to include TypeScript/Node.js actions](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions#modify-copilotruntime-to-include-typescriptnodejs-actions) [Test your implementation](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions#test-your-implementation) [Key Points](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions#key-points)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/backend-actions/typescript-backend-actions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Tool-based Generative UI
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Generative UI](https://docs.copilotkit.ai/crewai-crews/generative-ui)

# Tool-based Generative UI

Render your agent's tool calls with custom UI components.

This video demonstrates the [implementation](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#implementation) section applied
to out [coagents starter\\
project](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews).

## [What is this?](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#what-is-this)

Tools are a way for the LLM to call predefined, typically, deterministic functions. CopilotKit allows you to render these tools in the UI
as a custom component, which we call **Generative UI**.

## [When should I use this?](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#when-should-i-use-this)

Rendering tools in the UI is useful when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## [Implementation](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#implementation)

### [Run and connect your agent](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#run-and-connect-your-agent)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter-crewai-crews) as a starting point
as this guide uses it as a starting point.

### [Render the tool call in your frontend](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#render-the-tool-call-in-your-frontend)

In the case of CrewAI Crew agents, there is one tool call that indicates that the crew is being executed. It has the same name as the crew. In this example, the crew is named `research_crew`. To display progress of the crew, we just need to add a `useCopilotAction` hook to render the tool call in
the UI.

Important

In order to render a tool call in the UI, the name of the action must match
the name of the tool.

app/page.tsx

```
import { useCopilotAction } from "@copilotkit/react-core";
// ...

const YourMainContent = () => {
  // ...

  useCopilotAction({
    name: "research_crew",
    parameters: [\
      {\
        name: "topic",\
      },\
      {\
        name: "current_year",\
      },\
    ],
    render({ args, status }) {
      return (
        <div className="m-4 p-4 bg-gray-100 rounded shadow">
          <h1 className="text-center text-sm">
            Researching {args.topic} in {args.current_year}{" "}
            {status == "complete" ? "✅" : "⏳"}
          </h1>
        </div>
      );
    },
  });
  // ...
};
```

### [Give it a try!](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#give-it-a-try)

Try giving the crew enough information to complete the task, i.e. "Research the state of AI in 2025". You should see the custom UI component that we added render the tool call and display the arguments that were passed to the tool.

## [Rendering Arbitrary Tool Calls](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based\#rendering-arbitrary-tool-calls)

When working with agents, they may call tools that you haven't explicitly defined UI components for. You can use a catch-all action to render these tool calls:

```
import {
  useCopilotAction,
  CatchAllActionRenderProps,
} from "@copilotkit/react-core";

useCopilotAction({
  name: "*",
  followUp: false,
  render: ({ name, args, status, result }: CatchAllActionRenderProps<[]>) => {
    return (
      <div className="m-4 p-4 bg-gray-100 rounded shadow">
        <h2 className="text-sm font-medium">Tool: {name}</h2>
        <pre className="mt-2 text-xs overflow-auto">
          {JSON.stringify(args, null, 2)}
        </pre>
        {status === "complete" && (
          <div className="mt-2 text-xs text-green-600">✓ Complete</div>
        )}
      </div>
    );
  },
});
```

This will render any tool call that doesn't have a specific UI component defined for it, displaying the tool name, arguments, and completion status.

[Previous\\
\\
Agentic Generative UI](https://docs.copilotkit.ai/crewai-crews/generative-ui/agentic) [Next\\
\\
Human in the Loop (HITL)](https://docs.copilotkit.ai/crewai-crews/human-in-the-loop)

### On this page

[What is this?](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#what-is-this) [When should I use this?](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#implementation) [Run and connect your agent](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#run-and-connect-your-agent) [Render the tool call in your frontend](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#render-the-tool-call-in-your-frontend) [Give it a try!](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#give-it-a-try) [Rendering Arbitrary Tool Calls](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based#rendering-arbitrary-tool-calls)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-crews/generative-ui/tool-based.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangGraph Platform Deployment
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageDeploy a Graph to LangGraph Platform

[Backend Actions & Agents](https://docs.copilotkit.ai/guides/backend-actions)

# Remote Endpoint (LangGraph Platform)

Connect your CopilotKit application to an agent deployed on LangGraph Platform.

This guide assumes you've created a LangGraph agent, and have a `langgraph.json` file set up. If you need a quick introduction, check out [this brief example\\
from the LangGraph docs](https://langchain-ai.github.io/langgraph/) or follow one of our demos.

## [Deploy a Graph to LangGraph Platform](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint\#deploy-a-graph-to-langgraph-platform)

### [Deploy your agent](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint\#deploy-your-agent)

First, you need to host your agent so that CopilotKit can access it.

Local (LangGraph Studio)Self hosted (FastAPI)LangGraph Platform

For local development, you can use the [LangGraph CLI](https://langchain-ai.github.io/langgraph/cloud/reference/cli/) to start a development server and LangGraph studio session.

You will need a [LangSmith account](https://smith.langchain.com/) to use this method.

```
# For Python 3.11 or above
langgraph dev --host localhost --port 8000
```

```
# For TypeScript with Node 18 or above
npx @langchain/langgraph-cli dev --host localhost --port 8000
```

After starting the LangGraph server, the deployment URL will be `http://localhost:8000`.

### Having trouble?

### [Setup your Copilot Runtime](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint\#setup-your-copilot-runtime)

Copilot Cloud (Recommended)

I'm already using or want to use Copilot Cloud.

Self-Hosted

I'm using or want to use a self-hosted Copilot Runtime.

If you followed the [Copilot Cloud Quickstart](https://docs.copilotkit.ai/docs/quickstart) and opted to use CopilotCloud,
you only need to add your LangGraph Platform deployment URL and LangSmith API key to your CopilotCloud.

### Haven't setup Copilot Cloud yet? Click here!

To connect to LangGraph agents through Copilot Cloud, we leverage a concept called "Remote Endpoints"
which allow CopilotKit runtime to connect to various backends.

Navigate to [cloud.copilotkit.ai](https://go.copilotkit.ai/copilot-cloud-button-docs?ref=docs&session_id=0196217c-152e-758e-a4fb-d41efea3cec3) and follow the video!

You'll need a LangSmith API key which you can get with [this guide](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key#create-an-api-key) on LangSmith's website.

### Using LangGraph Studio

![Configure Remote Endpoint LangGraph](https://docs.copilotkit.ai/images/copilot-cloud/cpk-cloud-lgp-endpoint.gif)

🎉 You should now see your LangGraph agent in the list of available agents in CopilotKit!

### [Test Your Implementation](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint\#test-your-implementation)

After setting up the remote endpoint and modifying your `CopilotRuntime`, you can test your implementation by asking the copilot to perform actions that invoke your agent.

The graph and interactions can viewed in [LangGraph Studio](https://docs.copilotkit.ai/guides/backend-actions/smith.langchain.com/studio) and any logs should be available on [LangSmith](https://docs.copilotkit.ai/guides/backend-actions/smith.langchain.com)

* * *

## [Troubleshooting](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint\#troubleshooting)

A few things to try if you are running into trouble:

1. Make sure that you listed your agents according to the graphs mentioned in the `langgraph.json` file
2. Make sure the agent names are the same between the agent Python implementation, the `langgraph.json` file and the remote endpoint declaration
3. Make sure the LangGraph Platform deployment has all environment variables listed as you need them to be, according to your agent implementation

[Previous\\
\\
Remote Endpoint (Python)](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint) [Next\\
\\
Customize Instructions](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior)

### On this page

[Deploy a Graph to LangGraph Platform](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint#deploy-a-graph-to-langgraph-platform) [Deploy your agent](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint#deploy-your-agent) [Setup your Copilot Runtime](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint#setup-your-copilot-runtime) [Test Your Implementation](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint#test-your-implementation) [Troubleshooting](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint#troubleshooting)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/backend-actions/langgraph-platform-endpoint.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Remote Backend Integration
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageStand up a FastAPI server using the CopilotKit Python SDK

[Backend Actions & Agents](https://docs.copilotkit.ai/guides/backend-actions)

# Remote Endpoint (Python)

Connect your CopilotKit application to a remote backend endpoint, allowing integration with Python-based services or other non-Node.js backends.

## [Stand up a FastAPI server using the CopilotKit Python SDK](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#stand-up-a-fastapi-server-using-the-copilotkit-python-sdk)

### [Install CopilotKit Python SDK and Dependencies](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#install-copilotkit-python-sdk-and-dependencies)

To integrate a Python backend with your CopilotKit application, set up your project and install the necessary dependencies by choosing your dependency management solution below.

Poetrypipconda

#### [Initialize a New Poetry Project](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#initialize-a-new-poetry-project)

Run the following command to create and initialize a new Poetry project:

```
poetry new My-CopilotKit-Remote-Endpoint
```

Follow the prompts to set up your `pyproject.toml`.

#### [Install Dependencies](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#install-dependencies)

After initializing the project, install the dependencies:

```
poetry add copilotkit fastapi uvicorn
# or including support for crewai
poetry add copilotkit[crewai] fastapi uvicorn
```

**Dependencies:**

- **copilotkit**: The CopilotKit Python SDK.
- **fastapi**: A modern, fast (high-performance) web framework for building APIs with Python.
- **uvicorn**: A lightning-fast ASGI server for Python.

### [Set Up a FastAPI Server](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#set-up-a-fastapi-server)

Create a new Python file `/my_copilotkit_remote_endpoint/server.py` and set up a FastAPI server:

/my\_copilotkit\_remote\_endpoint/server.py

```
from fastapi import FastAPI

app = FastAPI()
```

### [Define Your Backend Actions](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#define-your-backend-actions)

Import the CopilotKit SDK and define your backend actions. For example:

/my\_copilotkit\_remote\_endpoint/server.py

```
from fastapi import FastAPI
from copilotkit.integrations.fastapi import add_fastapi_endpoint
from copilotkit import CopilotKitRemoteEndpoint, Action as CopilotAction

app = FastAPI()

# Define your backend action
async def fetch_name_for_user_id(userId: str):
    # Replace with your database logic
    return {"name": "User_" + userId}

# this is a dummy action for demonstration purposes
action = CopilotAction(
    name="fetchNameForUserId",
    description="Fetches user name from the database for a given ID.",
    parameters=[\
        {\
            "name": "userId",\
            "type": "string",\
            "description": "The ID of the user to fetch data for.",\
            "required": True,\
        }\
    ],
    handler=fetch_name_for_user_id
)

# Initialize the CopilotKit SDK
sdk = CopilotKitRemoteEndpoint(actions=[action])

# Add the CopilotKit endpoint to your FastAPI app
add_fastapi_endpoint(app, sdk, "/copilotkit_remote")

def main():
    """Run the uvicorn server."""
    import uvicorn
    uvicorn.run("server:app", host="0.0.0.0", port=8000, reload=True)

if __name__ == "__main__":
    main()
```

### [Run Your FastAPI Server](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#run-your-fastapi-server)

Since we've added the entry point in `server.py`, you can run your FastAPI server directly by executing the script:

Poetrypipconda

```
poetry run python3 server.py
```

**Note:** Ensure that you're in the same directory as `server.py` when running this command.

## [Connect your app to the remote endpoint](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#connect-your-app-to-the-remote-endpoint)

Now that you've set up your FastAPI server with the backend actions, integrate it into your CopilotKit application by modifying your `CopilotRuntime` configuration.

Copilot Cloud (Recommended)

I want to use Copilot Cloud to connect to my remote endpoint.

Self-Hosted Copilot Runtime

I want to use a self-hosted Copilot Runtime to connect to my remote endpoint.

To connect a FastAPI server to Copilot Cloud, we leverage a concept called "Remote Endpoints"
which allow CopilotKit runtime to connect to various backends.

To get started, [navigate to Copilot Cloud](https://go.copilotkit.ai/copilot-cloud-button-docs?ref=docs&session_id=0196217c-93b4-7a50-92fd-231e440765bd).

Don't want to use a tunnel?

Just skip the tunnel setup and use your hosted FastAPI server address instead.

```
npx copilotkit@latest dev --port <port_number>
```

![Configure Remote Endpoint](https://docs.copilotkit.ai/images/copilot-cloud/cpk-cloud-remote-endpoint-setup.gif)

You should now see your CopilotKit runtime in the list of available agents in CopilotKit!

### [Test Your Implementation](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#test-your-implementation)

After setting up the remote endpoint and modifying your `CopilotRuntime`, you can test your implementation by asking the copilot to perform actions that invoke your Python backend. For example, ask the copilot: "Fetch the name for user ID `123`."

### [Advanced](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#advanced)

#### [Configuring the Thread Pool Executor](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#configuring-the-thread-pool-executor)

The request to the remote endpoint is made in a thread pool executor. You can configure the size of the thread pool executor by passing the `max_workers` parameter to the `add_fastapi_endpoint` function.

```
add_fastapi_endpoint(app, sdk, "/copilotkit_remote", max_workers=10) # default is 10
```

#### [Dynamically returning actions and agents](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint\#dynamically-returning-actions-and-agents)

Both the `actions` and `agents` parameters can optionally be functions that return a list of actions or agents. This allows you to dynamically return actions and agents based on the user's request.

For example, to dynamically configure an agent based on properties from the frontend, set the properties on the frontend first:

```
<CopilotKit properties={{someProperty: "xyz"}}>
   <YourApp />
</CopilotKit>
```

Then, in your backend, use a function to return dynamically configured agents:

```
def build_agents(context):
    return [\
        LangGraphAgent(\
            name="some_agent",\
            description="This agent does something",\
            graph=graph,\
            langgraph_config={\
                "some_property": context["properties"]["someProperty"]\
            }\
        )\
    ]


app = FastAPI()
sdk = CopilotKitRemoteEndpoint(
    agents=build_agents,
)
```

* * *

[Previous\\
\\
LangServe actions](https://docs.copilotkit.ai/guides/backend-actions/langserve-backend-actions) [Next\\
\\
Remote Endpoint (LangGraph Platform)](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint)

### On this page

[Stand up a FastAPI server using the CopilotKit Python SDK](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#stand-up-a-fastapi-server-using-the-copilotkit-python-sdk) [Install CopilotKit Python SDK and Dependencies](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#install-copilotkit-python-sdk-and-dependencies) [Initialize a New Poetry Project](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#initialize-a-new-poetry-project) [Install Dependencies](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#install-dependencies) [Set Up a Virtual Environment (optional)](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#set-up-a-virtual-environment-optional) [Install Dependencies](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#install-dependencies-1) [Create a New Conda Environment](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#create-a-new-conda-environment) [Install Dependencies](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#install-dependencies-2) [Set Up a FastAPI Server](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#set-up-a-fastapi-server) [Define Your Backend Actions](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#define-your-backend-actions) [Run Your FastAPI Server](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#run-your-fastapi-server) [Connect your app to the remote endpoint](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#connect-your-app-to-the-remote-endpoint) [Troubleshooting](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#troubleshooting) [Test Your Implementation](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#test-your-implementation) [Advanced](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#advanced) [Configuring the Thread Pool Executor](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#configuring-the-thread-pool-executor) [Dynamically returning actions and agents](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint#dynamically-returning-actions-and-agents)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/backend-actions/remote-backend-endpoint.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Human-in-the-Loop Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is Human-in-the-Loop (HITL)?

# Human in the Loop (HITL)

Allow your agent and users to collaborate on complex tasks.

## [What is Human-in-the-Loop (HITL)?](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop\#what-is-human-in-the-loop-hitl)

Human-in-the-loop (HITL) allows agents to request human input or approval during execution, making AI systems more reliable and trustworthy. This pattern is essential when building AI applications that need to handle complex decisions or actions that require human judgment.

![Agentic Copilot Human in the Loop](https://docs.copilotkit.ai/images/coagents/coagents-hitl-infographic.png)

## [When should I use this?](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop\#when-should-i-use-this)

HITL combines the efficiency of AI with human judgment, creating a system that's both powerful and reliable. The key advantages include:

- **Quality Control**: Human oversight at critical decision points
- **Edge Cases**: Graceful handling of low-confidence situations
- **Expert Input**: Leverage human expertise when needed
- **Reliability**: More robust system for real-world use

## [How can I use this?](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop\#how-can-i-use-this)

Read more about the approach to HITL in CrewAI Flows.

[Flow-based\\
\\
Utilize CrewAI Flows to create Human-in-the-Loop workflows.](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop/flow)

[Previous\\
\\
Tool-based Generative UI](https://docs.copilotkit.ai/crewai-flows/generative-ui/tool-based) [Next\\
\\
CrewAI Flows](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop/flow)

### On this page

[What is Human-in-the-Loop (HITL)?](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop#what-is-human-in-the-loop-hitl) [When should I use this?](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop#when-should-i-use-this) [How can I use this?](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop#how-can-i-use-this)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/crewai-flows/human-in-the-loop/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Authenticated Actions Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageIntroduction

# Authenticated Actions  Cloud Only

## [Introduction](https://docs.copilotkit.ai/guides/authenticated-actions\#introduction)

CopilotKit Cloud enables secure propagation of authentication state within AI conversations, allowing your copilot to interact with authenticated backend services and tools on behalf of the user.

This feature is only available with [CopilotKit Cloud](https://cloud.copilotkit.ai/).

## [Overview](https://docs.copilotkit.ai/guides/authenticated-actions\#overview)

When building AI copilots that interact with user-specific data or services (like calendars, emails, or custom APIs), you need to ensure that:

1. The user is properly authenticated
2. The authentication state is securely propagated to backend tools
3. The copilot maintains proper authorization context

## [How It Works](https://docs.copilotkit.ai/guides/authenticated-actions\#how-it-works)

### [Authentication Flow](https://docs.copilotkit.ai/guides/authenticated-actions\#authentication-flow)

1. Your frontend app configures authentication state using `authConfig_c`
2. When a user authenticates, their auth state (headers, metadata) is securely captured
3. CopilotKit Cloud Runtime maintains this auth context throughout the conversation
4. When the LLM or runloop needs to call your registered endpoints/tools:
   - All auth headers are automatically propagated
   - Your endpoints receive the same auth context
   - Tools can verify user identity and permissions

### [Example Scenario](https://docs.copilotkit.ai/guides/authenticated-actions\#example-scenario)

This means your backend tools and APIs:

- Receive the same authentication headers as your frontend
- Can verify user identity and permissions
- Maintain security context throughout the AI interaction
- Don't need additional auth handling specific to CopilotKit

## [Frontend Implementation](https://docs.copilotkit.ai/guides/authenticated-actions\#frontend-implementation)

### [Configure Authentication State](https://docs.copilotkit.ai/guides/authenticated-actions\#configure-authentication-state)

```
import { CopilotKit } from "@copilotkit/react-core";

interface AuthState {
  status: "authenticated" | "unauthenticated";
  authHeaders: Record<string, string>;
  userId?: string;
  metadata?: Record<string, any>;
}

// Your SignInComponent component
function SignInComponent({
  onSignInComplete,
}: {
  onSignInComplete: (authState: AuthState) => void;
}) {
  const handleAuth = async () => {
    // Your auth logic (e.g., OAuth, custom auth)
    const authState = {
      status: "authenticated",
      authHeaders: {
        Authorization: "Bearer your_token",
        // Add any other headers needed by your backend
      },
      userId: "user_123",
      metadata: {
        email: "user@example.com",
        // Any other user context needed by tools
      },
    };

    onAuthComplete(authState);
  };

  return <button onClick={handleAuth}>Authenticate</button>;
}

// Root configuration
export default function App() {
  return (
    <CopilotKit
      publicApiKey={process.env.COPILOTKIT_PUBLIC_API_KEY}
      authConfig_c={{
        SignInComponent,
      }}
    >
      {/* Your app */}
    </CopilotKit>
  );
}
```

## [Backend Integration](https://docs.copilotkit.ai/guides/authenticated-actions\#backend-integration)

Your backend endpoints will receive the authentication context automatically. Example of a tool endpoint:

```
// Example backend endpoint
async function handleCalendarRequest(req, res) {
  // Auth headers from the frontend are automatically available
  const authHeader = req.headers.authorization;
  const userId = req.headers["x-user-id"];

  // Verify authentication as you normally would
  if (!isValidAuth(authHeader)) {
    return res.status(401).json({ error: "Unauthorized" });
  }

  // Proceed with authenticated operation
  const calendar = await getCalendarForUser(userId);
  return res.json(calendar);
}
```

## [Best Practices](https://docs.copilotkit.ai/guides/authenticated-actions\#best-practices)

1. **Authentication Headers**
   - Include all necessary auth tokens
   - Add relevant user context
   - Consider token expiration
   - Handle refresh tokens if needed
2. **Backend Security**
   - Always verify auth headers
   - Implement proper validation
   - Use secure token verification
   - Handle expired tokens gracefully
3. **Error Handling**
   - Provide clear auth errors
   - Handle token refresh scenarios
   - Implement proper fallbacks
   - Give helpful user feedback

[Previous\\
\\
Customize Instructions](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior) [Next\\
\\
Guardrails](https://docs.copilotkit.ai/guides/guardrails)

### On this page

[Introduction](https://docs.copilotkit.ai/guides/authenticated-actions#introduction) [Overview](https://docs.copilotkit.ai/guides/authenticated-actions#overview) [How It Works](https://docs.copilotkit.ai/guides/authenticated-actions#how-it-works) [Authentication Flow](https://docs.copilotkit.ai/guides/authenticated-actions#authentication-flow) [Example Scenario](https://docs.copilotkit.ai/guides/authenticated-actions#example-scenario) [Frontend Implementation](https://docs.copilotkit.ai/guides/authenticated-actions#frontend-implementation) [Configure Authentication State](https://docs.copilotkit.ai/guides/authenticated-actions#configure-authentication-state) [Backend Integration](https://docs.copilotkit.ai/guides/authenticated-actions#backend-integration) [Best Practices](https://docs.copilotkit.ai/guides/authenticated-actions#best-practices)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/authenticated-actions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## CoAgents Terminology
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# Terminology

Here are the key terms and concepts used throughout CoAgents:

| Term | Definition |
| --- | --- |
| Agentic Copilot | An AI agent designed to collaborate with users in Agent-Native applications, rather than operate autonomously. |
| CoAgent | Terminology referring to CopilotKit's suite of tools for building agentic applications. Typically interchangeable with agentic copilot. |
| Agent State | The current data and context maintained by a LangGraph agent during its execution, including both internal state and data that can be synchronized with the frontend UI. |
| Agentic Generative UI | UI components that are dynamically generated and updated based on the agent's current state, providing users with visibility into what the agent is doing and building trust through transparency. |
| Ground Truth | In CoAgents, CopilotKit serves as the "ground truth" for the full chat session, maintaining the persistent chat history and ensuring conversational continuity across different agents. |
| Human-in-the-Loop (HITL) | A workflow pattern where human input or validation is required during agent execution, enabling quality control and oversight at critical decision points. |
| Intermediate State | The updates to agent state that occur during node execution, rather than only at node transitions, enabling real-time feedback about the agent's progress. |
| [LangGraph](https://langchain-ai.github.io/langgraph/) | The agent framework integrated with CopilotKit that provides the orchestration layer for CoAgents, enabling sophisticated multi-step reasoning and state management. |
| Agent Lock Mode | A mode where CopilotKit is configured to work exclusively with a specific agent, ensuring all requests stay within a single workflow graph for precise control. |
| Router Mode | A mode where CopilotKit dynamically routes requests between different agents and tools based on context and user input, enabling flexible multi-agent workflows. |
| State Streaming | The real-time synchronization of agent state between the backend and frontend, enabling immediate updates to the UI as the agent performs tasks. |

These terms are referenced throughout the documentation and are essential for understanding how CoAgents work and how to implement them effectively in your applications.

[Previous\\
\\
Video: Perplexity Clone](https://docs.copilotkit.ai/coagents/videos/perplexity-clone) [Next\\
\\
Agentic Copilots](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/concepts/terminology.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Contributing to Documentation
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pagePrerequisites

Contributing

# Documentation Contributions

We understand that as we move quickly, sometimes our documentation website can be a bit outdated. Therefore, we highly value contributions to our documentation.

## [Prerequisites](https://docs.copilotkit.ai/contributing/docs-contributions\#prerequisites)

- [Node.js](https://nodejs.org/en/) 20.x or later
- [pnpm](https://pnpm.io/) v9.x installed globally ( `npm i -g pnpm@^9`)

## [How To Contribute](https://docs.copilotkit.ai/contributing/docs-contributions\#how-to-contribute)

### [Fork The Repository](https://docs.copilotkit.ai/contributing/docs-contributions\#fork-the-repository)

First, head over to the [CopilotKit GitHub repository](https://github.com/CopilotKit/CopilotKit) and create a fork.

Then, clone the forked repository to your local machine:

```
git clone https://github.com/<your-username>/CopilotKit
cd CopilotKit/docs
```

### [Run the Documentation Site Locally](https://docs.copilotkit.ai/contributing/docs-contributions\#run-the-documentation-site-locally)

To run the documentation site locally, install the dependencies and then start the docs in development mode:

```
pnpm install
pnpm run dev
```

The documentation site should be available at [http://localhost:3000](http://localhost:3000/).

### [Make Your Changes](https://docs.copilotkit.ai/contributing/docs-contributions\#make-your-changes)

Now, you can make your changes to the documentation website.

- All documentation-related files are located in the docs repository
- You may want to familiarize yourself with [Nextra](https://nextra.site/) to understand how the documentation website is structured.

Please ensure you review your changes for grammar, spelling and formatting errors. Also, ensure that links and images are working.

### [Review Changes & Submit Pull Request](https://docs.copilotkit.ai/contributing/docs-contributions\#review-changes--submit-pull-request)

Once you are happy with your changes, you can commit and push them. Then, head over to the [Pull Requests page](https://github.com/CopilotKit/CopilotKit/pulls) and create a pull request. Thank you for your contribution!

## [Need help?](https://docs.copilotkit.ai/contributing/docs-contributions\#need-help)

If you need help with anything, please don't hesitate to reach out to us on [Discord](https://discord.gg/6dffbvGU3D). We have a dedicated [#contributing](https://discord.com/channels/1122926057641742418/1183863183149117561) channel.

[Previous\\
\\
Advanced: Package Linking](https://docs.copilotkit.ai/contributing/code-contributions/package-linking) [Next\\
\\
Anonymous Telemetry](https://docs.copilotkit.ai/telemetry)

### On this page

[Prerequisites](https://docs.copilotkit.ai/contributing/docs-contributions#prerequisites) [How To Contribute](https://docs.copilotkit.ai/contributing/docs-contributions#how-to-contribute) [Fork The Repository](https://docs.copilotkit.ai/contributing/docs-contributions#fork-the-repository) [Run the Documentation Site Locally](https://docs.copilotkit.ai/contributing/docs-contributions#run-the-documentation-site-locally) [Make Your Changes](https://docs.copilotkit.ai/contributing/docs-contributions#make-your-changes) [Review Changes & Submit Pull Request](https://docs.copilotkit.ai/contributing/docs-contributions#review-changes--submit-pull-request) [Need help?](https://docs.copilotkit.ai/contributing/docs-contributions#need-help)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/(other)/contributing/docs-contributions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## useCopilotChat Hook
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageUsage

# useCopilotChat

`useCopilotChat` is a React hook that lets you directly interact with the
Copilot instance. Use to implement a fully custom UI (headless UI) or to
programmatically interact with the Copilot instance managed by the default
UI.

## [Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChat\#usage)

### [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChat\#simple-usage)

```
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function YourComponent() {
  const { appendMessage } = useCopilotChat();

  appendMessage(
    new TextMessage({
      content: "Hello World",
      role: Role.User,
    }),
  );

  // optionally, you can append a message without running chat completion
  appendMessage(yourMessage, { followUp: false });
}
```

`useCopilotChat` returns an object with the following properties:

```
const {
  visibleMessages, // An array of messages that are currently visible in the chat.
  appendMessage, // A function to append a message to the chat.
  setMessages, // A function to set the messages in the chat.
  deleteMessage, // A function to delete a message from the chat.
  reloadMessages, // A function to reload the messages from the API.
  stopGeneration, // A function to stop the generation of the next message.
  reset, // A function to reset the chat.
  isLoading, // A boolean indicating if the chat is loading.
} = useCopilotChat();
```

## [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotChat\#parameters)

idstring

A unique identifier for the chat. If not provided, a random one will be
generated. When provided, the `useChat` hook with the same `id` will
have shared states across components.

headersRecord<string, string> \| Headers

HTTP headers to be sent with the API request.

initialMessagesMessage\[\]

System messages of the chat. Defaults to an empty array.

makeSystemMessageSystemMessageFunction

A function to generate the system message. Defaults to `defaultSystemMessage`.

[Previous\\
\\
useCopilotAdditionalInstructions](https://docs.copilotkit.ai/reference/hooks/useCopilotAdditionalInstructions) [Next\\
\\
useCopilotChatSuggestions](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions)

### On this page

[Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChat#usage) [Simple Usage](https://docs.copilotkit.ai/reference/hooks/useCopilotChat#simple-usage) [Parameters](https://docs.copilotkit.ai/reference/hooks/useCopilotChat#parameters)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/hooks/useCopilotChat.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Human-in-the-Loop Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Human in the Loop (HITL)](https://docs.copilotkit.ai/coagents/human-in-the-loop)

# Node-based

Learn how to implement Human-in-the-Loop (HITL) using a node-based flow.

The usage of node based interrupt is [now discouraged](https://langchain-ai.github.io/langgraph/concepts/v0-human-in-the-loop/) by both LangGraph and CopilotKit.
As of LangGraph 0.2.57, the recommended way to set breakpoints is using [the interrupt function](https://https//docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow) as it simplifies human-in-the-loop patterns.

Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) with
the implementation below applied!

## [What is this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#what-is-this)

[Node based flows](https://langchain-ai.github.io/langgraph/concepts/v0-human-in-the-loop/#dynamic-breakpoints) are predicated on LangGraph concept
of `breakpoints` which will interrupt a node before or after its execution to allow for user input.

CopilotKit allows you to add custom UI to take user input and then pass it back to the agent upon completion.

## [Why should I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#why-should-i-use-this)

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

Node-based flows are a great way to implement HITL for more complex workflows where you want to ensure the agent is aware
of everything that has happened during a HITL interaction. This is contrasted with interrupt-based flows, where the agent
is interrupted and then resumes execution from where it left off, unaware of the context of the interaction by default.

## [Implementation](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#implementation)

### [Run and connect your agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#run-and-connect-your-agent)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/coagents/quickstart/langgraph) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.

### [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#install-the-copilotkit-sdk)

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic
experiences with CopilotKit requires our LangGraph SDK.

PythonTypeScript

Poetrypipconda

```
poetry add copilotkit
# including support for crewai
poetry add copilotkit[crewai]
```

### [Add a `useCopilotAction` to your Frontend](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#add-a-usecopilotaction-to-your-frontend)

First, we'll create a component that renders the agent's essay draft and waits for user approval.

ui/app/page.tsx

```
import { useCopilotAction } from "@copilotkit/react-core"
import { Markdown } from "@copilotkit/react-ui"

function YourMainContent() {
  // ...

  useCopilotAction({
    name: "writeEssay",
    available: "remote",
    description: "Writes an essay and takes the draft as an argument.",
    parameters: [\
      { name: "draft", type: "string", description: "The draft of the essay", required: true },\
    ],

    renderAndWaitForResponse: ({ args, respond, status }) => {
      return (
        <div>
          <Markdown content={args.draft || 'Preparing your draft...'} />

          <div className={`flex gap-4 pt-4 ${status !== "executing" ? "hidden" : ""}`}>
            <button
              onClick={() => respond?.("CANCEL")}
              disabled={status !== "executing"}
              className="border p-2 rounded-xl w-full"
            >
              Try Again
            </button>
            <button
              onClick={() => respond?.("SEND")}
              disabled={status !== "executing"}
              className="bg-blue-500 text-white p-2 rounded-xl w-full"
            >
              Approve Draft
            </button>
          </div>
        </div>
      );
    },
  });

  // ...
}
```

### [Setup the LangGraph Agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#setup-the-langgraph-agent)

Now we'll setup the LangGraph agent. Node-based flows are hard to understand without a complete example, so below
is the complete implementation of the agent with explanations.

Some main things to note:

- The agent's state inherits from `CopilotKitState` to bring in the CopilotKit actions.
- CopilotKit's actions are binded to the model as tools.
- If the `writeEssay` action is found in the model's response, the agent will transition to the `user_feedback_node`.
- The agent is interrupted before the `user_feedback_node` to allow for user input.

PythonTypeScript

agent/sample\_agent/agent.py

```
from typing_extensions import Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command
from copilotkit import CopilotKitState

# 1. Define our agent's state and inherit from CopilotKitState, this brings in the CopilotKit actions
class AgentState(CopilotKitState):
    # 1.1 Define any other state variables
    pass

# 2. Define the chat node, this will be where the agent will talk to user and
#    decide if it needs to call the writeEssay tool
async def chat_node(state: AgentState, config: RunnableConfig) -> Command[Literal["user_feedback_node", "__end__"]]:
    # 2.1 Define the model and bind CopilotKit's actions as tools
    model = ChatOpenAI(model="gpt-4o")
    model_with_tools = model.bind_tools([*state.get("copilotkit", {}).get("actions", [])])

    # 2.2 Define the system message
    system_message = SystemMessage(
        content="You write essays. Use your tools to write an essay, don't just write it in plain text."
    )

    # 2.3 Run the model to generate a response
    response = await model_with_tools.ainvoke([\
        system_message,\
        *state["messages"],\
    ], config)


    # 2.4 Check for the writeEssay tool call and, if found, go  to the
    #     user_feedback_node to handle the user's response
    if isinstance(response, AIMessage) and response.tool_calls:
        if response.tool_calls[0].get("name") == "writeEssay":
            return Command(goto="interrupt_node", update={"messages": response})

    # 2.5 If no tool call is found, end the agent
    return Command(goto=END, update={"messages": response})

# 3. Define an empty interrupt node to act as buffer as we use the interrupt_after property
def interrupt_node(state: AgentState, config: RunnableConfig):
  pass

# 4. Define the user_feedback_node, this node will be interrupted before execution
#    where CopilotKit's renderAndWaitForResponse provide the user's response.
def user_feedback_node(state: AgentState, config: RunnableConfig) -> Command[Literal["chat_node"]]:

    # 3.1 Get the last message from the state, this will be
    #     what is returned by respond() in the frontend
    last_message = state["messages"][-1]

    # 3.2 If the user declined the essay, ask them how they'd like to improve it
    if last_message.content != "SEND":
        return Command(goto="chat_node", update={
            "messages": [SystemMessage(content="The user declined they essay, please ask them how they'd like to improve it")]
        })

    # 3.3 If the user approved the essay, ask them if they'd like anything else
    return Command(goto="chat_node", update={
        "messages": [SystemMessage(content="The user approved the essay, ask them if they'd like anything else")]
    })

# 5. Configure the workflow
workflow = StateGraph(AgentState)
workflow.add_node("chat_node", chat_node)
workflow.add_node("interrupt_node", interrupt_node)
workflow.add_node("user_feedback_node", user_feedback_node)
workflow.add_edge("interrupt_node", "user_feedback_node")
workflow.set_entry_point("chat_node")


# 6. Compile the workflow and set the interrupt_after property
graph = workflow.compile(MemorySaver(), interrupt_after=["interrupt_node"])
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow\#give-it-a-try)

Try asking your agent to write an essay about the benefits of AI. You'll see that it will generate an essay,
stream the progress and eventually ask you to review it.

[Previous\\
\\
Interrupt](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow) [Next\\
\\
Shared State](https://docs.copilotkit.ai/coagents/shared-state)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#what-is-this) [Why should I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#why-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#implementation) [Run and connect your agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#run-and-connect-your-agent) [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#install-the-copilotkit-sdk) [Add a useCopilotAction to your Frontend](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#add-a-usecopilotaction-to-your-frontend) [Setup the LangGraph Agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#setup-the-langgraph-agent) [Give it a try!](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/human-in-the-loop/node-flow.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Headless UI Customization
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageResetting the chat history

[Customize UI](https://docs.copilotkit.ai/guides/custom-look-and-feel)

# Fully Headless UI

Fully customize your Copilot's UI from the ground up using headless UI

The built-in Copilot UI can be customized in many ways -- both through CSS and by passing in custom sub-components.

CopilotKit also offers **fully custom headless UI** through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

```
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function CustomChatInterface() {
  const {
    visibleMessages,
    appendMessage,
    setMessages,
    deleteMessage,
    reloadMessages,
    stopGeneration,
    isLoading,
  } = useCopilotChat();

  const sendMessage = (content: string) => {
    appendMessage(new TextMessage({ content, role: Role.User }));
  };

  return (
    <div>
      {/* Implement your custom chat UI here */}
    </div>
  );
}
```

## [Resetting the chat history](https://docs.copilotkit.ai/guides/custom-look-and-feel/headless-ui\#resetting-the-chat-history)

In some cases, users may want to reset the chat to clear the conversation history and start fresh. This can be useful when:

- The current conversation has become too long or confusing.
- You want to test different prompts or approaches from a clean slate.
- A user needs to reset the context to ensure the AI responds appropriately.

This simple method allows you to reset the chat state with a button click.

Why Reset the Chat?

Resetting the chat clears all conversation history, helping you start fresh or troubleshoot AI responses.

PreviewCode

![](https://docs.copilotkit.ai/images/concepts/customize-look-and-feel/reset-chat.gif)

[Previous\\
\\
Custom Sub-Components](https://docs.copilotkit.ai/guides/custom-look-and-feel/bring-your-own-components) [Next\\
\\
Connecting Your Data](https://docs.copilotkit.ai/guides/connect-your-data)

### On this page

[Resetting the chat history](https://docs.copilotkit.ai/guides/custom-look-and-feel/headless-ui#resetting-the-chat-history)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/custom-look-and-feel/headless-ui.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Agent State Writing Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Shared State](https://docs.copilotkit.ai/coagents/shared-state)

# Writing agent state

Write to agent's state from your application.

This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the previous steps applied to it!

## [What is this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#what-is-this)

This guide shows you how to write to your agent's state from your application.

## [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#when-should-i-use-this)

You can use this when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## [Implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#implementation)

### [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#run-and-connect-your-agent-to-copilotkit)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/getting-started) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.

### [Define the Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#define-the-agent-state)

LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
let's assume that our agent state looks something like this.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState
from typing import Literal

class AgentState(CopilotKitState):
    language: Literal["english", "spanish"] = "english"
```

### [Call `setState` function from the `useCoAgent` hook](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#call-setstate-function-from-the-usecoagent-hook)

`useCoAgent` returns a `setState` function that you can use to update the agent state. Calling this
will update the agent state and trigger a rerender of anything that depends on the agent state.

ui/app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
}

// Example usage in a pseudo React component
function YourMainContent() {
  const { state, setState } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // ...

  const toggleLanguage = () => {
    setState({ language: state.language === "english" ? "spanish" : "english" });
  };

  // ...

  return (
    // style excluded for brevity
    <div>
      <h1>Your main content</h1>
      <p>Language: {state.language}</p>
      <button onClick={toggleLanguage}>Toggle Language</button>
    </div>
  );
}
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#give-it-a-try)

You can now use the `setState` function to update the agent state and `state` to read it. Try toggling the language button
and talking to your agent. You'll see the language change to match the agent's state.

## [Advanced Usage](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#advanced-usage)

### [Re-run the agent with a hint about what's changed](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#re-run-the-agent-with-a-hint-about-whats-changed)

The new agent state will be used next time the agent runs.
If you want to re-run it manually, use the `run` argument on the `useCoAgent` hook.

The agent will be re-run, and it will get not only the latest updated state, but also a **hint** that can depend on the data delta between the previous and the current state.

ui/app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";
import { TextMessage, MessageRole } from "@copilotkit/runtime-client-gql";

// ...

function YourMainContent() {
  const { state, setState, run } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // setup to be called when some event in the app occurs
  const toggleLanguage = () => {
    const newLanguage = state.language === "english" ? "spanish" : "english";
    setState({ language: newLanguage });

    // re-run the agent and provide a hint about what's changed
    run(({ previousState, currentState }) => {
      return new TextMessage({
        role: MessageRole.User,
        content: `the language has been updated to ${currentState.language}`,
      });
    });
  };

  return (
    // ...
  );
}
```

### [Intermediately Stream and Render Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#intermediately-stream-and-render-agent-state)

By default, the LangGraph agent state will only update _between_ LangGraph node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](https://docs.copilotkit.ai/coagents/shared-state/intermediate-state-streaming).**

[Previous\\
\\
Reading agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read) [Next\\
\\
Agent state inputs and outputs](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#implementation) [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#run-and-connect-your-agent-to-copilotkit) [Define the Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#define-the-agent-state) [Call setState function from the useCoAgent hook](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#call-setstate-function-from-the-usecoagent-hook) [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#give-it-a-try) [Advanced Usage](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#advanced-usage) [Re-run the agent with a hint about what's changed](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#re-run-the-agent-with-a-hint-about-whats-changed) [Intermediately Stream and Render Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#intermediately-stream-and-render-agent-state)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/shared-state/in-app-agent-write.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Chat Components Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

# All Chat Components

[**<CopilotChat />** \\
The CopilotChat component, providing a chat interface for interacting with your copilot.](https://docs.copilotkit.ai/reference/components/chat/CopilotChat) [**<CopilotPopup />** \\
The CopilotPopup component, providing a popup interface for interacting with your copilot.](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup) [**<CopilotSidebar />** \\
The CopilotSidebar component, providing a sidebar interface for interacting with your copilot.](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar)

[Previous\\
\\
API Reference](https://docs.copilotkit.ai/reference) [Next\\
\\
CopilotChat](https://docs.copilotkit.ai/reference/components/chat/CopilotChat)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/reference/components/chat/index.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## LangChain JS Integration
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageIntegrate LangChain JS actions with CopilotRuntime

[Backend Actions & Agents](https://docs.copilotkit.ai/guides/backend-actions)

# LangChain.js

Integrate LangChain JS chains as backend actions in your CopilotKit application.

### Find your CopilotRuntime

The starting point for this section is the `CopilotRuntime` you set up during quickstart (the CopilotKit backend endpoint).
For a refresher, see [Self-Hosting](https://docs.copilotkit.ai/guides/self-hosting) (or alternatively, revisit the [quickstart](https://docs.copilotkit.ai/quickstart)).

**First, find your `CopilotRuntime` instance in your code.** You can simply search your codebase for `CopilotRuntime`.

If you followed the quickstart, it'll be where you set up the `/api/copilotkit` endpoint.

### [Integrate LangChain JS actions with CopilotRuntime](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions\#integrate-langchain-js-actions-with-copilotruntime)

CopilotKit allows actions to return not only values but also LangChain streams. This means you can call LangChain chains directly and return their streams as part of your backend actions. Here's how to implement LangChain JS backend actions:

**Note** that `actions` is not merely an array of actions, but an array **generator**.
This generator takes `properties` and `url` as input.

This means you can **customize which backend actions are made available** according to the current frontend URL, as well as custom properties you can pass from the frontend.

/api/copilotkit/route.ts

```
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const runtime = new CopilotRuntime({
  // ... existing configuration
  actions: ({properties, url}) => {
    // Note that actions returns not an array, but an array **generator**.
    // You can use the input parameters to the actions generator to expose different backend actions to the Copilot at different times:
    // `url` is the current URL on the frontend application.
    // `properties` contains custom properties you can pass from the frontend application.

    return [\
      {\
        name: "generateJokeForTopic",\
        description: "Generates a joke for a given topic.",\
        parameters: [\
          {\
            name: "topic",\
            type: "string",\
            description: "The topic to generate a joke about.",\
            required: true,\
          },\
        ],\
        handler: async ({topic}: {topic: string}) => {\
          const prompt = ChatPromptTemplate.fromMessages([\
            [\
              "system",\
              "You are a witty comedian. Generate a short, funny joke about the given topic. But make it sound like a pirate joke!",\
            ],\
            ["user", "Topic: {topic}"],\
          ]);\
          const chain = prompt.pipe(new ChatOpenAI());\
\
          return chain.stream({ // return directly chain.stream\
            topic: topic,\
          });\
        },\
      },\
    ]
  }
});

// ... rest of your route definition
```

### [Test your implementation](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions\#test-your-implementation)

After adding the LangChain JS action, test it by asking the copilot to generate a joke about a specific topic. Observe how it uses the LangChain components to generate and stream the response.

[Previous\\
\\
TypeScript (Node.js)](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions) [Next\\
\\
LangServe actions](https://docs.copilotkit.ai/guides/backend-actions/langserve-backend-actions)

### On this page

[Integrate LangChain JS actions with CopilotRuntime](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions#integrate-langchain-js-actions-with-copilotruntime) [Test your implementation](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions#test-your-implementation)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/(root)/guides/backend-actions/langchain-js-backend-actions.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Read Agent State
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Shared State](https://docs.copilotkit.ai/coagents/shared-state)

# Reading agent state

Read the realtime agent state in your native application.

![read agent state](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Fcoagents%2Fread-agent-state.png&w=3840&q=75)

Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) with
the [implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#implementation) section applied!

## [What is this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#what-is-this)

You can easily use the realtime agent state not only in the chat UI, but also in the native application UX.

## [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#when-should-i-use-this)

You can use this when you want to provide the user with feedback about what your agent's state. As your agent's
state update you can reflect these updates natively in your application.

## [Implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#implementation)

### [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#run-and-connect-your-agent-to-copilotkit)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/getting-started) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.

### [Define the Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#define-the-agent-state)

LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
let's assume that our agent state looks something like this.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState
from typing import Literal

class AgentState(CopilotKitState):
    language: Literal["english", "spanish"] = "spanish"

def chat_node(state: AgentState, config: RunnableConfig):
  # If language is not defined, set a value.
  # this is because a default value in a state class is not read on runtime
  language = state.get("language", "spanish")

  # ... add the rest of the node implementation and use the language variable

  return {
    # ... add the rest of state to return
    # return the language to make it available for the next nodes & frontend to read
    "language": language
  }
```

### [Use the `useCoAgent` Hook](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#use-the-usecoagent-hook)

With your agent connected and running all that is left is to call the [useCoAgent](https://docs.copilotkit.ai/reference/hooks/useCoAgent) hook, pass the agent's name, and
optionally provide an initial state.

ui/app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
}

function YourMainContent() {
  const { state } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // ...

  return (
    // style excluded for brevity
    <div>
      <h1>Your main content</h1>
      <p>Language: {state.language}</p>
    </div>
  );
}
```

The `state` in `useCoAgent` is reactive and will automatically update when the agent's state changes.

### [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#give-it-a-try)

As the agent state updates, your `state` variable will automatically update with it! In this case, you'll see the
language set to "spanish" as that's the initial state we set.

## [Rendering agent state in the chat](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#rendering-agent-state-in-the-chat)

You can also render the agent's state in the chat UI. This is useful for informing the user about the agent's state in a
more in-context way. To do this, you can use the [useCoAgentStateRender](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender) hook.

ui/app/page.tsx

```
import { useCoAgentStateRender } from "@copilotkit/react-core";

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
}

function YourMainContent() {
  // ...

  useCoAgentStateRender({
    name: "sample_agent",
    render: ({ state }) => {
      if (!state.language) return null;
      return <div>Language: {state.language}</div>;
    },
  });
  // ...
}
```

The `state` in `useCoAgentStateRender` is reactive and will automatically update when the agent's state changes.

## [Intermediately Stream and Render Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read\#intermediately-stream-and-render-agent-state)

By default, the LangGraph agent state will only update _between_ LangGraph node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates).**

[Previous\\
\\
Shared State](https://docs.copilotkit.ai/coagents/shared-state) [Next\\
\\
Writing agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#implementation) [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#run-and-connect-your-agent-to-copilotkit) [Define the Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#define-the-agent-state) [Use the useCoAgent Hook](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#use-the-usecoagent-hook) [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#give-it-a-try) [Rendering agent state in the chat](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#rendering-agent-state-in-the-chat) [Intermediately Stream and Render Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read#intermediately-stream-and-render-agent-state)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/shared-state/in-app-agent-read.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

![read agent state](https://docs.copilotkit.ai/_next/image?url=%2Fimages%2Fcoagents%2Fread-agent-state.png&w=3840&q=75)

## Human-in-the-Loop Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Human in the Loop (HITL)](https://docs.copilotkit.ai/coagents/human-in-the-loop)

# Interrupt

Learn how to implement Human-in-the-Loop (HITL) using a interrupt-based flow.

Pictured above is the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) with
the implementation below applied!

## [What is this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#what-is-this)

[LangGraph's interrupt flow](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/) provides an intuitive way to implement Human-in-the-loop workflows.

This guide will show you how to both use `interrupt` and how to integrate it with CopilotKit.

## [When should I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#when-should-i-use-this)

Human-in-the-loop is a powerful way to implement complex workflows that are production ready. By having a human in the loop,
you can ensure that the agent is always making the right decisions and ultimately is being steered in the right direction.

Interrupt-based flows are a very intuitive way to implement HITL. Instead of having a node await user input before or after its execution,
nodes can be interrupted in the middle of their execution to allow for user input. The trade-off is that the agent is not aware of the
interaction, however [CopilotKit's SDKs provide helpers to alleviate this](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#make-your-agent-aware-of-interruptions).

## [Implementation](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#implementation)

### [Run and connect your agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#run-and-connect-your-agent)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/coagents/quickstart/langgraph) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.

### [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#install-the-copilotkit-sdk)

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic
experiences with CopilotKit requires our LangGraph SDK.

PythonTypeScript

Poetrypipconda

```
poetry add copilotkit
# including support for crewai
poetry add copilotkit[crewai]
```

### [Setup your agent state](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#setup-your-agent-state)

We're going to have the agent ask us to name it, so we'll need a state property to store the name.

PythonTypeScript

agent/sample\_agent/agent.py

```
# ...
from copilotkit import CopilotKitState # extends MessagesState
# ...

# This is the state of the agent.
# It inherits from the CopilotKitState properties from CopilotKit.
class AgentState(CopilotKitState):
    agent_name: str
```

Choose how to display the interrupt to the user

As a Custom Chat UI

I'd like to display a custom UI in the chat window

As Message

I'd like to display the interrupt as a copilot message

### [Call `interrupt` in your LangGraph agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#call-interrupt-in-your-langgraph-agent)

Now we can call `interrupt` in our LangGraph agent.

Your agent will not be aware of the `interrupt` interaction by default in LangGraph.

If you want this behavior, see the [section on it below](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#make-your-agent-aware-of-interruptions).

PythonTypeScript

agent/sample\_agent/agent.py

```
from langgraph.types import interrupt
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI
from copilotkit import CopilotKitState

# add the agent state definition from the previous step
class AgentState(CopilotKitState):
    agent_name: str

def chat_node(state: AgentState, config: RunnableConfig):
    if not state.get("agent_name"):
    # Interrupt and wait for the user to respond with a name
    state["agent_name"] = interrupt("Before we start, what would you like to call me?")

    # Tell the agent its name
    system_message = SystemMessage(
        content=f"You are a helpful assistant named {state.get('agent_name')}..."
    )

    response = ChatOpenAI(model="gpt-4o").invoke(
        [system_message, *state["messages"]],
        config
    )

    return {
        **state,
        "messages": response,
    }
```

### [Handle the interrupt in your frontend](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#handle-the-interrupt-in-your-frontend)

At this point, your LangGraph agent's `interrupt` will be called. However, we currently have no handling for rendering or
responding to the interrupt in the frontend.

To do this, we'll use the `useLangGraphInterrupt` hook, give it a component to render, and then call `resolve` with the user's response.

app/page.tsx

```
import { useLangGraphInterrupt } from "@copilotkit/react-core";
// ...

const YourMainContent = () => {
// ...

// styles omitted for brevity
useLangGraphInterrupt({
    render: ({ event, resolve }) => (
        <div>
            <p>{event.value}</p>
            <form onSubmit={(e) => {
                e.preventDefault();
                resolve((e.target as HTMLFormElement).response.value);
            }}>
                <input type="text" name="response" placeholder="Enter your response" />
                <button type="submit">Submit</button>
            </form>
        </div>
    )
});
// ...

return <div>{/* ... */}</div>
}
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#give-it-a-try)

Try talking to your agent, you'll see that it now pauses execution and waits for you to respond!

## [Make your agent aware of interruptions](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#make-your-agent-aware-of-interruptions)

By default, your agent will not be made aware of LangGraph `interrupts`. This is because the decision is not saved into the message's state.
For simple and sensitive flows, this is ideal. However, you may want to make your agent aware of these interactions.

If you've been using the "As Message" implementation, you may have noticed that the messages are returned from the interrupt function.
These can be used to notify the LLM about the recent communication:

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import copilotkit_interrupt

# ...
agent_name, new_messages = copilotkit_interrupt(message="Before we start, what would you like to call me?")
state["messages"] = state["messages"] + new_messages
state["agent_name"] = agent_name
# ...
```

## [Condition UI executions](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#condition-ui-executions)

When opting for custom chat UI while having multiple `interrupt` events in the agent, there could be conflicts between multiple `useLangGraphInterrupt` hooks calls in the UI.
For this reason, the hook can take an `enabled` argument which will apply it conditionally:

### [Define multiple interrupts](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#define-multiple-interrupts)

First, let's define two different interrupts. We will include a "type" property to differentiate them.

PythonTypeScript

agent/sample\_agent/agent.py

```
from langgraph.types import interrupt
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI

# ... your full state definition

def chat_node(state: AgentState, config: RunnableConfig):

  state["approval"] = interrupt({ "type": "approval", "content": "please approve" })

  if not state.get("agent_name"):
    # Interrupt and wait for the user to respond with a name
    state["agent_name"] = interrupt({ "type": "ask", "content": "Before we start, what would you like to call me?" })

  # Tell the agent its name
  system_message = SystemMessage(
    content=f"You are a helpful assistant..."
  )

  response = ChatOpenAI(model="gpt-4o").invoke(
    [system_message, *state["messages"]],
    config
  )

  return {
    **state,
    "messages": response,
  }
```

### [Add multiple frontend handlers](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#add-multiple-frontend-handlers)

With the differentiator in mind, we will add a handler that takes care of any "ask" and any "approve" types.
With two `useLangGraphInterrupt` hooks in our page, we can leverage the `enabled` property to enable each in the right time:

app/page.tsx

```
import { useLangGraphInterrupt } from "@copilotkit/react-core";
// ...

const ApproveComponent = ({ content, onAnswer }: { content: string; onAnswer: (approved: boolean) => void }) => (
    // styles omitted for brevity
    <div>
        <h1>Do you approve?</h1>
        <button onClick={() => onAnswer(true)}>Approve</button>
        <button onClick={() => onAnswer(false)}>Reject</button>
    </div>
)

const AskComponent = ({ question, onAnswer }: { question: string; onAnswer: (answer: string) => void }) => (
// styles omitted for brevity
    <div>
        <p>{question}</p>
        <form onSubmit={(e) => {
            e.preventDefault();
            onAnswer((e.target as HTMLFormElement).response.value);
        }}>
            <input type="text" name="response" placeholder="Enter your response" />
            <button type="submit">Submit</button>
        </form>
    </div>
)

const YourMainContent = () => {
    // ...

    useLangGraphInterrupt({
        enabled: ({ eventValue }) => eventValue.type === 'ask',
        render: ({ event, resolve }) => (
            <AskComponent question={event.value.content} onAnswer={answer => resolve(answer)} />
        )
    });

    useLangGraphInterrupt({
        enabled: ({ eventValue }) => eventValue.type === 'approval',
        render: ({ event, resolve }) => (
            <ApproveComponent content={event.value.content} onAnswer={answer => resolve(answer)} />
        )
    });

    // ...
}
```

## [Preprocessing of an interrupt and programmatically handling an interrupt value](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow\#preprocessing-of-an-interrupt-and-programmatically-handling-an-interrupt-value)

When opting for custom chat UI, some cases may require pre-processing of the incoming values of interrupt event or even resolving it entirely without showing a UI for it.
This can be achieved using the `handler` property, which is not required to return a React component.

The return value of the handler will be passed to the `render` method as the `result` argument.

app/page.tsx

```
// We will assume an interrupt event in the following shape
type Department = 'finance' | 'engineering' | 'admin'
interface AuthorizationInterruptEvent {
    type: 'auth',
    accessDepartment: Department,
}

import { useLangGraphInterrupt } from "@copilotkit/react-core";

const YourMainContent = () => {
    const [userEmail, setUserEmail] = useState({ email: 'example@user.com' })
    function getUserByEmail(email: string): { id: string; department: Department } {
        // ... an implementation of user fetching
    }

    // ...
    // styles omitted for brevity

    useLangGraphInterrupt({
        handler: async ({ result, event, resolve }) => {
            const { department } = await getUserByEmail(userEmail)
            if (event.value.accessDepartment === department || department === 'admin') {
                // Following the resolution of the event, we will not proceed to the render method
                resolve({ code: 'AUTH_BY_DEPARTMENT' })
                return;
            }

            return { department, userId }
        },
        render: ({ result, event, resolve }) => (
            <div>
                <h1>Request for {event.value.type}</h1>
                <p>Members from {result.department} department cannot access this information</p>
                <p>You can request access from an administrator to continue.</p>
                <button
                    onClick={() => resolve({ code: 'REQUEST_AUTH', data: { department: result.department, userId: result.userId } })}
                >
                    Request Access
                </button>
                <button
                    onClick={() => resolve({ code: 'CANCEL' })}
                >
                    Cancel
                </button>
            </div>
        )
    });
    // ...

    return <div>{/* ... */}</div>
}
```

[Previous\\
\\
Human in the Loop (HITL)](https://docs.copilotkit.ai/coagents/human-in-the-loop) [Next\\
\\
Node-based](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#implementation) [Run and connect your agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#run-and-connect-your-agent) [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#install-the-copilotkit-sdk) [Setup your agent state](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#setup-your-agent-state) [Call interrupt in your LangGraph agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#call-interrupt-in-your-langgraph-agent) [Handle the interrupt in your frontend](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#handle-the-interrupt-in-your-frontend) [Call copilotkit\_interrupt in your LangGraph agent](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#call-copilotkit_interrupt-in-your-langgraph-agent) [Give it a try!](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#give-it-a-try) [Make your agent aware of interruptions](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#make-your-agent-aware-of-interruptions) [Condition UI executions](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#condition-ui-executions) [Define multiple interrupts](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#define-multiple-interrupts) [Add multiple frontend handlers](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#add-multiple-frontend-handlers) [Preprocessing of an interrupt and programmatically handling an interrupt value](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow#preprocessing-of-an-interrupt-and-programmatically-handling-an-interrupt-value)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/human-in-the-loop/interrupt-flow.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Writing Agent State
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

[Shared State](https://docs.copilotkit.ai/coagents/shared-state)

# Writing agent state

Write to agent's state from your application.

This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the previous steps applied to it!

## [What is this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#what-is-this)

This guide shows you how to write to your agent's state from your application.

## [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#when-should-i-use-this)

You can use this when you want to provide the user with feedback about what your agent is doing, specifically
when your agent is calling tools. CopilotKit allows you to fully customize how these tools are rendered in the chat.

## [Implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#implementation)

### [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#run-and-connect-your-agent-to-copilotkit)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/getting-started) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.

### [Define the Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#define-the-agent-state)

LangGraph is stateful. As you transition between nodes, that state is updated and passed to the next node. For this example,
let's assume that our agent state looks something like this.

PythonTypeScript

agent-py/sample\_agent/agent.py

```
from copilotkit import CopilotKitState
from typing import Literal

class AgentState(CopilotKitState):
    language: Literal["english", "spanish"] = "english"
```

### [Call `setState` function from the `useCoAgent` hook](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#call-setstate-function-from-the-usecoagent-hook)

`useCoAgent` returns a `setState` function that you can use to update the agent state. Calling this
will update the agent state and trigger a rerender of anything that depends on the agent state.

ui/app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";

// Define the agent state type, should match the actual state of your agent
type AgentState = {
  language: "english" | "spanish";
}

// Example usage in a pseudo React component
function YourMainContent() {
  const { state, setState } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // ...

  const toggleLanguage = () => {
    setState({ language: state.language === "english" ? "spanish" : "english" });
  };

  // ...

  return (
    // style excluded for brevity
    <div>
      <h1>Your main content</h1>
      <p>Language: {state.language}</p>
      <button onClick={toggleLanguage}>Toggle Language</button>
    </div>
  );
}
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#give-it-a-try)

You can now use the `setState` function to update the agent state and `state` to read it. Try toggling the language button
and talking to your agent. You'll see the language change to match the agent's state.

## [Advanced Usage](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#advanced-usage)

### [Re-run the agent with a hint about what's changed](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#re-run-the-agent-with-a-hint-about-whats-changed)

The new agent state will be used next time the agent runs.
If you want to re-run it manually, use the `run` argument on the `useCoAgent` hook.

The agent will be re-run, and it will get not only the latest updated state, but also a **hint** that can depend on the data delta between the previous and the current state.

ui/app/page.tsx

```
import { useCoAgent } from "@copilotkit/react-core";
import { TextMessage, MessageRole } from "@copilotkit/runtime-client-gql";

// ...

function YourMainContent() {
  const { state, setState, run } = useCoAgent<AgentState>({
    name: "sample_agent",
    initialState: { language: "spanish" }  // optionally provide an initial state
  });

  // setup to be called when some event in the app occurs
  const toggleLanguage = () => {
    const newLanguage = state.language === "english" ? "spanish" : "english";
    setState({ language: newLanguage });

    // re-run the agent and provide a hint about what's changed
    run(({ previousState, currentState }) => {
      return new TextMessage({
        role: MessageRole.User,
        content: `the language has been updated to ${currentState.language}`,
      });
    });
  };

  return (
    // ...
  );
}
```

### [Intermediately Stream and Render Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write\#intermediately-stream-and-render-agent-state)

By default, the LangGraph agent state will only update _between_ LangGraph node transitions --
which means state updates will be discontinuous and delayed.

You likely want to render the agent state as it updates **continuously.**

See **[emit intermediate state](https://docs.copilotkit.ai/coagents/shared-state/intermediate-state-streaming).**

[Previous\\
\\
Reading agent state](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read) [Next\\
\\
Agent state inputs and outputs](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#implementation) [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#run-and-connect-your-agent-to-copilotkit) [Define the Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#define-the-agent-state) [Call setState function from the useCoAgent hook](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#call-setstate-function-from-the-usecoagent-hook) [Give it a try!](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#give-it-a-try) [Advanced Usage](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#advanced-usage) [Re-run the agent with a hint about what's changed](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#re-run-the-agent-with-a-hint-about-whats-changed) [Intermediately Stream and Render Agent State](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write#intermediately-stream-and-render-agent-state)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/shared-state/in-app-agent-write.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Message Management Overview
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageCan I modify the message history?

# Message flow

Message management in CoAgents operates with CopilotKit as the "ground truth" for the full chat session.
When an CoAgent session begins, it receives the existing CopilotKit chat history to maintain conversational
continuity across different agents.

While all of this information is great to know, in most cases you won't need to worry about these details to
build rich agentic applications. Use the information here as a reference when getting really deep into
the CoAgent internals.

### [Can I modify the message history?](https://docs.copilotkit.ai/coagents/concepts/message-management\#can-i-modify-the-message-history)

You can modify the message history from LangGraph by using the `RemoveMessage` class. For example to remove all messages from the chat history:

```
from langchain_core.messages import RemoveMessage

def a_node(state: AgentState, config):
    # ...
    return {"messages":  [RemoveMessage(id=m.id) for m in state['messages']]}
```

See the [LangGraph documentation](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/) for more information.

Editing the message history is not currently supported on the front-end, but will be soon.

### [Can I persist chat history?](https://docs.copilotkit.ai/coagents/concepts/message-management\#can-i-persist-chat-history)

Yes! There are a few ways to persist various portions of a chat's history:

- [Threads](https://docs.copilotkit.ai/coagents/persistence/threads)
- [Message Persistence](https://docs.copilotkit.ai/coagents/persistence/message-persistence)
- [Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state)

## [Types of LLM Messages](https://docs.copilotkit.ai/coagents/concepts/message-management\#types-of-llm-messages)

Modern LLM interactions produce two distinct types of messages:

1. **Communication Messages**: Direct responses and interactions with users
2. **Internal Messages**: Agent "thoughts" and reasoning processes

A well known example of this pattern is OpenAI's o1 model, which has sophisticated reasoning capabilities and thoughts. Its internal
thought processes are presented distinctly from 'communication messages' which are clearly visible to the end-user.

LangGraph agents can operate similarly. An LLM call's output can be considered either a communication message, or an internal message.

### [Emitting Messages for long running tasks](https://docs.copilotkit.ai/coagents/concepts/message-management\#emitting-messages-for-long-running-tasks)

Sometimes you'll have a task that is running for a long time, and you want the user to be aware of what's happening. By default, LangGraph does not support this, because messages are only emitted on node transitions. However, CopilotKit allows you to accomplish this by using the `copilotkit_emit_message` function.

```
async def ask_name_node(state: GreetAgentState, config: RunnableConfig):
    """
    Ask the user for their name.
    """

    content = "Hey, what is your name? 🙂"

    await copilotkit_emit_message(config, content)

    # something long running here...

    return {
        "messages": AIMessage(content=content),
    }
```

Want some more help managing messages in your CoAgent application? Check out our guide on [emitting messages](https://docs.copilotkit.ai/coagents/advanced/emit-messages).

## [Message Flow](https://docs.copilotkit.ai/coagents/concepts/message-management\#message-flow)

Messages flow between CopilotKit and LangGraph in a specific way:

- All messages from LangGraph are forwarded to CopilotKit
- On a fresh agent invocation, the full CopilotKit chat history is provided to the LangGraph agent as its pre-existing chat history.

When a CoAgent completes its execution, its relevant messages become part of CopilotKit's persistent chat history. This allows for all future agent invocations to get context from the full chat history.

[Previous\\
\\
LangGraph](https://docs.copilotkit.ai/coagents/concepts/langgraph) [Next\\
\\
Common Issues](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues)

### On this page

[Can I modify the message history?](https://docs.copilotkit.ai/coagents/concepts/message-management#can-i-modify-the-message-history) [Can I persist chat history?](https://docs.copilotkit.ai/coagents/concepts/message-management#can-i-persist-chat-history) [Types of LLM Messages](https://docs.copilotkit.ai/coagents/concepts/message-management#types-of-llm-messages) [Emitting Messages for long running tasks](https://docs.copilotkit.ai/coagents/concepts/message-management#emitting-messages-for-long-running-tasks) [Message Flow](https://docs.copilotkit.ai/coagents/concepts/message-management#message-flow)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/concepts/message-management.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Exiting Agent Loop
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageInstall the CopilotKit SDK

Advanced

# Exiting the agent loop

After your agent has finished a workflow, you'll usually want to explicitly end that loop by calling the CopilotKit exit method in your agent code.

Exiting the agent has different effects depending on mode:

- **Router Mode**: Exiting the agent hands responsibility for handling input back to the router, which can initiate chat, call actions, other agents, etc. The router can return to this agent later (starting a new loop) to satisfy a user request.

- **Agent Lock Mode**: Exiting the agent restarts the workflow loop for the current agent.


In this example from [our email-sending app](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-qa), the `send_email` node explicitly exits, then manually sends a response back to the user as a `ToolMessage`:

### [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/advanced/exit-agent\#install-the-copilotkit-sdk)

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic
experiences with CopilotKit requires our LangGraph SDK.

PythonTypeScript

Poetrypipconda

```
poetry add copilotkit
# including support for crewai
poetry add copilotkit[crewai]
```

### [Exit the agent loop](https://docs.copilotkit.ai/coagents/advanced/exit-agent\#exit-the-agent-loop)

This will exit the agent session as soon as the current LangGraph run is finished, either by a breakpoint or by reaching the `END` node.

PythonTypeScript

```
from copilotkit.langgraph import (copilotkit_exit)
# ...
async def send_email_node(state: EmailAgentState, config: RunnableConfig):
    """Send an email."""

    await copilotkit_exit(config)

    # get the last message and cast to ToolMessage
    last_message = cast(ToolMessage, state["messages"][-1])
    if last_message.content == "CANCEL":
        return {
            "messages": [AIMessage(content="❌ Cancelled sending email.")],
        }
    else:
        return {
            "messages": [AIMessage(content="✅ Sent email.")],
        }
```

[Previous\\
\\
Manually emitting messages](https://docs.copilotkit.ai/coagents/advanced/emit-messages) [Next\\
\\
Overview](https://docs.copilotkit.ai/coagents/tutorials/agent-native-app)

### On this page

[Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/advanced/exit-agent#install-the-copilotkit-sdk) [Exit the agent loop](https://docs.copilotkit.ai/coagents/advanced/exit-agent#exit-the-agent-loop)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/advanced/exit-agent.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Message Persistence Guide
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this page

Persistence

# Message Persistence

To learn about how to load previous messages and agent states, check out the [Loading Message History](https://docs.copilotkit.ai/coagents/persistence/loading-message-history) and [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state) pages.

To persist LangGraph messages to a database, you can use either `AsyncPostgresSaver` or `AsyncSqliteSaver`. Set up the asynchronous memory by configuring the graph within a lifespan function, as follows:

```
from contextlib import asynccontextmanager
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver

@asynccontextmanager
async def lifespan(app: FastAPI):
    async with AsyncPostgresSaver.from_conn_string(
        "postgresql://postgres:postgres@127.0.0.1:5432/postgres"
    ) as checkpointer:
        # NOTE: you need to call .setup() the first time you're using your checkpointer
        await checkpointer.setup()
        # Create an async graph
        graph = workflow.compile(checkpointer=checkpointer)

        # Create SDK with the graph
        sdk = CopilotKitRemoteEndpoint(
            agents=[\
                LangGraphAgent(\
                    name="research_agent",\
                    description="Research agent.",\
                    graph=graph,\
                ),\
            ],
        )

        # Add the CopilotKit FastAPI endpoint
        add_fastapi_endpoint(app, sdk, "/copilotkit")
        yield

app = FastAPI(lifespan=lifespan)
```

To learn more about persistence in LangGraph, check out the [LangGraph documentation](https://langchain-ai.github.io/langgraph/how-tos/#persistence).

[Previous\\
\\
Threads](https://docs.copilotkit.ai/coagents/persistence/loading-message-history) [Next\\
\\
Using Agent Execution Parameters](https://docs.copilotkit.ai/coagents/advanced/adding-runtime-configuration)

### On this page

No Headings

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/persistence/message-persistence.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)

## Emit Messages in Agents
CrewAI CrewAI support is here! Checkout the [Crew](https://docs.copilotkit.ai/crewai-crews) and [Flow](https://docs.copilotkit.ai/crewai-flows) documentation.

Search docs

`⌘`  `K`

On this pageWhat is this?

Advanced

# Manually emitting messages

While most agent interactions happen automatically through shared state updates as the agent runs, you can also **manually send messages from within your agent code** to provide immediate feedback to users.

This video shows the [coagents starter](https://github.com/CopilotKit/CopilotKit/tree/main/examples/coagents-starter) repo with the [implementation](https://docs.copilotkit.ai/coagents/advanced/emit-messages#implementation) section applied to it!

## [What is this?](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#what-is-this)

In LangGraph, messages are only emitted when a node is completed. CopilotKit allows you to manually emit messages
in the middle of a node's execution to provide immediate feedback to the user.

## [When should I use this?](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#when-should-i-use-this)

Manually emitted messages are great for **when you don't want to wait for the node** to complete **and you**:

- Have a long running task that you want to provide feedback on
- Want to provide a status update to the user
- Want to provide a warning or error message

## [Implementation](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#implementation)

### [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#run-and-connect-your-agent-to-copilotkit)

You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](https://docs.copilotkit.ai/coagents/quickstart/langgraph) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.

### [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#install-the-copilotkit-sdk)

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic
experiences with CopilotKit requires our LangGraph SDK.

PythonTypeScript

Poetrypipconda

```
poetry add copilotkit
# including support for crewai
poetry add copilotkit[crewai]
```

### [Manually emit a message](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#manually-emit-a-message)

The `copilotkit_emit_message` method allows you to emit messages early in a node's execution to communicate status updates to the user. This is particularly useful for long running tasks.

PythonTypeScript

```
from langchain_core.messages import SystemMessage, AIMessage
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableConfig
from copilotkit.langgraph import copilotkit_emit_message
# ...

async def chat_node(state: AgentState, config: RunnableConfig):
    model = ChatOpenAI(model="gpt-4o")


    intermediate_message = "Thinking really hard..."
    await copilotkit_emit_message(config, intermediate_message)

    # simulate a long running task
    await asyncio.sleep(2)

    response = await model.ainvoke([\
        SystemMessage(content="You are a helpful assistant."),\
        *state["messages"]\
    ], config)

    return Command(
        goto=END,
        update={
            # Make sure to include the emitted message in the messages history
            "messages": [AIMessage(content=intermediate_message), response]
        }
    )
```

### [Give it a try!](https://docs.copilotkit.ai/coagents/advanced/emit-messages\#give-it-a-try)

Now when you talk to your agent you'll notice that it immediately responds with the message "Thinking really hard..."
before giving you a response 2 seconds later.

[Previous\\
\\
Disabling state streaming](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming) [Next\\
\\
Exiting the agent loop](https://docs.copilotkit.ai/coagents/advanced/exit-agent)

### On this page

[What is this?](https://docs.copilotkit.ai/coagents/advanced/emit-messages#what-is-this) [When should I use this?](https://docs.copilotkit.ai/coagents/advanced/emit-messages#when-should-i-use-this) [Implementation](https://docs.copilotkit.ai/coagents/advanced/emit-messages#implementation) [Run and Connect Your Agent to CopilotKit](https://docs.copilotkit.ai/coagents/advanced/emit-messages#run-and-connect-your-agent-to-copilotkit) [Install the CopilotKit SDK](https://docs.copilotkit.ai/coagents/advanced/emit-messages#install-the-copilotkit-sdk) [Manually emit a message](https://docs.copilotkit.ai/coagents/advanced/emit-messages#manually-emit-a-message) [Give it a try!](https://docs.copilotkit.ai/coagents/advanced/emit-messages#give-it-a-try)

[Edit on GitHub](https://github.com/CopilotKit/CopilotKit/blob/main/docs/content/docs/coagents/advanced/emit-messages.mdx)

![](https://static.scarf.sh/a.png?x-pxid=ffc9f65d-0186-4575-b065-61d62ea9d7d3)




================================================
FILE: docs/public/llms.txt
================================================
# http://docs.copilotkit.ai llms.txt

- [CopilotKit Documentation](https://docs.copilotkit.ai/): Explore tools for building AI copilots and agents.
- [Copilot Infrastructure Overview](https://docs.copilotkit.ai/coagents): Explore Copilot Infrastructure for building Agent-Native Applications.
- [CopilotKit API Reference](https://docs.copilotkit.ai/reference): Comprehensive API reference for CopilotKit components and hooks.
- [Copilot Infrastructure Overview](https://docs.copilotkit.ai/crewai-flows): Explore Copilot Infrastructure for building Agent-Native Applications.
- [LangGraph Quickstart Guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph): Quickly set up a LangGraph agent with CopilotKit.
- [CrewAI Support](https://docs.copilotkit.ai/crewai-crews): Explore Copilot Infrastructure for building Agent-Native Applications.
- [Self-Hosting Copilot](https://docs.copilotkit.ai/guides/self-hosting): Learn to self-host Copilot Runtime for seamless integration.
- [useCopilotAction Hook](https://docs.copilotkit.ai/reference/hooks/useCopilotAction): React hook for custom actions in Copilot applications.
- [State Machine Guide](https://docs.copilotkit.ai/cookbook/state-machine): Learn to implement state machines for guided conversations.
- [Agent State Management](https://docs.copilotkit.ai/reference/hooks/useCoAgent): Integrate and manage agent state in applications easily.
- [CopilotKit Component Guide](https://docs.copilotkit.ai/reference/components/CopilotKit): Comprehensive guide to using the CopilotKit component.
- [Frontend Actions Guide](https://docs.copilotkit.ai/coagents/frontend-actions): Learn to create and implement frontend actions for AI agents.
- [Generative UI Overview](https://docs.copilotkit.ai/coagents/generative-ui): Explore Generative UI for rendering agent behaviors and outputs.
- [CopilotKit Quickstart Guide](https://docs.copilotkit.ai/quickstart?component=CopilotChat): Quickly integrate CopilotKit for chat functionality in apps.
- [Message History Management](https://docs.copilotkit.ai/guides/messages-localstorage): Learn to save and restore message history using localStorage.
- [Copilot Suggestions Guide](https://docs.copilotkit.ai/guides/copilot-suggestions): Learn to auto-generate chat suggestions based on app state.
- [CopilotTask Overview](https://docs.copilotkit.ai/reference/classes/CopilotTask): Execute one-off tasks using CopilotTask in applications.
- [Copilot Textarea Guide](https://docs.copilotkit.ai/guides/copilot-textarea): Learn to implement AI-powered Copilot Textarea in React.
- [CrewAI Documentation](https://docs.copilotkit.ai/crewai-crews/components): Find support and documentation for CrewAI components.
- [CopilotRuntime Class Reference](https://docs.copilotkit.ai/reference/classes/CopilotRuntime): Explore CopilotRuntime class for LLM interactions and configurations.
- [useLangGraphInterrupt Hook](https://docs.copilotkit.ai/reference/hooks/useLangGraphInterrupt): React hook for custom UI on LangGraph Interrupt events.
- [CopilotTextarea Component](https://docs.copilotkit.ai/reference/components/CopilotTextarea): AI-powered textarea component with enhanced autocomplete features.
- [CopilotKit Quickstart Guide](https://docs.copilotkit.ai/quickstart?component=CopilotSidebar): Quickly set up CopilotKit for your application in minutes.
- [Generative UI Guide](https://docs.copilotkit.ai/guides/generative-ui): Learn to embed custom UI components in chat interfaces.
- [Chat Suggestions Hook](https://docs.copilotkit.ai/reference/hooks/useCopilotChatSuggestions): Generate chat suggestions based on app state in real-time.
- [Anonymous Telemetry Management](https://docs.copilotkit.ai/telemetry): Learn how to manage anonymous telemetry in CopilotKit.
- [Shared State Overview](https://docs.copilotkit.ai/coagents/shared-state): Learn about shared state for UI and agent interaction.
- [Frontend Actions Guide](https://docs.copilotkit.ai/guides/frontend-actions): Learn to enable Copilot actions in frontend applications.
- [CopilotKit Common Issues](https://docs.copilotkit.ai/troubleshooting/common-issues): Find solutions to common CopilotKit issues and errors.
- [LangGraph Quickstart Guide](https://docs.copilotkit.ai/coagents/quickstart/langgraph): Quickly set up a LangGraph agent with CopilotKit.
- [LangGraph Framework Overview](https://docs.copilotkit.ai/coagents/concepts/langgraph): Explore LangGraph framework for building LLM applications.
- [Backend Actions Guide](https://docs.copilotkit.ai/guides/backend-actions): Learn to implement backend actions and agents in Copilot.
- [Agent State Rendering](https://docs.copilotkit.ai/reference/hooks/useCoAgentStateRender): Render agent state in chat using useCoAgentStateRender hook.
- [useCopilotReadable Hook](https://docs.copilotkit.ai/reference/hooks/useCopilotReadable): React hook for managing app state with Copilot.
- [CopilotPopup Component](https://docs.copilotkit.ai/reference/components/chat/CopilotPopup): Interactive chatbot popup component for CopilotKit framework.
- [CoAgents Common Issues](https://docs.copilotkit.ai/coagents/troubleshooting/common-issues): Troubleshooting guide for common CoAgents issues and solutions.
- [Agentic Generative UI](https://docs.copilotkit.ai/coagents/generative-ui/agentic): Learn to render agent state with custom UI components.
- [Agentic Copilots Overview](https://docs.copilotkit.ai/coagents/concepts/agentic-copilots): Explore advanced control and orchestration of AI agents.
- [Connect Your Data](https://docs.copilotkit.ai/guides/connect-your-data): Learn to connect your data to CopilotKit effectively.
- [CopilotChat Component](https://docs.copilotkit.ai/reference/components/chat/CopilotChat): Explore the customizable CopilotChat component for chat interfaces.
- [CrewAI Components Guide](https://docs.copilotkit.ai/crewai-crews/components/types): Explore CrewAI components and documentation for effective usage.
- [CopilotKit Quickstart Guide](https://docs.copilotkit.ai/quickstart?component=Headless+UI): Quickly set up CopilotKit for your application in minutes.
- [LangGraph SDK Overview](https://docs.copilotkit.ai/reference/sdk/python/LangGraph): Explore the Python LangGraph SDK for CopilotKit workflows.
- [CopilotKit Remote Endpoints](https://docs.copilotkit.ai/reference/sdk/python/RemoteEndpoints): Connect Python actions and agents to CopilotKit applications.
- [LangGraph SDK Overview](https://docs.copilotkit.ai/reference/sdk/js/LangGraph): JavaScript SDK for building LangGraph workflows with CopilotKit.
- [Multi-Agent Flows](https://docs.copilotkit.ai/coagents/multi-agent-flows): Learn to orchestrate complex flows with multiple agents.
- [Copilot Sidebar Component](https://docs.copilotkit.ai/reference/components/chat/CopilotSidebar): Customizable sidebar component for chatbot interactions in CopilotKit.
- [CrewAI Quickstart Guide](https://docs.copilotkit.ai/crewai-flows/quickstart/crewai): Quickly set up CrewAI Flows with CopilotKit integration.
- [Copilotkit Configuration Guide](https://docs.copilotkit.ai/coagents/concepts/copilotkit-config): Learn to configure message streaming and tool calls in Copilotkit.
- [Agentic Chat UI](https://docs.copilotkit.ai/coagents/agentic-chat-ui): Explore CopilotKit's agentic chat UI components for user interaction.
- [CrewAIAgent Overview](https://docs.copilotkit.ai/reference/sdk/python/CrewAIAgent): Define and serve agents using CrewAIAgent in Python.
- [CrewAI Quickstart Guide](https://docs.copilotkit.ai/crewai-crews/quickstart/crewai): Quickly set up CrewAI Crews with CopilotKit integration.
- [LangGraphAgent Overview](https://docs.copilotkit.ai/reference/sdk/python/LangGraphAgent): Define and configure agents for CopilotKit using Python.
- [CopilotKit Guardrails Guide](https://docs.copilotkit.ai/guides/guardrails): Learn to implement content moderation guardrails in CopilotKit.
- [LangSmith Observability](https://docs.copilotkit.ai/observability/langsmith): Setup LangSmith for tracing LLM runs with CopilotKit.
- [Disabling State Streaming](https://docs.copilotkit.ai/coagents/advanced/disabling-state-streaming): Control state streaming to the frontend in CopilotKit.
- [Integrate Your LLM](https://docs.copilotkit.ai/guides/bring-your-own-llm): Learn to integrate any LLM with CopilotKit easily.
- [Customizing UI](https://docs.copilotkit.ai/guides/custom-look-and-feel): Customize CopilotKit's UI components for unique interfaces.
- [Self-Host CopilotKit](https://docs.copilotkit.ai/quickstart?copilot-hosting=self-hosted): Quickly set up and self-host CopilotKit in minutes.
- [Connect Your Data](https://docs.copilotkit.ai/guides/connect-your-data/frontend): Learn to connect data to CopilotKit for better responses.
- [Loading Message History](https://docs.copilotkit.ai/coagents/persistence/loading-message-history): Learn to load and manage chat message threads effectively.
- [Human-in-the-Loop Overview](https://docs.copilotkit.ai/coagents/human-in-the-loop): Explore Human-in-the-Loop for AI collaboration and reliability.
- [CopilotKit Quickstart Guide](https://docs.copilotkit.ai/quickstart?component=Headless%20UI): Quickly set up CopilotKit for your application in minutes.
- [Customize AI Assistant](https://docs.copilotkit.ai/guides/custom-ai-assistant-behavior): Learn to customize your AI assistant's behavior effectively.
- [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state): Learn how to load previous agent states using threadId.
- [OpenAIAdapter Overview](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAdapter): Explore the OpenAIAdapter for Copilot Runtime integration.
- [GroqAdapter Overview](https://docs.copilotkit.ai/reference/classes/llm-adapters/GroqAdapter): Explore GroqAdapter for Copilot Runtime integration and usage.
- [OpenAI Assistant Adapter](https://docs.copilotkit.ai/reference/classes/llm-adapters/OpenAIAssistantAdapter): Adapter for integrating OpenAI Assistant API with Copilot.
- [LangChainAdapter Overview](https://docs.copilotkit.ai/reference/classes/llm-adapters/LangChainAdapter): Explore the LangChainAdapter for Copilot Runtime integration.
- [Loading Agent State](https://docs.copilotkit.ai/coagents/persistence/loading-agent-state): Learn how to load previous agent states using threadId.
- [CopilotKit Documentation](https://docs.copilotkit.ai/?ref=github_readme): Explore tools for building AI copilots and agents.
- [Google Generative AI](https://docs.copilotkit.ai/reference/classes/llm-adapters/GoogleGenerativeAIAdapter): Adapter for Google Generative AI in Copilot Runtime.
- [CrewAI Documentation](https://docs.copilotkit.ai/crewai-crews?ref=blog.crewai.com): Explore Copilot Infrastructure for building Agent-Native Applications.
- [Agent State Management](https://docs.copilotkit.ai/coagents/shared-state/state-inputs-outputs): Guide on managing agent state inputs and outputs effectively.
- [Predictive State Updates](https://docs.copilotkit.ai/coagents/shared-state/predictive-state-updates): Learn to implement predictive state updates for agents.
- [CopilotKit Migration Guide](https://docs.copilotkit.ai/troubleshooting/migrate-to-1.8.2): Migration guide for CopilotKit version 1.8.2 features.
- [Generative UI Guide](https://docs.copilotkit.ai/guides/generative-ui?ref=hackernoon.com): Learn to embed custom UI components in chat interfaces.
- [Agentic Generative UI](https://docs.copilotkit.ai/coagents/generative-ui/agentic): Learn to render agent state with custom UI components.
- [TypeScript Backend Actions](https://docs.copilotkit.ai/guides/backend-actions/typescript-backend-actions): Learn to implement TypeScript backend actions in CopilotKit.
- [Tool-based Generative UI](https://docs.copilotkit.ai/crewai-crews/generative-ui/tool-based): Learn to render tool calls with custom UI components.
- [LangGraph Platform Deployment](https://docs.copilotkit.ai/guides/backend-actions/langgraph-platform-endpoint): Guide to deploy and connect agents on LangGraph Platform.
- [Remote Backend Integration](https://docs.copilotkit.ai/guides/backend-actions/remote-backend-endpoint): Integrate Python backend with CopilotKit using FastAPI.
- [Human-in-the-Loop Overview](https://docs.copilotkit.ai/crewai-flows/human-in-the-loop): Explore Human-in-the-Loop for AI collaboration and reliability.
- [Authenticated Actions Guide](https://docs.copilotkit.ai/guides/authenticated-actions): Learn to implement secure authenticated actions in CopilotKit.
- [CoAgents Terminology](https://docs.copilotkit.ai/coagents/concepts/terminology): Key terms and definitions for understanding CoAgents concepts.
- [Contributing to Documentation](https://docs.copilotkit.ai/contributing/docs-contributions): Learn how to contribute to CopilotKit documentation effectively.
- [useCopilotChat Hook](https://docs.copilotkit.ai/reference/hooks/useCopilotChat): React hook for interacting with Copilot chat instance.
- [Human-in-the-Loop Guide](https://docs.copilotkit.ai/coagents/human-in-the-loop/node-flow): Learn to implement Human-in-the-Loop with node-based flows.
- [Headless UI Customization](https://docs.copilotkit.ai/guides/custom-look-and-feel/headless-ui): Customize Copilot's UI using headless components and hooks.
- [Agent State Writing Guide](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write): Learn how to write to your agent's state effectively.
- [Chat Components Overview](https://docs.copilotkit.ai/reference/components/chat): Explore various chat components for Copilot integration.
- [LangChain JS Integration](https://docs.copilotkit.ai/guides/backend-actions/langchain-js-backend-actions): Integrate LangChain JS actions with CopilotRuntime for backend.
- [Agent State Management](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-read): Learn to read and manage agent state in apps.
- [Human-in-the-Loop Guide](https://docs.copilotkit.ai/coagents/human-in-the-loop/interrupt-flow): Learn to implement Human-in-the-Loop workflows with interrupts.
- [Agent State Writing Guide](https://docs.copilotkit.ai/coagents/shared-state/in-app-agent-write): Learn how to write to your agent's state effectively.
- [Message Management Overview](https://docs.copilotkit.ai/coagents/concepts/message-management): Explore message management in CoAgents with CopilotKit.
- [Exiting Agent Loop](https://docs.copilotkit.ai/coagents/advanced/exit-agent): Learn how to exit the agent loop in CopilotKit.
- [Message Persistence Guide](https://docs.copilotkit.ai/coagents/persistence/message-persistence): Learn to persist messages and agent states effectively.
- [Emit Messages Guide](https://docs.copilotkit.ai/coagents/advanced/emit-messages): Learn to manually emit messages in CopilotKit agents.


================================================
FILE: docs/public/robots.txt
================================================
User-agent: *
Allow: /

Host: https://docs.copilotkit.ai

Sitemap: https://docs.copilotkit.ai/sitemap.xml




================================================
FILE: docs/public/images/logo-light.webp
================================================
[Non-text file]














================================================
FILE: docs/snippets/component-examples.mdx
================================================

<Tabs groupId="component" items={["CopilotPopup", "CopilotSidebar", "CopilotChat", "Headless UI"]}>
  <Tab value="CopilotPopup">

    `CopilotPopup` is a convenience wrapper for `CopilotChat` that lives at the same level as your main content in the view hierarchy. It provides **a floating chat interface** that can be toggled on and off.

    <img src="/images/popup-example.gif" alt="Popup Example" className="w-full rounded-lg my-4" />

    ```tsx
    // [!code word:CopilotPopup]
    import { CopilotPopup } from "@copilotkit/react-ui";

    export function YourApp() {
      return (
        <>
          <YourMainContent />
          <CopilotPopup
            instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
            labels={{
              title: "Popup Assistant",
              initial: "Need any help?",
            }}
          />
        </>
      );
    }
    ```

  </Tab>
  <Tab value="CopilotSidebar">
    `CopilotSidebar` is a convenience wrapper for `CopilotChat` that wraps your main content in the view hierarchy. It provides a **collapsible and expandable sidebar** chat interface.

    <img src="/images/sidebar-example.gif" alt="Popup Example" className="w-full rounded-lg my-4" />

    ```tsx
    // [!code word:CopilotSidebar]
    import { CopilotSidebar } from "@copilotkit/react-ui";

    export function YourApp() {
      return (
        <CopilotSidebar
          defaultOpen={true}
          instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
          labels={{
            title: "Sidebar Assistant",
            initial: "How can I help you today?",
          }}
        >
          <YourMainContent />
        </CopilotSidebar>
      );
    }
    ```



  </Tab>
  <Tab value="CopilotChat">
    `CopilotChat` is a flexible chat interface component that **can be placed anywhere in your app** and can be resized as you desire.

    <img src="/images/copilotchat-example.gif" alt="Popup Example" className="w-full rounded-lg my-4" />

    ```tsx
    // [!code word:CopilotChat]
    import { CopilotChat } from "@copilotkit/react-ui";

    export function YourComponent() {
      return (
        <CopilotChat
          instructions={"You are assisting the user as best as you can. Answer in the best way possible given the data you have."}
          labels={{
            title: "Your Assistant",
            initial: "Hi! 👋 How can I assist you today?",
          }}
        />
      );
    }
    ```

  </Tab>
  <Tab value="Headless UI">
    The built-in Copilot UI can be customized in many ways -- both through css and by passing in custom sub-components.

    CopilotKit also offers **fully custom headless UI**, through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

    ```tsx
    import { useCopilotChat } from "@copilotkit/react-core";
    import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

    export function CustomChatInterface() {
      const {
        visibleMessages,
        appendMessage,
        setMessages,
        deleteMessage,
        reloadMessages,
        stopGeneration,
        isLoading,
      } = useCopilotChat();

      const sendMessage = (content: string) => {
        appendMessage(new TextMessage({ content, role: Role.User }));
      };

      return (
        <div>
          {/* Implement your custom chat UI here */}
        </div>
      );
    }
    ```
  </Tab>
</Tabs>



================================================
FILE: docs/snippets/copilot-cloud-configure-copilotkit-provider.mdx
================================================
import { Callout } from 'fumadocs-ui/components/callout';
import { LinkToCopilotCloud } from '@/components/react/link-to-copilot-cloud';

The [`<CopilotKit>`](/reference/components/CopilotKit) provider must wrap the Copilot-aware parts of your application.
For most use-cases, it's appropriate to wrap the `CopilotKit` provider around the entire app, e.g. in your `layout.tsx`

<Callout type="info">
  Note that you can add the `<CopilotKit>` provider anywhere in your application. In fact, you can have multiple `<CopilotKit>` providers per app if you want independent copilots.
</Callout>


<Callout type="info">
    <LinkToCopilotCloud asButton={false}>Click here to get your Copilot Cloud API key for free</LinkToCopilotCloud>. Then, replace `<your-public-api-key>` with your actual API key.
</Callout>

```tsx title="layout.tsx" showLineNumbers
import "./globals.css";

import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core"; // [!code highlight]

export default function RootLayout({ children }: { children: ReactNode }) {
    return (
      <html lang="en">
        <body> 
          {/* Use the public api key you got from Copilot Cloud  */} // [!code highlight:4]
          <CopilotKit publicApiKey="<your-copilot-cloud-public-api-key>"> 
            {children}
          </CopilotKit>
        </body>
      </html>
    );
}
```


================================================
FILE: docs/snippets/copilot-cloud-configure-remote-endpoint-langgraph.mdx
================================================
import { Callout } from 'fumadocs-ui/components/callout';
import { LinkToCopilotCloud } from '@/components/react/link-to-copilot-cloud';
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

To connect to LangGraph agents through Copilot Cloud, we leverage a concept called "Remote Endpoints"
which allow CopilotKit runtime to connect to various backends.

Navigate to <LinkToCopilotCloud asButton={false}>cloud.copilotkit.ai</LinkToCopilotCloud> and follow the video!

You'll need a LangSmith API key which you can get with [this guide](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key#create-an-api-key) on LangSmith's website.

<Accordions>
<Accordion title="Using LangGraph Studio">

    If you're using a local deployment from LangGraph Studio, you'll need to open a tunnel to your LangGraph Studio deployment URL.

    ```bash
    npx copilotkit@latest dev --port <port_number>
    ```
</Accordion>
</Accordions>

<Frame className="mt-4">
    <img src="/images/copilot-cloud/cpk-cloud-lgp-endpoint.gif" alt="Configure Remote Endpoint LangGraph" />
</Frame>

🎉 You should now see your LangGraph agent in the list of available agents in CopilotKit!


================================================
FILE: docs/snippets/copilot-cloud-configure-remote-endpoint.mdx
================================================
import { Callout } from 'fumadocs-ui/components/callout';
import { LinkToCopilotCloud } from '@/components/react/link-to-copilot-cloud';
import { Accordions, Accordion } from "fumadocs-ui/components/accordion";

To connect a FastAPI server to Copilot Cloud, we leverage a concept called "Remote Endpoints"
which allow CopilotKit runtime to connect to various backends.

To get started, <LinkToCopilotCloud asButton={false}>navigate to Copilot Cloud</LinkToCopilotCloud>. 

<Callout title="Don't want to use a tunnel?">
Just skip the tunnel setup and use your hosted FastAPI server address instead.
</Callout>

```sh
npx copilotkit@latest dev --port <port_number>
```

<Frame className="mt-4">
    <img src="/images/copilot-cloud/cpk-cloud-remote-endpoint-setup.gif" alt="Configure Remote Endpoint" />
</Frame>

You should now see your CopilotKit runtime in the list of available agents in CopilotKit!


================================================
FILE: docs/snippets/copilot-ui.mdx
================================================
import ComponentExamples from "@/snippets/component-examples.mdx";

First, import the default styles in your root component (typically `layout.tsx`) :

```tsx filename="layout.tsx"
import "@copilotkit/react-ui/styles.css";
```

<Callout type="info">
  Copilot UI ships with a number of built-in UI patterns, choose whichever one you like.
</Callout>

<ComponentExamples components={props.components} />



================================================
FILE: docs/snippets/crew-quickstart.mdx
================================================
## Complete Crew Setup

This guide shows how to set up your CrewAI agent with CopilotKit in a **single file**, including:

1. **Starting** your crew
2. **Rendering** Crew state and progress
3. **Handling** human feedback
4. **(Optional)** Extending for final results

Below is a **copy-paste** example called `crew-quickstart.tsx`. Once you have it in your code, just render `<QuickstartCrew />` in your application to see it in action!

```tsx title="use-crew-quickstart.tsx"
"use client";

import {
  CrewsAgentState,
  CrewsResponseStatus,
  CrewsStateItem,
  CrewsTaskStateItem,
  CrewsToolStateItem,
  useCoAgent,
  useCoAgentStateRender,
  useCopilotAction,
  useCopilotChat,
  useCopilotAdditionalInstructions,
} from "@copilotkit/react-core";
import { useEffect, useMemo, useRef, useState } from "react";

import { MessageRole, TextMessage } from "@copilotkit/runtime-client-gql";

interface CrewsFeedback extends CrewsStateItem {
  /**
   * Output of the task execution
   */
  task_output?: string;
}

/**
 * Renders your Crew's steps & tasks in real-time.
 */
function CrewStateRenderer({
  state,
  status,
}: {
  state: CrewsAgentState;
  status: CrewsResponseStatus;
}) {
  const [isCollapsed, setIsCollapsed] = useState(true);
  const contentRef = useRef<HTMLDivElement>(null);
  const prevItemsLengthRef = useRef<number>(0);
  const [highlightId, setHighlightId] = useState<string | null>(null);

  // Combine steps + tasks
  const items = useMemo(() => {
    if (!state) return [];
    return [...(state.steps || []), ...(state.tasks || [])].sort(
      (a, b) =>
        new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
    );
  }, [state]);

  // Highlight newly added item & auto-scroll
  useEffect(() => {
    if (!state) return;
    if (items.length > prevItemsLengthRef.current) {
      const newestItem = items[items.length - 1];
      setHighlightId(newestItem.id);
      setTimeout(() => setHighlightId(null), 1500);

      if (contentRef.current && !isCollapsed) {
        contentRef.current.scrollTop = contentRef.current.scrollHeight;
      }
    }
    prevItemsLengthRef.current = items.length;
  }, [items, isCollapsed, state]);

  if (!state) {
    return <div>Loading crew state...</div>;
  }

  // Hide entirely if collapsed & empty & not in progress
  if (isCollapsed && items.length === 0 && status !== "inProgress") return null;

  return (
    <div style={{ marginTop: "8px", fontSize: "0.9rem" }}>
      <div
        style={{ cursor: "pointer", display: "flex", alignItems: "center" }}
        onClick={() => setIsCollapsed(!isCollapsed)}
      >
        <span style={{ marginRight: 4 }}>{isCollapsed ? "▶" : "▼"}</span>
        {status === "inProgress" ? "Crew is analyzing..." : "Crew analysis"}
      </div>

      {!isCollapsed && (
        <div
          ref={contentRef}
          style={{
            maxHeight: "200px",
            overflow: "auto",
            borderLeft: "1px solid #ccc",
            paddingLeft: "8px",
            marginLeft: "4px",
            marginTop: "4px",
          }}
        >
          {items.length > 0 ? (
            items.map((item) => {
              const isTool = (item as CrewsToolStateItem).tool !== undefined;
              const isHighlighted = item.id === highlightId;
              return (
                <div
                  key={item.id}
                  style={{
                    marginBottom: "8px",
                    animation: isHighlighted ? "fadeIn 0.5s" : undefined,
                  }}
                >
                  <div style={{ fontWeight: "bold" }}>
                    {isTool
                      ? (item as CrewsToolStateItem).tool
                      : (item as CrewsTaskStateItem).name}
                  </div>
                  {"thought" in item && item.thought && (
                    <div style={{ opacity: 0.8, marginTop: "4px" }}>
                      Thought: {item.thought}
                    </div>
                  )}
                  {"result" in item && item.result !== undefined && (
                    <pre style={{ fontSize: "0.85rem", marginTop: "4px" }}>
                      {JSON.stringify(item.result, null, 2)}
                    </pre>
                  )}
                  {"description" in item && item.description && (
                    <div style={{ marginTop: "4px" }}>{item.description}</div>
                  )}
                </div>
              );
            })
          ) : (
            <div style={{ opacity: 0.7 }}>No activity yet...</div>
          )}
        </div>
      )}

      {/* Simple fadeIn animation */}
      <style>{`
        @keyframes fadeIn {
          0% { opacity: 0; transform: translateY(4px); }
          100% { opacity: 1; transform: translateY(0); }
        }
      `}</style>
    </div>
  );
}

/**
 * Renders a simple UI for agent-requested user feedback (Approve / Reject).
 */
function CrewHumanFeedbackRenderer({
  feedback,
  respond,
  status,
}: {
  feedback: CrewsFeedback;
  respond?: (input: string) => void;
  status: CrewsResponseStatus;
}) {
  const [isExpanded, setIsExpanded] = useState(true);
  const [userResponse, setUserResponse] = useState<string | null>(null);

  if (status === "complete") {
    return (
      <div style={{ marginTop: 8, textAlign: "right" }}>
        {userResponse || "Feedback submitted."}
      </div>
    );
  }

  if (status === "inProgress" || status === "executing") {
    return (
      <div style={{ marginTop: 8 }}>
        {isExpanded && (
          <div
            style={{
              border: "1px solid #ddd",
              padding: "8px",
              marginBottom: "8px",
            }}
          >
            {feedback.task_output}
          </div>
        )}
        <div style={{ textAlign: "right" }}>
          <button
            style={{ marginRight: 8 }}
            onClick={() => setIsExpanded(!isExpanded)}
          >
            {isExpanded ? "Hide" : "Show"} Feedback
          </button>
          <button
            style={{
              marginRight: 8,
              backgroundColor: "#222222",
              border: "none",
              padding: "8px 16px",
              color: "white",
              cursor: "pointer",
              borderRadius: "4px",
            }}
            onClick={() => {
              setUserResponse("Approved");
              /**
               * This string is arbitrary. It can be any serializable input that will be forwarded to your Crew as feedback.
               */
              respond?.("Approve");
            }}
          >
            Approve
          </button>
          <button
            style={{
              backgroundColor: "#222222",
              border: "none",
              padding: "8px 16px",
              color: "white",
              cursor: "pointer",
              borderRadius: "4px",
            }}
            onClick={() => {
              setUserResponse("Rejected");
              /**
               * This string is arbitrary. It can be any serializable input that will be forwarded to your Crew as feedback.
               */
              respond?.("Reject");
            }}
          >
            Reject
          </button>
        </div>
      </div>
    );
  }

  return null;
}

/**
 * useCrewQuickstart
 * Minimal example that:
 * 1) Sets up a crew/agent
 * 2) Handles text-based user input (get_input)
 * 3) Renders real-time crew state
 * 4) Handles "crew_requesting_feedback"
 */
export const useCrewQuickstart = ({
  crewName,
  inputs,
}: {
  crewName: string;
  inputs: Array<string>;
}): {
  output: string;
} => {
  const [initialMessageSent, setInitialMessageSent] = useState(false);

  const { state, setState, run } = useCoAgent<
    CrewsAgentState & {
      result: string;
      inputs: Record<string, string>;
    }
  >({
    name: crewName,
    initialState: {
      inputs: {},
      result: "Crew result will appear here...",
    },
  });

  const { appendMessage, isLoading } = useCopilotChat();

  const instructions =
    "INPUTS ARE ABSOLUTELY REQUIRED. Please call getInputs before proceeding with anything else.";

  // Render an initial message when the chat is first loaded
  useEffect(() => {
    if (initialMessageSent || isLoading) return;

    setTimeout(async () => {
      await appendMessage(
        new TextMessage({
          content: "Hi, Please provide your inputs before we get started.",
          role: MessageRole.Developer,
        })
      );
      setInitialMessageSent(true);
    }, 0);
  }, []);

  useEffect(() => {
    if (!initialMessageSent && Object.values(state?.inputs || {}).length > 0) {
      appendMessage(
        new TextMessage({
          role: MessageRole.Developer,
          content: "My inputs are: " + JSON.stringify(state?.inputs),
        })
      ).then(() => {
        setInitialMessageSent(true);
      });
    }
  }, [initialMessageSent, state?.inputs]);

  useCopilotAdditionalInstructions({
    instructions,
    available:
      Object.values(state?.inputs || {}).length > 0 ? "enabled" : "disabled",
  });

  useCopilotAction({
    name: "getInputs",
    followUp: false,
    description:
      "This action allows Crew to get required inputs from the user before starting the Crew.",
    renderAndWaitForResponse({ status }) {
      if (status === "inProgress" || status === "executing") {
        return (
          <form
            style={{ display: "flex", flexDirection: "column", gap: "16px" }}
            onSubmit={async (e: React.FormEvent<HTMLFormElement>) => {
              e.preventDefault();
              const form = e.currentTarget;
              const input = form.elements.namedItem(
                "input"
              ) as HTMLTextAreaElement;
              const inputValue = input.value;
              const inputKey = input.id;

              setState({
                ...state,
                inputs: {
                  ...state.inputs,
                  [inputKey]: inputValue,
                },
              });
              setTimeout(async () => {
                console.log("running crew");
                await run();
                console.log("crew run complete");
              }, 0);
            }}
          >
            <div
              style={{ display: "flex", flexDirection: "column", gap: "16px" }}
            >
              {inputs.map((input) => (
                <div
                  key={input}
                  style={{
                    display: "flex",
                    flexDirection: "column",
                    gap: "8px",
                  }}
                >
                  <label htmlFor={input}>{input}</label>
                  <textarea
                    id={input}
                    autoFocus
                    name="input"
                    placeholder={`Enter ${input} here`}
                    required
                  />
                </div>
              ))}
              <button
                type="submit"
                style={{
                  cursor: "pointer",
                }}
              >
                Submit
              </button>
            </div>
          </form>
        );
      }
      return <>Inputs submitted</>;
    },
  });

  useCoAgentStateRender({
    name: crewName,
    render: ({ state, status }) => (
      <CrewStateRenderer state={state} status={status} />
    ),
  });

  useCopilotAction({
    name: "crew_requesting_feedback",
    description: "Request feedback from the user",
    renderAndWaitForResponse(props) {
      const { status, args, respond } = props;
      return (
        <CrewHumanFeedbackRenderer
          feedback={args as unknown as CrewsFeedback}
          respond={respond}
          status={status as CrewsResponseStatus}
        />
      );
    },
  });

  return {
    output: state?.result || "",
  };
};
```



================================================
FILE: docs/snippets/find-your-copilot-runtime.mdx
================================================
### Find your CopilotRuntime

The starting point for this section is the `CopilotRuntime` you set up during quickstart (the CopilotKit backend endpoint).
For a refresher, see [Self-Hosting](/guides/self-hosting) (or alternatively, revisit the [quickstart](/quickstart)).

**First, find your `CopilotRuntime` instance in your code.** You can simply search your codebase for `CopilotRuntime`.

If you followed the quickstart, it'll be where you set up the `/api/copilotkit` endpoint.



================================================
FILE: docs/snippets/headless-ui.mdx
================================================
The built-in Copilot UI can be customized in many ways -- both through css and by passing in custom sub-components.

CopilotKit also offers **fully custom headless UI**, through the `useCopilotChat` hook. Everything built with the built-in UI (and more) can be implemented with the headless UI, providing deep customizability.

```tsx
import { useCopilotChat } from "@copilotkit/react-core";
import { Role, TextMessage } from "@copilotkit/runtime-client-gql";

export function CustomChatInterface() {
  const {
    visibleMessages,
    appendMessage,
    setMessages,
    deleteMessage,
    reloadMessages,
    stopGeneration,
    isLoading,
  } = useCopilotChat();

  const sendMessage = (content: string) => {
    appendMessage(new TextMessage({ content, role: Role.User }));
  };

  return (
    <div>
      {/* Implement your custom chat UI here */}
    </div>
  );
}
```


================================================
FILE: docs/snippets/install-python-sdk-crew.mdx
================================================
<Tabs groupId="python-pm" items={['Poetry', 'pip', 'conda']} default="Poetry">
    <Tab value="Poetry">
    ```bash
    poetry add copilotkit
    # including support for crewai
    poetry add copilotkit[crewai]
    ```
    </Tab>
    
    <Tab value="pip">

    ```bash
    pip install copilotkit --extra-index-url https://copilotkit.gateway.scarf.sh/simple/
    # including support for crewai
    pip install copilotkit[crewai] --extra-index-url https://copilotkit.gateway.scarf.sh/simple/
    ```
    </Tab>

    <Tab value="conda">
    ```bash
    conda install copilotkit -c copilotkit-channel
    # including support for crewai
    conda install copilotkit[crewai] -c copilotkit-channel
    ```
    </Tab>

</Tabs>



================================================
FILE: docs/snippets/install-python-sdk.mdx
================================================
<Tabs groupId="python-pm" items={['Poetry', 'pip', 'conda']} default="Poetry">
    <Tab value="Poetry">
    ```bash
    poetry add copilotkit
    ```
    </Tab>
    
    <Tab value="pip">

    ```bash
    pip install copilotkit --extra-index-url https://copilotkit.gateway.scarf.sh/simple/
    ```
    </Tab>

    <Tab value="conda">
    ```bash
    conda install copilotkit -c copilotkit-channel
    ```
    </Tab>
</Tabs>



================================================
FILE: docs/snippets/install-sdk.mdx
================================================
import InstallPythonSDKSnippet from "@/snippets/install-python-sdk.mdx";

Any LangGraph agent can be used with CopilotKit. However, creating deep agentic 
experiences with CopilotKit requires our LangGraph SDK.

<Tabs groupId="language" items={["Python", "TypeScript"]}>
  <Tab value="Python">
    <div className="py-6">
      <InstallPythonSDKSnippet components={props.components} />
    </div>
  </Tab>
  <Tab value="TypeScript" className="py-6">
    <div className="py-6">
      ```package-install
      npm install @copilotkit/sdk-js
      ```
    </div>
  </Tab>
</Tabs>



================================================
FILE: docs/snippets/langgraph-platform-deployment-tabs.mdx
================================================
<Tabs groupId="lg-deployment-type" items={['Local (LangGraph Studio)', 'Self hosted (FastAPI)', 'LangGraph Platform']}>
  <Tab value="Local (LangGraph Studio)">
    For local development, you can use the [LangGraph CLI](https://langchain-ai.github.io/langgraph/cloud/reference/cli/) to start a development server and LangGraph studio session.

    <Callout type="info">
      You will need a [LangSmith account](https://smith.langchain.com) to use this method.
    </Callout>
  
    ```bash
    # For Python 3.11 or above
    langgraph dev --host localhost --port 8000 
    ```

    ```bash
    # For TypeScript with Node 18 or above
    npx @langchain/langgraph-cli dev --host localhost --port 8000
    ```

    After starting the LangGraph server, the deployment URL will be `http://localhost:8000`.

    <Accordions className="mb-4">
        <Accordion title="Having trouble?">
            If you cannot run the `langgraph dev` command, or encounter any issues with it, try this one instead:
            `uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.12 langgraph dev`
        </Accordion>
    </Accordions>
  </Tab>

  <Tab value="Self hosted (FastAPI)">
    <Callout type="info">
      This method is currently only supported for Python LangGraph agents.
    </Callout>

    1. Add a `.env` file to contain your LangSmith API key.

    ```plaintext title=".env"
    LANGSMITH_API_KEY=your_langsmith_api_key
    ```
    
    2. Next, use CopilotKit's FastAPI integration to serve your LangGraph agent.

    ```python title="server.py"
    import os
    from fastapi import FastAPI
    import uvicorn
    from copilotkit.integrations.fastapi import add_fastapi_endpoint # [!code highlight]
    from copilotkit import CopilotKitRemoteEndpoint, LangGraphAgent # [!code highlight]
    from sample_agent.agent import graph # the coagents-starter path, replace this if its different # [!code highlight]
    
    from dotenv import load_dotenv
    load_dotenv()

    app = FastAPI()
    # [!code highlight:10]
    sdk = CopilotKitRemoteEndpoint(
        agents=[
            LangGraphAgent(
                name="sample_agent", # the name of your agent defined in langgraph.json
                description="Describe your agent here, will be used for multi-agent orchestration",
                graph=graph, # the graph object from your langgraph import
            )
        ],
    )

    # Use CopilotKit's FastAPI integration to add a new endpoint for your LangGraph agents # [!code highlight:2]
    add_fastapi_endpoint(app, sdk, "/copilotkit", use_thread_pool=False)

    # add new route for health check
    @app.get("/health")
    def health():
        """Health check."""
        return {"status": "ok"}

    def main():
        """Run the uvicorn server."""
        port = int(os.getenv("PORT", "8000"))
        uvicorn.run(
            "sample_agent.demo:app", # the path to your FastAPI file, replace this if its different
            host="0.0.0.0",
            port=port,
            reload=True,
        )

    ```
  </Tab>

  <Tab value="LangGraph Platform">
    For production, you can deploy to LangGraph Platform by following the official [LangGraph Platform deployment guide](https://langchain-ai.github.io/langgraph/cloud/deployment/cloud/).

    Come back with that URL and a LangSmith API key before proceeding.

    <Callout type="info">
      A successful deployment will yield an API URL (often referred to here as "deployment URL").
      In LangGraph Platform, it will look like this: `https://{project-identifiers}.langgraph.app`.
    </Callout>
  </Tab>
</Tabs>




================================================
FILE: docs/snippets/llm-adapters.mdx
================================================
import { Callout } from 'fumadocs-ui/components/callout';
import { TailoredContent, TailoredContentOption } from "@/components/react/tailored-content.tsx";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";
import { FaCloud, FaServer } from "react-icons/fa";
import FindYourCopilotRuntime from "@/snippets/find-your-copilot-runtime.mdx";

LLM Adapters are responsible for executing the request with the LLM and standardizing the request/response format in a way that the Copilot Runtime can understand.

Currently, we support the following LLM adapters natively:

- [OpenAI Adapter (Azure also supported)](/reference/classes/llm-adapters/OpenAIAdapter)
- [OpenAI Assistant Adapter](/reference/classes/llm-adapters/OpenAIAssistantAdapter)
- [LangChain Adapter](/reference/classes/llm-adapters/LangChainAdapter)
- [Groq Adapter](/reference/classes/llm-adapters/GroqAdapter)
- [Google Generative AI Adapter](/reference/classes/llm-adapters/GoogleGenerativeAIAdapter)
- [Anthropic Adapter](/reference/classes/llm-adapters/AnthropicAdapter)

<Callout type="info">
  You can use the [LangChain Adapter](/reference/classes/llm-adapters/LangChainAdapter) to use any LLM provider we don't yet natively support!
</Callout>


<Callout type="info">
  It's not too hard to write your own LLM adapter from scratch -- see the existing adapters for inspiration. And of course, we would love a contribution! ⭐️
</Callout>


<TailoredContent id="hosting">
  <TailoredContentOption
    id="copilot-cloud"
    title="Copilot Cloud (Recommended)"
    description="Use our hosted backend endpoint to get started quickly (OpenAI only)."
    icon={<FaCloud />}
  >
  Configure the used LLM adapter [on your Copilot Cloud dashboard](https://cloud.copilotkit.ai/)!

  </TailoredContentOption>

  <TailoredContentOption
    id="self-hosted"
    title="Self-hosting"
    description="Learn to host CopilotKit's runtime yourself with your own backend."
    icon={<FaServer />}
  >

  <Steps>
    <Step>
    ## Find your CopilotRuntime instance
    <FindYourCopilotRuntime components={props.components} />

    </Step>

    <Step>
    ## Modify the used LLM Adapter

    Use the example code below to tailor your CopilotRuntime instantiation to your desired llm adapter.

    <SelfHostingCopilotRuntimeCreateEndpoint components={props.components} />
    </Step>

    <Step>
    ## Make further customizations
    See the reference documentation linked above for further customization parameters.
    </Step>

  </Steps>



  </TailoredContentOption>
</TailoredContent>






================================================
FILE: docs/snippets/self-hosting-copilot-runtime-configure-copilotkit-provider.mdx
================================================
```tsx title="layout.tsx"
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core"; // [!code highlight]

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body> 
        {/* Make sure to use the URL you configured in the previous step  */} // [!code highlight:4]
        <CopilotKit runtimeUrl="/api/copilotkit"> 
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}


================================================
FILE: docs/snippets/self-hosting-copilot-runtime-create-endpoint.mdx
================================================
import {
  MultiProviderContent,
  If,
} from "@/components/react/multi-provider-content/multi-provider-content";
import { quickStartProviders } from "@/components/react/multi-provider-content/utils";
import { IoLogoVercel, IoLogoNodejs } from "react-icons/io5";
import { SiNestjs } from "react-icons/si";
import { RiNextjsLine } from "react-icons/ri";

<MultiProviderContent providersConfig={quickStartProviders}>
<Callout type="info">
  If you are planning to use a single LangGraph agent in [agent-lock mode](/coagents/multi-agent-flows) as your agentic backend, your LLM adapter will only be used for peripherals such as suggestions, etc.

If you are not sure yet, simply ignore this note.

</Callout>

    <If conditions={[{ key: 'id', value: 'langchain' }]}>
        <Callout type="info">
            The LangChain adapter shown here is using OpenAI, but can be used with any LLM!
        </Callout>
    </If>

    <If conditions={[{ key: 'id', value: 'empty' }]}>
        <Callout type="error">
            Be aware that the empty adapter only works in combination with CoAgents in agent lock mode!

            In addition, bare in mind that `useCopilotChatSuggestions`, `CopilotTextarea` and `CopilotTask` will not work, as these require an LLM.
        </Callout>
    </If>

    <If conditions={[{ key: 'packageName', value: true }]}>
        ### Install provider package

        ```package-install
        npm install {{packageName}}
        ```
    </If>

    <If conditions={[{ key: 'envVarName', value: true }]}>
        ### Add your API key

        Next, add your API key to your `.env` file in the root of your project (unless you prefer to provide it directly to the client):

        ```plaintext title=".env"
        {{envVarName}}=your_api_key_here
        ```
    </If>

    <If conditions={[{ key: 'id', value: 'openai' }, { key: 'id', value: 'openai-assistants' }]}>
        <Callout type="warn">
            Please note that the code below uses GPT-4o, which requires a paid OpenAI API key. **If you are using a free OpenAI API key**, change the model to a different option such as `gpt-3.5-turbo`.
        </Callout>
    </If>

    ### Setup the Runtime Endpoint

    <Callout type="warn">
        ### Serverless Function Timeouts

        When deploying to serverless platforms (Vercel, AWS Lambda, etc.), be aware that default function timeouts may be too short for CopilotKit's streaming responses:

        - Vercel defaults: 10s (Hobby), 15s (Pro)
        - AWS Lambda default: 3s

        **Solution options:**
        1. Increase function timeout:
            ```json
            // vercel.json
            {
              "functions": {
                "api/copilotkit/**/*": {
                  "maxDuration": 60
                }
              }
            }
            ```
        2. Use [Copilot Cloud](https://cloud.copilotkit.ai/) to avoid timeout issues entirely
    </Callout>

    <Tabs groupId="endpoint-type" items={[
        { value: 'Next.js App Router', icon: <RiNextjsLine className="text-xl" /> },
        { value: 'Next.js Pages Router', icon: <RiNextjsLine className="text-xl" /> },
        { value: 'Node.js Express', icon: <IoLogoNodejs className="text-xl" /> },
        { value: 'Node.js HTTP', icon: <IoLogoNodejs className="text-xl" /> },
        { value: 'NestJS', icon: <SiNestjs className="text-xl" /> }
    ]}>

        {/* Next.js App Router */}
        <Tab value="Next.js App Router">
            Create a new route to handle the `/api/copilotkit` endpoint.

            ```ts title="app/api/copilotkit/route.ts"
            import {
              CopilotRuntime,
              {{adapterImport}},
              copilotRuntimeNextJSAppRouterEndpoint,
            } from '@copilotkit/runtime';
            {{extraImports}}
            import { NextRequest } from 'next/server';

            {{clientSetup}}
            {{adapterSetup}}
            const runtime = new CopilotRuntime();

            export const POST = async (req: NextRequest) => {
              const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
                runtime,
                serviceAdapter,
                endpoint: '/api/copilotkit',
              });

              return handleRequest(req);
            };
            ```

            Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.
        </Tab>

        {/* Next.js Pages Router */}
        <Tab value="Next.js Pages Router">
            Create a new route to handle the `/api/copilotkit` endpoint:

            ```ts title="pages/api/copilotkit.ts"
            import { NextApiRequest, NextApiResponse } from 'next';
            import {
              CopilotRuntime,
              {{adapterImport}},
              copilotRuntimeNextJSPagesRouterEndpoint,
            } from '@copilotkit/runtime';
            {{extraImports}}

            {{clientSetup}}
            {{adapterSetup}}

            const handler = async (req: NextApiRequest, res: NextApiResponse) => {
              const runtime = new CopilotRuntime();

              const handleRequest = copilotRuntimeNextJSPagesRouterEndpoint({
                endpoint: '/api/copilotkit',
                runtime,
                serviceAdapter,
              });

              return await handleRequest(req, res);
            };

            export default handler;
            ```

            Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.
        </Tab>

        {/* Node.js Express */}
        <Tab value="Node.js Express">
            Create a new Express.js app and set up the Copilot Runtime handler:

            ```ts title="server.ts"
            import express from 'express';
            import {
              CopilotRuntime,
              {{adapterImport}},
              copilotRuntimeNodeHttpEndpoint,
            } from '@copilotkit/runtime';
            {{extraImports}}

            const app = express();
            {{clientSetup}}
            {{adapterSetup}}

            app.use('/copilotkit', (req, res, next) => {
              (async () => {
                const runtime = new CopilotRuntime();
                const handler = copilotRuntimeNodeHttpEndpoint({
                  endpoint: '/copilotkit',
                  runtime,
                  serviceAdapter,
                });

                return handler(req, res);
              })().catch(next);
            });

            app.listen(4000, () => {
              console.log('Listening at http://localhost:4000/copilotkit');
            });
            ```

            Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

            <Callout type="warn">
                Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
            </Callout>
        </Tab>

        {/* Node.js HTTP */}
        <Tab value="Node.js HTTP">
            Set up a simple Node.js HTTP server and use the Copilot Runtime to handle requests:

            ```ts title="server.ts"
            import { createServer } from 'node:http';
            import {
              CopilotRuntime,
              {{adapterImport}},
              copilotRuntimeNodeHttpEndpoint,
            } from '@copilotkit/runtime';
            {{extraImports}}

            {{clientSetup}}
            {{adapterSetup}}

            const server = createServer((req, res) => {
              const runtime = new CopilotRuntime();
              const handler = copilotRuntimeNodeHttpEndpoint({
                endpoint: '/copilotkit',
                runtime,
                serviceAdapter,
              });

              return handler(req, res);
            });

            server.listen(4000, () => {
              console.log('Listening at http://localhost:4000/copilotkit');
            });
            ```

            Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

            <Callout type="warn">
                Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
            </Callout>
        </Tab>

        {/* NestJS */}
        <Tab value="NestJS">
            Set up a controller in NestJS to handle the Copilot Runtime endpoint:

            ```ts title="copilotkit.controller.ts"
            import { All, Controller, Req, Res } from '@nestjs/common';
            import { CopilotRuntime, copilotRuntimeNestEndpoint, {{adapterImport}} } from '@copilotkit/runtime';
            import { Request, Response } from 'express';

            @Controller()
            export class CopilotkitController {
              @All('/copilotkit')
              copilotkit(@Req() req: Request, @Res() res: Response) {
                {{adapterSetup}}
                const runtime = new CopilotRuntime();

                const handler = copilotRuntimeNestEndpoint({
                  runtime,
                  serviceAdapter,
                  endpoint: '/copilotkit',
                });
                return handler(req, res);
              }
            }
            ```

            Your Copilot Runtime endpoint should be available at `http://localhost:3000/copilotkit`.

            <Callout type="warn">
                Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
            </Callout>
        </Tab>
    </Tabs>

</MultiProviderContent>



================================================
FILE: docs/snippets/self-hosting-copilot-runtime-langgraph-endpoint.mdx
================================================
import { MultiProviderContent, If } from "@/components/react/multi-provider-content/multi-provider-content";
import { quickStartProviders } from "@/components/react/multi-provider-content/utils";
import { IoLogoVercel, IoLogoNodejs } from "react-icons/io5";
import { SiNestjs } from "react-icons/si";
import { RiNextjsLine } from "react-icons/ri";

<Tabs groupId="endpoint-type" items={[
  { value: 'Next.js App Router', icon: <RiNextjsLine className="text-xl" /> },
  { value: 'Next.js Pages Router', icon: <RiNextjsLine className="text-xl" /> },
  { value: 'Node.js Express', icon: <IoLogoNodejs className="text-xl" /> },
  { value: 'Node.js HTTP', icon: <IoLogoNodejs className="text-xl" /> },
  { value: 'NestJS', icon: <SiNestjs className="text-xl" /> }
]}>
  {/* Next.js App Router */}
  <Tab value="Next.js App Router">
    Create a new route to handle the `/api/copilotkit` endpoint.

    ```ts title="app/api/copilotkit/route.ts"
    import {
      CopilotRuntime,
      OpenAIAdapter,
      copilotRuntimeNextJSAppRouterEndpoint,
      langGraphPlatformEndpoint
    } from "@copilotkit/runtime";
    import OpenAI from "openai";
    import { NextRequest } from "next/server";

    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    const serviceAdapter = new OpenAIAdapter({ openai } as any);

    const runtime = new CopilotRuntime({
      remoteEndpoints: [
        // [!code highlight:12]
        langGraphPlatformEndpoint({
          deploymentUrl: "your-api-url", // make sure to replace with your real deployment url,
          langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
          agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
            {
              name: 'my_agent', 
              description: 'A helpful LLM agent.',
              assistantId: 'your-assistant-ID' // optional, but recommended!
            }
          ]
        }),
      ],
    });

    export const POST = async (req: NextRequest) => {
      const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
        runtime,
        serviceAdapter,
        endpoint: "/api/copilotkit",
      });

      return handleRequest(req);
    };
    ```
  </Tab>

    {/* Next.js Pages Router */}
    <Tab value="Next.js Pages Router">
        Create a new route to handle the `/api/copilotkit` endpoint:

        ```ts title="pages/api/copilotkit.ts"
        import {
          CopilotRuntime,
          OpenAIAdapter,
          copilotRuntimeNextJSPagesRouterEndpoint,
          langGraphPlatformEndpoint
        } from '@copilotkit/runtime';
        import OpenAI from "openai";
        import { NextApiRequest, NextApiResponse } from 'next';

        const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
        const serviceAdapter = new OpenAIAdapter({ openai } as any);

        const handler = async (req: NextApiRequest, res: NextApiResponse) => {
          const runtime = new CopilotRuntime({
            remoteEndpoints: [
              // [!code highlight:12]
              langGraphPlatformEndpoint({
                deploymentUrl: "your-api-url", // make sure to replace with your real deployment url
                langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
                agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
                  {
                    name: 'my_agent',
                    description: 'A helpful LLM agent.',
                    assistantId: 'your-assistant-ID' // optional, but recommended!
                  }
                ]
              }),
            ],
          });

          const handleRequest = copilotRuntimeNextJSPagesRouterEndpoint({
            endpoint: '/api/copilotkit',
            runtime,
            serviceAdapter,
          });

          return await handleRequest(req, res);
        };

        export default handler;
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.
    </Tab>

    {/* Node.js Express */}
    <Tab value="Node.js Express">
        Create a new Express.js app and set up the Copilot Runtime handler:

        ```ts title="server.ts"
        import express from 'express';
        import {
          CopilotRuntime,
          OpenAIAdapter,
          copilotRuntimeNodeHttpEndpoint,
          langGraphPlatformEndpoint
        } from '@copilotkit/runtime';
        import OpenAI from "openai";

        const app = express();
        const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
        const serviceAdapter = new OpenAIAdapter({ openai } as any);

        app.use('/copilotkit', (req, res, next) => {
          const runtime = new CopilotRuntime({
            remoteEndpoints: [
              // [!code highlight:12]
              langGraphPlatformEndpoint({
                deploymentUrl: "your-api-url", // make sure to replace with your real deployment url
                langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
                agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
                  {
                    name: 'my_agent',
                    description: 'A helpful LLM agent.',
                    assistantId: 'your-assistant-ID' // optional, but recommended!
                  }
                ]
              }),
            ],
          });

          const handler = copilotRuntimeNodeHttpEndpoint({
            endpoint: '/copilotkit',
            runtime,
            serviceAdapter,
          });

          return handler(req, res, next);
        });

        app.listen(4000, () => {
          console.log('Listening at http://localhost:4000/copilotkit');
        });
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>

    {/* Node.js HTTP */}
    <Tab value="Node.js HTTP">
        Set up a simple Node.js HTTP server and use the Copilot Runtime to handle requests:

        ```ts title="server.ts"
        import { createServer } from 'node:http';
        import {
          CopilotRuntime,
          OpenAIAdapter,
          copilotRuntimeNodeHttpEndpoint,
          langGraphPlatformEndpoint
        } from '@copilotkit/runtime';
        import OpenAI from "openai";

        const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
        const serviceAdapter = new OpenAIAdapter({ openai } as any);

        const server = createServer((req, res) => {
          const runtime = new CopilotRuntime({
            remoteEndpoints: [
              // [!code highlight:12]
              langGraphPlatformEndpoint({
                deploymentUrl: "your-api-url", // make sure to replace with your real deployment url
                langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
                agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
                  {
                    name: 'my_agent',
                    description: 'A helpful LLM agent.',
                    assistantId: 'your-assistant-ID' // optional, but recommended!
                  }
                ]
              }),
            ],
          });

          const handler = copilotRuntimeNodeHttpEndpoint({
            endpoint: '/copilotkit',
            runtime,
            serviceAdapter,
          });

          return handler(req, res);
        });

        server.listen(4000, () => {
          console.log('Listening at http://localhost:4000/copilotkit');
        });
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>

    {/* NestJS */}
    <Tab value="NestJS">
        Set up a controller in NestJS to handle the Copilot Runtime endpoint:

        ```ts title="copilotkit.controller.ts"
        import { All, Controller, Req, Res } from '@nestjs/common';
        import { 
          CopilotRuntime, 
          copilotRuntimeNestEndpoint, 
          OpenAIAdapter,
          langGraphPlatformEndpoint 
        } from '@copilotkit/runtime';
        import { Request, Response } from 'express';
        import OpenAI from "openai";

        @Controller()
        export class CopilotkitController {
          @All('/copilotkit')
          copilotkit(@Req() req: Request, @Res() res: Response) {
            const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
            const serviceAdapter = new OpenAIAdapter({ openai } as any);
            
            const runtime = new CopilotRuntime({
              remoteEndpoints: [
                // [!code highlight:12]
                langGraphPlatformEndpoint({
                  deploymentUrl: "your-api-url", // make sure to replace with your real deployment url
                  langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
                  agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
                    {
                      name: 'my_agent',
                      description: 'A helpful LLM agent.',
                      assistantId: 'your-assistant-ID' // optional, but recommended!
                    }
                  ]
                }),
              ],
            });

            const handler = copilotRuntimeNestEndpoint({
              runtime,
              serviceAdapter,
              endpoint: '/copilotkit',
            });
            return handler(req, res);
          }
        }
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>
</Tabs>



================================================
FILE: docs/snippets/self-hosting-copilot-runtime-starter.mdx
================================================
import { MultiProviderContent, If } from "@/components/react/multi-provider-content/multi-provider-content";
import { quickStartProviders } from "@/components/react/multi-provider-content/utils";
import { IoLogoVercel, IoLogoNodejs } from "react-icons/io5";
import { SiNestjs } from "react-icons/si";
import { RiNextjsLine } from "react-icons/ri";

<Tabs groupId="endpoint-type" items={[
  { value: 'Next.js App Router', icon: <RiNextjsLine className="text-xl" /> },
  { value: 'Next.js Pages Router', icon: <RiNextjsLine className="text-xl" /> },
  { value: 'Node.js Express', icon: <IoLogoNodejs className="text-xl" /> },
  { value: 'Node.js HTTP', icon: <IoLogoNodejs className="text-xl" /> },
  { value: 'NestJS', icon: <SiNestjs className="text-xl" /> }
]}>
  {/* Next.js App Router */}
  <Tab value="Next.js App Router">
    Create a new route to handle the `/api/copilotkit` endpoint.

    ```ts title="app/api/copilotkit/route.ts"
    import {
      CopilotRuntime,
      ExperimentalEmptyAdapter,
      copilotRuntimeNextJSAppRouterEndpoint,
      langGraphPlatformEndpoint
    } from "@copilotkit/runtime";;
    import { NextRequest } from "next/server";

    // You can use any service adapter here for multi-agent support.
    const serviceAdapter = new ExperimentalEmptyAdapter();

    const runtime = new CopilotRuntime({
      remoteEndpoints: [
        // added in next step...
      ],
    });

    export const POST = async (req: NextRequest) => {
      const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
        runtime,
        serviceAdapter,
        endpoint: "/api/copilotkit",
      });

      return handleRequest(req);
    };
    ```
  </Tab>

    {/* Next.js Pages Router */}
    <Tab value="Next.js Pages Router">
        Create a new route to handle the `/api/copilotkit` endpoint:

        ```ts title="pages/api/copilotkit.ts"
        import {
          CopilotRuntime,
          ExperimentalEmptyAdapter,
          copilotRuntimeNextJSPagesRouterEndpoint,
        } from '@copilotkit/runtime';
        import { NextApiRequest, NextApiResponse } from 'next';

        const serviceAdapter = new ExperimentalEmptyAdapter();

        const handler = async (req: NextApiRequest, res: NextApiResponse) => {
          const runtime = new CopilotRuntime({
            remoteEndpoints: [
              // added in next step...
            ],
          });

          const handleRequest = copilotRuntimeNextJSPagesRouterEndpoint({
            endpoint: '/api/copilotkit',
            runtime,
            serviceAdapter,
          });

          return await handleRequest(req, res);
        };

        export default handler;
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/api/copilotkit`.
    </Tab>

    {/* Node.js Express */}
    <Tab value="Node.js Express">
        Create a new Express.js app and set up the Copilot Runtime handler:

        ```ts title="server.ts"
        import express from 'express';
        import {
          CopilotRuntime,
          ExperimentalEmptyAdapter,
          copilotRuntimeNodeHttpEndpoint,
          langGraphPlatformEndpoint
        } from '@copilotkit/runtime';

        const app = express();
        const serviceAdapter = new ExperimentalEmptyAdapter();

        app.use('/copilotkit', (req, res, next) => {
          const runtime = new CopilotRuntime({
            remoteEndpoints: [
              // added in next step...
            ],
          });

          const handler = copilotRuntimeNodeHttpEndpoint({
            endpoint: '/copilotkit',
            runtime,
            serviceAdapter,
          });

          return handler(req, res, next);
        });

        app.listen(4000, () => {
          console.log('Listening at http://localhost:4000/copilotkit');
        });
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>

    {/* Node.js HTTP */}
    <Tab value="Node.js HTTP">
        Set up a simple Node.js HTTP server and use the Copilot Runtime to handle requests:

        ```ts title="server.ts"
        import { createServer } from 'node:http';
        import {
          CopilotRuntime,
          ExperimentalEmptyAdapter,
          copilotRuntimeNodeHttpEndpoint,
        } from '@copilotkit/runtime';


        const serviceAdapter = new ExperimentalEmptyAdapter();

        const server = createServer((req, res) => {
          const runtime = new CopilotRuntime({
            remoteEndpoints: [
              // added in next step...
            ],
          });

          const handler = copilotRuntimeNodeHttpEndpoint({
            endpoint: '/copilotkit',
            runtime,
            serviceAdapter,
          });

          return handler(req, res);
        });

        server.listen(4000, () => {
          console.log('Listening at http://localhost:4000/copilotkit');
        });
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:4000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>

    {/* NestJS */}
    <Tab value="NestJS">
        Set up a controller in NestJS to handle the Copilot Runtime endpoint:

        ```ts title="copilotkit.controller.ts"
        import { All, Controller, Req, Res } from '@nestjs/common';
        import { 
          CopilotRuntime, 
          copilotRuntimeNestEndpoint, 
          ExperimentalEmptyAdapter,
        } from '@copilotkit/runtime';
        import { Request, Response } from 'express';


        @Controller()
        export class CopilotkitController {
          @All('/copilotkit')
          copilotkit(@Req() req: Request, @Res() res: Response) {
            const serviceAdapter = new ExperimentalEmptyAdapter();
            
            const runtime = new CopilotRuntime({
              remoteEndpoints: [
                // added in next step...
              ],
            });

            const handler = copilotRuntimeNestEndpoint({
              runtime,
              serviceAdapter,
              endpoint: '/copilotkit',
            });
            return handler(req, res);
          }
        }
        ```

        Your Copilot Runtime endpoint should be available at `http://localhost:3000/copilotkit`.

        <Callout type="warn">
            Remember to point your `runtimeUrl` to the correct endpoint in your client-side code, e.g. `http://localhost:PORT/copilotkit`.
        </Callout>
    </Tab>
</Tabs>



================================================
FILE: docs/snippets/self-hosting-remote-endpoints.mdx
================================================
import { MultiProviderContent, If } from "@/components/react/multi-provider-content/multi-provider-content";
import { quickStartProviders } from "@/components/react/multi-provider-content/utils";
import { IoLogoVercel, IoLogoNodejs } from "react-icons/io5";
import { SiNestjs } from "react-icons/si";
import { RiNextjsLine } from "react-icons/ri";

<Tabs groupId="lg-deployment-type" items={["Local (LangGraph Studio)", "Self hosted (FastAPI)", "LangGraph Platform"]}>
  <Tab value="Local (LangGraph Studio)">
    ```ts
    import { 
      CopilotRuntime,
      langGraphPlatformEndpoint  // [!code highlight]
      // ...
    } from "@copilotkit/runtime";
    // ...
    const runtime = new CopilotRuntime({
      remoteEndpoints: [
        // [!code highlight:12]
        langGraphPlatformEndpoint({
          deploymentUrl: "your-api-url", // make sure to replace with your real deployment url,
          langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
          agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
            {
              name: 'sample_agent', 
              description: 'A helpful LLM agent.',
              assistantId: 'your-assistant-ID' // optional, but recommended!
            }
          ]
        }),
      ],
    });
    // ...
    ```
  </Tab>
  <Tab value="Self hosted (FastAPI)">
    ```ts
    import { 
      CopilotRuntime,
      // ...
    } from "@copilotkit/runtime";
    // ...
    const runtime = new CopilotRuntime({
      remoteEndpoints: [
        // [!code highlight:3]
        // Our FastAPI endpoint URL
        { url: "http://localhost:8000/copilotkit" },
      ],
    });
    // ...
    ```
  </Tab>

  <Tab value="LangGraph Platform">
    ```ts
    import { 
      CopilotRuntime,
      langGraphPlatformEndpoint  // [!code highlight]
      // ...
    } from "@copilotkit/runtime";
    // ...
    const runtime = new CopilotRuntime({
      remoteEndpoints: [
        // [!code highlight:12]
        langGraphPlatformEndpoint({
          deploymentUrl: "your-api-url", // make sure to replace with your real deployment url,
          langsmithApiKey: process.env.LANGSMITH_API_KEY, // only used in LangGraph Platform deployments
          agents: [ // List any agents available under "graphs" list in your langgraph.json file; give each a description explaining when it should be called.
            {
              name: 'sample_agent', 
              description: 'A helpful LLM agent.',
              assistantId: 'your-assistant-ID' // optional, but recommended!
            }
          ]
        }),
      ],
    });
    // ...
    ```
  </Tab>
</Tabs>



================================================
FILE: docs/snippets/use-client-callout.mdx
================================================
### Specify `"use client"` (Next.js App Router)

<Callout type="info">
  This is only necessary if you are using Next.js with the App Router.
</Callout>

```tsx title="YourComponent.tsx"
"use client"
```

Like other React hooks such as `useState` and `useEffect`, this is a **client-side** hook.
If you're using Next.js with the App Router, you'll need to add the `"use client"` directive at the top of any file using this hook.


================================================
FILE: docs/snippets/cloud/cloud-copilotkit-provider.mdx
================================================
```tsx title="layout.tsx"
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core"; // [!code highlight]
 
export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body>
        {/* Use the public api key you got from Copilot Cloud  */} // [!code highlight:4]
        <CopilotKit publicApiKey="<your-copilot-cloud-public-api-key>"> 
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```


================================================
FILE: docs/snippets/coagents/cloud-configure-copilotkit-provider.mdx
================================================
```tsx title="layout.tsx"
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core"; // [!code highlight]

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body> 
        {/* Use the public api key you got from Copilot Cloud  */} // [!code highlight:5]
        <CopilotKit 
          publicApiKey="<your-copilot-cloud-public-api-key>"
          agent="sample_agent" // the name of the agent you want to use
        > 
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```


================================================
FILE: docs/snippets/coagents/run-and-connect-agent.mdx
================================================
You'll need to run your agent and connect it to CopilotKit before proceeding. If you haven't done so already,
you can follow the instructions in the [Getting Started](/coagents/quickstart/langgraph) guide.

If you don't already have an agent, you can use the [coagent starter](https://github.com/copilotkit/copilotkit/tree/main/examples/coagents-starter) as a starting point
as this guide uses it as a starting point.



================================================
FILE: docs/snippets/coagents/self-host-configure-copilotkit-provider.mdx
================================================
```tsx title="layout.tsx"
import "./globals.css";
import { ReactNode } from "react";
import { CopilotKit } from "@copilotkit/react-core"; // [!code highlight]

export default function RootLayout({ children }: { children: ReactNode }) {
  return (
    <html lang="en">
      <body> 
        {/* Use the public api key you got from Copilot Cloud  */} // [!code highlight:5]
        <CopilotKit 
          runtimeUrl="/api/copilotkit"
          agent="sample_agent" // the name of the agent you want to use
        > 
          {children}
        </CopilotKit>
      </body>
    </html>
  );
}
```


================================================
FILE: docs/.husky/pre-commit
================================================
pnpm test


